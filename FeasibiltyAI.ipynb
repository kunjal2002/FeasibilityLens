{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6c04b3d737804c7191b3b4c8946d417e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6fae665d7cf6436683f0152500ddab15",
              "IPY_MODEL_f2c942dcb0be43dcb63c599a1bd1f629",
              "IPY_MODEL_88f00bbae556467fb35b57145f809386"
            ],
            "layout": "IPY_MODEL_fbce5e01cc7d437d81b8e4a53cb4abd7"
          }
        },
        "6fae665d7cf6436683f0152500ddab15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6696be1f10b245938c6c545cb76d4c5f",
            "placeholder": "​",
            "style": "IPY_MODEL_983bc14708864556b9ddcd6b5dedad49",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f2c942dcb0be43dcb63c599a1bd1f629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ac9ea49f5e345f0bd21a2e07f8960a6",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ae1ade4db0e457eb5d63f438fa753a5",
            "value": 2324
          }
        },
        "88f00bbae556467fb35b57145f809386": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b21181ca77a4a4cacd56fd88c35b11d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d681751cb2544859847f530a3803bb7",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "fbce5e01cc7d437d81b8e4a53cb4abd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6696be1f10b245938c6c545cb76d4c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983bc14708864556b9ddcd6b5dedad49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ac9ea49f5e345f0bd21a2e07f8960a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae1ade4db0e457eb5d63f438fa753a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7b21181ca77a4a4cacd56fd88c35b11d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d681751cb2544859847f530a3803bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c9dd46c49b14f80b0aeaaaf81fd3e02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d85797b24b3484f93a62809aa5c699b",
              "IPY_MODEL_8a90d67a1bd2435889c9b50d481fc87f",
              "IPY_MODEL_1f0a72e1e0a44b26ac61efcd89d117fb"
            ],
            "layout": "IPY_MODEL_fb447596414f4988a5e80b3bc400f5f3"
          }
        },
        "1d85797b24b3484f93a62809aa5c699b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be9946c7030d4ac280becd6e0a771d2c",
            "placeholder": "​",
            "style": "IPY_MODEL_4f171b546ed345308435156ff65ff943",
            "value": "spiece.model: 100%"
          }
        },
        "8a90d67a1bd2435889c9b50d481fc87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_501d368476d94e80b7de223344a42022",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12f316c7a54541be8378001508e9e86c",
            "value": 791656
          }
        },
        "1f0a72e1e0a44b26ac61efcd89d117fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e2d1a7b39ad46de8ea20d4b07dd9885",
            "placeholder": "​",
            "style": "IPY_MODEL_ecd945ed92514333bc56aa35d7e74042",
            "value": " 792k/792k [00:00&lt;00:00, 4.03MB/s]"
          }
        },
        "fb447596414f4988a5e80b3bc400f5f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be9946c7030d4ac280becd6e0a771d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f171b546ed345308435156ff65ff943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "501d368476d94e80b7de223344a42022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12f316c7a54541be8378001508e9e86c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9e2d1a7b39ad46de8ea20d4b07dd9885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd945ed92514333bc56aa35d7e74042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b5ed1daecc94f4c9ae77d3ddc701ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79e26eed6bd1497b9d2ccdfaca13a5c2",
              "IPY_MODEL_21b9e081195a4ed1bf02a38255ac8e07",
              "IPY_MODEL_420e66b3ca424955bf8b1880cc047305"
            ],
            "layout": "IPY_MODEL_ec67fabbe8d240ec8cf64f532d369132"
          }
        },
        "79e26eed6bd1497b9d2ccdfaca13a5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbdb35cbf1e54ad9b1884c26f61ba5f5",
            "placeholder": "​",
            "style": "IPY_MODEL_c9217a40b1cb4dd7bc4c63a4408cd0a2",
            "value": "tokenizer.json: 100%"
          }
        },
        "21b9e081195a4ed1bf02a38255ac8e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a5a649a002949b4a73b3a8ad59cab7f",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6397ae95a51a4f19a3d85e3c82294dd7",
            "value": 1389353
          }
        },
        "420e66b3ca424955bf8b1880cc047305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1b8adb3e26f4c3da545f3a378f67b6b",
            "placeholder": "​",
            "style": "IPY_MODEL_32c28f399ca44ce2bb0396df222cc497",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 39.8MB/s]"
          }
        },
        "ec67fabbe8d240ec8cf64f532d369132": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbdb35cbf1e54ad9b1884c26f61ba5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9217a40b1cb4dd7bc4c63a4408cd0a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a5a649a002949b4a73b3a8ad59cab7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6397ae95a51a4f19a3d85e3c82294dd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a1b8adb3e26f4c3da545f3a378f67b6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32c28f399ca44ce2bb0396df222cc497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9bd8eff9bf6434bbbd0898447b86ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4cf8f67ee92a44018b0e0caddab8bf3d",
              "IPY_MODEL_532d57fe101d4be3b354171f6f6d9b40",
              "IPY_MODEL_0e3a4eb80f50415aafa0a02dbb8ff495"
            ],
            "layout": "IPY_MODEL_a4d8e709b31545dbb94ddf46bebe47b5"
          }
        },
        "4cf8f67ee92a44018b0e0caddab8bf3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cd6d4af36aa4844bbd788d3158ff966",
            "placeholder": "​",
            "style": "IPY_MODEL_60adae0d71bb431b8f4b932c31369bd9",
            "value": "config.json: 100%"
          }
        },
        "532d57fe101d4be3b354171f6f6d9b40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b7fb1d30f2d4d54b0dea326167023e9",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8460bd8216e4d80adb99c1fbf1a02d1",
            "value": 1206
          }
        },
        "0e3a4eb80f50415aafa0a02dbb8ff495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd159fb41f4c43399a3361c7e183f409",
            "placeholder": "​",
            "style": "IPY_MODEL_38aa632f0af14f7a92219e09611710d8",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 80.4kB/s]"
          }
        },
        "a4d8e709b31545dbb94ddf46bebe47b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cd6d4af36aa4844bbd788d3158ff966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60adae0d71bb431b8f4b932c31369bd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1b7fb1d30f2d4d54b0dea326167023e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8460bd8216e4d80adb99c1fbf1a02d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd159fb41f4c43399a3361c7e183f409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38aa632f0af14f7a92219e09611710d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9fe5f76d6eb4ded874eebe4571be764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b4ffe8cb9e9c4542b9d186383521bd0f",
              "IPY_MODEL_de6e3800eee14b3a9de53decacb6a600",
              "IPY_MODEL_624195d353764320b8dfd3d4312c2342"
            ],
            "layout": "IPY_MODEL_ea98dda097ed448ca3ed2d7b3e667e05"
          }
        },
        "b4ffe8cb9e9c4542b9d186383521bd0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae7b4a4eba244bcad904eeb90107d37",
            "placeholder": "​",
            "style": "IPY_MODEL_d1cb70ee2ac94ac68306fa25e1c4db4d",
            "value": "model.safetensors: 100%"
          }
        },
        "de6e3800eee14b3a9de53decacb6a600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ab9c32e70b744bcaa62d1d86597d7f7",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2b5460cc5b643f78debc8a6c1e1339c",
            "value": 242043056
          }
        },
        "624195d353764320b8dfd3d4312c2342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_309e60c0314e4430a1f38584f6af9e2a",
            "placeholder": "​",
            "style": "IPY_MODEL_f3c99d5211254891bbc38f4ee21f848e",
            "value": " 242M/242M [00:01&lt;00:00, 171MB/s]"
          }
        },
        "ea98dda097ed448ca3ed2d7b3e667e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae7b4a4eba244bcad904eeb90107d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1cb70ee2ac94ac68306fa25e1c4db4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9ab9c32e70b744bcaa62d1d86597d7f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2b5460cc5b643f78debc8a6c1e1339c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "309e60c0314e4430a1f38584f6af9e2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3c99d5211254891bbc38f4ee21f848e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Init"
      ],
      "metadata": {
        "id": "Fz-3MVoSEMln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Libraries"
      ],
      "metadata": {
        "id": "cZoKyP8FkWWY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6diFsoJjBQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a8c2d6b-2f13-4c21-81b7-c502e6162f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.20)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.5-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/42.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.44)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.6)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.39)\n",
            "Collecting pdfminer.six==20231228 (from pdfplumber)\n",
            "  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfplumber-0.11.5-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, PyPDF2, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pdfminer.six, nvidia-cusolver-cu12, pdfplumber\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.10.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pdfminer.six-20231228 pdfplumber-0.11.5 pypdfium2-4.30.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torch transformers faiss-cpu langchain PyPDF2 pdfplumber"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive"
      ],
      "metadata": {
        "id": "YLTf0rbdDvIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CS0f7y9ZkScC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375fcd5f-226b-4540-8776-e35d9226d871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "\n",
        "# # Load SciBERT tokenizer & model\n",
        "# model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# # Function to get embeddings\n",
        "# def get_embedding(text):\n",
        "#     inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs)\n",
        "#     return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()"
      ],
      "metadata": {
        "id": "vaqnIs3WM-oJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize FAISS"
      ],
      "metadata": {
        "id": "PszUopjMDzC9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import faiss\n",
        "# import numpy as np\n",
        "\n",
        "# # Initialize FAISS index\n",
        "# d = 512  # T5 output dimension\n",
        "# index = faiss.IndexFlatIP(d)"
      ],
      "metadata": {
        "id": "qOeSofX4kdIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnwgpuqBjHUW",
        "outputId": "724296b9-b464-45b2-8e0f-6536e975239d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Extraction\n",
        "\n",
        "1.   Extract Text\n",
        "2.   Convert to chunks\n",
        "3.   Pickle for later use\n",
        "\n"
      ],
      "metadata": {
        "id": "yMQDa3P7ECfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Text"
      ],
      "metadata": {
        "id": "IDy4Cf0cD28i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import textwrap\n",
        "\n",
        "# def chunk_text(text, chunk_size=500):\n",
        "#     return textwrap.wrap(text, width=chunk_size)"
      ],
      "metadata": {
        "id": "xn6kNE3Iocam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#path to the papers\n",
        "pdf_directory = \"/content/drive/Shareddrives/ECS_289G/papers\""
      ],
      "metadata": {
        "id": "0-1wVKgQp2Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pdfplumber\n",
        "# from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# # Initialize SciBERT tokenizer and model\n",
        "# tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "# model = BertModel.from_pretrained('allenai/scibert_scivocab_uncased').to(device)\n",
        "\n",
        "# # Function to extract text from PDFs\n",
        "# def extract_text_from_pdf(pdf_path):\n",
        "#     with open(pdf_path, \"rb\") as file:\n",
        "#         reader = PyPDF2.PdfReader(file)\n",
        "#         text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "#     sentences = text.split('.')\n",
        "#     return sentences"
      ],
      "metadata": {
        "id": "aPRYobZiOSWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sliding_window_chunking_raw(text, window_size=2048, overlap=512):\n",
        "    \"\"\"\n",
        "    Chunk the raw text using the sliding window approach.\n",
        "    \"\"\"\n",
        "    chunks = []\n",
        "    for i in range(0, len(text), window_size - overlap):\n",
        "        chunk = text[i:i + window_size]\n",
        "        chunks.append(chunk)\n",
        "\n",
        "        # Stop if we've reached the end of the text\n",
        "        if i + window_size >= len(text):\n",
        "            break\n",
        "\n",
        "    return chunks\n"
      ],
      "metadata": {
        "id": "yULBN6Fgaqc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "\n",
        "# Function to extract text from PDFs\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        reader = PyPDF2.PdfReader(file)\n",
        "        text = \"\\n\".join([page.extract_text() for page in reader.pages if page.extract_text()])\n",
        "\n",
        "    chunks = sliding_window_chunking_raw(text)\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "DXc5k7DJYl8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5Model\n",
        "tokenizer = T5Tokenizer.from_pretrained('t5-small')  # or 't5-large'\n",
        "model = T5Model.from_pretrained('t5-small').to(device)"
      ],
      "metadata": {
        "id": "NdY9IZegYb4T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318,
          "referenced_widgets": [
            "6c04b3d737804c7191b3b4c8946d417e",
            "6fae665d7cf6436683f0152500ddab15",
            "f2c942dcb0be43dcb63c599a1bd1f629",
            "88f00bbae556467fb35b57145f809386",
            "fbce5e01cc7d437d81b8e4a53cb4abd7",
            "6696be1f10b245938c6c545cb76d4c5f",
            "983bc14708864556b9ddcd6b5dedad49",
            "2ac9ea49f5e345f0bd21a2e07f8960a6",
            "4ae1ade4db0e457eb5d63f438fa753a5",
            "7b21181ca77a4a4cacd56fd88c35b11d",
            "0d681751cb2544859847f530a3803bb7",
            "3c9dd46c49b14f80b0aeaaaf81fd3e02",
            "1d85797b24b3484f93a62809aa5c699b",
            "8a90d67a1bd2435889c9b50d481fc87f",
            "1f0a72e1e0a44b26ac61efcd89d117fb",
            "fb447596414f4988a5e80b3bc400f5f3",
            "be9946c7030d4ac280becd6e0a771d2c",
            "4f171b546ed345308435156ff65ff943",
            "501d368476d94e80b7de223344a42022",
            "12f316c7a54541be8378001508e9e86c",
            "9e2d1a7b39ad46de8ea20d4b07dd9885",
            "ecd945ed92514333bc56aa35d7e74042",
            "4b5ed1daecc94f4c9ae77d3ddc701ace",
            "79e26eed6bd1497b9d2ccdfaca13a5c2",
            "21b9e081195a4ed1bf02a38255ac8e07",
            "420e66b3ca424955bf8b1880cc047305",
            "ec67fabbe8d240ec8cf64f532d369132",
            "dbdb35cbf1e54ad9b1884c26f61ba5f5",
            "c9217a40b1cb4dd7bc4c63a4408cd0a2",
            "3a5a649a002949b4a73b3a8ad59cab7f",
            "6397ae95a51a4f19a3d85e3c82294dd7",
            "a1b8adb3e26f4c3da545f3a378f67b6b",
            "32c28f399ca44ce2bb0396df222cc497",
            "c9bd8eff9bf6434bbbd0898447b86ad8",
            "4cf8f67ee92a44018b0e0caddab8bf3d",
            "532d57fe101d4be3b354171f6f6d9b40",
            "0e3a4eb80f50415aafa0a02dbb8ff495",
            "a4d8e709b31545dbb94ddf46bebe47b5",
            "5cd6d4af36aa4844bbd788d3158ff966",
            "60adae0d71bb431b8f4b932c31369bd9",
            "1b7fb1d30f2d4d54b0dea326167023e9",
            "a8460bd8216e4d80adb99c1fbf1a02d1",
            "bd159fb41f4c43399a3361c7e183f409",
            "38aa632f0af14f7a92219e09611710d8",
            "a9fe5f76d6eb4ded874eebe4571be764",
            "b4ffe8cb9e9c4542b9d186383521bd0f",
            "de6e3800eee14b3a9de53decacb6a600",
            "624195d353764320b8dfd3d4312c2342",
            "ea98dda097ed448ca3ed2d7b3e667e05",
            "bae7b4a4eba244bcad904eeb90107d37",
            "d1cb70ee2ac94ac68306fa25e1c4db4d",
            "9ab9c32e70b744bcaa62d1d86597d7f7",
            "b2b5460cc5b643f78debc8a6c1e1339c",
            "309e60c0314e4430a1f38584f6af9e2a",
            "f3c99d5211254891bbc38f4ee21f848e"
          ]
        },
        "outputId": "81ca0f93-ac4f-430d-f563-4fe726b07787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c04b3d737804c7191b3b4c8946d417e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c9dd46c49b14f80b0aeaaaf81fd3e02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b5ed1daecc94f4c9ae77d3ddc701ace"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9bd8eff9bf6434bbbd0898447b86ad8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a9fe5f76d6eb4ded874eebe4571be764"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# s = \"I like dancing. Dancing is my hobby\"\n",
        "# print(s.split('.'))"
      ],
      "metadata": {
        "id": "xDsN5Nh0v1kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to generate embedding for text using SciBERT\n",
        "def get_embedding(text):\n",
        "    if not text or not isinstance(text, str):\n",
        "        raise ValueError(\"Input text must be a non-empty string\")\n",
        "\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=4096).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.encoder(**inputs)  # Use the encoder to get embeddings\n",
        "\n",
        "    embedding = outputs.last_hidden_state.mean(dim=1).squeeze().cpu().numpy().reshape(1,-1).astype('float32')\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "AzhX82SUPAH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def normalize_embeddings(embeddings):\n",
        "    norm = np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
        "    return embeddings / norm"
      ],
      "metadata": {
        "id": "ywbncY4AQ_eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chunk_map = {}"
      ],
      "metadata": {
        "id": "yIJVA0mMPIRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# import PyPDF2\n",
        "\n",
        "# chunk_id = 0  # ID for the text chunks\n",
        "# for filename in os.listdir(pdf_directory):\n",
        "#     if filename.endswith(\".pdf\"):\n",
        "#         pdf_path = os.path.join(pdf_directory, filename)\n",
        "#         print(f\"Processing {filename}...\")\n",
        "\n",
        "#         # Extract text from the PDF\n",
        "#         sentences = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "#         # Split text into smaller chunks if needed (e.g., paragraphs or sentences)\n",
        "#         # text_chunks = chunk_text(text)  # You can split by sentence or paragraphs\n",
        "\n",
        "#         # Generate embeddings for each chunk\n",
        "#         for sentence in sentences:\n",
        "#               embedding = get_embedding(sentence)\n",
        "#               embedding = embedding.reshape(1, -1)  # Reshape to (1, d)\n",
        "#               normalize_embedding = normalize_embeddings(embedding)\n",
        "#               # Add the embedding to FAISS index\n",
        "#               index.add(normalize_embedding)\n",
        "\n",
        "\n",
        "#               # Store the chunk with a unique ID\n",
        "#               chunk_map[chunk_id] = (sentence, filename)\n",
        "#               chunk_id += 1"
      ],
      "metadata": {
        "id": "TG6FLMGLv1uS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d288ddc-3312-4c7f-9816-5844751dcc4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing A novel classification method for paper-reviewer recommendation.pdf...\n",
            "Processing A Novel Method for Video Tracking Performance Evaluation.pdf...\n",
            "Processing A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf...\n",
            "Processing A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf...\n",
            "Processing Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf...\n",
            "Processing A Novel Approach for E-mail Classification Using FastText.pdf...\n",
            "Processing A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf...\n",
            "Processing A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf...\n",
            "Processing A Case Against CXL Memory Pooling.pdf...\n",
            "Processing A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf...\n",
            "Processing Camouflage_Defect_Identification_A_Novel_Approach.pdf...\n",
            "Processing Gender Classification using Facial Embeddings A Novel Approach.pdf...\n",
            "Processing NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf...\n",
            "Processing CogVideo Large-scale Pretraining for Text-to-Video.pdf...\n",
            "Processing The Rise and Potential of Large Language Model.pdf...\n",
            "Processing A comparison of machine learning algorithms on design smell detection.pdf...\n",
            "Processing Issues and assumptions on the road from raw signals.pdf...\n",
            "Processing Persistent Memory Research in the Post-Optane Era.pdf...\n",
            "Processing Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf...\n",
            "Processing THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf...\n",
            "Processing AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf...\n",
            "Processing The CHERI capability model- Revisiting RISC in an age of risk.pdf...\n",
            "Processing Application Performance and Hexibility on Exokernel Systems .pdf...\n",
            "Processing Design_Tradeoffs_for_SSD_Performance.pdf...\n",
            "Processing Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf...\n",
            "Processing Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf...\n",
            "Processing Project_loon.pdf...\n",
            "Processing Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf...\n",
            "Processing holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf...\n",
            "Processing The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf...\n",
            "Processing Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf...\n",
            "Processing QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf...\n",
            "Processing TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf...\n",
            "Processing Noise Estimation Using Density Estimation.pdf...\n",
            "Processing Adaptive Graph Convolutional Recurrent Network.pdf...\n",
            "Processing A Learning Algorithm for Boltzmann machines.pdf...\n",
            "Processing Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf...\n",
            "Processing An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf...\n",
            "Processing Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf...\n",
            "Processing The Generalization-Stability Tradeoff In Neural Network Pruning.pdf...\n",
            "Processing EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf...\n",
            "Processing Towards High Resolution Video Generation with Progressive Growing.pdf...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(chunk_map))\n",
        "print(index.ntotal)"
      ],
      "metadata": {
        "id": "wNfw3S0aKZ_K"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the FAISS index and chunk mapping to Google Drive\n",
        "faiss.write_index(index, \"/content/drive/Shareddrives/ECS_289G/faiss_index_1.idx\")\n",
        "with open(\"/content/drive/Shareddrives/ECS_289G/chunk_map_1.pkl\", \"wb\") as f:\n",
        "    pickle.dump(chunk_map, f)\n",
        "\n",
        "print(\"FAISS index and chunk mapping saved successfully!\")"
      ],
      "metadata": {
        "id": "JlHVsWk7wDMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "185dee31-a03f-4513-af7f-f928b2a22382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index and chunk mapping saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #embeddings\n",
        "# from transformers import AutoTokenizer, AutoModel\n",
        "# import torch\n",
        "\n",
        "# # Load SciBERT tokenizer & model\n",
        "# model_name = \"allenai/scibert_scivocab_uncased\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# # Function to get embeddings\n",
        "# def get_embedding(text):\n",
        "#     inputs = tokenizer(text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(**inputs)\n",
        "#     return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n"
      ],
      "metadata": {
        "id": "lMbMkyvQpKjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AkG6pj-k43kG",
        "outputId": "effa49ff-76d9-4d6d-a8e3-d89d8ca8ac6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "\n",
        "index = faiss.read_index(\"/content/drive/Shareddrives/ECS_289G/faiss_index.idx\")"
      ],
      "metadata": {
        "id": "l25QAMZ94Lt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Specify the path to your pickle file\n",
        "pickle_file_path = '/content/drive/Shareddrives/ECS_289G/chunk_map.pkl'\n",
        "\n",
        "# Open the pickle file in binary read mode\n",
        "with open(pickle_file_path, 'rb') as f:\n",
        "    chunk_map = pickle.load(f)\n",
        "\n",
        "# Verify the extracted dictionary\n",
        "print(chunk_map)"
      ],
      "metadata": {
        "id": "xeAsTGc44ulp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55e1fa2d-4189-4424-8353-2cafeed25d58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: ('A novel classiﬁcation method for paper-reviewer\\nrecommendation\\nShu Zhao1•Dong Zhang1•Zhen Duan1•Jie Chen1•Yan-ping Zhang1•\\nJie Tang2\\nReceived: 3 November 2017 / Published online: 31 March 2018\\n/C211Akade ´miai Kiado ´, Budapest, Hungary 2018\\nAbstract Reviewer recommendation problem in the research ﬁeld usually refers to invite\\nexperts to comment on the quality of papers, proposals, etc. How to effectively and\\naccurately recommend reviewers for the submitted papers and proposals is a meaningful\\nand still tough task. At present, many unsupervised recommendation methods have been\\nresearched to solve this task. In this paper, a novel classiﬁcation method named Word\\nMover’s Distance–Constructive Covering Algorithm (WMD–CCA, for short) is proposed\\nto solve the reviewer recommendation problem as a classiﬁcation issue. A submission or a\\nreviewer is described by some tags, such as keywords, research interests, and so on. First,\\nthe submission or the reviewer is represented as some vectors by a word embedding\\nmethod. That is to say, each tag describing a submission or a reviewer is represented as a\\nvector. Second, the Word Mover’s Distance (WMD, for short) method is used to measure\\nthe minimum distances between submissions and reviewers. Actually, the papers usually\\nhave research ﬁeld information, and utilizing them well might improve the reviewer rec-\\nommendation accuracy. So ﬁnally, the reviewer recommendation task is transformed into a\\nclassiﬁcation problem which is solved by a supervised learning method- Constructive\\n&Shu Zhao\\nzhaoshuzs2002@hotmail.com\\nDong Zhang\\ndarkzd_zhang@163.com\\nZhen Duan\\nycduan@gmail.com\\nJie Chen\\nchenjie200398@163.com\\nYan-ping Zhang\\nzhangyp2@gmail.com\\nJie Tang\\njery.tang@gmail.com\\n1School of Computer Science and Technology, Anhui University, Hefei 230601, China\\n2Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China\\n123Scientometrics (2018) 115:1293–1313\\nhttps://doi.org/10.1007/s11192-018-2726-6\\nCovering Algorithm (CCA, for short). Comparative experiments are con', 'A novel classification method for paper-reviewer recommendation.pdf'), 1: ('\\n&Shu Zhao\\nzhaoshuzs2002@hotmail.com\\nDong Zhang\\ndarkzd_zhang@163.com\\nZhen Duan\\nycduan@gmail.com\\nJie Chen\\nchenjie200398@163.com\\nYan-ping Zhang\\nzhangyp2@gmail.com\\nJie Tang\\njery.tang@gmail.com\\n1School of Computer Science and Technology, Anhui University, Hefei 230601, China\\n2Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China\\n123Scientometrics (2018) 115:1293–1313\\nhttps://doi.org/10.1007/s11192-018-2726-6\\nCovering Algorithm (CCA, for short). Comparative experiments are conducted with 4\\npublic datasets and a synthetic dataset from Baidu Scholar, which show that the proposedmethod WMD–CCA effectively solves the reviewer recommendation task as a classiﬁ-cation issue and improves the recommendation accuracy.\\nKeywords Reviewer recommendation /C1Classiﬁcation /C1Word embedding /C1Word\\nMover’s Distance /C1Constructive Covering Algorithm\\nMathematics Subject Classiﬁcation 68T99\\nJEL Classiﬁcation C63/C1C89\\nIntroduction\\nIn academic ﬁeld, lots of papers and proposals are submitted to conferences, journals or\\nadministration departments. And generally professional experts are invited to comment on\\nthe quality of submissions (Jin et al. 2017 ). A very important task in this process is the\\nrecommendation of reviewers for papers (i.e. paper-reviewer recommendation). As far aswe know, the manual reviewer recommendation is time-consuming and sometimes unfair(Yang et al. 2009 ). Thus, how to effectively and accurately recommend reviewers for the\\nsubmitted papers or proposals is a meaningful but still tough task.\\nSigniﬁcant progress has been made in paper-reviewer recommendation recently. Several\\napproaches have been proposed to improve the quality of recommendation and make itperform more automatically. Most of these approaches mainly fall into two categories:retrieval-based methods and matching-based methods. They mainly treat it as a retrievalproblem or a matching problem (Fang and Zhai 2007 ; Karimzadehgan et al. 2008 ;\\nKarimzadehgan and Zhai 2009 ; Shon et al. 2017 ), applying some unsupervised', 'A novel classification method for paper-reviewer recommendation.pdf'), 2: ('till tough task.\\nSigniﬁcant progress has been made in paper-reviewer recommendation recently. Several\\napproaches have been proposed to improve the quality of recommendation and make itperform more automatically. Most of these approaches mainly fall into two categories:retrieval-based methods and matching-based methods. They mainly treat it as a retrievalproblem or a matching problem (Fang and Zhai 2007 ; Karimzadehgan et al. 2008 ;\\nKarimzadehgan and Zhai 2009 ; Shon et al. 2017 ), applying some unsupervised methods to\\nsolve it. First, the retrieval-based approaches mainly focus on the topic relationshipbetween submissions and reviewer candidates, such as language model (Karimzadehganet al. 2008 ), Latent Semantic Index (LSI) (Deerwester et al. 1990 ), topic model (Mimno\\nand Mccallum 2007 ; Peng et al. 2017 ), etc. Others investigate different aspects of reviewer\\nrecommendation or expert ﬁnding, including a number of considerations, such as authority,diversity, expertise, availability (Karimzadehgan and Zhai 2009 ; Liu et al. 2014 ; Tang\\net al. 2008 ; Liu et al. 2016 ) and the research interests (Jin et al. 2017 ) of the reviewer.\\nSecond, the matching-based approaches compute a matching based on a bipartite graphbetween the submissions and the reviewer candidates (Charlin et al. 2012 ; Conry et al.\\n2009 ). They compute the relevance degree and construct a bipartite graph and then the\\nright matching can be obtained according to the maximum weight matching based bipartite\\ngraph.\\nOne of the major steps in reviewer recommendation is the selection of reviewers. There\\nwere many other approaches developed to promote and improve the selection of reviewers.Optimization approaches were widely used as a search algorithm in various assignmentand combinational application where it demonstrated satisfactory performances (Deep andDas2008 ). Genetic algorithms (GA) and ant colony optimization (ACO) are combined to\\nquickly ﬁnd good solutions (Kolasa and Kro ´l2010 ). Several heuristic algorithms have also\\nbeen proposed for automat', 'A novel classification method for paper-reviewer recommendation.pdf'), 3: ('recommendation is the selection of reviewers. There\\nwere many other approaches developed to promote and improve the selection of reviewers.Optimization approaches were widely used as a search algorithm in various assignmentand combinational application where it demonstrated satisfactory performances (Deep andDas2008 ). Genetic algorithms (GA) and ant colony optimization (ACO) are combined to\\nquickly ﬁnd good solutions (Kolasa and Kro ´l2010 ). Several heuristic algorithms have also\\nbeen proposed for automatically assigning reviewers to papers that provide effective andgood results (Kolasa and Krol 2011 ). Besides, some intelligent decision support approa-\\nches were proposed to recommend experts for proposals (Liu et al. 2016 ; Xu et al. 2010 ;\\nFan et al. 2009 ; Sun et al. 2008 ). They used decision models to determine the best solution1294 Scientometrics (2018) 115:1293–1313\\n123\\nof reviewer assignment. A content-based recommender system was proposed, which aimed\\nat the selection of reviewers (experts) to evaluate research proposals or articles (Pro-tasiewicz et al. 2016 ).\\nTo make reviewer recommendation more effective and accurate is an important and\\narduous task, which still faces some key challenges. First, there is a typically complexlexical gap between submissions and reviewers which are usually text. So an accurate textrepresentation is exactly important. Second, the deeper relationship between submissionsand reviewer candidates can improve the recommendation quality. Besides, some methods\\nseldom make full use of the existing key information. They often only utilize the text\\ninformation of submissions in the reviewer recommendation task.\\nWe aim to tackle these challenges via a proposed classiﬁcation method called Word\\nMover’s Distance–Constructive Covering Algorithm (WMD–CCA, for short), whichtransforms the reviewer recommendation problem into a classiﬁcation problem integratingthe research ﬁeld information of submissions. In other words, given some reviewer can-didates and a new submission, we predict the ', 'A novel classification method for paper-reviewer recommendation.pdf'), 4: ('l use of the existing key information. They often only utilize the text\\ninformation of submissions in the reviewer recommendation task.\\nWe aim to tackle these challenges via a proposed classiﬁcation method called Word\\nMover’s Distance–Constructive Covering Algorithm (WMD–CCA, for short), whichtransforms the reviewer recommendation problem into a classiﬁcation problem integratingthe research ﬁeld information of submissions. In other words, given some reviewer can-didates and a new submission, we predict the research ﬁeld labels for reviewers and assignone to the submission owing to the same label.\\nThe main contribution of this paper is to treat the paper-reviewer recommendation\\nproblem as a classiﬁcation issue. We accomplish it with the following steps. First, werepresent the submission and the reviewer with their tags, which are the keywords of the\\nsubmission and the research interests of the reviewer. To ﬁnd the complex semantic\\nrelationship, inspired by the success of word embedding, the tags are transformed intovectors to overcome the lexical gap and the word-to-word relation can be regarded as thesimilarity of word vector. Then based on the word embedding, the Word Mover’s Distance(Kusner et al. 2015 ) (WMD, for short) is used. And it learns the deep correlation between\\nthe submission and the reviewer using an optimization. Finally, the research ﬁeld labels areconsidered as supervised information in our method. So the reviewer recommendationproblem is transformed into a classiﬁcation issue with a supervised method—ConstructiveCovering Algorithm (Zhang et al. 2013 ) (CCA, for short), and we predict the potential\\nresearch ﬁeld information of reviewer. Experimental study on 4 public datasets shows theeffectiveness of WMD–CCA method. Furthermore, we utilize the proposed method to\\nrecommend reviewers for papers on a synthetic dataset, and it presents the potential of our\\nmethod.\\nThe remainder of the paper is organized as follows. ‘‘ Related works ’’ section presents\\nthe related works in solving the reviewer recomm', 'A novel classification method for paper-reviewer recommendation.pdf'), 5: (' method—ConstructiveCovering Algorithm (Zhang et al. 2013 ) (CCA, for short), and we predict the potential\\nresearch ﬁeld information of reviewer. Experimental study on 4 public datasets shows theeffectiveness of WMD–CCA method. Furthermore, we utilize the proposed method to\\nrecommend reviewers for papers on a synthetic dataset, and it presents the potential of our\\nmethod.\\nThe remainder of the paper is organized as follows. ‘‘ Related works ’’ section presents\\nthe related works in solving the reviewer recommendation problem. ‘‘ Problem formula-\\ntion’’ section formally formulates the introduced problem. ‘‘ WMD–CCA method for\\nreviewer recommendation ’’ section mainly introduces the proposed method WMD–CCA.\\nIn ‘‘Experiments ’’ section, experiments and evaluations present the potential of the pro-\\nposed method on 4 public datasets and a synthetic dataset. And ‘‘ Conclusions ’’ section\\nsummarizes our contributions and gives future work.\\nRelated works\\nThe research on paper-reviewer recommendation is similar to the researches on peerreview and research and development (R&D) project selection. Quality of peer review\\ngreatly depends on the degree of matching between reviewers and assigned research\\nproposals (Xu et al. 2010 ). Peer review and experts play important roles in research project\\nselection, because their opinions affect the potential value of a project (Liu et al. 2016 ).Scientometrics (2018) 115:1293–1313 1295\\n123\\nHow to assign the most appropriate experts to review project proposals might greatly affect\\nthe quality of project selection, which in turn could affect the return on investment of thefunding organization (Liu et al. 2016 ).\\nConventionally, the research on reviewer recommendation can be mainly categorized\\ninto two branches. One is the retrieval-based methods which treat each submission as aquery to retrieve the relevant reviewers. Commonly, ﬁrst, publications of reviewer can-didates are collected to represent his/her research ﬁeld knowledge. Then, submissions aremodelled as a query. Finally, reviewers ', 'A novel classification method for paper-reviewer recommendation.pdf'), 6: ('uality of project selection, which in turn could affect the return on investment of thefunding organization (Liu et al. 2016 ).\\nConventionally, the research on reviewer recommendation can be mainly categorized\\ninto two branches. One is the retrieval-based methods which treat each submission as aquery to retrieve the relevant reviewers. Commonly, ﬁrst, publications of reviewer can-didates are collected to represent his/her research ﬁeld knowledge. Then, submissions aremodelled as a query. Finally, reviewers are recommended according to the relevance of\\ntheir knowledge and submissions. Fang and Zhai ( 2007 ) proposed a general probabilistic\\nframework for studying expert ﬁnding problem and proposed estimation strategies whichare all effective to improve retrieval accuracy. Karimzadehgan et al. ( 2008 ) proposed three\\ngeneral strategies for reviewer retrieval and studied how to model multiple aspects ofreviewer expertise. Liu et al. ( 2014 ) studied how to rank reviewer candidates while bal-\\nancing three objectives: authority, expertise and diversity. They also proposed a graphconstructed on reviewer candidates and the query paper, and then an optimizationframework with sparsity principle was applied.\\nAnd the other is matching-based methods which commonly have two steps. First, it\\nconstructs a bipartite graph and computes the weights of the edges. Then an appropriatematching is formulated based on the graph. Charlin et al. ( 2012 ) proposed a framework to\\noptimize paper-to-reviewer assignments and studied several matching objectives. Conry\\net al. ( 2009 ) proposed to learn the weights and computed the maximum weight matching\\nfor a recommendation. Li et al. ( 2017 ) modelled papers and reviewers based on matching\\ndegree considering an academic social network to ﬁnd a conﬁdent, fair and balancedassignment.\\nWith the main two categories methods proposed, there were also many other approaches\\ndeveloped to improve the quality of the reviewer selection and ﬁnd the better solutions.Jian Ma et al. proposed a hybrid knowledge ', 'A novel classification method for paper-reviewer recommendation.pdf'), 7: ('atching objectives. Conry\\net al. ( 2009 ) proposed to learn the weights and computed the maximum weight matching\\nfor a recommendation. Li et al. ( 2017 ) modelled papers and reviewers based on matching\\ndegree considering an academic social network to ﬁnd a conﬁdent, fair and balancedassignment.\\nWith the main two categories methods proposed, there were also many other approaches\\ndeveloped to improve the quality of the reviewer selection and ﬁnd the better solutions.Jian Ma et al. proposed a hybrid knowledge and model approach for reviewer assignment(Sun et al. 2008 ). And then a hybrid approach using knowledge rule and genetic algorithm\\nto group the proposals (Fan et al. 2009 ). Knowledge rules are designed to deal with\\nproposal identiﬁcation and proposal classiﬁcation, and the genetic algorithm is developed\\nto search for the expected groupings. Decision support approaches (Sun et al. 2008 ; Fan\\net al. 2009 ; Xu et al. 2010 ) were often proposed to identify valid proposals and reviewers,\\nand it increased overall grouping quality. Protasiewicz et al. ( 2016 ) proposed the archi-\\ntecture of the content-based recommender system for selection of reviewers, which wassupported by various techniques of information retrieval. The recommendation were basedon the combination of cosine similarity between keywords and full-text index. Tayal et al.proposed a new method of solving reviewer assignment problem using type-2 fuzzy sets torepresent the expertise levels of the various reviewers in the different domains. Thismethod considered the four important aspects: workload balancing of reviewers, avoidingconﬂicts of interest, considering individual preferences by incorporating bidding andmapping multiple keywords of a proposal (Tayal et al. 2014 ). And it can calculate the\\nexpertise level of each reviewer in different domains.\\nIn the past, many methods of paper-reviewer recommendation considered the keywords\\nof papers or the proﬁles of reviewers. Word is the most basic unit of carrying semantics ina sentence or a document. Prope', 'A novel classification method for paper-reviewer recommendation.pdf'), 8: ('considered the four important aspects: workload balancing of reviewers, avoidingconﬂicts of interest, considering individual preferences by incorporating bidding andmapping multiple keywords of a proposal (Tayal et al. 2014 ). And it can calculate the\\nexpertise level of each reviewer in different domains.\\nIn the past, many methods of paper-reviewer recommendation considered the keywords\\nof papers or the proﬁles of reviewers. Word is the most basic unit of carrying semantics ina sentence or a document. Properly transforming words into a continuous vector space is acommonly used method in many natural language processing (NLP) tasks or other text-related works. Word embedding may be the most popular technique for word represen-tation learning over billions of words and skip-gram model (Mikolov et al. 2013a )i sa\\nwidely employed method to compute such an embedding. In embedding spaces, the1296 Scientometrics (2018) 115:1293–1313\\n123\\nneighbors of every word are generally semantically related (Mikolov et al. 2013b ), espe-\\ncially we can also use a similarity function to predict how likely a word is given its context.Many researchers used this property to solve challenging problems, such as Q/A matching(Shen et al. 2017 ), sentiment classiﬁcation (Ren et al. 2016 ), query expansion (Diaz et al.\\n2016 ).\\nFor many approaches, few of them can exploit the semantic information of reviewers\\nand papers, and capture the semantic similarity between reviewers and papers. Besides,making full use of the research ﬁeld label information of reviewers and papers can improve\\nthe quality of the reviewer recommendation. Hence, in this study, a method is proposed to\\nmeasure the deeper research relationship between the reviewers and papers, and ﬁnd thebetter solutions with the help of label information.\\nProblem formulation\\nIn this section, we ﬁrst deﬁne fundamental concepts, including papers (i.e. submissions),reviewers, research ﬁeld labels and ﬁeld relationship. Subsequently, we give the formu-lations of problems and the solutions to the ', 'A novel classification method for paper-reviewer recommendation.pdf'), 9: ('ation of reviewers and papers can improve\\nthe quality of the reviewer recommendation. Hence, in this study, a method is proposed to\\nmeasure the deeper research relationship between the reviewers and papers, and ﬁnd thebetter solutions with the help of label information.\\nProblem formulation\\nIn this section, we ﬁrst deﬁne fundamental concepts, including papers (i.e. submissions),reviewers, research ﬁeld labels and ﬁeld relationship. Subsequently, we give the formu-lations of problems and the solutions to the problems we face.\\nWe assume that the paper and the reviewer are described as different numbers of tags,\\ndenoted as p\\ni¼fki1;ki2;...;kini(for paper pi) and rj¼fkj1;kj2;...;kjnjg(for reviewer rj),\\nrespectively. For instance, different tags kiniare the different keywords of the submission\\npi, and tags kjnjare research interests of the reviewer rj. The paper submitted has the\\nresearch ﬁeld label liand then the paper set can be represented as\\nP¼f p1;l1ðÞ ;p2;l2ðÞ ;...;ðpn;lnÞg. Let L¼fL1;L2;...;Ltgbe the set of | L|=t ( t \\\\n)\\ndifferent ﬁeld labels and all li2L. It’s notable that research ﬁeld relationship distance\\nbetween a paper piand a reviewer rjis important in paper-reviewer recommendation task.\\nTo make reviewer recommendation more effective and accurate, we transform this task\\ninto a classiﬁcation issue.\\nAccording to the above notations, the problem is formulated as follows.\\nProblem\\nGiven a paper set P¼f p1;l1ðÞ ;p2;l2ðÞ ;...;ðpn;lnÞg, where pi¼fki1;ki2;...;kinigis a\\npaper described by nitags, and lirefers to the label of this paper. And given a reviewer\\ncandidate set R¼fr1;r2;...;rmg, where rj¼fkj1;kj2;...;kjnjgis a reviewer candidate\\ndescribed by njresearch interests. The goal of the problem is to predict the yj2Lfor each\\nrj.To achieve the goal mentioned before, there are two main sub-problems we should solve\\nﬁrst. We deﬁne these sub-problems addressed in this paper:\\nSub-problem 1\\nTags representation The complex lexical gap between kiniandkjnjis the obstacle of mining\\nthe deeper relationship of piandrj. To ov', 'A novel classification method for paper-reviewer recommendation.pdf'), 10: (' the label of this paper. And given a reviewer\\ncandidate set R¼fr1;r2;...;rmg, where rj¼fkj1;kj2;...;kjnjgis a reviewer candidate\\ndescribed by njresearch interests. The goal of the problem is to predict the yj2Lfor each\\nrj.To achieve the goal mentioned before, there are two main sub-problems we should solve\\nﬁrst. We deﬁne these sub-problems addressed in this paper:\\nSub-problem 1\\nTags representation The complex lexical gap between kiniandkjnjis the obstacle of mining\\nthe deeper relationship of piandrj. To overcome this problem, we represent kiniandkjnjas\\nvectors viandvjwhich can capture distributional syntactic and semantic information in a\\ncorpus.Scientometrics (2018) 115:1293–1313 1297\\n123\\nSub-problem 2\\nThe deeper research ﬁeld relationship The semantic relationship of kiniand kjnjcan be\\nattained from a distance function and the tag-level relationship contributes to the research\\nﬁeld relationship between piandrj. It’s not accurate to learn the deeper relationship by\\neasily considering the semantic distance dðvi;vjÞof two keyword (tag) vectors. To tackle\\nthis limitation, the keyword-level correlation and the weight of keyword are used to\\noptimize the deeper relationship between piand rj. A minimum cumulative distance\\ndistance ðpi;rjÞis computed to represent the deeper relationship. The d/C1;/C1ðÞ and\\ndistance /C1;/C1ðÞ are formulated by two distance methods, which would be introduced in next\\nsection.\\nWith above two sub-problems solved, it’s highly desirable but challenging to transform\\nthis recommendation task into a classiﬁcation problem. The research ﬁeld labels liof each\\npiare seldom utilized to guide the reviewer recommendation as supervised information. In\\nthis paper, we use a constructive classiﬁcation methods to achieve our goal. The ﬁeld labelsof P are considered to predict y\\nj2Lfor a given rj. After ﬁeld label prediction, rjcan be\\nassigned to review piowing to li¼yj.\\nThis paper-reviewer recommendation task is transformed into a classiﬁcation issue, and\\nwe proposed a method WMD–CCA to solve it. We ﬁrst re', 'A novel classification method for paper-reviewer recommendation.pdf'), 11: ('into a classiﬁcation problem. The research ﬁeld labels liof each\\npiare seldom utilized to guide the reviewer recommendation as supervised information. In\\nthis paper, we use a constructive classiﬁcation methods to achieve our goal. The ﬁeld labelsof P are considered to predict y\\nj2Lfor a given rj. After ﬁeld label prediction, rjcan be\\nassigned to review piowing to li¼yj.\\nThis paper-reviewer recommendation task is transformed into a classiﬁcation issue, and\\nwe proposed a method WMD–CCA to solve it. We ﬁrst represent the tags of piandrjas\\ndistributional vectors. Then the deeper research ﬁeld relationship between piand rjis\\ncalculated, and ﬁnally, we predict the ﬁeld label for the reviewer candidate according to the\\nﬁeld relationship. The details of the proposed method are introduced in ‘‘ WMD–CCA\\nmethod for reviewer recommendation ’’ section.\\nWMD–CCA method for reviewer recommendation\\nTransforming the reviewer recommendation problem into a classiﬁcation issue is a chal-\\nlenging task. In the context of paper-reviewer recommendation, it is crucial to accuratelymine the relationship between the paper and the reviewer candidate. Actually, a reviewercan review a paper when they belong to the same research ﬁeld. In another word, they arein the same category. In this paper, we propose novel classiﬁcation method WMD–CCA,which takes the research ﬁeld relationship and the research ﬁeld information into con-\\nsideration. In Algorithm 1, we introduce WMD–CCA, and we denote the ‘‘paper or pro-\\nposals’’ as ‘‘paper’’ in this section. The details of the proposed method are described asfollowed and an overview is presented in Fig. 1.1298 Scientometrics (2018) 115:1293–1313\\n123\\nIn Algorithm 1 above, Euclidean ðvi;vjÞis Euclidean Norm to measure the similarity\\nbetween two tag vectors. It will be introduced in ‘‘ Tags representation of submission and\\nreviewer ’’ section. The distance wmdðpi;rjÞis the deeper relationship between a paper piand\\na reviewer rjcalculated by the operation function WMD ðpi;rjÞ. It will be introduced in\\n‘‘Mining', 'A novel classification method for paper-reviewer recommendation.pdf'), 12: ('ion. The details of the proposed method are described asfollowed and an overview is presented in Fig. 1.1298 Scientometrics (2018) 115:1293–1313\\n123\\nIn Algorithm 1 above, Euclidean ðvi;vjÞis Euclidean Norm to measure the similarity\\nbetween two tag vectors. It will be introduced in ‘‘ Tags representation of submission and\\nreviewer ’’ section. The distance wmdðpi;rjÞis the deeper relationship between a paper piand\\na reviewer rjcalculated by the operation function WMD ðpi;rjÞ. It will be introduced in\\n‘‘Mining relationship between paper and reviewer ’’ section. In Step 3, a relationship matrix\\nQis computed, and the element is the relationship WMD ðpi;pi0Þ. According to the matrix\\nQand the paper set P, the classiﬁcation algorithm CCA is used to form a cover set C.\\nFinally, the research ﬁeld label is predicted by the function Predict ðC;distance wmdðpi;rjÞÞ\\nbased on the cover set Cand distance wmdðpi;rjÞ. The details of Step 3 will be introduced in\\n‘‘Predict the label of reviewer ’’ section.\\nFig. 1 Overview of WMD–CCA method for reviewer recommendationScientometrics (2018) 115:1293–1313 1299\\n123\\nTags representation of submission and reviewer\\nRepresenting the tags of submission and reviewer is a fundamental task. The keywords of a\\npaper are important tags in an academic repository, generally summarizing the coreinformation of paper. The aim of our method is to transform keywords into a continuousspace and carry the syntactic and semantic information. For this purpose, techniques fromWord2vec package\\n1are used, which contains two main models, namely skip-gram and\\nCBOW. They could produce word embedding based a training corpus. For comparisonexperiments, we use the Google News (Mikolov et al. 2013b ) as public corpus and choose\\nthe skip-gram model to obtain the distribution representation of tags (keywords). Forexample, a brief description of tags representation for a paper (or a reviewer) is presented\\nin Fig. 2. From the trained neural network based language model, the tags k\\ni1;ki2;...;kini fg\\nare represented as vector', 'A novel classification method for paper-reviewer recommendation.pdf'), 13: ('contains two main models, namely skip-gram and\\nCBOW. They could produce word embedding based a training corpus. For comparisonexperiments, we use the Google News (Mikolov et al. 2013b ) as public corpus and choose\\nthe skip-gram model to obtain the distribution representation of tags (keywords). Forexample, a brief description of tags representation for a paper (or a reviewer) is presented\\nin Fig. 2. From the trained neural network based language model, the tags k\\ni1;ki2;...;kini fg\\nare represented as vectors vi1;vi2;...;vini fg . All of tag vectors have the dimensionality of\\n300.\\nMining relationship between paper and reviewer\\nMining the ﬁeld relationship between paper and reviewer is crucial to the performance of\\nreviewer recommendation. The easily-measured similarity between the word embeddingscannot describe the deeper ﬁeld relationship. An optimization problem on the relationship\\nbetween paper and reviewer is considered in our proposed method. We utilize a distance\\nmetric-Word Mover’s Distance to measure the minimum distance as the deeper relation-ship between them.\\nWord Mover’s Distance (WMD) (Kusner et al. 2015 ) is enlightened by a metric Earth\\nMover’s Distance (EMD) (Rubner et al. 1998 ) in Computer Vision and it’s a novel\\neffective metric to measure the similarity or dissimilarity for a pair documents. Anassumption that the distance (or similarity) between two words is a natural building blockto measure the distance between two documents. In this paper, we regard the paper or thereviewer as documents, which consist of some tags. Further, the distance calculated fromWMD can be the deeper relationship between a paper and a reviewer.\\nWe begin with the word-level distance between two keywords k\\niniandkjnjinpiandrj\\nrespectively according to their learned word embedding viandvj. Here we use Euclidean\\nNorm to compute the relationship between two distributional vectors. The relationship is\\ndeﬁned as:\\ndðkini;kjnjÞ¼ vi/C0vj/C12/C12/C12/C12¼Euclidean ðvi;vjÞð 1Þ\\nWe convert a transportation problem to an optimization', 'A novel classification method for paper-reviewer recommendation.pdf'), 14: ('hich consist of some tags. Further, the distance calculated fromWMD can be the deeper relationship between a paper and a reviewer.\\nWe begin with the word-level distance between two keywords k\\niniandkjnjinpiandrj\\nrespectively according to their learned word embedding viandvj. Here we use Euclidean\\nNorm to compute the relationship between two distributional vectors. The relationship is\\ndeﬁned as:\\ndðkini;kjnjÞ¼ vi/C0vj/C12/C12/C12/C12¼Euclidean ðvi;vjÞð 1Þ\\nWe convert a transportation problem to an optimization problem as Eq. ( 2). The\\nresearch ﬁeld correlation between piandrjcan be obtained owing to the keyword-level\\ndistance d ðkini;kjnjÞis a distance metric.\\n1https://code.google.com/p/word2vec/ .1300 Scientometrics (2018) 115:1293–1313\\n123\\ndistance wmdpi;rj/C0/C1\\n¼min\\nW/C210Xn\\ni;j¼1Wij/C1dðkini;kjnjÞ\\nSubject to:\\nXn\\nj¼1Wij¼weight ki8i21;...;n fg\\nXn\\ni¼1Wij¼weight0\\nkj8j2f1;...;ngð2Þ\\nThe core of our work as Eq. ( 2) showed is to calculate the deeper research ﬁeld rela-\\ntionship between piand rj. We ﬁrst regard piorrjas a keyword list. Then we denote\\nweightki¼tfi=Pn\\ni0tfi0as the weight of keyword kiifkiappears tfitimes in pi, where nis\\nthe number of words in the list. And weight0\\nkj¼tfj=Pn\\nj0tfj0is the weight of kjinrj.\\nHowever, word embedding and Euclidean Norm can incorporate the semantic information\\nbetween two individual words into the paper-reviewer level distance. Then the relationshipbetween p\\niandrjis mined out by the minimum amount of summing up keyword-level\\ndistances, which are the similarities between the keywords in piand the keywords in rj. Let\\nW2Rn/C2nbe a ﬂow matrix, where Wij/C210 represents how much weight of word kiinpi\\nmoves to kjinrj, and nis the number of unique words in piandrj. Theoretically, WMD\\nallows every word travel into any word in total or in parts. When entirely moving pi(all\\nkeywords in pi)t orj(all keywords in rj), we ensure that the entire outgoing ﬂow from word\\nkishould equal to weightkiand the entire incoming ﬂow from word kjshould equal to\\nweight0\\nkj.\\nThe distance wmdðpi;rjÞreprese', 'A novel classification method for paper-reviewer recommendation.pdf'), 15: (' keywords in piand the keywords in rj. Let\\nW2Rn/C2nbe a ﬂow matrix, where Wij/C210 represents how much weight of word kiinpi\\nmoves to kjinrj, and nis the number of unique words in piandrj. Theoretically, WMD\\nallows every word travel into any word in total or in parts. When entirely moving pi(all\\nkeywords in pi)t orj(all keywords in rj), we ensure that the entire outgoing ﬂow from word\\nkishould equal to weightkiand the entire incoming ﬂow from word kjshould equal to\\nweight0\\nkj.\\nThe distance wmdðpi;rjÞrepresents the deeper research ﬁeld relationship between piand\\nrjafter an optimization. It’s a good solution to mining the correlation by the similarities\\namong their tag vectors. Therefore, we incorporate the deeper ﬁeld relationship further in\\nour method to predict the research ﬁeld label for an unlabelled reviewer.\\nPredict the label of reviewer\\nAccording to the deeper research ﬁeld relationship above, we transform the reviewer\\nrecommendation task into a classiﬁcation issue. In another word, the solution is to predict\\nFig. 2 Tags representationScientometrics (2018) 115:1293–1313 1301\\n123\\nthe research ﬁeld labels for reviewer candidates using a classiﬁcation method. The fast and\\nconstructive learning method- Constructive Covering Algorithm (CCA) is applied to ourrecommendation task. CCA can construct some covers adaptively by computing the coverradius based on the relationship between given paper samples and the location of sampledistribution space. During the constructive learning process of CCA (Wang 2008 ), the\\ncover radius is related to the distances among the papers. We regard the relationshipbetween papers as this distance, so the relationship mined from WMD are used rightlyhere. In our method, we only utilize CCA to predict the label of the reviewer candidate due\\nto the relationship obtained from the WMD.\\nBefore the CCA process, we ﬁrst compute the relationship WMD ðp\\ni;pi0Þbetween every\\ntwo papers piand pi0. Then a relationship matrix Qis formed and the element Qi;i0is\\nWMD ðpi;pi0Þ. Given a training paper set', 'A novel classification method for paper-reviewer recommendation.pdf'), 16: ('cover radius is related to the distances among the papers. We regard the relationshipbetween papers as this distance, so the relationship mined from WMD are used rightlyhere. In our method, we only utilize CCA to predict the label of the reviewer candidate due\\nto the relationship obtained from the WMD.\\nBefore the CCA process, we ﬁrst compute the relationship WMD ðp\\ni;pi0Þbetween every\\ntwo papers piand pi0. Then a relationship matrix Qis formed and the element Qi;i0is\\nWMD ðpi;pi0Þ. Given a training paper set P¼f p1;l1ðÞ ;p2;l2ðÞ ;...;ðpn;lnÞgand the rela-\\ntionship matrix Q. CCA ﬁrst trains the covers according to Qand then predicts the labels in\\nthe testing process for the reviewer candidates. The main steps of CCA is presented inAlgorithm 2 below.\\nRadius computing is very important in covers training process, and we can clearly\\nunderstand from Fig. 3. For current learning paper pcurrent which is regarded as a cover\\ncenter in a cover construction. Cover radius Ris the compromise radius Rcom(Zhang et al.\\n2013 ),which is computed from Eq. ( 3) with a balanced parameter l.Rmaxis the minimum\\ndistance (i.e. relationship) between the cover center and the dissimilar (i.e. different cat-\\negory) papers, while Rminis the maximum distance between the cover center and the\\nsimilar (i.e. same category) papers. The Rmaxand the Rminare described as Eqs. (4)and\\n(5)respectively. Notably, Rmincannot beyond Rmax, and three kinds of radius (i.e.\\nRmax,RminandRcom) are three cover radius computing methods. We choose Rcomin our\\nproposed method. Based on the relationship and distribution of the papers, compromiseradius R\\ncom is computed and the covers of the different category are constructed\\nadaptively.\\nRcom¼1/C0l ðÞ /C1 Rminþl/C1Rmax ð3Þ1302 Scientometrics (2018) 115:1293–1313\\n123\\nRmax¼min\\nli6¼li0Qi;i0i¼1;2;...;n ð4Þ\\nRmin¼max\\nli¼li0fQi;i0jQi;i0\\\\min\\nli6¼li0Qi;i0gi¼1;2;...;n ð5Þ\\nAfter the training process, a cover set C¼fC1\\n1;C2\\n1;...;Cn1\\n1;C1\\n2;C2\\n2;...;Cn2\\n2;...;\\nC1\\nk;...;Cnk\\nkgare formed. Based on the cover set, reviewer candidates are', 'A novel classification method for paper-reviewer recommendation.pdf'), 17: ('d method. Based on the relationship and distribution of the papers, compromiseradius R\\ncom is computed and the covers of the different category are constructed\\nadaptively.\\nRcom¼1/C0l ðÞ /C1 Rminþl/C1Rmax ð3Þ1302 Scientometrics (2018) 115:1293–1313\\n123\\nRmax¼min\\nli6¼li0Qi;i0i¼1;2;...;n ð4Þ\\nRmin¼max\\nli¼li0fQi;i0jQi;i0\\\\min\\nli6¼li0Qi;i0gi¼1;2;...;n ð5Þ\\nAfter the training process, a cover set C¼fC1\\n1;C2\\n1;...;Cn1\\n1;C1\\n2;C2\\n2;...;Cn2\\n2;...;\\nC1\\nk;...;Cnk\\nkgare formed. Based on the cover set, reviewer candidates are treated as testing\\nsamples to predict the ﬁeld labels.\\nFurthermore, we let the reviewer candidate set R¼fr1;r2;...;rmgbe the testing set.\\nThe samples in PandRare located in the same distribution space. To be simple, we take\\nthe two-dimensional dataset as an example to describe the testing process. From thedescription in Fig. 4, there are three covers cover\\n1;cover 2;cover 3constructed which\\nconsist of three different categories and c1;c2;c3are the cover centers, R1;R2;R3are the\\ncover radiuses respectively. The samples in black are training samples, and the samples inwhite are testing samples. We have two strategies for prediction process according to thelocation of the testing sample. First, for the reviewer r\\n1;r2;r3which are in a cover, their\\nlabels are similar to the cover center of these covers. Second, for some samples which are\\nnot in the covers, such as r4;r5, etc. A simple method, which is according to the shortest\\ndistance from the sample to the different cover boundary, is applied to the predictionprocess. For example, d\\n1;d2;d3are the distances from r5to the three cover boundaries. The\\nlabel of r5is similar to c3because of the inequality d3\\\\d2\\\\d1.\\nThe ﬁeld labels of all reviewer candidates are predicted based on two strategies here.\\nThe prediction is related to the reviewer candidate location, and it’s an adaptive process.From the descriptions of Constructive Covering Algorithm in our method, the advantagesare fast and constructive. First, every sample in the training set is learned only once. Based', 'A novel classification method for paper-reviewer recommendation.pdf'), 18: ('process. For example, d\\n1;d2;d3are the distances from r5to the three cover boundaries. The\\nlabel of r5is similar to c3because of the inequality d3\\\\d2\\\\d1.\\nThe ﬁeld labels of all reviewer candidates are predicted based on two strategies here.\\nThe prediction is related to the reviewer candidate location, and it’s an adaptive process.From the descriptions of Constructive Covering Algorithm in our method, the advantagesare fast and constructive. First, every sample in the training set is learned only once. Basedon the distribution of the current learned sample, it can either be learned immediately ormemorized (the information of the cover construction can be memorized). If a sample is\\nlearned, it is removed from the training set immediately after learning. Not only that, the\\nsamples which are covered during training process are also removed and they cannot be\\nmaxRminR\\ncomRcurrentp\\nFig. 3 Computing the new radius. There are three kinds of cover radius computing methods and the Rcom\\nwe choose in this paperScientometrics (2018) 115:1293–1313 1303\\n123\\nselected as a cover center anymore. Second, CCA begins without covers. It computes the\\nradius and adds new covers according to the location of the sequentially coming data. Thislearning process can be applied to low or high dimensional datasets. Besides, it has 100%recognition rate for the test sample which is located in a cover. That’s to say, it canincrease the classiﬁcation accuracy to some extent.\\nExperiments\\nIn this section, we evaluate the efﬁciency of our method proposed in ‘‘ WMD–CCA method\\nfor reviewer recommendation ’’ section. We conducted experiments compared with nine\\nmethods, and we used four public datasets and one Synthetic dataset.\\nExperimental datasets and comparison methods\\nIn this paper, the reviewer recommendation problem is transformed into a classiﬁcation\\nissue. We compare against nine methods and apply them to the text classiﬁcation problem\\non four public datasets. Furthermore, to show the efﬁciency and the potential on reviewerrecommendation for subm', 'A novel classification method for paper-reviewer recommendation.pdf'), 19: ('posed in ‘‘ WMD–CCA method\\nfor reviewer recommendation ’’ section. We conducted experiments compared with nine\\nmethods, and we used four public datasets and one Synthetic dataset.\\nExperimental datasets and comparison methods\\nIn this paper, the reviewer recommendation problem is transformed into a classiﬁcation\\nissue. We compare against nine methods and apply them to the text classiﬁcation problem\\non four public datasets. Furthermore, to show the efﬁciency and the potential on reviewerrecommendation for submissions, we evaluate our method on a synthetic paper-reviewerdataset.\\nPublic dataset\\nTWITTER (Sanders 2011 ): a set of tweets labelled with sentiments ‘positive’, ‘negative’, or\\n‘neutral’. OHSUMED : a collection of medical abstracts categorized by different cardio-\\nvascular disease groups (we use the 3rd class and the 7th class). 3-class MOV2(Bo and Lee\\nFig. 4 Label prediction for\\nreviewer\\n2http://www.cs.cornell.edu/people/pabo/movie-review-data/ .1304 Scientometrics (2018) 115:1293–1313\\n123\\n2005 ): a collection of movie-review documents labelled subjective rating. 4-class MOV2\\n(Bo and Lee 2005 ): a collection of movie-review documents labelled subjective rating. The\\nstatistical description of public datasets is given in Table 1.\\nSynthetic dataset\\nThe experimental data used in academic expert recommendation or co-author prediction is\\noften from the scientiﬁc paper repository. The papers in this repository are often matchedto the wrong authors due to duplication of full names and abbreviations of the researchers(i.e. reviewers) are very common. As a result, the recommended reviewers are not suit-able in fact, and this problem has a great effect on the evaluation results (Tang et al. 2012 ).\\nTo solve it, we construct an experimental dataset from the Baidu Scholar\\n3according to the\\nMember List of the Program Committee in NCIIP20174(The 6th National Conference on\\nIntelligent Information Processing in 2017). The reviewers (experts) on this list areauthentic and distinct due to the names and organizations.\\nReferring ', 'A novel classification method for paper-reviewer recommendation.pdf'), 20: ('rs(i.e. reviewers) are very common. As a result, the recommended reviewers are not suit-able in fact, and this problem has a great effect on the evaluation results (Tang et al. 2012 ).\\nTo solve it, we construct an experimental dataset from the Baidu Scholar\\n3according to the\\nMember List of the Program Committee in NCIIP20174(The 6th National Conference on\\nIntelligent Information Processing in 2017). The reviewers (experts) on this list areauthentic and distinct due to the names and organizations.\\nReferring to the ﬁfth edition of Chinese Library Classiﬁcation (CLC), we randomly\\nselect 152 papers, which are published in latest years and belongs to three subareas in TP\\n(the ﬁeld automation technology & computer technology ) with respective CLC code TP181\\n(the subﬁeld of Automatic reasoning & machine learning ), TP301 ( the subﬁeld of theory &\\nmethod ) and TP391 ( the subﬁeld of information processing ). Then we randomly choose 38\\nreviewers from NCIIP2017 and crawl their 5 papers published in latest years. For each of\\nall 342 papers, we collect the keywords the author written and the CLC Codes. So weregard the 152 publications as submissions, and every reviewer in our experiment has ﬁveCLC Codes r\\n;¼fy1;y2;y3;y4;y5g. The description of the synthetic dataset is given in\\nTable 2. Finally, we regard the 152 submissions and 38 reviewers as the training and the\\ntesting in our method, respectively.\\nWe preprocess all datasets by removing all words in the SMART stop word list (Salton\\n1971 ). For all submissions and reviewers above, we regard the CLC Code as their research\\nﬁeld label. The word embedding utilized in our experiments is the open-available\\nword2vec word embedding, which obtained from the trained corpus (Google News) in theapproach in Mikolov et al. ( 2013b ).\\nComparison methods\\nWe compare the following nine methods with our proposed method. These methods are\\ncombinations of a text representation method and a classiﬁer. However, LDA (Blei et al.2003 ) (latent dirichlet allocation), LSI (Deerwester et al. 1990 ) (L', 'A novel classification method for paper-reviewer recommendation.pdf'), 21: ('rs above, we regard the CLC Code as their research\\nﬁeld label. The word embedding utilized in our experiments is the open-available\\nword2vec word embedding, which obtained from the trained corpus (Google News) in theapproach in Mikolov et al. ( 2013b ).\\nComparison methods\\nWe compare the following nine methods with our proposed method. These methods are\\ncombinations of a text representation method and a classiﬁer. However, LDA (Blei et al.2003 ) (latent dirichlet allocation), LSI (Deerwester et al. 1990 ) (Latent Semantic Index-\\ning), KNN (K-nearest neighbor), SVM, GaussianNB we used in experiments.\\nLDA –KNN It calculates the text topic distributions by LDA and KNN are used as\\nclassiﬁers based on Euclidean Norm\\nLDA –CCA It calculates the text topic distributions by LDA and CCA are used as\\nclassiﬁers based on Euclidean Norm\\nLSI–KNN It calculates the text topic distributions by LSI and KNN are used as\\nclassiﬁers based on Euclidean Norm.\\n3http://xueshu.baidu.com/ .\\n4http://www.htu.edu.cn/nciip2017 .Scientometrics (2018) 115:1293–1313 1305\\n123\\nLSI–CCA It calculates the text topic distributions by LSI and CCA are used as\\nclassiﬁers based on Euclidean Norm.\\nWMD –KNN It calculates the text relationship by WMD and KNN is used as a\\nclassiﬁer based on Euclidean Norm.\\nLDA –\\nGaussianNBIt calculates the text topic distributions by LDA and then feeds them to\\nGaussianNB as features.\\nLDA –SVM It calculates the text topic distributions by LDA and then feed them to\\nSVM as features.\\nLSI–\\nGaussianNBIt calculates the text topic distributions by LSI and then feed them to\\nGaussianNB as features.\\nLSI–SVM It calculates the text topic distributions by LSI and then feed them to\\nSVM as features.\\nFor all methods, we split the datasets into 80/20 train/test. It’s worth emphasizing that\\nwe set the neighborhood size (K 2f1;...;5g) of KNN and the balanced parameter\\n(l2f0:70;0:71;...;0:89g) in CCA as a result of empirical experience. The ﬁrst ﬁve\\ncompared methods need a similarity function after text representation, and we all useEuclidean Norm he', 'A novel classification method for paper-reviewer recommendation.pdf'), 22: ('ributions by LSI and then feed them to\\nGaussianNB as features.\\nLSI–SVM It calculates the text topic distributions by LSI and then feed them to\\nSVM as features.\\nFor all methods, we split the datasets into 80/20 train/test. It’s worth emphasizing that\\nwe set the neighborhood size (K 2f1;...;5g) of KNN and the balanced parameter\\n(l2f0:70;0:71;...;0:89g) in CCA as a result of empirical experience. The ﬁrst ﬁve\\ncompared methods need a similarity function after text representation, and we all useEuclidean Norm here. For the last four compared methods, we ﬁrst calculate the text\\nrepresentations and feed them to the classiﬁer as features directly.\\nEvaluation metrics\\nWe transform the recommendation problem as a classiﬁcation issue, and here we evaluatethe performance with accuracy ,precision andrecall .\\nAccuracy ¼1\\nRjjXRjj\\nj¼11fypre¼yigð6Þ\\nGenerally, the fact that a reviewer can review a paper as long as his research ﬁeld is\\nsimilar to this paper should be addressed. Given a reviewer r who has 5 publication label\\nr;¼fy1;y2;y3;y4;y5g(5 published papers have 5 CLC codes, i.e. 5 publication labels), weTable 1 Statistical description\\nof public datasetName Number Doc length (AVG) |Class|\\nTWITTER 3108 9.9 3\\nOHSUMED 953 88.5 23-class MOV 1027 103.1 34-class MOV 1027 103.1 4\\nTable 2 Statistical description\\nof the synthetic datasetDescription Value\\nNumber of reviewers 38\\nNumber of reviewer papers 190\\nNumber of submitted papers 152\\nCLC Code number of a reviewer 5CLC Code kinds of submitted papers 3CLC Code kinds of reviewer papers 271306 Scientometrics (2018) 115:1293–1313\\n123\\npredict the ﬁeld label yprefor reviewers and recommend them to the papers as their ﬁeld\\nlabel is similar.\\nDue to the practicality and particularity of our study, the evaluation metric accuracy is\\ncalculated according to that fact mentioned before. When ypreis included in the r;, the ypre\\nis equal to yi. The accuracy is a real number in [0, 1] and 1/C1fgin this function is the\\nindicator function. When ypreis included in the r;, it suggests that this reviewer h', 'A novel classification method for paper-reviewer recommendation.pdf'), 23: ('s 271306 Scientometrics (2018) 115:1293–1313\\n123\\npredict the ﬁeld label yprefor reviewers and recommend them to the papers as their ﬁeld\\nlabel is similar.\\nDue to the practicality and particularity of our study, the evaluation metric accuracy is\\ncalculated according to that fact mentioned before. When ypreis included in the r;, the ypre\\nis equal to yi. The accuracy is a real number in [0, 1] and 1/C1fgin this function is the\\nindicator function. When ypreis included in the r;, it suggests that this reviewer has studied\\nthe research about the ﬁeld ypreand it’s reasonable to assign this reviewer to review the\\npapers which are labelled with ypre.\\nPrecision ¼TP\\nTPþFPð7Þ\\nRecall ¼TP\\nTPþFNð8Þ\\nThe metrics precision andrecall are described as Eqs. ( 7) and ( 8), where TP denotes the\\nnumber of true positives, FP denotes the number of false positives and FN denotes thenumber of false negatives.\\nExperiment results and discussion\\nThe test accuracies of ﬁrst ﬁve methods and WMD–CCA on 4 text classiﬁcation datasets ispresented in Fig. 5. Violin plot shows the result distribution of 6 methods with different K\\nvalues and lvalues. The average accuracy and the best accuracy of each method are\\npresented clearly. On all datasets except OHSUMED, our method WMD–CCA outper-\\nformed other 5 methods. Although WMD–CCA was not better than WMD–KNN onOHSUMED, it was still better than other 4 methods. It’s worth noting that WMD–CCA,LSI–CCA, LDA–CCA can almost obtain a better performance than WMD–KNN, LSI–KNN, LDA–KNN respectively. The performance of KNN is limited to the parameter K,but CCA is a constructive learning algorithm which can adaptively construct the coversbased on different datasets. Besides, CCA has the 100% recognition rate for the learnedsamples which are in some covers. So the WMD–CCA can perform better than these ﬁvemethods.\\nCombined with KNN or CCA, WMD–CCA attained the higher average accuracy and\\nbest accuracy than LDA–CCA, LDA–KNN, LSI–CCA and LSI–KNN on all 4 datasets. It\\ncan be deduced that WMD can deeply measure the relatio', 'A novel classification method for paper-reviewer recommendation.pdf'), 24: ('ce of KNN is limited to the parameter K,but CCA is a constructive learning algorithm which can adaptively construct the coversbased on different datasets. Besides, CCA has the 100% recognition rate for the learnedsamples which are in some covers. So the WMD–CCA can perform better than these ﬁvemethods.\\nCombined with KNN or CCA, WMD–CCA attained the higher average accuracy and\\nbest accuracy than LDA–CCA, LDA–KNN, LSI–CCA and LSI–KNN on all 4 datasets. It\\ncan be deduced that WMD can deeply measure the relationship between each pair texts.\\nWMD captures distributional syntactic and semantic information. Thus it can easilydescribe the real relationship between two text samples.\\nAdditionally, Fig. 6shows the performance of WMD–CCA on the synthetic paper-\\nreviewer dataset. Based the fact mentioned, WMD–CCA performed much better than othermethods on the real paper dataset. The average accuracy can approximately reach 0.73 andthe best accuracy reached 0.84. Notably, the average accuracy increased by 4% thanWMD–KNN and 8% promotion for the best accuracy. In Fig. 7, the accuracy all surpass\\n0.5 with different balance parameter lvalues in WMD–CCA. Especially, for more than\\nhalf of lvalues, the accuracy exceeds the average accuracy 0.73. The higher accuracy\\nvalue of WMD–CCA method indicates that the reviewer recommendation problem is more\\ndesirable to transform into the classiﬁcation issue. However, our method has the promising\\nefﬁciency and potential on the reviewer recommendation task.Scientometrics (2018) 115:1293–1313 1307\\n123\\nFig. 5 Test accuracy results on 4 public datasets, compared to other 5 methods\\nFig. 6 Accuracy of WMD–CCA\\non SYNTHETIC dataset\\nFig. 7 Accuracy of different l\\nvalues on SYNTHETIC dataset1308 Scientometrics (2018) 115:1293–1313\\n123\\nBesides, Table 3shows the best accuracies of last four compared methods and WMD–\\nCCA. From Table 3, our method still has a better performance on all ﬁve datasets.\\nEspecially for the SYNTHETIC dataset, the accuracy can reach 0.842. From the com-parisons with the ﬁrst ﬁve met', 'A novel classification method for paper-reviewer recommendation.pdf'), 25: ('307\\n123\\nFig. 5 Test accuracy results on 4 public datasets, compared to other 5 methods\\nFig. 6 Accuracy of WMD–CCA\\non SYNTHETIC dataset\\nFig. 7 Accuracy of different l\\nvalues on SYNTHETIC dataset1308 Scientometrics (2018) 115:1293–1313\\n123\\nBesides, Table 3shows the best accuracies of last four compared methods and WMD–\\nCCA. From Table 3, our method still has a better performance on all ﬁve datasets.\\nEspecially for the SYNTHETIC dataset, the accuracy can reach 0.842. From the com-parisons with the ﬁrst ﬁve methods, WMD can calculate the deeper relationship betweentwo texts and CCA has high recognition rate. From the combination view, our proposedmethod WMD–CCA can perform better than LSI–GuassianNB, LSI–SVM, LDA–Guas-sianNB and LDA–SVM. It also shows the quite optimistic performance when comparedwith SVM.\\nTo be more convincing, Table 4shows the part of experimental results when l= 0.76\\nand the accuracy reach 0.84. We choose three reviewers (Reviewer 8, Reviewer 9 andReviewer 37) from Member List in NCIIP2017 and their tags (keywords extracted from\\npublications) presented in Fig. 8. The research ﬁeld information of three reviewers is easyTable 3 Test accuracy results compared to 4 no-similarity function based methods\\nDataset\\nMethodTWITTER OHSUMED 3-class MOV 4-class MOV SYNTHETIC\\nLSI-GuassianNB 0.162 0.571 0.364 0.442 0.605\\nLSI-SVM 0.685 0.555 0.417 0.432 0.605\\nLDA-GuassianNB 0.563 0.838 0.437 0.360 0.632\\nLDA-SVM 0.687 0.880 0.476 0.445 0.684\\nWMD-CCA 0.736 0.880 0.539 0.481 0.842 \\nThe best performance is denoted by bold font on different datasets\\nTable 4 Description of reviewer 8, reviewer 16, reviewer 37\\nPublication labels Predicted label Field description\\nReviewer 8 TP391, TP391, TP751, TP391, TP309 TP391 Information processing\\nReviewer 16 TP301, TP301, TN911, TP18, TP391 TP301 Theory & methodReviewer 37 TP181, TP301, TP181, TP181, TP391 TP181 Automatic reasoning &\\nmachine learning\\nFig. 8 Tags (keywords) of reviewer 8, reviewer 16, reviewer 37, which are showed in sub-ﬁgures ( a), (b),\\n(c), respectivelyScientometri', 'A novel classification method for paper-reviewer recommendation.pdf'), 26: (' bold font on different datasets\\nTable 4 Description of reviewer 8, reviewer 16, reviewer 37\\nPublication labels Predicted label Field description\\nReviewer 8 TP391, TP391, TP751, TP391, TP309 TP391 Information processing\\nReviewer 16 TP301, TP301, TN911, TP18, TP391 TP301 Theory & methodReviewer 37 TP181, TP301, TP181, TP181, TP391 TP181 Automatic reasoning &\\nmachine learning\\nFig. 8 Tags (keywords) of reviewer 8, reviewer 16, reviewer 37, which are showed in sub-ﬁgures ( a), (b),\\n(c), respectivelyScientometrics (2018) 115:1293–1313 1309\\n123\\nto know from their word cloud. For example, we can easily judge that Reviewer 37 is\\nrelated to the ﬁeld of machine learning from the keyword tags such as ‘‘learning’’, ‘‘su-pervised’’, ‘‘multi’’, ‘‘machine’’ and ‘‘label’’. While the prediction of research ﬁeld usingWMD–CCA is TP181, which is related to the ﬁeld of automatic reasoning & machinelearning. The Reviewer 8 and Reviewer 16 are easily judged from Table 4and Fig. 8.\\nTo measure the quality of proposed method further, Tables 5and6show the experi-\\nmental results on precision and recall respectively. We report the best value of all methodson four public datasets. From the table of precision, WMD–CCA can rank ﬁrst on three\\ndatasets and rank second on two datasets. WMD–CCA also rank ﬁrst on four datasets and\\nrank second on one dataset in the table of recall value. Generally, WMD–CCA doesn’t\\nTable 5 Experimental results on precision\\nDataset\\nMethodTWITTER OHSUMED 3-class MOV 4-class MOV SYNTHETIC\\nLDA-KNN 0.574 0.862 0.446 0.403 0.713\\nLDA-CCA 0.595 0.859 0.491 0.396 0.715\\nLSI-KNN 0.540 0.534 0.434 0.314 0.671\\nLSI-CCA 0.548 0.549 0.421 0.361 0.697\\nLDA-GaussianNB 0.575 0.838 0.433 0.358 0.717\\nLDA-SVM 0.532 0.880 0.486 0.414 0.751\\nLSI-GaussianNB 0.672 0.563 0.426 0.380 0.535\\nLSI-SVM 0.506 0.544 0.292 0.475 0.599\\nWMD-KNN 0.734 0.916 0.491 0.469 0.745\\nWMD-CCA 0.729 0.881 0.544 0.491 0.828\\nThe best performance is denoted by bold font on different datasets\\nTable 6 Experimental results on recall\\nDataset\\nMethodTWITTER OHSUMED 3-class MOV ', 'A novel classification method for paper-reviewer recommendation.pdf'), 27: ('3 0.713\\nLDA-CCA 0.595 0.859 0.491 0.396 0.715\\nLSI-KNN 0.540 0.534 0.434 0.314 0.671\\nLSI-CCA 0.548 0.549 0.421 0.361 0.697\\nLDA-GaussianNB 0.575 0.838 0.433 0.358 0.717\\nLDA-SVM 0.532 0.880 0.486 0.414 0.751\\nLSI-GaussianNB 0.672 0.563 0.426 0.380 0.535\\nLSI-SVM 0.506 0.544 0.292 0.475 0.599\\nWMD-KNN 0.734 0.916 0.491 0.469 0.745\\nWMD-CCA 0.729 0.881 0.544 0.491 0.828\\nThe best performance is denoted by bold font on different datasets\\nTable 6 Experimental results on recall\\nDataset\\nMethodTWITTER OHSUMED 3-class MOV 4-class MOV SYNTHETIC\\nLDA-KNN 0.578 0.859 0.437 0.398 0.405\\nLDA-CCA 0.650 0.859 0.481 0.408 0.408\\nLSI-KNN 0.572 0.534 0.427 0.345 0.406\\nLSI-CCA 0.606 0.545 0.422 0.393 0.385\\nLDA-GaussianNB 0.563 0.838 0.437 0.359 0.400\\nLDA-SVM 0.687 0.880 0.476 0.447 0.430\\nLSI-GaussianNB 0.188 0.571 0.364 0.442 0.339\\nLSI-SVM 0.682 0.555 0.417 0.432 0.337\\nWMD-KNN 0.727 0.916 0.471 0.466 0.435\\nWMD-CCA 0.748 0.880 0.549 0.495 0.461\\nThe best performance is denoted by bold font on different datasets1310 Scientometrics (2018) 115:1293–1313\\n123\\nonly measure the deeper relationship between two texts, but also predict the label\\naccurately.\\nConclusions\\nIn this paper, we transform the reviewer recommendation problem into a classiﬁcationissue by proposing a novel classiﬁcation method named Word Mover’ s Distance–Con-structive Covering Algorithm (WMD–CCA). Firstly, the keywords of submissions andreviewers are represented as word embeddings. These word embeddings incorporate thecomplex semantic relationship, which is the basis of the deeper relationship further.Secondly, the deeper ﬁeld relationship between submission and reviewer is computed byan optimization WMD from the keyword-level relationship. Thirdly, we learn from sub-missions with the ﬁeld label information by a constructed learning algorithm CCA. Itmakes full use of the ﬁeld information of papers, and it transforms the recommendationtask into the classiﬁcation issue ingeniously. Furthermore, we can assign the same ﬁeld\\nresearch reviewer to the submissions. Comparing to nine method', 'A novel classification method for paper-reviewer recommendation.pdf'), 28: ('r relationship further.Secondly, the deeper ﬁeld relationship between submission and reviewer is computed byan optimization WMD from the keyword-level relationship. Thirdly, we learn from sub-missions with the ﬁeld label information by a constructed learning algorithm CCA. Itmakes full use of the ﬁeld information of papers, and it transforms the recommendationtask into the classiﬁcation issue ingeniously. Furthermore, we can assign the same ﬁeld\\nresearch reviewer to the submissions. Comparing to nine methods presents that WMD can\\ndeeply compute the relationship and CCA can conduct an accurate prediction process. Ourexperiment results on ﬁve public datasets present that our method has the potentiality inreviewer recommendation.\\nRegarding the paper-reviewer recommendation problem as a classiﬁcation issue is an\\ninteresting and novel idea. But this classiﬁcation issue has two important features whichare multi-label and multi-granular. In the future, a multi-labels problem will be studied,which would improve the applicability of the real reviewer recommendation. From thecoarse granular to the thin granular, we aim to recommend the more suitable reviewer toreview the submission and improve the accuracy. Also, our proposed method is planned tobe evaluated on different academic datasets from other research ﬁelds, including Digital\\nBibliography & Library Project (DBLP) in computer and information science. In addition,\\nunder the training of big data, reviewer or expert recommendation for scientiﬁc andtechnology projects is challenging to study.\\nAcknowledgements This work was partially supported by National Natural Science Foundation of China\\n(Grants #61402006, #61602003 and #61673020), National High Technology Research and Development\\nProgram (863 Plan)(Grant #2015AA124102), Innovation Zone Project Program for Science and Technology\\nof China’s National Defense (Grant No. 2017-0001-863015-0009), the National Key Research andDevelopment Program of China (2017YFB1401903), the Provincial Natural Science Foundation of Anhui\\nPro', 'A novel classification method for paper-reviewer recommendation.pdf'), 29: ('is challenging to study.\\nAcknowledgements This work was partially supported by National Natural Science Foundation of China\\n(Grants #61402006, #61602003 and #61673020), National High Technology Research and Development\\nProgram (863 Plan)(Grant #2015AA124102), Innovation Zone Project Program for Science and Technology\\nof China’s National Defense (Grant No. 2017-0001-863015-0009), the National Key Research andDevelopment Program of China (2017YFB1401903), the Provincial Natural Science Foundation of Anhui\\nProvince (Grants #1508085MF113 and #1708085QF156), Scientiﬁc Research Foundation for the Returned\\nOverseas Chinese Scholars, State Education Ministry (Forty-ninth batch) and the Recruitment Project of\\nAnhui University for Academic and Technology Leader.\\nReferences\\nBlei, D. M., Ng, A. Y., & Jordan, M. I. (2003). Latent dirichlet allocation . JMLR.org.\\nBo, P., & Lee, L. Seeing stars: exploiting class relationships for sentiment categorization with respect to\\nrating scales. In Meeting on association for computational linguistics, University of Michigan, USA,\\n2005 (pp. 115–124).\\nCharlin, L., Zemel, R. S., & Boutilier, C. (2012). A framework for optimizing paper matching. Paper\\npresented at the Proceedings of the twenty-seventh conference on uncertainty in artiﬁcial intelligence,\\nBarcelona, Spain.Scientometrics (2018) 115:1293–1313 1311\\n123\\nConry, D., Koren, Y., & Ramakrishnan, N. Recommender systems for the conference paper assignment\\nproblem. In ACM conference on recommender systems, New York, 2009 (pp. 357–360).\\nDeep, K., & Das, K. N. (2008). Quadratic approximation based hybrid genetic algorithm for function\\noptimization. Applied Mathematics and Computation, 203 (1), 86–98.\\nDeerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent\\nsemantic analysis. Journal of the American Society for Information Science, 41 (6), 391.\\nDiaz, F., Mitra, B., & Craswell, N. (2016). Query expansion with locally-trained word embedding s. Paper\\npresented at the proceedings of the 54th annual ', 'A novel classification method for paper-reviewer recommendation.pdf'), 30: ('eep, K., & Das, K. N. (2008). Quadratic approximation based hybrid genetic algorithm for function\\noptimization. Applied Mathematics and Computation, 203 (1), 86–98.\\nDeerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., & Harshman, R. (1990). Indexing by latent\\nsemantic analysis. Journal of the American Society for Information Science, 41 (6), 391.\\nDiaz, F., Mitra, B., & Craswell, N. (2016). Query expansion with locally-trained word embedding s. Paper\\npresented at the proceedings of the 54th annual meeting of the association for computational lin-\\nguistics , ACL 2016, Berlin.\\nFan, Z. P., Chen, Y., Ma, J., & Zhu, Y. (2009). Decision support for proposal grouping: A hybrid approach\\nusing knowledge rule and genetic algorithm. Expert Systems with Applications, 36 (2), 1004–1013.\\nFang, H., & Zhai, C. X. Probabilistic models for expert ﬁnding. In European conference on Ir research,\\nRome, 2007 (pp. 418–430).\\nJin, J., Geng, Q., Zhao, Q., & Zhang, L. Integrating the trend of research interest for reviewer assignment. In\\nInternational conference on world wide web companion, Perth, 2017 (pp. 1233–1241).\\nKarimzadehgan, M., & Zhai, C. X. Constrained multi-aspect expertise matching for committee review\\nassignment. In ACM conference on information and knowledge management, Hong Kong, 2009 (pp.\\n1697–1700).\\nKarimzadehgan, M., Zhai, C. X., & Belford, G. Multi-aspect expertise matching for review assignment. In\\nACM conference on information and knowledge management, Napa Valley, 2008 (pp. 1113–1122).\\nKolasa, T., & Krol, D. (2011). A survey of algorithms for paper-reviewer assignment problem. IETE\\nTechnical Review, 28 (2), 123–134.\\nKolasa, T., & Kro ´l, D. (2010). ACO-GA approach to paper-reviewer assignment problem in CMS . Berlin:\\nSpringer.\\nKusner, M., Sun, Y., Kolkin, N., & Weinberger, K. From word embeddings to document distances. In\\nInternational conference on machine learning, Lille, 2015 (pp. 957–966).\\nLi, K., Cao, Z., & Qu, D. Fair reviewer assignment considering academic social network. In Asia-Paciﬁc\\nWeb, 2017 (pp.', 'A novel classification method for paper-reviewer recommendation.pdf'), 31: ('. (2011). A survey of algorithms for paper-reviewer assignment problem. IETE\\nTechnical Review, 28 (2), 123–134.\\nKolasa, T., & Kro ´l, D. (2010). ACO-GA approach to paper-reviewer assignment problem in CMS . Berlin:\\nSpringer.\\nKusner, M., Sun, Y., Kolkin, N., & Weinberger, K. From word embeddings to document distances. In\\nInternational conference on machine learning, Lille, 2015 (pp. 957–966).\\nLi, K., Cao, Z., & Qu, D. Fair reviewer assignment considering academic social network. In Asia-Paciﬁc\\nWeb, 2017 (pp. 362–376).\\nLiu, O., Wang, J., Ma, J., & Sun, Y. (2016). An intelligent decision support approach for reviewer\\nassignment in R&D project selection . Amsterdam: Elsevier.\\nLiu, X., Suel, T., & Memon, N. (2014) A robust model for paper reviewer assignment. In Eighth ACM\\nconference on recommender systems, RecSys ‘14, Foster City, Silicon Valley, CA, USA (pp. 25–32).\\nMikolov, T., Chen, K., Corrado, G., & Dean, J. (2013a). Efﬁcient estimation of word representations in\\nvector space. Computer Science .arXiv:1301.3781 .\\nMikolov, T., Sutskever, I., Chen, K., Corrado, G., & Dean, J. (2013b). Distributed representations of words\\nand phrases and their compositionality. Advances in Neural Information Processing Systems, 26,\\n3111–3119.\\nMimno, D., & Mccallum, A. Expertise modeling for matching papers with reviewers. In ACM SIGKDD\\nInternational conference on knowledge discovery and data mining, San Jose, California, USA, August,\\n2007 (pp. 500–509).\\nPeng, H., Hu, H., Wang, K., & Wang, X. (2017). Time-aware and topic-based reviewer assignment. Paper\\npresented at the database systems for advanced applications—22nd international conference , Suzhou,\\nChina.\\nProtasiewicz, J., Pedrycz, W., Kozłowski, M., Dadas, S., Stanisławek, T., Kopacz, A., et al. (2016). A\\nrecommender system of reviewers and experts in reviewing problems. Knowledge-Based Systems,\\n106(C), 164–178.\\nRen, Y., Zhang, Y., Zhang, M., & Ji, D. Improving Twitter sentiment classiﬁcation using topic-enriched\\nmulti-prototype word embeddings. In Thirtieth AAAI conference on ar', 'A novel classification method for paper-reviewer recommendation.pdf'), 32: ('ewer assignment. Paper\\npresented at the database systems for advanced applications—22nd international conference , Suzhou,\\nChina.\\nProtasiewicz, J., Pedrycz, W., Kozłowski, M., Dadas, S., Stanisławek, T., Kopacz, A., et al. (2016). A\\nrecommender system of reviewers and experts in reviewing problems. Knowledge-Based Systems,\\n106(C), 164–178.\\nRen, Y., Zhang, Y., Zhang, M., & Ji, D. Improving Twitter sentiment classiﬁcation using topic-enriched\\nmulti-prototype word embeddings. In Thirtieth AAAI conference on artiﬁcial intelligence, 2016 (pp.\\n3038–3044).\\nRubner, Y., Tomasi, C., & Guibas, L. J. A metric for distributions with applications to image databases. In\\nInternational conference on computer vision, Bombay, 1998 (pp. 59–66).\\nSalton. (1971). The SMART retrieval system—experiments in automatic document processing . Upper Saddle\\nRiver: Prentice-hall Inc.\\nSanders, N. J. (2011). Sanders-twitter sentiment corpus.\\nShen, Y., Rong, W., Jiang, N., Peng, B., Tang, J., & Xiong, Z. (2017). Word embedding based correlation\\nmodel for question/answer matching. Paper presented at the proceedings of the thirty-ﬁrst AAAI\\nconference on artiﬁcial intelligence , San Francisco, California.\\nShon, H. S., Han, S. H., Kim, K. A., Cha, E. J., & Ryu, K. H. (2017). Proposal reviewer recommendation\\nsystem based on big data for a national research management institute. Journal of Information Science,\\n43(2), 147–158.1312 Scientometrics (2018) 115:1293–1313\\n123\\nSun, Y. H., Ma, J., Fan, Z. P., & Wang, J. (2008). A hybrid knowledge and model approach for reviewer\\nassignment. Expert Systems with Applications, 34 (2), 817–824.\\nTang, J., Fong, A. C. M., Wang, B., & Zhang, J. (2012). A uniﬁed probabilistic framework for name\\ndisambiguation in digital library. IEEE Transactions on Knowledge and Data Engineering, 24 (6),\\n975–987.\\nTang, J., Zhang, J., Yao, L., Li, J., Zhang, L., & Su, Z. ArnetMiner:extraction and mining of academic social\\nnetworks. In ACM SIGKDD international conference on knowledge discovery and data mining, Las\\nVegas, Nevada, USA, 2008 ', 'A novel classification method for paper-reviewer recommendation.pdf'), 33: ('oach for reviewer\\nassignment. Expert Systems with Applications, 34 (2), 817–824.\\nTang, J., Fong, A. C. M., Wang, B., & Zhang, J. (2012). A uniﬁed probabilistic framework for name\\ndisambiguation in digital library. IEEE Transactions on Knowledge and Data Engineering, 24 (6),\\n975–987.\\nTang, J., Zhang, J., Yao, L., Li, J., Zhang, L., & Su, Z. ArnetMiner:extraction and mining of academic social\\nnetworks. In ACM SIGKDD international conference on knowledge discovery and data mining, Las\\nVegas, Nevada, USA, 2008 (pp. 990–998).\\nTayal, D. K., Saxena, P. C., Sharma, A., Khanna, G., & Gupta, S. (2014). New method for solving reviewer\\nassignment problem using type-2 fuzzy sets and fuzzy functions. Applied Intelligence, 40 (1), 54–73.\\nWang, D. (2008). Fast constructive-covering algorithm for neural networks and its implement in classiﬁ-\\ncation. Applied Soft Computing Journal, 8 (1), 166–173.\\nXu, Y., Ma, J., Sun, Y., Hao, G., Xu, W., & Zhao, D. (2010). A decision support approach for assigning\\nreviewers to proposals. Expert Systems with Applications, 37 (10), 6948–6956.\\nYang, K. H., Kuo, T. L., Lee, H. M., & Ho, J. M. A Reviewer recommendation system based on collab-\\norative intelligence. In Ieee/wic/acm international joint conference on web intelligence and intelligent\\nagent technology, Milan, 2009 (pp. 564–567).\\nZhang, Y., Xing, H., Zou, H., Zhao, S., & Wang, X. A three-way decisions model based on constructive\\ncovering algorithm. In International conference on rough sets and knowledge technology, Halifax,\\n2013 (pp. 346–353).Scientometrics (2018) 115:1293–1313 1313\\n123', 'A novel classification method for paper-reviewer recommendation.pdf'), 34: ('A Novel Method for Video Tracking Performance Evaluation\\n \\nJames Black \\nDigital Imaging Research Centre \\nKingston University \\nSurrey KT1 2EE \\nJ.Black@kingston.ac.uk \\n \\n Tim Ellis \\nDigital Imaging Research Centre \\nKingston University \\nSurrey KT1 2EE \\nT.Ellis@kingston.ac.uk \\n \\n Paul Rosin \\nDepartment of Computer Science \\nCardiff University \\nCardiff CF24 3XF \\nPaul.Rosin@cs.cf.ac.uk \\n \\n \\nAbstract \\n \\nThis paper presents a methodology for evaluating the \\nperformance of video surveillance tracking systems. We \\nintroduce a novel framework for performance \\nevaluation using pseudo-synthetic video, which employs \\ndata captured online and stored in a surveillance \\ndatabase. Tracks are automatically selected from the \\nsurveillance database and then used to generate ground \\ntruthed video sequences with a controlled level of \\nperceptual complexity that can be used to quantitatively \\ncharacterise the quality of the tracking algorithms. \\n \\n1. Introduction\\n \\nPerformance evaluation of image surveillance systems is \\nan essential requirement, particularly when the system is \\ndeployed in a live environment. Our motivation for the \\nwork presented in this paper is to resolve some of the \\nissues that arise when evaluating the performance of a \\nvideo tracking algorithm. The evaluation issues include: \\nhow can we define ground truth for large datasets of \\nvideo? What measures can be used to determine the \\ncomplexity of a dataset along with the quality of its \\nassociated ground truth? What measures are appropriate \\nto characterise tracking performance? The performance \\nevaluation framework presented in this paper addresses \\neach of these issues. \\nOur online surveillance system [1] comprises of \\na set of intelligent camera units with fixed camera views \\nthat utilise vision algorithms for detecting and tracking \\nmoving objects in 2D image coordinates. Each intelligent \\ncamera unit employs background subtraction [2] for \\nmotion detection and a partial observation-tracking \\nalgorithm [3] for object tracking and trajectory \\nprediction. Tracked o', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 35: ('g performance? The performance \\nevaluation framework presented in this paper addresses \\neach of these issues. \\nOur online surveillance system [1] comprises of \\na set of intelligent camera units with fixed camera views \\nthat utilise vision algorithms for detecting and tracking \\nmoving objects in 2D image coordinates. Each intelligent \\ncamera unit employs background subtraction [2] for \\nmotion detection and a partial observation-tracking \\nalgorithm [3] for object tracking and trajectory \\nprediction. Tracked object data generated by each \\nintelligent camera unit is stored in an on-line \\nsurveillance database. We will demonstrate how pseudo-\\nsynthetic video sequences can be generated from this \\ndata and then used within our performance evaluation \\nframework. We choose to use pseudo-synthetic video to \\nevaluate system performance, since it is possible to generate a large variety of datasets that represent a \\nnumber of different tracking scenarios, which can vary in \\nperceptual complexity. In addition, the ground truth is \\nautomatically acquired from the tracking data stored in \\nthe surveillance database. By adopting this approach it \\nbecomes practical to perform experiments over several \\nhundred thousand frames of video data in order to \\nquantitatively evaluate tracking performance. \\nThe conventional approach for performance \\nevaluation is to generate ground truth from pre-recorded \\nvideo sequences. A number of semi-automatic tools are \\ncurrently available for generating ground truth. The open \\ndevelopment environment for evaluation of video systems \\n(ODViS) [4] allows a user to generate ground truth for \\npre-recorded video. New tracking engines can be \\nincorporated into the environment for evaluation within \\nthe ODViS framework. The Video Performance \\nEvaluation Resource (ViPER)[5] provides a set of tools \\nfor ground truth generation, metrics for evaluation, and \\nvisualization of video analysis results. A number of \\nmetrics have been defined for tracker performance \\nevaluation [5,6,7,8,9]. In [9] a number of metrics ', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 36: ('nt for evaluation of video systems \\n(ODViS) [4] allows a user to generate ground truth for \\npre-recorded video. New tracking engines can be \\nincorporated into the environment for evaluation within \\nthe ODViS framework. The Video Performance \\nEvaluation Resource (ViPER)[5] provides a set of tools \\nfor ground truth generation, metrics for evaluation, and \\nvisualization of video analysis results. A number of \\nmetrics have been defined for tracker performance \\nevaluation [5,6,7,8,9]. In [9] a number of metrics are \\nused to evaluate tracking performance where ground \\ntruth is not available. They used a set of colour and \\nmotion metrics to assess the consistency of the tracked \\nobject between image frames. A number of metrics are \\ndefined for positional tracker evaluation in [8]. The main \\nfocus is on trajectory comparison to account for detection \\nlag, or constant spatial shift. In [12] ground truth is \\nautomatically generated by using pre-determined cues \\nsuch as shape and size on controlled test sequences. \\n The remainder of this paper is organized as \\nfollows: Section 2 describes the framework used to \\nevaluate system performance using manual ground truth. \\nSection 3 describes the method used to automatically \\nselect ground truth tracks from the surveillance database, \\nand generate pseudo synthetic video sequences. Section 4 \\ndefines a set of surveillance metrics. Section 5 shows \\nresults obtained for performance evaluation using \\nconventional pre-recorded and pseudo-synthetic video \\nsequences. Section 6 is a discussion of what has been \\nachieved by the current version of the evaluation \\nframework and what new work is planned for the future. \\n2. Performance Evaluation \\n \\nA typical approach to evaluating the performance of the \\ndetection and tracking system uses ground truth to \\nprovide independent and objective data (e.g. \\nclassification, location, size) that can be related to the \\nobservations extracted from the video sequence. Manual \\nground truth is conventionally gathered by a human \\noperator who uses a ‘point ', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 37: ('cussion of what has been \\nachieved by the current version of the evaluation \\nframework and what new work is planned for the future. \\n2. Performance Evaluation \\n \\nA typical approach to evaluating the performance of the \\ndetection and tracking system uses ground truth to \\nprovide independent and objective data (e.g. \\nclassification, location, size) that can be related to the \\nobservations extracted from the video sequence. Manual \\nground truth is conventionally gathered by a human \\noperator who uses a ‘point and click’ user interface to \\nstep through a video sequence and select well-defined \\npoints for each moving object. The manual ground truth \\nconsists of a set of points that define the trajectory of \\neach object in the video sequence (e.g. the object \\ncentroid). The human operator decides if objects should \\nbe tracked as individuals or classified as a group. The \\nmotion detection and tracking algorithm is then run on \\nthe pre-recorded video sequence and ground truth and \\ntracking results are compared to assess tracking \\nperformance. \\nThe reliability of the video tracking algorithm \\ncan be associated with a number of criteria: the \\nfrequency and complexity of dynamic occlusions, the \\nduration of targets behind static occlusions, the \\ndistinctiveness of the targets (e.g. if they are all different \\ncolours), and changes in illumination or weather \\nconditions. In this paper we express a measure for \\nestimating the perceptual complexity of the sequence \\nbased on the occurrence and duration of dynamic \\nocclusions, since this is the event most likely to cause the \\ntracking algorithm to fail. Such information can be \\nestimated from the ground truth data by computing the \\nratio of the number of target occlusion frames divided by \\nthe total length of each target track (i.e. the number of \\nframes over which it is observed), averaged over the \\nsequence (see section 4). \\n \\n3. Pseudo Synthetic Video \\n \\nAs an alternative to manual ground truthing we propose \\nusing pseudo synthetic video to evaluate tracking \\nperformance. A pr', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 38: ('since this is the event most likely to cause the \\ntracking algorithm to fail. Such information can be \\nestimated from the ground truth data by computing the \\nratio of the number of target occlusion frames divided by \\nthe total length of each target track (i.e. the number of \\nframes over which it is observed), averaged over the \\nsequence (see section 4). \\n \\n3. Pseudo Synthetic Video \\n \\nAs an alternative to manual ground truthing we propose \\nusing pseudo synthetic video to evaluate tracking \\nperformance. A problem for performance evaluation of \\ntracking algorithms is that it is not trivial to accumulate \\ndatasets of varying perceptual complexity. Ideally, we \\nwant to be able to run a number of experiments and vary \\nthe perceptual complexity of the scene to test the tracking \\nalgorithm under a variety of different conditions. This is \\npossible using manual ground truth but requires the \\ncapture of a large number of video sequences, which may \\nnot be practical at some surveillance sites. \\n The novelty of our framework is that we \\nautomatically compile a set of isolated ground truth \\ntracks from the surveillance database. We then use the ground truth tracks to construct a comprehensive set of \\npseudo synthetic video sequences that are used to \\nevaluate the performance of a tracking algorithm. \\n \\n3.1 Ground Truth Track Selection \\n \\nA list of ground truth tracks is initially compiled from \\nthe surveillance database. We select ground truth tracks \\nduring periods of low object activity (e.g. over \\nweekends), since there is a smaller likelihood of object \\ninteractions that can result in tracking errors. The \\nground truth tracks are checked for consistency with \\nrespect to path coherence, colour coherence, and shape \\ncoherence in order to identify and remove tracks of poor \\nquality. \\n \\nPath Coherence: The path coherence metric [3] makes \\nthe assumption that the derived tracked object trajectory \\nshould be smooth subject to direction and motion \\nconstraints. Measurements are penalised for lower \\nconsistency with respect to d', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 39: (' is a smaller likelihood of object \\ninteractions that can result in tracking errors. The \\nground truth tracks are checked for consistency with \\nrespect to path coherence, colour coherence, and shape \\ncoherence in order to identify and remove tracks of poor \\nquality. \\n \\nPath Coherence: The path coherence metric [3] makes \\nthe assumption that the derived tracked object trajectory \\nshould be smooth subject to direction and motion \\nconstraints. Measurements are penalised for lower \\nconsistency with respect to direction and speed, while \\nmeasurements are rewarded for the converse situation. \\n∑−\\n= + −+ −\\n+ −+ −\\n\\uf8f4\\n\\uf8fe\\uf8f4\\n\\uf8fd\\uf8fc\\n\\uf8f4\\n\\uf8f3\\uf8f4\\n\\uf8f2\\uf8f1\\n\\uf8f7\\uf8f7\\uf8f7\\n\\uf8f8\\uf8f6\\n\\uf8ec\\uf8ec\\uf8ec\\n\\uf8ed\\uf8eb\\n+−+\\n\\uf8f7\\uf8f7\\uf8f7\\n\\uf8f8\\uf8f6\\n\\uf8ec\\uf8ec\\uf8ec\\n\\uf8ed\\uf8eb•−−=1N\\n2k 1kkk1k1kkk1k\\n2\\n1kkk1k1kkk1k\\n1 pcXXXXXXXX2\\n1w\\nXXXXXXXX1w2N1\\x00\\nWhere k1kXX−is the vector representing the positional \\nshift of the tracked object between frames k and k-1. The \\nweighting factors can be appropriately assigned to define \\nthe contribution of the direction and speed components of \\nthe measure. The value of both weights was set to 0.5. \\n \\nColour Coherence: The colour coherence metric \\nmeasures the average inter-frame histogram distance of a \\ntracked object. It is assumed that the object histogram \\nshould remain constant between image frames. The \\nnormalised histogram is generated using the (r,g) colour \\nspace in order to account for small lighting variations. \\nThis metric has low values if the segmented object has \\nsimilar colour attributes, and higher values when colour \\nattributes are different. Each histogram contains 8x8 bins \\nfor the normalised colour components. \\n∑∑\\n= =−−−=N\\nkM\\nuk k cc upupN2 11)()( 111ε  \\nWhere )u(pk is the normalised colour histogram of the \\ntracked object at frame k, which has M bins, and N is the \\nnumber of frames the object was tracked over. This \\nmetric is a popular colour similarity measure employed \\nby several robust tracking algorithms [10,11]. \\nShape Coherence: The shape coherence metric gives an \\nindication of the level of agreement between the tracked \\nobject position and the object foreground region. This \\nmetri', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 40: ('ised colour components. \\n∑∑\\n= =−−−=N\\nkM\\nuk k cc upupN2 11)()( 111ε  \\nWhere )u(pk is the normalised colour histogram of the \\ntracked object at frame k, which has M bins, and N is the \\nnumber of frames the object was tracked over. This \\nmetric is a popular colour similarity measure employed \\nby several robust tracking algorithms [10,11]. \\nShape Coherence: The shape coherence metric gives an \\nindication of the level of agreement between the tracked \\nobject position and the object foreground region. This \\nmetric will have a high value when the localisation of the \\ntracked object is incorrect due to poor initialisation or an \\nerror in tracking. The value of the metric is computed by \\nevaluating the symmetric shape difference between the \\nbounding box of the foreground object and tracked object \\nstate. \\n∑\\n= ∪−+−\\n=N\\nk f tf t t f\\nsckRkRkRkRkRkR\\nN1)()()()()()(1ε  \\nWhere )k(R)k(Rf t−  represents the area difference \\nbetween the bounding box of the tracked object (state) \\nand the overlapping region with the foreground object \\n(measurement). The normalisation factor )k(R)k(Rf t∪ \\nrepresents the area of the union of both bounding boxes. \\n0 0.05 0.1 0.15 0.2 0.25051015202530354045Path Coherence Histogram\\nPath CoherenceFrequency\\n \\n   (a) \\n0.04 0.06 0.08 0.1 0.12 0.14 0.16 0.1805101520253035404550Colour Coherence Histogram\\nColour CoherenceFrequency\\n \\n   (b) \\n0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.405101520253035Shape Coherence Histogram\\nShape CoherenceFrequency\\n \\n   (c) \\nFigure 1: Distribution of the average path coherence (a), \\naverage colour coherence (b), and average shape \\ncoherence of each track selected from the surveillance \\ndatabase. Outlier ground truth tracks can be removed by applying a \\nthreshold to the values of pcε, ccε, and scε. The \\ndistributions of the values are shown in the figure 1. It \\ncan be observed that a Gaussian distribution can \\nadequately approximate each metric. The threshold is set \\nso that the value should be within two standard \\ndeviations of the mean. The mean and standard \\ndeviations of pcε, ccε, and', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 41: ('erage colour coherence (b), and average shape \\ncoherence of each track selected from the surveillance \\ndatabase. Outlier ground truth tracks can be removed by applying a \\nthreshold to the values of pcε, ccε, and scε. The \\ndistributions of the values are shown in the figure 1. It \\ncan be observed that a Gaussian distribution can \\nadequately approximate each metric. The threshold is set \\nso that the value should be within two standard \\ndeviations of the mean. The mean and standard \\ndeviations of pcε, ccε, and scε were (0.092, 0.086, \\n0.157) and (0.034, 0.020, 0.054) respectively. We also \\nexclude any tracks that are short in duration and have \\nnot been tracked for at least N=50 frames, or have \\nformed a dynamic occlusion with another track. \\n \\n \\nFigure 2: Example of outlier tracks identified during \\nground truth track selection. \\n \\nIn figure 2 some example outlier tracks are shown. The \\ntop left track was rejected due to poor path coherence, \\nsince the derived object trajectory is not smooth. The top \\nright track was rejected due to poor colour coherence, \\nwhich is a consequence of the poor object segmentation. \\nThe bottom left track was rejected due to poor shape \\ncoherence, where an extra pedestrian merges into the \\ntrack. The tracked bounding boxes are not consistent \\nwith the detected foreground object. The bottom right \\ntrack was rejected due to forming a dynamic occlusion \\nwith another track. It can be observed that in this \\ninstance the tracking failed and the objects switched \\nidentities near the bottom of the image. These examples \\nillustrate that the metrics: path coherence, colour \\ncoherence, and shape coherence are effective for \\nrejecting outlier ground truth tracks of poor quality. \\n \\n3.2 Pseudo Synthetic Video Generation \\n \\nOnce the ground truth tracks have been selected they are \\nemployed to generate pseudo-synthetic videos. Each \\npseudo-synthetic video is constructed by replaying the \\nground truth tracks randomly in the generated video \\nsequence. Two ground truth tracks are shown in left and \\nmiddl', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 42: ('f the image. These examples \\nillustrate that the metrics: path coherence, colour \\ncoherence, and shape coherence are effective for \\nrejecting outlier ground truth tracks of poor quality. \\n \\n3.2 Pseudo Synthetic Video Generation \\n \\nOnce the ground truth tracks have been selected they are \\nemployed to generate pseudo-synthetic videos. Each \\npseudo-synthetic video is constructed by replaying the \\nground truth tracks randomly in the generated video \\nsequence. Two ground truth tracks are shown in left and \\nmiddle images of figure 3, the tracked object is plotted \\nevery few frames in order to visualise the motion history \\nof the object through the scene. When the two tracks are \\ninserted in a pseudo-synthetic video sequence a dynamic \\nocclusion can be created as shown in the right image of \\nfigure 3. Since the ground truth is known for each track \\nwe can determine the exact time and duration of the \\ndynamic occlusion. By adding more ground truth tracks \\nmore complex object interactions are generated. \\n \\n \\nFigure 3: The left and middle images show two ground \\ntruth tracks. The right image shows how the two tracks \\ncan form a dynamic occlusion. \\n \\n \\n(a) \\n \\n \\n(b) \\nFigure 4: Examples of dynamic occlusions in a pseudo \\nsynthetic video sequence: The top and bottom rows in \\nboth figures represent the pseudo synthetic and original \\nimage frames, respectively (taken from PETS2001 \\ndataset 2 (camera2)). \\n \\nA number of steps are taken to construct each \\npseudo-synthetic video, since simple insertion of the \\nground truth tracks is not sufficient to create realistic \\nvideo. Initially, a dynamic background video is captured \\nfor the camera view. This allows the pseudo-synthetic \\nvideo to simulate small illumination changes that \\ntypically occur in outdoor environments. The framelets \\nstored in the surveillance database consist of the \\nforeground regions identified by the tracking algorithm \\n(i.e. within the bounding box). When the framelet is \\nreplayed in the pseudo-synthetic video this improves the realism of dynamic occlusions. Al', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 43: ('is not sufficient to create realistic \\nvideo. Initially, a dynamic background video is captured \\nfor the camera view. This allows the pseudo-synthetic \\nvideo to simulate small illumination changes that \\ntypically occur in outdoor environments. The framelets \\nstored in the surveillance database consist of the \\nforeground regions identified by the tracking algorithm \\n(i.e. within the bounding box). When the framelet is \\nreplayed in the pseudo-synthetic video this improves the realism of dynamic occlusions. All the ground truth \\ntracks are selected from a fixed camera view. This \\nensures the object motion in the constructed video \\nsequence is consistent with the typical activity in the \\nscene. 3D calibration information is used to ensure that \\nframelets are plotted correctly during dynamic \\nocclusions, according to their estimated depth from the \\ncamera. This gives the effect of an object occluding or \\nbeing occluded by other objects based on their distance \\nfrom the camera. This point is illustrated in figure 4, \\nwhere a dynamic occlusion is simulated in a video \\nsequence. The pseudo-synthetic and original image \\nframes are shown to demonstrate how ground truth \\ntracks can be used to construct realistic dynamic object \\nocclusions. A pedestrian ground truth track is used to \\ncreate a dynamic occlusion in figure 4a. In figure 4b a \\ncyclist and pedestrian occlude a phantom vehicle, and the \\nsame vehicle then occludes a pedestrian later in the video \\nsequence. \\nThere are several benefits of using pseudo \\nsynthetic video: it is possible to simulate a wide variety \\nof dynamic occlusions of varying complexity; pseudo-\\nsynthetic video can be generated for a variety of weather \\nconditions; the perceptual complexity of each synthetic \\nvideo can be automatically estimated; and ground truth \\ncan be automatically acquired. One disadvantage is that \\nthe pseudo synthetic video is biased towards the motion \\ndetection algorithm used to capture the original data, and \\nfew ground truth tracks will be generated in regions \\nwhere track', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 44: ('deo: it is possible to simulate a wide variety \\nof dynamic occlusions of varying complexity; pseudo-\\nsynthetic video can be generated for a variety of weather \\nconditions; the perceptual complexity of each synthetic \\nvideo can be automatically estimated; and ground truth \\ncan be automatically acquired. One disadvantage is that \\nthe pseudo synthetic video is biased towards the motion \\ndetection algorithm used to capture the original data, and \\nfew ground truth tracks will be generated in regions \\nwhere tracking or detection performance is poor. In \\naddition, the metrics described in section 3.1 do not \\ncompletely address all the problems associated with \\nmotion segmentation. For example, the affects of \\nshadows cast by moving objects, changes in weather \\nconditions, the detection of low contrast objects, and the \\ncorrect segmentation of an object’s boundary. However, \\nthe pseudo-synthetic video is effective for evaluating the \\nperformance of tracking with respect to dynamic \\nocclusion reasoning, which is the main focus of this \\npaper. \\n \\n3.3 Perceptual Complexity \\n \\nThe perceptual complexity of each pseudo-synthetic \\nvideo sequence is controlled by a set of tuneable \\nparameters: \\nMax Objects (Max): The maximum number of the \\nobjects that can be present in any frame of the generated \\nvideo sequence. \\n \\nNew Object Probability - p(new): The probability of \\ncreating a new object in the video sequence while the \\nmaximum number of objects has not been exceeded. \\nIncreasing the value of p(new) results in a larger number \\nof objects appearing in the constructed video sequence. \\nThis is illustrated in figure 5 where the three images \\ndemonstrate how the value of p(new) can be used to \\ncontrol the density of objects in each pseudo-synthetic \\nvideo sequence. The images show examples for p(new) \\nhaving the values 0.01, 0.10 and 0.20, respectively. \\nThese two parameters are used to vary the complexity of \\neach generated video sequence. Increasing the values of \\nthe parameters results in an increase of object activity. \\nWe have', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 45: ('r \\nof objects appearing in the constructed video sequence. \\nThis is illustrated in figure 5 where the three images \\ndemonstrate how the value of p(new) can be used to \\ncontrol the density of objects in each pseudo-synthetic \\nvideo sequence. The images show examples for p(new) \\nhaving the values 0.01, 0.10 and 0.20, respectively. \\nThese two parameters are used to vary the complexity of \\neach generated video sequence. Increasing the values of \\nthe parameters results in an increase of object activity. \\nWe have found this model provides a realistic simulation \\nof actual video sequences. \\n \\n \\nFigure 5: Perceptual Complexity: left – p(new)=0.01 \\nimage, middle – framelets plotted for p(new)=0.1,  right \\n– framelets plotted for p(new)=0.2. \\n00.050.10.150.20.250.30.350.402468101214161820Perceptual Complexity - Average number of objects per frameNumber of objects\\nP(new) \\n(a) \\n00.050.10.150.20.250.30.350.401002003004005006007008009001000Perceptual Complexity - Average number of dynamic occlusionsNumber of dynamic occlusions\\nP(new) \\n(b) \\nFigure 6: (a) – plot of average no. of objects per frame by \\np(new), (b) – plot of average no. of dynamic occlusions \\nby p(new); No. frames=1500, Max No. objects=20. \\n \\nThe number of dynamic occlusions in each \\npseudo synthetic video was determined by counting the number of occurrences where the bounding box of two or \\nmore ground truth objects overlap in the same image \\nframe. We can count the number of dynamic occlusions \\n(NDO), the average number of occluding objects (NOO), \\nand the average duration of a dynamic occlusion (DDO) \\nto provide a measure of the perceptual complexity [6]. \\nFigure 6 demonstrates how p(new) can vary the \\nperceptual complexity of each generated pseudo-synthetic \\nvideo. Figure 6a and 6b are plots of p(new) by average \\nnumber of objects per frame in the pseudo-synthetic \\nvideo, and the average number of dynamic object \\nocclusions respectively. The error bars on each plot \\nindicate the standard deviation over the five simulations \\nperformed for each value of p(new). ', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 46: ('rage duration of a dynamic occlusion (DDO) \\nto provide a measure of the perceptual complexity [6]. \\nFigure 6 demonstrates how p(new) can vary the \\nperceptual complexity of each generated pseudo-synthetic \\nvideo. Figure 6a and 6b are plots of p(new) by average \\nnumber of objects per frame in the pseudo-synthetic \\nvideo, and the average number of dynamic object \\nocclusions respectively. The error bars on each plot \\nindicate the standard deviation over the five simulations \\nperformed for each value of p(new). The values become \\nasymptotic in both plots as the number of objects per \\nframe approaches the maximum of 20, representing a \\ncomplex and dense video sequence. \\n \\n4. Surveillance Metrics \\n \\nThe surveillance metrics have been derived from a \\nnumber of sources [4,5,6,7,8]. We first align the ground \\ntruth and results tracks by minimizing the trajectory \\ndistance metric that appears in [7]: \\n∑\\n∧ ∃−+− =\\n)()(2 2)()(1),(\\nitritgii i i i\\nrgT yrygxrxgNrgD  \\nWhere rgN is the number of frames that the ground truth \\ntrack and result track have in common, and \\n),(),,(ii iiyrxrygxg is the location of the ground truth and \\nresult track at frame irespectively.  \\nOnce the ground truth and results trajectories \\nhave been matched we use the following metrics to \\ncharacterize the tracking performance: \\n \\nTracker Detection Rate (TRDR) =  \\n PointsTruth  Ground ofNumber  Total PositivesTrue Total \\n \\nFalse Alarm Rate (FAR) =  \\nPositives False Total  Positives True TotalPositivesFalse Total\\n+ \\n \\nTrack Detection Rate (TDR) =  \\nobjectfor  points truth ground ofnumber Totalobject d for tracke positives  trueofNumber  \\nObject Tracking Error (OTE) =  \\n∑\\n∧ ∃−+−\\n)()(2 2) () (1\\ni itrtgiii ii\\nrgyrygxrxg\\nN \\nTrack Fragmentation (TF) = Number of result tracks \\nmatched to ground truth track \\nOcclusion Success Rate (OSR) =  \\nocclusions dynamic ofnumber  ofnumber Totalocclusions dynamic sucessful ofNumber  \\n \\nTracking Success Rate (TSR) =  \\nobjects truth ground ofnumber  ofnumber Totalobjects  tracked fragmented-non ofNumber  \\n \\nA true positive is de', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 47: ('or  points truth ground ofnumber Totalobject d for tracke positives  trueofNumber  \\nObject Tracking Error (OTE) =  \\n∑\\n∧ ∃−+−\\n)()(2 2) () (1\\ni itrtgiii ii\\nrgyrygxrxg\\nN \\nTrack Fragmentation (TF) = Number of result tracks \\nmatched to ground truth track \\nOcclusion Success Rate (OSR) =  \\nocclusions dynamic ofnumber  ofnumber Totalocclusions dynamic sucessful ofNumber  \\n \\nTracking Success Rate (TSR) =  \\nobjects truth ground ofnumber  ofnumber Totalobjects  tracked fragmented-non ofNumber  \\n \\nA true positive is defined as a ground truth point \\nthat is located within the bounding box of an object \\ndetected and tracked by the tracking algorithm. A false \\nnegative is a ground truth point that is not located with \\nthe bounding box of any object tracked by the tracking \\nalgorithm. A false positive is an object that is tracked by \\nthe system that does not have a matching ground truth \\npoint. These conditions are illustrated in figure 7. In \\nfigure 7(a) the vehicle in the top image has not been \\ntracked correctly. The ground truth point for the vehicle \\nis classified as a false negative. The bounding box of the \\nincorrectly tracked vehicle is counted as a false positive. \\nThe three objects in the bottom image are counted as true \\npositives, since the ground truth point is within the \\ntracked bounding box. \\n \\n \\n      (a)          (b) \\nFigure 7: (a) Image to illustrate true positives, false \\nnegative and false positive,  (b) Image to illustrate a \\nfragmented tracked object trajectory. \\n \\nThe tracker detection rate (TRDR) and false \\nalarm rate (FAR) characterise the tracking performance \\nof the object-tracking algorithm. The track detection rate \\n(TDR) indicates the tracking completeness of a specific \\nground truth track. The object tracking error (OTE) \\nindicates the mean distance between the ground truth \\nand the tracked object trajectory. The track \\nfragmentation (TF) indicates how often a track label \\nchanges. Ideally, the TF value should be one, with larger \\nvalues reflecting poor tracking and trajectory \\nmaintenance. The tr', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 48: ('alse \\nalarm rate (FAR) characterise the tracking performance \\nof the object-tracking algorithm. The track detection rate \\n(TDR) indicates the tracking completeness of a specific \\nground truth track. The object tracking error (OTE) \\nindicates the mean distance between the ground truth \\nand the tracked object trajectory. The track \\nfragmentation (TF) indicates how often a track label \\nchanges. Ideally, the TF value should be one, with larger \\nvalues reflecting poor tracking and trajectory \\nmaintenance. The tracking success rate (TSR) \\nsummarises the performance of the tracking algorithm \\nwith respect to track fragmentation. The occlusion \\nsuccess rate (OSR) indicates how effective the tracking \\nalgorithm is with respect to occlusion reasoning. Figure \\n7(b) shows a tracked object trajectory for the pedestrian who is about to leave the camera view. The track is \\nfragmented into two parts shown as black and white \\ntrajectories. The two track segments are used to \\ndetermine the track detection rate, which indicates the \\ncompleteness of the tracked object. As a consequence the \\nground truth object had a TDR, OTE, and TF of 0.99, \\n6.43 pixels, and 2 respectively. \\n \\n5. Results \\n \\nA number of experiments were run to test the \\nperformance of the tracking algorithm used by our online \\nsystem. The tracking algorithm employs a partial-\\nobservation tracking model [3] for occlusion reasoning. \\nWe first generated purely manual ground truth for the \\nsecond PETS2001 dataset (camera 2) using the point and \\nclick method described in section 2. We processed the \\ndata at a rate of 5fps. Table 1 provides a summary of the \\nsurveillance metrics report. The results demonstrate the \\nrobust tracking performance, since the track \\ncompleteness is nearly perfect for all the objects. A \\ncouple of the tracks are fragmented due to poor \\ninitialisation or early termination. Figure 8 demonstrates \\nwhat can happen when a tracked object is not initialised \\ncorrectly. The left, and right images show the pedestrian \\nexiting and leaving the parked vehic', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 49: ('in section 2. We processed the \\ndata at a rate of 5fps. Table 1 provides a summary of the \\nsurveillance metrics report. The results demonstrate the \\nrobust tracking performance, since the track \\ncompleteness is nearly perfect for all the objects. A \\ncouple of the tracks are fragmented due to poor \\ninitialisation or early termination. Figure 8 demonstrates \\nwhat can happen when a tracked object is not initialised \\ncorrectly. The left, and right images show the pedestrian \\nexiting and leaving the parked vehicle. The pedestrian is \\npartially occluded by other objects, so is not detected by \\nthe tracking algorithm until it has moved from the \\nvehicle. The pedestrian relates to ground truth object 9. \\nAn example of dynamic occlusion reasoning is \\nshown in figure 9. The cyclist overtakes the two \\npedestrians, forming two dynamic occlusions and it can \\nbe noted that the correct trajectory is maintained for all \\nthree objects. The object labels in figure 9 have been \\nassigned by the tracking algorithm and are different from \\nthe ground truth object labels.  \\nWe have also used the second PETS2001 dataset \\n(camera 2) to construct a pseudo synthetic video by \\nadding four additional ground truth tracks to the original \\nvideo sequence. Table 2 summarises the differences in \\nperceptual complexity between the original and pseudo \\nsynthetic video sequence. The number of dynamic object \\nocclusions increases from 4 to 12, having the desired \\naffect of increasing the complexity of the original video \\nsequence. Table 2 also summarises the tracking \\nperformance for the original and pseudo synthetic \\nsequences. These results validate our assumption that our \\nobject tracker can be used to generate ground truth for \\nvideo with low activity. \\nIn order to test the effectiveness of the tracking \\nalgorithm for tracking success and dynamic occlusion \\nreasoning we generated several pseudo synthetic videos \\n\\nsequences. We automatically selected ground truth tracks \\nfrom the surveillance database using the method \\ndescribed in section 3.1. We t', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 50: ('ises the tracking \\nperformance for the original and pseudo synthetic \\nsequences. These results validate our assumption that our \\nobject tracker can be used to generate ground truth for \\nvideo with low activity. \\nIn order to test the effectiveness of the tracking \\nalgorithm for tracking success and dynamic occlusion \\nreasoning we generated several pseudo synthetic videos \\n\\nsequences. We automatically selected ground truth tracks \\nfrom the surveillance database using the method \\ndescribed in section 3.1. We then generated five synthetic \\nvideo sequences for each level of perceptual complexity. \\nThe value of p(new) was varied between 0.01 to 0.4 with \\nincrements of 0.01. Each pseudo synthetic video \\nsequence was 1500 frames in length, which is equivalent \\nto approximately 4 minutes of live captured video by our \\nonline system running at 7Hz. Hence, in total the system \\nwas evaluated with 200 different video sequences, \\ntotalling three hundred thousand image frames, or \\napproximately 800 minutes of video. \\n \\n \\nFigure 8: An example of how poor track initialisation \\nresults in low object track detection rate of the pedestrian \\nleaving the vehicle. \\n \\nFigure 9: Example of dynamic occlusion reasoning for \\nPETS2001 dataset 2 camera 2.  \\n \\nThe synthetic video sequences were used as input to the \\ntracking algorithm. The tracking results and ground \\ntruth were then compared and used to generate a \\nsurveillance metrics report as described in section 4. \\nTable 3 gives a summary of the complexity of a selection \\nof the generated video sequences. These results confirm \\nthat p(new) controls the perceptual complexity, since the \\nnumber of objects, average number of dynamic \\nocclusions and occluding objects increases from (12.8, \\n2.4, 2.0) to (357.2, 755.2, 3.24) respectively for the \\nsmallest and largest values of p(new). Table 4 \\nsummarises the tracking performance for various values \\nof p(new). The object tracking error increases with the \\nvalue of p(new), which represents a degradation of \\ntracking performance with respect to o', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 51: ('ted video sequences. These results confirm \\nthat p(new) controls the perceptual complexity, since the \\nnumber of objects, average number of dynamic \\nocclusions and occluding objects increases from (12.8, \\n2.4, 2.0) to (357.2, 755.2, 3.24) respectively for the \\nsmallest and largest values of p(new). Table 4 \\nsummarises the tracking performance for various values \\nof p(new). The object tracking error increases with the \\nvalue of p(new), which represents a degradation of \\ntracking performance with respect to occlusion \\nreasoning. The occlusion success rate (OSR) and \\ntracking success rate (TSR) decreases in value from \\n(86%, 73%) to (53%, 18%) with the increasing value of \\np(new). When the number of objects per frame \\napproaches the maximum this limits the number of \\ndynamic occlusions created, hence increasing values of p(new) have a diminished affect of increasing the \\nperceptual complexity. As a consequence the TSR and \\nOSR become asymptotic once the number of objects per \\nframe approaches the maximum of 20 as illustrated in \\nthe plots of figure (10). Larger values of p(new) and the \\nmaximum number of objects would result in more \\ncomplex video sequences. Hence even with the bias \\npresent in the generated video sequences we can still \\nevaluate the object tracking performance with respect to \\ntracking success and occlusion reasoning, without \\nexhaustive manual truthing, fulfilling the main objective \\nof our framework for performance evaluation. \\n0 0.05 0.10.15 0.20.25 0.30.35 0.400.10.20.30.40.50.60.70.80.9Surveillance Metrics - Tracking Success RateTracking Success Rate\\nP(new) \\n   (a) \\n0 0.05 0.10.15 0.20.25 0.30.35 0.400.20.40.60.81Surveillance Metrics - Dynamic Occlusion Success RateOcclusion Success Rate\\nP(new) \\n   (b) \\nFigure 10: Plot of: (a) Tracking success rate, (b) \\nocclusion success rate \\n \\n6. Conclusion \\n \\nWe have presented a novel framework for evaluating the \\nperformance of a video tracking algorithm. The \\nperformance evaluation framework automatically selects \\nground truth tracks from a surveillance ', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 52: ('illance Metrics - Tracking Success RateTracking Success Rate\\nP(new) \\n   (a) \\n0 0.05 0.10.15 0.20.25 0.30.35 0.400.20.40.60.81Surveillance Metrics - Dynamic Occlusion Success RateOcclusion Success Rate\\nP(new) \\n   (b) \\nFigure 10: Plot of: (a) Tracking success rate, (b) \\nocclusion success rate \\n \\n6. Conclusion \\n \\nWe have presented a novel framework for evaluating the \\nperformance of a video tracking algorithm. The \\nperformance evaluation framework automatically selects \\nground truth tracks from a surveillance database in \\norder to construct pseudo synthetic video sequences. We \\nhave compiled a comprehensive set of metrics, which \\ncan be used to measure the quality of the ground truth \\ntracks, as well as characterise tracking performance. We \\nrecognise that the pseudo synthetic video will have a \\ndegree of bias to the motion detection algorithm used to \\ncapture the original data. However, the generated video \\nsequences are effective for evaluating performance of \\nocclusion reasoning, and can be used to evaluate other \\ntracking algorithms. The main strength of our \\nevaluation framework is that we can automatically \\ngenerate a variety of different testing datasets. In this \\npaper we have evaluated a tracking algorithm over three \\nhundred thousand frames of video, without any human intervention or semi-automatic ground truth generation. \\nIn future work we plan evaluate other tracking \\nalgorithms within our framework using the results \\npresented in this paper as a benchmark. \\n \\n           \\nTrack  0 1 2 3 4 5 6 7 8 9 \\nTP 25 116 26 104 36 369 78 133 43 88 \\nFN 0 2 0 5 0 5 1 1 1 2 \\nTDR 1.00 0.98 1.00 0.95 1.00 0.99 0.99 0.99 0.98 0.98 \\nTF 1 1 1 1 1 1 1 2 1 2 \\nOTE 11.09 7.23 8.37 4.70 10.82 11.63 9.05 6.43 8.11 11.87 \\nTP: Number of true positives FN: Number of false positives TF: Track Fragmentation  \\nTDR: Track Detection Rate OTE: Object Tracking Error \\nTable 1: Summary of surveillance metrics for PETS2001 dataset2 (camera 2) \\n \\n TNO NDO DDO NOO TRDR TSR FAR AOTE ATDR \\n        mean stdev mean Stdev \\nDataset 2(Cam 2) 10 4 8.5', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 53: ('P 25 116 26 104 36 369 78 133 43 88 \\nFN 0 2 0 5 0 5 1 1 1 2 \\nTDR 1.00 0.98 1.00 0.95 1.00 0.99 0.99 0.99 0.98 0.98 \\nTF 1 1 1 1 1 1 1 2 1 2 \\nOTE 11.09 7.23 8.37 4.70 10.82 11.63 9.05 6.43 8.11 11.87 \\nTP: Number of true positives FN: Number of false positives TF: Track Fragmentation  \\nTDR: Track Detection Rate OTE: Object Tracking Error \\nTable 1: Summary of surveillance metrics for PETS2001 dataset2 (camera 2) \\n \\n TNO NDO DDO NOO TRDR TSR FAR AOTE ATDR \\n        mean stdev mean Stdev \\nDataset 2(Cam 2) 10 4 8.5 2 0.99 8/10 0.01 8.93 2.4 0.99 0.010 \\nPseudo Synthetic PETS Dataset 14 12 8.58 2.08 1.00 9/13 0.01 1.36 2.09 1.00 0.002 \\nNDO: No. of Dynamic Occlusions DDO: Duration of Dynamic Occlusion (frames) \\nNOO: Number of Occluding Objects TNO: Total Number of Objects \\nTable 2: Summary of perceptual complexity of the PETS2001 dataset2 (camera2) and object tracking metrics. \\n \\n TNO NDO DDO NOO \\nP(new) mean stdev mean stdev mean stdev mean stdev \\n0.01 12.80 4.147 2.40 1.140 6.42 5.353 2.00 0.000 \\n0.20 284.00 16.538 595.20 49.957 10.70 0.310 2.95 0.020 \\n0.40 357.20 4.087 755.20 15.466 12.26 0.461 3.24 0.112 \\nTable 3: Summary of the perceptual complexity of the 200 synthetic video sequences (300000 frames). \\n \\n TRDR FAR OSR AOTE ATDR ATSR \\nP(new)   mean stdev Mean stdev mean stdev mean stdev \\n0.01 0.91 0.08 0.86 0.149 3.21 1.466 0.90 0.049 0.73 0.129 \\n0.20 0.91 0.09 0.57 0.010 12.64 0.599 0.76 0.008 0.23 0.029 \\n0.40 0.90 0.09 0.53 0.014 14.12 0.581 0.72 0.006 0.18 0.015 \\nTable 4: Summary of metrics generated using each synthetic video sequence. \\n \\nReferences \\n \\n[1] T.J. Ellis, J. Black. A Multi-view surveillance system. IEE Intelligent \\nDistributed Surveillance Systems, London, February 2003. \\n[2] M. Xu, and T.J. Ellis, “Illumination-Invariant Motion Detection \\nUsing Colour Mixture Models”, British Machine Vision Conference \\n(BMVC 2001), Manchester, September 2001, pp 163-172. \\n[3] M. Xu, and T.J. Ellis, “Partial Observation vs Blind Tracking \\nthrough Occlusion”, British Machine Vision Conference (BMVC 2002), \\nCardiff, Sept', 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 54: (\"nthetic video sequence. \\n \\nReferences \\n \\n[1] T.J. Ellis, J. Black. A Multi-view surveillance system. IEE Intelligent \\nDistributed Surveillance Systems, London, February 2003. \\n[2] M. Xu, and T.J. Ellis, “Illumination-Invariant Motion Detection \\nUsing Colour Mixture Models”, British Machine Vision Conference \\n(BMVC 2001), Manchester, September 2001, pp 163-172. \\n[3] M. Xu, and T.J. Ellis, “Partial Observation vs Blind Tracking \\nthrough Occlusion”, British Machine Vision Conference (BMVC 2002), \\nCardiff, September 2002, pp 777-786. \\n[4] C. Jaynes, S. Webb, R. Matt Steele, and Q. Xiong, “An Open \\nDevelopment Environment for Evaluation of Video Surveillance \\nSystems”, Proceedings of the Third International Workshop on \\nPerformance Evaluation of Tracking and Surveillance (PETS’2002), \\nCopenhagen, June 2002. \\n[5] D. Doermann, and D. Mihalcik, “Tools and Techniques for Video \\nPerformance Evaluation”, Proceedings of the International Conference \\non Pattern Recognition (ICPR’00), Barcelona, September 2000, pp \\n4167-4170. \\n[6] T.J. Ellis, “Performance Metrics and Methods for Tracking in \\nSurveillance”, Proceedings of the Third International Workshop on \\nPerformance Evaluation of Tracking and Surveillance (PETS’2002), \\nCopenhagen, June 2002. [7] A. Senior, A. Hampapur, Y. Tian, L. Brown, S. Pankanti, R. Bolle, \\n“Appearance Models for Occlusion Handling” Proceedings of the Second \\nInternational Workshop on Performance Evaluation of Tracking and \\nSurveillance (PETS’2001), Hawaii, Kauai, December 2001. \\n[8] C.J. Needham, R.D. Boyle. Performance Evaluation Metrics and \\nStatistics for Positional Tracker Evaluation. International Conference on \\nComputer Vision Systems (ICVS'03), Graz, Austria, April 2003, pp \\n278-289. \\n[9] Ç. Erdem, B. Sankur, A.M. Tekalp. Metrics for Performance \\nEvaluation of Video Object Segmentation and Tracking Without \\nGround-Truth. IEEE International Conference on Image Processing \\n(ICIP'01), Thessaloniki, Greece, October 2001. \\n[10] D. Comaniciu., V. Ramesh, P. Meer. Real-Time Tracking of Non-\\nRigid Objec\", 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 55: (\". Boyle. Performance Evaluation Metrics and \\nStatistics for Positional Tracker Evaluation. International Conference on \\nComputer Vision Systems (ICVS'03), Graz, Austria, April 2003, pp \\n278-289. \\n[9] Ç. Erdem, B. Sankur, A.M. Tekalp. Metrics for Performance \\nEvaluation of Video Object Segmentation and Tracking Without \\nGround-Truth. IEEE International Conference on Image Processing \\n(ICIP'01), Thessaloniki, Greece, October 2001. \\n[10] D. Comaniciu., V. Ramesh, P. Meer. Real-Time Tracking of Non-\\nRigid Objects Using Mean Shift. IEEE Conference on Computer Vision \\nand Pattern Recognition (CVPR'00), Hilton Head, South Carolina, June \\n2000, pp 2142-2151. \\n[11] K. Nummiaro, E. Koller-Meier, L. Van Gool. Color Features for \\nTracking Non-Rigid Objects. Special Issue on Visual Surveillance, \\nChinese Journal of Automation, May 2003, Vol. 29, No. 3, pp 345-355. \\n[12] P.L. Rosin, E. Ioannidis. Evaluation of Global Image Thresholding \\nfor Change Detection, Pattern Recognition Letters, 2003, Vol. 24, No. \\n14, pp 2345-2356. \", 'A Novel Method for Video Tracking Performance Evaluation.pdf'), 56: ('A Novel Method of Combined Feature Extraction for Recognition \\n \\n \\nTingkai Sun1, Songcan Chen2,3, Jingyu Yang1, Pengfei Shi4 \\n1School of Computer Science and Technology, Nanjing University of Science and Technology, Nanjing, China \\nE-mail: {suntingkai, yangjy}@mail.njust.edu.cn \\n2Dept. of Computer Science & Engineering, Nanjing University of Aeronautics & Astronautics, Nanjing, \\nChina, E-mail: s.chen@nuaa.edu.cn \\n3State Key Lab. for Novel Software Technology, Nanjing University, Nanjing, China \\n4School of Electronic, Information and Electrical Engineering, Shanghai Jiaotong University, Shanghai, \\nChina, E-mail: pfshi@sjtu.edu.cn   \\n \\n \\nAbstract \\n \\nMultimodal recognition is an emerging technique to \\novercome the non-robustness of the unimodal \\nrecognition in real applications. Canonical correlation \\nanalysis (CCA) has been employed as a powerful tool \\nfor feature fusion in the realization of such multimodal \\nsystem. However, CCA is the unsupervised feature \\nextraction and it does not utilize the class information \\nof the samples, resulting in the constraint of the \\nrecognition performance. In this paper, the class \\ninformation is incorporated into the framework of CCA \\nfor combined feature extraction, and a novel method of \\ncombined feature extraction for multimodal \\nrecognition, called discriminative canonical \\ncorrelation analysis (DCCA), is proposed. The \\nexperiments show that DCCA outperforms some \\nrelated methods of both  unimodal recognition and \\nmultimodal recognition. \\n \\n1. Introduction \\n \\nMost of the state-of-the-art pattern recognition \\nmethods are unimodal, e.g., audio-only speech \\nrecognition, and some commercially available \\nunimodal recognition systems work well in reasonably \\ngood conditions. However, the performance of such \\nsystems may unpredictably deteriorate under some \\nnoisy conditions. When the non-robustness of \\nunimodal recognition is noticed in real applications, \\nmultimodal recognition emerges and has been gained \\nmore and more attentions [1,2].  \\n  For multimodal recognition, it is a cri', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 57: ('ate-of-the-art pattern recognition \\nmethods are unimodal, e.g., audio-only speech \\nrecognition, and some commercially available \\nunimodal recognition systems work well in reasonably \\ngood conditions. However, the performance of such \\nsystems may unpredictably deteriorate under some \\nnoisy conditions. When the non-robustness of \\nunimodal recognition is noticed in real applications, \\nmultimodal recognition emerges and has been gained \\nmore and more attentions [1,2].  \\n  For multimodal recognition, it is a critical issue to \\neffectively utilize the information stemming from \\ndifferent sources to improve the recognition \\nperformance. An effective solution to this problem is \\ninformation fusion, which is defined as the synergistic use of information from diverse sources to improve \\noverall understanding of a phenomenon or the \\nrecognition of an object [3]. By the proper approach, \\ninformation fusion can make use of the complementary \\ninformation to emphasize the useful information for \\nthe problem at hand; meanwhile it also can reduce the \\nuncertainties to some extent [3].  Pan et al [4] studied \\nthe multisensory information fusion in the Bayesian \\ninference framework, that is, given n pairwise samples \\n1 {( , )}n\\nii i = xy  coming from c classes 1 {}c\\niiω=, a new \\npairwise sample ( x,y) should be classified according to \\nits a posteriori  conditional probability, which is \\ncomputed by the Bayes rule \\n1(, | )( )(| , )\\n(, | )( )ii\\ni c\\njj jpPP\\npPωωω\\nωω==∑xyxy\\nxy  (1) \\nSince the denominator is common and the priori  \\nprobability ()iPωis easily to be estimated, so the task \\nturns to be how to effectively estimate the priori  joint \\nprobability distribution function (pdf) (, | )i p ω xy  \\nfor the recognition task. However, in the case of high \\ndimensional and highly-coupled signals, the direct \\nestimating pdf (, | )i p ω xy  is difficult. An \\nalternative approach to this problem is 1) mapping the \\nhigh dimensional signals to low-dimensional subspace \\nby a linear mapping, 2) in the low-dimensional \\nsubspace, it is easy to e', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 58: ('robability ()iPωis easily to be estimated, so the task \\nturns to be how to effectively estimate the priori  joint \\nprobability distribution function (pdf) (, | )i p ω xy  \\nfor the recognition task. However, in the case of high \\ndimensional and highly-coupled signals, the direct \\nestimating pdf (, | )i p ω xy  is difficult. An \\nalternative approach to this problem is 1) mapping the \\nhigh dimensional signals to low-dimensional subspace \\nby a linear mapping, 2) in the low-dimensional \\nsubspace, it is easy to estimate the pdf, and 3) turning \\nback to the high dimensional and obtaining the \\nestimated pdf (, | )i p ω xy , which is satisfied with \\nthe maximum entropy constraint. Pan et al [4] found \\nthat when the data distribution is Gaussian, the optimal \\nlinear mapping for the estimating of (, | )i p ω xy  \\nexactly corresponds to a CCA problem using the \\n2008 Eighth IEEE International Conference on Data Mining\\n1550-4786/08 $25.00 © 2008 IEEE\\nDOI 10.1109/ICDM.2008.281043\\n2008 Eighth IEEE International Conference on Data Mining\\n1550-4786/08 $25.00 © 2008 IEEE\\nDOI 10.1109/ICDM.2008.281043\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. \\nsamples in class iω! So in this sense, the works in [4] \\nlaid the mathematical foundation of CCA for feature \\nfusion. Unfortunately, for some applications, in which \\nc is large, the separate CCAs based on the samples in \\neach class are fussy computational tasks; what is \\nworse, when the number of the samples x(y) in iω is \\nsmall, the estimated (, | )i p ω xy  based on too few \\nsamples in iω may be imprecise. Alternatively, Sun et \\nal. [5] employ CCA to extract features from all the \\nsamples1 {( , )}n\\nii i = xy , and directly fuse the extracted \\nfeatures for recognition. The advantage of doing so [5] \\nis that it can obtain the global solution at once rather \\nthan separately estimating the class pdf (, | )i p ω xy , \\nhowever, CCA is unsupervised feature extraction \\nmethod, and in doing so the class l', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 59: (' the samples x(y) in iω is \\nsmall, the estimated (, | )i p ω xy  based on too few \\nsamples in iω may be imprecise. Alternatively, Sun et \\nal. [5] employ CCA to extract features from all the \\nsamples1 {( , )}n\\nii i = xy , and directly fuse the extracted \\nfeatures for recognition. The advantage of doing so [5] \\nis that it can obtain the global solution at once rather \\nthan separately estimating the class pdf (, | )i p ω xy , \\nhowever, CCA is unsupervised feature extraction \\nmethod, and in doing so the class label information is \\nnot exploited, resulting in the limitation of the recognition performance. \\nTo remedy this shortcoming of CCA, in this paper, \\nthe class information is incorporated into the \\nframework of CCA for combined feature extraction, and a novel method of combined feature extraction for multimodal recognition, called discriminative \\ncanonical correlation analysis (DCCA), is proposed. \\nThe experiments of text categorization, face recognition and handwritten digit recognition show that DCCA outperforms some related methods of both \\nunimodal recognition and multimodal recognition. \\n \\n2. Review of canonical correlation analysis \\n \\nGiven n pairs of mean-normalized pairwise  samples \\n1 {( , )}n\\nii i = xyp q∈ℜ ×ℜ  coming from c classes, \\nCCA aims to find pairs of projection directions xwand \\nyw that maximize the correlation between the random \\nvariable T\\nxi x=wx  andT\\nyi y=wy , i =1,… n. More \\nformally, CCA can be described as:  \\n()[]\\n[] [],,a r g m a x\\nvar varxyxyEx y\\nx y=\\nwwww  \\n1\\n,\\n11arg max\\nxyn TT\\nxi i y i\\nnnTT TT\\nxi i x yi i y ii=\\n===\\n⋅∑\\n∑∑wwwx yw\\nwx xw w yyw \\n,(2) arg max\\nxyTT\\nxy\\nTT T T\\nxx y y=\\n⋅wwwX Yw\\nwX Xw w Y Yw    Solving this optimization problem, it is easy to obtain \\nthe following equation: \\nT\\nTλ⎛⎞⎛⎞ ⎛⎞ ⎛⎞= ⎜⎟⎜⎟ ⎜⎟ ⎜⎟⎜⎟⎜⎟⎝⎠ ⎝⎠ ⎝⎠⎝⎠T\\nxx\\nT\\nyyww XY XX\\nww YX YY   (3) \\nwhere the generalized eigenvalue λ is exactly the \\ncorrelation between the random variable x and y. \\nSuppose there are at most r non-zero generalized \\neigenvalues λ corresponding to (3), once the vector \\npairs (, )xiy iww , i=1,…, d', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 60: (' i y i\\nnnTT TT\\nxi i x yi i y ii=\\n===\\n⋅∑\\n∑∑wwwx yw\\nwx xw w yyw \\n,(2) arg max\\nxyTT\\nxy\\nTT T T\\nxx y y=\\n⋅wwwX Yw\\nwX Xw w Y Yw    Solving this optimization problem, it is easy to obtain \\nthe following equation: \\nT\\nTλ⎛⎞⎛⎞ ⎛⎞ ⎛⎞= ⎜⎟⎜⎟ ⎜⎟ ⎜⎟⎜⎟⎜⎟⎝⎠ ⎝⎠ ⎝⎠⎝⎠T\\nxx\\nT\\nyyww XY XX\\nww YX YY   (3) \\nwhere the generalized eigenvalue λ is exactly the \\ncorrelation between the random variable x and y. \\nSuppose there are at most r non-zero generalized \\neigenvalues λ corresponding to (3), once the vector \\npairs (, )xiy iww , i=1,…, d, corresponding to the first d \\nlargest generalized eigenvalues are obtained, let \\nWx=[1,...,x xd ww ], Wy=[1,...,y yd ww ], the combined \\nfeature extraction and the feature fusion can be \\nperformed in the following ways [5]: \\n  I) 0\\n0T\\nx\\ny⎛⎞ ⎛⎞=⎜⎟ ⎜⎟⎝⎠ ⎝⎠W xzW y                                     (4) \\nII)  T\\nx\\ny⎛⎞⎛⎞=⎜⎟⎜⎟⎝⎠⎝⎠W xzW y                                          (5) \\nwhich hereafter are called feature fusion strategy I and \\nII (FFS-I and -II), respectively. Sun et al [5] studied \\nFFS-I and –II using CCA and apply them to pattern recognition.  \\n3. Discriminative canonical correlation \\nanalysis \\n \\nUsing CCA, the correlated information T\\nxiwx  \\nandT\\nyiwy ,i=1,…, n, are extracted and fused for \\nrecognition [5]. However, the class information of the \\nsamples is not exploited, resulting in the limitation of the recognition performance of CCA. In fact, CCA was \\noriginally proposed for modeling [6] rather than \\nrecognition, and correlation \\nλ indicates the \\npredictability between T\\nxiwx  andT\\nyiwy ,i=1,…, n. In \\nfact, CCA was more applied to modeling and \\nprediction, such as image retrieval [7] and parameter \\nestimation [8]. If the featur es are to be extracted for \\nrecognition, the class information of the samples should be exploited to extract more discriminative features. To this end, we incorporate the class \\ninformation in the framework of CCA for combined \\nfeature extraction, and propose a novel method of combined feature extraction for multimodal recognition, called discriminative canonical correlati', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 61: (' n. In \\nfact, CCA was more applied to modeling and \\nprediction, such as image retrieval [7] and parameter \\nestimation [8]. If the featur es are to be extracted for \\nrecognition, the class information of the samples should be exploited to extract more discriminative features. To this end, we incorporate the class \\ninformation in the framework of CCA for combined \\nfeature extraction, and propose a novel method of combined feature extraction for multimodal recognition, called discriminative canonical correlation \\nanalysis (DCCA), which is detailed as follows. \\n1044\\n1044\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. \\nGiven n pairs of mean-normalized pairwise samples \\n1 {( , )}n\\nii i = xyp q∈ℜ ×ℜ  coming from c classes, \\nDCCA can be formulated as the following \\noptimization problem: \\n()\\n,\\n,max\\ns.t. 1 1xyTT\\nxwy xby\\nTT T T\\nxx y yη−⋅\\n==wwwCw wCw\\nwX Xw w Y Yw          (6) \\nwhere the matrices  C w and Cb are constructed to \\nmeasure the within-class similarity and the between-\\nclass similarity, respectively (detailed definition are \\ngiven below), and η>0 a tunable parameter that \\nindicates the relative significance of the within-class  \\nsimilarity T\\nx wywCw versus the between-class \\nsimilarity T\\nx bywCw . In addition, the constraint \\ncondition denotes the scale constraint on ,x y ww . Let \\n1( 1 ) ( 1 ) () ()\\n11,..., ,......, ,...,\\nccc\\nnn⎡⎤=⎣⎦Xx x x x         (7) \\n1(1) (1) ( ) ( )\\n11,..., ,......, ,...,\\nccc\\nnn⎡⎤=⎣⎦Yy y y y          (8) \\nNNN\\n1\\n11[0,...0,1,...1,0,...0]\\ni\\niii\\njj\\njjTn\\nn\\nn\\nnn nR\\n−\\n==−=∈\\n∑∑e                 (9) \\n[1,...1]Tn\\nn R =∈1                                          (10) \\nwhere()i\\njxdenotes the jth sample in the ith class, so \\ndoes ()i\\njy, and ni denotes the number of samples of \\n()i\\njxor()i\\njy in the ith class. The matrix  Cw is defined as \\n() ()\\n11 1 1() ( )ii\\niinn cc\\nii T T\\nwk l n n\\nikl i\\nT== = ===\\n=∑∑∑ ∑ Cx y X e Y e\\nXAY(11) \\nwhere \\n11\\nii\\nccnn\\nnn\\nnn\\nnn×\\n×\\n×\\n×⎡⎤\\n⎢⎥⎢⎥⎢⎥=∈ ℜ⎢⎥\\n⎢⎥⎢⎥\\n⎣⎦1\\n1 A\\n1%\\n%\\n (12) \\nis a symmetric', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 62: ('  (8) \\nNNN\\n1\\n11[0,...0,1,...1,0,...0]\\ni\\niii\\njj\\njjTn\\nn\\nn\\nnn nR\\n−\\n==−=∈\\n∑∑e                 (9) \\n[1,...1]Tn\\nn R =∈1                                          (10) \\nwhere()i\\njxdenotes the jth sample in the ith class, so \\ndoes ()i\\njy, and ni denotes the number of samples of \\n()i\\njxor()i\\njy in the ith class. The matrix  Cw is defined as \\n() ()\\n11 1 1() ( )ii\\niinn cc\\nii T T\\nwk l n n\\nikl i\\nT== = ===\\n=∑∑∑ ∑ Cx y X e Y e\\nXAY(11) \\nwhere \\n11\\nii\\nccnn\\nnn\\nnn\\nnn×\\n×\\n×\\n×⎡⎤\\n⎢⎥⎢⎥⎢⎥=∈ ℜ⎢⎥\\n⎢⎥⎢⎥\\n⎣⎦1\\n1 A\\n1%\\n%\\n (12) \\nis a symmetric, positive semidefinite, blocked diagonal \\nmatrix, and rank( A)=c.  \\nOn the other hand, the matrix  Cb is defined as \\n() ( )\\n111 1j in n cc\\nij T\\nbk l\\nij k l\\nji=== =\\n≠=∑∑∑∑ Cx y  () ( ) () ()\\n111 1 11 1j ii in nn n cc c\\nij T i i T\\nkl kl\\nij k l i k l=== = == ==−∑∑∑∑ ∑∑∑ xy xy  \\n() ( )T T\\nnn\\nT=−\\n=−X1 Y1 XAY\\nXAY                (13) \\nThe last “=” holds due to the fact that the samples have \\nbeen mean-normalized so  that both X1 n=0 and Y1n=0 \\nhold. Comparing (13) with (11), the difference between \\nCw and Cb is only one negative sign, so the objective of \\n(6) turns to be (1 )T\\nx wy η+wCw , and this optimization \\nproblem is independent of the parameter η, so η can \\nbe omitted. Thus DCCA can be formulated as: \\n,max\\ns.t. 1, 1xyTT\\nxy\\nTT T T\\nxx y y ==wwwX A Yw\\nwX Xw w Y Yw      (14) \\nUsing the Lagrangian multiplier technique, it is easy to \\nobtain the corresponding primary equation of DCCA \\nas follows: \\nTT\\nx x\\nTT\\ny yλ⎛⎞ ⎛ ⎞ ⎛⎞ ⎛⎞= ⎜⎟ ⎜ ⎟ ⎜⎟ ⎜⎟⎜⎟ ⎜ ⎟⎝⎠ ⎝⎠ ⎝⎠ ⎝ ⎠ww XAY XX\\nww YAX YY (15) \\nOnce the vector pairs (, )xiy iww , i=1,…, d, \\ncorresponding to the first d largest generalized \\neigenvalues are obtained, let Wx=[1,...,x xd ww ], \\nWy=[1,...,y yd ww ], the combined feature extraction \\nand the feature fusion can be performed according to \\nFFS-I and –II, respectively, where d satisfies the \\nconstraints d≤min( p,q) and d≤c. Based on the extracted \\nfeatures in this way, any classifier, e.g., the nearest-neighbor classifier, can be used for recognition. \\nFor DCCA, the following conclusion holds: \\nTheorem  1. Let \\n,TT\\nix iiy i=', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 63: (', i=1,…, d, \\ncorresponding to the first d largest generalized \\neigenvalues are obtained, let Wx=[1,...,x xd ww ], \\nWy=[1,...,y yd ww ], the combined feature extraction \\nand the feature fusion can be performed according to \\nFFS-I and –II, respectively, where d satisfies the \\nconstraints d≤min( p,q) and d≤c. Based on the extracted \\nfeatures in this way, any classifier, e.g., the nearest-neighbor classifier, can be used for recognition. \\nFor DCCA, the following conclusion holds: \\nTheorem  1. Let \\n,TT\\nix iiy i==ξwXζwY  denote the \\nextracted features using DCCA, they satisfy that: \\n,ij i j δ <> =ξξ , ,ij i j δ <> =ζζ , where ijδ denotes \\nthe Kronecker symbol, i.e., 1ijδ=if i=j, and 0 \\notherwise. Besides, iξand iζ are matrix A-\\northonormal, i.e., T\\nij i i j λδ=ξAζ . \\nProof: Let T\\nx=CX X ,T\\ny=CY Y , and (15) can be  \\ndecoupled as: \\n12\\n12T\\nwy wx xx\\nT\\nwx wy yyλ\\nλ−\\n−⎧ =⎪⎨= ⎪⎩CC Cw Cw\\nCC Cw Cw                             (16) \\n1045\\n1045\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. \\nLet 11\\n22 pq\\nxw y R−− ×=∈HC C C ， 1\\n2\\nx x =uC w ，\\n1\\n2\\ny y =vC w , and rank( H)=r, Eqs. (16) turn to be \\n2\\n2T\\nTλ\\nλ⎧ =⎪⎨=⎪⎩HHu u\\nHHv v                                              (17) \\nwhich exactly correspond the singular value \\ndecomposition (SVD) of matrix H. Let the SVD of H \\nbe1rTT\\niii iλ===∑ HUDV u v , where  ,iiuv are the \\ni-th column vector of the orthonormal matrix U and V, \\nrespectively.  Thus 1\\n2\\nxix i−=wC u and1\\n2\\nyiy i−=wC v , \\ni=1,…, d. So  \\n,TT T\\ni j xi xj i j ij δ <> = ==ξξ wX Xw u u ,  \\n,TT T\\nij y i y j i j i j δ <> = = =ζζ wY Yw vv , and \\nTT T T\\nij x i y j i j i i j λδ == =ξAζ wX A Yw uH v .  □ \\nFrom Theorem  1, we know that for DCCA, the \\nfeatures extracted in the same modality (e.g., X sample \\nspace) are statistically uncorrelated each other. So \\nDCCA eliminates the redundant information in the same modality. According to the theory of the statistical pattern recognition, the features with less \\ncorrelation, or without correlation, wi', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 64: ('o  \\n,TT T\\ni j xi xj i j ij δ <> = ==ξξ wX Xw u u ,  \\n,TT T\\nij y i y j i j i j δ <> = = =ζζ wY Yw vv , and \\nTT T T\\nij x i y j i j i i j λδ == =ξAζ wX A Yw uH v .  □ \\nFrom Theorem  1, we know that for DCCA, the \\nfeatures extracted in the same modality (e.g., X sample \\nspace) are statistically uncorrelated each other. So \\nDCCA eliminates the redundant information in the same modality. According to the theory of the statistical pattern recognition, the features with less \\ncorrelation, or without correlation, will benefit to the \\nsubsequent recognition.    \\n4. Experiments and analysis \\n \\nIn this section, we will evaluate the ability of \\nDCCA to combined feature extraction for recognition. To this end, some experiments are performed to compare DCCA with some related methods, i.e., CCA \\nand partial least squares (PLS), which is also used for \\ncombined feature extraction and recognition [9]. After feature extraction using these methods, the nearest neighbor classifier is employed. After several times of \\nthe random experiments, the average recognition \\naccuracy is reported.  \\n4.1 Text categorization \\n The WebKB hypertext dataset (available at\\n \\nhttp://www.cs.cmu.edu/afs/cs/project/theo-11/www/-wwkb/ ) \\nis employed in the experiment of text categorization. WebKB consists of 1051 web pages collected from web sites of computer science departments of four \\nfamous universities in U.S. The 1051 pages were \\nmanually classified into the categories of course  (230 \\npages) and non-course  (821 pages). Each page \\ncorresponds to two views, i.e., fulltext  (the text on the \\nweb pages, referred to as sample in X set) and inlinks  (the anchor text on the hyperlinks pointing to the \\npage, referred to as sample in Y set). The original \\nhypertext documents are pre-processed by skipping \\nhtml tokens, toss stop-words and stemming, resulting in 1854-dimensional vector for each fulltext document and a 106-dimensional vector for each \\ninlinks document. Each entry of the vector denotes \\nthe term-frequency in the corresponding document. 120 and ', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 65: ('wo views, i.e., fulltext  (the text on the \\nweb pages, referred to as sample in X set) and inlinks  (the anchor text on the hyperlinks pointing to the \\npage, referred to as sample in Y set). The original \\nhypertext documents are pre-processed by skipping \\nhtml tokens, toss stop-words and stemming, resulting in 1854-dimensional vector for each fulltext document and a 106-dimensional vector for each \\ninlinks document. Each entry of the vector denotes \\nthe term-frequency in the corresponding document. 120 and 400 pages in class course  and class non-\\ncourse , respectively, are randomly selected for \\ntraining, and the remaining 531 pages are used for \\ntest. Then, the term frequency / inverse document frequency (TF-IDF) [10] vector corresponding to each document is  computed. In this experiment, the \\nproposed DCCA and other methods of combined \\nfeature extraction, such as CCA and PLS, are compared. Further, some frequently used text classifiers, such us Naïve Bayes[11], k-nearest \\nneighbor [12] (k-NN), class mean vector [10] (CMV), \\nare also employed for comparison. The random experiments are repeated 100 times, and the average results are reported in Table 1 and 2, respectively.  \\nTable 1. The recognition accuracies of some \\nunimodal classifiers\\n \\nMethod Recognition accuracy \\nfulltext inlinks \\nNaïve Bayes 0.9083 0.8753 \\nk-NN 0.9448 0.9467 \\nCMV 0.9098 0.8881 \\nTable 2. The recognition accuracies of some \\nmultimodal classifiers  \\nMethod Recognition accuracy \\nRatio-1 Ratio-2 \\nDCCA 0.9574 0.9522 \\nCCA 0.9213 0.9235 \\nPLS 0.9203 0.9215 \\n* Ratio-1 and -2 correspond to FFS-I and –II, respectively.  \\nFrom Table 1, k-NN method outperforms Naïve \\nBayes and CMV, and from Table 2, we can see that \\nDCCA outperforms not only CCA and PLS, but also all the related unimodal classifiers in Table 1.   \\n4.2 Face recognition \\n \\nThe well-known ORL face dataset contains 400 face \\nimages of 40 persons, each providing 10 different faces, taken at different times and with varying facial expressions (smile/no smile, open/closed eyes), facial \\ndet', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 66: ('0.9203 0.9215 \\n* Ratio-1 and -2 correspond to FFS-I and –II, respectively.  \\nFrom Table 1, k-NN method outperforms Naïve \\nBayes and CMV, and from Table 2, we can see that \\nDCCA outperforms not only CCA and PLS, but also all the related unimodal classifiers in Table 1.   \\n4.2 Face recognition \\n \\nThe well-known ORL face dataset contains 400 face \\nimages of 40 persons, each providing 10 different faces, taken at different times and with varying facial expressions (smile/no smile, open/closed eyes), facial \\ndetails (with or without glasses) and poses. The images \\nare in upright, frontal position with tolerance for some tilting and rotation of up to 20 degree. All images are \\n1046\\n1046\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. \\ngrayscale with 256 levels and normalized to 112×92 \\npixels. In each experiment, 5 images of each person are \\nrandomly selected for training, and the remaining 5 \\nimages for test. The random experiments are repeated 10 times. In this experiment, the famous Eigenface [13] and Fisherface [14] methods are selected as benchmark \\nmethods for comparison. In addition, for DCCA, CCA \\nand PLS, the Daubechies wavelet transform is performed on images, and the resultant low-frequent images are specified as another set of data.  Fig.1 \\nshows 5 low-frequent images corresponding to one \\nperson (the original images are omitted). \\n \\nFig.1 the low-frequent images \\nTable 3 tabulates the recognition accuracies on ORL \\ndataset, and we can find that DCCA outperforms not \\nonly Eigenface, Fisherface, but also CCA and PLS. \\nTable 3.  The recognition accuracies on ORL \\nMethod Recognition accuracy \\nEigenface 0.9355 \\nFisherface 0.9065 \\nDCCA 0.94951 / 0.94852 \\nCCA 0.90111 / 0.90882 \\nPLS 0.93951 / 0.94052 \\n*superscript 1, 2 correspond to FFS-I and –II, respectively.  \\n \\n4.3 Handwritten digit recognition \\n \\nMultiple Features database (available at \\nhttp://www.ics.uci.edu/~mlearn/MLSummary.html ) \\nconsists of features of handwritt', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 67: (' \\ndataset, and we can find that DCCA outperforms not \\nonly Eigenface, Fisherface, but also CCA and PLS. \\nTable 3.  The recognition accuracies on ORL \\nMethod Recognition accuracy \\nEigenface 0.9355 \\nFisherface 0.9065 \\nDCCA 0.94951 / 0.94852 \\nCCA 0.90111 / 0.90882 \\nPLS 0.93951 / 0.94052 \\n*superscript 1, 2 correspond to FFS-I and –II, respectively.  \\n \\n4.3 Handwritten digit recognition \\n \\nMultiple Features database (available at \\nhttp://www.ics.uci.edu/~mlearn/MLSummary.html ) \\nconsists of features of handwritten numerals (‘0’-‘9’, total 10 classes) extracted from a collection of Dutch \\nutility maps. 200 patterns per class (for a total of 2000 \\npatterns) have been digitized in binary images of size 30×48. Digits are represented in terms of Fourier coefficients (76 dimensions, referred to as FOU,76), \\nprofile correlations (FAC,216), Kar hunen-Love \\ncoefficients (KAR,64), pixel averages (PIX,240), Zernike moments (ZER,47) and morphological features (MOR,6), respectively.  \\nIn experiments, any two datasets of Multiple \\nFeatures database are picked out to construct the X and \\nY set for CCA, PLS and DCCA methods, thus there are \\ntotal \\n2\\n6C=15 pairs of different dataset combinations. \\nFor each combination, 100 pairs of feature vectors per \\nclass are randomly selected for training, the remaining \\n1000 pairs for test. The random experiment is repeated \\n10 times.  Table 4 tabulates the recognition results \\n(corresponding to FFS-I) using CCA, PLS and DCCA. We can find that in most cases, DCCA outperforms \\nCCA and PLS in terms of the recognition accuracy. As \\nto the recognition results corresponding to FFS-II, \\nthings are similar and omitted. \\nTable 4. The recognition accuracies (using FFS-I) \\non Multiple Features database \\nX Y Recognition accuracy \\nDCCA CCA PLS \\nFAC FOU 0.9813 0.8785 0.9394 \\nFAC KAR 0.9789 0.9598 0.9397 \\nFAC MOR 0.9302 0.7656 0.8789 \\nFAC PIX 0.9752 0.9476 0.9396 \\nFAC ZER 0.9772 0.8623 0.9570 \\nFOU KAR 0.9687 0.9195 0.9698 \\nFOU MOR 0.8278 0.7633 0.4389 \\nFOU PIX 0.9662 0.8431 0.9756 \\nFOU ZER 0.8543 0.8351 0.8119', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 68: ('ms of the recognition accuracy. As \\nto the recognition results corresponding to FFS-II, \\nthings are similar and omitted. \\nTable 4. The recognition accuracies (using FFS-I) \\non Multiple Features database \\nX Y Recognition accuracy \\nDCCA CCA PLS \\nFAC FOU 0.9813 0.8785 0.9394 \\nFAC KAR 0.9789 0.9598 0.9397 \\nFAC MOR 0.9302 0.7656 0.8789 \\nFAC PIX 0.9752 0.9476 0.9396 \\nFAC ZER 0.9772 0.8623 0.9570 \\nFOU KAR 0.9687 0.9195 0.9698 \\nFOU MOR 0.8278 0.7633 0.4389 \\nFOU PIX 0.9662 0.8431 0.9756 \\nFOU ZER 0.8543 0.8351 0.8119 \\nKAR MOR 0.9253 0.8158 0.6234 \\nKAR PIX 0.9497 0.9641 0.9753 \\nKAR ZER 0.9638 0.9211 0.8289 \\nMOR PIX 0.9100 0.7602 0.7078 \\nMOR ZER 0.8097 0.7452 0.7154 \\nPIX ZER 0.9544 0.8398 0.8401 \\n \\nThe proposed DCCA stems from the framework of \\nthe combined feature extraction using CCA, and it outperforms the latter in terms of the recognition \\naccuracy. Let us analyze their difference that could \\nbenefit to the recognition. For CCA, the features to be \\nfused is pairwise  T\\nxiwx and T\\nyiwy ,  and the correlation \\nbetween these two random variate  can be written as \\ncorr( , )TT\\nxi yi i λ= wx wy [5], if the correlation between \\nthem is too high (even be perfect correlation, i.e., \\n1λ=, in the extreme case), it makes no sense to fuse \\nthem that contain too much redundant information. For \\nDCCA, what the correlation corr( , )TT\\nxi yiwx wy  will \\nbe? To compare the correlation of DCCA with that of \\nCCA, we numerically compute them in this experiment. \\nFor instance, in the first combination, FAC and FOU, \\nthe correlation between the pairwise features are computed and illustrated in Fig. 2. Note that in this case, there are total 76 pairs of features for CCA, and \\nonly 9 pairs for DCCA, respectively. Fig.2 shows that \\nthe correlation between the ith, i=1,…,9, pair of \\nfeatures of DCCA is less than the correlation between the ith, i=1,…,9, pair of features of CCA. However, the \\nrecognition performance of DCCA is better than that of \\n1047\\n1047\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 69: (' the pairwise features are computed and illustrated in Fig. 2. Note that in this case, there are total 76 pairs of features for CCA, and \\nonly 9 pairs for DCCA, respectively. Fig.2 shows that \\nthe correlation between the ith, i=1,…,9, pair of \\nfeatures of DCCA is less than the correlation between the ith, i=1,…,9, pair of features of CCA. However, the \\nrecognition performance of DCCA is better than that of \\n1047\\n1047\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. \\nCCA. In other words, the features extracted by DCCA \\nare more discriminative than those extracted by CCA.  \\n \\nFig.2 The correlation between the pairwise \\nfeatures in DCCA and CCA. The horizontal and \\nthe vertical coordinates denote the serial number \\nof the pairwise features and the correlation, \\nrespectively. \\n \\n5. Conclusion and discussion \\n \\nAs an effective method of combined feature \\nextraction, CCA can extract features between two sets of samples, and the features can be fused for the \\nsubsequent recognition. The related study verified the \\nusefulness of CCA for recognition. However, the class information of the samples is not exploited by CCA, resulting in the limitation of the recognition \\nperformance. In this paper, we incorporate the class \\ninformation into the framework of combined feature extraction and propose discriminative CCA (DCCA). The experimental results of the text categorization, \\nface recognition and handwritten digit recognition \\nshow that DCCA outperform some related methods of both unimodal recognition and multimodal recognition. In addition, DCCA is a linear feature extraction \\nmethod. Although the related work [15] show that if it \\nis \\nkernelized using so-called kernel trick , better \\nrecognition performance can be achieved, yet the choice of the kernel and kernel parameter(s) are still \\ntroublesome, resulting in heavy computational tasks. In \\ncontrast, DCCA can be easily computed and applied to multimodal recognition problem. The next', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 70: ('at DCCA outperform some related methods of both unimodal recognition and multimodal recognition. In addition, DCCA is a linear feature extraction \\nmethod. Although the related work [15] show that if it \\nis \\nkernelized using so-called kernel trick , better \\nrecognition performance can be achieved, yet the choice of the kernel and kernel parameter(s) are still \\ntroublesome, resulting in heavy computational tasks. In \\ncontrast, DCCA can be easily computed and applied to multimodal recognition problem. The next step of our aim is to generalize this method to the cases of more \\nmodalities.  \\n \\nAcknowledgement \\n This works is supported by National Natural \\nScience Foundation of China (No.60775009 & \\n60803049), National Postdoctoral Science Foundation of China (No.20070411056) and Postdoctoral \\nSustentation Fund of Jiangsu Province (No. 0701016B).  \\n \\nReferences \\n \\n[1] A. Ross, A. K. Jain. Multimodal biometrics: an overview. \\nIn: Proc. of 12th European Signal Processing Conference  \\n, Vienna, 2004, pp. 1221-1224. \\n[2] M.Sargin, E. Erzin, Y. Yemez, et al. Multimodal speaker \\nidentification using canonical correlation analysis. IEEE \\nInternational Conference on Acoustics, Speech and Signal Processing , 2006, 1:I-613 - I-616. \\n[3] H. Pan. A Bayesian fusion approach and its application to \\nintegrating audio and visual signals in HCI. [ph.D. Dissertations], University of Illinois at Urbana-\\nChampaign, 2001. \\n[4] Hao Pan, Z-P. Liang, Thomas S. Huang. Estimation of \\nthe joint probability of multisensory signals. Pattern \\nRecognition Letters , 2001, 22(13):1431-1437. \\n[5] Q. Sun, S. Zeng, et al. A new method of feature fusion \\nand its application in image recognition. Pattern \\nRecognition , 2005, 38(12): 2437-2448.  \\n[6] H. Hotelling, Relations between two sets of variates. \\nBiometrika , 1936, 28:321–377. \\n[7] D.R. Hardoon, S. Szedmak, J. Shawe-Taylor. Canonical \\ncorrelation analysis: an overview with application to \\nlearning methods. Neural Computation  2004, 16: 2639-\\n2664. \\n[8] T. Melzer, M. Reiter, H. Bischof, Appearance mo', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 71: ('ognition Letters , 2001, 22(13):1431-1437. \\n[5] Q. Sun, S. Zeng, et al. A new method of feature fusion \\nand its application in image recognition. Pattern \\nRecognition , 2005, 38(12): 2437-2448.  \\n[6] H. Hotelling, Relations between two sets of variates. \\nBiometrika , 1936, 28:321–377. \\n[7] D.R. Hardoon, S. Szedmak, J. Shawe-Taylor. Canonical \\ncorrelation analysis: an overview with application to \\nlearning methods. Neural Computation  2004, 16: 2639-\\n2664. \\n[8] T. Melzer, M. Reiter, H. Bischof, Appearance models \\nbased on kernel canonical correlation analysis, Pattern \\nRecognition , 2003, 36(9):1961–1971. \\n[9] J. Wegelin. A survey of partial least squares (PLS) \\nmethods, with emphasis on the two-block case. Technical \\nReport  No.371, Dept. of Statistics, University of \\nWashing, 2000. \\n[10] F. Sebastiani. Machine learning in automated text \\ncategorization. ACM Computing Surveys , 2002, 34:1-47. \\n[11] J. Rennie. Improving multi-class text classification with \\nnaive Bayes. [Master thesis],  Massachusetts Institute of \\nTechnology, 2001. \\n[12] B. Dasarathy. Nearest neighbor (NN) norms: NN pattern \\nclassification techniques. Las Alamitos, California, IEEE Computer Society Press, 1990. \\n[13] M. Turk, A. Pentland. Eigenfaces for recognition. \\nJournal of Cognitive Neuroscience , 1991, 3(1): 71-86. \\n[14] P. N. Belhumeour, J. P. Hespanha, D. J. Kriegman.  \\nEigenfaces vs. Fisherfaces: recognition using class specific linear projection. IEEE Transactions on Pattern \\nAnalysis and Machine Intelligence , 1997, 19(7):711-720. \\n[15] T. Sun, S. Chen, et al, Kernelized Discriminative \\nCanonical Correlation Analysis, International Conf. \\nWavelet Analysis and Pattern Recognition , Nov.2-4, \\n2007, Beijing. vol.3, pp.1283-1287. \\n \\n1048\\n1048\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:01:45 UTC from IEEE Xplore.  Restrictions apply. ', 'A_Novel_Method_of_Combined_Feature_Extraction_for_Recognition.pdf'), 72: ('A NOVEL METHOD FOR DETECTING CROPPED AND RECOMPRESSED IMAGE BLOCK\\nWeiqi Luo†, Zhenhua Qu†, Jiwu Huang†∗, Guoping Qiu‡\\n†Guangdong Key Lab. of Information Security Technology\\nSun Yat-Sen University, Guangdong, China, 510275\\n‡School of Computer Science, University of Nottingham, NG 8, 1BB, UK\\nABSTRACT\\nOne of the most common practices in image tampering in-\\nvolves cropping a patch from a source and pasting it onto atarget. In this paper, we present a novel method for the detec-tion of such tampering operations in JPEG images. The lossy\\nJPEG compression introduces inherent blocking artifacts into\\nthe image and our method exploits such artifacts to serve as\\na ‘watermark’for the detection of image tampering. We de-\\nvelop the blocking artifact characteristics matrix (BACM) andshow that, for the original JPEG images, the BACM exhibits\\nregular symmetrical shape; for images that are cropped from\\nanother JPEG image and re-saved as JPEG images, the regu-\\nlar symmetrical property of the BACM is destroyed. We fullyexploit this property of the BACM and derive representation\\nfeatures from the BACM to train a support vector machine\\n(SVM) classiﬁer for recognizing whether an image is an orig-\\ninal JPEG image or it has been cropped from another JPEG\\nimage and re-saved as a JPEG image. We present experimentresults to show the efﬁcacy of our method.\\nIndex T erms —Digital Forensic, Blocking Artifacts, Block\\nArtifact Characteristics Matrix\\n1. INTRODUCTION\\nWith the advancement in image processing, tampering digi-\\ntal images without leaving obvious traces has become easierand easier. The problem of digital image counterfeiting ispotentially very serious. It will get worse as counterfeitingtechniques get more and more sophisticated. Authenticationof digital images presents many challenges.\\nDigital watermarking has been proposed as a means to\\nauthenticate the contents of digital images. The watermark-based methods, however, must insert the watermark when cre-ating the digital images, which would limit their applications.Furthermore, the sec', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 73: ('ving obvious traces has become easierand easier. The problem of digital image counterfeiting ispotentially very serious. It will get worse as counterfeitingtechniques get more and more sophisticated. Authenticationof digital images presents many challenges.\\nDigital watermarking has been proposed as a means to\\nauthenticate the contents of digital images. The watermark-based methods, however, must insert the watermark when cre-ating the digital images, which would limit their applications.Furthermore, the security of watermark in terms of resisting\\nhostile attacks needs to be strengthened.\\nRecently, several researchers have started to develop tech-\\nniques for detecting various forms of digital image forgery\\nThis work was supported by NSFC (60325208, 90604008, 60633030), 973\\nProgram (2006CB303104), NSF of Guangdong (04205407).\\n*Contact Author (isshjw@mail.sysu.edu.cn)without using watermark. Fridrich et al presented methods\\nfor camera identiﬁcation based on detecting the pattern noise\\nof the sensor in the digital cameras [1], and the identiﬁcation\\nof double JPEG compressed images [2]. Swaminathan et al\\nproposed some methods for non-intrusive component foren-\\nsics [3, 4]. Farid and Popescu developed several statisticalmethods for detecting forgeries based on color ﬁlter inter-\\npolation [5], and re-sampling[6]. Ng and Chang proposed\\na model of image spicing for detecting photomontage [7],\\nphysics-based models for distinguishing computer graphics\\nfrom nature photographs [8] and so on.\\nJPEG is a commonly used compression standard and has\\nbeen widely used in the Internet and other applications. De-tection of forgery in JPEG images can play an important rolein countering image forgery. In [2], Lukas and Fridrich pre-sented a method for the estimation of primary quantization\\nmatrix from a double compressed JPEG image. In [9], Popescu\\nproposed a method for detecting and quantifying double com-pressed images. However the methods proposed in [2] and[9] can not determine whether a given JPEG image had beencropped and recompres', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 74: ('ion standard and has\\nbeen widely used in the Internet and other applications. De-tection of forgery in JPEG images can play an important rolein countering image forgery. In [2], Lukas and Fridrich pre-sented a method for the estimation of primary quantization\\nmatrix from a double compressed JPEG image. In [9], Popescu\\nproposed a method for detecting and quantifying double com-pressed images. However the methods proposed in [2] and[9] can not determine whether a given JPEG image had beencropped and recompressed which always occurs in a compos-\\nite or region-duplication image. So far, we are not aware of\\nany research work that addresses this issue.\\nThe organization of the paper is as follows. Section 2\\nwe describes the tampering process we attempt to address.\\nSection 3 presents the blocking artifact characteristics ma-\\ntrix (BACM), and 14 representation features derived from theBACM. Experimental results are shown in section 4 and con-\\ncluding remarks are presented in section 5.\\n2. MODEL OF TAMPERING IN JPEG IMAGES\\nOne of the most common types of digital image tampering is\\ncompositing in which two or more images are spliced together\\nto create a composite image, as illustrated in Fig.1.\\nImage1(X ,Y ) 11(X ,Y ) 22 (X ,Y ) 22Image2 composite imageCopy to\\nFig. 1 . Composite imageII\\xa0\\xad\\xa0217 1\\xad4244\\xad0728\\xad1/07/$20.00\\xa0©2007\\xa0IEEE ICASSP\\xa02007\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:02:30 UTC from IEEE Xplore.  Restrictions apply. \\nWith reference to Fig. 1, we assume that the ﬁrst im-\\nageImage 1and the composite image are JPEG images with\\nthe quantization factors QF 1and QF 2respectively. (x1,y1),\\n(x2,y2)are the coordinates in the tampered region before/after\\ntampering respectively, where x1−x2≡m1(mod 8),y1−\\ny2≡m2(mod 8). In our method, we assume that m1and m2\\nare not 0 or 4 at the same time.This is a very reasonable as-\\nsumption: assuming that m1,m 2are uniform distribution in\\n[0,7], then we have p((m1=0 & m2=0 ) ,(m1=4 & m2=\\n4)) =2\\n82=3.125%\\nThe tampered region in the composit', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 75: ('ﬁrst im-\\nageImage 1and the composite image are JPEG images with\\nthe quantization factors QF 1and QF 2respectively. (x1,y1),\\n(x2,y2)are the coordinates in the tampered region before/after\\ntampering respectively, where x1−x2≡m1(mod 8),y1−\\ny2≡m2(mod 8). In our method, we assume that m1and m2\\nare not 0 or 4 at the same time.This is a very reasonable as-\\nsumption: assuming that m1,m 2are uniform distribution in\\n[0,7], then we have p((m1=0 & m2=0 ) ,(m1=4 & m2=\\n4)) =2\\n82=3.125%\\nThe tampered region in the composite image had been\\ncropped and JPEG-recompressed, as shown in Fig.2.\\nJPEG\\nCompressionCrop\\nJPEG JPEG\\nFig. 2 . Cropped and recompressed\\nThe solution for detecting the composite region is then\\nconverted to that of identifying whether it contains a cropped\\nand recompressed block in the image.\\nIn this paper, we focus on the problem: given a JPEG im-\\nage block, identify whether it has been cropped from anotherJPEG image and recompressed by JPEG compression.\\n3. PROPOSED METHOD\\nOur proposed method ﬁrst analyses the process in JPEG com-\\npression, and then derives the blocking artifact characteristicsmatrix (BACM) to measure the symmetrical property of theblocking artifacts introduced by JPEG encoder, and ﬁnally,we train a SVM classiﬁer using feature vectors derived fromthe BACMs before/after cropped-recompressed operations.\\n3.1. Detection of Blocking Effects\\nIn the JPEG encoder, the image is ﬁrst divided into small 8×\\n8non-overlapping blocks. Each block is DCT-transformed,\\nquantized and then entropy encoded to yields a data stream.\\nOne of simple and effective ideas for detection of JPEG\\nblock artifacts have been proposed in [10]. In [10], it assumesthat if there is no compression the pixel differences acrossblocks should be similar to those within blocks.\\nAB\\nCD\\nEF\\nGH\\nJPEG\\nFig. 3 . Blocking artifacts detectionIf the image is JPEG-compressed, the differences across\\nblocks should be different due to block artifacts. As shownin Fig. 3, assume the block grid is known. We then calculatethe differences within a block and spannin', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 76: ('data stream.\\nOne of simple and effective ideas for detection of JPEG\\nblock artifacts have been proposed in [10]. In [10], it assumesthat if there is no compression the pixel differences acrossblocks should be similar to those within blocks.\\nAB\\nCD\\nEF\\nGH\\nJPEG\\nFig. 3 . Blocking artifacts detectionIf the image is JPEG-compressed, the differences across\\nblocks should be different due to block artifacts. As shownin Fig. 3, assume the block grid is known. We then calculatethe differences within a block and spanning across a blockboundary. For each block, we compute\\nZ\\n/prime\\n(x,y)=|A+D−B−C|,Z/prime/prime\\n(x,y)=|E+H−F−G|(1)\\nwhere A ∼H are the values of the pixels in the position, and\\nthe (x, y )is the coordinate of A in each block. The coordi-\\nnates of A to H in each block change according to the coordi-nate of A, as shown in Fig.4 (a) (b) and (c). For example, thecoordinate of E: P(E)= P(A)+( 4 ,4).\\nIn Fig.4, we ﬁrstly compute the histograms H\\nI,HIIof\\nZ/prime\\n(x,y)and Z/prime/prime\\n(x,y)with (x, y )=( 4 ,4),(2,4)and (3,3)re-\\nspectively. Then the energy Kof the difference between HI\\nand HIIwith the value nis calculated as follows.\\nK(x,y)(n)=|HI(n)−HII(n)| (2)\\nWhere n∈[0,255×2],HI(n),H II(n)are the total num-\\nber in the Z/primeand Z/prime/primerespectively with the lever n. Fig.4(d)\\nshows the K(x,y)with different coordinates of A. We can\\nobserve that the differences are larger across a JPEG blockboundary e.g. Fig.4(a) and (b). The biggest differences al-ways occur when P(A)=( 4 ,4), and when ( x=4 )o r\\n(y=4 ) the difference is also large. When the coordinates\\nof A to D and E to H are all inside a block respectively, thenthe difference is small.\\nAB\\nCD\\nEF\\nGH\\n(a)(x, y )=( 4 ,4)AB\\nCD\\nEF\\nGH\\n(b)(x, y )=( 2 ,4)AB\\nCD\\nEF\\nGH\\n(c)(x, y )=( 3 ,3)\\n0 10 20 30 40 5001002003004005006007008009001000The histograms of K(x,y) with different coordinate (x,y)\\n(x,y)=(4,4)\\n(x,y)=(2,4)\\n(x,y)=(3,3)\\nLena with QF=85\\n(d) Three histograms of K(x,y)\\nFig. 4 . Comparing the K(x,y)with the different coordinates\\nof A in the Lena Image with QF 85II\\xa0\\xad\\xa0218\\nAuth', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 77: ('nce is also large. When the coordinates\\nof A to D and E to H are all inside a block respectively, thenthe difference is small.\\nAB\\nCD\\nEF\\nGH\\n(a)(x, y )=( 4 ,4)AB\\nCD\\nEF\\nGH\\n(b)(x, y )=( 2 ,4)AB\\nCD\\nEF\\nGH\\n(c)(x, y )=( 3 ,3)\\n0 10 20 30 40 5001002003004005006007008009001000The histograms of K(x,y) with different coordinate (x,y)\\n(x,y)=(4,4)\\n(x,y)=(2,4)\\n(x,y)=(3,3)\\nLena with QF=85\\n(d) Three histograms of K(x,y)\\nFig. 4 . Comparing the K(x,y)with the different coordinates\\nof A in the Lena Image with QF 85II\\xa0\\xad\\xa0218\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:02:30 UTC from IEEE Xplore.  Restrictions apply. \\n3.2. Symmetry from Blocking Artifacts\\nWe ﬁrst divide an image into non-overlapping 8×8blocks.\\nFor each block, we compute Z/prime\\n(x,y)and Z/prime/prime\\n(x,y)using Eq. (1).\\nThen we compute the difference between the histograms viaEq.(2) and get the average of K\\n(x,y), denoted as M(x, y )=PK(x,y )(n)\\n255×2+1, for each 1≤x, y≤8. Lastly normalize the\\naverage matrix M(x, y ). The matrix M(x, y )is called the\\nblocking artifact characteristics matrix (BACM).\\n(a) LenaUncompressed Lena\\n1 2 3 4 5 6 7 812345678\\n(b) Uncompression\\nCompressed Lena(QF=85)\\n1 2 3 4 5 6 7 812345678\\n(c) QF =8 5Cropped and Recompressed Lena\\n1 2 3 4 5 6 7 812345678\\n(d) Cropped and recompressed\\nFig. 5 . Comparing the contour of M(x, y )in uncompressed\\nLena (b), original JPEG image with quality factor 85 (c), orig-inal JPEG image with QF\\n1=5 0 had been cropped 2 rows\\nand 3 columns and recompressed with QF 2=8 5 (d).\\nFig. 5 shows the contour of M(x, y )for uncompressed,\\nJPEG compressed, and cropped and JPEG recompressed Lenaimages. From the ﬁgures above, we observe that the valuesofM(x, y )in uncompressed image are random. While in the\\noriginal JPEG image the values of M(x, y )become regular.\\nThe max value occurs in M(4,4)and the values in the 4th row\\nand column are bigger. There are four ﬂat regions around thecenter M(4,4)as shown in (c). Fig5.(d) shows the contour of\\nM(x, y )in the cropped and recompressed image, t', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 78: (').\\nFig. 5 shows the contour of M(x, y )for uncompressed,\\nJPEG compressed, and cropped and JPEG recompressed Lenaimages. From the ﬁgures above, we observe that the valuesofM(x, y )in uncompressed image are random. While in the\\noriginal JPEG image the values of M(x, y )become regular.\\nThe max value occurs in M(4,4)and the values in the 4th row\\nand column are bigger. There are four ﬂat regions around thecenter M(4,4)as shown in (c). Fig5.(d) shows the contour of\\nM(x, y )in the cropped and recompressed image, the symme-\\ntry of the values of M(x, y )obviously descends comparing\\nwith that in Fig.5(c).\\nDue to the nature of the JPEG image, we can get block-\\ning artifacts, an inherent ‘semi-fragile watermark’from theblock-based compression. The ‘watermark’measured usingthe symmetry of the BACM M(x, y )would change after be-\\ning cropped and recompressed. So the key idea of our method\\nis to identify the differences between the BACMs as shown in\\n(c) and (d) of Fig.5 .3.3. Feature Vector from BACM\\n*\\n1 4 781478\\nR2 R3\\nR1 R4\\nVH C\\nFig. 6 . the Symmetry of BACM\\nAs shown in Fig 6, we ﬁrst crop 7×7block from the ma-\\ntrixM(x, y ), and then divide the block into 7 non-overlapping\\nparts: region R1,R2,R3,R4, the horizontal direction H, ver-\\ntical direction Vand the center point M(4,4).\\nR1:{M(1,1),M (1,2),M (1,3),M (2,1),M (2,2),\\nM(2,3),M (3,1).M(3,2),M (3,3)}\\nR2:{M(1,5),M (1,6),M (1,7),M (2,5),M (2,6),\\nM(2,7),M (3,5).M(3,6),M (3,7)}\\nR3:{M(5,5),M (5,6),M (5,7),M (6,5),M (6,6),\\nM(6,7),M (7,5).M(7,6),M (7,7)}\\nR4:{M(5,1),M (5,2),M (5,3),M (6,1),M (6,2),\\nM(6,3),M (7,1).M(7,2),M (7,3)}\\nH:{M(1,4),M (2,4),M (3,4),M (5,4),M (6,4),\\nM(7,4)}\\nV:{M(4,1),M (4,2),M (4,3),M (4,5),M (4,6),\\nM(4,7)}\\nC:{M(4,4)}\\nWe construct the following 14 features:\\n1) The ﬁrst 2 features describe the symmetry of H and V\\naround the center point C;\\n2)Then the symmetry of the four ﬂat region R1,R2,R3\\nand R4around H,Vand Care recorded ( C2\\n4=6 features);\\n3) Lastly the percentage of the center point Coccupying\\nthe region R1,R2,R3,R4,VandHare recorded respectively\\n(6 features).', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 79: (' (6,1),M (6,2),\\nM(6,3),M (7,1).M(7,2),M (7,3)}\\nH:{M(1,4),M (2,4),M (3,4),M (5,4),M (6,4),\\nM(7,4)}\\nV:{M(4,1),M (4,2),M (4,3),M (4,5),M (4,6),\\nM(4,7)}\\nC:{M(4,4)}\\nWe construct the following 14 features:\\n1) The ﬁrst 2 features describe the symmetry of H and V\\naround the center point C;\\n2)Then the symmetry of the four ﬂat region R1,R2,R3\\nand R4around H,Vand Care recorded ( C2\\n4=6 features);\\n3) Lastly the percentage of the center point Coccupying\\nthe region R1,R2,R3,R4,VandHare recorded respectively\\n(6 features).\\nNote that the symmetry feature is the sum of energy of\\ndifferences between the values in the matrix. For example,the symmetry of H around C is: |M(1,4)−M(7,4)|+\\n|M(2,4)−M(6,4)|+|M(3,4)−M(5,4)|, other features\\nin 1) and 2) are derived similarly. For the features in 3), e.g.\\nthe percentage of the center point Coccupying the region R\\n1\\nis deﬁned asM(4,4)\\nS, where S=/summationtextr, r∈R1.\\n4. EXPERIMENTAL RESULTS AND DISCUSSION\\nIn our experiments, we ﬁrst collect 1128 uncompressed im-\\nages. The images are taken using Panasonic Lumix DMC-FZ30 with TIFF format including outdoor and indoor sceneswith different camera setting. The maximal and minimal res-\\nolutions of the camera are 3264×2448 and 1280×960.W e\\nhave the 3 sizes ( 1600×1200 ,1280×960 and 640×480 )II\\xa0\\xad\\xa0219\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:02:30 UTC from IEEE Xplore.  Restrictions apply. \\nfrom cropping the original images for our experiments. The\\nmethod for creating experimental data is as following:\\n1) Original JPEG images. For each TIFF image, we con-\\nvert it to JPEG image with quality factor QF 2.\\n2) Tampered JPEG images. For each TIFF image, we sim-\\nulate the process as shown in Fig.2. Firstly convert it to JPEG\\nimage with a random quality factor QF 1. Then crop the im-\\nage randomly and resave it with QF 2.\\nFor a given quality factor QF 2, we obtain 2256 JPEG im-\\nages, and then divide them into two categories, one for train-\\ning(including 500 original and 500 tampered JPEG images re-spectively) an', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 80: (':\\n1) Original JPEG images. For each TIFF image, we con-\\nvert it to JPEG image with quality factor QF 2.\\n2) Tampered JPEG images. For each TIFF image, we sim-\\nulate the process as shown in Fig.2. Firstly convert it to JPEG\\nimage with a random quality factor QF 1. Then crop the im-\\nage randomly and resave it with QF 2.\\nFor a given quality factor QF 2, we obtain 2256 JPEG im-\\nages, and then divide them into two categories, one for train-\\ning(including 500 original and 500 tampered JPEG images re-spectively) and the other for testing . We calculate the BACMM(x, y )and obtain a feature vector for each JPEG image.\\nThe feature vectors are fed to SVM[11] and to train a classi-ﬁer from the training data set to distinguish the original from\\nthe tampered images. Fig. 7 and Table 1 show the experi-\\nmental results using the classiﬁer on the testing data set for\\ndifferent quality factors and sizes.\\n60 65 70 75 80 85 90 9500.10.20.30.40.50.60.70.80.91\\nQuality Factors(QF2)Accuracy640 * 480 \\n1280 * 960\\n1600 * 1200\\nFig. 7 .QF 1∈[50,95],the curves show the accuracy increase\\nwith increasing quality factor QF 2from 60 to 95 with step 5.\\nTable 1 . Detection accuracy(%).In this experiment, QF 1∈\\n[50,59],[60,69],[70,79],[80,89],QF 2is from 60 to 95 with\\nstep 5, the block are of 1280×960 pixels.\\nHHHHHQF1QF260 65 70 75 80 85 90 95\\n50-59 84.6 89.3 94.7 97.8 99.0 98.9 97.8 96.3\\n60-69 72.4 81.9 89.6 91.7 97.6 99.2 97.9 97.1\\n70-79 68.0 67.8 80.9 81.8 90.2 96.5 97.8 96.9\\n80-89 66.7 63.9 64.8 64.4 72.2 80.4 92.2 95.9\\nFrom the experimental results above, we can see that when\\nthe original JPEG image with lower quality factor had beencropped and recompressed with higher quality factor, our pro-posed method work well, which implies that the symmetry ofblocking artifacts is obvious in low quality JPEG images andchanges slightly after tampering with high quality factor.\\n5. CONCLUDING REMARKS\\nWhen creating a digital forgery, it is sometimes necessary to\\ncopy a part of an image and then move it to the same imageor another image in order to conceal or c', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 81: ('ults above, we can see that when\\nthe original JPEG image with lower quality factor had beencropped and recompressed with higher quality factor, our pro-posed method work well, which implies that the symmetry ofblocking artifacts is obvious in low quality JPEG images andchanges slightly after tampering with high quality factor.\\n5. CONCLUDING REMARKS\\nWhen creating a digital forgery, it is sometimes necessary to\\ncopy a part of an image and then move it to the same imageor another image in order to conceal or create an important\\nobject in the scene. These types of manipulations will lead toinconsistent blocking artifacts in the tampered region, whichcan therefore be used as evidence of tampering. Our contri-bution in this paper is the introduction of the blocking artifactcharacteristics matrix (BACM) which exhibits a symmetricalshape for the original JPEG images and that this symmetri-cal property will be altered by cropping and recompressionoperations. We have presented a method that exploits thisproperty of the BACM for effectively detecting cropping andrecompression operations in JPEG images.\\n6. REFERENCES\\n[1] J. Lukas, J. Fridrich, and M. Goljan, “Detecting digital\\nimage forgeries using sensor pattern noise,” Proc. of\\nSPIE,vol . 6072, pp. 60720Y ,2006.\\n[2] J. Lukas and J. Fridrich, “Estimation of primary quanti-\\nzation matrix in double compressed jpeg images,” Proc.\\nof DFRWS , Cleveland, Oh, USA, August 2003.\\n[3] A. Swaminathan, M. Wu, and K.J.R. Liu, “Compo-\\nnent forensics of digital cameras: A non-intrusive ap-proach,” Proc. of Conf. on Information Sciences and\\nSystems , Princeton, NJ, March 2006.\\n[4] A. Swaminathan, M. Wu, and K.J.R. Liu, “Non-\\nintrusive forensic analysis of visual sensors using outputimages,” Proc. of IEEE ICASSP ,Toulouse France,vol.5,\\nPP.V401-404, May 2006.\\n[5] A.C. Popescu and H. Farid, “Exposing digital forgeries\\nin color ﬁlter array interpolated images,” IEEE Trans.\\non Signal Processing , vol. 53, no. 10, pp. 3948–3959,\\n2005.\\n[6] A.C. Popescu and H. Farid, “Exposing digital forgeries\\nby ', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 82: ('p-proach,” Proc. of Conf. on Information Sciences and\\nSystems , Princeton, NJ, March 2006.\\n[4] A. Swaminathan, M. Wu, and K.J.R. Liu, “Non-\\nintrusive forensic analysis of visual sensors using outputimages,” Proc. of IEEE ICASSP ,Toulouse France,vol.5,\\nPP.V401-404, May 2006.\\n[5] A.C. Popescu and H. Farid, “Exposing digital forgeries\\nin color ﬁlter array interpolated images,” IEEE Trans.\\non Signal Processing , vol. 53, no. 10, pp. 3948–3959,\\n2005.\\n[6] A.C. Popescu and H. Farid, “Exposing digital forgeries\\nby detecting traces of re-sampling,” IEEE Trans. on Sig-\\nnal Processing , vol. 53, no. 2, pp. 758–767, 2005.\\n[7] T.T. Ng and S.F. Chang, “Blind detection of digital\\nphotomontage using higher order statistics,” ADVENTTechnical Report, Columbia University, June 2004.\\n[8] T.T. Ng, S.F. Chang, J. Hsu, L. Xie, and M.P. Tsui,\\n“Physics-motivated features for distinguishing photo-graphic images and computer graphics,” Proc. of ACM\\nMultimedia , Singapore, vol. 5, pp. 239–248, November\\n2005.\\n[9] A.C. Popescu, Statistical Tools for Digital Image F oren-\\nsics, Ph.D. thesis, Department of Computer Science,\\nDartmouth College, Hanover, NH, 2005.\\n[10] Z. Fan and R.L. de Queiroz, “Identiﬁcation of bitmap\\ncompression history: JPEG detection and quantizer es-timation,” IEEE Trans. on Image Processing , vol. 12,\\nno. 2, pp. 230–235, February 2003.\\n[11] C.W. Hsu, C.C. Chang, and C.J. Lin, “A prac-\\ntical guide to support vector classiﬁcation,”\\nhttp://www.csie.ntu.edu.tw/cjlin/papers/guide/guide.pdf.II\\xa0\\xad\\xa0220\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:02:30 UTC from IEEE Xplore.  Restrictions apply. ', 'A_Novel_Method_for_Detecting_Cropped_and_Recompressed_Image_Block.pdf'), 83: ('Hui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  277 Analysis of Practicality and Performance Evaluation  for \\nMonolithic Kernel and Micro-Kernel Operating System s \\n \\n \\nHui Miao                          hui.miao@microchip.com  \\nMicrochip Australia Design Centre \\nMicrochip Technology Inc. \\nBrisbane, 4108, Australia \\n \\nAbstract \\nThe microkernel system (as opposite to monolithic syste ms) has been developed for several \\nyears, with the hope that microkernels could solve the problems of other operating systems. \\nHowever, the evolution of the microkernel systems did  not go as many people expected. Because \\nof faultinesses of the design in system structure, t he performance of the first generation of \\nmicrokernel operating systems was disappointing. The o verhead of the system was too high to \\nbear for users. However, the second-generation microke rnel system uses an improved design \\narchitecture that could substantially reduce the overh ead in previous microkernel systems.  \\n \\nThis project evaluates the system performance of the MINIX3.1.2a and compares the results with \\nthe performance of Linux by using Unixbench system eval uating tool. By this way, it could testify \\nwhether the microkernel systems could be more flexible, portable and secure than monolithic \\noperating systems. Unixbench could give sufficient sta tistics on different capacities of MINIX3 and \\nLinux, such as system call overhead, pipe throughput, a rithmetic test and so on. The result \\nillustrates MINIX3 has better performance on Shell S cripts running and Arithmetic test and Linux \\nhas better performance on other aspects such as system call overhead, process creation and so \\non. Furthermore, we provide a more detailed analyse on the microkernel Minix 3 system and \\npropose a method that could improve the performance of  the MINIX3 system. \\n Keywords:  Monolithic System, Microkernel System, Operating System \\n \\n \\n1. INTRODUCTION  \\nKernel controls the critical parts of operating systems . Nowadays, many current oper', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 84: ('tter performance on Shell S cripts running and Arithmetic test and Linux \\nhas better performance on other aspects such as system call overhead, process creation and so \\non. Furthermore, we provide a more detailed analyse on the microkernel Minix 3 system and \\npropose a method that could improve the performance of  the MINIX3 system. \\n Keywords:  Monolithic System, Microkernel System, Operating System \\n \\n \\n1. INTRODUCTION  \\nKernel controls the critical parts of operating systems . Nowadays, many current operating \\nsystems are monolithic kernel operating systems (e.g. L inux). Monolithic kernel operating \\nsystems implement most system functionalities such as f ile management, device drivers, process \\nmanagement and I/O management in kernel mode. Althou gh monolithic kernel operating systems \\nare very popular, they may have some disadvantages.  First, the kernel is intensively complex. A \\nkernel with thousands lines of code could be hard and difficult to maintain. Updating one part of \\nthe system may result in needing to recompile the who le kernel. Second, a large amount of code \\nmeans that the operating system could not be ported t o different hardware, especially for \\nembedded systems. Third, the monolithic operating syst em is not reliable; since the kernel’s \\ncomplexity, the possibility of a system crash could be hi gh. A single tiny error in the kernel could \\nlead the whole system to crash. So microkernel operatin g systems are designed to overcome the \\ndisadvantages of the monolithic systems. \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  278 The microkernel system excludes several services out of  the kernel. One service can run as a \\nuser level application out of the kernel. For example , Mach [1] uses an external pager and the file \\nsystem can also be running out of the kernel. Minix3 i s another microkernel-based operating \\nsystem which is an earlier version of OS inspired the  invention of Linux. The kernel of the latest \\nversion of Minix3 only has 4000 lines of ', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 85: ('nternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  278 The microkernel system excludes several services out of  the kernel. One service can run as a \\nuser level application out of the kernel. For example , Mach [1] uses an external pager and the file \\nsystem can also be running out of the kernel. Minix3 i s another microkernel-based operating \\nsystem which is an earlier version of OS inspired the  invention of Linux. The kernel of the latest \\nversion of Minix3 only has 4000 lines of code [6], m uch smaller than Linux. The L4 kernel is a \\ndeveloping microkernel system; the latest version of L4 kernel is L4ka::Pistachio 0.4, which can \\nrun on a wide variety of hardware [6].  \\n \\nCompared with macrokernel systems, the microkernel appr oach has following advantages: First, \\na microkernel system can provide higher reliability th an a monolithic system. A microkernel \\nsystem has much less chance to crash than a system with a  huge kernel. Reducing the size of a \\nkernel is a strategy to reduce the problems in the syst em. Second, a microkernel system with less \\nkernel code could be maintained more easily. Recompiling  the kernel is not a huge task for \\nmicrokernel systems. Last, a microkernel system could be e asily ported to simple hardware, \\nespecially in embedded systems. \\n \\n2. RELATED WORKS AND MOTIVATIONS  \\n \\n2.1 First Generation Microkernels \\nThe first pioneering microkernel conception was in Carn egie-Mellon University, the microkernel \\nMach operating system. Mach minimizes the kernel into a very small module. The kernel of Mach \\nonly provides process management; thread management, IPC and I/O service. The file \\nmanagement, which traditionally is in the kernel, is p laced out of the kernel. Mach’s external \\npager [1] was the first conceptual breakthrough toward  real microkernel. The conceptual \\nfoundation of the external pager is that the kernel manages physical and virtual memory, yet the \\npager is outside of the kernel. As Fig. 1 shows: if a page fault occurs in user applications it will', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 86: ('o a very small module. The kernel of Mach \\nonly provides process management; thread management, IPC and I/O service. The file \\nmanagement, which traditionally is in the kernel, is p laced out of the kernel. Mach’s external \\npager [1] was the first conceptual breakthrough toward  real microkernel. The conceptual \\nfoundation of the external pager is that the kernel manages physical and virtual memory, yet the \\npager is outside of the kernel. As Fig. 1 shows: if a page fault occurs in user applications it will \\nforward the faults to the pager by message passing. T he message is handled by the kernel. This \\ntechnique permits the mapping of files and databases  into user address spaces without having to \\nintegrate the file/database systems into the kernel [1]. \\n \\nFIGURE 1:  Page Fault Processing [1] \\n \\nThe prospect of Mach seems splendid. But it was not a s ideal as people expected. The Mach \\nsystem makes the file system run as a user processes on top of the kernel and uses interprocess \\ncommunication (IPC) to control this module. IPC contrib utes a huge overhead to the whole \\noperating system. System calls of traditional operatin g systems use traps, which are much faster \\nthan IPC. Mach needs to create messages, send and switch  between processes. As Fig. 2 shows, \\nthe overhead is excessive. Chen and Bershad [2] compa red applications under Ultrix (a Unix \\nbased operating system) and Mach on a DECStation 5-2 00/200 and found peak degradations of \\nup to 66% on Mach (compared to Ultrix); 66% is really  unbearable for user. 75% of the low \\nefficiency is related to IPC. So this first generation  microkernel system failed. The Mach system \\nproject was abandoned by Carnegie-Mellon University te am in 1994. \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  279 \\n \\nFIGURE 2:  Non-idle cycles under Ultrix and Mach [1] \\n \\nIn the case of the failure of first generation, peop le put forward a compromised way of designing \\nthe microkernel system. The main idea is to expand the  kernel, put the', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 87: ('r user. 75% of the low \\nefficiency is related to IPC. So this first generation  microkernel system failed. The Mach system \\nproject was abandoned by Carnegie-Mellon University te am in 1994. \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  279 \\n \\nFIGURE 2:  Non-idle cycles under Ultrix and Mach [1] \\n \\nIn the case of the failure of first generation, peop le put forward a compromised way of designing \\nthe microkernel system. The main idea is to expand the  kernel, put the some file services and \\ndevice drivers back into the kernel again. In this way, they could reduce the switch time between \\nthe user space and kernel. The Chorus operating system  [1] uses this design idea. However, the \\nidea of expanding the kernel impairs the original in tention of building a small high integrity \\nmicrokernel. It reduces the extensibility, flexibility, portability and reliability of the operating system. \\nSo L4ka appeared. \\n \\n2.2 Second Generation Microkernels \\nAfter the failure of the Mach operating system, scient ists began to redesign the structure of the \\nkernel. Prof Dr. Jochen Liedtke invented his first micro kernel with low overhead in passing \\nmessages, L3. The L3 kernel directly passes the mess age between processes leaving the \\nprocess security and authentication to user space servers . This design method greatly reduced \\nmassive IPC overhead which occured in Mach system. On the  same system where Mach \\nrequired 114 microseconds for even the smallest of m essages, L3 could send the same message \\nfor less than 10. The overall time for a system call was less than half the time on Unix, as \\nopposed to Mach where the same system call took five ti mes longer that of Unix [3]. \\n \\nAfter successfully implementing L3, Liedtke designed L 3 more comprehensively. The result was a \\nmore flexible kernel, L4. A basic idea of L4 is to su pport recursive construction of address spaces \\nby user-level servers outside the kernel. The kernel o nly does three address space operations: \\nGrant, Mapping and', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 88: ('e same message \\nfor less than 10. The overall time for a system call was less than half the time on Unix, as \\nopposed to Mach where the same system call took five ti mes longer that of Unix [3]. \\n \\nAfter successfully implementing L3, Liedtke designed L 3 more comprehensively. The result was a \\nmore flexible kernel, L4. A basic idea of L4 is to su pport recursive construction of address spaces \\nby user-level servers outside the kernel. The kernel o nly does three address space operations: \\nGrant, Mapping and Unmapping. Liedtke’s design was a s follows [3]: the owner of an address \\nspace can assign any of its pages to another space, prov ided that the recipient agrees. Similarly, \\nthe owner of an address space can map any of its page s into another address space, provided \\nthe recipient agrees. The owner of an address space c an also flush any of its pages. The flushed \\npage remains accessible in the flusher’s address space, but is removed from all other address \\nspaces which had received the page directly or indirectl y from the flusher.  \\n \\nThe Mach microkernel had a limitation of implementing the external pager policy outside the \\nkernel. And now, this limitation is largely removed by L4’s address space concept. This \\nmechanism implements some protection schemes and physica l memory management on the top \\nof the kernel. Grant and map operations need IPC, si nce they require an agreement between \\ngranter/mapper and recipient of the mapping. So cro ss-address-space communication, also \\ncalled inter-process communication (IPC), must be suppor ted by the microkernel, which gives \\nextra overhead to Mach system. L4 uses many methods a nd techniques to reduce the IPC \\noverhead. Liedtke improved the performance of the syst em and reduced the overhead of IPC by \\nredesigning the kernel. The result is positive. One RPC cost L4 only 10µs, in contrast to 230µs in \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  280 Mach and 20µs in Unix. IPC is not a burden to L4 any more. Tests of a Lin', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 89: ('nication (IPC), must be suppor ted by the microkernel, which gives \\nextra overhead to Mach system. L4 uses many methods a nd techniques to reduce the IPC \\noverhead. Liedtke improved the performance of the syst em and reduced the overhead of IPC by \\nredesigning the kernel. The result is positive. One RPC cost L4 only 10µs, in contrast to 230µs in \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  280 Mach and 20µs in Unix. IPC is not a burden to L4 any more. Tests of a Linux kernel ported to run \\non top of L4 and another ported to run on Mach (MkLin ux) and the basic Linux system itself \\nshowed clear performance gains with L4. Even in the b est case MkLinux was 15% slower than \\nthe monolithic kernel, whereas L4 was about 5-10% slo wer [16]. \\n \\nMinix3 is another second generation microkernel system which is developed by Andrew \\nTanenbaum. Minix3 was redesigned to be a pure microke rnel system from its early version \\nMinix2. Like other microkernel systems, device drivers, process manager, file system and \\nmemory manager are all implemented outside the kernel . Recently, there is another radical idea \\nof designing a kernel. In the exokernel concept [7], th e operating system only provides \\nmanipulating the raw hardware. The kernel only takes charge of securing the hardware and \\ncontrols it. The application-level libraries and serv ers can directly implement traditional operating \\nsystem abstractions. There are already some exokernel o perating systems in experimental stage, \\nsuch as XOK that is implemented by MIT research group and also Nemesis, written by University \\nof Cambridge, University of Glasgow, Citrix Systems, and the Swedish Institute of Computer \\nScience. \\n \\n2.3 Motivation and Project Aims \\nThe Mach operating system is considered to have poor p erformance by many people, because of \\nthe overheads in IPC. There are many kinds of other microkernel systems that are claimed to \\nboast better performance such as L4ka and Minix3. The project’s topic is to use several user \\napp', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 90: (' as XOK that is implemented by MIT research group and also Nemesis, written by University \\nof Cambridge, University of Glasgow, Citrix Systems, and the Swedish Institute of Computer \\nScience. \\n \\n2.3 Motivation and Project Aims \\nThe Mach operating system is considered to have poor p erformance by many people, because of \\nthe overheads in IPC. There are many kinds of other microkernel systems that are claimed to \\nboast better performance such as L4ka and Minix3. The project’s topic is to use several user \\napplication tools such as Unixbench which run on differ ent operating systems to evaluate their \\nperformance and to discuss the practicality of new genera tion microkernel operating systems. \\nThe project also uses monolithic operating systems for  comparison, because most current \\noperating systems are based on monolithic kernel. Lin ux is a typical monolithic operating system \\nwe can use. Comparing the test results of microkernel- based systems to the test results of Linux \\ncould be a good source of discussing the practicality of m icrokernel operating system. \\n \\nThe comparison has been done by using the benchmark to ol Unixbench. Minix3, a pure \\nmicrokernel operating systems has been used for testin g. Minix3 is a developing microkernel \\nsystem, which could be a good option, and also Minix3 s upports POSIX [6]. It is well developed \\nand it can be installed easily. Minix3 has C compiler and Shell like Unix. Therefore, it is easier to \\nimplement and run application test programs on Minix 3 than implementing test programs on L4. \\nFurthermore Minix3 is written by C and Minix3 is a c learly structured microkernel system, so we \\ncould clearly know how microkernel system works after rea ding the source code of Minix3. \\n \\nThis research is designed to compare and evaluate the  performance of two different operating \\nsystems by using OS benchmark tool Unixbench. There are many benchmarks Unixbench can \\nprovide, such as system call overheads, context switch o verhead, file read/write throughput, pipe \\nthroughput, arithmeti', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 91: (' programs on L4. \\nFurthermore Minix3 is written by C and Minix3 is a c learly structured microkernel system, so we \\ncould clearly know how microkernel system works after rea ding the source code of Minix3. \\n \\nThis research is designed to compare and evaluate the  performance of two different operating \\nsystems by using OS benchmark tool Unixbench. There are many benchmarks Unixbench can \\nprovide, such as system call overheads, context switch o verhead, file read/write throughput, pipe \\nthroughput, arithmetic performance and so on. Even mo re accurate evaluations were done by \\nwriting test programs which could test single IPC tim e or single system call time. We could \\nanalyze the result and discuss the practicality of microke rnel from the evaluation results. \\n \\nLinux and Minix3 were used in the testing. Minix3 is  a mature microkernel based operating \\nsystem. It is well structured and could easily be inst alled. Also Minix3 supports POSIX. It is Unix-\\nlike operating system. Linux is currently one of the m ost popular monolithic operating systems; it \\nis open source and also supports POSIX. Linux is used widely in many fields. So Linux is a good \\noption for testing. L4Linux is an operating system wh ich runs with the L4 microkernel on the \\nbottom level, and with Unix-like application runs on t op of L4Linux. The reason not to use L4Linux \\nis there are few research documents available for L4L inux. It is hard to get started and installed. \\nBesides that, because the Linux kernel is in the midd le between application level and L4 \\nmicrokernel in L4Linux architecture, the result may not  be accurate. The user application program \\nis not implemented directly on L4 microkernel. So accur ate results required implementing Unix-\\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  281 like user application level directly on the L4 microkerne l. It is required to work at all levels of \\nabstraction from the bare machine to the application l ayer, which is a big challenge for \\nresearchers. Al', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 92: ('ion level and L4 \\nmicrokernel in L4Linux architecture, the result may not  be accurate. The user application program \\nis not implemented directly on L4 microkernel. So accur ate results required implementing Unix-\\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  281 like user application level directly on the L4 microkerne l. It is required to work at all levels of \\nabstraction from the bare machine to the application l ayer, which is a big challenge for \\nresearchers. Also, the exokernel is now in the experi mental stage, and there are not sufficient \\ndocuments and resources on the exokernel, and therefor e the exokernel is not included in testing. \\n \\nSecond generation microkernels like L4ka had proved tha t the microkernel system could perform \\nas well as monolithic kernel system. L4Linux on AIM b enchmarks report a maximum throughput \\nwhich is only 5% lower than that of native Linux. How ever, it is hard to compare pure L4 system \\nwith Linux, because it is difficult to implement user level application on L4 kernel. For native Linux, \\nAIM measures a maximum load of 130 jobs per minute. L4Linux achieves 123 jobs per minute, \\n95% of native Linux. The corresponding numbers for us er-mode L4Linux are 81 jobs per minute, \\n62% of native Linux, and 95 (73%) for the inkernel v ersion. Averaged over all loads, L4Linux is \\n8.3% slower than native Linux, and 6.8% slower at th e maximum load. This is consistent with the \\n6-7% we measured for recompiling Linux [4]. L4 is de signed for optimizing the IPC overhead and \\ncontext switch between processes, so the user level appl ication implementation is poor. The \\nperformance of operating system is not only the kernel performance, but also the application layer \\nperformance, which is directly to users. So evaluate the performance of a relatively mature \\nmicrokernel system is meaningful to microkernel system. \\n \\nThe project designed does not only to make evaluation benchmarks for microkernel system, but \\nalso would like to analyze the benchmark', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 93: ('ptimizing the IPC overhead and \\ncontext switch between processes, so the user level appl ication implementation is poor. The \\nperformance of operating system is not only the kernel performance, but also the application layer \\nperformance, which is directly to users. So evaluate the performance of a relatively mature \\nmicrokernel system is meaningful to microkernel system. \\n \\nThe project designed does not only to make evaluation benchmarks for microkernel system, but \\nalso would like to analyze the benchmarks of microkernel system and compare it to monolithic \\nkernel systems. By that, we would like to outline a mu ch clearer performance figure of \\nmicrokernel system such as Minix3. From previous papers , IPC overhead was complained most \\nin microkernel system, which was seen a biggest flaw af fecting microkernel system performance. \\nHowever, we believe not all the performance differen ces in microkernel system are due to the \\nheavy IPC overhead. There are many different ways in i mplementing kernel and user layer \\nbetween Minix3 and Linux, therefore it is important to find out which part of benchmark \\ndifferences are due to the different system implement ation. From analyzing the benchmarks, we \\ntry to separate performance results that are caused by different system implementation from the \\nresults that are inherited due to the heavy IPC over head. The discuss on performance evaluating \\nresults are meaningful, because it makes a scrutiny fig ure on Minix3 microkernel performance \\nand could give advices that which part of system could b e improved by tuning the microkernel \\nsystem. \\n \\n3. Evaluation Environment and Equipments  \\n \\n3.1 Hardware Environment \\nThe result of the test has to be accurate and correct. The selection of hardware is important. The \\nentire test has to work on the same hardware, thus t he hardware selected must be a common \\none which is supported by all the system kernels (Minix 3, Linux). Minix3 supports many kinds of \\nhardware: 386, 486 and Pentium and so on. To instal l Minix3 requires: Intel ', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 94: ('h part of system could b e improved by tuning the microkernel \\nsystem. \\n \\n3. Evaluation Environment and Equipments  \\n \\n3.1 Hardware Environment \\nThe result of the test has to be accurate and correct. The selection of hardware is important. The \\nentire test has to work on the same hardware, thus t he hardware selected must be a common \\none which is supported by all the system kernels (Minix 3, Linux). Minix3 supports many kinds of \\nhardware: 386, 486 and Pentium and so on. To instal l Minix3 requires: Intel 386 or higher with 4 \\nMB of RAM, an IDE hard disk with 100 MB of free disk space and an IDE CD-ROM for booting [5]. \\nLinux also could support IA32 (Pentium). So a computer  with Pentium or higher is a good choice. \\nThe RAM has to be 256MB or higher. PC must have IDE  CD-ROM, VESA compatible VGA, PS/2 \\nkeyboard and PS/2 Mouse.  \\n \\nThe configurations of the hardware machines are liste d as the following: \\nCentral Process: Pentium \\x01 with 800MHz speed; \\nRandom Access Memory: 256MB RAM; \\nHard Disk: IBM DTLA-307020 20GB ATA hard disk; \\nCD-ROM: 24X IDE CD-ROM \\nAccessories: VESA compatible VGA, PS/2 keyboard and PS/2 Mo use \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  282 3.2 Minix3 Environment \\nThe version of Minix3 used for evaluating is 3.1.2a , which is claimed to be a stable version of the \\nMinix3 operating system [9]. To install, download th e compressed CD image of Minix3.1.2a from \\nofficial server in Minix3 home website, then decompre ss CD image and burn it into a writable CD. \\nAfter that, boot computer from CD-ROM. Set Minix3 bo ot in regular sequence, because we have \\nmore than 16MB RAM. The following are the configurat ions of Minix3 in installation: \\n \\nKeyboard Standard: US-Keyboard Standard; \\nEthernet Chip: None; \\nFull distribution: Yes (requires 1GB space); \\nSize of “/home” directory: 2GB; \\nData Block Size: 4-KB per block; \\n \\nFor easier implementing testing programs and benchma rk tools on Minix3, extra software \\npackages should be installed on Minix3 system. T', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 95: ('writable CD. \\nAfter that, boot computer from CD-ROM. Set Minix3 bo ot in regular sequence, because we have \\nmore than 16MB RAM. The following are the configurat ions of Minix3 in installation: \\n \\nKeyboard Standard: US-Keyboard Standard; \\nEthernet Chip: None; \\nFull distribution: Yes (requires 1GB space); \\nSize of “/home” directory: 2GB; \\nData Block Size: 4-KB per block; \\n \\nFor easier implementing testing programs and benchma rk tools on Minix3, extra software \\npackages should be installed on Minix3 system. These s oftware packages can be downloaded \\nfrom the Minix3 home website or installed directly fr om Minix3.1.2a installation CD. Because \\nLinux uses the compiler GCC to compile test programs and the benchmark tool, the GCC \\nsoftware package was installed in Minix3. Moreover, b ecause Linux uses the Bash shell to \\nexecute programs, the shell Minix3 used should be id entical with Bash. Consequently, the Bash \\n3.0 software package was also installed in Minix3 syst em. If Minix3 used its compiler CC compiler \\nto compile programs and the default shell ash to exe cute test programs, it will make an inaccurate \\nperformance benchmarks. Linux uses compiler GCC to compi le programs and uses Bash shell to \\nexecute test programs. There are sufficient hard dis k spaces for storing, so both the package \\nsoftware binary distributions and their source codes a re install in Minix3.  \\n \\nMinix3 has a version of the X window software package  (X11 R6.8.2) which provides a window \\ndisplay for Minix3. However, the Minix3 X window syst em was not installed in Minix3 in the testing, \\nbecause the X windows software is not a crucial part fo r system performance evaluating. \\nFurthermore, due to the way Minix3 memory management works, running X window could lead a \\nprogram to fail because it runs of out of memory. “ch mem” command should be used to provide \\nsufficient stack space for the program. The memory of X  window binary usually set to a very large \\nnumber, which often could result in X window not star ting. The hardware has 256MB m', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 96: ('syst em was not installed in Minix3 in the testing, \\nbecause the X windows software is not a crucial part fo r system performance evaluating. \\nFurthermore, due to the way Minix3 memory management works, running X window could lead a \\nprogram to fail because it runs of out of memory. “ch mem” command should be used to provide \\nsufficient stack space for the program. The memory of X  window binary usually set to a very large \\nnumber, which often could result in X window not star ting. The hardware has 256MB memory \\nwhich is not sufficient for running the X windows as  default setting. So “chmem” should be used \\nfor giving the sufficient stack spaces. The higher mem ory X window consumed the less free \\nmemory will be available for other application progra ms [10]. That means the system \\nperformance of Minix3 could be greatly deteriorated i f running X window software on the system. \\n \\n3.3 Linux Environment \\nFedora core 6.0 and FreeBSD 6.0 were used in perform ance evaluation at the initial stage of the \\nresearch. The ISO images of Fedora core and FreeBSD co uld be downloaded from AARNet. \\nFedora core is an RPM-based Linux distribution. It is  well developed and widely used around \\nworld, which is a typical monolithic kernel operating sys tem and POSIX-compatible with 7000 \\nsoftware packages. Therefore, Fedora core 6.0 is a sui table Linux distribution system to be used \\nfor system evaluation. The Fedora core involved in re search was installed with X window \\nsoftware.  \\n \\nFreeBSD is also an Unix-like operating system. It is similar to Linux and also is a typical \\nmonolithic kernel operating system. Many software packag es are identical with those of Linux. \\nFreeBSD is totally free for the user, and it also pr ovides binary compatibility with other Unix-like \\noperating systems, including Linux, which means progr ams running on Linux could also run well \\non FreeBSD without any modifications. It is as reliab le and robust as Linux. In this research, \\nFreeBSD 6 was installed for testing.  \\n \\nHui Miao \\nInternational Jour', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 97: ('tem. It is similar to Linux and also is a typical \\nmonolithic kernel operating system. Many software packag es are identical with those of Linux. \\nFreeBSD is totally free for the user, and it also pr ovides binary compatibility with other Unix-like \\noperating systems, including Linux, which means progr ams running on Linux could also run well \\non FreeBSD without any modifications. It is as reliab le and robust as Linux. In this research, \\nFreeBSD 6 was installed for testing.  \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  283 At the initial stage of the research, Linux, FreeBSD  and Minix3.1.2a were used in the system \\nperformance evaluation. As the research went along, w e found the performance results were very \\nsimilar between Linux and FreeBSD. There was only 5% -10% difference between Linux and \\nFreeBSD in system call overhead. There is about a 5% difference between Linux and FreeBSD \\non pipe throughput overhead. The shell and software  packages are almost the same in Linux and \\nFreeBSD. At the middle stage of the project, we deci ded to stop evaluate the performance of \\nFreeBSD. The following reasons are why we did that: \\n \\n1. The purpose of the project is to obtain benchmarks of microkernel system and monolithic \\nkernel system and discuss the practicality of microkernel s ystem to see whether it could be more \\nreliable and sophisticate as well as current monolith ic kernel system. Performance comparison \\nbetween Linux and FreeBSD does not make any sense fo r the intention of the project. \\nFurthermore, there are already many benchmarks and ben chmark tools for the performance \\nevaluation between those Unix-like monolithic kernel systems. Many documents about \\nbenchmarks and performance evaluations could be found i n the Internet.  \\n \\n2. The performance evaluation results are very simil ar in Linux and FreeBSD. There is only 5%-\\n10% difference between Linux and FreeBSD in system cal l overhead. It is about 5% difference \\nbetween Linux and FreeBSD on pipe throughput o', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 98: ('intention of the project. \\nFurthermore, there are already many benchmarks and ben chmark tools for the performance \\nevaluation between those Unix-like monolithic kernel systems. Many documents about \\nbenchmarks and performance evaluations could be found i n the Internet.  \\n \\n2. The performance evaluation results are very simil ar in Linux and FreeBSD. There is only 5%-\\n10% difference between Linux and FreeBSD in system cal l overhead. It is about 5% difference \\nbetween Linux and FreeBSD on pipe throughput overhe ad. The structure of the kernels in Linux \\nand FreeBSD are similar. Both of the FreeBSD and Li nux are designed as monolithic kernel \\nsystem, so performance measurement between two monoli thic kernel systems certainly will give \\na similar result.  \\n \\n3.4 Benchmark Tool \\nThe selection criteria of benchmark tool were not compl ex. The benchmark tool should be able to \\nrun correctly on Minix3 and Linux, and gives accurate be nchmarks for the system. After carefully \\nreviewing through benchmark tools such as LMbench, Uni xbench and Ubench, we finally decided \\nto use Unixbench 4.0.1 [11] to test the system perfor mance of Minix3 and Linux. The reason not \\nuse LMbench is that LMbench requires specific header f iles at time of configuration. The header \\nfiles only could be found in Linux system or other mat ure Unix-like system. Minix3 does not have \\nthese header files; therefore it will cause compiling  failure during install LMbench on Minix3.  \\n \\nUnixbench is another system benchmark tool like LMbench. Unixbench gives performance \\nbenchmarks on many aspects of operating systems. Unixben ch is a simple portable and POSIX \\nmicrobenchmarks tool. Unixbench can give operating system  benchmarks such as Dhrystone, \\nsystem call overhead, file system performance on Write/ Read/Copy, pipe throughput, context \\nswitch, shell script running, arithmetic test, compiler performance and so on. Thus, Unixbench \\ncan give a comprehensive figure of system performance o n Minix3 and Linux. The main idea \\nUnixbench use to evaluate', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 99: ('bench gives performance \\nbenchmarks on many aspects of operating systems. Unixben ch is a simple portable and POSIX \\nmicrobenchmarks tool. Unixbench can give operating system  benchmarks such as Dhrystone, \\nsystem call overhead, file system performance on Write/ Read/Copy, pipe throughput, context \\nswitch, shell script running, arithmetic test, compiler performance and so on. Thus, Unixbench \\ncan give a comprehensive figure of system performance o n Minix3 and Linux. The main idea \\nUnixbench use to evaluate performance of operating sys tem as follows: On each system, a \\nconstant running time is given. Then, an infinite lo op running test program is started, and a global \\nvariable is used to record the number of loops. When  the time is up, a signal interrupts the loop \\nand records how many times the test program runs. Obv iously, an operating system which has \\nhigher efficiency could run more loops than that with lower performance. The more loops run the \\nbetter system performed. For example, we use Unixben ch to evaluate process creation on Linux: \\n \\n1. At start, the test program is set to run 10 secon ds. “signal(SIGALRM, func)” is used for setting \\nan interrupt function handler. “alarm(10)” will sign  a signal after 10 seconds. \\n2. Use “while (1)” to run an infinite loop. In the loop, “fork()” and “wait(&status)” are used for \\ncreating process, and “iter++” counts the times progra m run during 10 seconds. \\n3. After 10 seconds, the infinite loop is interrupte d by a signal sent by the “alarm(10)” system \\ncall. In the end, record the value of variable “iter” . The bigger “iter” is the better system \\nperforms in process creation. \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  284 The Unixbench only gives the number of loops run to p resent the performance of the system. \\nWhat if people want more direct performance benchmar ks? For example: microsecond time \\nvalues on each test program run are wanted. Therefor e, in this project we also used another way \\nto measure the per', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 100: (\". In the end, record the value of variable “iter” . The bigger “iter” is the better system \\nperforms in process creation. \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  284 The Unixbench only gives the number of loops run to p resent the performance of the system. \\nWhat if people want more direct performance benchmar ks? For example: microsecond time \\nvalues on each test program run are wanted. Therefor e, in this project we also used another way \\nto measure the performance of Minix3 and Linux. The system call “gettimeofday()” returns the \\ntime in seconds and microseconds since epoch in GMT. So  we could run “gettimeofday()” system \\ncall at the beginning and the end of test program an d subtract the returned values in order to get \\nthe microseconds used in running test program. Also,  taking the process creation test as an \\nexample, the following code determines the execution time of one process creation:  \\n \\ngettimeofday(time, tzone); /*get the time befor runn ing */ \\n            if ((slave = fork()) == 0) { \\n   exit(0); \\n  } else if (slave < 0) { \\n   exit(2); \\n  } else \\n   wait(&status); \\n  if (status != 0) { \\n   exit(2); \\n  } \\ngettimeofday(time1, tzone1); /*record finish time */ \\n \\nFrom the value of structure “time1” and “time” we cou ld calculate the execution time of process \\ncreation for once. \\n \\n4. Evaluation Results and Analysis \\n \\n4.1 Unixbench Evaluation Benchmarks \\nAt the beginning of the evaluation, we installed Un ixbench on Linux and Minix3 separately first. \\nFirst problem was how to transfer data into Minix3.  Minix3 was not developed as well as Windows \\nand Linux. Linux could automatically mount and unmount many file devices such as USB and \\nCD-ROM. With X window, Linux could easily transfer Un ixbench program from mobile devices \\n(USB, CD) to hard disk. However, Minix3 could not obt ain data sophisticatedly from outside \\ndevices. MINIX's primary purpose is to illustrate op erating system principles. Keeping MINIX \\nsmall enough to fit into a student's head\", 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 101: (\"t. \\nFirst problem was how to transfer data into Minix3.  Minix3 was not developed as well as Windows \\nand Linux. Linux could automatically mount and unmount many file devices such as USB and \\nCD-ROM. With X window, Linux could easily transfer Un ixbench program from mobile devices \\n(USB, CD) to hard disk. However, Minix3 could not obt ain data sophisticatedly from outside \\ndevices. MINIX's primary purpose is to illustrate op erating system principles. Keeping MINIX \\nsmall enough to fit into a student's head during a semester- or year-long course has required \\nkeeping it simple. In particular, the MINIX file syste m supports mounting only media containing \\nMINIX file systems [9]. In this research, we used comm and “isoread” to read the content of \\nUnixbench from ISO-9660 CD-ROM and copied the content to local hard disk. We wrote \\nUnixbench install program into a writable CD and use  “isoread /dev/c0d2/ Unixbench.zip > \\n/home/Unixbench/Unixbench.zip” command to copy Unixbench. zip into /home/unixbench/ \\ndirectory. After that, to use GCC, we have to change the PATH to add “/usr/gnu/bin” into PATH of \\nMinix3 system. At last, using “make” command to compile  and link all the programs of Unixbench \\nthen we used “./run” to run Unixbench to get benchmarks . \\n \\nThe total evaluation procedure lasted for 52 minutes . Unixbench gave system evaluation \\nbenchmarks on Dhrystone, system call overhead, file syste m performance on Write/Read/Copy, \\npipe throughput, context switch, shell script running (with 8 and 16 concurrent users), arithmetic \\ntest, C compiler throughput and process creation. Becau se Linux uses Bash shell, which is \\ndifferent from Minix3’s ash shell, so we installed Ba sh 3.0 shell on Minix3 and run Unixbench on \\nMinix3 with Bash 3.0. The following table Table 1 i n next page are benchmarks of Unixbench on \\nMinix3 with Bash 3.0, Minix3 and Linux. Here are the  terminologies for the table: \\n \\nlps: loops per second \\nlmp: loops per minute \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue \", 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 102: ('sers), arithmetic \\ntest, C compiler throughput and process creation. Becau se Linux uses Bash shell, which is \\ndifferent from Minix3’s ash shell, so we installed Ba sh 3.0 shell on Minix3 and run Unixbench on \\nMinix3 with Bash 3.0. The following table Table 1 i n next page are benchmarks of Unixbench on \\nMinix3 with Bash 3.0, Minix3 and Linux. Here are the  terminologies for the table: \\n \\nlps: loops per second \\nlmp: loops per minute \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  285 KBps: Kbytes per second \\n \\nFrom table.1, we could find that performance of Minix3  with Bash shell is similar to Minix3 with \\nthe default shell. Therefore, we only compare perform ance of Minix3 with performance of Linux \\ninstead of comparing those three benchmarks between Mi nix3, Minix3 with Bash and Linux. From \\nthe table, we could see Minix3 behaves little worse than Linux in some benchmarks such as in \\nDhrystone, File Write, Shell scripts and Recursion Tes t. In some benchmarks Minix3 could \\nperform as well as Linux did, such as Arithmetic Tes t in short integer. In some cases like System \\nCall overhead, Pipe throughput, Pipe-based context s witching, Process Creation, Exce \\nthroughput and Arithmetic test in float and double t ype. Minix3 is far slower than Linux. For \\nexample, Minix3 is about 182 times slower than Linu x. Minix3 could give better performance on \\nShell Script running with 8 or 16 concurrent users and  Arithmetic test in integer and long integer. \\nWe used bar charts (Fig 3, Fig 4, Fig. 5 and Fig. 6)  to illustrate the benchmarks. The bar charts of \\nthe performance benchmarks of Minix3 and Linux are aft er Table. 1 (Linux as 100 marks). \\n \\n \\n \\nFIGURE 3:  and FIGURE 4:  Benchmarks in Shell Script Running \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume (5) : Issue (4) : 2011  286  \\nTABLE 1:  Unixbench Benchmarks in Minix3 and Linux Benchmarks Minix 3.1.2a running \\nBash-3.0 Minix 3.1.2a Linux \\nDhrystone 2 using register \\nvaribles 1944025.1 loop/s 1892225 lps 234042', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 103: (', Fig 4, Fig. 5 and Fig. 6)  to illustrate the benchmarks. The bar charts of \\nthe performance benchmarks of Minix3 and Linux are aft er Table. 1 (Linux as 100 marks). \\n \\n \\n \\nFIGURE 3:  and FIGURE 4:  Benchmarks in Shell Script Running \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume (5) : Issue (4) : 2011  286  \\nTABLE 1:  Unixbench Benchmarks in Minix3 and Linux Benchmarks Minix 3.1.2a running \\nBash-3.0 Minix 3.1.2a Linux \\nDhrystone 2 using register \\nvaribles 1944025.1 loop/s 1892225 lps 2340428.8 lps \\nSystem Call Overhead 60340.9 lps 60366 lps 521107.6  lps \\nPipe Throughput 42795.4 lps 42584.1 lps 251399.8 lp s \\nPipe-based Context \\nSwithing 16668.3 lps 17506.2 lps 89164.7 lps \\nProcess Creation 30 lps 24.6 lps 4479 lps \\nExcel Throughput 36.7 lps 36.7 lps 1051.9 lps \\nFile Read 1024 bufsize \\n2000 maxblocks 81011 KBps 80693 KBps 220582 KBps \\nFile Write 1024 bufsize \\n2000 maxblocks 75644 KBps 75511 KBps 99276 KBps \\nFile Copy 1024 bufsize \\n2000 maxblocks 39228 KBps 39165 KBps 65518 KBps \\nFile Read 256 bufsize 500 \\nmaxblocks 24833 KBps 24721 KBps 81638 KBps \\nFile Write 256 bufsize 500 \\nmaxblocks 26400 KBps 26372 KBps 42460 KBps \\nFile Copy 256 bufsize 500 \\nmaxblocks 12674 KBps 12664 KBps 25413 KBps \\nFile Read 4096 bufsize \\n8000 maxblocks 30002 KBps 29997 KBps 392921 KBps \\nFile Write 4096 bufsize \\n8000 maxblocks 32800 KBps 32799 KBps 158023 KBps \\nFile Copy 4096 bufsize \\n8000 maxblocks 14064 KBps 14014 KBps 109613 KBps \\nShell scripts (1 \\nconcurrent)/ (8 \\nconcurrent)/ \\n(16 concurrent) 922.5 lps / 212 lps / \\n112.3 lps 825.6 lps / 207 lps / \\n111 lps 1452.8 lps / 199 \\nlps / 99 lps \\nArithmetic Test (double) / \\n(float) 3656 lps / 7066 lps 3656 lps / 7067.4 lps 250048.8 lps / \\n259010.4 lps \\nArithmetic Test (short) 249705 lps 249774 lps 25204 2 lps \\nArithmetic Test (int) /  \\n(long) 261163.6 lps / \\n261175.5 lps 261163.9 lps / \\n261159.6 lps 258079.3 lps / \\n258180.7 lps \\nArithoh 4597523.4 lps 4598553 lps 140482502 lps \\nC Compiler Troughput 43.8 lpm 43.6 lpm 358.7 lmp \\nDc: sqrt(2) to 99 decimal \\nplaces 1721.8 lps 1424.7 ', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 104: ('112.3 lps 825.6 lps / 207 lps / \\n111 lps 1452.8 lps / 199 \\nlps / 99 lps \\nArithmetic Test (double) / \\n(float) 3656 lps / 7066 lps 3656 lps / 7067.4 lps 250048.8 lps / \\n259010.4 lps \\nArithmetic Test (short) 249705 lps 249774 lps 25204 2 lps \\nArithmetic Test (int) /  \\n(long) 261163.6 lps / \\n261175.5 lps 261163.9 lps / \\n261159.6 lps 258079.3 lps / \\n258180.7 lps \\nArithoh 4597523.4 lps 4598553 lps 140482502 lps \\nC Compiler Troughput 43.8 lpm 43.6 lpm 358.7 lmp \\nDc: sqrt(2) to 99 decimal \\nplaces 1721.8 lps 1424.7 lps 38247.5 lps \\nRecursion Test-Tower of \\nHanoi 27023.3 lps 27149.8 lps 37328.8 lps \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  287   \\n \\n \\nFIGURE 5:   File System Benchmarks \\n \\n \\n \\nFIGURE 6:  Arithmetic Benchmarks \\n \\n3.2 Microsecond Level Evaluation Benchmarks \\nAs stated in last chapter, Unixbench starts an infini te loop running a test program and uses a \\nglobal variable to record the number of loops. When the time is up, it uses a signal to interrupt the \\nloop and records how many times the test program ran . The more loops run the better system \\nhas performed. Next we want a more precise evaluatio n result at the microsecond level. So we \\nran the system call function “gettimeofday()” at the be ginning and the end of test program and \\nsubtracted the returned values in order to get the m icroseconds used in running test program. In \\nUnixbench, the main program to evaluate system call ov erhead is as the following: \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  288  while (1) { \\nclose(dup(0)); \\ngetpid(); \\ngetuid(); \\numask(022); \\niter++; \\n} \\n \\nWhen the time is up, the signal sent from kernel wil l interrupt the infinite loop and the value of iter  \\nwill be recorded. For testing the real execution time  on system call overhead, we run \\n“gettimeofday()” system call at the beginning and the end of the program. So the main program \\ncodes are the following: \\n \\ngettimeofday(time, tzone); /*get the time befor runn ing */ \\nfor ( i =0 ; ', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 105: ('JE), Volume ( 5) : Issue (4) : 2011  288  while (1) { \\nclose(dup(0)); \\ngetpid(); \\ngetuid(); \\numask(022); \\niter++; \\n} \\n \\nWhen the time is up, the signal sent from kernel wil l interrupt the infinite loop and the value of iter  \\nwill be recorded. For testing the real execution time  on system call overhead, we run \\n“gettimeofday()” system call at the beginning and the end of the program. So the main program \\ncodes are the following: \\n \\ngettimeofday(time, tzone); /*get the time befor runn ing */ \\nfor ( i =0 ; i<1; i++)  /* do test program for just o nce */ \\n{                        /* copy from Unixbench */ \\nclose(dup(0)); \\ngetpid(); \\ngetuid(); \\numask(022); \\n} \\ngettimeofday(time1, tzone1); /*record finish time */ \\n \\nRan the test program on Minix3 and Linux separately. When the test program ran for one \\niteration, the result could not be measured on Minix3  because the system is too fast. So we \\nincreased the running loops of test program. When we  run test program for 1000 times, the \\nexecution time was get in Minix3. The following tabl e are the evaluation results: \\n \\n Minix3 Linux \\nIterations (i) 1 10 100 1000 10000 1 10 100 1000 10 000 \\nTime \\n(Microsecs) None None None 15,333 166,666 23 45 220 2,000 22,00 0 \\n \\nTABLE 2 :  Benchmarks on microsecond level \\n \\nFrom Table 2, we could see running system call test pr ogram for 1000 iterations cost Minix3 \\n15333 microseconds and cost Linux 2000 microseconds. In 1 0000 iterations, Minix3 spent \\n166666 microseconds, whereas Linux use 22000 microsecond s. In 1000 iterations case, Minix3 \\nis about 15333/2000 = 7.6 times slower than Linux. In 10000 iterations case, Minix3 is \\n166666/22000 = 7.58 times slower than Linux. We back t o the evaluation result Unixbench got; \\nMinix3 is about 521107.6 lps/60366 lps = 8.6 times slower than Linux. The results of Unixbench \\nand the results of microsecond level evaluation are similar. The purpose of the project is to \\nevaluate the performance of microkernel operating syste m, which could define whether \\nmicrokernel operating systems are a', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 106: ('s case, Minix3 \\nis about 15333/2000 = 7.6 times slower than Linux. In 10000 iterations case, Minix3 is \\n166666/22000 = 7.58 times slower than Linux. We back t o the evaluation result Unixbench got; \\nMinix3 is about 521107.6 lps/60366 lps = 8.6 times slower than Linux. The results of Unixbench \\nand the results of microsecond level evaluation are similar. The purpose of the project is to \\nevaluate the performance of microkernel operating syste m, which could define whether \\nmicrokernel operating systems are as practical as current  monolithic operating systems. Then the \\napproach was to analyze the benchmarks and separate perf ormance results that are caused by \\ndifferent system implementation from the results tha t are inherited due to the heavy IPC \\noverhead. Therefore, we could only consider the benchma rks Unixbench gave, if the \\nmicrosecond level results are similar to the benchmark s Unixbench gave. \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  289  \\n \\n \\nFIGURE 7:  Similar Results in Unixbench and Microseconds Level \\n \\n5. SUMMARY AND CONCLUSION \\n \\n5.1 Summary of the Conclusion \\nThe project used micro-benchmark tool Unixbench to meas ure the overall system performance of \\nMinix3.1.2a and the performance of Linux (Fedora Cor e 6.0). The evaluation test was done in \\nuser application layer of the systems. In this way that  we could testify the second generation \\nmicrokernel operating systems whether could be as flexib le, portable and secure as monolithic \\noperating systems like Linux. Unixbench gave many benchma rks on MINIX3 and Linux, such as \\nsystem call overhead, pipe throughput, arithmetic tes t and so on. The result shows MINIX3 has \\nbetter performance on Shell Scripts running and Arith metic test and Linux has better performance \\non other aspects such as system call overhead, process cr eation and so on. Linux gave a better \\nperformance than Minix3 on the overview of benchmarks.  However, after analyzing the \\nbenchmarks Unixbench gave, we realized that many benchma', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 107: ('ems like Linux. Unixbench gave many benchma rks on MINIX3 and Linux, such as \\nsystem call overhead, pipe throughput, arithmetic tes t and so on. The result shows MINIX3 has \\nbetter performance on Shell Scripts running and Arith metic test and Linux has better performance \\non other aspects such as system call overhead, process cr eation and so on. Linux gave a better \\nperformance than Minix3 on the overview of benchmarks.  However, after analyzing the \\nbenchmarks Unixbench gave, we realized that many benchmar ks such as process creation, \\nfloating point arithmetic test and Arithoh test in M inix3 could be optimized by system tuning. The \\nfollowing list is the summary of the Unixbench benchm arks discussions: \\n \\nProcess Creation: The benchmark shows that Minix3 is a bout 182 times slower than Linux. \\nHowever, COW (Copy-On-Write) technique is a main reas on that causes the big performance \\ndifference in process creation benchmarks. \\n \\nFloating Point Arithmetic Test: The benchmark shows that Minix3 is about 68 times and 36 times \\nslower than Linux in double and float data type respe ctively while Minix3 perform as well as Linux \\nin integer arithmetic test. The reason that causes the  poor performance on floating point \\narithmetic test is Minix3 does not support Floating  Point Unit (FPU) that is integrated into CPU. \\nMinix3 used software to emulation the floating poin t operations, which is much slower than \\nhardware floating point operation supported by Linux . \\n \\nShell Script Running: In Unixbench’s benchmarks, Minix 3 performed better than Linux in shell \\nscript running in 8 and 16 concurrent users cases. Becau se Minix3 does not have virtual file \\nsystem, so the buffer cache implementation in the syste ms would be different from Minix3 to \\nLinux. Linux with virtual memory system may require mo re CPU cycle on page allocation than \\nMinix3.  \\n \\n5.2 Future Works \\nAt the middle of this project, a new experimental ve rsion of Minix3 was released. Minix3.1.3, an \\nexperimental version of Minix3 which was released at  13', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 108: ('inix 3 performed better than Linux in shell \\nscript running in 8 and 16 concurrent users cases. Becau se Minix3 does not have virtual file \\nsystem, so the buffer cache implementation in the syste ms would be different from Minix3 to \\nLinux. Linux with virtual memory system may require mo re CPU cycle on page allocation than \\nMinix3.  \\n \\n5.2 Future Works \\nAt the middle of this project, a new experimental ve rsion of Minix3 was released. Minix3.1.3, an \\nexperimental version of Minix3 which was released at  13 th  April 2007. A few changes were made \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  290  in Minix3.1.3, such as enlarged file system, adding v irtual file system, new boot procedure and so \\non. Notice that virtual file system was imported to M inix3; therefore there must be a big change in \\nfile system in Minix3. So we should measure the perf ormance of new Minix3 virtual system again \\nusing same benchmark tool and benchmarks in Linux. Measu rement on process creation may \\ngive us a different benchmark compare with the current  benchmark. Another benchmark we \\nshould focus on is the shell script running. In curre nt benchmarks, Minix3 gave better \\nperformance on shell script running with 8 and 16 concu rrent users. We guess in this report that \\nthe reason that causes better performance in Minix3 i n shell script running is Minix3 does not \\nimplement virtual file system. In Minix3.1.3, virtua l file system was ported on Minix3. Therefore, \\nthe benchmarks of shell script running in Minix3.1.3 c ould give crucial information that whether \\nthe virtual memory system is the reason causes Linux sl ower than Minix3 in shell script running \\nbenchmark. \\n \\nForm the benchmarks in chapter 3, we could see that the re are many benchmarks such as \\nsystem call overheads, pipe throughput, context switch o verheads, excel overheads and C \\ncompiler throughput which we did not discuss yet. Resear ch on those benchmarks need to be \\ndone in the future. By doing that, we could make a very cl', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 109: ('ipt running in Minix3.1.3 c ould give crucial information that whether \\nthe virtual memory system is the reason causes Linux sl ower than Minix3 in shell script running \\nbenchmark. \\n \\nForm the benchmarks in chapter 3, we could see that the re are many benchmarks such as \\nsystem call overheads, pipe throughput, context switch o verheads, excel overheads and C \\ncompiler throughput which we did not discuss yet. Resear ch on those benchmarks need to be \\ndone in the future. By doing that, we could make a very clear figure that on Minix3 microkernel \\nperformance and could find out that which part of syste m could be improved by tuning the \\nmicrokernel system. Then try to optimize the system perfo rmance by tuning the microkernel \\nsystem if we know exactly why Minix3 behaved such a low p erformance in the benchmark.  \\n \\nFrom the Minix3 official web site, we also found tha t some future works should be done by \\nresearchers [9]: \\n1. Testing MINIX 3 on different platforms  \\n2. Porting programs and applications to MINIX 3  \\n3. Porting drivers to MINIX 3  \\n4. Building a driver framework to use FreeBSD or Lin ux drivers  \\n5. Porting MINIX 3 to different architectures \\n \\n6. REFERENCES  \\n[l]    Jochen Liedtke, “ toward real microkernels ”. Communications of ACM September 1996. \\nVo139, No. 9. \\n \\n[2]     Chen, J.B. and Bershad, B.N. “ The impact of operating system structure on memory system \\nperformance ”. In Proceedings of the 14th ACM Symposium on Opera ting System Principles \\n(SOSP) (Asheville, N.C., Dec. 1993). ACM Press, 1993 , pp. 120—133. \\n \\n[3]    Liedtke, J. “ On microkernel construction ”. In Proceedings of the 15th ACM Symposium on \\nOperating System Principles (SOSP) (Copper Mountain Resort, Cob., Dec. 1995). ACM \\nPress, New York, 1995, pp. 23 7-250. \\n \\n[4]   Liedtke, J. “ Improving the IPC by design Kernel ”. 14th ACM Symposium on Operating \\nSystem Principles (SOSP) Asheville. 1993, pp. 10-11. \\n \\n[5]    Andrew S Tanenbaum & Albert S Woodhull. “ Operating System Design and Implementation ” \\n(3rd Edition). Prentice Hal', 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 110: (\"1993 , pp. 120—133. \\n \\n[3]    Liedtke, J. “ On microkernel construction ”. In Proceedings of the 15th ACM Symposium on \\nOperating System Principles (SOSP) (Copper Mountain Resort, Cob., Dec. 1995). ACM \\nPress, New York, 1995, pp. 23 7-250. \\n \\n[4]   Liedtke, J. “ Improving the IPC by design Kernel ”. 14th ACM Symposium on Operating \\nSystem Principles (SOSP) Asheville. 1993, pp. 10-11. \\n \\n[5]    Andrew S Tanenbaum & Albert S Woodhull. “ Operating System Design and Implementation ” \\n(3rd Edition). Prentice Hall Software Series. 2006. \\n \\n[6]    L4 Kickstart < http://www.l4ka.org/projects/pis tachio/kickstart.php >. Edited by University of \\nKarlsruhe. 2000-2006. Viewed on 24th Mar. 2010. \\n \\n[7]    D. R. Engler, M. F. Kaashoek, J. O'Toole. “ Exokernel: an operation system architecture for \\napplication-level resource management ”. ACM SIGOPS Operating Systems Review , \\nProceedings of the fifteenth ACM symposium on Operat ing systems principles SOSP '95, \\nVolume 29 Issue 5. \\n \\nHui Miao \\nInternational Journal of Engineering (IJE), Volume ( 5) : Issue (4) : 2011  291  [8]  Lmbench home website <http://www.bitmover.com/lm bench/ >LMbench - Tools for \\nPerformance Analysis. Viewed on 24th Mar. 2010. \\n \\n[9]   Minix3 home website < http://www.minix3.org/d oc/environ.html> MiniFAQ about MINIX 3 \\nProgramming. Viewed on 14 th  May 2010. \\n \\n[10]  Minixtip website < http://www.minixtips.com/> T ips For Running the Minix OS Version 3. \\nViewed on 14 th  May 2010. \\n \\n[11]   FTP of Unixbench <http://www.tux.org/pub/tux/be nchmarks/System/unixbench> Viewed on \\n13 th  Mar 2010. \\n \\n[12]   Daniel P. Bovet & Macro Cesati. “ Understanding the Linux Kernel ”. O’REILLY Press, Nov \\n2005. \\n \\n[13]   Floating Point Unit, <http://en.wikipedia.or g/wiki/Floating_point_unit>, From Wikipedia, the \\nfree encyclopaedia. Viewed on 24th Mar 2010 \\n \\n[14]   Comparing Linux and Minix, <http://lwn.net/A rticles/220255/>, LWN.net article, Viewed on \\n16 th  May 2010. \\n \\n[15]    Hbench-OS Operating system Benchmarks <http://w ww.eecs.harvard.edu/vino/perf/hben \\n  \", 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 111: (\"tem/unixbench> Viewed on \\n13 th  Mar 2010. \\n \\n[12]   Daniel P. Bovet & Macro Cesati. “ Understanding the Linux Kernel ”. O’REILLY Press, Nov \\n2005. \\n \\n[13]   Floating Point Unit, <http://en.wikipedia.or g/wiki/Floating_point_unit>, From Wikipedia, the \\nfree encyclopaedia. Viewed on 24th Mar 2010 \\n \\n[14]   Comparing Linux and Minix, <http://lwn.net/A rticles/220255/>, LWN.net article, Viewed on \\n16 th  May 2010. \\n \\n[15]    Hbench-OS Operating system Benchmarks <http://w ww.eecs.harvard.edu/vino/perf/hben \\n          ch/index.html>, Viewed on 16 th  May 2010. \\n \\n[16]   H. Hartig, M. Hohmuth, J. Liedtke, S. Schänber g, J. Wolter, “ The Performance of µ-Kernel-\\nbased Systems ”, 16th SOSP TU Dresden, Fakultat Informatik, Heft Jan  1997. \\n \\n[17]  Ben Leslie, Carl van Schaik and Gernot Heiser,  “Wombat: a portable user-mode Linux for \\nembedded systems ”, Proceedings of the 6th Linux Conference Australia,  Canberra, April, \\n2005. \\n \\n[18]  ERTOS Website <http://www.ertos.nicta.com.au/re search/l4/performance.pml>, National \\nICT Australia United, Viewed on 16 th  May 2010. \\n \\n[19]     Release Notes of MINIX 3.1.3 - Developer's  Interim Release, <http://www.minix3.org \\n           /download/releasenotes-3.1.3.html>, Mini x3 Home Website, Viewed on 17 th  May 2010. \", 'Analysis of Practicality and Performance Evaluation for Monolithic Kernel and Micro-Kernel Operating Systems.pdf'), 112: ('2020 IEEE Region 10 Symposium (TENSYMP), 5-7 June 2020, Dhaka, Bangladesh \\n \\n978-1-7281-7366-5/20/$31.00 ©2020 IEEE A Novel Approach for E-mail Classification Using \\nFastText\\nRaisa Tahsin \\nDepartment of Computer Science and \\nEngineering  \\nKhulna University of Engineering & \\nTechnology \\nKhulna, Bangladesh \\nEmail: tahsinraisa1@gmail.comMahmudul Hasan Mozumder \\nDepartment of Computer Science and \\nEngineering  \\nKhulna University of Engineering & \\nTechnology \\nKhulna, Bangladesh \\nEmail: mahmuud.al.hasan@gmail.com \\nMd. Abdus Salim Mollah \\nDepartment of Computer Science and \\nEngineering  \\nKhulna University of Engineering & \\nTechnology \\nKhulna, Bangladesh \\nEmail: salim9326@cse.kuet.ac.bd Shaikh Akib Shahriyar \\nDepartment of Computer Science and \\nEngineering  \\nKhulna University of Engineering & \\nTechnology \\nKhulna, Bangladesh \\nEmail: akib.shahriyar@cse.kuet.ac.bd \\nAbstract —The upward trend of communication through \\nemails has made the task of handling mails efficiently very \\nvital. As the number of email users is growing considerably \\neach day, the volume of mails to each user is also enlarging. It mostly requires an intelligent cl assification system for multi-\\nfolder categorization of emails to save time and manual labor. \\nSeveral studies and experiments done till date have been \\nproved to provide a great extent of automation to this classification task. However, mult i-folder classification task has \\nalways been a little more challenging than others, especially \\nwith emails, because of the large number of the possible \\nclasses. This paper suggests an approach with machine learning for multi-class categorization of emails in a simple text classification method. We used our own dataset to build a text \\nclassifier with fastText, keeping different features of each class \\ninto consideration. The results from our proposed method were also compared to the performance of methods like Convolutional Neural Network with the same dataset and \\nfastText was observed to perform better.  \\nKeywords—  Multi-folder, FastText, Email class', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 113: ('e \\nclasses. This paper suggests an approach with machine learning for multi-class categorization of emails in a simple text classification method. We used our own dataset to build a text \\nclassifier with fastText, keeping different features of each class \\ninto consideration. The results from our proposed method were also compared to the performance of methods like Convolutional Neural Network with the same dataset and \\nfastText was observed to perform better.  \\nKeywords—  Multi-folder, FastText, Email classes, Type-\\nspecific-keywords, Unstructured texts \\nI. INTRODUCTION  \\nThe unavoidable explosion of emails is a familiar \\nscenario even for an average user of emails. Despite the availability of much faster interfaces and platforms for \\nconnecting with people, emails are still considered the best \\noption when it comes to formal communication or for official purposes. Therefore, the expert management of emails is also a matter of concern for all the email service providing platforms.\\n A practical and viable solution is to \\ndivide the emails in folders by categorizing them based on their types. Again, doing this manually is as cumbersome as it is time consuming for users, and is really not user-friendly at all. So, convenient interfaces can use automated e-mail classification techniques and have useful folders for emails like social, educational, or career-related etc. Hence, our proposed method suggests an automated approach and machine learning is one of the best options to make this task as user-independent as possible. \\nThe required dataset for the proposed approach has five \\ndifferent classes. For all these classes, most of the emails were taken from already labelled mails by Gmail and some \\n(mostly spam) from the Enron-spam dataset to achieve better spam filtration. As most of the user emails are raw in nature and this method only considers the email body for classification, the data pre-processing step is mandatory. In addition with that, the mails needed to be reformatted in a task-specific form. Other steps ', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 114: ('ossible. \\nThe required dataset for the proposed approach has five \\ndifferent classes. For all these classes, most of the emails were taken from already labelled mails by Gmail and some \\n(mostly spam) from the Enron-spam dataset to achieve better spam filtration. As most of the user emails are raw in nature and this method only considers the email body for classification, the data pre-processing step is mandatory. In addition with that, the mails needed to be reformatted in a task-specific form. Other steps for the classification task include: feature extraction, consideration of type-specific-keywords, training the classifier and finally testing for evaluation of performance. \\nThe proposed method here contains some of the new \\nexplorations of ways to use a more simplified version of email data for classification without compromising with the accuracy. The customized dataset simply works with the email header and body, and keeps the rest of the parts out of consideration. \\nII. R\\nELATED WORKS  \\nClassification of emails has been a subject undergoing \\nintense study because of the diversity in its classification \\nareas. Spam-ham filtering, detecting phishing mails, topic assignment to parts of an email, multi-folder classification etc. are some of the mostly worked on fields for emails. Reference [2] shows a study on using neural networks for e-\\nmail classification. The use of a neural network based \\nmethod- LINGER, is shown in this study for spam filtering. A thorough study on machine learning algorithms for spam detection, which include Naïve Bayes filtering, k-Nearest Neighbor classifier, artificial neural network etc., is done in the study of [1]. Research in [3] shows the classification of \\nmails in three eventual classes by treating emails as events. \\nHere, the emails are further converted into graphs and classification is performed. The research of [5] demonstrates the results for email classification using Parallel SVM based on MapReduce technique, which proved to be a better classifier than Naïve Bayes for te', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 115: ('etection, which include Naïve Bayes filtering, k-Nearest Neighbor classifier, artificial neural network etc., is done in the study of [1]. Research in [3] shows the classification of \\nmails in three eventual classes by treating emails as events. \\nHere, the emails are further converted into graphs and classification is performed. The research of [5] demonstrates the results for email classification using Parallel SVM based on MapReduce technique, which proved to be a better classifier than Naïve Bayes for text categorization. In the \\ndetailed study of [6], it is noticed that Support Vector \\nMachines (SVM), Naïve Bayesian classifier, decision trees, J48 etc. are the most frequently used methods for email classification so far. Different forms of encryption technology are applied to the unstructured texts like emails 1392\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:14 UTC from IEEE Xplore.  Restrictions apply. \\nto preserve the security of the text in emails [4]. The \\nresearch shown in [9] depicts the use of CNN for multi-labeling tasks. Reference [12] is a research on fastText in \\nclassifying flu-related tweets. \\nIII. P\\nROPOSED SYSTEM  \\nThe proposed method in this paper consists of some basic \\ntext classification steps along with feature and type-based keyword extraction techniques for improving classifier performance. The basic scheme is as follows: \\nA. Dataset Generation \\nThe dataset used for this approach is a custom dataset, \\nwhich consists of emails from 10 average email users. The collected emails are the ones pre-labelled by Gmail, since determining correct and standard labels for such data is a complex task. Furthermore, for better filtering of spam and to add variety to the dataset, Enron corpus was used in this compilation. The mails were labelled in the following five classes: social, promotional, educational, spam and general. It contains 1,000 emails with predefined classes. \\nB. Reformatting Dataset and Pre-processing \\nThe task of data pre-processing for', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 116: ('erage email users. The collected emails are the ones pre-labelled by Gmail, since determining correct and standard labels for such data is a complex task. Furthermore, for better filtering of spam and to add variety to the dataset, Enron corpus was used in this compilation. The mails were labelled in the following five classes: social, promotional, educational, spam and general. It contains 1,000 emails with predefined classes. \\nB. Reformatting Dataset and Pre-processing \\nThe task of data pre-processing for our dataset took a \\nfew steps to convert the data into a convenient form that we can feed into the fastText classifier. FastText requires the labelling of the dataset to be in a particular format like this: \\n__label__<label_name> <text> \\nAfter this conversion of the label format, the new lines, \\nsingle characters and multiple spaces were removed as part of the cleaning process. Lemmatization, conversion to lower case letters, stop words removal etc. steps are also performed for the basic pre-processing of all our email data. \\nDifferent Natural Language Toolkit functions were used for \\ntasks like stemming, lemmatizing and removing stop words. Here, an important consideration was made based on the significance of some specific special characters (i.e. non-numeric or non-alphabetic) like ‘$’, ‘%’ etc. in case of classifying spam, or sometimes promotional type of emails. \\nTherefore, these characters are preserved for further \\ninformation extraction as mentioned in the next section, despite of the requirement of the model to have cleaned texts as input. The rest of the insignificant special characters are removed for reducing complexity. \\nC. Extraction of Features \\nThe fastText library itself extracts features by using skip-\\ngram method. It considers character-level n-gram features for extraction, e.g., the word ‘ fantastic’  would be considered as \\nfan, fant, fanta,fantas, fantast, fantasti, fantastic etc. where \\nthe value of n could vary from 1 to the length of the word. \\nThis makes sure that the more rare or uns', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 117: ('the model to have cleaned texts as input. The rest of the insignificant special characters are removed for reducing complexity. \\nC. Extraction of Features \\nThe fastText library itself extracts features by using skip-\\ngram method. It considers character-level n-gram features for extraction, e.g., the word ‘ fantastic’  would be considered as \\nfan, fant, fanta,fantas, fantast, fantasti, fantastic etc. where \\nthe value of n could vary from 1 to the length of the word. \\nThis makes sure that the more rare or unseen words in the dataset is not returned a zero vector representation, and thus, making the model stronger for less seen words which contribute more to classifying between topics. \\nAs well as the inherent feature extraction of fastText, our \\nproposed model also uses other linguistic feature extraction techniques, which are described as follows: \\na) A distinguishing factor could be the presence of \\npercentage (%), monetary value ($), or URLs in emails, which are more likely to be seen in particular classes. Such features are handled before feeding the dataset to the classifier, by using regular expressions to replace all URLs, any percentage or \\nmonetary values with the keywords url, per and dol \\nrespectively. \\nb) Another technique was to keep five arrays of \\ntriggering keywords for each class. For example, the words ‘facebook’, ‘instagram’, ‘share’ would be seen more in social emails, or the terms ‘course’, ‘contest’ etc. are more expected in the educational mails. Such prior estimations, obviously keeping our dataset into consideration, came to use to increase the likelihood weights of each class. \\nD. Training and Classification \\nThe classification task proposed in this paper uses \\nfastText library by Facebook. Since the method needs classification of texts with our pre-labelled dataset, we used the supervised technique for text classification. The research published in [7] shows how a fastText classifier works efficiently even with very moderate resources. Since our dataset has five classes in total, which ma', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 118: ('r dataset into consideration, came to use to increase the likelihood weights of each class. \\nD. Training and Classification \\nThe classification task proposed in this paper uses \\nfastText library by Facebook. Since the method needs classification of texts with our pre-labelled dataset, we used the supervised technique for text classification. The research published in [7] shows how a fastText classifier works efficiently even with very moderate resources. Since our dataset has five classes in total, which makes it quite difficult to learn and classify correctly without overlapping between classes, so we needed some techniques to help increase the \\nperformance beforehand, as described previously in the \\nExtraction of Features part. As seen from [7], fastText works as a linear classifier taking word representations as input, and performing the whole classification task for the supervised method. It also uses softmax function for the calculation of probability distribution of the preset classes, and hierarchical softmax in case of large number of classes. A hashing function is also attached to the n-gram features for overcoming the drawbacks of simple Bag of Words (BoW) representation. \\nThe model was trained after working on the dataset, \\nusing fastText supervised classification technique. The experimental settings are described below: \\n1) Since the dataset has considerably larger number of \\nclasses compared with the total number of emails available (1,000), the epoch was thus set to 50 after several experiments so that the model is well trained. Also, the learning rate was set to 0.5. \\n2) The wordNgrams parameter was set to 2, which \\nbasically means the bigram features were used. \\n3) The cross-validation was done on a k-Fold \\nvalidation dataset, with k=8 to reduce biasness in \\ntest set accuracy due to small test set size. \\n4) FastText uses its skip-gram model and multinomial \\nlogistic regression to train and finally evaluate the model. \\nAfter the supervised training phase, the model returns a \\nbin file with which th', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 119: (' that the model is well trained. Also, the learning rate was set to 0.5. \\n2) The wordNgrams parameter was set to 2, which \\nbasically means the bigram features were used. \\n3) The cross-validation was done on a k-Fold \\nvalidation dataset, with k=8 to reduce biasness in \\ntest set accuracy due to small test set size. \\n4) FastText uses its skip-gram model and multinomial \\nlogistic regression to train and finally evaluate the model. \\nAfter the supervised training phase, the model returns a \\nbin file with which the testing was done on the test dataset. The basic commands which are used to simplify the training and testing are as follows: \\n• supervised: train a supervised classifier \\n• skipgram: train a skip-gram model \\n• test: evaluate a supervised classifier \\n• predict: predict most likely labels \\nFig. 1 shows the basic structure of this working procedure, \\ndepicting the classification task. FastText has an advantage over many other classification techniques for this simplicity that most of the work required a neural network working on multinomial logistic regression [7]. 1393\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:14 UTC from IEEE Xplore.  Restrictions apply. \\n \\nFig. 1.  Proposed Classification System \\nAlthough it needs a simple architecture, it still has noticeable \\nperformance for text classification tasks because of the efficient vector representation of words. The time required in training was also significantly less using even an averagely configured computer. \\nIV. R\\nESULT ANALYSIS  \\nThe performance of the proposed scheme was evaluated \\nusing precision, recall and f1-score metrics. The findings for the five classes are demonstrated in Table 1. It is observed from the precision and recall scores of the classes that some of the labels like promotional and spam are inherently a little difficult to distinguish from each other because of the nature of such mails.  \\n \\nTABLE I.  PERFORMANCE EVALUATION OF FASTTEXT   There have been only a few studies in text classifi', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 120: ('er. \\nIV. R\\nESULT ANALYSIS  \\nThe performance of the proposed scheme was evaluated \\nusing precision, recall and f1-score metrics. The findings for the five classes are demonstrated in Table 1. It is observed from the precision and recall scores of the classes that some of the labels like promotional and spam are inherently a little difficult to distinguish from each other because of the nature of such mails.  \\n \\nTABLE I.  PERFORMANCE EVALUATION OF FASTTEXT   There have been only a few studies in text classification \\nusing fastText. The research in [12] has an F-measure between 86.47% and 89.9% for different sets of n-gram features with a dataset almost ten times larger than ours, whereas our proposed method for email classification gives 87.8% F-measure for the bigram setting and the classification accuracy is 92.5%. For comparison purpose, the same set of data was tested with a CNN classifier for text classification, and it yielded an accuracy of <85% during the k-fold validation phase. Fig. 2 shows how the precision-recall curve along with iso-f1 curves is extended for the multiclass problem. The methodology provided here uses only the neural network architecture of fastText with some new feature extraction techniques, and yet performs without compromising with accuracy. Other standard and traditional \\nmethods for this task, e.g. Naïve Bayesian method, SVM, or \\ndecision trees provide accuracies ranging from 90% to 95% in average for binary classification methods over different datasets [6], [8]. For larger number of classes, the accuracy generally seems to deteriorate a bit. However, the accuracy acquired from the technique described in this paper is 92.5%, which is very close to those found from other techniques for binary classification, and higher than most methods for multiple classes as noticed from [6]. \\nThe precision and recall scores of the five classes as \\ndepicted in Table 1 show that social and spam classes have a lower recall score and thus some of the social and spam mails are not correctly classifie', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 121: ('er of classes, the accuracy generally seems to deteriorate a bit. However, the accuracy acquired from the technique described in this paper is 92.5%, which is very close to those found from other techniques for binary classification, and higher than most methods for multiple classes as noticed from [6]. \\nThe precision and recall scores of the five classes as \\ndepicted in Table 1 show that social and spam classes have a lower recall score and thus some of the social and spam mails are not correctly classified, which consequently increases false negatives for the two classes. This also explains why the promotional class has low precision and thus more false positives since some of those spam mails are misclassified as promotional mails for the structural nature of many promotional mails being much similar to spam mails. Some of the social mails are classified as general mails as well, resulting in a low recall for the social class. The classifier provides good precision and recall scores for the educational class. \\n \\nFig. 2.  Precision-Recall curve for five classes \\nClass Precision Recall F1-score \\nSocial 0.922 0.79 0.85 \\nPromotional 0.76 0.946 0.84 \\nEducational 0.96 0.92 0.94 \\nSpam 0.91 0.79 0.85 \\nGeneral 0.84 0.895 0.87 1394\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:14 UTC from IEEE Xplore.  Restrictions apply. \\n The overall result derived in this method demonstrates \\nthe necessity of preserving likely words’ importance as we showed in the type-based-keywords extraction technique. \\nThe classifier was seen to work really well for the parameter \\nwordNgram in supervised training set to 3 as well, and thus showing this particular characteristic for our small dataset. Also, fasttext worked well even for our small dataset since the pre-processing step also included the likelihood increasing step. The accuracy is slightly lower without this, as we see while testing. \\nV. C\\nONCLUSION AND FURTHER ENHANCEMENT  \\nClassification of emails into multiple folders is often a \\ndiv', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 122: ('extraction technique. \\nThe classifier was seen to work really well for the parameter \\nwordNgram in supervised training set to 3 as well, and thus showing this particular characteristic for our small dataset. Also, fasttext worked well even for our small dataset since the pre-processing step also included the likelihood increasing step. The accuracy is slightly lower without this, as we see while testing. \\nV. C\\nONCLUSION AND FURTHER ENHANCEMENT  \\nClassification of emails into multiple folders is often a \\ndiverse problem, having difficulties that make it different from traditional topic-based text categorization. The feature extraction task here is enhanced by modifying weights for some particular triggering words in emails for which the chances of the mails to fall into a particular class increases. This works as the key technique to boost the performance by an increase of 3-4% in the true positives for each class, which is observed by working through the validation phase. In addition to that, the methodology here needs much less information than other existing methods of email clustering, yet gives quite a satisfactory result. The fastText library proved to be a good classifier for our dataset since we treated the email classification task more as a text classification problem, rather than treating the emails in a more sophisticated way. This reduced further hassles of modifying the data before being provided to the classifier to many magnitudes. However, the accuracy gained from the proposed mechanism can be raised if we consider similar type of classes to be one class, e.g. the two classes promotional and spam could be considered as a single class due to the similarities of features. This would lower the misclassification rate to a good extent. Other classes having \\nmore varied features can be added to this classification task \\nand be tested with larger datasets. Nevertheless, the approach demonstrated in this paper provides very good results if compared with the other modern techniques and classifiers for text', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 123: ('aised if we consider similar type of classes to be one class, e.g. the two classes promotional and spam could be considered as a single class due to the similarities of features. This would lower the misclassification rate to a good extent. Other classes having \\nmore varied features can be added to this classification task \\nand be tested with larger datasets. Nevertheless, the approach demonstrated in this paper provides very good results if compared with the other modern techniques and classifiers for text classification.  R\\nEFERENCES  \\n[1] W.A, Awad & S.M, ELseuofi. (2011). “Machine Learning \\nmethods for E-mail Classification,” International Journal of \\nComputer Applications,  16. 10.5120/1974-2646. \\n[2] J. Clark, I. Koprinska and J. Poon, \"A neural network based \\napproach to automated e-mail classification,\" Proceedings \\nIEEE/WIC International Conference on Web Intelligence (WI \\n2003),  Halifax, NS, Canada, 2003, pp. 702-705. \\n[3] Wasi, S., Jami, S.I., & Shaikh, Z.A. (2016). “Context-based \\nemail classification model,” Expert Systems , 33, 129-144.  \\n[4] S. S. Roy, S. A. Shahriyar, M. Asaf-Uddowla, K. M. R. Alam \\nand Y. Morimoto, \"A novel encryption model for text messages using delayed chaotic neural network and DNA cryptography,\" 2017 20th International Conference of Computer and \\nInformation Technology (ICCIT),  Dhaka, 2017, pp. 1-6. \\n[5] Xu, Ke, Cui Wen, Qiong Yuan, Xiangzhu He, and Jun Tie. \"A \\nMapReduce based parallel SVM for email classification.\" \\nJournal of Networks  9, no. 6 (2014): 1640. \\n[6] G. Mujtaba, L. Shuib, R. G. Raj, N. Majeed and M. A. Al-Garadi, \\n\"Email Classification Research Trends: Review and Open \\nIssues,\" in IEEE Access , vol. 5, pp. 9044-9064, 2017. \\n[7] Joulin, Armand, et al. \"Bag of tricks for efficient text \\nclassification.\" arXiv preprint arXiv:1607.01759  (2016). \\n[8] Alberts, Inge and Dominic Forest. “Email pragmatics and \\nautomatic classification: A study in the organizational context.” \\nJASIST 63  (2012): 904-922. \\n[9] S. A. Shahriyar, K. M. Rokibul Alam, S. S. Roy and Y. Mor', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 124: ('ujtaba, L. Shuib, R. G. Raj, N. Majeed and M. A. Al-Garadi, \\n\"Email Classification Research Trends: Review and Open \\nIssues,\" in IEEE Access , vol. 5, pp. 9044-9064, 2017. \\n[7] Joulin, Armand, et al. \"Bag of tricks for efficient text \\nclassification.\" arXiv preprint arXiv:1607.01759  (2016). \\n[8] Alberts, Inge and Dominic Forest. “Email pragmatics and \\nautomatic classification: A study in the organizational context.” \\nJASIST 63  (2012): 904-922. \\n[9] S. A. Shahriyar, K. M. Rokibul Alam, S. S. Roy and Y. Morimoto, \\n\"An Approach for Multi Label Image Classification Using Single Label Convolutional Neural Network,\" 2018 21st International \\nConference of Computer and Information Technology (ICCIT),  \\nDhaka, Bangladesh, 2018, pp. 1-6. \\n[10] S. Chakravarthy, A. Venkatachalam and A. Telang, \"A Graph-\\nBased Approach for Multi-folder Email Classification,\" 2010 \\nIEEE International Conference on Data Mining,  Sydney, NSW, \\n2010, pp. 78-87. \\n[11] S. Mahmud, X. Lin and J. Kim, \"Interface for Human Machine \\nInteraction for assistant devices: A Review,\" 2020 10th Annual \\nComputing and Communication Workshop and Conference \\n(CCWC),  Las Vegas, NV, USA, 2020, pp. 0768-0773.  \\n[12] A. Alessa, M. Faezipour and Z. Alhassan, \"Text Classification of \\nFlu-Related Tweets Using FastText with Sentiment and Keyword Features,\" 2018 IEEE International Conference on Healthcare \\nInformatics (ICHI),  New York, NY, 2018, pp. 366-367. \\n \\n 1395\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:14 UTC from IEEE Xplore.  Restrictions apply. ', 'A Novel Approach for E-mail Classification Using FastText.pdf'), 125: ('IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001 1267\\nA Novel Method for Tracking and Counting\\nPedestrians in Real-Time Using a Single Camera\\nOsama Masoud and Nikolaos P. Papanikolopoulos , Senior Member, IEEE\\nAbstract— Thispaperpresentsareal-timesystemforpedestrian\\ntrackinginsequencesofgrayscaleimagesacquiredbyastationary\\ncamera.Theobjectiveistointegratethissystemwithatrafficcon-trol application such as a pedestrian control scheme at intersec-tions.Theproposedapproachcanalsobeusedtodetectandtrackhumans in front of vehicles. Furthermore, the proposed schemescan be employed for the detection of several diverse traffic ob-jects of interest (vehicles, bicycles, etc.) The system outputs thespatio-temporal coordinates of each pedestrian during the periodthe pedestrian is in the scene. Processing is done at three levels:raw images, blobs, and pedestrians. Blob tracking is modeled as agraph optimization problem. Pedestrians are modeled as rectan-gular patches with a certain dynamic behavior. Kalman filteringis used to estimate pedestrian parameters. The system was imple-mented on a Datacube MaxVideo 20 equipped with a DatacubeMax860 and was able to achieve a peak performance of over 30framespersecond.Experimentalresultsbasedonindoorandout-doorscenesdemonstratedthesystem’srobustnessundermanydif-ficult situations such aspartial or fullocclusions of pedestrians.\\nIndexTerms— Applications,imagesequenceanalysis,intelligent\\ntrasportation systems, pedestrian control at intersections, pedes-trian tracking, real-time tracking.\\nI. INTRODUCTION\\nTHERE is a wealth of potential applications of pedestrian\\ntracking. Different applications, however, have different\\nrequirements. Tracking systems suitable for virtual reality ap-\\nplicationsandforthosemeasuringathleticperformancerequirethat specific body parts be robustly tracked. In contrast, secu-rity monitoring, event recognition, pedestrian counting, traffic\\ncontrol, and traffic-flow pattern identification applications em-\\nphasize tracking on a coarser level. Her', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 126: ('ing, real-time tracking.\\nI. INTRODUCTION\\nTHERE is a wealth of potential applications of pedestrian\\ntracking. Different applications, however, have different\\nrequirements. Tracking systems suitable for virtual reality ap-\\nplicationsandforthosemeasuringathleticperformancerequirethat specific body parts be robustly tracked. In contrast, secu-rity monitoring, event recognition, pedestrian counting, traffic\\ncontrol, and traffic-flow pattern identification applications em-\\nphasize tracking on a coarser level. Here all individuals in thescenecanbeconsideredassingleindivisibleunits.Ofcourse,asystem that can perform simultaneous tracking on all different\\nscalesishighlydesirablebutuntilnow,nosuchsystemexists.A\\nfewsystemsthattrackbodypartsofoneperson[24],[13],[16]andtwopersons[6]havebeen developed.Itremainstobeseen\\nManuscript received April 22, 1997; revised January 28, 2001. This work\\nwas supported by the Minnesota Department of Transportation through Con-\\ntracts #71789-72983-169 and #71789-72447-159, the Center for Transporta-tionStudiesthroughContract#USDOT/DTRS93-G-0017-01,theNationalSci-\\nence Foundation through Contracts #IRI-9410003 and #IRI-9502245, the De-\\npartment of Energy (Sandia National Laboratories) through Contracts #AC-\\n3752D and #AL-3021, and the McKnight Land-Grant Professorship Program\\nat the University of Minnesota.\\nThe authors are with the Artificial Intelligence, Robotics, and Vision\\nLaboratory, Department of Computer Science and Engineering, Universityof Minnesota, Minneapolis, MN 55455 USA (e-mail: masoud@cs.umn.edu;\\nnpapas@cs.umn.edu).\\nPublisher Item Identifier S 0018-9545(01)08257-3.whether these systems can be generalized to track an arbitrary\\nnumber of pedestrians.\\nTheworkdescribedinthispapertargetsthesecondcategoryof\\napplications[12],[10].Theproposedapproachhasalargenumberof potential applications which extend beyond pedestrians. For\\nexample, it cannot only detect and track humans in front of or\\naroundvehiclesbutitcanalsobeemployedtotrackseveraldiversetrafficobjectsofinterest(vehiclesinweavingse', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 127: (' masoud@cs.umn.edu;\\nnpapas@cs.umn.edu).\\nPublisher Item Identifier S 0018-9545(01)08257-3.whether these systems can be generalized to track an arbitrary\\nnumber of pedestrians.\\nTheworkdescribedinthispapertargetsthesecondcategoryof\\napplications[12],[10].Theproposedapproachhasalargenumberof potential applications which extend beyond pedestrians. For\\nexample, it cannot only detect and track humans in front of or\\naroundvehiclesbutitcanalsobeemployedtotrackseveraldiversetrafficobjectsofinterest(vehiclesinweavingsections,bicycles,rollerbladers,etc.).Oneshouldnotethatthereliabledetectionand\\ntrackingoftrafficobjectsisimportantinseveralvehicularappli-\\ncations(e.g.,parkingsensoryaids,lanedepartureavoidancesys-tems,etc.).Inthispaper,wearemainlyinterestedinapplications\\nrelatedtotrafficcontrolwiththegoalofincreasingbothsafetyand\\nefficiency of existing roadways. Information about pedestrianscrossingthestreets wouldallowforautomaticcontrol oftrafficlightsatanintersection,forexample.Pedestriantrackingalsoal-\\nlows the use of a warning system, which can warn drivers and\\nworkersataworkzonefrompossiblecollisionrisks.\\nSeveralattemptshavebeenmadetotrackpedestriansassingle\\nunits. Baumberg and Hogg [3] used deformable templates to\\ntrack the silhouette of a walking pedestrian. The advantage of\\ntheirsystemisthatitisabletoidentifytheposeofthepedestrian.Trackingresultswereshownforonepedestrianinthesceneandthesystemassumedthatoverlapandocclusionsareminimal[2].\\nAnotheruseofthesilhouettewasmadebySegenandPingali[19].\\nIn their case, features on the pedestrian silhouette were trackedand their paths were clustered. The system ran in real-time butwasnotabletodealwellwithtemporaryocclusions.Occlusions\\nand overlaps seem to be a primary source of instability for\\nmany systems. Rossi and Bozzoli [17] avoided the problem bymounting the camera vertically in their system which aimed tomainly count passing pedestrians in a corridor. Such a camera\\nconfiguration, however, may not be feasible in some cases.\\nOcclusions and overlaps occur very commonly in pedestri', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 128: ('the pedestrian silhouette were trackedand their paths were clustered. The system ran in real-time butwasnotabletodealwellwithtemporaryocclusions.Occlusions\\nand overlaps seem to be a primary source of instability for\\nmany systems. Rossi and Bozzoli [17] avoided the problem bymounting the camera vertically in their system which aimed tomainly count passing pedestrians in a corridor. Such a camera\\nconfiguration, however, may not be feasible in some cases.\\nOcclusions and overlaps occur very commonly in pedestrianscenes; and cannot be ignored by a pedestrian tracking system.Theuseofmultiplecamerascanalleviatetheocclusionproblem.\\nCaiandAggarwal[4]trackedpedestrianswithmultiplecameras.\\nThe system, however, did not address the occlusion problem inparticularbutratherhowtomatchthepedestrianacrossdifferentcameraviews.Theswitchingamongcameraswasdonemanually.\\nSmithet al.[22] performed pedestrian detection in real-time.\\nThesystemusedseveralsimplisticcriteriatojudgewhetherthedetected object is a pedestrian or not but did not actually trackpedestrians.\\nShio and Sklansky [20] presented a method for segmenting\\npeopleinmotionwiththeuseofcorrelationtechniquesoversuc-cessiveframestorecoverthemotionfield.Iterativemergingwasthen used to recover regions with similar motion. The method\\n0018–9545/01$10.00 © 2001 IEEE\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1268 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\nFig. 1. (a) Background image. (b) Foreground. (c) Difference image showing that a blob does not alwayscorrespond to one pedestrian.\\nwas able to deal with partial occlusions. The assumption was\\nthat pedestrians do not change direction as they move. A dis-\\nadvantage of this method is the high computational cost of thecorrelation and the iterative merging steps. An interesting ap-proach which was presented by Heisele et al.[9] is based on\\ntheir earlier work on color cluster flow [8]. An image is clus-\\ntered into ', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 129: ('. 1. (a) Background image. (b) Foreground. (c) Difference image showing that a blob does not alwayscorrespond to one pedestrian.\\nwas able to deal with partial occlusions. The assumption was\\nthat pedestrians do not change direction as they move. A dis-\\nadvantage of this method is the high computational cost of thecorrelation and the iterative merging steps. An interesting ap-proach which was presented by Heisele et al.[9] is based on\\ntheir earlier work on color cluster flow [8]. An image is clus-\\ntered into regions of similar color. In the subsequent images,the clusters are updated using a\\n-means clustering algorithm.\\nAssuming that the pedestrian legs form one cluster, a step to\\nrecognizelegsenablesthesystemtorecognizeandtrackpedes-\\ntrians. This was done by checking the periodicity of the clustershape and by feeding the gray scale images of the legs into atime delay neural network. The advantage of this approach is\\nthatitworksinthecaseofamovingcamera.Unfortunately,due\\nto several costly steps, real-time implementation was not pos-sible.Lipton etal.[14]performedclassificationandtrackingof\\nvehiclesandpedestrians.Theyusedasimplecriterionforclassi-\\nficationandtemplatematching,guidedbymotiondetectionfor\\ntracking. The system was able to track multiple isolated pedes-trians and vehicles robustly. The classification step is criticalsince the template that is used for tracking is decided based on\\nit.Morerecently,Haritaoglu etal.[7]successfullytrackedmul-\\ntiple pedestrians as well as their body parts. The system madeuse of silhouette analysis in finding body parts which can besensitive to occlusions.\\nIn developing our method, robustness in arbitrary input\\nscenes with arbitrary environmental conditions without com-promising real-time performance was the primary motivation.Our approach does not have a restriction on the camera posi-\\ntion.Moreimportantly,wedonotmakeanyassumptionsabout\\nocclusionsandoverlaps.Oursystemusesasinglefixedcameramounted at an arbitrary position. We use simple rectangularpatches with a certain dynamic be', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 130: (' silhouette analysis in finding body parts which can besensitive to occlusions.\\nIn developing our method, robustness in arbitrary input\\nscenes with arbitrary environmental conditions without com-promising real-time performance was the primary motivation.Our approach does not have a restriction on the camera posi-\\ntion.Moreimportantly,wedonotmakeanyassumptionsabout\\nocclusionsandoverlaps.Oursystemusesasinglefixedcameramounted at an arbitrary position. We use simple rectangularpatches with a certain dynamic behavior to model pedestrians.Overlaps and occlusions are dealt with by allowing pedestrian\\nmodels to overlap in the image space and by maintaining their\\nexistence in spite of the disappearance of some cues. The cuesthat we use are blobs obtained by thresholding the result ofsubtracting the image from the background.\\nOur choice of using blobs obtained after background sub-\\ntractionismotivatedbytheefficiencyofthispreprocessingstepeven though some information is permanently lost. In a typicalscene,ablobobtainedthiswaydoesnotalwayscorrespondtoa\\nsinglepedestrian.AnexampleisshowninFig.1.Thisisthemain\\nsource of weakness in many of the systems mentioned abovewhichassumeacleanone-to-onecorrespondencebetweenblobsand pedestrians. In our system, we allow maximum flexibility\\nby allowing this relation to be many-to-many. This relation is\\nupdated iteratively depending on the observed blobs behaviorandpredictionsofpedestriansbehavior.Fig.2givesanoverviewof the system. Three levels of abstraction are used. The lowest\\nlevel deals with raw images. In the second level, blobs are\\ncomputed and subsequently tracked. Tracked blobs are passedon to the pedestrians level where relations between pedestriansand blobs as well as information about pedestrians are inferred\\nusingpreviousinformationaboutpedestriansinthatlevel.\\nAtthe imageslevel,weperform backgroundsubtractionand\\nthresholdingtoproduce differenceimages .Backgroundsubtrac-\\ntion has been used by many to extract moving objects in the\\nscene[2],[4],[19],[22].Changedetectionalgorithmsth', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 131: ('ls with raw images. In the second level, blobs are\\ncomputed and subsequently tracked. Tracked blobs are passedon to the pedestrians level where relations between pedestriansand blobs as well as information about pedestrians are inferred\\nusingpreviousinformationaboutpedestriansinthatlevel.\\nAtthe imageslevel,weperform backgroundsubtractionand\\nthresholdingtoproduce differenceimages .Backgroundsubtrac-\\ntion has been used by many to extract moving objects in the\\nscene[2],[4],[19],[22].Changedetectionalgorithmsthatcom-\\nparesuccessiveframes[11],[21]canalsobeusedtoextractmo-tion.However,thesealgorithmsalsooutputregionsintheback-ground that get uncovered by the moving object as well which\\nisundesirableinourcase.Thechoiceofthethresholdiscritical.\\nMany thresholding techniques [15], [18] work very well whenthereisanobjectinthe scene.This isbecausethese techniquesassumethattheimagetobethresholdedcontainstwocategories\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\nMASOUD AND PAPANIKOLOPOULOS: TRACKING AND COUNTING PEDESTRIANS IN REAL-TIME 1269\\nFig. 2. The three levels of abstraction and data flows among them.\\nofpixelvaluesandtheytrytoseparatethetwo.However,when\\nthereisonly onecategory,theresultsbecome unpredictable.In\\nour case, this happens often since the scene may not have any\\nobjects at one point in time. Instead, we used a fixed thresholdvalue. The value was obtained by examining an empty back-ground for a short while and measuring the maximum fluctua-\\ntionofpixelvaluesduringthistrainingperiod.Thethresholdis\\nset to be slightly above that value. This technique worked suf-ficiently well for our purpose. Several measures were taken tofurther reduce the effect of noise. A single step of erosion fol-\\nlowed by a step of dilation is performed on the resulting image\\nand small clusters are totally removed. Also, the backgroundimage is updated using a very slow recursive function to cap-ture slow changes in the background (e.g., changes in ', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 132: ('ing the maximum fluctua-\\ntionofpixelvaluesduringthistrainingperiod.Thethresholdis\\nset to be slightly above that value. This technique worked suf-ficiently well for our purpose. Several measures were taken tofurther reduce the effect of noise. A single step of erosion fol-\\nlowed by a step of dilation is performed on the resulting image\\nand small clusters are totally removed. Also, the backgroundimage is updated using a very slow recursive function to cap-ture slow changes in the background (e.g., changes in lighting\\nconditions due to a passing cloud).\\nIt should be noted that even with these precautions, in a real\\nworldsequence,thefeatureimagemaystillcapturesomeunde-sirable features (e.g., shadows, excessive noise, sudden changein lighting conditions, and trees moved by the wind (see Fig.\\n7 frame 104), etc.). It also may miss parts of moving pedes-\\ntriansduetoocclusions(seeFig.8frame32)orcolorsimilaritybetween the pedestrian clothes and the background (see Fig. 8frame44).Oursystemhandlesthemajorityofthesesituationas\\nwill be explained in the subsequent sections.\\nThe next section describes the processing done at the blobs\\nlevel. The pedestrians level is presented in Section III. Experi-mentalresultsfollowinSectionIV.Finally,conclusionsarepre-\\nsented in Section V.\\nII. B\\nLOBSLEVEL\\nIn this level, we present a novel approach to track blobs re-\\ngardless of what they represent. The tracking scheme attempts\\nFig.3. (a)Blobsinframe /40 /105 /0 /49/41.(b)Blobsinframe /105.(c)Relationshipamong\\nblobs.\\ntodescribechangesinthedifferenceimageintermsofmotionof\\nblobsandbyallowingblobstomerge,split,appear,andvanish.Robust blob tracking was necessary since the pedestrians levelreliessolelyoninformationpassedfromthislevel.Thefirststep\\nis to extract blobs. Connected regions are extracted efficiently\\nusingboundaryfollowing[5].Anotherwaytoextractconnectedcomponents is to use the raster scan algorithm [5]. The advan-tageofthelattermethodisthatitextractsholesinsidetheblobs\\nwhile boundary following does not. However, for the purpose\\nof our sys', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 133: ('ferenceimageintermsofmotionof\\nblobsandbyallowingblobstomerge,split,appear,andvanish.Robust blob tracking was necessary since the pedestrians levelreliessolelyoninformationpassedfromthislevel.Thefirststep\\nis to extract blobs. Connected regions are extracted efficiently\\nusingboundaryfollowing[5].Anotherwaytoextractconnectedcomponents is to use the raster scan algorithm [5]. The advan-tageofthelattermethodisthatitextractsholesinsidetheblobs\\nwhile boundary following does not. However, for the purpose\\nof our system, holes do not constitute a major issue. Movingpedestriansusuallyformsolidblobsinthedifferenceimageandiftheseblobshaveholes,theymaybestillconsideredpartofthe\\npedestrian.Boundaryfollowinghastheextraadvantageofbeing\\nmoreefficientsincetheblobinteriorisnotconsidered.Thefol-lowing parameters are computed for each blob\\n1) area— : the number of pixels inside the blob;\\n2) bounding box—the smallest rectangle surrounding the\\nblob;\\n3) density— /bounding box area;\\n4) velocity— , calculated in pixels per second in hori-\\nzontal and vertical directions.\\nA. Blob Tracking\\nWhenanewsetofblobsiscomputedforframe ,anassocia-\\ntionwithframe ’ssetofblobsissought.Ideally,thisas-\\nsociationcan bean unrestricted relation. With each newframe,\\nblobs can split, merge, appear, or disappear. Examples of blobbehavior can be seen in the blob images in Figs. 7 and 8. Therelation among blobs can be represented by an undirected bi-\\npartitegraph,\\n,where .and\\narethesetsofverticesassociatedwiththeblobsinframes and\\n, respectively. We will refer to this graph as a blob graph .\\nSince there is a one-to-one correspondence between the blobs\\nin frame and the elements of , we will use the terms blob\\nand vertex interchangeably. Fig. 3 shows how the blobs in twoconsecutiveframes areassociated.Theblob graphin thefigureexpressesthefactthatblob1splitintoblobs4and5,blob2and\\npart of blob 1 merged to form blob 4, blob 3 disappeared, and\\nblob 6 appeared.\\nThe process of blob tracking is equivalent to computing\\nfor , where is the total number of frames.\\nLet denote the', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 134: ('this graph as a blob graph .\\nSince there is a one-to-one correspondence between the blobs\\nin frame and the elements of , we will use the terms blob\\nand vertex interchangeably. Fig. 3 shows how the blobs in twoconsecutiveframes areassociated.Theblob graphin thefigureexpressesthefactthatblob1splitintoblobs4and5,blob2and\\npart of blob 1 merged to form blob 4, blob 3 disappeared, and\\nblob 6 appeared.\\nThe process of blob tracking is equivalent to computing\\nfor , where is the total number of frames.\\nLet denote the set of neighbors of vertex\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1270 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\nFig. 4. Overlap area. Pedestrians /112and /112share blob /98while /98is only part of /112(see Section III-B3 for overlap area computation).\\n. To simplify the graph computation,\\nwewillrestrictthegeneralityofthegraphtothosegraphswhich\\ndo not have more than one vertex of degree more than one in\\nevery connected component of the graph. This is equivalentto saying that from one frame to the next, a blob may not\\nparticipate in a splitting and a merging at the same time. We\\nrefer to this as the parent structure constraint . According to\\nthis constraint, the graph in Fig. 3(c) is invalid. If, however,\\nwe eliminate the arc between 1 and 5 or the arc between 2and 4, it will be a valid graph. This restriction is reasonable\\nassuming a high frame rate where such simultaneous split\\nand merge occurrences are rare. To further reduce the numberof possible graphs, we use another constraint which we call\\nthelocality constraint . With this constraint, vertices can be\\nconnected only if their corresponding blobs have a bounding\\nbox overlap area which is at least half the size of the bounding\\nbox of the smaller blob. This constraint, which significantlyreduces possible graphs, relies on the assumption that a blob\\nis not expected to be too far from where it is predicted to\\nbe, taking into con', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 135: ('t\\nand merge occurrences are rare. To further reduce the numberof possible graphs, we use another constraint which we call\\nthelocality constraint . With this constraint, vertices can be\\nconnected only if their corresponding blobs have a bounding\\nbox overlap area which is at least half the size of the bounding\\nbox of the smaller blob. This constraint, which significantlyreduces possible graphs, relies on the assumption that a blob\\nis not expected to be too far from where it is predicted to\\nbe, taking into consideration its speed and location in the\\nprevious frame. This is also reasonable to assume if we have a\\nrelatively high frame rate. We refer to a graph which satisfiesboth the parent structure and locality constraints as a valid\\ngraph.\\nTofind theoptimum\\n, wedefineacost function so\\nthat different graphs can be compared. A graph with no edges,i.e.,\\n, is one extreme solution in which all blobs in\\ndisappear and all blobs in appear. This solution has no as-\\nsociation among blobs and should, therefore, have a high cost.\\nIn order to proceed with our formulation of the cost function,we define two disjoint sets, which we call parents,\\n, andde-\\nscendents ,, whose union is such that .\\ncan be easily constructed by selecting from all vertices\\nofdegreemorethanone,allverticesofdegreezero,andallver-ticesofdegreeonethatareonlyin\\n.Furthermore,let\\nbethetotalareaoccupiedbytheneighborsof .\\nThe cost function that we use penalizes graphs in which blobs\\nchange significantly in size. A perfect match would be one inwhich blob sizes remain constant (e.g., the size of a blob thatsplitsequals tothe sumof thesizesof blobsit split into). Wenow write the formula for the cost function as\\n(1)\\nThis function is a summation of ratios of size change over all\\nparent blobs.\\nUsing this cost function, we can proceed to compute the op-\\ntimum graph. First, we notice that given a valid graph\\nand two vertices such that , the graph\\nhas a lower cost than provided\\nthatis a valid graph. If it is not possible to find such a ,\\nwecall dense.Usingthisproperty,weca', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 136: ('main constant (e.g., the size of a blob thatsplitsequals tothe sumof thesizesof blobsit split into). Wenow write the formula for the cost function as\\n(1)\\nThis function is a summation of ratios of size change over all\\nparent blobs.\\nUsing this cost function, we can proceed to compute the op-\\ntimum graph. First, we notice that given a valid graph\\nand two vertices such that , the graph\\nhas a lower cost than provided\\nthatis a valid graph. If it is not possible to find such a ,\\nwecall dense.Usingthisproperty,wecanavoidsomeuseless\\nenumeration of graphs that are not dense. In fact, this observa-tion is thebasis of our algorithmto compute the optimum\\n.\\nOuralgorithmtocomputetheoptimumgraphworksasfollows:\\nAgraph isconstructedsuchthattheadditionofanyedgeto\\nmakesitviolatethelocalityconstraint.Therecanbeonlyonesuch\\ngraph.Notethat mayviolatetheparentstructureconstraintsat\\nthismoment.Thenextstepinouralgorithmsystematicallyelimi-\\nnatesjustenoughedgesfrom tomakeitsatisfytheparentstruc-\\ntureconstraint.Theresultinggraphisvalidandalsodense.Theprocess is repeated so that all possible dense graphs are gener-ated.Theoptimumgraphistheonewiththeminimumcost.By\\nsystematicallyeliminatingedges,weareeffectivelyenumerating\\nvalidgraphs.Thecomputationalcomplexityofthisstepishighlydependentonthegraphbeingconsidered.Ifthegraphalreadysat-isfiestheparentstructureconstraint,itis\\n.Ontheotherhand,\\nifwehaveafullyconnectedgraph,thecomplexityisexponential\\ninthenumberofvertices.Fortunately,becauseofthelocalitycon-straintandthehighframerate,themajorityofgraphsconsideredalreadysatisfytheparentstructureconstrained.Occasionally,a\\nsmallclusterofthegraphmaynotsatisfytheparentstructurecon-\\nstraintandthealgorithmwillneedtoenumerateafewgraphs.Inpractice,thealgorithmnevertookmorethanafewmillisecondstoexecuteeveninthemostclutteredscenes.Othertechniquestofind\\ntheoptimum(ornearoptimum)graph(e.g.,stochasticrelaxation\\nusingsimulatedannealing)canalsobeused.Themainconcern,however,wouldbetheirefficiencywhichmaynotbeappropriateforthisreal-timeapplicationduetotheiriterativenat', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 137: ('aphsconsideredalreadysatisfytheparentstructureconstrained.Occasionally,a\\nsmallclusterofthegraphmaynotsatisfytheparentstructurecon-\\nstraintandthealgorithmwillneedtoenumerateafewgraphs.Inpractice,thealgorithmnevertookmorethanafewmillisecondstoexecuteeveninthemostclutteredscenes.Othertechniquestofind\\ntheoptimum(ornearoptimum)graph(e.g.,stochasticrelaxation\\nusingsimulatedannealing)canalsobeused.Themainconcern,however,wouldbetheirefficiencywhichmaynotbeappropriateforthisreal-timeapplicationduetotheiriterativenature.\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\nMASOUD AND PAPANIKOLOPOULOS: TRACKING AND COUNTING PEDESTRIANS IN REAL-TIME 1271\\n(a)\\nFig. 5. (a) A number of snapshots from the input sequence overlaid with pedestrian boxes shown in white and blob boxes shown in black.\\nAt the endof thisstage, weuse asimple method tocalculate\\nthe velocity of each blob based on the velocities of the blobs\\natthepreviousstageandthecomputedblobgraph.Theblobve-\\nlocity will be used to initialize pedestrian models as describedlater. If\\nis the outcome of a splitting operation, it will be as-\\nsigned the same velocityas the parentblob. If is the outcome\\nof a merging operation, it will be assigned the velocity of the\\nlargest child blob. If is a new blob, it will be assigned zero\\nvelocity. Finally, if there is only one blob, , related to , the\\nvelocity is computed as\\n(2)where\\nand centers of the bounding boxes of and,\\nrespectively;\\nweight factor set to 0.5 (foundempirically);\\nsampling interval since the last stage.\\nIII. PEDESTRIANS LEVEL\\nThe input to this level is tracked blobs and the output is the\\nspatio-temporalcoordinatesofeachpedestrian.Therelationship\\nbetween pedestrians and blobs in the image is not necessarily\\none to one. A pedestrian wearing clothes that are close in colortothebackgroundmayshowupasmorethanoneblob.Partiallyoccluded pedestrians may also result in more than one blob or\\nAuthorized licensed use limited to: Univ of Calif Davis.', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 138: (' set to 0.5 (foundempirically);\\nsampling interval since the last stage.\\nIII. PEDESTRIANS LEVEL\\nThe input to this level is tracked blobs and the output is the\\nspatio-temporalcoordinatesofeachpedestrian.Therelationship\\nbetween pedestrians and blobs in the image is not necessarily\\none to one. A pedestrian wearing clothes that are close in colortothebackgroundmayshowupasmorethanoneblob.Partiallyoccluded pedestrians may also result in more than one blob or\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1272 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\n(b)\\nFig. 5. ( Continued. ) (b)A number of snapshots fromthe input sequence overlaid withpedestrian boxes shown in white and blob boxesshown in black.\\neven in no blobs at all if the pedestrian is fully occluded. Two\\nor more pedestrians walking close to each other may give rise\\nto a single blob. For this reason, it was necessary to make thepedestrians level capable of handling all the above cases. Wedo this by modeling the pedestrian as a rectangular patch with\\na certain dynamic behavior. We found that for the purpose of\\ntracking,thissimplemodeladequatelyresemblesthepedestrianshapeandmotiondynamics.Wenowpresentthismodelinmoredetail and then describe how tracking is performed.\\nA. Pedestrian Model\\nPedestrians usually walk with a constant speed. Moreover,\\nthe speed of a pedestrian usually changes gradually whenthe pedestrian desires to stop or start walking. Our approach\\nassumes that motion in the scene is constrained to a plane(alsocalledtheground-planeconstraint).Withthisassumption,\\nback projection from the scene to the image plane can be\\nperformed (with the knowledge of the camera geometry) to\\ndetermine the expected dimensions and dynamic behavior of\\nthepedestrianintheimagecoordinatesystem.Smallvariations\\nin ground elevation will still be tolerated especially in distant\\nareas. This restriction can be removed if the scene topologycan be determined a pri', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 139: ('king. Our approach\\nassumes that motion in the scene is constrained to a plane(alsocalledtheground-planeconstraint).Withthisassumption,\\nback projection from the scene to the image plane can be\\nperformed (with the knowledge of the camera geometry) to\\ndetermine the expected dimensions and dynamic behavior of\\nthepedestrianintheimagecoordinatesystem.Smallvariations\\nin ground elevation will still be tolerated especially in distant\\nareas. This restriction can be removed if the scene topologycan be determined a priori. Camera geometry can be obtained\\nusing calibration techniques. A suitable technique for traffic\\nscenes which makes use of the ground-plane constraint is\\ngiven in [23].\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\nMASOUD AND PAPANIKOLOPOULOS: TRACKING AND COUNTING PEDESTRIANS IN REAL-TIME 1273\\nFig. 6. A number of snapshots from the input sequence in a snowy afternoon overlaid with pedestrian boxes shown in black.\\nThe pedestrian is modeled as a rectangular patch whose di-\\nmensions depend on its location in the image. The dimensionsareequalto theprojection of thedimensions ofan averagesizepedestrianatthecorrespondinglocationinthescene.Thepatch\\nis assumed to move with constant velocity in the scene coordi-\\nnate system. The patch acceleration is modeled as zero mean,Gaussian noise to accommodate for changes in velocity. Givenasamplinginterval\\n,thediscrete-timedynamicsystemforthepedestrian model can be described by thefollowing equation:\\n(3)\\nwhere\\nstatevectorconsistingofthepedestrian\\nlocation, and velocity, ;\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1274 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\nFig. 7. Tracking sequence of a pedestrian in different occlusion situations.\\ntransitionmatrixofthesystemgivenby\\n;\\nsequence of zero-mean, white,\\nGaussian process noise with covari-\\nance matrix .\\nden', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 140: ('hefollowing equation:\\n(3)\\nwhere\\nstatevectorconsistingofthepedestrian\\nlocation, and velocity, ;\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1274 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\nFig. 7. Tracking sequence of a pedestrian in different occlusion situations.\\ntransitionmatrixofthesystemgivenby\\n;\\nsequence of zero-mean, white,\\nGaussian process noise with covari-\\nance matrix .\\ndenotes the location of the pedestrian in the scene. is\\ncomputed as in [1] (p. 84) to become whereandrepresents the variance of the accel-\\neration.\\nB. Pedestrian Tracking\\nTracking pedestrians depends on the current state of pedes-\\ntrians as well as the input to pedestrians level which is the\\ntrackedblobs.Inoursystem,weuseextendedKalmanfiltering(EKF) to estimate pedestrian parameters. We maintain amany-to-many relationship between pedestrians and blobs and\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\nMASOUD AND PAPANIKOLOPOULOS: TRACKING AND COUNTING PEDESTRIANS IN REAL-TIME 1275\\nFig. 8. Tracking sequence demonstrating occlusions and pedestrian overlap.\\nthen use it to provide measurements to the filter. The next five\\nsections describe one tracking cycle.\\n1) RelatingPedestrianstoBlobs: Werepresenttherelation-\\nshipbetweenpedestriansandblobsasadirectedbipartitegraph.Werelatepedestrianstoblobsusingasimplerule:ifapedestrianwasrelatedtoablobinframe\\nandthatblobisrelatedto\\nanotherblobinthe thframe(throughasplit,merge,etc.),then\\nthe pedestrian is also related to the latter blob.\\n2) Prediction: Given the system equation as in Section\\nIII-A, theprediction phaseoftheKalmanfilterisgiven by the\\nfollowing equations:\\n(4)Here,andare the predicted state vector and state error co-\\nvariance matrix, respectively. andare the previously es-\\ntimated state vector and state error covariance matrix, respec-\\ntively.\\n3) CalculatingPedestrianPosition', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 141: ('wasrelatedtoablobinframe\\nandthatblobisrelatedto\\nanotherblobinthe thframe(throughasplit,merge,etc.),then\\nthe pedestrian is also related to the latter blob.\\n2) Prediction: Given the system equation as in Section\\nIII-A, theprediction phaseoftheKalmanfilterisgiven by the\\nfollowing equations:\\n(4)Here,andare the predicted state vector and state error co-\\nvariance matrix, respectively. andare the previously es-\\ntimated state vector and state error covariance matrix, respec-\\ntively.\\n3) CalculatingPedestrianPositions: Inthisstep,weusethe\\npredicted pedestrian locations as starting positions and we em-\\nploy a two-dimensional (2-D) search to locate the pedestrian.\\nThesearchattemptstofindthebestoverlapbetweenthepedes-trianpatchandtheblobsassignedtothepedestrian.Theoverlapcomputationtakesintoconsiderationthedensityoftheblobsas\\nwell as the possibility that a blob is shared by more than one\\npedestrian.Fig.4illustratesthiscomputation.The overlapareafor\\niscomputedas .\\nFor,theoverlapareais .Toper-\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1276 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\nformthesearch,weemployaheuristicsolutionusingrelaxation.\\nFirst,alargestepsizeischosen.Then,eachpedestrianismovedin all possible directions by the step size and the location (in-\\ncludingtheoriginallocation)whichmaximizestheoverlaparea\\nisrecorded.Allpedestrianlocationsarethenupdatedaccordingto the recorded locations. This completes one iteration. In eachfollowingiteration,thestepsizeisdecreased.Inourimplemen-\\ntation, we start with a step of 64 pixels and halve the step size\\nin each iteration until 1 pixel step size is reached.\\nThe resulting locations form the measurements that will be\\nfedbackintotheEKFtoproducethenewstateestimates.More-\\nover,weusetheoverlapareatoprovidefeedbackaboutthemea-\\nsurementconfidencebysettingthemeasurementerrorstandarddeviation,whichisdescribedbelow,tobeinverselyproportionaltotheratiooftheoverlaparea', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 142: ('completes one iteration. In eachfollowingiteration,thestepsizeisdecreased.Inourimplemen-\\ntation, we start with a step of 64 pixels and halve the step size\\nin each iteration until 1 pixel step size is reached.\\nThe resulting locations form the measurements that will be\\nfedbackintotheEKFtoproducethenewstateestimates.More-\\nover,weusetheoverlapareatoprovidefeedbackaboutthemea-\\nsurementconfidencebysettingthemeasurementerrorstandarddeviation,whichisdescribedbelow,tobeinverselyproportionaltotheratiooftheoverlapareatothepedestrianarea.Thatis,the\\nsmaller the overlap area, the less confident the measurement is\\nconsidered.\\n4) Estimation: A measurement is a location in the image\\ncoordinate system as computed in the previous section,\\n. Measurements are related to the state vector by\\n(5)\\nwhereis the measurement function and is a sequence of\\nzero-mean,white,Gaussianmeasurementnoisewithcovariance\\ngiven by . The measurement error standard devi-\\nationdepends on the overlap area computed in the previous\\nsection.Pedestrianlocationsareexpressedinworldcoordinates\\nresulting in being a nonlinear function which performs pro-\\njection into image coordinates. We let be the Jacobian of .\\nThe EKF state estimation equations become\\n(6)\\nwhere is the Kalman gain at .\\nThe estimated state vector isthe outcomeof the pedes-\\ntrians level. The dimensions of the pedestrian patch are com-\\nputed based on the estimated pedestrian location.\\n5) Refinement: At the end of this stage, we perform some\\nchecks to refine the pedestrian-blob relationships since pedes-trianshavebeenrelocated.Thesecanbesummarizedasfollows.\\n1) If the overlap area between a pedestrian and one of its\\nblobsbecomeslessthanacertainthreshold(apercentageof the size of both), it will no longer be considered be-longingtothispedestrian.Thisservesasthesplittingpro-\\ncedure when two pedestrians walk past each other. This\\nthreshold determines the degree of stickiness betweenblobs and pedestrians. In our experiments, a threshold of\\n10% gave the best tracking performance.\\n2) If the overlap area between', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 143: ('es-trianshavebeenrelocated.Thesecanbesummarizedasfollows.\\n1) If the overlap area between a pedestrian and one of its\\nblobsbecomeslessthanacertainthreshold(apercentageof the size of both), it will no longer be considered be-longingtothispedestrian.Thisservesasthesplittingpro-\\ncedure when two pedestrians walk past each other. This\\nthreshold determines the degree of stickiness betweenblobs and pedestrians. In our experiments, a threshold of\\n10% gave the best tracking performance.\\n2) If the overlap area between a pedestrian and a blob that\\ndoes not belong to any pedestrian becomes more thanthe threshold mentionedabove,the blob will beadded to\\nthepedestrianblobs.Thismakesthepedestrianreacquire\\nsome blobs that mayhavedisappeared due toocclusion.\\n3) Look for a cluster of blobs, which are not related to any\\npedestriansandwhoseageislargerthanathreshold(i.e.,\\nFig. 9. Computed rms errors fora pedestrian in the sequenceof Fig. 5.\\nhave been successfully tracked for a certain number offrames). A new pedestrian may be initialized only if itwill become sufficiently covered by the blobs cluster.\\nThe pedestrian is given an initial velocity equal to\\nthe average of the blobs velocities. This serves as theinitialization step. The requirement on the age helpsin reducing chances of unstable blobs being used to\\ninitialize pedestrians (for example, blobs resulting from\\ntree motion caused by wind and blobs due to noise). Athreshold of one second was sufficient in most cases.\\n4) Select one of the blobs which is already assigned one or\\nmore pedestrians but can accommodate more pedestrian\\npatches. Create a new pedestrian for this blob as in 3).This handles cases in which a group of people form onebig blob, which does not split. If we do not do this step,\\nonly one pedestrian would be assigned to this blob.\\nIV. E\\nXPERIMENTAL RESULTS\\nThe system was implemented on a Datacube MaxVideo 20\\nvideo processor, and a Datacube Max860 vector processor. It\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC ', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 144: ('re pedestrians but can accommodate more pedestrian\\npatches. Create a new pedestrian for this blob as in 3).This handles cases in which a group of people form onebig blob, which does not split. If we do not do this step,\\nonly one pedestrian would be assigned to this blob.\\nIV. E\\nXPERIMENTAL RESULTS\\nThe system was implemented on a Datacube MaxVideo 20\\nvideo processor, and a Datacube Max860 vector processor. It\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\nMASOUD AND PAPANIKOLOPOULOS: TRACKING AND COUNTING PEDESTRIANS IN REAL-TIME 1277\\nFig. 10. A number of snapshots from aweaving section tracking sequence (the vehicles in the twolanes closer to the edge of the highwayare tracked).\\nwaslaterportedtoa400-MHzPentiumPCequippedwithaC80\\nMatrox Genesis vision board.\\nThe system was tested on several indoor and outdoor image\\nsequences. Several outdoor sequences in different weather\\nconditions (sunny, cloudy, snow, etc.) have been used. In\\nmost cases, pedestrians were tracked correctly throughoutthe period they appeared in the scene. Scenarios includedpedestrians moving at a slow or very high speeds, partial and\\nfull occlusions, bicycles, and several pedestrian interactions.\\nInteractions between pedestrians included occlusion of oneanother, repeated merging and splitting of blobs correspondingto two or more pedestrians walking together, pedestrians\\nwalking past each other, and pedestrians meeting and then\\nwalking back in the direction they came from. The system hasa peak performance of 30 frames/s. In a relatively clutteredimage with about six pedestrians, the frame processing rate\\ndropped down to about 18 frames/s. Fig. 5 shows 16 snapshots\\nspanning a sequence of 8.4 s. The sequence demonstrates thesystem behavior against occlusions—both partial and full.The figure also demonstrates how the system works at the\\nblobs level. Blobs are shown by their black bounding boxes.\\nNoticehowtrackingispreserveddespitethelackofone-to-onecorresponde', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 145: ('on they came from. The system hasa peak performance of 30 frames/s. In a relatively clutteredimage with about six pedestrians, the frame processing rate\\ndropped down to about 18 frames/s. Fig. 5 shows 16 snapshots\\nspanning a sequence of 8.4 s. The sequence demonstrates thesystem behavior against occlusions—both partial and full.The figure also demonstrates how the system works at the\\nblobs level. Blobs are shown by their black bounding boxes.\\nNoticehowtrackingispreserveddespitethelackofone-to-onecorrespondence between blobs and pedestrians. Fig. 6 shows12 snapshots from a scene under different weather conditions.\\nThesnapshotsspanasequenceof35seconds.Amorecluttered\\nsequence is shown in Fig. 7. This sequence was taped during asnowstorm.Onecanseetheeffectofthewindonthetreewhichresulted in false blobs in the difference images (frames 36, 66,\\n104,140).Thesystemdealswiththissituationinseveralways.\\n1) If the blobs generated are too small, they are automati-\\ncally eliminated.\\n2) A blob is considered at the pedestrian level only if it is\\ntracked successfully for a certain period of time. This\\neliminates blobs that appear then disappear momentarily(such as most blobs that appear due to tree motion backand forth).\\n3) The system can be given information about the scene.\\nIn particular, the locations where pedestrians can be ex-pected to appear. Thus, the system will not instantiatepedestrian boxes except at these locations.\\nFig. 8 shows another tracking sequence which involves\\nmissing pedestrian blob information due to occlusion (frame32)andsimilarityofcolortothebackground(frame44).Italsoshowswhathappenswhentwopedestrianwalkpasteachother.\\nKalman filtering is essential here because it provides goodprediction when there is little or no data. The blob-pedestrianrelationship refinement procedures guarantee that the pedes-\\ntrian will be related to the correct blobs when data is available\\nagain.Fig.9showsthecomputedrootmeansquare(rms)errorsfor a pedestrians in the sequence of Fig. 5.\\nWealsoperformedapedestriancountingexperimentfora', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 146: ('usion (frame32)andsimilarityofcolortothebackground(frame44).Italsoshowswhathappenswhentwopedestrianwalkpasteachother.\\nKalman filtering is essential here because it provides goodprediction when there is little or no data. The blob-pedestrianrelationship refinement procedures guarantee that the pedes-\\ntrian will be related to the correct blobs when data is available\\nagain.Fig.9showsthecomputedrootmeansquare(rms)errorsfor a pedestrians in the sequence of Fig. 5.\\nWealsoperformedapedestriancountingexperimentforase-\\nquence of 12 min in which 124 pedestrians were counted man-\\nually.Thesystemgaveacountof130.Mostofthefailureswere\\nduetobicyclistswhoweredoublecountedbecausetheblobtheygenerated was closer to the size of two pedestrians.\\nThereareothercaseswherethesystemfailed.Thoseinclude\\nhighly crowded images. Also, when a pedestrian becomes to-\\ntallyoccludedbutthenreappearsatanunexpectedlocation,the\\npedestrianboxwilllosetrack.Shadowscastbypedestrianshowasblobsinthedifferenceimage.Whentheshadowsarenottoolarge,thesystemcanusuallyhandlethesituationbyconsidering\\ntheshadowblobpartofthepedestrian.However,largeshadows\\nareproblematicandtheycanbeconfusedaspedestrians.Partofourongoingresearchaddressesrobusthandlingoftheeffectsofshadows, which remains an open problem.\\nOverall,oursystemworkswellinavarietyofreal-worldcon-\\nditions. We feel that this is the major contribution and whatmakes our approach distinguishable from other approaches.\\nA. Other Applications: Monitoring Weaving Sections\\nTo demonstrate the versatility of our approach, we recently\\nused our system with slight modification to track vehicles. The\\nidea was to track vehicles in short weaving sections that have\\nmore than one point of entry, followed by more than one pointofexit.Sensorswhicharebasedonlanedetectionortrip-linede-tectionoftenfailtomonitorweavingsectionssincetheycannot\\ntrack vehicles which cross lanes. Our system was able to suc-\\ncessfullytrackandrecordthespeedofeachvehicle.Italsogaveperiodic averages of speeds of vehicles that belong to one ofseveralcategories.Th', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 147: (', we recently\\nused our system with slight modification to track vehicles. The\\nidea was to track vehicles in short weaving sections that have\\nmore than one point of entry, followed by more than one pointofexit.Sensorswhicharebasedonlanedetectionortrip-linede-tectionoftenfailtomonitorweavingsectionssincetheycannot\\ntrack vehicles which cross lanes. Our system was able to suc-\\ncessfullytrackandrecordthespeedofeachvehicle.Italsogaveperiodic averages of speeds of vehicles that belong to one ofseveralcategories.Thecategorieswereintheformof“vehicles\\nthatremainedinlane\\n”and“vehiclesthatchangedlanesfrom\\nto.” Example snapshots are given in Fig. 10.\\nV. CONCLUSION AND FUTURERESEARCH\\nWe presented a real-time model-based pedestrian tracking\\nsystem capable of working robustly under many difficult cir-\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. \\n1278 IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, VOL. 50, NO. 5, SEPTEMBER 2001\\ncumstancessuchasocclusionsandambiguities.Foreachpedes-\\ntrianintheviewofthecamera,thesystemproduceslocationandvelocity information as long as the pedestrian is visible. This\\ndatacanbeusedbyaschedulingalgorithmtocontrolwalksig-\\nnals at an intersection in order to increase the safety and effi-ciency of existing traffic systems.\\nThereareseveralissuesthatstillneedtobeaddressed.Spatial\\ninterpretation of blobs is one such issue. In the current system,\\ntheonlyspatialattributeofblobstakenintoconsiderationistheblobarea.Theshapeoftheblobcangiveagoodclueonitscon-tents. Although blobs obtained from difference images can be\\nsufficient to decide the location of pedestrians in many cases,\\nthe intensity information may be useful to resolve certain am-biguities. The use of such information in the form of statisticaldistribution of intensities may add to the robustness of the cur-\\nrent system and is worth pursuing.\\nIn its current state, our system assumes that all the objects\\nin the scene are pedestrians. This means that if another ob', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 148: ('hapeoftheblobcangiveagoodclueonitscon-tents. Although blobs obtained from difference images can be\\nsufficient to decide the location of pedestrians in many cases,\\nthe intensity information may be useful to resolve certain am-biguities. The use of such information in the form of statisticaldistribution of intensities may add to the robustness of the cur-\\nrent system and is worth pursuing.\\nIn its current state, our system assumes that all the objects\\nin the scene are pedestrians. This means that if another object(such as a vehicle) comes into the scene, it will be tracked as\\na pedestrian (or a group of pedestrians). The problem is cur-\\nrentlyhandledbyperformingsimpleclassificationbasedonthelocationandthedirectionofmotionoftheobjectbeingtracked.Furtherworkisinprogresstoclassifypedestriansandvehicles.\\nA\\nCKNOWLEDGMENT\\nTheauthorswouldliketothanktheanonymousreviewersfor\\ntheir thoughtful comments.\\nREFERENCES\\n[1] Y. Bar-Shalom and T. E. Fortmann, Tracking and Data Associa-\\ntion. New York: Academic, 1988.\\n[2] A. Baumberg and D. Hogg, “Learning flexible models from image se-\\nquences,”in Proc.Eur.Conf.ComputerVision ,vol.1,Berlin,Germany,\\nMay 1994, pp. 229–308.\\n[3] , “An efficient method for contour tracking using active shape\\nmodels,” Proc. IEEE Workshop Motion of Nonrigid and Articulated\\nObjects, pp. 194–199, Nov. 1994.\\n[4] Q. Cai and J. K. Aggarwal, “Tracking human motion using multiple\\ncameras,” in Proc. 13th Int. Conf. Pattern Recognition , Los Alamitos,\\nCA, Aug. 1996, pp. 68–72.\\n[5] E. R. Davies, Machine Vision: Theory, Algorithms, Practicalities , 2nd\\ned. New York: Academic, 1997.\\n[6] D. M. Gavrila and L. S. Davis, “3-D model-based tracking of humans\\nin action: A multi-view approach,” Proc. IEEE Conf. Computer Vision\\nand Pattern Recognition , pp. 73–80, June 1996.\\n[7] I. Haritaoglu, D. Harwood, and L. S. Davis, “ /87: Real-time surveil-\\nlance of people and their activities,” IEEE Trans. Pattern Anal. Mach.\\nIntell., vol. 22, pp. 809–830, Aug. 2000.\\n[8] B. Heisele, U. Kressel, and W. Ritter, “Tracking nonrigid, moving o', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 149: ('ry, Algorithms, Practicalities , 2nd\\ned. New York: Academic, 1997.\\n[6] D. M. Gavrila and L. S. Davis, “3-D model-based tracking of humans\\nin action: A multi-view approach,” Proc. IEEE Conf. Computer Vision\\nand Pattern Recognition , pp. 73–80, June 1996.\\n[7] I. Haritaoglu, D. Harwood, and L. S. Davis, “ /87: Real-time surveil-\\nlance of people and their activities,” IEEE Trans. Pattern Anal. Mach.\\nIntell., vol. 22, pp. 809–830, Aug. 2000.\\n[8] B. Heisele, U. Kressel, and W. Ritter, “Tracking nonrigid, moving ob-\\njects based on color cluster flow,” Proc. IEEE Conf. Computer Vision\\nand Pattern Recognition , pp. 257–260, June 1997.\\n[9] B. Heisele and C. Wohler, “Motion-based recognition of pedestrians,”\\ninProc.14thInt.Conf.PatternRecognition ,vol.2,Brisbane,Qld,Aus-\\ntralia, Aug. 1998, pp. 1325–1330.\\n[10] R.Hosie,S.Venkatesh,andG.West,“Detectingdeviationsfromknown\\npathsandspeedsinasurveillancesituation,”in Proc.4thInt.Conf.Con-\\ntrol,Automation, Robotics,and Vision , Singapore, Dec.1996,pp. 3–6.\\n[11] R. Jain, D. Militzer, and H. H. Nagel, “Separating nonstationary from\\nstationary scene components in a sequence of real-world TV images,”\\ninProc. Int. Joint Conf. Artificial Intelligence , Cambridge, MA, Aug.\\n1977, pp. 612–618.\\n[12] N. Johnson and D. Hogg, “Learning the distribution of object trajecto-\\nries for event recognition,” ImageVision Computing , vol. 14, no. 8, pp.\\n609–615, Aug. 1996.[13] I. A. Kakadiaris and D. Metaxas, “3-D human body model acquisition\\nfrom multiple views,” in Proc. 5th Int. Conf. Computer Vision , Boston,\\nMA, June 1995, pp. 618–623.\\n[14] A. Lipton, H. Fujiyoshi, and R. Patil, “Moving target classification and\\ntracking from real-time video,” Proc. IEEE Workshop Application of\\nComputer Vision , Oct. 1998.\\n[15] J. R. Parker, “Gray level thresholding in badly illuminated images,”\\nIEEE Trans. Pattern Anal. Mach. Intell. , vol. 13, pp. 813–819, Aug.\\n1991.\\n[16] K. Rohr, “Toward model-based recognition of human movements in\\nimage sequences,” CVGIP: Image Understanding , vol. 59, pp. 94–115,\\nJan. 1994.\\n[1', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 150: ('n , Boston,\\nMA, June 1995, pp. 618–623.\\n[14] A. Lipton, H. Fujiyoshi, and R. Patil, “Moving target classification and\\ntracking from real-time video,” Proc. IEEE Workshop Application of\\nComputer Vision , Oct. 1998.\\n[15] J. R. Parker, “Gray level thresholding in badly illuminated images,”\\nIEEE Trans. Pattern Anal. Mach. Intell. , vol. 13, pp. 813–819, Aug.\\n1991.\\n[16] K. Rohr, “Toward model-based recognition of human movements in\\nimage sequences,” CVGIP: Image Understanding , vol. 59, pp. 94–115,\\nJan. 1994.\\n[17] M.RossiandA.Bozzoli,“Trackingandcountingmovingpeople,” Proc.\\n2nd IEEE Int. Conf. ImageProcessing , pp. 212–216, Nov. 1994.\\n[18] P. K. Sahoo, S. Soltani, and A. K. C. Wong, “A survey of thresholding\\ntechniques,” Computer Vision Graphics Image Processing , vol. 41, pp.\\n233–260, 1988.\\n[19] J. Segen and S. Pingali, “A camera-basedsystem fortracking people in\\nreal time,” in Proc. 13th Int. Conf. Pattern Recognition , Los Alamitos,\\nCA, Aug. 1996, pp. 63–67.\\n[20] A. Shio and J. Sklansky, “Segmentation of people in motion,” Proc.\\nIEEE Workshop Visual Motion , pp. 325–332, Oct. 1991.\\n[21] K.SkiestadandR.Jain,“Illuminationindependentchangedetectionfor\\nreal world image sequences,” Computer Vision Graphics Image Pro-\\ncessing, vol. 46, pp. 387–399, 1989.\\n[22] C. Smith, C. Richards, S. A. Brandt, and N. P. Papanikolopoulos, “Vi-\\nsualtrackingforintelligentvehicle-highwaysystems,” IEEETrans.Veh.\\nTechnol., vol. 45, pp. 744–759, Nov. 1996.\\n[23] A. D. Worral, G. D. Sullivan, and K. D. Baker, “A simple, intuitive\\ncameracalibrationtoolfornaturalimages,”in Proc.5thBritishMachine\\nVision Conf. , vol. 2, York, U.K., Sept. 1994, pp. 781–790.\\n[24] C. R. Wren, A. Azarbayejani, T. Darrell, and A. Pentland, “Pfinder:\\nReal-time tracking of the human body,” in Proc. 2nd Int. Conf. Auto-\\nmaticFaceandGestureRecognition ,LosAlamitos,CA,Oct.1996,pp.\\n51–56.\\nOsama Masoud was born in Riyadh, Saudi Arabia, in 1971. He received the\\nB.S. and M.S. degrees in computer science from King Fahd University of Pe-\\ntroleum and Minerals (KFUPM), Dhahran, Saud', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 151: ('ationtoolfornaturalimages,”in Proc.5thBritishMachine\\nVision Conf. , vol. 2, York, U.K., Sept. 1994, pp. 781–790.\\n[24] C. R. Wren, A. Azarbayejani, T. Darrell, and A. Pentland, “Pfinder:\\nReal-time tracking of the human body,” in Proc. 2nd Int. Conf. Auto-\\nmaticFaceandGestureRecognition ,LosAlamitos,CA,Oct.1996,pp.\\n51–56.\\nOsama Masoud was born in Riyadh, Saudi Arabia, in 1971. He received the\\nB.S. and M.S. degrees in computer science from King Fahd University of Pe-\\ntroleum and Minerals (KFUPM), Dhahran, Saudi Arabia, in 1992 and 1994,\\nrespectively, and the Ph.D. degree in computer science from the University of\\nMinnesota, Minneapolis, in 2000.\\nHe is currently the Director of Research and Development at Point Cloud\\nInc.,Plymouth,MN,andaPostdoctoralAssociatewiththeDepartmentofCom-\\nputerScienceand Engineering,UniversityofMinnesota.Hisresearchinterestsinclude computer vision, robotics, transportation applications, and computer\\ngraphics.\\nDr.Masoudisa recipientof the ResearchContribution Awardfromthe Uni-\\nversity of Minnesota, the Rosemount Instrumentation Award from Rosemount\\nInc.,and the MattHuber Awardfor Excellence in Transportation Research.\\nNikolaos P. Papanikolopoulos (S’88–M’93–SM’01) was born in Piraeus,\\nGreece, in 1964. He received the Diploma degree in electrical and computer\\nengineeringfromtheNationalTechnicalUniversityofAthens,Athens,Greece,\\nin 1987, the M.S.E.E. degree in electrical engineering from Carnegie Mellon\\nUniversity (CMU), Pittsburgh, PA, in 1988, and the Ph.D. degree in electrical\\nand computer engineering from Carnegie Mellon University, Pittsburgh, PA,\\nin 1992.\\nCurrently,heisaProfessorintheDepartmentofComputerScienceandEngi-\\nneering,UniversityofMinnesota,Minneapolis.HewasaMcKnightLand-Grant\\nProfessorattheUniversityofMinnesotafrom1995to1997.Hehasauthoredor\\ncoauthoredmorethan100journalandconferencepapersintheareasofrobotics,\\nsensors for transportation applications, control, and computer vision (30 ref-\\nereedjournalpapers).Hisresearchinterestsincluderobotics,sensorsfortrans-\\nportation applications', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 152: (' engineering from Carnegie Mellon University, Pittsburgh, PA,\\nin 1992.\\nCurrently,heisaProfessorintheDepartmentofComputerScienceandEngi-\\nneering,UniversityofMinnesota,Minneapolis.HewasaMcKnightLand-Grant\\nProfessorattheUniversityofMinnesotafrom1995to1997.Hehasauthoredor\\ncoauthoredmorethan100journalandconferencepapersintheareasofrobotics,\\nsensors for transportation applications, control, and computer vision (30 ref-\\nereedjournalpapers).Hisresearchinterestsincluderobotics,sensorsfortrans-\\nportation applications, control, and computer vision.\\nDr.PapanikolopouloswasafinalistfortheAntonPhilipsAwardforBestStu-\\ndent Paper in the 1991 IEEE Robotics and Automation Conference. He wasrecipient ofthe KritskiFellowshipin1986 and 1987 and receivedthe NSFRe-\\nsearch Initiation and Early Career Development Awards. He has also received\\ngrants from DARPA, Sandia National Laboratories, NSF, USDOT, MN/DOT,\\nHoneywell, and 3M.\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:03:26 UTC from IEEE Xplore.  Restrictions apply. ', 'A_novel_method_for_tracking_and_counting_pedestrians_in_real-time_using_a_single_camera.pdf'), 153: ('A novel method to look for the hysteresis thresholds for the Canny\\nedge detector\\nR. Medina-Carnicer/C3, R. Mun ˜oz-Salinas, E. Yeguas-Bolivar, L. Diaz-Mas\\nDepartment of Computing and Numerical Analysis, Cordoba University, 14071 Cordoba, Spain\\narticle info\\nArticle history:\\nReceived 27 July 2010Received in revised form20 November 2010Accepted 10 December 2010\\nAvailable online 17 December 2010\\nKeywords:\\nCanny edge detector\\nHysteresis thresholdsabstract\\nIn the last few years, several works have been proposed to solve the problem of determining the hysteresis\\nthresholds in an unsupervised way. In this paper, a novel method to solve this problem is proposed. Givena set of candidates for hysteresis thresholds, the basic idea of the proposed method is to combine gradient\\ninformation with information obtained when the linking process is applied to all candidates. Using the\\nsame dataset and the same evaluation methodology already proposed by other works, the resultsobtained by our method show a performance better than that of the previous methods. The resultsobtained by the proposed method have been validated only for the Canny edge detector, but there are no\\nrestrictions on applying the proposed method to any other edge detector whose strategy is based on the\\nhysteresis mechanism.\\n&2010 Elsevier Ltd. All rights reserved.\\n1. Introduction\\nEdge detection is a well-established area of image processing. The\\nfeature extraction process and the criterion to determine the ﬁnal\\nedge map by using the features selected are the more important\\nquestions for edge detection. The ﬁrst works on the feature extrac-\\ntion process are based on a convolution of the image with a given\\noperator [1,2] followed by a thresholding of the feature image [3]so\\nas to obtain an edge map. After, Marr and Hildreth [4]and Canny [5]\\nintroduced more complex methods. In the last years many edge\\ndetection methods have been proposed. Wavelet ﬁltering [6,7] ,\\nneural networks [8],s t a t i s t i c s [9],r u l eb a s e s [10], fuzzy concepts\\n[11] are different appr', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 154: ('e important\\nquestions for edge detection. The ﬁrst works on the feature extrac-\\ntion process are based on a convolution of the image with a given\\noperator [1,2] followed by a thresholding of the feature image [3]so\\nas to obtain an edge map. After, Marr and Hildreth [4]and Canny [5]\\nintroduced more complex methods. In the last years many edge\\ndetection methods have been proposed. Wavelet ﬁltering [6,7] ,\\nneural networks [8],s t a t i s t i c s [9],r u l eb a s e s [10], fuzzy concepts\\n[11] are different approximations used for this objective.\\nA methodology based on the comparison with reference images\\nhas been most often used to analyze the performance of edge\\ndetection methods. Many works on edge detection have used the\\nCanny edge detector to build the reference images (by using a\\nsupervised procedure to determine the parameters values) and\\ncurrently this methodology is still being used [12,13] . This is\\nbecause there is a consensus in the scientiﬁc community about the\\nsuperior performance of the Canny edge detector. So, why not using\\nthe Canny edge detector, instead of other methods, for unsuper-\\nvised edge detection? The reason is that the unsupervised deter-\\nmination of the optimal values for the Canny parameters is not\\ntrivial. Therefore, new unsupervised edge detection methods have\\nbeen proposed [14–16] .\\nThis work proposes a novel method for automatic determina-\\ntion of Canny’s hysteresis thresholds so that it can be used as anunsupervised edge detector. Notice that is not our aim to propose a\\nnew edge detection method but to enable the use of the well-tested\\nCanny method in an unsupervised manner.\\nThe remainder of this paper is structured as follows. Section 1.1\\ndiscusses related previous methods with this objective, Section 2\\ndescribes our method and Section 3 discusses its performance\\nwhen compared with the related methods. Finally, Section 4\\nsummarizes the main conclusions.\\n1.1. Related works\\nThe Canny edge detector [5]is based on the hysteresis concept;\\nit primarily consists of determining a high thres', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 155: ('tection method but to enable the use of the well-tested\\nCanny method in an unsupervised manner.\\nThe remainder of this paper is structured as follows. Section 1.1\\ndiscusses related previous methods with this objective, Section 2\\ndescribes our method and Section 3 discusses its performance\\nwhen compared with the related methods. Finally, Section 4\\nsummarizes the main conclusions.\\n1.1. Related works\\nThe Canny edge detector [5]is based on the hysteresis concept;\\nit primarily consists of determining a high threshold that allows a\\ngroup of pixels to be classiﬁed as edge points without usinginformation about their connectivity. A low threshold then deter-\\nmines which pixels will not be edge points and permits only those\\npoints that increase the connectivity of the previously determined\\nedge points to be aggregated as edge points. The hysteresis process\\nuses spatial information and thus is a better method than thresh-\\nolding for edge detection.\\nHowever, how to look for the two hysteresis thresholds in an\\nunsupervised process is not an easy problem. To make the manual\\ndetermination of hysteresis thresholds easier, several solutions\\nhave been proposed. Two different strategies are oriented toward\\nsolving this objective: (1) to propose a feature image in order to\\ndetermine the hysteresis thresholds more easily than on the\\ngradient image [9]and (2) to propose an automatic method to\\ndetermine a set of candidates for hysteresis thresholds on the\\ngradient image [19]. However these methods do not solve the\\ndetermination of hysteresis thresholds in an unsupervised way.Contents lists available at ScienceDirect\\njournal homepage: www.elsevier.com/locate/prPattern Recognition\\n0031-3203/$ - see front matter &2010 Elsevier Ltd. All rights reserved.\\ndoi:10.1016/j.patcog.2010.12.008/C3Corresponding author. Tel.: +34 957 21 83 46; fax: +34 957 21 86 30.\\nE-mail address: rmedina@uco.es (R. Medina-Carnicer).Pattern Recognition 44 (2011) 1201–1211\\nThe proposal of Hancock and Kittler [20] was the ﬁrst to\\ndetermine the hysteresis thresholds in ', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 156: ('teresis thresholds in an unsupervised way.Contents lists available at ScienceDirect\\njournal homepage: www.elsevier.com/locate/prPattern Recognition\\n0031-3203/$ - see front matter &2010 Elsevier Ltd. All rights reserved.\\ndoi:10.1016/j.patcog.2010.12.008/C3Corresponding author. Tel.: +34 957 21 83 46; fax: +34 957 21 86 30.\\nE-mail address: rmedina@uco.es (R. Medina-Carnicer).Pattern Recognition 44 (2011) 1201–1211\\nThe proposal of Hancock and Kittler [20] was the ﬁrst to\\ndetermine the hysteresis thresholds in an unsupervised way. This\\nmethod is a probabilistic approach in a Bayesian context; it\\nassumes that the hysteresis thresholds can be related to the\\nparameters of an image model and that the parameters of the\\nimage model can be estimated from image statistics. Unfortu-\\nnately, this proposal requires us to know the value of a parameter\\n(the proportion between the value of the low threshold and the\\nvalue of the high threshold Thigh =Tlow), and estimating this propor-\\ntion is not easy. Therefore, this method cannot be considered a fully\\nautomatic method [21]. More details on this method and its\\nperformance are shown in [21].\\nIn a recent paper, Yitzhaky and Peli [22] propose a method for\\nselecting the best edge detector parameters. Their method basically\\nconsists of constructing an EGT (estimated ground truth) using\\ndifferent detection results and determining the best parameter set\\nby means of a Chi-square test. Thus, if a candidates set for hysteresis\\nthresholds is known (for example, by using the method proposed in\\n[19]), this method is a fully unsupervised method. More details on\\nthis method and its performance are shown in [21,23] .\\nTwo recent methods [21,23] have been proposed, and the\\nperformance of both methods has been compared with respect\\nto the performance of the Yitzhaky and Peli method [22].\\nThe basic ideas of these two methods are very different:\\n(1) Give an image I,i n[23] is assumed that it is possible to ﬁnd an\\noverset Oset(I) and a subset Sset(I) (two edge maps) of the\\nunknown set of edge points Et', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 157: (' in\\n[19]), this method is a fully unsupervised method. More details on\\nthis method and its performance are shown in [21,23] .\\nTwo recent methods [21,23] have been proposed, and the\\nperformance of both methods has been compared with respect\\nto the performance of the Yitzhaky and Peli method [22].\\nThe basic ideas of these two methods are very different:\\n(1) Give an image I,i n[23] is assumed that it is possible to ﬁnd an\\noverset Oset(I) and a subset Sset(I) (two edge maps) of the\\nunknown set of edge points Etrue(I). Then, using a measure\\nbased on the measure w2, the hysteresis thresholds are\\ndetermined while considering that the ﬁnal edge map should\\nbe between the overset and the subset already determined\\n(more details on this method can be found in [23]).\\nTo apply this method, an overset and a subset are needed, and\\nthe performance of the method is dependent on this choice\\n[23]. However, by using on the histogram of the gradient image\\nG(I) the thresholding methods proposed by Otsu [3]and Rosin\\n[14] to obtain the subset and the superset, respectively, the\\nperformance of this method is shown to be better [23] than the\\nperformance of the Yitzhaky and Peli method. Also, it has been\\nshown that the computational complexity of this method is\\nsmaller than that of the Yitzhaky and Peli method.\\n(2) In [21], it is assumed that, by using a set with a large enough\\nnumber of candidates for hysteresis thresholds, the additional\\ntimes that each pixel is added when carrying out hysteresis by\\nusing all candidates will cause the information to be more\\nrelevant in determining a good result in edge detection.\\nTherefore, the set of edge maps\\nHCðIÞ¼fDGlow ,highðIÞ,ðlow ,highÞACðIÞg\\n(see Eq. (1)) is used, where C(I) is the set of candidates for the image\\nI,G(I) is the gradient image, Glow,high(I) is the edge map obtained by\\nthe hysteresis process and Ghigh(I) is the edge map obtained by\\nthresholding the gradient image G(I) with the high threshold.\\nDGlow ,highðIÞ¼Glow ,highðIÞ/C0GhighðIÞð 1Þ\\nThen, the authors show that the histogram of th', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 158: ('nformation to be more\\nrelevant in determining a good result in edge detection.\\nTherefore, the set of edge maps\\nHCðIÞ¼fDGlow ,highðIÞ,ðlow ,highÞACðIÞg\\n(see Eq. (1)) is used, where C(I) is the set of candidates for the image\\nI,G(I) is the gradient image, Glow,high(I) is the edge map obtained by\\nthe hysteresis process and Ghigh(I) is the edge map obtained by\\nthresholding the gradient image G(I) with the high threshold.\\nDGlow ,highðIÞ¼Glow ,highðIÞ/C0GhighðIÞð 1Þ\\nThen, the authors show that the histogram of the image SM HCðIÞ(see\\nEq. (2)) is a unimodal histogram and, by using a speciﬁc unimodal\\nthresholding method, the edge map HystSM HCðIÞis obtained.\\nSM HCðIÞ¼X\\nðlow ,highÞACðIÞDGlow ,highðIÞð 2Þ\\nBy thresholding the gradient image while increasing the\\nthreshold, the authors ﬁnd the ﬁrst edge map satisfying\\nGthðIÞ/C2HystSM HCðIÞ¼0Edge, where all pixels of the edge map 0 Edge\\nhave a gray level of zero, and ﬁnally, the edge map Edge Proposed (I)\\n( s e eE q .( 3 ) )i sp r o p o s e da st h er e sult is more approximate to thatobtained by using the hysteresis process.\\nEdgeProposed ðIÞ¼HystSM HCðIÞþGthðIÞð 3Þ\\nTo apply this method, a unimodal thresholding method should be\\nused; then the results will be dependent on this choice. However,\\nby using the thresholding method proposed by Rosin [14] on the\\nhistogram of the image SM HCðIÞ, the performance of this method is\\nbetter than that of the Yitzhaky and Peli method [21].A l s o ,i th a s\\nbeen shown that the computational complexity of this method is\\nsmaller than that of the Yitzhaky and Peli method.\\nFig. 1 shows the results obtained by the methods in [21,23] for\\nan image example used for experimenting with these two methods\\n(this image can be obtained in ftp://ﬁgmeatnt.csee.usf.edu/pub/\\nEdge_Comparison/images/results ).\\nIn our opinion both methods [21,23] have advantages and\\ndisadvantages. The method proposed in [23] allows us to obtain\\nthe hysteresis thresholds while the method proposed in [21] only\\nallows us to obtain a result approximate to the result of the\\nhysteresis pr', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 159: ('e Yitzhaky and Peli method.\\nFig. 1 shows the results obtained by the methods in [21,23] for\\nan image example used for experimenting with these two methods\\n(this image can be obtained in ftp://ﬁgmeatnt.csee.usf.edu/pub/\\nEdge_Comparison/images/results ).\\nIn our opinion both methods [21,23] have advantages and\\ndisadvantages. The method proposed in [23] allows us to obtain\\nthe hysteresis thresholds while the method proposed in [21] only\\nallows us to obtain a result approximate to the result of the\\nhysteresis process —i.e., the hysteresis thresholds are not obtained\\n(this fact is the main disadvantage of this method). However, the\\ncomputational complexity of the method in [21] is smaller than\\nthe computational complexity of the method in [23] and this fact is\\nthe main advantage of the method in [21].\\nAdditionally, the basic idea in the method in [23] can be\\ngeneralized to solve other pattern recognition problems, while\\nthe basic idea in the method in [21] cannot be generalized thus.\\nTherefore, to summarize:\\n/C15The computational complexity of the methods [21,23] is smaller\\nthan that of the Yitzhaky and Peli method, and its performance is\\nbetter.\\n/C15The hysteresis thresholds are not determined by the method in [21].\\n/C15At present, there is no comparison between the performance of\\nthe methods in [21,23] .\\n2. Our method\\n2.1. Basic idea\\nThe hysteresis process can be summarized in two steps: (1) by\\nusing the hysteresis thresholds the set of edge points and the set of\\nnon-edge points are determined and (2) the pixels with gradient\\nlevels between both thresholds are classiﬁed by using the linking\\nprocess, and the ﬁnal edge map is determined. In this work we call\\nthe interval of gradient levels between both thresholds as the\\n‘‘instability zone.’’\\nPrevious proposals to determine the hysteresis thresholds\\n[19,20,22,23] have as their main strategy a direct determination\\nof the low and high thresholds, i.e., in these proposals the criterion\\nused is oriented to look for the hysteresis thresholds. The main idea\\nof our proposal is', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 160: ('th gradient\\nlevels between both thresholds are classiﬁed by using the linking\\nprocess, and the ﬁnal edge map is determined. In this work we call\\nthe interval of gradient levels between both thresholds as the\\n‘‘instability zone.’’\\nPrevious proposals to determine the hysteresis thresholds\\n[19,20,22,23] have as their main strategy a direct determination\\nof the low and high thresholds, i.e., in these proposals the criterion\\nused is oriented to look for the hysteresis thresholds. The main idea\\nof our proposal is different to this: to propose a strategy for a direct\\ndetermination of the ‘‘instability zone.’’ Obviously, by determining\\nthe hysteresis thresholds the instability zone is obtained, and\\nsimilarly, by determining the instability zone the hysteresis thresh-\\nolds are obtained; but notice that there is a subtle difference\\nbetween our idea and the idea of the previous methods, because\\nour criterion is oriented to look for the instability zone.\\nIn addition, in previous works on unsupervised determination of\\nthe hysteresis thresholds, only gradient information has been used[20,22,23] . On the other hand, Medina et al. [21] proposes to use the\\nnumber of times that a pixel is added by the hysteresis process as a\\nrelevant piece of information to determine the most similar edge\\nmap to the one obtained by Canny’s. Despite this method not being\\ncapable to obtain the hysteresis thresholds, it can however be used\\nto determine the instability zone as we show in this paper.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1202\\nThe main novelties of our method, with respect to previous\\nproposals, are: (1) it is oriented to look for the instability zone, (2) for\\nthis objective it uses a combination of gradient information and\\ninformation obtained by the linking process and (3) the hysteresis\\nthresholds are obtained from the previous fused information.\\nThe ideas behind the method for combining the different pieces\\nof information are:\\n/C15A pixel with a low value of gradient will have a low probability to be\\nan ', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 161: ('(2011) 1201–1211 1202\\nThe main novelties of our method, with respect to previous\\nproposals, are: (1) it is oriented to look for the instability zone, (2) for\\nthis objective it uses a combination of gradient information and\\ninformation obtained by the linking process and (3) the hysteresis\\nthresholds are obtained from the previous fused information.\\nThe ideas behind the method for combining the different pieces\\nof information are:\\n/C15A pixel with a low value of gradient will have a low probability to be\\nan edge point. Only if many pixels with the same gradient value\\nhave been added by the hysteresis process the probability of this\\ngradient value, to be a member of the instability zone, should incre-\\nase because the connectivity information is an indicator of this fact.\\n/C15A pixel with a high value of gradient will have a high probability tobe an edge point. If few pixels with the same gradient value have\\nbeen added by the hysteresis process the probability of these pixels\\nto be edge points should not decrease, but the probability of its\\ngradient value, to be a member of the instability zone, decreases.\\n/C15For a pixel with middle value of gradient the information ofadded pixels by the hysteresis process should be very relevant. If\\nmany pixels with the same middle value of gradient have been\\nadded by the hysteresis process the probability of this gradient\\nvalue, to be a member of the instability zone, increases.\\n2.2. The information used to determine the instability zone\\nLetIbe an image and G(I) an approximation of the gradient image\\nwith gray levels in the interval (0,1). Using only the histogram ( H\\nG(I))\\nof the image G(I) as information to detect edge points (see Fig. 2 )i sacomplex problem because this histogram is usually unimodal [14],\\ni.e., the threshold is hidden so that it is not easy to determine its\\noptimal value. To solve this proble m, unimodal thresholding techni-\\nques have been used [14,15,19] , but without considering the spatial\\ninformation. On the other hand, determining the hysteresis thresh-\\no', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 162: ('n of the gradient image\\nwith gray levels in the interval (0,1). Using only the histogram ( H\\nG(I))\\nof the image G(I) as information to detect edge points (see Fig. 2 )i sacomplex problem because this histogram is usually unimodal [14],\\ni.e., the threshold is hidden so that it is not easy to determine its\\noptimal value. To solve this proble m, unimodal thresholding techni-\\nques have been used [14,15,19] , but without considering the spatial\\ninformation. On the other hand, determining the hysteresis thresh-\\nolds in the gradient histogram is even a more complex problem\\nbecause of its two-dim ensional nature.\\nThen, to determine the hysteresis thresholds, we use a new\\ninformation obtained by combining the gradient information with\\nthe information from pixels added by the hysteresis process. Fig. 3\\nwill be used as an example to clarify the steps of our method.\\nLetC(I) be a set of possible hysteresis thresholds and let GC(I)be\\nthe set of edge maps corresponding to the set of candidates C(I). The\\ninformation from pixels added by the hysteresis process, when this\\nprocess is applied to all candidates, is considered as in [21],i . e . ,w e\\nconstruct the image SM HCðIÞ(see Eq. (2)). Notice that the histogram of\\nthe image SM HCðIÞis a unimodal histogram [21] and that the gray level\\nof each pixel in this image is the number of times that this pixel is\\nadded by using all candidates. Then, in the image ProbðSM HCðIÞÞ¼\\nSM HCðIÞ=jCðIÞj(jCðIÞjis the number of elements of the set C(I)), the gray\\nlevel of each pixel is the probability that each pixel will be added as\\nan edge point by using the hysteresis process. Fig. 3 (a) shows an\\nexample of the histogram of the image ProbðSM HCðIÞÞ(called the added\\nhistogram) and the histogram of the gradient image obtained for the\\nimage is shown in Fig. 1 (a).\\nLetProb xðSM HCðIÞÞbe the binary edge map obtained by thresh-\\nolding the image ProbðSM HCðIÞÞwith xAð0,1Þ. Let jProb xðSM HCðIÞÞjbe\\nthe number of pixels with gray level 1 in the edge map Prob x\\nðSM HCðIÞÞ. These pixels have a probability eq', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 163: ('ity that each pixel will be added as\\nan edge point by using the hysteresis process. Fig. 3 (a) shows an\\nexample of the histogram of the image ProbðSM HCðIÞÞ(called the added\\nhistogram) and the histogram of the gradient image obtained for the\\nimage is shown in Fig. 1 (a).\\nLetProb xðSM HCðIÞÞbe the binary edge map obtained by thresh-\\nolding the image ProbðSM HCðIÞÞwith xAð0,1Þ. Let jProb xðSM HCðIÞÞjbe\\nthe number of pixels with gray level 1 in the edge map Prob x\\nðSM HCðIÞÞ. These pixels have a probability equal or greater than xof\\nbeing added by the hysteresis process.\\nFig. 1. Results obtained by the two methods cited. The reference image has been obtained with the Canny edge detector by using the best parameters values for th is image [24]\\n(s¼0:6, low threshold 0.039, high threshold 0.091). (a) Original image. (b) Reference image. (c) Proposed method in [21]. (d) Proposed method in [23].R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1203\\nLetFIðxÞ¼GðIÞ3Prob xðSM HCðIÞÞbe with xAð0,1Þ(3is the Hadamard\\nproduct). Notice that for each xvalue FI(x) is an image and\\nnotice that a pixel qwith gray level qG(I)in the gradient image\\nG(I) and with a probability equal to or greater than xof being addedby the hysteresis process (pixel with gray level 1 in the edge\\nmap Prob xðSM HCðIÞÞ) has gray level qG(I)in the image FI(x). If this\\npixel has a probability smaller than xof being added by\\nthe hysteresis process, it has gray level zero in the image FI(x). 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7\\n00.10.20.30.40.50.60.70.80.9 1Probability\\nGray Level 0 0.01 0.02 0.03 0.04 0.05 0.06\\n0.05 0.1 0.15 0.2 0.25 0.3Probability\\nGray LevelGradient histogram Gradient histogram\\nFig. 2. An example of the gradient histogram information. The approximation to the gradient image was obtained by smoothing the input image using a Gaussian k ernel with\\ns¼0:6, derivating using the ﬁrst difference operator ( /C01,0,1) and performing non-maxima suppression. (a) Histogram of the gradient image for Fig. 1 (a). (b) A detail of the\\nhistogram in (a).', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 164: ('0.80.9 1Probability\\nGray Level 0 0.01 0.02 0.03 0.04 0.05 0.06\\n0.05 0.1 0.15 0.2 0.25 0.3Probability\\nGray LevelGradient histogram Gradient histogram\\nFig. 2. An example of the gradient histogram information. The approximation to the gradient image was obtained by smoothing the input image using a Gaussian k ernel with\\ns¼0:6, derivating using the ﬁrst difference operator ( /C01,0,1) and performing non-maxima suppression. (a) Histogram of the gradient image for Fig. 1 (a). (b) A detail of the\\nhistogram in (a).\\n 0 0.01 0.02 0.03 0.04 0.05 0.06\\n0.05 0.10.15 0.20.25 0.30.35 0.40.45 0.5Probability\\nGray LevelGradient histogram\\nAdded histogram\\n 0 0.05 0.1 0.15 0.2 0.25 0.3\\n0.02 0.04 0.06 0.08 0.1 0.12 0.14Probability\\nGray LevelConditioned Probability\\nProbability interesting zone\\n 0 0.05 0.1 0.15 0.2 0.25 0.3\\n0.02 0.04 0.06 0.08 0.1 0.12 0.14Probability\\nGray LevelGradient histogram\\nProbability interesting zone\\nFig. 3. An example of the choice of hysteresis thresholds, by determining the instability zone, for Fig. 1 (a). (a) Gradient histogram and histogram of the image ProbðSM HCðIÞÞ\\n(added histogram). (b) Histogram of P(FI(x)) (conditioned histogram) and the interesting zone in the histogram of ProbðSM HCðIÞÞ(probability interesting zone). (c) Gradient\\nhistogram and histogram of the probability interesting zone. (d) Edge map obtained for Fig. 1 (a)R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1204\\nLetjFIðxÞjbe the number of pixels with gray level xin the\\nimage FI(x).\\nWe construct PðFIðxÞÞ8xAð0,1Þas\\nPðFIðxÞÞ ¼jFIðxÞj\\njProb xðSM HCðIÞÞjjProb xðSM HCðIÞÞj40\\n0 jProb xðSM HCðIÞÞj ¼08\\n><\\n>:ð4Þ\\nThe value P(FI(x)) is the probability that a pixel has gradient level\\nxif it is a pixel with probability equal to or greater than xof being\\nadded. Fig. 3 (b) shows an example of the histogram of the\\ndistribution P(FI(x)) (it is called conditioned probability) obtained\\nfor the image in Fig. 1 (a).\\nNotice that when xhas a high value, jProb xðSM HCðIÞÞjwill have a\\nlow value because there is a low number of pixels that a', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 165: ('\\nPðFIðxÞÞ ¼jFIðxÞj\\njProb xðSM HCðIÞÞjjProb xðSM HCðIÞÞj40\\n0 jProb xðSM HCðIÞÞj ¼08\\n><\\n>:ð4Þ\\nThe value P(FI(x)) is the probability that a pixel has gradient level\\nxif it is a pixel with probability equal to or greater than xof being\\nadded. Fig. 3 (b) shows an example of the histogram of the\\ndistribution P(FI(x)) (it is called conditioned probability) obtained\\nfor the image in Fig. 1 (a).\\nNotice that when xhas a high value, jProb xðSM HCðIÞÞjwill have a\\nlow value because there is a low number of pixels that are added\\nmany times. However, in this case, jFIðxÞjwill be close to zero in\\nvalue because if a pixel has a high gradient level it has a high\\nprobability of being an edge point, and thus it is not added by the\\nhysteresis process. When xhas a low value jProb xðSM HCðIÞÞjwill have\\na high value because there is a high number of pixels that are added\\nat least once. However, in this case, jFIðxÞjwill be close to zero in\\nvalue because if a pixel has a low gradient level it has a high\\nprobability of not being an edge point; thus it is not added by the\\nhysteresis process. We should then hope that many values of the\\ndistribution of PðFIðxÞÞ,xAð0,1Þhave zero value.\\nThe information P(FI(x)) will be the combined information used\\nby our method and we deﬁne as an ‘‘instable gradient level’’ a\\ngradient of level xwith PðFIðxÞÞa0. The instability zone is deﬁned\\nby the instable gradient levels (see an example of the combined\\ninformation P(FI(x)) in Fig. 3 (b)).\\n2.3. The determination of the hysteresis thresholds\\nWhen the instability zone has been found, the corresponding\\ninstability zone in the image ProbðSM HCðIÞÞcan be found (an example\\nof the histogram corresponding to this image is named the\\nprobability interesting zone in Figs. 3 (b) and (c)).\\nBecause the gray level xof each pixel in the image ProbðSM HCðIÞÞis\\nthe probability that this pixel will be added as an edge point byusing the hysteresis process, we should hope that when xincreases\\nthis probability decreases. Then any local maximum into the\\ninstability zone of the ima', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 166: ('ility zone has been found, the corresponding\\ninstability zone in the image ProbðSM HCðIÞÞcan be found (an example\\nof the histogram corresponding to this image is named the\\nprobability interesting zone in Figs. 3 (b) and (c)).\\nBecause the gray level xof each pixel in the image ProbðSM HCðIÞÞis\\nthe probability that this pixel will be added as an edge point byusing the hysteresis process, we should hope that when xincreases\\nthis probability decreases. Then any local maximum into the\\ninstability zone of the image ProbðSM\\nHCðIÞÞshould be a relevant\\ninformation. Therefore the ﬁrst and last maximum local (see\\nvertical lines in Fig. 3 (c)) are selected and the corresponding\\nhysteresis thresholds, in the gradient histogram, can be found.\\nA visual comparison of the histograms in Fig. 3 (c) shows that\\no u rp r o p o s a la l l o w su st od i s c o v e ri n f o r m a t i o nh i d d e ni nt h e\\ngradient histogram to determine th e hysteresis thresholds. Finally,\\nFig. 3 (d) shows the edge map obtained for the image in Fig. 1 (a) by\\nusing the hysteresis thresholds determined by our proposal.\\n2.4. An easy way to implement our method\\nIfG(I) is the gradient image and CðIÞ¼f ð low ,highÞjlow ,\\nhighAð0,1Þgis a candidates set for hysteresis thresholds:\\n/C15Obtain the edge maps DGlow ,highðIÞfor each ( low,high) in the\\ncandidates set C(I) (see Eq. (1)).\\n/C15Obtain the image SM HCðIÞ(see Eq. (2)).\\n/C15Obtain the distribution PðFIðxÞÞ,xAð0,1Þ(see Eq. (4)) where:\\n3ProbðSM HCðIÞÞ¼SM HCðIÞ=jCðIÞj.\\n3Prob xðSM HCðIÞÞis the binary edge map obtained by threshold-\\ning the image ProbðSM HCðIÞÞwith xAð0,1Þ.\\n3jProb xðSM HCðIÞÞjis the number of pixels with gray level 1 in the\\nedge map Prob xðSM HCðIÞÞ.\\n3FIðxÞ¼GðIÞ3Prob xðSM HCðIÞÞ(3is the Hadamard product).3jFIðxÞjis the number of pixels with gradient level x in the\\nimage FI(x).\\n/C15Obtain the set D¼fxAð0,1ÞjPðFxðIÞÞa0gto determine the ﬁrst\\nand last local maximum of the histogram of the image\\nProbðSM HCðIÞÞfor the values in D. These values will be the\\nhysteresis thresholds.\\n3. Experiments, results ', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 167: ('obtained by threshold-\\ning the image ProbðSM HCðIÞÞwith xAð0,1Þ.\\n3jProb xðSM HCðIÞÞjis the number of pixels with gray level 1 in the\\nedge map Prob xðSM HCðIÞÞ.\\n3FIðxÞ¼GðIÞ3Prob xðSM HCðIÞÞ(3is the Hadamard product).3jFIðxÞjis the number of pixels with gradient level x in the\\nimage FI(x).\\n/C15Obtain the set D¼fxAð0,1ÞjPðFxðIÞÞa0gto determine the ﬁrst\\nand last local maximum of the histogram of the image\\nProbðSM HCðIÞÞfor the values in D. These values will be the\\nhysteresis thresholds.\\n3. Experiments, results and discussion\\nThe performances of previous methods in determining the\\nhysteresis thresholds [21,23] have been compared to the perfor-\\nmance of the Yitzhaky and Peli method [22] but, at present, the\\nperformances of the proposals in [21,23] have not been compared\\nto each other.\\nA summary of the evaluation methodology used in [21,23] to\\ncompare their methods to the Yitzhaky and Peli method is as follows:\\n3.1. First experiment\\n/C15To compare the performance of each proposal [21] or[23] to the\\nperformance of the Yitzhaky and Peli method, the same dataset(28 images) found in the original work of Yitzhaky and Peli was\\nused: Heath’s set of images [24],f o u n di n ftp://ﬁgmeatnt.csee.usf.\\nedu/pub/Edge_Compari son/images/results . The reference images\\nin Heath’s set were determined by humans from a set of edge maps\\nobtained by the Canny edge detector (with different values for its\\nparameters). Table 1 shows the best parameter values indicated in\\n[24] for constructing the reference images.\\n/C15To apply each method an approximation of the gradient image is\\nrequired. For all methods [21,23,22] , the same approximation of\\nthe gradient image was used:\\n3Smooth the input image using a Gaussian kernel with a given\\ns(seesvalue in Table 1 ).\\n3Differentiate using the ﬁrst difference operator ( /C01,0,1).\\n3Perform non-maxima suppression.\\n/C15To quantify the performance of each method, the same dis-\\ncrepancy measure was used (Baddeley’s measure [25]).\\nBaddeley’s discrepancy [18,25] is an error measure for binary\\nimages based on the', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 168: ('approximation of the gradient image is\\nrequired. For all methods [21,23,22] , the same approximation of\\nthe gradient image was used:\\n3Smooth the input image using a Gaussian kernel with a given\\ns(seesvalue in Table 1 ).\\n3Differentiate using the ﬁrst difference operator ( /C01,0,1).\\n3Perform non-maxima suppression.\\n/C15To quantify the performance of each method, the same dis-\\ncrepancy measure was used (Baddeley’s measure [25]).\\nBaddeley’s discrepancy [18,25] is an error measure for binary\\nimages based on the Hausdorff distance. This measure is\\nDp\\nwðA,BÞ¼1\\nNX\\nxAXjwðdðx,AÞÞ/C0wðdðx,BÞÞjp\"#1=p\\nð5Þ\\nwhere d(x,A) denotes the shortest distance from xAXtoADX,\\nw(t) is a continuous function on ½0,1Þ, concave and strictly\\nincreasing, 1 rpo1,0rDp\\nwðA,BÞr1a n d Dp\\nwðA,BÞ/C250f o rs i m i l a r\\nTable 1\\nReferences images in [24]: for each image the best parameters values for the Canny\\nedge detector.\\nImage s Low High Image s Low High\\nAirplane 0.60 0.067 0.135 Orange 1.20 0.016 0.04\\nBanana 0.60 0.015 0.05 Pillow 0.60 0.027 0.09Basket 1.20 0.029 0.072 Pinecone 1.20 0.056 0.14Beehive 1.80 0.016 0.054 Pitcher 0.60 0.026 0.088Briefcase 1.20 0.012 0.0645 Pond 0.60 0.048 0.16\\nBrush 0.60 0.039 0.091 Shoppingcart 0.60 0.056 0.189\\nCoffeemaker 1.20 0.014 0.049 Stairs 0.60 0.045 0.15Egg 1.20 0.013 0.033 Stapler 0.60 0.014 0.048Elephant 0.60 0.052 0.176 Tiger 0.60 0.049 0.099Feather 0.60 0.042 0.142 Tire 1.20 0.006 0.030Flower 0.60 0.031 0.103 Trafﬁcone 0.60 0.041 0.13Golfcart 0.60 0.045 0.151 Trashcan 1.80 0.004 0.02\\nGrater 0.60 0.038 0.127 Turtle 0.60 0.028 0.056\\nMailbox 1.20 0.028 0.072 Videocamera 1.80 0.006 0.033R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1205\\nimages AandB.B a d d e l e yu s e dt h et r a n s f o r m a t i o n wðtÞ¼minft,cg\\nfor a ﬁxed c40.\\nIfAand Bdenote, respectively, the binary edge map and the\\nr e f e r e n c ee d g em a p , Dp\\nwðA,BÞtakes into account the reference edge\\npoints, the detected edge points and all the others points in the\\nimages. The values c¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\\nM2þN2p\\nand p¼2w e r', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 169: ('7 Turtle 0.60 0.028 0.056\\nMailbox 1.20 0.028 0.072 Videocamera 1.80 0.006 0.033R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1205\\nimages AandB.B a d d e l e yu s e dt h et r a n s f o r m a t i o n wðtÞ¼minft,cg\\nfor a ﬁxed c40.\\nIfAand Bdenote, respectively, the binary edge map and the\\nr e f e r e n c ee d g em a p , Dp\\nwðA,BÞtakes into account the reference edge\\npoints, the detected edge points and all the others points in the\\nimages. The values c¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\\nM2þN2p\\nand p¼2w e r eu s e di nb o t h\\nexperiments. If c¼ﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃﬃ\\nM2þN2p\\n,w h e r e M/C2Nis the dimension ofthe image, the error when detecting an edge point is weighted by\\nthe distance between the reference edge point and the detected\\nedge point.\\nIn order to compute the Baddeley value the distance transformed\\nmethod [26] has been applied to edge maps AandB(by using the\\nchessboard distance and the value c)s oa st oo b t a i nt h ei m a g e s Au\\nand Bu.T h e n ,\\nDp\\nwðA,BÞ¼1\\nM/C2NX\\nðx,yÞAAjAuðx,yÞÞ/C0Buðx,yÞjp2\\n43\\n51=p\\nð6Þ\\nis obtained.\\n/C15To apply the methods [21,23,22] , a set Cof candidates for\\nhysteresis thresholds is needed. For all methods the same set\\nC¼{0.01,0.02, y,0.25} was used.\\nTo apply our proposal, the same gradient image and the same set C\\nwere used, and to compare our proposal with the methods in\\n[21,23] , the same methodology has been used.\\nTables 2 and 3 show the Baddeley values obtained by comparing\\nthe edge maps obtained by each method to the reference image\\nand each method is ordered according to its performance. We\\nlabel as SOHT (subset and overset for hysteresis thresholds) [23],\\nUTHT (unimodal thresholding for hysteresis thresholds) [21]\\nand NEW (our method), respectively, each method evaluated.\\nFig. 4 shows the performance of each method (for each image of\\ndataset used). For each image, left to right, the ﬁrst box represents\\nthe SOHT method, the second box represents the UTHT method and\\nthe third box represents the NEW method. For each image, a box of\\nlower height means a better performance was ac', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 170: ('s performance. We\\nlabel as SOHT (subset and overset for hysteresis thresholds) [23],\\nUTHT (unimodal thresholding for hysteresis thresholds) [21]\\nand NEW (our method), respectively, each method evaluated.\\nFig. 4 shows the performance of each method (for each image of\\ndataset used). For each image, left to right, the ﬁrst box represents\\nthe SOHT method, the second box represents the UTHT method and\\nthe third box represents the NEW method. For each image, a box of\\nlower height means a better performance was achieved.\\nTable 4 shows a summary of the results in Tables 2 and\\n3: for each method on each of the 28 images, the mean and\\nS.D.: (1) of the Baddeley values obtained and (2) of the ranknumbers obtained. As can be seen, of the three methods, theTable 2\\nResults obtained for the compared methods: SOHT, UTHT and NEW. Baddeley values\\nand rank number of each method according its performance.\\nImage SOHT UTHT NEW First Second Third\\n1 0.0248 0.0366 0.0300 SOHT NEW UTHT\\n2 0.0095 0.0070 0.0071 UTHT NEW SOHT3 0.0026 0.0083 0.0019 NEW SOHT UTHT4 0.0450 0.0336 0.0339 UTHT NEW SOHT5 0.0178 0.0194 0.0195 SOHT UTHT NEW6 0.0280 0.0300 0.0133 NEW SOHT UTHT7 0.0160 0.0223 0.0177 SOHT NEW UTHT\\n8 0.0170 0.0286 0.0267 SOHT NEW UTHT\\n9 0.0274 0.0175 0.0176 UTHT NEW SOHT\\n10 0.0046 0.0049 0.0031 NEW SOHT UTHT\\n11 0.0157 0.0080 0.0086 UTHT NEW SOHT12 0.0120 0.0154 0.0137 SOHT NEW UTHT13 0.0106 0.0116 0.0114 SOHT NEW UTHT14 0.0026 0.0024 0.0030 UTHT SOHT NEW\\nTable 3Results obtained for the compared methods: SOHT, UTHT and NEW. Baddeley valuesand rank number of each method according its performance.\\nImage SOHT UTHT NEW First Second Third\\n15 0.0217 0.0376 0.0260 SOHT NEW UTHT\\n16 0.0220 0.0124 0.0088 NEW UTHT SOHT17 0.0034 0.0061 0.0024 NEW SOHT UTHT18 0.0058 0.0032 0.0036 UTHT NEW SOHT19 0.0099 0.0058 0.0056 NEW UTHT SOHT\\n20 0.0140 0.0149 0.0038 NEW SOHT UTHT\\n21 0.0083 0.0063 0.0065 UTHT NEW SOHT22 0.0270 0.0327 0.0333 SOHT UTHT NEW23 0.0160 0.0093 0.0075 NEW UTHT SOHT24 0.0120 0.0271 0.0112 NEW SOHT UTHT25 0.0106 0.0087 0.0083 NEW UTHT SOHT26 0', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 171: ('sand rank number of each method according its performance.\\nImage SOHT UTHT NEW First Second Third\\n15 0.0217 0.0376 0.0260 SOHT NEW UTHT\\n16 0.0220 0.0124 0.0088 NEW UTHT SOHT17 0.0034 0.0061 0.0024 NEW SOHT UTHT18 0.0058 0.0032 0.0036 UTHT NEW SOHT19 0.0099 0.0058 0.0056 NEW UTHT SOHT\\n20 0.0140 0.0149 0.0038 NEW SOHT UTHT\\n21 0.0083 0.0063 0.0065 UTHT NEW SOHT22 0.0270 0.0327 0.0333 SOHT UTHT NEW23 0.0160 0.0093 0.0075 NEW UTHT SOHT24 0.0120 0.0271 0.0112 NEW SOHT UTHT25 0.0106 0.0087 0.0083 NEW UTHT SOHT26 0.0460 0.0499 0.0198 NEW SOHT UTHT27 0.0690 0.0293 0.0295 UTHT NEW SOHT\\n28 0.0310 0.0582 0.0215 NEW SOHT UTHT\\n0.06500.0700\\n0.0600\\n0.0550\\n0.0500\\n0.0450\\n0.0400\\n0.0350\\n0.03000.0250\\n0.0200\\n0.01500.01000.0050\\n0.0000\\n12345678 9 1 0 1 1 12 13 14 15 16 17 18192021 22 23 24 25 26 2728\\nImage NumberBaddeley value\\nFig. 4. Baddeley values obtained for each method and for each image. For each image, left to right, the ﬁrst box represents the SOHT method, the second box repre sents the\\nUTHT method and the third box represents the NEW method. For each image, a lower box height means a better performance was achieved.Table 4Summary of results obtained for the compared methods: SOHT, UTHT and NEW.Mean and S.D. of Baddeley values and of rank.\\nMethod Mean Baddeley S.D. Baddeley Rank mean Rank S.D.\\nSOHT 0.0189 0.0002 2.1071 0.6918\\nUTHT 0.0195 0.0002 2.2143 0.7672\\nNEW 0.0141 0.0001 1.6786 0.4484R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1206\\n0.0325000.035000\\n0.030000\\n0.0275000.025000\\n0.0200000.022500\\n0.017500\\n0.0150000.0125000.010000\\n0.007500\\n0.005000\\n0.002500\\n0.000000\\n1234 56 7 8 9 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 2 1 2 2 2 3 2 4 2 5 2 6 2 7 2 8\\nImage NumberBaddeley value\\nFig. 5. Dependence of our method on the initial set to search for hysteresis thresholds. Left to right: the ﬁrst box uses the values of the interval [0.01,0.25] with an increase in\\nvalue of 0.01, the second box uses the interval [0.01,0.25] with an increase in value of 0.03.\\nFig. 6. Edge maps obtained by each method and the refer', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 172: ('00\\n0.0150000.0125000.010000\\n0.007500\\n0.005000\\n0.002500\\n0.000000\\n1234 56 7 8 9 1 0 1 1 1 2 1 3 1 4 1 5 1 6 1 7 1 8 1 9 2 0 2 1 2 2 2 3 2 4 2 5 2 6 2 7 2 8\\nImage NumberBaddeley value\\nFig. 5. Dependence of our method on the initial set to search for hysteresis thresholds. Left to right: the ﬁrst box uses the values of the interval [0.01,0.25] with an increase in\\nvalue of 0.01, the second box uses the interval [0.01,0.25] with an increase in value of 0.03.\\nFig. 6. Edge maps obtained by each method and the reference image. (a) Original image. (b) Reference image. (c) SOHT edge map. (d) UTHT edge map. (e) NEW edge map .\\nFig. 7. Edge maps obtained by each method and the reference image. (a) Original image. (b) Reference image. (c) SOHT edge map. (d) UTHT edge map. (e) NEW edge map .R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1207\\nproposed method produces the smallest mean and standard\\ndeviation: (1) using the Baddeley values and (2) using the rank\\nnumbers.\\nThe performance of the methods SOHT and UTHT is very similar:\\na very small improvement, compared to method UTHT, is obtained\\nby the method SOHT if Baddeley values or rank numbers are\\nconsidered. We should expect the performance of the method\\nSOHT to be better than the performance of method UTHT because,\\nby using the method UTHT, the hysteresis thresholds are not\\ndetermined, i.e., the edge map obtained by the method UTHT is only\\nan approximation of an edge map obtained using unknown values\\nfor hysteresis thresholds, while the edge map obtained by the\\nmethod SOHT is an edge map corresponding to best values of\\nhysteresis thresholds determined by this method. In our opinionthis occurs because the SOHT method requires a subset and an\\noverset of the unknown set of edge points. When there is a mistake\\nin this choice for a given image, a low performance is obtained with\\nthis method.\\nFollowing the same methodology as in [23], the dependence of\\nour method on the candidates set is shown in Fig. 5 .Figs. 6 and 7\\nshow examples of edge maps obtained by the t', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 173: (' by the\\nmethod SOHT is an edge map corresponding to best values of\\nhysteresis thresholds determined by this method. In our opinionthis occurs because the SOHT method requires a subset and an\\noverset of the unknown set of edge points. When there is a mistake\\nin this choice for a given image, a low performance is obtained with\\nthis method.\\nFollowing the same methodology as in [23], the dependence of\\nour method on the candidates set is shown in Fig. 5 .Figs. 6 and 7\\nshow examples of edge maps obtained by the three methods and\\nthe reference images.\\n3.2. Second experiment\\nIn this experiment 30 images from Berkeley Segmentation\\nDataset [17,27] (http://www.eecs.berkeley.edu/Research/Projects/\\nCS/vision/bsds/ ) have been used. The same methodology as that in\\n 0 0.02 0.04 0.06 0.08 0.1\\n0 0.2 0.4 0.6 0.8 1Baddeley value\\nEdge Probability\\n 0 0.02 0.04 0.06 0.08 0.1\\n0 0.2 0.4 0.6 0.8 1Baddeley value\\nEdge ProbabilityUTHT\\nSOHT\\nNEWUTHT\\nSOHT\\nNEW\\nUTHT\\nSOHT\\nNEW\\n 0 0.02 0.04 0.06 0.08 0.1\\n0 0.2 0.4 0.6 0.8 1Baddeley value\\nEdge Probability\\nFig. 8. Mean discrepancy curves of the compared methods. For each edge probability value ( kA½0,1/C138), the Baddeley value means the performance to detect edge points with\\nprior probability Zk. For each x-axis value, a lower y-axis value means a better performance was achieved. (a) For s¼0:6. (b) For s¼1:2. (c) For s¼1:8.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1208\\n[21,23] has been used to compare the performance of all methods.\\nA summary of this methodology is:\\n/C15For each image, the same procedure carried out in our ﬁrst\\nexperiment has been used to obtain the gradient image. In this\\ncase, for each image, using s¼f0:6,1:2,1:8gthree different\\ngradient images are obtained. Then, using the interval\\n[0.01,0.25] as the candidates set, we apply the proposed method\\nand the methods [21,23] to all the 90 gradient images obtained.\\n/C15For each image, the ground truth boundary in the Berkeley\\nSegmentation Dataset is a gray level image with Llevels. If h\\npeople say that a pixel i', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 174: ('or each image, the same procedure carried out in our ﬁrst\\nexperiment has been used to obtain the gradient image. In this\\ncase, for each image, using s¼f0:6,1:2,1:8gthree different\\ngradient images are obtained. Then, using the interval\\n[0.01,0.25] as the candidates set, we apply the proposed method\\nand the methods [21,23] to all the 90 gradient images obtained.\\n/C15For each image, the ground truth boundary in the Berkeley\\nSegmentation Dataset is a gray level image with Llevels. If h\\npeople say that a pixel is an edge point for an original image then\\nthis pixel has gray level hrLin the ground truth boundary\\nimage. Therefore, if the ground truth boundary image is normal-\\nized to [0,1], the gray level of each pixel is the prior probability of\\na pixel being an edge point. Thus, if the ground truth boundary\\nimage is thresholded with value kA½0,1Þin steps of Dk¼0:01,\\n100 binary edge maps are obtained.\\n/C15Each of the 100 binary edge maps is considered the referenceedge map for threshold k. In the reference binary edge map that\\nis obtained for threshold k, the pixels with gray level a0 are the\\npixels of the ground truth boundary image with a probability\\nZkof being an edge point. Baddeley value is then calculated\\nbetween the reference edge map obtained for threshold kand\\nthe binary edge map obtained for each of the methods eval-\\nuated. This discrepancy value (the ideal value is 0) is considered\\nthe error measure of a given method to detect edge points with a\\nprobability Zk.\\n/C15We construct the curve that describes the different discrepancy\\nvalues obtained for thresholds fk,kA½0,1Þgfor each method andfor each gradient image. This curve is an error measure of a given\\nmethod to detect edge points with distinct probabilities.\\nFor each s¼f0:6,1:2,1:8gvalue, we show in Fig. 8 the mean\\ndiscrepancy curves for the 30 gradient images used for each\\nsvalue.\\nIn order to analyze the performance of each method, the\\ndiscrepancy curves have been used. Suppose that we want compare\\nthe performance of two methods in detecting true edge poin', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 175: ('different discrepancy\\nvalues obtained for thresholds fk,kA½0,1Þgfor each method andfor each gradient image. This curve is an error measure of a given\\nmethod to detect edge points with distinct probabilities.\\nFor each s¼f0:6,1:2,1:8gvalue, we show in Fig. 8 the mean\\ndiscrepancy curves for the 30 gradient images used for each\\nsvalue.\\nIn order to analyze the performance of each method, the\\ndiscrepancy curves have been used. Suppose that we want compare\\nthe performance of two methods in detecting true edge points with\\na probability greater than k. Then, by using the corresponding\\ncurves, the threshold kin the x-axis should be considered. The\\ncorresponding values in the y-axis are the Baddeley values\\nobtained by comparing each method with the reference edge\\nmap. Finally, the smallest value (between two Baddeley values)\\ndetermines the best method for the threshold k. For instance, the\\nbest method for detecting edge points with a probability greater\\nthan 0.2 and for any svalue (see Figs. 8 (a)–(c)) is the NEW method.\\nWhile if it is desired to detect edge points with a probability greater\\nthan 0.7, the best is the SOHT method ( s¼0:6 or 1.2) or the UTHT\\nmethod ( s¼1:8).\\nFigs. 8 (a) and (b) show that using s¼0:6o rs¼1:2 there is a\\nthreshold k0. Then, to detect edge points with a prior probability\\nPZk,krk0, the method NEW performs better than the methods\\nUTHT and SOHT. If k4k0the SOHT method performs better than\\nthe methods UTHT and NEW. To detect edge points with a prior\\nprobability PZk,krk0, the UTHT method performs better than the\\nmethod SOHT and if k4k0the opposite happens. Notice that the\\nthreshold k0is smaller for s¼0:6 than for s¼1:2.\\nSmoothing with s¼1:8(Fig. 8 (c)), there is a threshold /C250:4. To\\ndetect edge points with a prior probability PZk,kr0:4, the\\nmethod NEW performs better than the method UTHT. If k40:4\\nFig. 9. Edge maps obtained by each method. (a) Original image. (b) SOHT edge map. (c) UTHT edge map. (d) NEW edge map.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1209\\nthe opposite ', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 176: ('tter than the\\nmethod SOHT and if k4k0the opposite happens. Notice that the\\nthreshold k0is smaller for s¼0:6 than for s¼1:2.\\nSmoothing with s¼1:8(Fig. 8 (c)), there is a threshold /C250:4. To\\ndetect edge points with a prior probability PZk,kr0:4, the\\nmethod NEW performs better than the method UTHT. If k40:4\\nFig. 9. Edge maps obtained by each method. (a) Original image. (b) SOHT edge map. (c) UTHT edge map. (d) NEW edge map.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1209\\nthe opposite happens. For any probability, the method UTHT\\nperforms better than the method SOHT. To detect edge points\\nwith a prior probability PZk,kr/C250:8, the method NEW performs\\nbetter than the method SOHT.\\nTherefore, by comparing Figs. 8 (a)–(c) the following conclusions\\nare obtained:\\n/C15When the svalue increases, the performance of all methods\\ndecreases (see y-axis values). It is an expected result since the\\nmore we blur the image the less amount of information is\\npreserved.\\n/C15The SOHT method is less robust than the NEW and UTHTmethods (see Fig. 8 (c)) with respect to the level of smoothing\\nused (\\nsvalue). This is a logical fact because the criterion used by\\nthe method SOHT is based on a measure calculated for the\\nnumber of true and false positives and negatives (TP, FP, TN and\\nFN) by comparing each possible ﬁnal edge map with respect to a\\nsubset and a superset of the set of true edge points (more details\\nSection II-B in [23]). When the smoothing level increases, these\\nnumbers are very different and also the ﬁnal edge map is very\\ndifferent.\\n/C15For any svalue, the NEW method has the best performance in\\ndetecting edge points for k0r0:4 (see Figs. 8 (a)–(c)) because it\\nhas the greatest sensitivity. Notice that the k0value indicates\\nthat the NEW method detects these as true edge points\\nindicated by a minimum of 10 k0% people.\\nFigs. 9 and 10 show two examples of edge maps obtained by the\\nthree compared methods.Additionally, in a discussion of the SOHT and UTHT methods\\n(see [23,21] ), it is stated that the computationa', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 177: ('l edge map is very\\ndifferent.\\n/C15For any svalue, the NEW method has the best performance in\\ndetecting edge points for k0r0:4 (see Figs. 8 (a)–(c)) because it\\nhas the greatest sensitivity. Notice that the k0value indicates\\nthat the NEW method detects these as true edge points\\nindicated by a minimum of 10 k0% people.\\nFigs. 9 and 10 show two examples of edge maps obtained by the\\nthree compared methods.Additionally, in a discussion of the SOHT and UTHT methods\\n(see [23,21] ), it is stated that the computational complexity of each\\nmethod is smaller than the computational complexity of the\\nYitzhaky and Peli method. Thus, the computational complexity\\nof our method (NEW) is discussed below:\\n/C15The computational complexity of our method is greater than thecomputational complexity of the UTHT method because to\\napply our proposed method, the same steps as those used by\\nthe UTHT method to generate the image SM\\nHCðIÞare needed; from\\nthere, additional steps are needed (see Section 1). This is logical\\nbecause our method ﬁnds the thresholds required, while the\\nUTHT method only ﬁnds an approximation of an edge map\\ncorresponding to the best thresholds.\\n/C15It is easy to see that the computational complexity of the SOHTmethod is greater than the computational complexity of our\\nmethod. To apply the SOHT method, many comparisons\\nbetween two edge maps are required to calculate TP, FP, TN\\nand FN (see Section II-B in [23]), and for these comparisons a\\nlarge computing time is required.\\n4. Conclusions\\nThe determination of hysteresis thresholds in an unsupervised\\nway is not an easy problem, and several methods to solve this\\nproblem have been proposed in the last years [22,21,23] . In this\\npaper, previous methods have been discussed and a novel method\\nis proposed to solve this problem.\\nFig. 10. Edge maps obtained by each method. (a) Original image. (b) SOHT edge map. (c) UTHT edge map. (d) NEW edge map.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1210\\nGiven a set of candidates for hysteresis thresholds, the main ide', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 178: ('hresholds in an unsupervised\\nway is not an easy problem, and several methods to solve this\\nproblem have been proposed in the last years [22,21,23] . In this\\npaper, previous methods have been discussed and a novel method\\nis proposed to solve this problem.\\nFig. 10. Edge maps obtained by each method. (a) Original image. (b) SOHT edge map. (c) UTHT edge map. (d) NEW edge map.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1210\\nGiven a set of candidates for hysteresis thresholds, the main idea\\nof the proposed method is to combine gradient information with\\ninformation obtained in the linking process by using all candidates.\\nUsing the same empirical measure [25] and the same metho-\\ndology as previous works [21,23] , the results obtained show that:\\n/C15Using Heath’s dataset [24] the results obtained show that the\\nperformance of our method is better than those of previous\\nmethods, as the mean and standard deviation of measured\\nvalues are smallest for our method. The performances of the\\nmethods UTHT [21] and SOHT [23] are very similar.\\n/C15Using the Berkeley segmentation dataset [27] the results\\nobtained show that: (1) to detect edge points with a prior\\nprobability PZk,krk0,k0A½0:4,0:5/C138, our method performs bet-\\nter than the methods UTHT [21] and SOHT [23].I fk4k0the\\nopposite happens. (2) The method SOHT is more sensitive than\\nthe method UTHT and our method with respect to level of\\nsmoothing used to obtain the gradient image.\\nThe computational complexity of our method is smaller than that of\\nthe method SOHT [23]. The UTHT method [21] has a smaller\\ncomputational complexity than our method, but this method only\\nﬁnds an approximate edge map as obtained by the hysteresis\\nprocess and it is not able to ﬁnd the hysteresis thresholds.\\nThe gradient image used in our experimentation is the gradient\\nimage proposed by the ﬁrst steps of the Canny edge detector.\\nTherefore, the results obtained by all methods have only been\\nvalidated for the Canny edge detector. However, there is no\\nrestriction on applying our met', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 179: ('ethod SOHT [23]. The UTHT method [21] has a smaller\\ncomputational complexity than our method, but this method only\\nﬁnds an approximate edge map as obtained by the hysteresis\\nprocess and it is not able to ﬁnd the hysteresis thresholds.\\nThe gradient image used in our experimentation is the gradient\\nimage proposed by the ﬁrst steps of the Canny edge detector.\\nTherefore, the results obtained by all methods have only been\\nvalidated for the Canny edge detector. However, there is no\\nrestriction on applying our method to any other edge detector\\nwhose strategy is based on the hysteresis mechanism.\\nReferences\\n[1] I. Sobel, G. Feldman, A 3 /C23 isotropic gradient operator for image processing,\\nPresented at a talk at the Stanford Artiﬁcial Project, 1968.\\n[2] J.M.S. Prewitt, Object Enhancement and Extraction Picture Processing and\\nPsychopictorics, Academic Press, 1970, pp. 75–149.\\n[3] N. Otsu, A threshold selection method from gray level histograms, IEEE\\nTransactions on Systems, Man and Cybernetics 9 (1979) 62–66.\\n[4] D. Marr, E. Hildreth, Theory of edge detection, Proceedings of the Royal Society\\nof London 207 (1167) (1980) 187–217.\\n[5] J. Canny, A computational approach to edge detection, IEEE Transactions\\nPattern Analysis and Machine Intelligence 8 (1986) 679–698.\\n[6] C. Ducottet, T. Fournel, C. Barat, Scale-adaptive detection and local character-\\nization of edges based on wavelet transform, Signal Processing 84 (2004)\\n2115–2137.[7] K.N. Le, K.P. Dabke, G.K. Egan, On mathematical derivations of auto-term\\nfunctions and signal-to-noise ratios of Choi–Williams, ﬁrst- and nth-order\\nhyperbolic kernels, Digital Signal Processing 16 (2006) 84–104.\\n[8] S. Lu, Z. Wang, J. Shen, Neuro-fuzzy synergism to the intelligent system for edge\\ndetection and enhancement, Pattern Recognition 36 (2003) 2395–2409.\\n[9] R. Rakesh, P. Chaudhuri, C.A. Murthy, Thresholding in edge detection:\\na statistical approach, IEEE Transactions on Image Processing 13 (2004)927–936.\\n[10] J. Bezdek, R. Chandrasekhar, Y. Attikouzel, A geometric approach to edge\\ndet', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 180: ('gnal-to-noise ratios of Choi–Williams, ﬁrst- and nth-order\\nhyperbolic kernels, Digital Signal Processing 16 (2006) 84–104.\\n[8] S. Lu, Z. Wang, J. Shen, Neuro-fuzzy synergism to the intelligent system for edge\\ndetection and enhancement, Pattern Recognition 36 (2003) 2395–2409.\\n[9] R. Rakesh, P. Chaudhuri, C.A. Murthy, Thresholding in edge detection:\\na statistical approach, IEEE Transactions on Image Processing 13 (2004)927–936.\\n[10] J. Bezdek, R. Chandrasekhar, Y. Attikouzel, A geometric approach to edge\\ndetection, IEEE Transactions on Fuzzy Systems 6 (1998) 52–75.\\n[11] D.-S. Kim, W.-H. Lee, I.-S. Kweon, Automatic edge detection using 3 /C23 ideal\\nbinary pixel patterns and fuzzy-based edge thresholding, Pattern RecognitionLetters 25 (2004) 101–106.\\n[12] Y.-T. Chen, A level set method based on the Bayesian risk for medical image\\nsegmentation, Pattern Recognition 43 (2010) 3699–3711.\\n[13] C. Lopez-Molina, H. Bustince, J. Fernandez, P. Couto, B. De Baets, A gravitational\\napproach to edge detection based on triangular norms, Pattern Recognition 43\\n(2010) 3730–3741.\\n[14] P.L. Rosin, Unimodal thresholding, Pattern Recognition 34 (2001) 2083–2096.[15] M.O. Baradez, C.P. McGuckin, N. Forraz, R. Pettengell, A. Hoppe, Robust and\\nautomated unimodal histogram thresholding and potential applications,\\nPattern Recognition 37 (2004) 1131–1148.\\n[16] R. Medina-Carnicer, F.J. Madrid Cuevas, Unimodal thresholding for edge\\ndetection, Pattern Recognition 41 (2008) 2337–2346.\\n[17] D.R. Martin, C.C. Fowlkes, Jitendra Malik, Learning to detect natural image\\nboundaries using local brightness, color, and texture cues, IEEE Transactions on\\nPattern Analysis and Machine Intelligence 26 (2004) 1–20.\\n[18] R. Medina-Carnicer, F.J. Madrid-Cuevas, N.L. Ferna ´ndez-Garcı ´a, A. Carmona-\\nPoyato, Evaluation of global thresholding techniques in non-contextual edge\\ndetection, Pattern Recognition Letters 26 (2005) 1423–1434.\\n[19] R. Medina-Carnicer, F.J. Madrid-Cuevas, A. Carmona-Poyato, R. Mun ˜oz-Salinas,\\nOn candidates selection for hysteresis threshol', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 181: (' detect natural image\\nboundaries using local brightness, color, and texture cues, IEEE Transactions on\\nPattern Analysis and Machine Intelligence 26 (2004) 1–20.\\n[18] R. Medina-Carnicer, F.J. Madrid-Cuevas, N.L. Ferna ´ndez-Garcı ´a, A. Carmona-\\nPoyato, Evaluation of global thresholding techniques in non-contextual edge\\ndetection, Pattern Recognition Letters 26 (2005) 1423–1434.\\n[19] R. Medina-Carnicer, F.J. Madrid-Cuevas, A. Carmona-Poyato, R. Mun ˜oz-Salinas,\\nOn candidates selection for hysteresis thresholds in edge detection, Pattern\\nRecognition 42 (2009) 1284–1296.\\n[20] E.R. Hancock, J. Kittler, Adaptive estimation of hysteresis thresholds,\\nin: Computer Vision and Pattern Recognition (Proceedings CVPR ’91), 1991,\\npp. 196–201.\\n[21] R. Medina-Carnicer, F.J. Madrid-Cuevas, R. Mun ˜oz-Salinas, A. Carmona-Poyato,\\nSolving the process of hysteresis without determining the optimal thresholds,\\nPattern Recognition 43 (2010) 1124–1232.\\n[22] Y. Yitzhaky, E. Peli, A method for objective edge detection evaluation and\\ndetector parameter selection, IEEE Transactions on Pattern Analysis andMachine Intelligence 25 (2003) 1027–1033.\\n[23] R. Medina-Carnicer, A. Carmona-Poyato, R. Mun ˜oz-Salinas, F.J. Madrid-Cuevas,\\nDetermining hysteresis thresholds for edge detection by combining the\\nadvantages and disadvantages of thresholding methods, IEEE Transactions\\non Image Processing 19, 165–173.\\n[24] M.D. Heath, S. Sarkar, T. Sanocki, K. Bowyer, A robust visual method for\\nassessing the relative performance of edge-detection algorithms, IEEE Trans-actions on Pattern Analysis and Machine Intelligence 19 (1997) 1338–1359.\\n[25] A.J. Baddeley, An error metric for binary images, Robust Computer Vision:\\nQuality of Vision Algorithms, Wichmann Verlag Karlsruhe, 1992, pp. 59–78.\\n[26] G. Borgefors, Distance transformations in digital images, Computer Vision,\\nGraphics, and Image Processing 34 (1986) 344–371.\\n[27] D. Martin, C. Fowlkes, D. Tal, J. Malik, A database of human segmented natural\\nimages and its application to evaluating segmentation algor', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 182: (' IEEE Trans-actions on Pattern Analysis and Machine Intelligence 19 (1997) 1338–1359.\\n[25] A.J. Baddeley, An error metric for binary images, Robust Computer Vision:\\nQuality of Vision Algorithms, Wichmann Verlag Karlsruhe, 1992, pp. 59–78.\\n[26] G. Borgefors, Distance transformations in digital images, Computer Vision,\\nGraphics, and Image Processing 34 (1986) 344–371.\\n[27] D. Martin, C. Fowlkes, D. Tal, J. Malik, A database of human segmented natural\\nimages and its application to evaluating segmentation algorithms and\\nmeasuring ecological statistics, in: Proceedings of the 8th International\\nConference on Computer Vision, vol. 2, 2001, pp. 416–423.\\nMedina-Carnicer received the Bachelor degree in Mathematics from University of Sevilla (Spain). He received the Ph. D. in Computer Science from the Polytechnic Unive rsity\\nof Madrid (Spain) in 1992. Since 1993 he has been a lecturer of Computer Vision in Cordoba University (Spain). His research is focused on Edge detection , Evaluation of\\nComputer Vision algorithms and Pattern Recognition.\\nMun˜oz-Salinas received the Bachelor degree in Computer Science from Granada University (Spain) and the Ph.D. degree from Granada University (Spain), in 2006. Sinc e 2006\\nhe has been working with the Department of Computing and Numerical Analysis of Cordoba University, currently he is assistant professor. His research is focused mainly on\\nMobile Robotics, Human-Robot Interaction, 3D Vision and Soft Computing techniques applied to Robotics.\\nYeguas-Bolivar received the Bachelor degree in Computer Science from Granada University (Spain) and the Ph.D. degree from Granada University (Spain), in 2008. Sinc e 2008\\nhe has been working with the Department of Computing and Numerical Analysis of Cordoba University, currently he is assistant professor. His research is focused mainly on\\nSoft Computing techniques applied to Computer Vision.\\nDiaz-Mas received the Bachelor degree in Computer Science from Cordoba University (Spain) in 2008. Currently he is a Phd student in the Department of Computing\\nan', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 183: ('n Computer Science from Granada University (Spain) and the Ph.D. degree from Granada University (Spain), in 2008. Sinc e 2008\\nhe has been working with the Department of Computing and Numerical Analysis of Cordoba University, currently he is assistant professor. His research is focused mainly on\\nSoft Computing techniques applied to Computer Vision.\\nDiaz-Mas received the Bachelor degree in Computer Science from Cordoba University (Spain) in 2008. Currently he is a Phd student in the Department of Computing\\nand\\nNumerical Analysis of Cordoba University. His research is focused mainly on Image Segmentation and 3D Vision.R. Medina-Carnicer et al. / Pattern Recognition 44 (2011) 1201–1211 1211', 'A novel method to look for the hysteresis thresholds for the Canny Edge Detector.pdf'), 184: ('A Case Against CXL Memory Pooling\\nPhilip Levis\\nGoogle\\nplevis@google .comKun Lin\\nGoogle\\nlinkun@google .comAmy Tai\\nGoogle\\namytai@google .com\\nAbstract\\nCompute Express Link (CXL) is a replacement for PCIe. With\\nmuch lower latency than PCIe and hardware support for cache\\ncoherence, programs can efficiently access remote memory\\nover CXL. These capabilities have opened the possibility of\\nCXL memory pools in datacenter and cloud networks, consist-\\ning of a large pool of memory that multiple machines share.\\nRecent work argues memory pools could reduce memory\\nneeds and datacenter costs.\\nIn this paper, we argue that three problems preclude CXL\\nmemory pools from being useful or promising: cost, complex-\\nity, and utility. The cost of a CXL pool will outweigh any\\nsavings from reducing RAM. CXL has substantially higher\\nlatency than main memory, enough so that using it will re-\\nquire substantial rewriting of network applications in complex\\nways. Finally, from analyzing two production traces from\\nGoogle and Azure Cloud, we find that modern servers are\\nlarge relative to most VMs; even simple VM packing algo-\\nrithms strand little memory, undermining the main incentive\\nbehind pooling.\\nDespite recent research interest, as long as these three\\nproperties hold, CXL memory pools are unlikely to be a\\nuseful technology for datacenter or cloud systems.\\nCCS Concepts\\n•Networks→Data center networks ;•Information sys-\\ntems→Enterprise resource planning .\\nKeywords\\ndatacenter networking, CXL memory pooling\\nACM Reference Format:\\nPhilip Levis, Kun Lin, and Amy Tai. 2023. A Case Against CXL\\nMemory Pooling. In The 22nd ACM Workshop on Hot Topics in\\nNetworks (HotNets ’23), November 28–29, 2023, Cambridge, MA,\\nUSA. ACM, New York, NY , USA, 7 pages. https://doi .org/10 .1145/\\n3626111 .3628195\\nPermission to make digital or hard copies of part or all of this work for\\npersonal or classroom use is granted without fee provided that copies are not\\nmade or distributed for profit or commercial advantage and that copies bear\\nthis notice and the full citation on t', 'A Case Against CXL Memory Pooling.pdf'), 185: (' Lin, and Amy Tai. 2023. A Case Against CXL\\nMemory Pooling. In The 22nd ACM Workshop on Hot Topics in\\nNetworks (HotNets ’23), November 28–29, 2023, Cambridge, MA,\\nUSA. ACM, New York, NY , USA, 7 pages. https://doi .org/10 .1145/\\n3626111 .3628195\\nPermission to make digital or hard copies of part or all of this work for\\npersonal or classroom use is granted without fee provided that copies are not\\nmade or distributed for profit or commercial advantage and that copies bear\\nthis notice and the full citation on the first page. Copyrights for third-party\\ncomponents of this work must be honored. For all other uses, contact the\\nowner/author(s).\\nHotNets ’23, November 28–29, 2023, Cambridge, MA, USA\\n© 2023 Copyright held by the owner/author(s).\\nACM ISBN 979-8-4007-0415-4/23/11.\\nhttps://doi.org/10.1145/3626111 .36281951 Introduction\\nMemory is an expensive component of datacenter and cloud\\nservers: recent papers report its fraction of a server’s cost is\\n40% for Meta [ 14] and 50% for Azure [ 21]. Google faces\\nsimilar pressures [ 6]. The pressure to reduce RAM needs\\nand costs has motivated work in far memory [ 18], memory\\ncompression [ 12], and Intel Optane memory, which trades off\\nperformance for lower cost [ 17]. If a server has insufficient\\nmemory, it can have free cores but no available memory\\n(stranded cores); if it has too much memory it can have free\\nmemory that cores do not use (stranded memory).\\nOne approach to reduce RAM costs is to disaggregate mem-\\nory through a shared pool. In this model, servers have their\\nown local RAM, which is sufficient for average or expected\\nuse. If a server needs more memory or has stranded cores,\\nit can allocate from a pool shared among several servers. A\\nmemory pool needs to solve two major problems: latency and\\ncache coherence. Main memory in a larger server CPU has\\na latency of 120-140ns; if a memory pool’s latency is much\\nhigher, application performance will suffer.\\nThe Compute Express Link (CXL) protocol promises to\\nprovide low-latency, cache coherent access to remote mem-\\nory. With ', 'A Case Against CXL Memory Pooling.pdf'), 186: ('local RAM, which is sufficient for average or expected\\nuse. If a server needs more memory or has stranded cores,\\nit can allocate from a pool shared among several servers. A\\nmemory pool needs to solve two major problems: latency and\\ncache coherence. Main memory in a larger server CPU has\\na latency of 120-140ns; if a memory pool’s latency is much\\nhigher, application performance will suffer.\\nThe Compute Express Link (CXL) protocol promises to\\nprovide low-latency, cache coherent access to remote mem-\\nory. With claimed latencies in the hundreds of nanoseconds,\\nCXL can build a large memory pool shared across several\\nservers. Disaggregating storage from compute led to much\\nmore efficient and scalable datacenter storage [ 7]; disaggre-\\ngating memory from compute could have a similar impact,\\nenabling more efficient and lower cost computing.\\nUnfortunately, this paper argues that CXL memory pool-\\ning faces three major problems. Each of these problems, in\\nisolation, might limit potential use cases but is surmountable.\\nTogether, however, they mean that CXL memory pools cost\\nmore, require rewriting software, and do not reduce resource\\nstranding (e.g., unused memory).\\nThe first problem is cost. The primary benefit of a CXL\\nmemory pool is reducing the aggregate RAM needs of data-\\ncenter and cloud systems. Today, servers are provisioned so\\nthey can keep all of their VMs or containers in memory even\\nwhen all of them maximize their footprint simultaneously (a\\n“sum-of-max” approach). Using a CXL pool can allow servers\\nto instead provision for expected use, and when VMs uses\\ntheir entire footprint the system can store cold data in a CXL\\npool. This cost calculation, however, ignores infrastructure\\ncosts. CXL requires a completely parallel network infras-\\ntructure to Ethernet, consisting of a top-of-rack (or top-of-N\\nserver) CXL appliance, with direct, alternative cabling to all\\nof its servers.\\nThe second problem is software complexity . Recent ex-\\nperimental results from real CXL hardware find that many of\\n18\\n\\nHotNets ’23, November 28', 'A Case Against CXL Memory Pooling.pdf'), 187: ('rovision for expected use, and when VMs uses\\ntheir entire footprint the system can store cold data in a CXL\\npool. This cost calculation, however, ignores infrastructure\\ncosts. CXL requires a completely parallel network infras-\\ntructure to Ethernet, consisting of a top-of-rack (or top-of-N\\nserver) CXL appliance, with direct, alternative cabling to all\\nof its servers.\\nThe second problem is software complexity . Recent ex-\\nperimental results from real CXL hardware find that many of\\n18\\n\\nHotNets ’23, November 28–29, 2023, Cambridge, MA, USA Philip Levis, Kun Lin, and Amy Tai\\nCXL’s latency claims are best-case estimates. For example,\\nestimates in the Pond system are that CXL will add 70-90ns\\nover same-NUMA-node DRAM. Recent experimental results,\\nhowever, are that CXL adds 140ns for pointer chasing work-\\nloads [ 19]. This slowdown is for a directly-connected CXL\\nmemory device, not a shared pool, which adds switching,\\nre-timers, and queueing. While loads and stores to a CXL de-\\nvice will be much slower than DRAM, hardware-accelerated\\ncopies of 8kB blocks are close to DRAM speed [ 20]. There-\\nfore, achieving good performance involves rewriting software\\nto explicitly manage CXL memory, copying blocks into lo-\\ncal DRAM; this explicit, conditional, and pervasive mem-\\nory management increases software complexity. Furthermore,\\nmaintaining multiple copies reduces CXL’s memory savings.\\nThe third problem is limited utility . The primary argument\\nfor CXL memory is that memory that would otherwise be\\nstranded, i.e. memory that cannot be allocated to a VM be-\\ncause there are no more compute resources to support a VM,\\ncan now be pooled and used by other servers. However, after\\nanalyzing common server and VM shapes in a 2019 Google\\ncluster trace [ 22] and 2020 Azure Cloud trace [ 9] using a\\nmethodology we developed to evaluate the conditions when\\nmemory pooling can improve stranding, we conclude pooling\\nis rarely helpful. Modern servers are large (hundreds of cores\\nand terabytes of RAM), and VMs are small enough, that VMs\\ncan be place', 'A Case Against CXL Memory Pooling.pdf'), 188: ('nnot be allocated to a VM be-\\ncause there are no more compute resources to support a VM,\\ncan now be pooled and used by other servers. However, after\\nanalyzing common server and VM shapes in a 2019 Google\\ncluster trace [ 22] and 2020 Azure Cloud trace [ 9] using a\\nmethodology we developed to evaluate the conditions when\\nmemory pooling can improve stranding, we conclude pooling\\nis rarely helpful. Modern servers are large (hundreds of cores\\nand terabytes of RAM), and VMs are small enough, that VMs\\ncan be placed on a single server with little stranding . For the\\ntraces we examined, the ratio of VM to server sizes must in-\\ncrease by 32x (Google) and 8x (Azure) before pooling yields\\neven modest efficiency gains. To the best of our knowledge,\\nthis is the first methodology for estimating the potential of\\nmemory pooling for resource packing.\\nIn summary, as long as the cost, software complexity, and\\nlack of utility properties hold, sharing a large DRAM bank\\nbetween servers with CXL is a losing proposition. If one of\\nthese issues goes away – CXL is cheap, CXL is nearly as fast\\nas main memory, or VM shapes become difficult to pack into\\nservers – then CXL memory pools might prove to be useful.\\n2 CXL Memory Pools\\nThis section explains Compute Express Link (CXL) and how\\nCXL memory pools work. Readers familiar with CXL can\\nskip this section. Because many of the details of CXL are\\nextraneous to this paper, we gloss over them; an interested\\nreader can consult the specifications [3–5].\\n2.1 CXL\\nIn this paper, we focus on CXL 1.1, the first productized ver-\\nsion. Samsung [ 15], Intel [ 10], and Astera Labs [ 1] produce\\nCXL 1.1 devices, but none of them are generally available;\\nthey are only for pilot use and commercial evaluation. Version\\n3.0 was published in August, 2022 [5].\\nCXL 1.1 uses the same physical layer (connections and\\nsignaling) as PCIe. PCIe connections consist of one or more\\nparallel “lanes”. CXL 1.1 uses PCIe Gen5 signaling, which\\nprovides 3.9GB/s per lane. CXL devices can have 1-32 lanes.\\nFigure 1: Processing path of ', 'A Case Against CXL Memory Pooling.pdf'), 189: ('the first productized ver-\\nsion. Samsung [ 15], Intel [ 10], and Astera Labs [ 1] produce\\nCXL 1.1 devices, but none of them are generally available;\\nthey are only for pilot use and commercial evaluation. Version\\n3.0 was published in August, 2022 [5].\\nCXL 1.1 uses the same physical layer (connections and\\nsignaling) as PCIe. PCIe connections consist of one or more\\nparallel “lanes”. CXL 1.1 uses PCIe Gen5 signaling, which\\nprovides 3.9GB/s per lane. CXL devices can have 1-32 lanes.\\nFigure 1: Processing path of a memory load (into a CXL\\nRequest) in a dual-socket server to a memory pool con-\\nnected through. Queueing is possible at almost every\\ntransition. The response goes through the same path;\\nlookups become updates.\\nA Samsung 128GB CXL memory device, for example, uses\\n8 lanes to support a maximum throughput of 35GB/s. [ 16]\\nCXL 3.0 uses PCIe Gen6 to double per-lane throughput. PCIe\\nGen7 is expected to double throughput again (to 15GB/s),\\nbut this approaches the practical limit for a differential pair\\n(224Gbps) due to gate switching latencies.\\nCXL differs from PCIe in two major ways: lower latency\\nand cache coherence. CXL strips out many of the protocol\\noverheads of PCIe to reduce latency. While PCIe Gen5 de-\\nvices have best-case round-trip-time latencies of over 500ns,\\nCXL devices can be as low as 150ns. This is the minimum\\nsignaling latency: it does not include the time for a device to\\ngenerate a response (e.g., read from DRAM), any protocol\\nprocessing, or queueing delays. While CXL 3.0 increases the\\nthroughput of CXL, it will not have lower latency [ 11] as\\npacketization delay is not significant.1\\nCXL’s second improvement is hardware cache coherence.\\nThis is useful for devices such as NICs or GPUs, but it is less\\nimportant for memory pools, which typically do not allow\\nservers to share memory.\\n2.2 Inside a CXL Pool\\nCXL memory pools can take many forms; in this section, we\\nfocus on the cloud use case of multiple servers connecting to a\\nsingle device through separate physical links (called a “multi-\\nheaded device”),', 'A Case Against CXL Memory Pooling.pdf'), 190: ('f CXL, it will not have lower latency [ 11] as\\npacketization delay is not significant.1\\nCXL’s second improvement is hardware cache coherence.\\nThis is useful for devices such as NICs or GPUs, but it is less\\nimportant for memory pools, which typically do not allow\\nservers to share memory.\\n2.2 Inside a CXL Pool\\nCXL memory pools can take many forms; in this section, we\\nfocus on the cloud use case of multiple servers connecting to a\\nsingle device through separate physical links (called a “multi-\\nheaded device”), as proposed by Pond. [ 13] We assume the\\nbest-case use of a CXL pool, in which effectively all memory\\naccesses are to memory that is exclusive to a single server,\\nsuch that there are no cache coherence overheads.\\nFigure 1 decomposes the sources of latency when reading\\nfrom a CXL memory pool. First, there are the standard mem-\\nory latency costs: a core must detect that the memory is not in\\n1For a 16-lane device at 62GB/s, a 256 byte CXL flit takes 4ns.\\n19\\nA Case Against CXL Memory Pooling HotNets ’23, November 28–29, 2023, Cambridge, MA, USA\\nany cache or local DRAM. In a dual-socket system (common\\nin cloud servers today), the CXL device might be connected\\nto either socket’s PCIe/CXL lanes, so there is potentially the\\nlatency overhead of the CPU interconnect from one socket to\\nthe other. The processor’s memory management unit (MMU)\\nmust transform a memory request into a CXL request. This\\nenters the CXL root port, which dispatches it to the virtual\\nswitch (VCS) and virtual PCI-to-PCI bridge (vPPB) of the\\ndevice; this dispatch is necessary because a port’s many lanes\\ncan be allocated to many devices (e.g., 16 lanes can be al-\\nlocated to 4 different 4-lane M.2 SSDs). The read request\\nis packetized, encoded, and modulated onto the CXL link,\\nadding packetization and propagation delays.\\nOn reception, the CXL read request has to be reassem-\\nbled from the parallel lanes, decoded and passed to the CXL\\nmemory controller. After protocol processing. the controller\\ntranslates the request into DDR memory read requests. DDR\\nre', 'A Case Against CXL Memory Pooling.pdf'), 191: ('; this dispatch is necessary because a port’s many lanes\\ncan be allocated to many devices (e.g., 16 lanes can be al-\\nlocated to 4 different 4-lane M.2 SSDs). The read request\\nis packetized, encoded, and modulated onto the CXL link,\\nadding packetization and propagation delays.\\nOn reception, the CXL read request has to be reassem-\\nbled from the parallel lanes, decoded and passed to the CXL\\nmemory controller. After protocol processing. the controller\\ntranslates the request into DDR memory read requests. DDR\\nreads are striped across multiple DDR sockets to maximize\\nbandwidth. Once the data is assembled, the CXL device re-\\nsponds with a data response, which goes through a similar\\nswitching, processing, and encoding as the request did.\\nAt every step of this process, there can be queueing. E.g.,\\nCXL read requests can queue at the client, memory read\\nrequests can queue at the device, DDR read requests can\\nqueue in the DDR memory controller, etc.\\n2.3 Pond, an example CXL Pool\\nPond is a recent proposal for using a CXL memory pool to\\nreduce RAM spending in cloud/VM systems [ 13]. Through\\nextensive analysis of Azure workloads, the paper finds that\\na sizeable fraction of Azure memory is stranded: some VMs\\nrequest a low RAM-to-CPU ratio, such that some servers\\nhave unused RAM but every core is in use. Pond argues\\nthat by moving a fraction of every server’s memory to a\\nCXL pool and statistically multiplexing the memory, a pool\\ncan reduce the total memory needed: memory that is unused\\ntoday can instead be used by another server. The tradeoff is\\nperformance: since some VM memory is in the CXL pool, it\\nis slower. Through careful prediction of which applications\\nare latency sensitive and which pages are untouched or rarely\\ntouched, Pond can reduce overall DRAM requirements by\\n7–9% with only 2% of VMs seeing performance degrade by\\nmore than 5%.\\n2.4 The Case Against Memory Pools\\nWe argue that, despite recent interest, CXL memory pools\\nare not an effective way to provision networked servers. They\\nseem like an exciting possibility and ', 'A Case Against CXL Memory Pooling.pdf'), 192: ('r. The tradeoff is\\nperformance: since some VM memory is in the CXL pool, it\\nis slower. Through careful prediction of which applications\\nare latency sensitive and which pages are untouched or rarely\\ntouched, Pond can reduce overall DRAM requirements by\\n7–9% with only 2% of VMs seeing performance degrade by\\nmore than 5%.\\n2.4 The Case Against Memory Pools\\nWe argue that, despite recent interest, CXL memory pools\\nare not an effective way to provision networked servers. They\\nseem like an exciting possibility and fruitful area of research,\\nbut this rosy picture is built on three mistaken and simplified\\nassumptions: cost, complexity, and utility. The next three\\nsections examine each issue in detail.\\n3 Cost\\nThe first obstacle for CXL memory pools is their cost. On\\none hand, RAM is a large fraction of server cost, so a sharedpool to meet peak needs while reducing per-server memory\\nwould reduce costs. We argue that such an analysis makes two\\nassumptions that do not hold in practice. First, it assumes that\\nmemory is fungible and it is possible to cut a server’s RAM by\\na small fraction (e.g., 7-9% in the Pond paper [ 13]). Second,\\nit ignores the cost of an additional cabling and networking\\ninfrastructure.\\n3.1 Memory Provisioning\\nCloud and datacenter servers are limited to discrete steps in\\nDRAM capacity; small reductions in memory do not necessar-\\nily translate to cost savings. Modern server CPUs have 8 (In-\\ntel) or 12 (AMD) DDR channels. Because many applications\\nare memory bandwidth bound, servers always populate ev-\\nery channel. DIMMs, however, only come in certain discrete\\nsizes (e.g., 32GB, 48GB, 64GB)2, and every channel must\\nhave the same sized DIMM. For example, a modern AMD\\nGenoa CPU has 12 channels and 192 cores (384 vCPUs). A\\nGenoa server can be configured with 750GB (64GB DIMMS),\\n1.15TB (96GB DIMMS), or 1.5TB (128GB DIMMS), but no\\nintervening values.\\nPond finds that allocating 25% of VM memory (on aver-\\nage) to a shared pool leads to only small slowdowns (1%\\nof VMs slow down by more than 5%). This is achievable,\\ne', 'A Case Against CXL Memory Pooling.pdf'), 193: ('channel. DIMMs, however, only come in certain discrete\\nsizes (e.g., 32GB, 48GB, 64GB)2, and every channel must\\nhave the same sized DIMM. For example, a modern AMD\\nGenoa CPU has 12 channels and 192 cores (384 vCPUs). A\\nGenoa server can be configured with 750GB (64GB DIMMS),\\n1.15TB (96GB DIMMS), or 1.5TB (128GB DIMMS), but no\\nintervening values.\\nPond finds that allocating 25% of VM memory (on aver-\\nage) to a shared pool leads to only small slowdowns (1%\\nof VMs slow down by more than 5%). This is achievable,\\ne.g., by replacing 128GB DIMMs with 96GB DIMMS. While\\nachievable, allocating 25% of memory to a pool does not\\nreduce the amount of memory. The servers still need the same\\namount of memory, just some of it is in a CXL-connected\\nmemory appliance.\\nMore importantly, Pond also finds that a CXL memory pool\\ncan reduce total RAM by 7-9% without significantly harming\\nperformance. Some VM memory is unused, and by clustering\\nmany servers worth of VMs together, Pond can aggregate\\nthese savings. However, as one cannot shrink server RAM\\nby 7% or 9%, servers must cut their RAM by 25%, and the\\nmemory pool takes the 7–9% out of this 25%. This, in turn,\\nrequires targeting a very specific amount of memory in the\\nCXL pool device, which is difficult given the need to populate\\nevery socket to maximize throughput and the large jumps in\\nDIMM size. There are some specific configurations where\\nthis can work out, but using them constrains the rest of the\\nsystem to specific amounts of memory, numbers of cores, and\\ndegree of CXL pooling.\\n3.2 CXL Infrastructure\\nCXL memory pools are not free. We find that their costs\\nexceed any savings from reducing RAM. When considering\\ncost tradeoffs, we consider consumer (MSRP) prices. Cloud\\nproviders and hyperscalers receive steep discounts, but as we\\nare considering relative costs and tradeoffs between compo-\\nnents, we make a simplifying assumption that hyperscaler\\ndiscounts are similar across high-volume parts.\\n2Today, sizes that are not a power of two, such as 48GB, are rare; we assume\\nvendors would pr', 'A Case Against CXL Memory Pooling.pdf'), 194: ('3.2 CXL Infrastructure\\nCXL memory pools are not free. We find that their costs\\nexceed any savings from reducing RAM. When considering\\ncost tradeoffs, we consider consumer (MSRP) prices. Cloud\\nproviders and hyperscalers receive steep discounts, but as we\\nare considering relative costs and tradeoffs between compo-\\nnents, we make a simplifying assumption that hyperscaler\\ndiscounts are similar across high-volume parts.\\n2Today, sizes that are not a power of two, such as 48GB, are rare; we assume\\nvendors would produce large numbers for a cloud provider if asked.\\n20\\nHotNets ’23, November 28–29, 2023, Cambridge, MA, USA Philip Levis, Kun Lin, and Amy Tai\\nFigure 2: Minimum pool size for RAM cost savings to\\nequal switch cost as pool RAM cost decreases relative to\\nserver RAM. Even if pool RAM is free, for a standard\\n4GB/core memory shape, the pool must be 24 nodes to\\nbreak even with just the switch cost.\\nBecause there are no CXL memory pool devices today,\\nwe do not know how much one costs. However, given the\\nspeeds and processing involved, we propose that an Ethernet\\nswitch is a good approximation. A CXL memory pool device\\nis effectively a high-speed switch, processing CXL packets,\\nmanaging cacheline state, reading and writing memory, and\\nsending responses back to servers. A standard CXL memory\\ndevice (e.g., a Astera Leo [ 1] or Intel device [ 10]) uses 16\\nlanes. At PCIe Gen5 speeds this is 480Gbps. A 16-server pool\\ntherefore processes data at 7.6Tbps.\\nA modern, low-end, 32-port 200Gbps Ethernet switch such\\nas the Mellanox MSN3700-VS2F0 costs $38,500. [ 2] DDR5\\nRAM today is≈3$/GB. For the CXL pool device to break\\neven with its RAM savings, it must save 12.6TB of RAM.\\nAssuming Pond’s optimistic 9% reduction, to break even with\\njust the switch, the servers must have12.6𝑇𝐵\\n0.09= 140TB of RAM\\nin aggregate (using Pond would reduce this to 127TB). For a\\n32-node pool, 127TB, means 4TB per server. A dual-socket\\nAMD Genoa server, the standard next-generation system for\\ncloud providers, has 384 vCPUs. At 4TB/server, there is\\n>10GB of', 'A Case Against CXL Memory Pooling.pdf'), 195: ('x MSN3700-VS2F0 costs $38,500. [ 2] DDR5\\nRAM today is≈3$/GB. For the CXL pool device to break\\neven with its RAM savings, it must save 12.6TB of RAM.\\nAssuming Pond’s optimistic 9% reduction, to break even with\\njust the switch, the servers must have12.6𝑇𝐵\\n0.09= 140TB of RAM\\nin aggregate (using Pond would reduce this to 127TB). For a\\n32-node pool, 127TB, means 4TB per server. A dual-socket\\nAMD Genoa server, the standard next-generation system for\\ncloud providers, has 384 vCPUs. At 4TB/server, there is\\n>10GB of RAM per Genoa vCPU, more than high-RAM\\nVMs provide. You have to buy considerably more RAM for\\nPond’s RAM savings to pay for themselves: you are better\\noff just buying less RAM.\\nWhat if pool RAM is cheaper than server RAM? E.g.,\\nit could be slower, more cost-efficient DIMMs, or DDR4.\\nFigure 2 shows how pool RAM cost affects the minimum\\npool size to break even. These results assume the Genoa setup\\ndescribed above, reducing server RAM by 25% of RAM, and\\nbeing able to reduce aggregate RAM by 9%. Even if pool\\nRAM is completely free, for a standard 4GB/core memory\\nshape, the pool must be 24 nodes to break even. For memory-\\noptimized VMs (8GB/core), if the pool memory is half the\\ncost of server memory (50%), a pool size of 20 could break\\neven with the switch cost.\\nThis accounting is only the capital expenditure of the pool\\ndevice: it doesn’t include the cost of the cabling, assembly,and maintenance to connect the servers to the pool, the cost\\nof the interface cards that connect to the cables, the space\\ncosts of giving up rack slots to pools, or the energy costs of\\nthe pool devices. It also does not consider any operational ex-\\npenditures for maintaining or managing this parallel network\\ninfrastructure. We conclude that the costs of introducing CXL\\ndevices into a datacenter network eclipse any cost savings of\\nreducing RAM.\\n4 Software Complexity\\nThe second major problem with a CXL memory pool is that\\nit will significantly add to software complexity. Experimental\\nresults from real hardware show that, for random accesses', 'A Case Against CXL Memory Pooling.pdf'), 196: ('ing up rack slots to pools, or the energy costs of\\nthe pool devices. It also does not consider any operational ex-\\npenditures for maintaining or managing this parallel network\\ninfrastructure. We conclude that the costs of introducing CXL\\ndevices into a datacenter network eclipse any cost savings of\\nreducing RAM.\\n4 Software Complexity\\nThe second major problem with a CXL memory pool is that\\nit will significantly add to software complexity. Experimental\\nresults from real hardware show that, for random accesses,\\nCXL devices are significantly slower than the best case num-\\nbers suggested in standards documents. While CXL has high\\nlatency, its high throughput means that transferring larger\\nblocks of memory (a few kB) can be competitive with DRAM.\\nThis requires explicitly copying the remote memory into local\\nmemory; the CXL pool stops being memory accessed directly\\nand instead becomes a far memory cache.\\nToday, CXL devices are not commercially available, and\\nNDAs preclude publishing results without prior approval.\\nThe only CXL experimental results we are aware of are from\\na series of versions of a paper by authors from UIUC and\\nIntel [ 19] (the Pond paper [ 13] assumes values reported in\\nstandards). Because we do not have an agreement with CXL\\ndevice vendors, we base our conclusions on these published\\nexperimental results.3\\n4.1 CXL Performance\\nCXL memory devices are high throughput. They are typically\\n16-lane CXL devices; at PCIe Gen5 speeds, this is 480Gbps.\\nA single DDR5-4800 DIMM (standard on new servers today)\\nis 300Gbps. Server CPUs have many DIMMs, but 480Gbps\\nis fast and it can support reasonable copy performance of\\nlarger objects. For example, a copy from CXL memory to\\nlocal DDR by a single core can use 80% of the bandwidth of\\ntwo DIMMs.\\nHowever, CXL memory devices are also high latency. The\\nUIUC measurement results of a directly connected (no switch-\\ning) CXL device show CXL loads have best case latencies\\nof 2x of local memory, substantially slower than a remote\\nNUMA node (1.5x) [ 19]. For a modern server CPU (', 'A Case Against CXL Memory Pooling.pdf'), 197: ('300Gbps. Server CPUs have many DIMMs, but 480Gbps\\nis fast and it can support reasonable copy performance of\\nlarger objects. For example, a copy from CXL memory to\\nlocal DDR by a single core can use 80% of the bandwidth of\\ntwo DIMMs.\\nHowever, CXL memory devices are also high latency. The\\nUIUC measurement results of a directly connected (no switch-\\ning) CXL device show CXL loads have best case latencies\\nof 2x of local memory, substantially slower than a remote\\nNUMA node (1.5x) [ 19]. For a modern server CPU (e.g.,\\nSapphire Rapids, as used in the paper), this means a memory\\naccess jumps from 140ns for local memory to 280ns for CXL\\nmemory. At 2.0-3.0 GHz in a multiple-issue superscalar pro-\\ncessor, this latency stalls the CPU for over 500 instructions.\\nSwitched system with re-timers will have higher latency.\\n3The revision of the UIUC/Intel paper accepted to MICRO [ 19] reports\\nresults from multiple CXL devices, which vary greatly in performance. We\\nfocus on latencies from the highest performance device measured, CXL-A,\\nwhich is an ASIC.\\n21\\nA Case Against CXL Memory Pooling HotNets ’23, November 28–29, 2023, Cambridge, MA, USA\\n4.2 Instructions or Transfers?\\nWhile CXL will perform poorly as a transparent far memory,\\nits throughput means it can read or write larger blocks with\\ngood performance. For example, early Intel/UIUC results\\nshow that synchronously copying 8kB from DRAM to CXL\\nmemory can have 80% the throughput of DRAM-to-DRAM\\ncopies when using the DSA memory copy accelerator. [20]\\nThis involves explicitly copying CXL memory into local\\nmemory. In this model, CXL memory is a far memory cache,\\nwhich processors can access faster than remote memory or\\nstorage, but which programs must explicitly copy from. This\\ngets at a fundamental question with using CXL memory: how\\ndoes a program access it?\\nInstruction-level loads and stores operate on a cache line\\ngranularity. Reasonable CXL performance, however, requires\\n8kB transfers. Unless an application can take an enormous\\nperformance hit when accessing CXL memory, it cannot', 'A Case Against CXL Memory Pooling.pdf'), 198: ('ing CXL memory into local\\nmemory. In this model, CXL memory is a far memory cache,\\nwhich processors can access faster than remote memory or\\nstorage, but which programs must explicitly copy from. This\\ngets at a fundamental question with using CXL memory: how\\ndoes a program access it?\\nInstruction-level loads and stores operate on a cache line\\ngranularity. Reasonable CXL performance, however, requires\\n8kB transfers. Unless an application can take an enormous\\nperformance hit when accessing CXL memory, it cannot do\\nso transparently. Instead, it must do so explicitly, or the device\\nmust act as a page-level cache (e.g., a far memory RAMdisk\\npartition).\\nExplicit copies require invasive changes to applications.\\nFor example, suppose a program calculates the maximum\\nvalue over an array (tens of kB), and this array is in CXL\\nmemory. The loop is fast, consisting of only 4 instructions. At\\n2 instructions per clock, it can process 2 bytes every clock. At\\n3GHz, 280ns is 840 ticks, and the loops processes 1680 bytes\\nin 280ns. A cache line is 64 bytes, so the processor must have\\nover 26 prefetches in flight in order to keep the pipeline busy.\\nProcessors do not prefetch so deeply, so this loop will spend\\nmost of its time stalled on CXL reads.\\nIn contrast, a program that explicitly copies from CXL\\nmemory into local memory will perform much faster, because\\nit pays the 280ns latency once then operates on local, in-cache\\nmemory. However, the problem is that this requires an explicit\\nmemory copy to local memory. It requires rewriting programs\\nto conditionally copy if data is in CXL; CXL memory is not\\ntransparent and requires pervasive changes to software. Fur-\\nthermore, it requires making copies of data, which increases\\napplication memory use.\\n5 Limited Utility\\nIn this section we develop a methodology for estimating the\\nefficiency gains that can be recouped with memory pool-\\ning. Our primary efficiency metric is utilization , defined as\\nused capacity\\ntotal capacity. The main argument for memory pooling is that it\\ncan improve utilization', 'A Case Against CXL Memory Pooling.pdf'), 199: ('programs\\nto conditionally copy if data is in CXL; CXL memory is not\\ntransparent and requires pervasive changes to software. Fur-\\nthermore, it requires making copies of data, which increases\\napplication memory use.\\n5 Limited Utility\\nIn this section we develop a methodology for estimating the\\nefficiency gains that can be recouped with memory pool-\\ning. Our primary efficiency metric is utilization , defined as\\nused capacity\\ntotal capacity. The main argument for memory pooling is that it\\ncan improve utilization by reducing the amount of stranded\\nmemory, in other words reducing ‘total capacity’.\\nMethodology. To approximate utilization improvement\\nfrom memory pooling, we need to estimate a cluster’s uti-\\nlization. Utilization is a multi-dimensional bin-packing prob-\\nlem [ 8,9,23,24], and to optimize efficiency, a datacenter\\ncluster scheduler should pack VMs onto physical machines\\nas tightly as possible. Of course, there are performance and\\nisolation considerations when packing workloads as tightly\\nas possible, so realistically, operators leave some fraction ofheadroom on each machine. Despite this, the optimal bin\\npacking utilization of a machine is still a good proxy for the\\nactual utilization an operator can achieve in a real deployment;\\nlater in this section, we validate that the optimal packing ap-\\nproximates an event-driven packer within reasonable error\\nbounds. Crucially, using the optimal utilization does not pin\\nefficiency gains to a specific cluster scheduler implementation\\nand enables faster analysis than re-running a full cluster trace.\\nTherefore, we define a cluster’s utilization as its utilization\\nunder the optimal packing of a VM workload on the cluster.\\nTo determine the efficiency gain of pooling, we calculate\\nthe utilization improvement from adding a pool to a cluster.\\nWe model a cluster as a set of machines. We model pooling\\nas a large machine that is 𝑁-times the size of a machine.\\n𝑁reflects the number of machines that share a CXL pool.\\nNote that modelling pooling as a large machine overestimates\\nthe u', 'A Case Against CXL Memory Pooling.pdf'), 200: ('e-running a full cluster trace.\\nTherefore, we define a cluster’s utilization as its utilization\\nunder the optimal packing of a VM workload on the cluster.\\nTo determine the efficiency gain of pooling, we calculate\\nthe utilization improvement from adding a pool to a cluster.\\nWe model a cluster as a set of machines. We model pooling\\nas a large machine that is 𝑁-times the size of a machine.\\n𝑁reflects the number of machines that share a CXL pool.\\nNote that modelling pooling as a large machine overestimates\\nthe utilization gain from pooling, because the large machine\\nelides allocation boundaries. In a true pooling setup compute\\nresources must still be allocated to the machine boundary, and\\nmemory resources must respect a machine and pool boundary.\\nTherefore any improvement due to pooling in this section\\nis a generous upper bound on what pooling can realistically\\nachieve.\\nDatacenter traces. For VM workloads and machine sizes\\nthat are representative of real deployments, we analyze two\\ncluster traces, the 2019 Google cluster trace and 2020 Azure\\nTrace for Packing [ 9]. From each trace we derive a distribution\\nof VM demand and realistic machine sizes [ 22]. In the Google\\ntrace, we use VMs and machines from Cell A and only include\\nVMs with production priority. In the Azure trace, we only\\ninclude VMs with high priority. Note that the Google trace\\nis a trace of internal workloads, and the Azure trace is for\\ncloud, or customer, VMs; we analyze both traces to see if the\\ntwo different settings affect the impact of pooling. We model\\nboth machines and VMs as two-dimensional vectors of CPU\\nand memory.\\nOptimal packing. We use a vector bin-packing library\\nto calculate the optimal packing of each set of VMs. The\\nlibrary takes a set of VMs and a machine size, and returns\\ntheminimum number of machines it takes to pack the entire\\nset. Therefore, from a utilization perspective, ‘used capacity’\\nis always fixed, because we must land all VMs, but ‘total\\ncapacity’ is variable, because it depends how optimally the\\nVMs can be packed on the give', 'A Case Against CXL Memory Pooling.pdf'), 201: ('model\\nboth machines and VMs as two-dimensional vectors of CPU\\nand memory.\\nOptimal packing. We use a vector bin-packing library\\nto calculate the optimal packing of each set of VMs. The\\nlibrary takes a set of VMs and a machine size, and returns\\ntheminimum number of machines it takes to pack the entire\\nset. Therefore, from a utilization perspective, ‘used capacity’\\nis always fixed, because we must land all VMs, but ‘total\\ncapacity’ is variable, because it depends how optimally the\\nVMs can be packed on the given machine sizes.\\nOur optimal packing packs a snapshot of the cluster, which\\nis a simpler problem than the packing problem in a real cluster\\nscheduler, because the snapshot is not bound to previous\\nplacement decisions and does not take VM departures and\\narrivals into consideration. We packed many snapshots and\\nstudied the result distribution; all snapshots had trends similar\\nto Figures 3 and 4.\\nValidation. We validate that a cluster’s utilization under\\noptimal packing is close to the utilization under a reasonable,\\nlive cluster scheduler. We implement a greedy bin packer that\\nreplays a cluster trace and compare the cluster’s utilization\\n22\\nHotNets ’23, November 28–29, 2023, Cambridge, MA, USA Philip Levis, Kun Lin, and Amy Tai\\nFigure 3: Google cluster trace: Pooling resources across\\nup to 16 machines yields does not yield utilization im-\\nprovements until VMs are at least 32x larger.\\nFigure 4: Azure trace: Pooling resources across up to 16\\nmachines does not yield utilization improvements until\\nVMs are at least 8x larger. These (cloud) VMs are much\\nlarger than the VMs in the Google trace, but still not\\nlarge enough for pooling to matter.\\nafter running the trace to the utilization of the optimal pack-\\ning, at the snapshot of the cluster after the trace has been\\nplayed. We do this comparison for subsets of traces across all\\n8 cells available in the 2019 Google trace and find that opti-\\nmal packing utilization is 0-17% better than the utilization of\\nthe greedy bin packer, with a median difference of 5%. This\\ngreedy b', 'A Case Against CXL Memory Pooling.pdf'), 202: ('8x larger. These (cloud) VMs are much\\nlarger than the VMs in the Google trace, but still not\\nlarge enough for pooling to matter.\\nafter running the trace to the utilization of the optimal pack-\\ning, at the snapshot of the cluster after the trace has been\\nplayed. We do this comparison for subsets of traces across all\\n8 cells available in the 2019 Google trace and find that opti-\\nmal packing utilization is 0-17% better than the utilization of\\nthe greedy bin packer, with a median difference of 5%. This\\ngreedy bin packer is likely worse at packing workloads than\\nproduction-grade cluster schedulers, which means that the\\noptimal packing can even more closely approximate the uti-\\nlization of production-grade schedulers. These error bounds\\nsuggest that the optimal packing is a reliable proxy for cluster\\nutilization in the following results.\\nResults. Figures 3 and 4 show the results, where utilization\\nis normalized to a 1x machine pooling factor and 1x VM sizes.\\nTaking the unmodified VM demands from the trace resulted\\nin no utilization gain from pooling of any size (flat blue line)\\nin both datasets.\\nTo see how sensitive this result is and how much packing\\nflexibility there is, we inflate the sizes of VMs. For example,\\nfor 8x we increase the core count and memory size of every\\nVM by a factor of 8. For the Google trace, we find that pooling\\nhas at most 1% utilization improvement, even when VMs are\\ninflated up to 16x. Weighed against the additional costs and\\ncomplexity of pooling outlined earlier in the paper, this smallimprovement renders pooling out of the question. In Figure 3,\\npooling begins to have a benefit with a 32x inflation factor,\\nand even then, it is modest, less than 5%. VMs must be 64x\\nlarger in order for there to be significant resource stranding at\\na single server, which is what reduces stranding with pooling.\\nOn the other hand, the Azure VMs (Figure 4) begin to see\\nutilization improve at around 8x VM sizes, suggesting that the\\ncloud VMs are larger than the internal Google VMs to begin\\nwith, and that the pooli', 'A Case Against CXL Memory Pooling.pdf'), 203: ('rovement renders pooling out of the question. In Figure 3,\\npooling begins to have a benefit with a 32x inflation factor,\\nand even then, it is modest, less than 5%. VMs must be 64x\\nlarger in order for there to be significant resource stranding at\\na single server, which is what reduces stranding with pooling.\\nOn the other hand, the Azure VMs (Figure 4) begin to see\\nutilization improve at around 8x VM sizes, suggesting that the\\ncloud VMs are larger than the internal Google VMs to begin\\nwith, and that the pooling calculus may differ for internal\\nworkloads versus public cloud workloads.\\nIn general, if VMs can reach a certain size with respect to\\nphysical machine size, pooling can help with the resulting\\nresource stranding. However, based on the analyzed traces,\\nmost VMs are small and servers are large: while bin-packing\\nis an NP-hard problem, if the bins are large and almost all of\\nthe objects are small, there is little leftover space in any bin.\\nAs long as VM sizes remain small, pooling is untenable.\\n6 Discussion\\nCompute Express Link provides numerous improvements to\\nPCIe, notably lower latency and cache coherence. For com-\\nplex, latency-sensitive peripherals such as NICs and GPUs,\\nCXL will allow much faster and more fine-grained coordina-\\ntion between the CPU and these processors.\\nThis paper examines another potential use of CXL, dis-\\naggregation memory across servers through a shared CXL\\nmemory pool. While there has been a lot of excitement and\\ninterest in such an approach, there has been almost no experi-\\nmental data to verify its feasibility. Furthermore, analyses of\\nits potential benefits ignore many of the practical deployment\\nissues and costs.\\nDisaggregation in datacenter and cloud systems was first\\nproposed for hard disk drive storage, where seek times of\\nmilliseconds outweigh any additional system or network la-\\ntency. Memory, however, is at the opposite of this spectrum.\\nArchitectures move memory closer to compute because lo-\\ncality is key to performance. GPUs, TPUs, and IPUs all have\\ntheir own memory. For ', 'A Case Against CXL Memory Pooling.pdf'), 204: (' data to verify its feasibility. Furthermore, analyses of\\nits potential benefits ignore many of the practical deployment\\nissues and costs.\\nDisaggregation in datacenter and cloud systems was first\\nproposed for hard disk drive storage, where seek times of\\nmilliseconds outweigh any additional system or network la-\\ntency. Memory, however, is at the opposite of this spectrum.\\nArchitectures move memory closer to compute because lo-\\ncality is key to performance. GPUs, TPUs, and IPUs all have\\ntheir own memory. For example, a 6 foot cable adds 12ns of\\npropagation delay in each direction, and at memory speeds\\nevery such little increase matters.\\nIn this paper, we described three reasons why CXL mem-\\nory pools will not be useful in cloud and datacenter systems:\\ncost, software complexity, and a lack of utility. Each reason is\\nbased on the best information we could find and is grounded\\nin computing today. Future advances or marketplace shifts\\nmay invalidate our assumptions and change the calculus to\\nmake CXL pools attractive; that they could play a role as\\nfar memory RAMdisks, which an OS copies into local mem-\\nory. We look forward to and encourage research on such a\\nfuture, but at the same time do not want to mistake hopeful\\npossibilities for technical reality.\\nReferences\\n[1]Astera Labs. Leo cxl memory connectivity platform. https:\\n/ / www.asteralabs.com / products / cxl - memory - platform / leo - cxl -\\nmemory-connectivity-platform/, 2023.\\n23\\nA Case Against CXL Memory Pooling HotNets ’23, November 28–29, 2023, Cambridge, MA, USA\\n[2]CDW Corporation. Mellanox Spectrum-2 MSN3700 switch 32\\nports. https://www .cdw.com/product/mellanox-spectrum-2-msn3700-\\nswitch-32-ports-managed-rack-mountable/6415759, 2023.\\n[3]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 1.1, 2019.\\n[4]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 2.0, 2020.\\n[5]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 3.0, 2022.\\n[6]P. Duraisamy, W.', 'A Case Against CXL Memory Pooling.pdf'), 205: ('A, USA\\n[2]CDW Corporation. Mellanox Spectrum-2 MSN3700 switch 32\\nports. https://www .cdw.com/product/mellanox-spectrum-2-msn3700-\\nswitch-32-ports-managed-rack-mountable/6415759, 2023.\\n[3]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 1.1, 2019.\\n[4]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 2.0, 2020.\\n[5]Compute Express Link Consortium, Inc. Compute Express Link (CXL)\\nSpecification, Revision 3.0, 2022.\\n[6]P. Duraisamy, W. Xu, S. Hare, R. Rajwar, D. Culler, Z. Xu, J. Fan,\\nC. Kennelly, B. McCloskey, D. Mijailovic, B. Morris, C. Mukher-\\njee, J. Ren, G. Thelen, P. Turner, C. Villavieja, P. Ranganathan, and\\nA. Vahdat. Towards an adaptable systems architecture for memory tier-\\ning at warehouse-scale. In Proceedings ofthe28th ACM International\\nConference onArchitectural Support forProgramming Languages and\\nOperating Systems, V olume 3, ASPLOS 2023, page 727–741, New\\nYork, NY , USA, 2023. Association for Computing Machinery.\\n[7]P. X. Gao, A. Narayan, S. Karandikar, J. Carreira, S. Han, R. Agar-\\nwal, S. Ratnasamy, and S. Shenker. Network requirements for re-\\nsource disaggregation. In Proceedings ofthe12th USENIX Conference\\nonOperating Systems Design andImplementation , OSDI’16, page\\n249–264, USA, 2016. USENIX Association.\\n[8]R. Grandl, G. Ananthanarayanan, S. Kandula, S. Rao, and A. Akella.\\nMulti-resource packing for cluster schedulers. ACM SIGCOMM\\nComputer Communication Review, 44(4):455–466, 2014.\\n[9]O. Hadary, L. Marshall, I. Menache, A. Pan, E. E. Greeff, D. Dion,\\nS. Dorminey, S. Joshi, Y . Chen, M. Russinovich, et al. Protean: Vm allo-\\ncation service at scale. In Proceedings ofthe14th USENIX Conference\\nonOperating Systems Design andImplementation , pages 845–861,\\n2020.\\n[10] I. Intel. Intel FPGA Compute Express Link (CXL) IP. https://\\nwww.intel.com/content/www/us/en/products/details/fpga/intellectual-\\nproperty/interface-protocols/cxl-ip .html, 2023.\\n[11] Ishwar Agarwal. CXL overview and evolution. In\\nProceedings of HotChips 34, 2022', 'A Case Against CXL Memory Pooling.pdf'), 206: ('he, A. Pan, E. E. Greeff, D. Dion,\\nS. Dorminey, S. Joshi, Y . Chen, M. Russinovich, et al. Protean: Vm allo-\\ncation service at scale. In Proceedings ofthe14th USENIX Conference\\nonOperating Systems Design andImplementation , pages 845–861,\\n2020.\\n[10] I. Intel. Intel FPGA Compute Express Link (CXL) IP. https://\\nwww.intel.com/content/www/us/en/products/details/fpga/intellectual-\\nproperty/interface-protocols/cxl-ip .html, 2023.\\n[11] Ishwar Agarwal. CXL overview and evolution. In\\nProceedings of HotChips 34, 2022.\\n[12] A. Lagar-Cavilla, J. Ahn, S. Souhlal, N. Agarwal, R. Burny, S. Butt,\\nJ. Chang, A. Chaugule, N. Deng, J. Shahid, G. Thelen, K. A. Yurt-\\nsever, Y . Zhao, and P. Ranganathan. Software-defined far memory\\nin warehouse-scale computers. In Proceedings oftheTwenty-Fourth\\nInternational Conference onArchitectural Support forProgramming\\nLanguages andOperating Systems , ASPLOS ’19, page 317–330, New\\nYork, NY , USA, 2019. Association for Computing Machinery.\\n[13] H. Li, D. S. Berger, L. Hsu, D. Ernst, P. Zardoshti, S. Novakovic,\\nM. Shah, S. Rajadnya, S. Lee, I. Agarwal, M. D. Hill, M. Fontoura,\\nand R. Bianchini. Pond: Cxl-based memory pooling systems for cloud\\nplatforms. In Proceedings ofthe28th ACM International Conference\\nonArchitectural Support forProgramming Languages andOperating\\nSystems, V olume 2, ASPLOS 2023, page 574–587, New York, NY ,\\nUSA, 2023. Association for Computing Machinery.\\n[14] H. A. Maruf, H. Wang, A. Dhanotia, J. Weiner, N. Agarwal,\\nP. Bhattacharya, C. Petersen, M. Chowdhury, S. Kanaujia, and\\nP. Chauhan. Tpp: Transparent page placement for cxl-enabled tiered-\\nmemory. In Proceedings ofthe28th ACM International Conference\\nonArchitectural Support forProgramming Languages andOperating\\nSystems, V olume 3, ASPLOS 2023, page 742–755, New York, NY ,\\nUSA, 2023. Association for Computing Machinery.\\n[15] S. Newsroom. Samsung Electronics Introduces Industry’s First 512GB\\nCXL Memory Module. https://news .samsung.com/global/samsung-\\nelectronics-introduces-industrys-first-512gb-cxl-memory-module,\\n2022.\\n[16] S.', 'A Case Against CXL Memory Pooling.pdf'), 207: ('P. Chauhan. Tpp: Transparent page placement for cxl-enabled tiered-\\nmemory. In Proceedings ofthe28th ACM International Conference\\nonArchitectural Support forProgramming Languages andOperating\\nSystems, V olume 3, ASPLOS 2023, page 742–755, New York, NY ,\\nUSA, 2023. Association for Computing Machinery.\\n[15] S. Newsroom. Samsung Electronics Introduces Industry’s First 512GB\\nCXL Memory Module. https://news .samsung.com/global/samsung-\\nelectronics-introduces-industrys-first-512gb-cxl-memory-module,\\n2022.\\n[16] S. Newsroom. Samsung Develops Industry’s First CXL DRAM Sup-\\nporting CXL 2.0. https://news .samsung.com/global/samsung-develops-\\nindustrys-first-cxl-dram-supporting-cxl-2-0, 2023.\\n[17] I. B. Peng, M. B. Gokhale, and E. W. Green. System Evaluation\\nof the Intel Optane Byte-Addressable NVM. In Proceedings ofthe\\nInternational Symposium onMemory Systems , MEMSYS ’19, page304–315, New York, NY , USA, 2019. Association for Computing Ma-\\nchinery.\\n[18] Z. Ruan, M. Schwarzkopf, M. K. Aguilera, and A. Belay. Aifm:\\nHigh-performance, application-integrated far memory. In Proceedings\\nofthe14th USENIX Conference onOperating Systems Design and\\nImplementation, OSDI’20, USA, 2020. USENIX Association.\\n[19] Y . Sun, Y . Yuan, Z. Yu, R. Kuper, I. Jeong, R. Wang, and N. S. Kim.\\nDemystifying cxl memory with genuine cxl-ready systems and devices,\\nOctober 2023.\\n[20] Y . Sun, Y . Yuan, Z. Yu, R. Kuper, I. Jeong, R. Wang, and N. S. Kim.\\nDemystifying cxl memory with genuine cxl-ready systems and devices,\\nv1, March 2023.\\n[21] The Next Platform. CXL And Gen-Z Iron Out A Coherent Interconnect\\nStrategy. https://www .nextplatform .com/2020/04/03/cxl-and-gen-z-\\niron-out-a-coherent-interconnect-strategy/, 2020.\\n[22] M. Tirmazi, A. Barker, N. Deng, M. E. Haque, Z. G. Qin, S. Hand,\\nM. Harchol-Balter, and J. Wilkes. Borg: the Next Generation.\\nInProceedings oftheFifteenth European Conference onComputer\\nSystems (EuroSys’20), Heraklion, Greece, 2020. ACM.\\n[23] A. Verma, M. Korupolu, and J. Wilkes. Evaluating job packing in\\nwarehouse-scale computing. In ', 'A Case Against CXL Memory Pooling.pdf'), 208: ('form. CXL And Gen-Z Iron Out A Coherent Interconnect\\nStrategy. https://www .nextplatform .com/2020/04/03/cxl-and-gen-z-\\niron-out-a-coherent-interconnect-strategy/, 2020.\\n[22] M. Tirmazi, A. Barker, N. Deng, M. E. Haque, Z. G. Qin, S. Hand,\\nM. Harchol-Balter, and J. Wilkes. Borg: the Next Generation.\\nInProceedings oftheFifteenth European Conference onComputer\\nSystems (EuroSys’20), Heraklion, Greece, 2020. ACM.\\n[23] A. Verma, M. Korupolu, and J. Wilkes. Evaluating job packing in\\nwarehouse-scale computing. In 2014 IEEE International Conference\\nonCluster Computing (CLUSTER), pages 48–56. IEEE, 2014.\\n[24] A. Verma, L. Pedrosa, M. Korupolu, D. Oppenheimer, E. Tune, and\\nJ. Wilkes. Large-scale cluster management at google with borg. In\\nProceedings oftheTenth European Conference onComputer Systems ,\\npages 1–17, 2015.\\n24', 'A Case Against CXL Memory Pooling.pdf'), 209: ('  \\n  \\nAbstract —Heart Beat Rate calculation has traditionally been \\nconducted using specialized hardware most commonly in the \\nform of pulse oximeters or Electrocardiogram devices. Even \\nthough these methods offer high reliability, they require the users to have special sensor to measure their heart rate. In this paper we propose a system capable of estimating the heart beat \\nrate using just a camera from a commercially available mobile \\nphone. The advantage of this method is that the user does not need specialized hardware and s/he can take a measurement in virtually any place under almost any circumstances. Moreover \\nthe measurement provided can be used as a tool for health \\ncoaching applications or effective telecare services aimed in enhancing the user’s well being. \\nI. INTRODUCTION  \\nHE rapid evolution of technology has brought highly \\nsophisticated electronic devices like modern mobile \\nphones in our daily lives. Smartphones with multimedia \\ncapabilities is such an example that opens up new \\npossibilities for application development and service delivery. High speed processors, direct access to embedded \\nmultimedia hardware and internet connectivity provides the \\nopportunity to interact with the user in a new and innovative \\nway. \\nAs the percentage of older people in the population of \\ndeveloped countries increases, there are more incidents of \\nchronic disease that call for a higher percentage of the GDP \\nto be spent on health care. Consequently, there is a call for technology to enhance the independence of the elder and \\nallow more care services to be delivered at home [1]. \\nOur work here is focused on utilizing a common device \\nsuch as a mobile phone with a camera in order to calculate \\nthe heart beat rate which can later be used in personal health coaching applications or in telecare services. Our goal has \\nbeen to demonstrate that such a measurement provides \\nrelatively good accuracy which can be enhanced further \\ndepending on the detection algorithm and the parameters \\nused. \\nThe research has been devel', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 210: (\"f the elder and \\nallow more care services to be delivered at home [1]. \\nOur work here is focused on utilizing a common device \\nsuch as a mobile phone with a camera in order to calculate \\nthe heart beat rate which can later be used in personal health coaching applications or in telecare services. Our goal has \\nbeen to demonstrate that such a measurement provides \\nrelatively good accuracy which can be enhanced further \\ndepending on the detection algorithm and the parameters \\nused. \\nThe research has been developed in collaboration with \\nHealth-Smart Limited that has substantial experience in self-\\ncare ICT for prevention and control of Long Term \\n \\nManuscript received [14/4/2010]. \\nP. Pelegris and K.Banitsas are with the Electrical and Computer \\nEngineering Department, Brunel University, West London, Uxbridge, Middlesex, UB8 3PH, United Kingdom (phone: +44(0)1895430058; \\nemail:{panagiotis.pelegris, konstantinos.banitsas}@brunel.ac.uk). \\nT. Orbach is with Health-Smart Limited, 77b Fleet Road, Hampstead, \\nLondon, NW3 2QU, United Kingdom (e-mail: Tuvi@health-smart.co.uk, \\nwww.healthsmart.co.uk\\n). \\nK. Marias is with the Institute of Computer Science in the Foundation \\nfor Research and Technology, PO Box 1385, 70013, Crete, Greece (email: \\nkmarias@ics.forth.gr) Conditions (LTC’s) including cardiovascular and \\npsychological conditions. One of their objectives is to \\nempower patients to assess their state of body and mind and \\ntrain them to improve their health and prevent LTC’s by using inexpensive and friendly consumer ICT sensors [2]. \\nCurrently, there is an increasing research activity on \\nwearable biosensor systems that often use a mobile phone or \\na PDA as a small scale processing and communications \\nplatform or as a media user interface unit. Studies have shown that when working with mobile phone and PDA's \\nimplementing healthcare systems, the vast majority of them \\nuse a mobile device for processing and user interface platform but not as a sensor itself [3].  \\nIn the study we can also observe that users tend to be \", 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 211: (\" ICT sensors [2]. \\nCurrently, there is an increasing research activity on \\nwearable biosensor systems that often use a mobile phone or \\na PDA as a small scale processing and communications \\nplatform or as a media user interface unit. Studies have shown that when working with mobile phone and PDA's \\nimplementing healthcare systems, the vast majority of them \\nuse a mobile device for processing and user interface platform but not as a sensor itself [3].  \\nIn the study we can also observe that users tend to be very \\nconcerned with the way a sensor affects their appearance or \\nhabits, thus utilizing a device embedded sensor as a camera \\nprovides a truly non intrusive way of acquiring health information from the users without the need for them to train \\non how to use a new type of device provided they already \\nfeel comfortable enough using the menu of a mobile phone \\n[3]. Moreover, the ease of use (simply placing one’s finger \\non the camera) combined with the live feedback will likely be more appealing to the users and might play a positive role \\nin engaging them to a process that could benefit their health; \\nfor example Health-Smart has developed breathing training applications that could help a patient practice breathing \\nproperly. \\nCommon pulse oximeters are based on the different light-\\nabsorbing characteristics of oxyhemoglobin and \\ndeoxyhemoglobin at two different wavelengths (ie, 660 nm red and 940 nm infrared) and the pulsating nature of arterial \\nblood flow [4]. With pulse oximeters, a finger or earlobe \\nprobe is used: a red light-emitting diode (LED) and an infrared LED are located on one side of the probe, and a \\nphotodetector is located on the other side [4]. \\nThe transmitted light is received by the photodetector and  \\nis divided into two components. Component A is transmitted \\nlight of variable intensity that occurs during a systole and is a function of the pulsations of oxygenated arterial blood. \\nComponent B is transmitted light that has a constant \\nintensity and is a function of various tissues. The pu\", 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 212: ('be is used: a red light-emitting diode (LED) and an infrared LED are located on one side of the probe, and a \\nphotodetector is located on the other side [4]. \\nThe transmitted light is received by the photodetector and  \\nis divided into two components. Component A is transmitted \\nlight of variable intensity that occurs during a systole and is a function of the pulsations of oxygenated arterial blood. \\nComponent B is transmitted light that has a constant \\nintensity and is a function of various tissues. The pulse \\noximeter divides the pulsatile absorption of component A by \\nthe background light absorption of component B, at the two different wavelengths, to obtain an absorption ratio and \\ncalculate oxyhemoglobin saturation often based on the \\nMendelson and Kent equation [5] \\n A Novel Method to Detect Heart Beat Rate Using a Mobile Phone \\nPelegris P., Banitsas K., Orbach T., Marias K.  \\nT32nd Annual International Conference of the IEEE EMBS\\nBuenos Aires, Argentina, August 31 - September 4, 2010\\n978-1-4244-4124-2/10/$25.00 ©2010 IEEE5488\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:04 UTC from IEEE Xplore.  Restrictions apply. \\n  \\nII. METHODOLOGY  \\nIn order to extract the heart beat information from a \\nstream of picture frames we need to deal with a number of \\nproblems in an efficient way. Live readings on a general \\npurpose device such as a mobile phone complicates things further as we cannot control the lighting conditions nor the \\nway the user is going to place his/her finger on the camera \\nlens, an example is show below in Figure 1. \\n \\n \\nFigure 1: Example of using a smartphone for pulse reading \\n \\nOur initial approach is to capture a given number of \\nframes depending on the sampling rate of the available \\nhardware and then analyse those trying to determine if our input matches the pattern of heart beating, or if the input \\nsuffers from high noise making it impossible to provide a \\nreliable estimate. A sample is demonstrated in Figure 2, that \\ndisplays Input data rea', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 213: ('/her finger on the camera \\nlens, an example is show below in Figure 1. \\n \\n \\nFigure 1: Example of using a smartphone for pulse reading \\n \\nOur initial approach is to capture a given number of \\nframes depending on the sampling rate of the available \\nhardware and then analyse those trying to determine if our input matches the pattern of heart beating, or if the input \\nsuffers from high noise making it impossible to provide a \\nreliable estimate. A sample is demonstrated in Figure 2, that \\ndisplays Input data read from the camera while the user has \\nhis/her finger on it. \\n \\n \\nFigure 2: Camera Input Sample \\n The camera captures “real” time preview frames as the \\nusers place their fingers on the lens, then a grayscale portion \\nof the image is scanned and processed resulting in brightness information for every individual frame. This way we can \\nextract an average brightness value for every frame. \\nEvery heart beat creates a wave of blood that reaches the \\ncapillaries in the tip of the finger: when the capillaries are \\nfull blood they will obstruct the light resulting in lower \\naverage brightness values. As blood is retracted more light can pass through – a change that is directly reflected on the \\nincreasing values of the brightness. This way we are able to \\ncapture the initial crude signal of the pulse and process it to \\nextract information on the heart beat rate. \\nWhile normally taking a picture or a video require the \\ncamera to focus on an object, in our approach this is not necessary as the information we are interested in is \\ncontained within the brightness information of the pixels, \\ntherefore we deliberately set the camera properties to disable the option to focus. \\nThe advantage of this application relies in its simplicity:  \\nthe users only need to put their finger on the camera as in \\nFigure 1 and then wait a few seconds to get a reading on \\ntheir pulse However there are certain limitations related to lighting conditions which will be discussed later. \\nNevertheless, being able to calculate heart rate using a \\ngen', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 214: ('sted in is \\ncontained within the brightness information of the pixels, \\ntherefore we deliberately set the camera properties to disable the option to focus. \\nThe advantage of this application relies in its simplicity:  \\nthe users only need to put their finger on the camera as in \\nFigure 1 and then wait a few seconds to get a reading on \\ntheir pulse However there are certain limitations related to lighting conditions which will be discussed later. \\nNevertheless, being able to calculate heart rate using a \\ngeneral purpose device such as a mobile phone opens up \\nnew possibilities for applications on health services and \\npersonal health coaching.  \\nIn order to ensure reliability on our readings we are \\nmatching our input signal to a crude heart beat pattern of \\nalternating peaks and troughs. The algorithm is scanning a subset of the frames until it detects a peak, then it will \\nattempt to detect a trough. When a predefined number of \\npeaks – troughs have been detected we consider the \\nalgorithm to be synchronized as shown in Figure 3, from that \\npoint on we are able to calculate a good estimation on the beats per minute. During our tests we have been working \\nwith a wide rage of frame sets resulting in synchronization \\nof five to ten or more pulses while matching local maximum \\nand minimum pairs. It appears that a minimum of six to \\nseven pulses gives good results in low noise / adequate lighting conditions, moreover mobile phones that come with \\na led-flash next to the camera as the one shown in Figure 1, \\ncan provide the necessary light in a dark environment, however our measurements were taken without the use of  \\nsuch additional light. \\n \\n \\nFigure 3: Input Sample with synchronization \\n \\nNaturally, when dealing with a general purpose device \\nand non laboratory conditions, for such a measurement one \\ngets a good amount of noise that can influence the \\ncalculation, therefore we always use a certain noise margin 5489\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:04 UTC f', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 215: ('ide the necessary light in a dark environment, however our measurements were taken without the use of  \\nsuch additional light. \\n \\n \\nFigure 3: Input Sample with synchronization \\n \\nNaturally, when dealing with a general purpose device \\nand non laboratory conditions, for such a measurement one \\ngets a good amount of noise that can influence the \\ncalculation, therefore we always use a certain noise margin 5489\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:04 UTC from IEEE Xplore.  Restrictions apply. \\n  \\nin order to sort an actual peak from noise signals. A peak is \\ndefined as point x where f(x-1) + nm < f(x) > f (x+1) + nm. \\nThe discrete function f(x) is our brightness sample and nm is \\nthe desired noise margin. \\nEvery average brightness value for each frame is extracted \\nalong with a timestamp of nanosecond resolution according to the operating system. This enables us to minimize the \\nnegative impact of the lag coming from the limited \\nprocessing power of the device, ensuring that our estimation will be practically unaffected. \\nAfter successfully developing this application on the \\nSymbian operating system [6] our research moved on \\nexperimenting with the Android platform using an HTC \\nTatoo running Android 1.6. One of the main differences is that Android adopts a higher level approach similar to Java \\nwhile Symbian takes the developer closer to the hardware by \\nusing C++. \\nFor this particular applicatio n it is desirable to access the \\nhardware in a direct way thus minimizing the delay for acquiring frame previews and processing them without \\nlagging the system. Even though Symbian would be most \\nsuitable for that cause, Android still provides adequate facilities to achieve a comparable result. \\nUnfortunately, the frame rate achieved under Android \\nusing our middle range hardware was only about 5 frames \\nper second; a higher framerate would provide higher \\naccuracy and reliability as our sample rate of 5 fps effectively limits the range of the beat rate we can estima', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 216: (' minimizing the delay for acquiring frame previews and processing them without \\nlagging the system. Even though Symbian would be most \\nsuitable for that cause, Android still provides adequate facilities to achieve a comparable result. \\nUnfortunately, the frame rate achieved under Android \\nusing our middle range hardware was only about 5 frames \\nper second; a higher framerate would provide higher \\naccuracy and reliability as our sample rate of 5 fps effectively limits the range of the beat rate we can estimate \\nas suggested by the sampling theorem. The equivalent frame \\nrate under Symbian, using Nokia N95 8GB was 25 fps. \\nThe relatively low frame rate is mostly related to the \\nhardware’s processing capability and also to the camera’s characteristics, but it’s not limited to that as Android \\ncurrently copies every preview frame to a new buffer before \\npassing it to the programmer; this subsequently triggers a garbage collector call that will slow down the given device \\nfor 80-90 ms per frame. Nonetheless, more powerful \\nhardware is expected to achieve higher framerates while \\nAndroid is still under heavy development and optimization.  \\nIII. R\\nESULTS  \\nWe evaluated the algorithm against a commercially \\navailable pulse oximeter with given maximum error of 2 \\nbeats per minute. Samples were taken from a group of 50 \\npeople between 21 and 55 years old, with an average age of 31,3 years. \\nTable 1 summarizes the results for the samples taken in \\nwell lit areas, were the average light absorbed by the camera lens without any obstruction was 46% of the maximum \\namount of light that the lens could absorb. The users had to \\nkeep their finger steady and the first measurement was \\nalways discarded so that users would get to feel more \\ncomfortable with the device. Results were also discarded in cases where users said they were not comfortable with the \\nplacement of their finger. The algorithm will also filter out \\nunreliable readings when there is excessive finger movement. \\nFifty frame subsets were used for this set of results; ', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 217: ('any obstruction was 46% of the maximum \\namount of light that the lens could absorb. The users had to \\nkeep their finger steady and the first measurement was \\nalways discarded so that users would get to feel more \\ncomfortable with the device. Results were also discarded in cases where users said they were not comfortable with the \\nplacement of their finger. The algorithm will also filter out \\nunreliable readings when there is excessive finger movement. \\nFifty frame subsets were used for this set of results; that \\ncorresponds to an average of 8.9 Seconds per decision which \\nonly provides marginal accuracy, however the algorithm was \\nfine tuned up to the point that it would consistently estimate \\nBeats per Minute (BpM) with over 91% accuracy. Moreover, there is an inherent 2 BpM maximum error for \\nthe pulse oximeter we used to check our precision. The \\naverage error for this scenario was at 4.13% with a maximum of 8.11% and a minimum of 1.49%. \\nDue to our synchronization window we have achieved \\nvery good resolution. Pulses are identified and nanosecond \\nresolution timestamps are acquired from Android while the \\napplication is running. Therefore the greatest risk for inaccurate results remains to be the user, low light and low \\nperformance hardware. \\n \\nTable 1: Well Lit Area Sample \\nEstimated \\nBpM Measured \\nBpM Relative \\nAccuracy Relative\\nError \\n65 66 98.46% 1.54% \\n63 67 93.65% 6.35% \\n73 70 95.89% 4.11% \\n71 68 95.77% 4.23% \\n68 70 97.06% 2.94% \\n67 68 98.51% 1.49% \\n68 71 95.59% 4.41% \\n75 72 96.00% 4.00% \\n76 73 96.05% 3.95% \\n74 68 91.89% 8.11% \\n73 71 97.26% 2.74% \\n68 71 95.59% 4.41% \\n75 72 96.00% 4.00% \\n72 77 93.06% 6.94% \\n75 73 97.33% 2.67% \\n In the next set of samples we tried to assess the \\nimportance of lightning conditions to the system. The \\naverage light absorbed by the camera in this case was 13 % \\nof the maximum amount of light the lens could absorb. The \\nsame protocol was followed. \\nThe results presented in Table 2 demonstrate how this \\napproach is tolerant to relatively low lighting conditions. \\nThe average ', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 218: ('% 3.95% \\n74 68 91.89% 8.11% \\n73 71 97.26% 2.74% \\n68 71 95.59% 4.41% \\n75 72 96.00% 4.00% \\n72 77 93.06% 6.94% \\n75 73 97.33% 2.67% \\n In the next set of samples we tried to assess the \\nimportance of lightning conditions to the system. The \\naverage light absorbed by the camera in this case was 13 % \\nof the maximum amount of light the lens could absorb. The \\nsame protocol was followed. \\nThe results presented in Table 2 demonstrate how this \\napproach is tolerant to relatively low lighting conditions. \\nThe average error was 4.67%, a value very close to that of our previous set of samples, while the lowest relative \\naccuracy observed was 89.87% and the lowest relative error \\nwas 1.28%. \\nThe sample time of 50 frames proved to be quite efficient \\nas it requires the user to stand still for roughly 9 seconds, \\nwhich proved to be acceptable. Larger frame sets were more \\nprone to errors as it is hard for the users not to move at all \\nfor e.g. 75 frames that take 14.7 Seconds. Smaller frame sets were found to be more inaccurate due to the small amount of \\nsamples the system can scan in a time window of less than 9 \\nseconds. 5490\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:04 UTC from IEEE Xplore.  Restrictions apply. \\n  \\n \\nTable 2: Average Lit Area Sample \\nEstimated   \\nBpM Measured \\nBpM Relative \\nAccuracy Relative\\nError \\n74 78 94.87% 5.13% \\n76 78 97.44% 2.56% \\n77 78 98.72% 1.28% \\n71 77 92.21% 7.79% \\n71 79 89.87% 10.13% \\n81 79 97.47% 2.53% \\n83 84 98.81% 1.19% \\n83 82 98.78% 1.22% \\n79 75 94.67% 5.33% \\n82 76 92.11% 7.89% \\n76 78 97.44% 2.56% \\n86 82 95.12% 4.88% \\n77 78 98.72% 1.28% \\n73 67 91.04% 8.96% \\n74 69 92.75% 7.25% \\nIV. DISCUSSION AND CONCLUSION  \\nThis application is a subsystem of a telecare platform that \\nis being developed in collaboration with our industrial partner Health-Smart Limited who has filed a patent [8] for \\nthis application, retaining the full intellectual property of this \\nproject. \\nIn this work we demonstrated the proof of concept and the \\npotential of the algori', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 219: (' \\n79 75 94.67% 5.33% \\n82 76 92.11% 7.89% \\n76 78 97.44% 2.56% \\n86 82 95.12% 4.88% \\n77 78 98.72% 1.28% \\n73 67 91.04% 8.96% \\n74 69 92.75% 7.25% \\nIV. DISCUSSION AND CONCLUSION  \\nThis application is a subsystem of a telecare platform that \\nis being developed in collaboration with our industrial partner Health-Smart Limited who has filed a patent [8] for \\nthis application, retaining the full intellectual property of this \\nproject. \\nIn this work we demonstrated the proof of concept and the \\npotential of the algorithm and the platform as a tool for \\nhealth care delivery. \\nThe research demonstrates a cheap and effective way of \\ncalculating the Heart Beat Rate using commercially available Smartphones. The system was successfully \\ndesigned and tested using the Symbian OS and is now being \\nextended to other OS’s including Android 1.x/2.x and \\nWindows Mobile, our current hardware cost on this system \\ndid not exceed 300£. \\nOur findings were very encouraging considering that the \\nalgorithm is not yet fully optimized up to the extent we plan \\nto, and we are waiting for new hardware to be available in order to improve the accuracy and resolution. Our forecast is \\nthat in the near future we will see commercially available \\napplications that will use a mobile camera as a sensor and \\ninnovative software that could use this input in order to \\nprovide health enhancing services to the users. \\nHigher sampling rates would not only improve accuracy, \\nbut also it could potentially shorten the sampling time for the \\nuser, making the application easier to use and less prone to \\nerrors from excessive movement. \\nMoreover, we have not exhausted our approach on \\nadaptive calculation estimates; the project is still in \\ndevelopment and one of the possible next steps will be to use \\nadaptive techniques for real time feedback in personal health coaching applications like using the data from this \\napplication to drive an interactive multimedia software that \\nwould aim on reducing a person’s blood pressure; all in the same device. The same adaptive te', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 220: ('cation easier to use and less prone to \\nerrors from excessive movement. \\nMoreover, we have not exhausted our approach on \\nadaptive calculation estimates; the project is still in \\ndevelopment and one of the possible next steps will be to use \\nadaptive techniques for real time feedback in personal health coaching applications like using the data from this \\napplication to drive an interactive multimedia software that \\nwould aim on reducing a person’s blood pressure; all in the same device. The same adaptive technique can be used in \\norder to dynamically estimate the noise levels and set the \\nnoise threshold accordingly; this will subsequently result in \\nmore accurate measurements in lower light conditions. \\nAs Shnayder et al. denote in [7], life expectancy is \\nconstantly increasing over the last decades, so does the burden on the health system supporting people with chronic \\nconditions. The only way out of this is implementing \\ntelecare solutions that will manage to increase the quality of delivered health care while maintaining low installation and \\nrunning costs. \\nHealth services delivery is about to change, but it is the \\nnature of the service itself that will gradually shift from re-\\nactive treatment of conditions to pre-emptive health care:  avoiding health risks can be more efficient than sustaining \\npatients with chronic conditions that could have been \\navoided [2]. This is where health monitoring and cognitive \\ntherapy comes to offer new possibilities, to provide the users \\nwith information on how to avoid getting a health condition rather than focusing on how to treat it. \\nA\\nCKNOWLEDGMENT  \\nWe would like to express our appreciation to Health-\\nSmart Limited, UK (www.health-smart.co.uk) for its important contribution to this work.  \\nR\\nEFERENCES  \\n[1] R. Gururajan, S. Murugesan and J. Soar, “Bringing Mobile \\nTechnologies in Support of Healthcare Recommendations for a Healthy Beginning and Growth,” Cutter IT Journal Article , Aug. \\n2005. \\n[2] T. Orbach and J. Vasquez, “Self-care and the need for interactive \\nIC', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 221: (' getting a health condition rather than focusing on how to treat it. \\nA\\nCKNOWLEDGMENT  \\nWe would like to express our appreciation to Health-\\nSmart Limited, UK (www.health-smart.co.uk) for its important contribution to this work.  \\nR\\nEFERENCES  \\n[1] R. Gururajan, S. Murugesan and J. Soar, “Bringing Mobile \\nTechnologies in Support of Healthcare Recommendations for a Healthy Beginning and Growth,” Cutter IT Journal Article , Aug. \\n2005. \\n[2] T. Orbach and J. Vasquez, “Self-care and the need for interactive \\nICT”, Journal of Holistic Healthcare , vol. 6, pp. 35-39, August 2009. \\n[3] A. Pantelopoulos and N. Bourbakis, “A Survey on Wearable \\nBiosensor Systems for Health Monitoring,” 30th Annual International \\nIEEE EMBS Conference, Vancouver, British Columbia, Canada, \\nAugust 20-24, 2008. \\n[4] L.J. Mengelkoch, D. Martin and J. Lawler, “A Review of the \\nPrinciples of Pulse Oximetry and Accuracy of Pulse Oximeter \\nEstimates During Exercise,”  Physical Therapy , vol. 74, no. 1, pp. 40-\\n49, Jan. 1994. \\n[5] D. Guowei, T. Xiaoying and L. Weifeng, “A Reflectance Pulse \\nOximeter Design Using the MSP430OF149,” in 2007 IEEE/ICME \\nInternation Conference on Complex Medical Engineering, pp 1081-1084 . \\n[6] K. Banitsas, P. Pelegris, T. Orbach, D. Cavouras, S. Kostopoulos and \\nK. Sidiropoulos, “A Simple Algorithm to Monitor HR for Real Time Treatment Applications,” in the 9\\nth International Conference on \\nInformation Technology and Applications in Biomedicine (ITAB) , \\nLarnaca, November 5-7, 2009. \\n[7] V. Shnayder, B. Chen, K. Lorincz, T. R. F. Fulford-Jones and M. \\nWelsh, “Sensor Networks for Medical Care,” Technical Report TR-\\n08-05, Division of Engineering and Applied Sciences , Harvard \\nUniversity, 2005. \\n[8] PCT patent application No. PCT/GB2009/050989 Blood Analysis –\\nHealth-Smart Ltd. 5491\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:04 UTC from IEEE Xplore.  Restrictions apply. ', 'A_novel_method_to_detect_Heart_Beat_Rate_using_a_mobile_phone.pdf'), 222: ('Camouflage Defect Identification: A Novel Approach. \\n \\nNagappa U. Bhajantri* †    and      P Nagabhushan†  \\n*Department of CS & E, S.J.College of Engineering, Mysore-570006,  India.   \\n† Department of Studies in CS, University of Mysore, Mysore -570006, India. \\nbhajan3nu@yahoo.com    pnagabhushan@hotmail.com  \\n \\nAbstract \\n Camouflaging is an attempt to obscure the \\nsignature of a target and sublimate the target in its \\nbackground frame in terms of co-occurrence \\nmatrix texture properties. The objective of this \\nresearch work is to detect such camouflaged defect. Since the texture similarity between the background and the defect is the premise for accomplishing camouflage, an intensive texture \\nanalysis should be able to discriminate defect from its background. In the proposed work we intended to employ Co-occurrence matrix based texture \\nfeatures are computed within the block, a small \\nregion of the image.  Finally defective portions are \\ndetected by cluster analysis and identified through Watershed segmentation. Several experiments have \\nbeen conducted to demonstrate the suitability of the \\nproposed model to spot camouflaged defects. Experimentation on the synthetic and real images corroborates the potential of the method. \\n \\n1. Introduction. \\n   Camouflage may occur due to several natural \\nreasons, such as defects in the products during the \\nmanufacturing process itself [2]. Even at operation \\nlevel certain defects remain camouflaged in most \\nof industrial product, the product could suffer a change in orientation or a slight misalignment. In fact automatic identification of defects in the industry has potential applications and it may be cost effective alternative. The wider application for \\nautomated surface defects’ detection would seem to offer several advantages.  \\n     In the proposed work, we have employed the co-occurrence matrix technique since it describes second order probability distribution and it is based on repeated occurrence of some gray level \\nconfiguration in the texture. We expect that such \\n', 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 223: ('tion or a slight misalignment. In fact automatic identification of defects in the industry has potential applications and it may be cost effective alternative. The wider application for \\nautomated surface defects’ detection would seem to offer several advantages.  \\n     In the proposed work, we have employed the co-occurrence matrix technique since it describes second order probability distribution and it is based on repeated occurrence of some gray level \\nconfiguration in the texture. We expect that such \\nresults are most applicable to the areas of camouflage image diagnose and assessment. The algorithm involves computing the Gray Level Co-occurrence (GLC) probability distribution matrix and in the sequel computing the texture parameters (energy, entropy, homogeneity contrast and correlation) from this matrix, [2] without indenting source image again and again for the computation of texture parameters        Quite extensive literature is available on texture \\nanalysis [1,2], but there is no significant amount of literature on camouflaged defect  recognition[1,2]. \\nThe literature on camouflaged target can be found in [1,2].  Thus, in this work, it is intend to divide an image frame into smaller blocks, and employ in each block an advanced texture analysis model \\nwhich involves computing invariant features. An \\nentire block need not be defective. The camouflaged portion perhaps could be spread partially in a block.  The rest of the paper is structured as follows. In section 2, we describe the methodology adopted. Algorithm, experiment and conclusion are in sections 3, 4 and 5 respectively. \\n \\n2. \\n2. Proposed methodology : In this section, the \\nproposed model to detect camouflaged region is \\nnarrated. The simplified block diagram of a general \\ncamouflaged detection system which employs \\nGLCM is shown in Fig.1. The GLCM method of texture description is based on the repeated occurrence of gray level configuration in the texture(detail is available in[2]). In general, smaller \\nthe block size higher is the sensitivity ', 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 224: (\". Algorithm, experiment and conclusion are in sections 3, 4 and 5 respectively. \\n \\n2. \\n2. Proposed methodology : In this section, the \\nproposed model to detect camouflaged region is \\nnarrated. The simplified block diagram of a general \\ncamouflaged detection system which employs \\nGLCM is shown in Fig.1. The GLCM method of texture description is based on the repeated occurrence of gray level configuration in the texture(detail is available in[2]). In general, smaller \\nthe block size higher is the sensitivity towards \\ndiscriminating the defective texture and hence an \\noptimal window size for camouflage portion detection is fixed up empirically. Normally, the defect portion will be small in percentage. For experimental analysis we have considered a defective surface (Fig. 2(b)) with 4% of \\ncamouflaged portion injected. Since we know the \\ntexture values corresponding to normal image (Fig. 2(a)) at different block levels, we have defined a sensitivity factor which provides quantification to the discriminating capability. Fig. 3 shows the plot of discrimination sensitivity versus block size with \\n4% of injected defect, for co-occurrence features at \\nφ = 45\\n0. The discrimination is perceivable only \\nwhen the block size becomes smaller and smaller.  \\nIn order to show that the clustering helps in \\nidentifying camouflaged blocks, an experiment is \\nconducted on the synthetic image shown in Fig. 2(b). Normally, camouflaging may not occur in only one block and also may not be in an entire block. Hence, segmentation process is used to spot the actual camouflaged portion and in the sequel, \\nfusing process to merge several adjacently placed camouflaged sectors becomes necessary.  \\n3. Algorithm: This section presents an \\nalgorithm for detection of camouflaged target in  \\n9th International Conference on Information Technology (ICIT'06)\\n0-7695-2635-7/06 $20.00  © 2006\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:43 UTC from IEEE Xplore.  Restrictions apply. \\n \\nFig 1: The block diagram\", 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 225: (\"s used to spot the actual camouflaged portion and in the sequel, \\nfusing process to merge several adjacently placed camouflaged sectors becomes necessary.  \\n3. Algorithm: This section presents an \\nalgorithm for detection of camouflaged target in  \\n9th International Conference on Information Technology (ICIT'06)\\n0-7695-2635-7/06 $20.00  © 2006\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:43 UTC from IEEE Xplore.  Restrictions apply. \\n \\nFig 1: The block diagram of the proposed camouflaged defect detection system \\n \\nterms of co-occurrence matrix derived texture \\nparameters. The overall algorithm is presented below. \\n    \\n  \\n      Fig. 2 (a) A normal surface      (b) A defective surface \\n \\n00.020.040.060.080.10.120.14\\n1024 512 256 128 64 32 16 8\\nBlock sizeSensitivityEnergy-45\\nEntrophy-45\\nHomogen_45\\nCorrln-45\\nContrast-45\\n \\nFig. 3. Co-occurrence features at φ= 450 \\n      Algorithm: Identification of Camouflaged regions   \\nInput : Test images suspected to contain \\ncamouflaged or defective portions \\nOutput : Camouflaged or defective segments \\nMethod: \\n1. Split the entire image into LxL disjoint blocks \\n2. Compute co-occurrence matrix features for \\neach block \\n3. Cluster analysis the blocks, those results in \\ntwo classes. \\n4. Identify the defective blocks with the help of \\ndendrogram. \\n5. Employ the Watershed segmentation in every \\ndefective block to trace and extract the camouflaged portion. \\n6. Fusion of camouflaged sectors based on their adjacencies is carried out and finally patch (es) of camouflage segment(s) is (are) obtained. \\nAlgorithm ends.  \\n4. Experimentation: The Co-occurrence \\nmatrix is computed over the each block of Image \\nand texture parameters. The texture parameters \\nconsidered are Energy, Entropy, Homogeneity, \\nContrast and Correlation.  The computations are done on camouflage images which provide the background image for camouflaging the target.  To establish the suitability of the proposed model for camouflaged detection, many case studies \\ninvolving bo\", 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 226: (\"finally patch (es) of camouflage segment(s) is (are) obtained. \\nAlgorithm ends.  \\n4. Experimentation: The Co-occurrence \\nmatrix is computed over the each block of Image \\nand texture parameters. The texture parameters \\nconsidered are Energy, Entropy, Homogeneity, \\nContrast and Correlation.  The computations are done on camouflage images which provide the background image for camouflaging the target.  To establish the suitability of the proposed model for camouflaged detection, many case studies \\ninvolving both synthetic and real images are considered. One of the typical experiment  on real image is described below. \\n \\nExperiment: This is a typical experiment with the \\nimages of tops of match boxes. The market is \\nflooded with substandard or duplicate products, only very close observation reveals the difference between the duplicate wrapper and the original wrapper.  In the example shown in Fig.4(a), 11\\nth \\nmatch box does not belong to the class of true or \\noriginal match boxes. It is natural that any body \\ngets deceived and fails to recognize the duplicate \\nmatch box, same can be observed from the \\ndendrogram presented in Fig. 4(b). \\n \\n5.  Conclusion: In proposed approach we \\nemployed second order statistical texture analysis \\nstrategy to identify the camouflaged defect in a similar background image. This is expected to provide better models for the detection of camouflage defect in synthetic and real images. \\n \\nFig. 4(a) Array of 4x4 match boxes \\n \\n \\nb)    Dendrogram \\nReferences : \\n[1] Mryka Hall Beyer, Co-occurrence Tutorial, http://   \\n      www.fp .ucalgary.ca/mhallbey, 2006 [2] Smith, M L, T. Hill, G. Smith, Surface texture        analysis based upon the visually acquired         perturbation of surface  normal,\\n Image and Vision   \\n     Computing Journal , Vol. 15,  No.12,pp.949- \\n      955,1997.  Split Image \\ninto blocks Compute \\nGLCM feature for each bloc\\nk Cluster \\nanalysis Watershe d\\nsegmentatio\\nnFusion of adjacently placed se\\ngmented portion \\n9th International Conference on Information Technology (ICIT'\", 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 227: (\"rrence Tutorial, http://   \\n      www.fp .ucalgary.ca/mhallbey, 2006 [2] Smith, M L, T. Hill, G. Smith, Surface texture        analysis based upon the visually acquired         perturbation of surface  normal,\\n Image and Vision   \\n     Computing Journal , Vol. 15,  No.12,pp.949- \\n      955,1997.  Split Image \\ninto blocks Compute \\nGLCM feature for each bloc\\nk Cluster \\nanalysis Watershe d\\nsegmentatio\\nnFusion of adjacently placed se\\ngmented portion \\n9th International Conference on Information Technology (ICIT'06)\\n0-7695-2635-7/06 $20.00  © 2006\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:05:43 UTC from IEEE Xplore.  Restrictions apply. \", 'Camouflage_Defect_Identification_A_Novel_Approach.pdf'), 228: ('ScienceDirect\\nAvailable online at www.sciencedirect.com\\nProcedia Computer Science 167 (2020)  2634–2642\\n1877-0509 © 2020 The Authors. Published by Elsevier B.V .\\nThis is an open access article under the CC BY-NC-ND license ( http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientific committee of the International Conference on Computational Intelligence and Data \\nScience (ICCIDS 2019).10.1016/j.procs.2020.03.342\\n10.1016/j.procs.2020.03.342 1877-0509© 2020 The Authors. Published by Elsevier B.V .\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/ )\\nPeer-review under responsibility of the scientific committee of the International Conference on Computational Intelligence and Data \\nScience (ICCIDS 2019).Available online at www.sciencedirect.com\\nProcedia Computer Science 00 (2019) 000–000\\nwww.elsevier.com/locate/procedia\\nInternational Conference on Computational Intelligence and Data Science (ICCIDS 2019)\\nGender Classiﬁcation using Facial Embeddings: A Novel Approach\\nAvinash Swaminathana, Mridul Chabaa,∗, Deepak Kumar Sharmaa, Yogesh Chabab\\naNetaji Subhas Institute of Technology, Dwarka Sec-3, New Delhi - 110078, India\\nbGuru Jambheshwar University of Science &Technology, Hisar - 125001, India\\nAbstract\\nImage Processing for Human recognition involves using bio-metric traits such as Face, Iris, Voice and other physical traits to\\nuniquely identify human faces. With the increase in Image Data on the Internet, there is a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 229: ('a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Peer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence andData Science (ICCIDS 2019).\\nKeywords: Computer vision; Convolutional networks; Face recognition; Gender classiﬁcation; Machine learning\\n1. Introduction\\nHuman Recognition AI uses a lot of features like iris, thumbprint, faces, gait, voice etc to identify humans uniquely.\\nHowever, over all these parameters facial images have been noted as a highly reliable metric for identifying humans.\\nEvery human being has a unique face which is distinguishable from other human beings. Demographic factors likerace, gender, age and place of origin can be extracted from the face itself. Some factors like gender and age can beused by corporations to recommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-computer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step b', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 230: ('ecommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-computer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence and Data Science(ICCIDS 2019).Available online at www.sciencedirect.com\\nProcedia Computer Science 00 (2019) 000–000\\nwww.elsevier.com/locate/procedia\\nInternational Conference on Computational Intelligence and Data Science (ICCIDS 2019)\\nGender Classiﬁcation using Facial Embeddings: A Novel Approach\\nAvinash Swaminathana, Mridul Chabaa,∗, Deepak Kumar Sharmaa, Yogesh Chabab\\naNetaji Subhas Institute of Technology, Dwarka Sec-3, New Delhi - 110078, India\\nbGuru Jambheshwar University of Science &Technology, Hisar - 125001, India\\nAbstract\\nImage Processing for Human recognition involves using bio-metric traits such as Face, Iris, Voice and other physical traits to\\nuniquely identify human faces. With the increase in Image Data on the Internet, there is a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tas', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 231: ('ar - 125001, India\\nAbstract\\nImage Processing for Human recognition involves using bio-metric traits such as Face, Iris, Voice and other physical traits to\\nuniquely identify human faces. With the increase in Image Data on the Internet, there is a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Peer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence andData Science (ICCIDS 2019).\\nKeywords:\\nComputer vision; Convolutional networks; Face recognition; Gender classiﬁcation; Machine learning\\n1. Introduction\\nHuman Recognition AI uses a lot of features like iris, thumbprint, faces, gait, voice etc to identify humans uniquely.\\nHowever, over all these parameters facial images have been noted as a highly reliable metric for identifying humans.\\nEvery human being has a unique face which is distinguishable from other human beings. Demographic factors likerace, gender, age and place of origin can be extracted from the face itself. Some factors like gender and age can beused by corporations to recommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-comput', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 232: ('uman being has a unique face which is distinguishable from other human beings. Demographic factors likerace, gender, age and place of origin can be extracted from the face itself. Some factors like gender and age can beused by corporations to recommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-computer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence and Data Science(ICCIDS 2019).2 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nMatching [3],etc. One of the recent approaches involves using Facial Embeddings for recognition and clustering[4].An embedding refers to the mapping of input features to a vector with ﬁxed dimension. In the case of Facial embed-dings the input features are the subjects face which are mapped to a vector representation. Word Embeddings likeword2vec [5] refer to the vector representations of words.\\nA neural network learns a function that maps entities in the input feature space to the output feature space. Due\\nto this functionality of neural networks, they are often used to learn diﬀerent types of embeddings. A special neuralnetwork called Facenet[4] was speciﬁcally de', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 233: ('ures to a vector with ﬁxed dimension. In the case of Facial embed-dings the input features are the subjects face which are mapped to a vector representation. Word Embeddings likeword2vec [5] refer to the vector representations of words.\\nA neural network learns a function that maps entities in the input feature space to the output feature space. Due\\nto this functionality of neural networks, they are often used to learn diﬀerent types of embeddings. A special neuralnetwork called Facenet[4] was speciﬁcally designed to learn mappings from facial images to facial embeddings.The network was trained in a manner that facial embeddings of the same face were closer together than the facialembeddings of two diﬀerent faces. Due to this property of facial embeddings, it becomes very easy to recognizefaces if their facial embeddings are already known beforehand. The method also helps overcoming the problemsencountered earlier while performing facial recognition like variance in illumination, pose, expression, etc.[1]\\nThe concept of Facial embeddings and the results obtained from the FaceNet Network[4] are used in this work to\\nperform gender classiﬁcation. While the concept of Facial Embeddings has been in scientiﬁc literature for a signif-icant period of time, the actual eﬀect and the context of these is yet to be ascertained. The proposed work is novelas previously facial embeddings have not been applied to the domain of predicting gender,race and age using facialimages. The main aim of the proposed work is to apply facial embeddings to previously unseen domain of genderclassiﬁcation using facial images and evaluate these results in order to ﬁnd out whether Facial embeddings are ac-tual representations of faces and can be universally applied to other problems involving classiﬁcation using facialimages.The research paper here is organized into various sections. In the second upcoming section, related work pre-viously done in this area has been discussed. The following section describes the motivation for proposing this work.T', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 234: (' embeddings to previously unseen domain of genderclassiﬁcation using facial images and evaluate these results in order to ﬁnd out whether Facial embeddings are ac-tual representations of faces and can be universally applied to other problems involving classiﬁcation using facialimages.The research paper here is organized into various sections. In the second upcoming section, related work pre-viously done in this area has been discussed. The following section describes the motivation for proposing this work.The fourth section talks about the method used and the ﬁfth section talks about the challenges in eﬀective gender clas-siﬁcation. The sixth section gives a description of the dataset used and then in the seventh section the results obtainedfrom our proposed approach have been discussed. In the eighth section comparison of results with the previous workin this area has been discussed and ﬁnally the subsequent sections provide a comprehensive analysis of the resultsalong with the conclusion of the proposed work.\\n2. Related work\\nInitial approaches to gender classiﬁcation involved using classiﬁers like linear discriminant classiﬁer, cosine clas-\\nsiﬁer, Support Vector Machines and Independent Component Analysis on images from the FERET facial database\\nwhich includes 250 female images and 25 male images. Jain et al.[6] in 2005 ﬁrst used the cosine classiﬁer to cal-culate the distance across two features stretched out on a hyper-sphere surface. SVM classiﬁer was trained whichpredicted a hyper-plane separating the suitable male and suitable female features. The accuracy was best obtainedaround 96% in ICA Space.\\nGolomb et al.[7] experimented gender classiﬁcation using the SEXNET Network on a face dataset of 90 images.\\nThe author extracted features from the entire face instead of extracting features from few facial points.Due to this hewas able to achieve an accuracy of 91.9%.\\nRoope Raisamo and Erno Makinen[8] performed gender classiﬁcation on automatically detected and aligned\\nfaces.There were four methods of automatic a', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 235: ('table male and suitable female features. The accuracy was best obtainedaround 96% in ICA Space.\\nGolomb et al.[7] experimented gender classiﬁcation using the SEXNET Network on a face dataset of 90 images.\\nThe author extracted features from the entire face instead of extracting features from few facial points.Due to this hewas able to achieve an accuracy of 91.9%.\\nRoope Raisamo and Erno Makinen[8] performed gender classiﬁcation on automatically detected and aligned\\nfaces.There were four methods of automatic alignment and four methods to classify gender that were applied onthe IMM Database as well as the FERET Database. Facial images were re-sized before or after they were aligned.There wasn’t any signiﬁcant contribution of Automatic Face Alignment Methods in improvement of classiﬁcation rateand the best accuracy actually depended on the image re-sizing. Input images of 36 x 36 pixel size passed throughSVM classiﬁer yielded the best accuracy\\nTejas et al.[9] conducted gender classiﬁcation problem using discriminant functions over a dataset of 8112 images\\nusing techniques like PCA, LDA and SubClass Discriminant Analysis with images having variations over illumina-tions, expressions, mirror pose and ethnicity. PCA performed better than PCA combined with LDA, PCA combinedwith SVM and PCA combined with SDA. The experiment led to the conclusion that Linear Discriminant Functionsare capable of descent generalization over a limited number of training samples and principal components and helpedachieve a higher accuracy.\\nSamarasena Buchala et al.[10] experimented with facial image properties such as age, gender and ethnicity. The\\nauthor used PCA to encode these properties and was able to classify them very well. The author also observed that\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2635Available online at www.sciencedirect.com\\nProcedia Computer Science 00 (2019) 000–000\\nwww.elsevier.com/locate/procedia\\nInternational Conference on Computational Intelligence and Data Science (ICCIDS 2019)\\nG', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 236: ('marasena Buchala et al.[10] experimented with facial image properties such as age, gender and ethnicity. The\\nauthor used PCA to encode these properties and was able to classify them very well. The author also observed that\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2635Available online at www.sciencedirect.com\\nProcedia Computer Science 00 (2019) 000–000\\nwww.elsevier.com/locate/procedia\\nInternational Conference on Computational Intelligence and Data Science (ICCIDS 2019)\\nGender Classiﬁcation using Facial Embeddings: A Novel Approach\\nAvinash Swaminathana, Mridul Chabaa,∗, Deepak Kumar Sharmaa, Yogesh Chabab\\naNetaji Subhas Institute of Technology, Dwarka Sec-3, New Delhi - 110078, India\\nbGuru Jambheshwar University of Science &Technology, Hisar - 125001, India\\nAbstract\\nImage Processing for Human recognition involves using bio-metric traits such as Face, Iris, Voice and other physical traits to\\nuniquely identify human faces. With the increase in Image Data on the Internet, there is a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Peer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence andData Science (ICCIDS 2019).\\nKeywords:\\nComputer vision; Convolutional networks; Face recognition; Gender classiﬁcation; Mac', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 237: ('ption Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Peer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence andData Science (ICCIDS 2019).\\nKeywords:\\nComputer vision; Convolutional networks; Face recognition; Gender classiﬁcation; Machine learning\\n1. Introduction\\nHuman Recognition AI uses a lot of features like iris, thumbprint, faces, gait, voice etc to identify humans uniquely.\\nHowever, over all these parameters facial images have been noted as a highly reliable metric for identifying humans.\\nEvery human being has a unique face which is distinguishable from other human beings. Demographic factors likerace, gender, age and place of origin can be extracted from the face itself. Some factors like gender and age can beused by corporations to recommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-computer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intel', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 238: ('tep beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence and Data Science(ICCIDS 2019).Available online at www.sciencedirect.com\\nProcedia Computer Science 00 (2019) 000–000\\nwww.elsevier.com/locate/procedia\\nInternational Conference on Computational Intelligence and Data Science (ICCIDS 2019)\\nGender Classiﬁcation using Facial Embeddings: A Novel Approach\\nAvinash Swaminathana, Mridul Chabaa,∗, Deepak Kumar Sharmaa, Yogesh Chabab\\naNetaji Subhas Institute of Technology, Dwarka Sec-3, New Delhi - 110078, India\\nbGuru Jambheshwar University of Science &Technology, Hisar - 125001, India\\nAbstract\\nImage Processing for Human recognition involves using bio-metric traits such as Face, Iris, Voice and other physical traits to\\nuniquely identify human faces. With the increase in Image Data on the Internet, there is a huge demand for Artiﬁcial Intelli-gence(AI) algorithms that can perform classiﬁcation tasks like Race and Gender Classiﬁcation. The advent of Deep LearningTechniques like Convolutional Networks has led to a rapid ascent in accuracy in various image classiﬁcation tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Pee', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 239: ('n tasks. Through thispaper, a novel method to predict Gender of a person by applying various Machine Learning Classiﬁcation Techniques on Facial Em-beddings has been proposed. The facial embeddings are found by passing through a Pretrained Inception Network. The maximumaccuracy obtained by the proposed work to classify gender is 97%.\\nc/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)Peer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence andData Science (ICCIDS 2019).\\nKeywords:\\nComputer vision; Convolutional networks; Face recognition; Gender classiﬁcation; Machine learning\\n1. Introduction\\nHuman Recognition AI uses a lot of features like iris, thumbprint, faces, gait, voice etc to identify humans uniquely.\\nHowever, over all these parameters facial images have been noted as a highly reliable metric for identifying humans.\\nEvery human being has a unique face which is distinguishable from other human beings. Demographic factors likerace, gender, age and place of origin can be extracted from the face itself. Some factors like gender and age can beused by corporations to recommend products accordingly and thereby increase their sales. Thus, a successful genderclassiﬁcation approach can help in boosting the performance of a lot of areas of machine learning applications likehuman recognition, bio-metric veriﬁcation and smart human-computer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published ', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 240: ('omputer interfaces.\\nFacial Recognition for the purposes of gender classiﬁcation can become tedious because of the huge variance in the\\nillumination and pose of the faces and so forth [1]. Thus, this step becomes a very important preprocessing step beforepredicting gender,race,etc. A lot of approaches have been undertaken by researchers, including Eigenfaces[2], Graph\\n∗Corresponding author. Tel.: +91-903-445-1260\\nE-mail address: mridulc.it.17@nsit.net.in\\n1877-0509 c/circlecopyrt2019 The Author(s). Published by Elsevier B.V.\\nThis is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)\\nPeer-review under responsibility of the scientiﬁc committee of the International Conference on Computational Intelligence and Data Science(ICCIDS 2019).2 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nMatching [3],etc. One of the recent approaches involves using Facial Embeddings for recognition and clustering[4].\\nAn embedding refers to the mapping of input features to a vector with ﬁxed dimension. In the case of Facial embed-dings the input features are the subjects face which are mapped to a vector representation. Word Embeddings likeword2vec [5] refer to the vector representations of words.\\nA neural network learns a function that maps entities in the input feature space to the output feature space. Due\\nto this functionality of neural networks, they are often used to learn diﬀerent types of embeddings. A special neuralnetwork called Facenet[4] was speciﬁcally designed to learn mappings from facial images to facial embeddings.The network was trained in a manner that facial embeddings of the same face were closer together than the facialembeddings of two diﬀerent faces. Due to this property of facial embeddings, it becomes very easy to recognizefaces if their facial embeddings are already known beforehand. The method also helps overcoming the problemsencountered earlier while performing facial recognition like variance in illumination, pose, expression, etc.[1', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 241: ('lly designed to learn mappings from facial images to facial embeddings.The network was trained in a manner that facial embeddings of the same face were closer together than the facialembeddings of two diﬀerent faces. Due to this property of facial embeddings, it becomes very easy to recognizefaces if their facial embeddings are already known beforehand. The method also helps overcoming the problemsencountered earlier while performing facial recognition like variance in illumination, pose, expression, etc.[1]\\nThe concept of Facial embeddings and the results obtained from the FaceNet Network[4] are used in this work to\\nperform gender classiﬁcation. While the concept of Facial Embeddings has been in scientiﬁc literature for a signif-icant period of time, the actual eﬀect and the context of these is yet to be ascertained. The proposed work is novelas previously facial embeddings have not been applied to the domain of predicting gender,race and age using facialimages. The main aim of the proposed work is to apply facial embeddings to previously unseen domain of genderclassiﬁcation using facial images and evaluate these results in order to ﬁnd out whether Facial embeddings are ac-tual representations of faces and can be universally applied to other problems involving classiﬁcation using facialimages.The research paper here is organized into various sections. In the second upcoming section, related work pre-viously done in this area has been discussed. The following section describes the motivation for proposing this work.The fourth section talks about the method used and the ﬁfth section talks about the challenges in eﬀective gender clas-siﬁcation. The sixth section gives a description of the dataset used and then in the seventh section the results obtainedfrom our proposed approach have been discussed. In the eighth section comparison of results with the previous workin this area has been discussed and ﬁnally the subsequent sections provide a comprehensive analysis of the resultsalong with the conclusion of the propos', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 242: ('work.The fourth section talks about the method used and the ﬁfth section talks about the challenges in eﬀective gender clas-siﬁcation. The sixth section gives a description of the dataset used and then in the seventh section the results obtainedfrom our proposed approach have been discussed. In the eighth section comparison of results with the previous workin this area has been discussed and ﬁnally the subsequent sections provide a comprehensive analysis of the resultsalong with the conclusion of the proposed work.\\n2. Related work\\nInitial approaches to gender classiﬁcation involved using classiﬁers like linear discriminant classiﬁer, cosine clas-\\nsiﬁer, Support Vector Machines and Independent Component Analysis on images from the FERET facial database\\nwhich includes 250 female images and 25 male images. Jain et al.[6] in 2005 ﬁrst used the cosine classiﬁer to cal-culate the distance across two features stretched out on a hyper-sphere surface. SVM classiﬁer was trained whichpredicted a hyper-plane separating the suitable male and suitable female features. The accuracy was best obtainedaround 96% in ICA Space.\\nGolomb et al.[7] experimented gender classiﬁcation using the SEXNET Network on a face dataset of 90 images.\\nThe author extracted features from the entire face instead of extracting features from few facial points.Due to this hewas able to achieve an accuracy of 91.9%.\\nRoope Raisamo and Erno Makinen[8] performed gender classiﬁcation on automatically detected and aligned\\nfaces.There were four methods of automatic alignment and four methods to classify gender that were applied onthe IMM Database as well as the FERET Database. Facial images were re-sized before or after they were aligned.There wasn’t any signiﬁcant contribution of Automatic Face Alignment Methods in improvement of classiﬁcation rateand the best accuracy actually depended on the image re-sizing. Input images of 36 x 36 pixel size passed throughSVM classiﬁer yielded the best accuracy\\nTejas et al.[9] conducted gender classiﬁcation problem using disc', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 243: ('atic alignment and four methods to classify gender that were applied onthe IMM Database as well as the FERET Database. Facial images were re-sized before or after they were aligned.There wasn’t any signiﬁcant contribution of Automatic Face Alignment Methods in improvement of classiﬁcation rateand the best accuracy actually depended on the image re-sizing. Input images of 36 x 36 pixel size passed throughSVM classiﬁer yielded the best accuracy\\nTejas et al.[9] conducted gender classiﬁcation problem using discriminant functions over a dataset of 8112 images\\nusing techniques like PCA, LDA and SubClass Discriminant Analysis with images having variations over illumina-tions, expressions, mirror pose and ethnicity. PCA performed better than PCA combined with LDA, PCA combinedwith SVM and PCA combined with SDA. The experiment led to the conclusion that Linear Discriminant Functionsare capable of descent generalization over a limited number of training samples and principal components and helpedachieve a higher accuracy.\\nSamarasena Buchala et al.[10] experimented with facial image properties such as age, gender and ethnicity. The\\nauthor used PCA to encode these properties and was able to classify them very well. The author also observed that\\n2636  Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 3\\nonly the ﬁrst few components of PCA were required to encode the properties and to actually capture a major part\\nof the data variance. These few components also played a decisive role in gender classiﬁcation. He also designed aglobal and feature based classiﬁcation of Faces. There were many algorithms like PCA, CCA,etc that were appliedon distinct parts of the face viz. eyes, mouth and full face. The PCA when compared to other methods gave 87.5%accuracy.\\nM. Nazir et al. [11] used the DCT Technique(Discrete Cosine Transformation). Euclidean distances were calculated\\nto locate the closest neighbours over the SUMS frontal images data-s', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 244: ('iance. These few components also played a decisive role in gender classiﬁcation. He also designed aglobal and feature based classiﬁcation of Faces. There were many algorithms like PCA, CCA,etc that were appliedon distinct parts of the face viz. eyes, mouth and full face. The PCA when compared to other methods gave 87.5%accuracy.\\nM. Nazir et al. [11] used the DCT Technique(Discrete Cosine Transformation). Euclidean distances were calculated\\nto locate the closest neighbours over the SUMS frontal images data-set. The accuracy obtained was 99.3% which wasbetter than SVM where the ratio of train and test images were kept 50 to 50 for KNN Classiﬁer.\\nZiyi Xu et al. [12] fused global features and local features using hybrid techniques. He preprocessed the data\\nusing face normalization via some geometric alignment and gray level normalization. Adaboost algorithm was usedto extract global features whereas AAM was used for local features.\\nRavi and Wilson [13] tried converting a RGB image to a YCbCr color space via an algorithm that detects the skin\\nregions in facial images. To obtain facial features from RGB Images, they were transformed into gray scale images.They proposed an idea that face detection acts as a pre processing step for classiﬁcation and hence they combined theface detection with facial features and gender classiﬁcation for better accuracy. They have used SVM as a classiﬁerwhere in features like mouth, eyes and lips are identiﬁed on conversion of color images to gray scale images whereasthe area of skin is identiﬁed on conversion of RGB to gray scale images.\\n3. Motivation\\nA lot of earlier techniques have been used before for gender classiﬁcation. They are mainly either based on image\\nclassiﬁcation using neural networks or application of some Machine Learning techniques on images like Logistic\\nRegression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and Decision Trees. WhileNeural Networks help in representation learning, Machine Learning techniques treat each pixel as features and clas', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 245: ('identiﬁed on conversion of RGB to gray scale images.\\n3. Motivation\\nA lot of earlier techniques have been used before for gender classiﬁcation. They are mainly either based on image\\nclassiﬁcation using neural networks or application of some Machine Learning techniques on images like Logistic\\nRegression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and Decision Trees. WhileNeural Networks help in representation learning, Machine Learning techniques treat each pixel as features and classifythem. The best approach to gender classiﬁcation, however is to learn representation from images and then classifygender on the basis of these learned representations. The proposed approach in this paper is also based on a similarpattern. The proposed work also intends to provide framework to use facial embeddings for classifying images on thebasis of facial images so that future works in this domain using facial embeddings can be done easily.\\n4. The proposed work\\nGender classiﬁcation can be considered as a binary class classiﬁcation problem. The Model that has been proposed\\naims to use embedding vectors as features to predict the gender using various Machine Learning Models. The exper-\\niments in this proposed work have been carried out using Python Programming Language with the aid of the sci-kitLearn Library using Jupyter Notebook as the simulation environment. These Embedding vectors are generated bypassing Facial Images through a pre-tained Facenet Model[4]. The proposed method can be broken down into threephases. First, faces in the given images are detected and cropped out. Second, the facial embedding for each faceare then calculated by passing it through a neural network. Third, treating these embeddings as feature vectors, thesevectors are passed through various Machine Learning Models to predict gender. A brief overview of all these stagesare given below.\\n4.1. Pre-processing\\nPre-processing involves cropping out faces from the original images, so that there is no anomaly while calculating\\nthe embedd', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 246: ('threephases. First, faces in the given images are detected and cropped out. Second, the facial embedding for each faceare then calculated by passing it through a neural network. Third, treating these embeddings as feature vectors, thesevectors are passed through various Machine Learning Models to predict gender. A brief overview of all these stagesare given below.\\n4.1. Pre-processing\\nPre-processing involves cropping out faces from the original images, so that there is no anomaly while calculating\\nthe embedding vector for those particular faces. This is done by ﬁnding the bounding boxes of all faces by applying\\nthrough Face Detection Algorithms like Viola-Jones[14], Local Binary Patterns[15], Adaboost[16] etc. As nowadays,Viola Jones algorithm is primarily the golden standard of face detection, it is applied over each of the original dataset’simages and a new dataset is created that contains all these cropped images of faces.With Preprocessing,the noiseinterfering in the prediction of Facial Embeddings have been eliminated.4 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nFig. 1. Inception Modules\\n4.2. Calculation of facial embeddings\\nA Convolutional Network has been used to downsize the images and convert a (224*224*3) sized image (which\\nis passed as input to the network) to a (128*1) sized vector. The same architecture as proposed for Facenet model byauthors of the original paper has been used here.[4].\\nBrieﬂy the network consists of a 3D convolutional ﬁlter followed by 2 Batch Normalisation and Max-Pooling\\nlayers. This is further followed by 10 Inception modules (ﬁg 1). Each Inception module comprises of 1*1,3*3 and 5*5\\nconvolutional ﬁlters. Output of all these ﬁlters are concatenated together and passed to deeper layers. The resultantimage after passing through all the 10 Inception Modules is of the dimensions 7*7*1024. Finally, all the 1024 channelsof the resultant image are subjected to layer of average pooling and output is a vector with 1024 dimensions. These1024 output units then go', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 247: ('tion and Max-Pooling\\nlayers. This is further followed by 10 Inception modules (ﬁg 1). Each Inception module comprises of 1*1,3*3 and 5*5\\nconvolutional ﬁlters. Output of all these ﬁlters are concatenated together and passed to deeper layers. The resultantimage after passing through all the 10 Inception Modules is of the dimensions 7*7*1024. Finally, all the 1024 channelsof the resultant image are subjected to layer of average pooling and output is a vector with 1024 dimensions. These1024 output units then go through a dense fully connected network having 128 output units with an output ReLUactivation layer. The output at all nodes are combined together to form a 128-dimensional vector.\\nSuch deeper layers,help the network in learning deeper representations within the image.In order to facilitate\\nfaster backpropagation residual connections are added between layers.Transfer Learning is performed and the weightslearned by the Facenet model originally via training have been used in this work.To summarize,the image of dimen-sion 224*224*3 is passed into the network which gives out a 128-dimensional vector at the other end containing thefacial embedding of the input image. The network is 24 Layers deep and had been designed using computationaleﬃciency in mind. The authors of the original paper chose 128-dimensions for their facial embeddings as it helpedthem achieve a higher accuracy and the same dimensions will be used in this paper also.\\n4.3. Predicting gender probabilities by applying machine learning models on facial embeddings\\nThe last phase involves training of Machine Learning Models to classify gender on the basis of the respective\\nfacial embeddings generated for each face. Facenet Neural Network gives us a mapping from higher-dimensional\\nspace (which signiﬁes the facial images) to a lower dimensional one[4]. The Embeddings serve as a representation ofthe image in a 128-dimensional space. All the major machine learning models are trained to predict the gender of thetraining images on the basis of these 128-dimens', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 248: ('al embeddings\\nThe last phase involves training of Machine Learning Models to classify gender on the basis of the respective\\nfacial embeddings generated for each face. Facenet Neural Network gives us a mapping from higher-dimensional\\nspace (which signiﬁes the facial images) to a lower dimensional one[4]. The Embeddings serve as a representation ofthe image in a 128-dimensional space. All the major machine learning models are trained to predict the gender of thetraining images on the basis of these 128-dimensional embeddings. The Major Machine Learning Techniques usedare Logistic Regression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and DecisionTrees. All the Machine Learning Techniques are trained for 400 iterations with a learning rate of 0.001. In case of\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2637\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 3\\nonly the ﬁrst few components of PCA were required to encode the properties and to actually capture a major part\\nof the data variance. These few components also played a decisive role in gender classiﬁcation. He also designed aglobal and feature based classiﬁcation of Faces. There were many algorithms like PCA, CCA,etc that were appliedon distinct parts of the face viz. eyes, mouth and full face. The PCA when compared to other methods gave 87.5%accuracy.\\nM. Nazir et al. [11] used the DCT Technique(Discrete Cosine Transformation). Euclidean distances were calculated\\nto locate the closest neighbours over the SUMS frontal images data-set. The accuracy obtained was 99.3% which wasbetter than SVM where the ratio of train and test images were kept 50 to 50 for KNN Classiﬁer.\\nZiyi Xu et al. [12] fused global features and local features using hybrid techniques. He preprocessed the data\\nusing face normalization via some geometric alignment and gray level normalization. Adaboost algorithm was usedto extract global features whereas AAM was used for local features.\\nRavi and Wilson [13] tried c', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 249: ('closest neighbours over the SUMS frontal images data-set. The accuracy obtained was 99.3% which wasbetter than SVM where the ratio of train and test images were kept 50 to 50 for KNN Classiﬁer.\\nZiyi Xu et al. [12] fused global features and local features using hybrid techniques. He preprocessed the data\\nusing face normalization via some geometric alignment and gray level normalization. Adaboost algorithm was usedto extract global features whereas AAM was used for local features.\\nRavi and Wilson [13] tried converting a RGB image to a YCbCr color space via an algorithm that detects the skin\\nregions in facial images. To obtain facial features from RGB Images, they were transformed into gray scale images.They proposed an idea that face detection acts as a pre processing step for classiﬁcation and hence they combined theface detection with facial features and gender classiﬁcation for better accuracy. They have used SVM as a classiﬁerwhere in features like mouth, eyes and lips are identiﬁed on conversion of color images to gray scale images whereasthe area of skin is identiﬁed on conversion of RGB to gray scale images.\\n3. Motivation\\nA lot of earlier techniques have been used before for gender classiﬁcation. They are mainly either based on image\\nclassiﬁcation using neural networks or application of some Machine Learning techniques on images like Logistic\\nRegression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and Decision Trees. WhileNeural Networks help in representation learning, Machine Learning techniques treat each pixel as features and classifythem. The best approach to gender classiﬁcation, however is to learn representation from images and then classifygender on the basis of these learned representations. The proposed approach in this paper is also based on a similarpattern. The proposed work also intends to provide framework to use facial embeddings for classifying images on thebasis of facial images so that future works in this domain using facial embeddings can be done easily.\\n4. The ', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 250: ('rning techniques treat each pixel as features and classifythem. The best approach to gender classiﬁcation, however is to learn representation from images and then classifygender on the basis of these learned representations. The proposed approach in this paper is also based on a similarpattern. The proposed work also intends to provide framework to use facial embeddings for classifying images on thebasis of facial images so that future works in this domain using facial embeddings can be done easily.\\n4. The proposed work\\nGender classiﬁcation can be considered as a binary class classiﬁcation problem. The Model that has been proposed\\naims to use embedding vectors as features to predict the gender using various Machine Learning Models. The exper-\\niments in this proposed work have been carried out using Python Programming Language with the aid of the sci-kitLearn Library using Jupyter Notebook as the simulation environment. These Embedding vectors are generated bypassing Facial Images through a pre-tained Facenet Model[4]. The proposed method can be broken down into threephases. First, faces in the given images are detected and cropped out. Second, the facial embedding for each faceare then calculated by passing it through a neural network. Third, treating these embeddings as feature vectors, thesevectors are passed through various Machine Learning Models to predict gender. A brief overview of all these stagesare given below.\\n4.1. Pre-processing\\nPre-processing involves cropping out faces from the original images, so that there is no anomaly while calculating\\nthe embedding vector for those particular faces. This is done by ﬁnding the bounding boxes of all faces by applying\\nthrough Face Detection Algorithms like Viola-Jones[14], Local Binary Patterns[15], Adaboost[16] etc. As nowadays,Viola Jones algorithm is primarily the golden standard of face detection, it is applied over each of the original dataset’simages and a new dataset is created that contains all these cropped images of faces.With Preprocessing,the noiseinte', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 251: (' that there is no anomaly while calculating\\nthe embedding vector for those particular faces. This is done by ﬁnding the bounding boxes of all faces by applying\\nthrough Face Detection Algorithms like Viola-Jones[14], Local Binary Patterns[15], Adaboost[16] etc. As nowadays,Viola Jones algorithm is primarily the golden standard of face detection, it is applied over each of the original dataset’simages and a new dataset is created that contains all these cropped images of faces.With Preprocessing,the noiseinterfering in the prediction of Facial Embeddings have been eliminated.4 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nFig. 1. Inception Modules\\n4.2. Calculation of facial embeddings\\nA Convolutional Network has been used to downsize the images and convert a (224*224*3) sized image (which\\nis passed as input to the network) to a (128*1) sized vector. The same architecture as proposed for Facenet model by\\nauthors of the original paper has been used here.[4].\\nBrieﬂy the network consists of a 3D convolutional ﬁlter followed by 2 Batch Normalisation and Max-Pooling\\nlayers. This is further followed by 10 Inception modules (ﬁg 1). Each Inception module comprises of 1*1,3*3 and 5*5\\nconvolutional ﬁlters. Output of all these ﬁlters are concatenated together and passed to deeper layers. The resultantimage after passing through all the 10 Inception Modules is of the dimensions 7*7*1024. Finally, all the 1024 channelsof the resultant image are subjected to layer of average pooling and output is a vector with 1024 dimensions. These1024 output units then go through a dense fully connected network having 128 output units with an output ReLUactivation layer. The output at all nodes are combined together to form a 128-dimensional vector.\\nSuch deeper layers,help the network in learning deeper representations within the image.In order to facilitate\\nfaster backpropagation residual connections are added between layers.Transfer Learning is performed and the weightslearned by the Facenet model originally via train', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 252: ('or with 1024 dimensions. These1024 output units then go through a dense fully connected network having 128 output units with an output ReLUactivation layer. The output at all nodes are combined together to form a 128-dimensional vector.\\nSuch deeper layers,help the network in learning deeper representations within the image.In order to facilitate\\nfaster backpropagation residual connections are added between layers.Transfer Learning is performed and the weightslearned by the Facenet model originally via training have been used in this work.To summarize,the image of dimen-sion 224*224*3 is passed into the network which gives out a 128-dimensional vector at the other end containing thefacial embedding of the input image. The network is 24 Layers deep and had been designed using computationaleﬃciency in mind. The authors of the original paper chose 128-dimensions for their facial embeddings as it helpedthem achieve a higher accuracy and the same dimensions will be used in this paper also.\\n4.3. Predicting gender probabilities by applying machine learning models on facial embeddings\\nThe last phase involves training of Machine Learning Models to classify gender on the basis of the respective\\nfacial embeddings generated for each face. Facenet Neural Network gives us a mapping from higher-dimensional\\nspace (which signiﬁes the facial images) to a lower dimensional one[4]. The Embeddings serve as a representation ofthe image in a 128-dimensional space. All the major machine learning models are trained to predict the gender of thetraining images on the basis of these 128-dimensional embeddings. The Major Machine Learning Techniques usedare Logistic Regression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and DecisionTrees. All the Machine Learning Techniques are trained for 400 iterations with a learning rate of 0.001. In case of\\n2638  Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642\\n Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 5\\nFig. 2. Architectu', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 253: (' of thetraining images on the basis of these 128-dimensional embeddings. The Major Machine Learning Techniques usedare Logistic Regression, Support Vector Machines(SVM), K-Nearest Neighbours(KNN), Naive-Bayes and DecisionTrees. All the Machine Learning Techniques are trained for 400 iterations with a learning rate of 0.001. In case of\\n2638  Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642\\n Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 5\\nFig. 2. Architecture Diagram of Proposed Model\\nK-Nearest Neighbours, the number of neighbours were taken as 40 and using it, the optimal test accuracy and F1\\nscore was calculated. The architecture diagram has been stated in (ﬁg 2). Early Stopping was applied whenever it was\\nfound that the validation accuracy and f1 score started decreasing.\\n5. Challenges\\nOne of the major challenges for classifying gender using facial images is the eﬀect of the posture of the person,\\nillumination and background noise. While neural networks are able to learn representations, they are subject to certain\\nspatial conditions of the input images. With the help of preprocessing, the proposed approach is able to make all inputimages uniform. This helps in better performance of the Machine Learning Methods.\\n6. Dataset\\nUTK Face Dataset[17] (Fig.3) is an expansive data set containing facial images of people belonging to the age\\ngroup 0-116(ﬁg 3). The UTK Faces Dataset[17] is a total collection of 22812 images of cropped faces. The Dataset\\nconsists of 11892 male faces and 10920 female faces. It contains the images of the faces of 9802 Whites, 4254 Blacks,\\n3843 Asians, 3275 Indians and 1636 people from other races. As the Dataset contains facial images of people from allraces, thus the proposed model can be applied to people of all races. These images are a subset of the Labelled Facesin the wild dataset[18] and have been manually annotated for the purpose of gender classiﬁcation.\\nThe diﬀerent Machine Learning Models process a synthetic dataset of Facial Embe', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 254: ('2 male faces and 10920 female faces. It contains the images of the faces of 9802 Whites, 4254 Blacks,\\n3843 Asians, 3275 Indians and 1636 people from other races. As the Dataset contains facial images of people from allraces, thus the proposed model can be applied to people of all races. These images are a subset of the Labelled Facesin the wild dataset[18] and have been manually annotated for the purpose of gender classiﬁcation.\\nThe diﬀerent Machine Learning Models process a synthetic dataset of Facial Embeddings. The Dataset consists of\\n128 columns(dimensionality of embeddings) and 22812 rows (total no. of images).\\nThe Dataset is available at (https: //susanqq.github.io/UTKFace/). The Dataset is open-sourced and available for\\ncommercial research purposes only. More information about the Dataset can be found at the above mentioned link.\\n6 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nFig. 3. Samples from the UTKFaces Dataset[17]\\n7. Results\\nThe dataset has been split into training data and test data sets for training and validation purposes. The train\\ndataset consists of 22406 images and validation dataset and train consists of 203 images each. The machine learning\\nmodel is trained over the train set along with the validation dataset so as to choose the optimal hyper parameters.\\nThe performance parameters of the model are then evaluated on the basis test dataset. In order to validate our results\\nAccuracy, Precision, Recall as well as F1 Score have been used for judging the performance of our proposed model.\\nTable 1. Performance of diﬀerent Machine Learning Models\\nMachine Learning Model Accuracy(%) Precision Recall F1 Score\\nLogistic Regression 92.4% 0.93 0.92 0.92\\nSupport Vector Machines 88.4% 0.88 0.88 0.88\\nK-Nearest Neighboursa97.02% 0.97 0.97 0.97\\nNaive-Bayes 89.4% 0.89 0.89 0.89\\nDecision Trees 93.2% 0.93 0.93 0.93\\naNo.of neighbours were taken as 40\\nTable 1shows the result of Gender classiﬁcation using Facial Embeddings w.r.t to these parameters. Across all\\nMachine Learning models, K Nea', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 255: (' our proposed model.\\nTable 1. Performance of diﬀerent Machine Learning Models\\nMachine Learning Model Accuracy(%) Precision Recall F1 Score\\nLogistic Regression 92.4% 0.93 0.92 0.92\\nSupport Vector Machines 88.4% 0.88 0.88 0.88\\nK-Nearest Neighboursa97.02% 0.97 0.97 0.97\\nNaive-Bayes 89.4% 0.89 0.89 0.89\\nDecision Trees 93.2% 0.93 0.93 0.93\\naNo.of neighbours were taken as 40\\nTable 1shows the result of Gender classiﬁcation using Facial Embeddings w.r.t to these parameters. Across all\\nMachine Learning models, K Nearest Neighbours has the best performance with accuracy of 97 and Precision, Recalland F1 Score of 0.97 each. The High F1 Score indicates that the model is not biased towards one class. Random Forests\\nhave an accuracy of 93% and Precision, Recall and F1 Score of 0.93. Logistic Regression also performs as well as\\nrandom forests with an accuracy of 92.4%. All the other Machine Learning models achieve an accuracy that is greaterthan 88% and accuracy, precision and recall greater than 0.88. Fig 4compares the performance of Machine Learning\\nmodels on the basis of their respective accuracies. Fig 5compares all the models on the basis of their Precision,Recall\\nand F1 Score .\\n8. Comparision with previous works\\nSome of the highly cited works in this area are mentioned in the table 2along with their accuracies. The existing\\nmethods for gender classiﬁcation can be broadly subdivided into categories of Classical machine learning and deep\\nneural networks. Sexnet proposed by Golomb et.al [7] was the ﬁrst known instance of using neural networks to clas-sify gender. However, due to computational costs it could only achieve 91.9% accuracy. Samarasena Buchala et.al\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2639 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 5\\nFig. 2. Architecture Diagram of Proposed Model\\nK-Nearest Neighbours, the number of neighbours were taken as 40 and using it, the optimal test accuracy and F1\\nscore was calculated. The architecture diagram has been ', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 256: ('sing neural networks to clas-sify gender. However, due to computational costs it could only achieve 91.9% accuracy. Samarasena Buchala et.al\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2639 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 5\\nFig. 2. Architecture Diagram of Proposed Model\\nK-Nearest Neighbours, the number of neighbours were taken as 40 and using it, the optimal test accuracy and F1\\nscore was calculated. The architecture diagram has been stated in (ﬁg 2). Early Stopping was applied whenever it was\\nfound that the validation accuracy and f1 score started decreasing.\\n5. Challenges\\nOne of the major challenges for classifying gender using facial images is the eﬀect of the posture of the person,\\nillumination and background noise. While neural networks are able to learn representations, they are subject to certain\\nspatial conditions of the input images. With the help of preprocessing, the proposed approach is able to make all inputimages uniform. This helps in better performance of the Machine Learning Methods.\\n6. Dataset\\nUTK Face Dataset[17] (Fig.3) is an expansive data set containing facial images of people belonging to the age\\ngroup 0-116(ﬁg 3). The UTK Faces Dataset[17] is a total collection of 22812 images of cropped faces. The Dataset\\nconsists of 11892 male faces and 10920 female faces. It contains the images of the faces of 9802 Whites, 4254 Blacks,\\n3843 Asians, 3275 Indians and 1636 people from other races. As the Dataset contains facial images of people from allraces, thus the proposed model can be applied to people of all races. These images are a subset of the Labelled Facesin the wild dataset[18] and have been manually annotated for the purpose of gender classiﬁcation.\\nThe diﬀerent Machine Learning Models process a synthetic dataset of Facial Embeddings. The Dataset consists of\\n128 columns(dimensionality of embeddings) and 22812 rows (total no. of images).\\nThe Dataset is available at (https: //susanqq.github.io/UTKFace/). The Dataset is op', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 257: ('ges of people from allraces, thus the proposed model can be applied to people of all races. These images are a subset of the Labelled Facesin the wild dataset[18] and have been manually annotated for the purpose of gender classiﬁcation.\\nThe diﬀerent Machine Learning Models process a synthetic dataset of Facial Embeddings. The Dataset consists of\\n128 columns(dimensionality of embeddings) and 22812 rows (total no. of images).\\nThe Dataset is available at (https: //susanqq.github.io/UTKFace/). The Dataset is open-sourced and available for\\ncommercial research purposes only. More information about the Dataset can be found at the above mentioned link.\\n6 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nFig. 3. Samples from the UTKFaces Dataset[17]\\n7. Results\\nThe dataset has been split into training data and test data sets for training and validation purposes. The train\\ndataset consists of 22406 images and validation dataset and train consists of 203 images each. The machine learning\\nmodel is trained over the train set along with the validation dataset so as to choose the optimal hyper parameters.\\nThe performance parameters of the model are then evaluated on the basis test dataset. In order to validate our results\\nAccuracy, Precision, Recall as well as F1 Score have been used for judging the performance of our proposed model.\\nTable 1. Performance of diﬀerent Machine Learning Models\\nMachine Learning Model Accuracy(%) Precision Recall F1 Score\\nLogistic Regression 92.4% 0.93 0.92 0.92\\nSupport Vector Machines 88.4% 0.88 0.88 0.88\\nK-Nearest Neighboursa97.02% 0.97 0.97 0.97\\nNaive-Bayes 89.4% 0.89 0.89 0.89\\nDecision Trees 93.2% 0.93 0.93 0.93\\naNo.of neighbours were taken as 40\\nTable 1shows the result of Gender classiﬁcation using Facial Embeddings w.r.t to these parameters. Across all\\nMachine Learning models, K Nearest Neighbours has the best performance with accuracy of 97 and Precision, Recalland F1 Score of 0.97 each. The High F1 Score indicates that the model is not biased towards one class. Random Fore', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 258: ('achines 88.4% 0.88 0.88 0.88\\nK-Nearest Neighboursa97.02% 0.97 0.97 0.97\\nNaive-Bayes 89.4% 0.89 0.89 0.89\\nDecision Trees 93.2% 0.93 0.93 0.93\\naNo.of neighbours were taken as 40\\nTable 1shows the result of Gender classiﬁcation using Facial Embeddings w.r.t to these parameters. Across all\\nMachine Learning models, K Nearest Neighbours has the best performance with accuracy of 97 and Precision, Recalland F1 Score of 0.97 each. The High F1 Score indicates that the model is not biased towards one class. Random Forests\\nhave an accuracy of 93% and Precision, Recall and F1 Score of 0.93. Logistic Regression also performs as well as\\nrandom forests with an accuracy of 92.4%. All the other Machine Learning models achieve an accuracy that is greaterthan 88% and accuracy, precision and recall greater than 0.88. Fig 4compares the performance of Machine Learning\\nmodels on the basis of their respective accuracies. Fig 5compares all the models on the basis of their Precision,Recall\\nand F1 Score .\\n8. Comparision with previous works\\nSome of the highly cited works in this area are mentioned in the table 2along with their accuracies. The existing\\nmethods for gender classiﬁcation can be broadly subdivided into categories of Classical machine learning and deep\\nneural networks. Sexnet proposed by Golomb et.al [7] was the ﬁrst known instance of using neural networks to clas-sify gender. However, due to computational costs it could only achieve 91.9% accuracy. Samarasena Buchala et.al\\n2640  Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 7\\nFig. 4. Comparision of Accuracies of diﬀerent ML Models\\nFig. 5. Comparision of Precision,Recall and F1 Scores of diﬀerent ML models\\n[10] used Principal Component Analysis to extract local and global features to predict genders but only could achieve\\n86.43% accuracy. Improving upon this method and with more amount of data, Li Lu et.al [19] used SVM analysison diﬀerent facial regions to predict the gender of t', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 259: ('cience 167 (2020) 2634–2642\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 7\\nFig. 4. Comparision of Accuracies of diﬀerent ML Models\\nFig. 5. Comparision of Precision,Recall and F1 Scores of diﬀerent ML models\\n[10] used Principal Component Analysis to extract local and global features to predict genders but only could achieve\\n86.43% accuracy. Improving upon this method and with more amount of data, Li Lu et.al [19] used SVM analysison diﬀerent facial regions to predict the gender of the face and was able to achieve a higher accuracy of 95.33%.\\nThe highest recorded accuracy of 99.3% is of M.Nazir et.al.s [11] work involving the use of Discrete Cosine Trans-\\nformation technique. Tejas et.al [9] had used a combination of Linear Discriminant Analysis along with SVM andwas able to achieve an accuracy of 83.43% across all ethinicities. Finally,K-Nearest Neighbours Algorithm to clas-\\nsify facial images using extracted features has been used in this work. The proposed work performs well than most of\\nthese existing methods with an accuracy of 97%. Recently, standard Neural network architectures like ALEXNET andGOOGLENET have been used by Gkhan zbulak et al.[20] and Sebastian Lapuschkin et al. [21] to achieve accuracies\\nof 93.3% and 89% respectively.\\n8 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nTable 2. Past Approaches to Gender Classiﬁcation using Facial Images\\nSerial No. Author Year Accuracy\\n1 Golomb et al. 1990 91.9%\\n2 Li Lu, Pengfei Shi 2009 95.33%\\n3 Samarasena Buchala et al. 2010 86.43%\\n4 Tejas et al. 2011 83.43%\\n5 M. Nazir et al. 2014 99.3%\\n6 Sebastian Lapuschkin et al. 2017 89%\\n7 Gkhan zbulak et al. 2016 93.30%\\nIn case of dataset sizes, while most of the existing works have been either trained upon the FERET facial database\\n(14126 images) or on the SUMS facial database (1300 images) the proposed work is trained on 22812 images from the\\nUTK Faces dataset making it less prone to variations in the images and a better State of the art for gender classiﬁcationusing facia', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 260: ('la et al. 2010 86.43%\\n4 Tejas et al. 2011 83.43%\\n5 M. Nazir et al. 2014 99.3%\\n6 Sebastian Lapuschkin et al. 2017 89%\\n7 Gkhan zbulak et al. 2016 93.30%\\nIn case of dataset sizes, while most of the existing works have been either trained upon the FERET facial database\\n(14126 images) or on the SUMS facial database (1300 images) the proposed work is trained on 22812 images from the\\nUTK Faces dataset making it less prone to variations in the images and a better State of the art for gender classiﬁcationusing facial images.\\nAs compared to previous works using classical machine learning or deep neural networks to predict gender,the pro-\\nposed work involves the combination of both.The proposed work has numerous advantages compared to the previousmethods. As the network is small, it can be exported to mobiles and used by consumers easily without any latency.Neural Networks have the ability to learn from large amounts of data and as huge amounts of data is accumulated, themodel can be updated easily.\\n9. Analysis\\nThe Similarity of facial embeddings highly depend on the similarity between faces and facial features[4]. Thus,\\nfaces of two men are more similar than that of a man and woman due to which the euclidean distances of the facial\\nembeddings between two men is smaller than the euclidean distances of the facial embeddings between a man anda woman. Due to this, Facial Embeddings of all the faces from the same gender are grouped together. When FacialEmbeddings for a test subject are calculated, it is located in the vicinity of one of these 2 Clusters based upon itsGender. Thus on the application of K-Nearest Neighbours Algorithm on the test image, most of the nearest neighboursto the test image consist primarily of facial embeddings of the faces belonging to the same gender. These nearestneighbours positively inﬂuence the prediction of the correct gender of the test image ﬁnally leading to a higheraccuracy for the algorithm.\\nLogistic regression and other Machine Learning models consider the Facial Embeddings as the character', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 261: ('y of one of these 2 Clusters based upon itsGender. Thus on the application of K-Nearest Neighbours Algorithm on the test image, most of the nearest neighboursto the test image consist primarily of facial embeddings of the faces belonging to the same gender. These nearestneighbours positively inﬂuence the prediction of the correct gender of the test image ﬁnally leading to a higheraccuracy for the algorithm.\\nLogistic regression and other Machine Learning models consider the Facial Embeddings as the characteristic fea-\\nture vectors for each and every image. However,the feature vectors might exhibit a small change depending on variousfactors. These factors contributes negatively to predicting the ﬁnal result leading to a poor result.\\n10. Conclusion\\nIn this paper, an approach to classify gender using facial embeddings has been proposed. The proposed approach\\nperforms consistently well across facial images of diﬀerent gender and races. This method is also robust and can be\\nused to scale towards industrial production environments. The study proves that instead of treating image pixels asfeatures, in order to perform better classiﬁcation using facial images, representations need to be learned from theseimages(using neural networks) and further classiﬁcation needs to be done on the basis of these learned representations.\\nAfter passing the dataset through the Facenet Network and then evaluating on some of the major Machine Learning\\nTechniques, the KNN Algorithm performs the best in comparison to others. After evaluating the dataset on ﬁve mainMachine Learning Techniques after passing through the Facenet Network,the KNN Algorithm performs highly incomparison to others. This approach also performs better as compared to previous works in this ﬁeld. This work canbe further extended to classify race, ethnicity and country of origin and also predict the age of person using regressionmethods on facial embeddings.\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2641\\nSwaminathan, Chaba et al. /Proced', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 262: (' the dataset on ﬁve mainMachine Learning Techniques after passing through the Facenet Network,the KNN Algorithm performs highly incomparison to others. This approach also performs better as compared to previous works in this ﬁeld. This work canbe further extended to classify race, ethnicity and country of origin and also predict the age of person using regressionmethods on facial embeddings.\\n Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642  2641\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 7\\nFig. 4. Comparision of Accuracies of diﬀerent ML Models\\nFig. 5. Comparision of Precision,Recall and F1 Scores of diﬀerent ML models\\n[10] used Principal Component Analysis to extract local and global features to predict genders but only could achieve\\n86.43% accuracy. Improving upon this method and with more amount of data, Li Lu et.al [19] used SVM analysison diﬀerent facial regions to predict the gender of the face and was able to achieve a higher accuracy of 95.33%.\\nThe highest recorded accuracy of 99.3% is of M.Nazir et.al.s [11] work involving the use of Discrete Cosine Trans-\\nformation technique. Tejas et.al [9] had used a combination of Linear Discriminant Analysis along with SVM andwas able to achieve an accuracy of 83.43% across all ethinicities. Finally,K-Nearest Neighbours Algorithm to clas-\\nsify facial images using extracted features has been used in this work. The proposed work performs well than most of\\nthese existing methods with an accuracy of 97%. Recently, standard Neural network architectures like ALEXNET andGOOGLENET have been used by Gkhan zbulak et al.[20] and Sebastian Lapuschkin et al. [21] to achieve accuracies\\nof 93.3% and 89% respectively.\\n8 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nTable 2. Past Approaches to Gender Classiﬁcation using Facial Images\\nSerial No. Author Year Accuracy\\n1 Golomb et al. 1990 91.9%\\n2 Li Lu, Pengfei Shi 2009 95.33%\\n3 Samarasena Buchala et al. 2010 86.43%\\n4 Tejas et al. 2011 83.43%\\n5 M. Nazir e', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 263: ('y, standard Neural network architectures like ALEXNET andGOOGLENET have been used by Gkhan zbulak et al.[20] and Sebastian Lapuschkin et al. [21] to achieve accuracies\\nof 93.3% and 89% respectively.\\n8 Swaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000\\nTable 2. Past Approaches to Gender Classiﬁcation using Facial Images\\nSerial No. Author Year Accuracy\\n1 Golomb et al. 1990 91.9%\\n2 Li Lu, Pengfei Shi 2009 95.33%\\n3 Samarasena Buchala et al. 2010 86.43%\\n4 Tejas et al. 2011 83.43%\\n5 M. Nazir et al. 2014 99.3%\\n6 Sebastian Lapuschkin et al. 2017 89%\\n7 Gkhan zbulak et al. 2016 93.30%\\nIn case of dataset sizes, while most of the existing works have been either trained upon the FERET facial database\\n(14126 images) or on the SUMS facial database (1300 images) the proposed work is trained on 22812 images from the\\nUTK Faces dataset making it less prone to variations in the images and a better State of the art for gender classiﬁcationusing facial images.\\nAs compared to previous works using classical machine learning or deep neural networks to predict gender,the pro-\\nposed work involves the combination of both.The proposed work has numerous advantages compared to the previousmethods. As the network is small, it can be exported to mobiles and used by consumers easily without any latency.Neural Networks have the ability to learn from large amounts of data and as huge amounts of data is accumulated, themodel can be updated easily.\\n9. Analysis\\nThe Similarity of facial embeddings highly depend on the similarity between faces and facial features[4]. Thus,\\nfaces of two men are more similar than that of a man and woman due to which the euclidean distances of the facial\\nembeddings between two men is smaller than the euclidean distances of the facial embeddings between a man anda woman. Due to this, Facial Embeddings of all the faces from the same gender are grouped together. When FacialEmbeddings for a test subject are calculated, it is located in the vicinity of one of these 2 Clusters based upon itsGender. Thus on th', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 264: ('etween faces and facial features[4]. Thus,\\nfaces of two men are more similar than that of a man and woman due to which the euclidean distances of the facial\\nembeddings between two men is smaller than the euclidean distances of the facial embeddings between a man anda woman. Due to this, Facial Embeddings of all the faces from the same gender are grouped together. When FacialEmbeddings for a test subject are calculated, it is located in the vicinity of one of these 2 Clusters based upon itsGender. Thus on the application of K-Nearest Neighbours Algorithm on the test image, most of the nearest neighboursto the test image consist primarily of facial embeddings of the faces belonging to the same gender. These nearestneighbours positively inﬂuence the prediction of the correct gender of the test image ﬁnally leading to a higheraccuracy for the algorithm.\\nLogistic regression and other Machine Learning models consider the Facial Embeddings as the characteristic fea-\\nture vectors for each and every image. However,the feature vectors might exhibit a small change depending on variousfactors. These factors contributes negatively to predicting the ﬁnal result leading to a poor result.\\n10. Conclusion\\nIn this paper, an approach to classify gender using facial embeddings has been proposed. The proposed approach\\nperforms consistently well across facial images of diﬀerent gender and races. This method is also robust and can be\\nused to scale towards industrial production environments. The study proves that instead of treating image pixels asfeatures, in order to perform better classiﬁcation using facial images, representations need to be learned from theseimages(using neural networks) and further classiﬁcation needs to be done on the basis of these learned representations.\\nAfter passing the dataset through the Facenet Network and then evaluating on some of the major Machine Learning\\nTechniques, the KNN Algorithm performs the best in comparison to others. After evaluating the dataset on ﬁve mainMachine Learning Techniques after pas', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 265: ('age pixels asfeatures, in order to perform better classiﬁcation using facial images, representations need to be learned from theseimages(using neural networks) and further classiﬁcation needs to be done on the basis of these learned representations.\\nAfter passing the dataset through the Facenet Network and then evaluating on some of the major Machine Learning\\nTechniques, the KNN Algorithm performs the best in comparison to others. After evaluating the dataset on ﬁve mainMachine Learning Techniques after passing through the Facenet Network,the KNN Algorithm performs highly incomparison to others. This approach also performs better as compared to previous works in this ﬁeld. This work canbe further extended to classify race, ethnicity and country of origin and also predict the age of person using regressionmethods on facial embeddings.\\n2642  Avinash Swaminathan  et al. / Procedia Computer Science 167 (2020) 2634–2642\\nSwaminathan, Chaba et al. /Procedia Computer Science 00 (2019) 000–000 9\\nReferences\\n[1] R. Sharma and M. Patterh (2015), “Age invariant face recognition using k-pca and k-nn on indian face age database (ifad),” International\\nJournal of Computer Applications, vol. 126, no. 5.\\n[2] F. Jalled (2017), “Face recognition machine vision system using eigenfaces.”\\n[3] M. Lades, J. Vorbruggen, J. Buhmann, J. Lange, C. von der Malsburg, R. Wurtz, and W. Konen (1993), “Distortion invariant object recognition\\nin the dynamic link architecture,” IEEE Transactions on Computers, vol. 42, no. 3.\\n[4] F. Schroﬀ, D. Kalenichenko, and J. Philbin (2015), “Facenet: A uniﬁed embedding for face recognition and clustering,” 2015 IEEE Conference\\non Computer Vision and Pattern Recognition (CVPR).\\n[5] T. Mikolov, K. Chen, G. Corrado, and J. Dean (2013), “Eﬃcient estimation of word representations in vector space.”[6] A. Jain, J. Huang, and S. F. (2005), “Gender identiﬁcation using frontal facial images,” 2005 IEEE International Conference on Multimedia\\nand Expo.\\n[7] B. A. Golomb, D. T. Lawrence, and T. J. Sejnowski (1990), “Sexnet: ', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 266: ('ichenko, and J. Philbin (2015), “Facenet: A uniﬁed embedding for face recognition and clustering,” 2015 IEEE Conference\\non Computer Vision and Pattern Recognition (CVPR).\\n[5] T. Mikolov, K. Chen, G. Corrado, and J. Dean (2013), “Eﬃcient estimation of word representations in vector space.”[6] A. Jain, J. Huang, and S. F. (2005), “Gender identiﬁcation using frontal facial images,” 2005 IEEE International Conference on Multimedia\\nand Expo.\\n[7] B. A. Golomb, D. T. Lawrence, and T. J. Sejnowski (1990), “Sexnet: A neural network identiﬁes sex from human faces.”[8] E. Makinen and R. Raisamo (2008), “Evaluation of gender classiﬁcation methods with automatically detected and aligned faces,” IEEE Trans-\\nactions on Pattern Analysis and Machine Intelligence, vol. 30, no. 3.\\n[9] T. I. Dhamecha, A. Sankaran, R. Singh, and M. Vatsa (2011), “Is gender classiﬁcation across ethnicity feasible using discriminant functions?”\\n2011 International Joint Conference on Biometrics (IJCB).\\n[10] S. Buchala, T. M. Gale, N. Davey, R. J. Frank, and K. Foley (2005), “Global and feature based gender classiﬁcation of faces: A comparison of\\nhuman performance and computational models,” Modeling Language, Cognition and Action.\\n[11] M. Nazir, A. Batool, and A. Jaﬀ ar (2010), “Feature selection for eﬃcient gender classiﬁcation.”\\n[12] Z. Xu, L. Lu, and P. S. (2008), “A hybrid approach to gender classiﬁcation from face images,” 2008 19th International Conference on Pattern\\nRecognition.\\n[13] S. Ravi and S. P. Wilson (2010), “Face detection with facial features and gender classiﬁcation based on support vector machine.”[14] P. Viola and M. Jones (2001), “Rapid object detection using a boosted cascade of simple features,” Proceedings of the 2001 IEEE Computer\\nSociety Conference on Computer Vision and Pattern Recognition. CVPR 2001.\\n[15] D. Huang, C. Shan, M. Ardabilian, Y. Wang, and L. Chen (2011), “Local binary patterns and its application to facial image analysis: A survey,”\\nIEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Revie', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 267: ('eatures and gender classiﬁcation based on support vector machine.”[14] P. Viola and M. Jones (2001), “Rapid object detection using a boosted cascade of simple features,” Proceedings of the 2001 IEEE Computer\\nSociety Conference on Computer Vision and Pattern Recognition. CVPR 2001.\\n[15] D. Huang, C. Shan, M. Ardabilian, Y. Wang, and L. Chen (2011), “Local binary patterns and its application to facial image analysis: A survey,”\\nIEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews), vol. 41, no. 6.\\n[16] A. Tharwat (2018), “Adaboost classiﬁer: an overview,” 02.[17] Susanqq(2017), “Utkfaces-dataset.” [Online]. Available: https:// susanqq.github.io/ UTKFace/\\n[18] G. B. Huang, M. Ramesh, T. Berg, and E. L. Miller (2010), “Labeled faces in the wild: A database for studying face recognition in unconstrained\\nenvironments,” 2010.\\n[19] L. Lu, Z. Xu, and P. Shi (2009), “Gender classiﬁcation of facial images based on multiple facial regions,” vol. 6, 05, pp. 48 – 52.[20] G. Ozbulak, Y. Aytar, and H. K. Ekenel (2016), “How transferable are cnn-based features for age and gender classiﬁcation?” in 2016 Interna-\\ntional Conference of the Biometrics Special Interest Group (BIOSIG), pp. 1–6.\\n[21] A. Binder, S. Bach, G. Montavon, K.-R. M ¨uller, and W. Samek (2016), “Layer-wise relevance propagation for deep neural network architec-\\ntures,” in Information Science and Applications (ICISA) 2016, K. J. Kim and N. Joukov, Eds. Singapore: Springer Singapore, pp. 913–922.', 'Gender Classification using Facial Embeddings A Novel Approach.pdf'), 268: ('Published as a conference paper at ICLR 2025\\nNEURO LM: A U NIVERSAL MULTI -TASK FOUNDATION\\nMODEL FOR BRIDGING THE GAP BETWEEN LAN-\\nGUAGE AND EEG S IGNALS\\nWei-Bang Jiang1∗, Yansen Wang2, Bao-Liang Lu1, Dongsheng Li2\\n1Shanghai Jiao Tong University2Microsoft Research Asia\\n{935963004,bllu }@sjtu.edu.cn, {yansenwang,dongsli }@microsoft.com\\nhttps://github.com/935963004/NeuroLM\\nABSTRACT\\nRecent advancements for large-scale pre-training with neural signals such as elec-\\ntroencephalogram (EEG) have shown promising results, significantly boosting\\nthe development of brain-computer interfaces (BCIs) and healthcare. However,\\nthese pre-trained models often require full fine-tuning on each downstream task\\nto achieve substantial improvements, limiting their versatility and usability, and\\nleading to considerable resource wastage. To tackle these challenges, we propose\\nNeuroLM, the first multi-task foundation model that leverages the capabilities\\nof Large Language Models (LLMs) by regarding EEG signals as a foreign lan-\\nguage, endowing the model with multi-task learning and inference capabilities.\\nOur approach begins with learning a text-aligned neural tokenizer through vector-\\nquantized temporal-frequency prediction, which encodes EEG signals into dis-\\ncrete neural tokens. These EEG tokens, generated by the frozen vector-quantized\\n(VQ) encoder, are then fed into an LLM that learns causal EEG information via\\nmulti-channel autoregression. Consequently, NeuroLM can understand both EEG\\nand language modalities. Finally, multi-task instruction tuning adapts NeuroLM\\nto various downstream tasks. We are the first to demonstrate that, by specific\\nincorporation with LLMs, NeuroLM unifies diverse EEG tasks within a single\\nmodel through instruction tuning. The largest variant NeuroLM-XL has record-\\nbreaking 1.7B parameters for EEG signal processing, and is pre-trained on a large-\\nscale corpus comprising approximately 25,000-hour EEG data. When evaluated\\non six diverse downstream datasets, NeuroLM showcases the huge potential of\\nthis multi-task', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 269: ('struction tuning adapts NeuroLM\\nto various downstream tasks. We are the first to demonstrate that, by specific\\nincorporation with LLMs, NeuroLM unifies diverse EEG tasks within a single\\nmodel through instruction tuning. The largest variant NeuroLM-XL has record-\\nbreaking 1.7B parameters for EEG signal processing, and is pre-trained on a large-\\nscale corpus comprising approximately 25,000-hour EEG data. When evaluated\\non six diverse downstream datasets, NeuroLM showcases the huge potential of\\nthis multi-task learning paradigm.\\n1 I NTRODUCTION\\n/uni00000024/uni00000045/uni00000051/uni00000052/uni00000055/uni00000050/uni00000044/uni0000004f\\n/uni00000027/uni00000048/uni00000057/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000028/uni00000059/uni00000048/uni00000051/uni00000057/uni00000003/uni00000037/uni0000005c/uni00000053/uni00000048\\n/uni00000026/uni0000004f/uni00000044/uni00000056/uni00000056/uni0000004c/uni00000049/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000028/uni00000050/uni00000052/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000035/uni00000048/uni00000046/uni00000052/uni0000004a/uni00000051/uni0000004c/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000036/uni0000004f/uni00000048/uni00000048/uni00000053/uni00000003/uni00000036/uni00000057/uni00000044/uni0000004a/uni00000048\\n/uni00000026/uni0000004f/uni00000044/uni00000056/uni00000056/uni0000004c/uni00000049/uni0000004c/uni00000046/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni0000003a/uni00000052/uni00000055/uni0000004e/uni0000004f/uni00000052/uni00000044/uni00000047\\n/uni00000027/uni00000048/uni00000057/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000036/uni0000004f/uni00000052/uni0000005a/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000028/uni00000059/uni00000048/uni00000051/uni00000057\\n/uni00000027/uni00000048/uni00000057/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000013/u', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 270: ('04c/uni00000052/uni00000051/uni0000003a/uni00000052/uni00000055/uni0000004e/uni0000004f/uni00000052/uni00000044/uni00000047\\n/uni00000027/uni00000048/uni00000057/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000036/uni0000004f/uni00000052/uni0000005a/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000028/uni00000059/uni00000048/uni00000051/uni00000057\\n/uni00000027/uni00000048/uni00000057/uni00000048/uni00000046/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000031/uni00000048/uni00000058/uni00000055/uni00000052/uni0000002f/uni00000030/uni00000003/uni0000000b/uni00000050/uni00000058/uni0000004f/uni00000057/uni0000004c/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni0000002f/uni00000044/uni00000025/uni00000055/uni00000044/uni00000030/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni00000003/uni00000036/uni00000032/uni00000037/uni00000024/uni0000000c\\n/uni00000036/uni00000033/uni00000044/uni00000035/uni00000026/uni00000031/uni00000048/uni00000057/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni00000026/uni00000031/uni00000031/uni00000010/uni00000037/uni00000055/uni00000044/uni00000051/uni00000056/uni00000049/uni00000052/uni00000055/uni00000050/uni00000048/uni00000055/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni00000029/uni00000029/uni00000026/uni0000002f/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni00000036/uni00000037/uni00000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 271: ('i00000051/uni00000056/uni00000049/uni00000052/uni00000055/uni00000050/uni00000048/uni00000055/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni00000029/uni00000029/uni00000026/uni0000002f/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\n/uni00000036/uni00000037/uni00000010/uni00000037/uni00000055/uni00000044/uni00000051/uni00000056/uni00000049/uni00000052/uni00000055/uni00000050/uni00000048/uni00000055/uni00000003/uni0000000b/uni00000056/uni0000004c/uni00000051/uni0000004a/uni0000004f/uni00000048/uni00000010/uni00000057/uni00000044/uni00000056/uni0000004e/uni0000000c\\nFigure 1: Comparison on six tasks.Electroencephalogram (EEG) signals have become a corner-\\nstone in the development of brain-computer interfaces and\\nhealthcare domains, offering a non-invasive solution to capture\\nthe electrical activity of the brain. EEG measures the voltage\\nfluctuations resulting from ionic current flows within the neu-\\nrons of the brain, providing real-time insights into brain func-\\ntion and neural dynamics. This capability makes EEG an in-\\nvaluable tool for creating interfaces that enable direct commu-\\nnication between the brain and external devices. EEG is advan-\\ntageous due to its high temporal resolution, cost-effectiveness,\\nand portability, and has been significantly enhanced by ad-\\nvanced computational methods. Therefore, a wide range of\\napplications have been utilizing EEG signals, including but\\nnot limited to human emotion recognition (Jenke et al., 2014),\\nbody motor imaginary (Tabar & Halici, 2016), automatic sleep stage classification (Supratak et al.,\\n2017), seizure epilepsy detection (Alotaiby et al., 2014), and fatigue detection (Gao et al., 2019).\\n∗Work done during Wei-Bang’s internship at Microsoft Research Asia. Correspondence to Yansen Wang.\\n1arXiv:2409.00101v2  [eess.SP]  2 Fe', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 272: ('ed computational methods. Therefore, a wide range of\\napplications have been utilizing EEG signals, including but\\nnot limited to human emotion recognition (Jenke et al., 2014),\\nbody motor imaginary (Tabar & Halici, 2016), automatic sleep stage classification (Supratak et al.,\\n2017), seizure epilepsy detection (Alotaiby et al., 2014), and fatigue detection (Gao et al., 2019).\\n∗Work done during Wei-Bang’s internship at Microsoft Research Asia. Correspondence to Yansen Wang.\\n1arXiv:2409.00101v2  [eess.SP]  2 Feb 2025\\nPublished as a conference paper at ICLR 2025\\nWhile EEG signals are popular among researchers, they have several disadvantages, including the\\nlow signal-to-noise ratio, inherent nonstationarity, as well as diverse configurations in EEG data\\ncollection. Besides, there is a lack of sufficient and consistent EEG data. These challenges compli-\\ncate the extraction of universal EEG representations. To overcome these problems, several studies\\nhave proposed methods compatible with diverse EEG configurations to learn effective and generic\\nrepresentations. For example, Yang et al. (2023a) introduce a Biosignal Transformer (BIOT), which\\nunifies various EEG data by tokenizing channels into fix-length segments with channel and relative\\nposition embeddings for preserving spatio-temporal features. Jiang et al. (2024) advance this ap-\\nproach by proposing a neural tokenizer to pre-train LaBraM by masked neural code prediction with\\n2,500 hours of EEG data, thus achieving state-of-the-art (SOTA) performance on various down-\\nstream tasks. Although these methods effectively address the aforementioned challenges, they still\\nrequire individual fine-tuning on each downstream dataset to obtain impressive improvement. De-\\nspite increasing model size and employing large-scale unsupervised pre-training to learn generic\\nrepresentations, such adaptation confines the fine-tuned model to perform only a single task. More-\\nover, this task-specific fine-tuning demands substantial computational and storage resources.\\nOver the past few years', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 273: ('n-\\nstream tasks. Although these methods effectively address the aforementioned challenges, they still\\nrequire individual fine-tuning on each downstream dataset to obtain impressive improvement. De-\\nspite increasing model size and employing large-scale unsupervised pre-training to learn generic\\nrepresentations, such adaptation confines the fine-tuned model to perform only a single task. More-\\nover, this task-specific fine-tuning demands substantial computational and storage resources.\\nOver the past few years, the advent of Large Language Models has brought remarkable progress\\nand demonstrated extraordinary emergent abilities (Brown et al., 2020; Touvron et al., 2023). The\\ndevelopment of LLMs has given rise to Multimodal Large Language Models (MLLMs) (Achiam\\net al., 2023; Liu et al., 2023), which unleash the potential of powerful LLMs to perform multimodal\\ntasks. MLLMs typically integrate a modality-specific encoder, pre-aligned with text embeddings,\\ninto off-the-shelf LLMs. Inspired by MLLMs, we unveil a new direction of integrating multiple\\nEEG tasks into a unified model by incorporating EEG signals into existing LLMs. However, there\\nare some challenges in harnessing LLMs to understand EEG patterns, comprising:\\n1) EEG-text embedding alignment. Aligning EEG and text embeddings presents a great challenge.\\nUnlike vision-language models which benefit from numerous high-quality image-text pairs, there are\\nno established EEG-text pairs available due to the difficulty of extracting semantic information from\\na given EEG segment.\\n2) Effective Representation learning with LLMs. Mainstream methods employ masked EEG\\nmodeling to effectively extract representations for EEG signals. When integrating LLMs, how to\\nlearn generic information within the LLM paradigm remains an unsolved issue.\\n3) Unified multi-task learning with various EEG tasks. Integrating multiple EEG tasks into a\\nunified model is complex due to the diversity and specificity of different tasks. Developing a model\\nthat can seamlessly handle various tasks without c', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 274: ('G segment.\\n2) Effective Representation learning with LLMs. Mainstream methods employ masked EEG\\nmodeling to effectively extract representations for EEG signals. When integrating LLMs, how to\\nlearn generic information within the LLM paradigm remains an unsolved issue.\\n3) Unified multi-task learning with various EEG tasks. Integrating multiple EEG tasks into a\\nunified model is complex due to the diversity and specificity of different tasks. Developing a model\\nthat can seamlessly handle various tasks without compromising performance on any individual task\\nis a major challenge.\\nIn light of the aforementioned challenges, we propose NeuroLM, a universal multi-task foundation\\nmodel for EEG signal processing. NeuroLM builds upon the compatibility with diverse EEG for-\\nmats established by LaBraM, and it is pre-trained on a large-scale dataset comprising approximately\\n25,000 hours of EEG data. The training of NeuroLM involves three stages. First, a text-aligned neu-\\nral tokenizer is trained using vector-quantized temporal-frequency prediction to encode continuous\\nEEG signals into discrete codes from a neural codebook, with adversarial training employed to align\\nthe EEG and text spaces. Next, the VQ encoder of the neural tokenizer is frozen to extract compact\\nembeddings, which serve as input for a LLM. To enable the LLM to learn causal EEG representa-\\ntions, we propose multi-channel autoregressive pre-training, which mimics autoregressive language\\nmodeling but is tailored for multi-channel EEG signals. Finally, we elaborate instructions for various\\ndownstream datasets and employ multi-task instruction tuning to empower NeuroLM for multi-task\\nlearning. Experiments on six different tasks, encompassing abnormal detection, event type classifi-\\ncation, emotion recognition, sleep stage classification, cognitive workload prediction, and slowing\\ntype classification, demonstrate NeuroLM’s superiority in multi-task learning and inference. To the\\nbest of our knowledge, we are the first to introduce instruction tuning to enable multi-t', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 275: ('te instructions for various\\ndownstream datasets and employ multi-task instruction tuning to empower NeuroLM for multi-task\\nlearning. Experiments on six different tasks, encompassing abnormal detection, event type classifi-\\ncation, emotion recognition, sleep stage classification, cognitive workload prediction, and slowing\\ntype classification, demonstrate NeuroLM’s superiority in multi-task learning and inference. To the\\nbest of our knowledge, we are the first to introduce instruction tuning to enable multi-task learning\\nand inference in the field of EEG signal processing. The highlights are summarized as follows:\\n1) Text-aligned neural tokenizer embeddings. We introduce a text-aligned neural tokenizer\\nthat effectively bridges the gap between EEG and text data. This tokenizer uses vector-quantized\\ntemporal-frequency prediction to convert EEG signals into discrete codes, facilitating the alignment\\nof EEG and text embeddings through adversarial training. This alignment is crucial for leveraging\\nthe strengths of LLMs in understanding and processing EEG data.\\n2\\nPublished as a conference paper at ICLR 2025\\n8\\n…ConvGroup NormGELUSpatial & Temporal\\nEmbeddingsVQ Encoder\\nTemporal EncoderTransformer\\nBlocksSpatial Encoder-norm\\nCodebook\\n𝑣ଵ\\n𝑣ଶ\\n𝑣ଷ\\n…\\n𝑣\\u0bdeିଶ\\n𝑣\\u0bdeିଵ\\n𝑣\\u0bde\\nlook upTemporal\\nDecoderFrequency\\nDecoder\\npachifyEEG signals\\nFPz\\nAF7\\nF5\\nFC1\\nCz\\nCP6\\nP8\\nO1\\nTemporal reconstruction\\nFrequency reconstructionVQ TrainingDomain\\nClassifier\\nText vocabreverse \\ngradientText orEEGEEG-Text Embedding \\nSpace Alignment\\nFigure 2: The architecture design of text-aligned neural tokenizer training. The neural tokenizer is\\ntrained by reconstructing both temporal and frequency domain of input EEG signals to discretize\\nthem into discrete neural tokens. To align EEG and text embedding space, we utilize a domain\\nclassifier through adversarial training.\\n2) Large-scale multi-channel autoregressive pre-training. NeuroLM employs multi-channel au-\\ntoregression, enabling the model to learn causal representations across different EEG channels. Pre-\\ntraining on 25,000 h', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 276: ('n of text-aligned neural tokenizer training. The neural tokenizer is\\ntrained by reconstructing both temporal and frequency domain of input EEG signals to discretize\\nthem into discrete neural tokens. To align EEG and text embedding space, we utilize a domain\\nclassifier through adversarial training.\\n2) Large-scale multi-channel autoregressive pre-training. NeuroLM employs multi-channel au-\\ntoregression, enabling the model to learn causal representations across different EEG channels. Pre-\\ntraining on 25,000 hours of EEG data ensures that NeuroLM captures a wide range of neural pat-\\nterns, enhancing its ability to generalize across diverse EEG tasks.\\n3) Joint multi-task tuning and inference. We pioneer the use of joint multi-task tuning and in-\\nference for EEG. By elaborating specific instructions for various downstream tasks and employing\\nmulti-task instruction tuning, NeuroLM is capable of performing multiple tasks within a single\\nmodel. This not only improves efficiency by reducing the need for individual fine-tuning for each\\ntask but also ensures high performance across a spectrum of applications.\\n2 M ETHOD\\nIn this section, we elaborate our design of NeuroLM. We first train a neural tokenizer by vector-\\nquantized temporal-frequency prediction. Whereafter, the VQ encoder of the tokenizer will serve\\nto encode EEG signals into embeddings aligned with text space, and the EEG embeddings will be\\nseamlessly used as input to Large Language Models.\\nGiven multi-channel EEG signals X∈RC×T, where Cdenotes the number of channels and T\\ndenotes total timestamps. An EEG sample is formulated as x∈RC×L, where Lis the window size,\\nresulting in a total number of ⌊T\\nL⌋samples. We pachify the EEG samples into non-overlap patches\\nx={xij∈RP|i= 1, ..., C, j = 1, ..., N}. LetPis patch size and N=⌊L\\nP⌋.\\n2.1 T EXT-ALIGNED NEURAL TOKENIZER TRAINING\\nTo incorporate EEG into off-the-shelf Large Language Models, we first need to encode EEG signals\\ninto embeddings whose space is well-aligned with text embedding space. VQ-V AE (Van Den Oord\\net al', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 277: ('annels and T\\ndenotes total timestamps. An EEG sample is formulated as x∈RC×L, where Lis the window size,\\nresulting in a total number of ⌊T\\nL⌋samples. We pachify the EEG samples into non-overlap patches\\nx={xij∈RP|i= 1, ..., C, j = 1, ..., N}. LetPis patch size and N=⌊L\\nP⌋.\\n2.1 T EXT-ALIGNED NEURAL TOKENIZER TRAINING\\nTo incorporate EEG into off-the-shelf Large Language Models, we first need to encode EEG signals\\ninto embeddings whose space is well-aligned with text embedding space. VQ-V AE (Van Den Oord\\net al., 2017) is a good choice that maps continuous signals to discrete tokens while preserving the\\nkey information. Our text-aligned neural tokenizer basically follows the well-established neural\\ntokenizer of LaBraM (Jiang et al., 2024) with some improvements. Vector-quantized temporal-\\nfrequency prediction is utilized to train the text-aligned neural tokenizer, as illustrated in Figure 2.\\nNeural Tokenizer. The neural tokenizer is composed of several vital components: VQ encoder,\\ncodebook, temporal/frequency decoder, and domain classifier. The codebook V ∈RK×Dcontains\\nKdiscrete D-dimension embeddings. Let hidenote the patch representations derived from the VQ\\nencoder. We find the nearest codes of each hifrom codebook embeddings {vi|i= 1, ..., K}:\\nzi= arg min\\nj∥ℓ2(hi)−ℓ2(vi)∥2, (1)\\nwhere j∈ {1, ..., K}andℓ2normalization is employed so that the above distance is equivalent to\\ncosine similarity. Consequently, an EEG sample is tokenized to z= [z1, ..., z N].\\n3\\nPublished as a conference paper at ICLR 2025\\nTemporal-frequency Prediction. We propose to predict both original signals and the frequency\\nmagnitude to capture the temporal and frequency domains of EEG signals. This differs from\\nLaBraM which regresses the Fourier amplitude and phase since we observe that reconstructing the\\nphase contributes minor to neural tokenizer training. We apply the Discrete Fourier Transform\\n(DFT) on an EEG patch xi,j= [x[1], x[2], ..., x [P]]of channel iand time j, and transform the\\nequation using Euler’s formula as follows\\n˜xm\\ni,j=MX\\nn=1x', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 278: ('quency Prediction. We propose to predict both original signals and the frequency\\nmagnitude to capture the temporal and frequency domains of EEG signals. This differs from\\nLaBraM which regresses the Fourier amplitude and phase since we observe that reconstructing the\\nphase contributes minor to neural tokenizer training. We apply the Discrete Fourier Transform\\n(DFT) on an EEG patch xi,j= [x[1], x[2], ..., x [P]]of channel iand time j, and transform the\\nequation using Euler’s formula as follows\\n˜xm\\ni,j=MX\\nn=1x[n] cos(2π\\nMmn)−jx[n] sin(2π\\nMmn). (2)\\nwhere m∈[1, N]andjis the imaginary unit. Accordingly, we calculate the frequency magnitude\\nasfm=q\\nRe(˜xm\\ni,j)2+Im(˜xm\\ni,j)2, where ReandImrepresent the real and imaginary parts of a\\ncomplex number. For stable convergence, we adopt z-score normalization to the magnitude within\\na sample.\\nAfter being quantized to the codebook embeddings, we feed the normalized neural embeddings\\n[ℓ2(z1), ..., ℓ 2(zN)]into two separate decoders. Let ot\\niandof\\nistand for the output of a temporal\\ndecoder and a frequency decoder, respectively. The optimizing target for the codebook learning is\\nL1=X\\nx∈DX\\ni∥ot\\ni−xi∥2\\n2+∥of\\ni−fi∥2\\n2| {z }\\nreconstruction loss+∥sg(ℓ2(hi))−ℓ2(vzi)∥2\\n2| {z }\\ncodebook loss+∥ℓ2(hi)−sg(ℓ2(vzi))∥2\\n2| {z }\\ncommitment loss,\\n(3)\\nwhere Drepresents the whole dataset and sgdenotes the stop-gradient operator that is identical\\nduring forward computation and has zero partial derivatives.\\nEEG-text Embedding Space Alignment. Current vision-language models usually utilize pre-\\ntrained CLIP-like (Radford et al., 2021) image encoders which are trained by large-scale image-text\\npairs and thus are embedding-wise well-aligned with text. However, when considering EEG, there\\nare much more challenges to align EEG with text: 1) EEG signals contain complicated cognitive and\\nnon-cognitive information, which is hard to be described by human language accurately and thor-\\noughly. For example, an EEG segment can not only contain one person’s emotion and mental states,\\nbut also represent the body movem', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 279: (' CLIP-like (Radford et al., 2021) image encoders which are trained by large-scale image-text\\npairs and thus are embedding-wise well-aligned with text. However, when considering EEG, there\\nare much more challenges to align EEG with text: 1) EEG signals contain complicated cognitive and\\nnon-cognitive information, which is hard to be described by human language accurately and thor-\\noughly. For example, an EEG segment can not only contain one person’s emotion and mental states,\\nbut also represent the body movement and medical normality. 2) The labeled EEG data available to\\nconstruct EEG-text pair are very limited. Therefore, we propose to align EEG with text space-wise\\ninstead of embedding-wise.\\nWe introduce a domain classifier Cto predict whether the embeddings are from EEG or text. During\\nthe codebook learning, we also feed some text embeddings from LLMs to train the domain classifier.\\nA gradient reverse layer (Ganin et al., 2016) is added after the VQ encoder to confuse the domain\\nclassifier. Hence, the embeddings from the VQ encoder fall into the same space of text embeddings.\\nConsequently, the training objective for text-aligned neural tokenizer training is defined as\\nminL1+λX\\nidilogC(hi), (4)\\nwhere diis the label of EEG or text domain and λ=2\\n1+e−10t/T−1is a scaling factor that gradually\\nchanges from 0 to 1.\\nVQ Encoder Architecture. We briefly introduce the architecture of the VQ encoder as it is almost\\nthe same as LaBraM. The temporal encoder and spatial encoder are two pivotal parts of the VQ\\nencoder. The temporal encoder contains several blocks of 1-D convolution which aims to extract\\ntemporal features in each EEG patch. After that, learnable temporal and spatial embeddings are\\nadded according to the standard 10-20 international system to inject both time and channel infor-\\nmation. Finally, the spatial encoder composed of vanilla Transformer blocks (Vaswani et al., 2017)\\nlearns interaction among patches.\\n2.2 M ULTI -CHANNEL AUTOREGRESSIVE PRE-TRAINING\\nBefore passing EEG data into Large Language Models, we fr', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 280: ('emporal encoder contains several blocks of 1-D convolution which aims to extract\\ntemporal features in each EEG patch. After that, learnable temporal and spatial embeddings are\\nadded according to the standard 10-20 international system to inject both time and channel infor-\\nmation. Finally, the spatial encoder composed of vanilla Transformer blocks (Vaswani et al., 2017)\\nlearns interaction among patches.\\n2.2 M ULTI -CHANNEL AUTOREGRESSIVE PRE-TRAINING\\nBefore passing EEG data into Large Language Models, we freeze the VQ encoder and first use it\\nto encode input EEG data to EEG tokens that are aligned with the text space. After that, we load a\\npre-trained Large Language Model and enlarge the text vocabulary with the learned EEG codebook.\\n4\\nPublished as a conference paper at ICLR 2025\\n10\\n…\\nVQ EncoderLarge Language Models\\n(causal Transformer)\\n1 2 3 4 5 6 7 8 9Neural Tokenizer\\n4 5 6 7 8 9Codebook Indices\\ntime 1 time 2ch1 ch2 ch3 ch1 ch2 ch3 ch1 ch2 ch3\\ntime 3\\nStage 1: Multi-channel autoregressive pre-trainingText vocab EEG vocabLarge Language Models\\n(causal Transformer)\\nVQ Encoder1 2 4\\nEEG tokens[SEP] emotion positive [END]38 9\\n5 6 7 8 9\\n:\\nStage 2: Joint instruction tuning with various tasksDownstream Datasets\\nevent classificationabnormal detection emotion recognition\\nsleep classificationBuild InstructionsAutoregressive Pre-training\\nFigure 3: Schematic of NeuroLM training. Left: We first pre-train NeuroLM via multi-channel\\nautoregression with EEG tokens output by the frozen VQ encoder. Right : The multi-task instruction\\ntuning enables NeuroLM to perform various BCI tasks within a single model.\\nThe EEG tokens are added with reused temporal embeddings from the LLM and new spatial embed-\\ndings. As shown in Figure 3, NeuroLM is then trained through multi-channel autoregression, that\\nis, predicting the next EEG tokens based on visible EEG tokens, to endow the model with the capa-\\nbility of learning special patterns of EEG causal relationship. In our experiments, the multi-channel\\nautoregressive pre-training contributes to th', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 281: ('on\\ntuning enables NeuroLM to perform various BCI tasks within a single model.\\nThe EEG tokens are added with reused temporal embeddings from the LLM and new spatial embed-\\ndings. As shown in Figure 3, NeuroLM is then trained through multi-channel autoregression, that\\nis, predicting the next EEG tokens based on visible EEG tokens, to endow the model with the capa-\\nbility of learning special patterns of EEG causal relationship. In our experiments, the multi-channel\\nautoregressive pre-training contributes to the performance of multi-task instruction tuning.\\n12ch1\\nch2\\nch3\\nch1\\nch2\\nch3\\nch1\\nch2\\nch3time 1\\ntime 2\\ntime 3ch1\\nch2\\nch1\\nch2\\n[SEP]\\nemotion\\n:\\npositive\\n[END]\\n(a) Stair-stepping maskEEG\\nText\\n(b) Instruction maskAttention Mask\\nch1\\nch2 \\nch3 \\nch1\\nch2 \\nch3 \\nch1\\nch2 \\nch3 \\nFigure 4: The stair-stepping\\nmask. Each row indicates atten-\\ntion masks for an EEG token.Formulation. Consider a sequence of EEG tokens h=\\n{hij|i= 1, ..., C, j = 1, ..., T}where idenotes the channel\\nandjdenote the time, and their corresponding indices of the\\nmerged text and EEG vocabulary I={Iij|i= 1, ..., C, j =\\n1, ..., T}derived from the neural tokenizer. Unlike language\\nthat can be predicted token by token intuitively, EEG signals\\nare of various configurations, thus it is impracticable to directly\\npredict EEG tokens one by one. We propose a multi-channel\\nautoregressive strategy to adopt the idea of autoregression on\\nEEG. The basic idea is that each token of a specific channel\\npredicts the next token of the same channel, which can be for-\\nmulized as\\np(I11, I12, ..., I CT) =TY\\nt=1p(I1n, I2n, ..., I Cn|h11, h12, ..., h C(t−1)). (5)\\nTherefore, the objective for multi-channel autoregressive pre-training is to optimize model parame-\\nters by maximizing p(h1t, h2t, ..., h Ct|h11, h12, ..., h C(t−1))throughout all EEG data.\\nFor implementation, we define stair-stepping masks where each EEG token is able to observe tokens\\nof all channels from its current and previous time step. Figure 4 illustrates the design of our stair-\\nstepping mask. Dark cells indicate that ', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 282: ('(I11, I12, ..., I CT) =TY\\nt=1p(I1n, I2n, ..., I Cn|h11, h12, ..., h C(t−1)). (5)\\nTherefore, the objective for multi-channel autoregressive pre-training is to optimize model parame-\\nters by maximizing p(h1t, h2t, ..., h Ct|h11, h12, ..., h C(t−1))throughout all EEG data.\\nFor implementation, we define stair-stepping masks where each EEG token is able to observe tokens\\nof all channels from its current and previous time step. Figure 4 illustrates the design of our stair-\\nstepping mask. Dark cells indicate that the elements should take part in attention.\\nTheory Analysis. We interpret the multi-channel autoregressive pre-training from the view of a\\nvariational autoencoder (Kingma & Welling, 2014). Let xdenote the original EEG signals, ydenote\\nthe temporal-frequency target of x, and ˆxbe the EEG tokens to be predicted. Assume that EEG\\nsignals xcan be generated by a random process with a latent variable z. We use qϕ(z|xi)to denote\\nthe VQ encoder encoding EEG signals into discrete neural codes, pψ(yi|zi)to stand for the temporal\\nand frequency decoder reconstructing temporal-frequency domain from encoded neural codes, and\\npθ(z|xi)to represent multi-channel autoregressive pre-training. Consider the log-likelihood p(y|x)\\nand its evidence lower bound (ELBO), involving predicting the temporal-frequency domain of the\\nEEG signals from the next time point:\\nNX\\ni=1logp(yi|xi)≥ −NX\\ni=1(Ezi∼qϕ(z|xi)[−logpψ(yi|zi)] +KL(qϕ(z|xi), pθ(z|xi)), (6)\\nwhere the first term is the reconstruction loss and the second term is Kullback-Leibler divergence\\nbetween qand EEG-text conditional prior. Our training paradigm encompasses two-stage learning\\n5\\nPublished as a conference paper at ICLR 2025\\nprocesses: 1) The neural tokenizer is optimized by minimizing the reconstruction loss. 2) A LLM\\nlearns the prior pθby minimizing KL loss with qϕandpψfixed. The sequence zican be sampled\\nfrom qϕ(z|xi)or one-point distribution zi= arg max zqϕ(z|xi)where we choose the latter for\\nsimplicity. In this case, ziis from the codebook Vandzi= [zi,1, ..., z i,T]. Therefor', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 283: ('vergence\\nbetween qand EEG-text conditional prior. Our training paradigm encompasses two-stage learning\\n5\\nPublished as a conference paper at ICLR 2025\\nprocesses: 1) The neural tokenizer is optimized by minimizing the reconstruction loss. 2) A LLM\\nlearns the prior pθby minimizing KL loss with qϕandpψfixed. The sequence zican be sampled\\nfrom qϕ(z|xi)or one-point distribution zi= arg max zqϕ(z|xi)where we choose the latter for\\nsimplicity. In this case, ziis from the codebook Vandzi= [zi,1, ..., z i,T]. Therefore, Equation 6\\ncan be rewritten as\\n−NX\\ni=1(Ezi∼qϕ(z|xi)[−logpψ(yi|zi)]−TX\\nj=2logpθ(zi,j|xi,<j)), (7)\\nwhere the latter term is the negative log-likelihood loss for multi-channel autoregressive pre-training\\nandzi,jdenotes latent variables of all channels at time step j.\\n2.3 M ULTI -TASK INSTRUCTION TUNING\\nIn this stage, we aim to leverage the power of LLMs to integrate different downstream datasets as a\\nwhole. Instruction tuning is introduced to handle various downstream tasks, as shown in Figure 3.\\nIt is worthwhile to mention that in both multi-channel autoregressive pre-training and multi-task\\ninstruction tuning stages, we feed the model a few text data at each iteration to preserve the language\\nmodeling capability of LLMs. We build instructions for each downstream dataset and the instruction\\ndesign can be found in Appendix B. A special token [SEP]is used to concatenate EEG and text\\ninstructions, indicating the modality switch. Notably, the loss is only calculated on the answer part\\nof the text to make the prediction more stable. Suppose xprepresents the EEG tokens along with the\\nquestion part of the instruction (prompt), and tarepresents the answer part of the instruction. Let\\nthe sequence length of tabeL, and this procedure can be written as\\np(ta|xp) =LY\\ni=1p(ta\\ni|xp, ta\\n,<i), (8)\\nwhere ta\\n,<iis the answer tokens before the current prediction token ta\\ni.\\n3 E XPERIMENTS\\n3.1 D OWNSREAM DATASETS\\nWe consider six different EEG datasets with highly varied data sizes to comprehensively evalu-\\nate NeuroLM, where the d', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 284: ('diction more stable. Suppose xprepresents the EEG tokens along with the\\nquestion part of the instruction (prompt), and tarepresents the answer part of the instruction. Let\\nthe sequence length of tabeL, and this procedure can be written as\\np(ta|xp) =LY\\ni=1p(ta\\ni|xp, ta\\n,<i), (8)\\nwhere ta\\n,<iis the answer tokens before the current prediction token ta\\ni.\\n3 E XPERIMENTS\\n3.1 D OWNSREAM DATASETS\\nWe consider six different EEG datasets with highly varied data sizes to comprehensively evalu-\\nate NeuroLM, where the detailed information is listed in Table 1: 1) TUAB (Harati et al., 2015)\\n(abnormal detection): This dataset contains EEG records that are classified as clinically normal or\\nabnormal. 2) TUEV (Harati et al., 2015) (event type classification): This corpus contains six events\\ninvolving periodic lateralized epileptiform discharge, generalized periodic epileptiform discharge,\\nspike and/or sharp wave discharges, artifact, and eye movement. 3) SEED (Zheng & Lu, 2015)\\n(emotion recognition): There are 3 emotions (positive, negative, and neutral) elicited by videos\\nfrom 15 subjects. There are 15 trials in each session and each subject underwent 3 sessions. 4)\\nHMC (Alvarez-Estevez & Rijsman, 2021) (sleep stage classification): HMC was developed for au-\\ntomatic sleep scoring, involving 5 sleep stages (wake, NREM-1, NREM-2, NREM-3, REM) from\\n154 subjects. 5) Workload (Zyma et al., 2019) (cognitive workload classification): This dataset\\ncontains 36 subjects performing serial subtraction. We regard mental workload trials as high work-\\nload and the last 60 seconds of the rest EEG as low workload. 6) TUSL (von Weltin et al., 2017)\\nTable 1: Information of datasets used for downstream evaluation.\\nDataset #Channel Sampling Rate Duration #Sample Task\\nTUAB 23 256 Hz 10 seconds 409,455 Binary classification\\nTUEV 23 256 Hz 5 seconds 112,491 6-class classification\\nSEED 62 1000 Hz 4 seconds 38,475 3-class classification\\nHMC 4 256 Hz 30 seconds 137,243 5-class classification\\nWorkload 19 500 Hz 4 seconds 2,088 Binary classification\\nTUSL 23', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 285: ('high work-\\nload and the last 60 seconds of the rest EEG as low workload. 6) TUSL (von Weltin et al., 2017)\\nTable 1: Information of datasets used for downstream evaluation.\\nDataset #Channel Sampling Rate Duration #Sample Task\\nTUAB 23 256 Hz 10 seconds 409,455 Binary classification\\nTUEV 23 256 Hz 5 seconds 112,491 6-class classification\\nSEED 62 1000 Hz 4 seconds 38,475 3-class classification\\nHMC 4 256 Hz 30 seconds 137,243 5-class classification\\nWorkload 19 500 Hz 4 seconds 2,088 Binary classification\\nTUSL 23 256 Hz 10 seconds 245 3-class classification\\n6\\nPublished as a conference paper at ICLR 2025\\n(slowing event classification): TUSL aims to differentiate between seizure, slowing, and complex\\nbackground events.\\nFor the data division, we split each dataset into training, validation, and test sets: 1) TUAB and\\nTUEV : Since the training and test division is provided by the original datasets, we further divide\\nthe training patients into training and validation groups by 80% and 20% randomly. 2) SEED : We\\nsplit total 15 trials into training, validation, and test trials by 9:3:3 according to the chronological\\norder, and merge all sessions into the final training, validation, and test set. 3) HMC : Subjects from\\nnumber 1 to 100 form the training set while subjects from number 101 to 126 and number 127 to\\n154 are validation and test sets, respectively. 4) Workload : The training, validation, and test sets\\nare derived by subjects from number 0 to 25, number 26 to 30, and number 31 to 35, respectively.\\n5)TUSL : The training, validation, and test sets are splitted by 60%:20%:20%.\\n3.2 E XPERIMENTAL SETUP\\nModel Configurations. NeuroLM is compatible with any causal LLM as its base language model.\\nFor simplicity and saving computing resources, we adopt GPT-2 (Radford et al., 2019) as our\\nbase language model. Accordingly, NeuroLM has three variants, NeuroLM-B, NeuroLM-L, and\\nNeuroLM-XL, which have 254M, 500M, and 1696M parameters (including the parameters of the\\nVQ encoder), respectively. Unless otherwise noted, NeuroLM refers t', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 286: ('ing, validation, and test sets are splitted by 60%:20%:20%.\\n3.2 E XPERIMENTAL SETUP\\nModel Configurations. NeuroLM is compatible with any causal LLM as its base language model.\\nFor simplicity and saving computing resources, we adopt GPT-2 (Radford et al., 2019) as our\\nbase language model. Accordingly, NeuroLM has three variants, NeuroLM-B, NeuroLM-L, and\\nNeuroLM-XL, which have 254M, 500M, and 1696M parameters (including the parameters of the\\nVQ encoder), respectively. Unless otherwise noted, NeuroLM refers to NeuroLM-B. Text embed-\\ndings which are randomly sampled from GPT-2’s vocabulary for each batch, are utilized for EEG-\\ntext alignment. The patch size Pis set to 200 (1 second), consistent with that of LaBraM. To\\nmaintain compatibility with GPT-2, the maximum sequence length (number of patches) is set to\\n1024. For input samples with sequence lengths shorter than 1024, we pad zeros to ensure the length\\nis equal to 1024 at neural tokenizer training and multi-channel autoregressive pre-training stages.\\nThe attention values for these zero paddings will be masked.\\nData Preprocessing. To eliminate environmental and physiological artifacts from EEG signals,\\nwe employ several necessary preprocessing methods. First, we apply a bandpass filter with cutoff\\nfrequencies of 0.1 Hz and 75 Hz. To avoid power-line interference, we use a notch filter at 50\\nHz or 60 Hz, depending on the geographic region of data collection. Additionally, all signals are\\nresampled to 200 Hz to reduce computational complexity. Given that EEG signal values typically\\nrange between -100 µV to 100 µV , all values are divided by 100 for normalization.\\nTraining & Environment Settings. To facilitate the training of NeuroLM, a huge volumn of data\\nis required. About 25,000 hours of EEG data from multiple public EEG datasets are collected after\\ncleaning and filtering, which are listed in Appendix C. All experiments are conducted on eight\\nNVIDIA A100-80G GPUs with Python 3.11.8 and PyTorch 2.2.2 + CUDA 12.1. For instruction\\ntuning, the results are obtained us', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 287: ('al values typically\\nrange between -100 µV to 100 µV , all values are divided by 100 for normalization.\\nTraining & Environment Settings. To facilitate the training of NeuroLM, a huge volumn of data\\nis required. About 25,000 hours of EEG data from multiple public EEG datasets are collected after\\ncleaning and filtering, which are listed in Appendix C. All experiments are conducted on eight\\nNVIDIA A100-80G GPUs with Python 3.11.8 and PyTorch 2.2.2 + CUDA 12.1. For instruction\\ntuning, the results are obtained using the final model after training. Notably, we choose the largest\\nlogits as the prediction at evaluation and test instead of beam search which is widely used in current\\nLLMs to obtain stable results. For other scenarios, the baselines are in a single-task manner and\\ntrained on individual datasets. Their best models are selected based on the best performance on\\nthe validation set, and then evaluated on the test set. The average and standard deviation values\\nare reported using three random seeds to ensure comparable results. Baselines and other detailed\\nhyperparameter settings are provided in Appendix D.\\n3.3 E XPERIMENTAL RESULTS\\nWe present all results in Table 2, 3, and 4. Underlined values represent the best results for single-\\ntask methods, while bold values indicate the best results for NeuroLM. Notably, it’s important to\\nnote that direct comparisons between NeuroLM and the baseline single-task methods are not en-\\ntirely fair, as the baselines are trained and tested on individual datasets. Although NeuroLM is still a\\nfew steps away from the state-of-the-art LaBraM, it achieves performance comparable to most other\\nsingle-task baselines. The key strength of NeuroLM lies in its unified instruction-tuning, which has\\nthe potential to enable generalization to novel tasks or prompts without the need for extensive task-\\nspecific fine-tuning. For NeuroLM-L and NeuroLM-XL, the performance is further enhanced on\\nmost downstream datasets with larger model capacity. However, the imbalance in data size among\\ndifferent dow', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 288: (' is still a\\nfew steps away from the state-of-the-art LaBraM, it achieves performance comparable to most other\\nsingle-task baselines. The key strength of NeuroLM lies in its unified instruction-tuning, which has\\nthe potential to enable generalization to novel tasks or prompts without the need for extensive task-\\nspecific fine-tuning. For NeuroLM-L and NeuroLM-XL, the performance is further enhanced on\\nmost downstream datasets with larger model capacity. However, the imbalance in data size among\\ndifferent downstream datasets poses a challenge for NeuroLM, as it reaches optimal performance at\\ndifferent training times for different datasets. Additionally, we find that models with more parame-\\nters are more prone to overfitting, which might account for the performance degradation observed on\\n7\\nPublished as a conference paper at ICLR 2025\\nTable 2: Results on TUAB and TUEV .\\nMethods Multi-taskTUAB TUEV\\nBalanced Acc. AUC-PR AUROC Balanced Acc. Cohen’s Kappa Weighted F1\\nSPaRCNet % 0.7896 ±0.0018 0.8414 ±0.0018 0.8676 ±0.0012 0.4161 ±0.0262 0.4233 ±0.0181 0.7024 ±0.0104\\nContraWR % 0.7746 ±0.0041 0.8421 ±0.0104 0.8456 ±0.0074 0.4384 ±0.0349 0.3912 ±0.0237 0.6893 ±0.0136\\nCNN-Transformer % 0.7777 ±0.0022 0.8433 ±0.0039 0.8461 ±0.0013 0.4087 ±0.0161 0.3815 ±0.0134 0.6854 ±0.0293\\nFFCL % 0.7848 ±0.0038 0.8448 ±0.0065 0.8569 ±0.0051 0.3979 ±0.0104 0.3732 ±0.0188 0.6783 ±0.0120\\nST-Transformer % 0.7966 ±0.0023 0.8521 ±0.0026 0.8707 ±0.0019 0.3984 ±0.0228 0.3765 ±0.0306 0.6823 ±0.0190\\nBIOT % 0.7959 ±0.0057 0.8792 ±0.0023 0.8815 ±0.0043 0.5281 ±0.0225 0.5273 ±0.0249 0.7492 ±0.0082\\nLaBraM-Base % 0.8140 ±0.0019 0.8965 ±0.0016 0.9022 ±0.0009 0.6409 ±0.0065 0.6637 ±0.0093 0.8312 ±0.0052\\nNeuroLM-B ! 0.7826 ±0.0065 0.6975 ±0.0081 0.7816 ±0.0079 0.4560 ±0.0048 0.4285 ±0.0048 0.7153 ±0.0028\\nNeuroLM-L ! 0.7876 ±0.0034 0.7099 ±0.0034 0.7876 ±0.0034 0.4132 ±0.1235 0.4414 ±0.0996 0.7387 ±0.0400\\nNeuroLM-XL ! 0.7969 ±0.0091 0.7219 ±0.0082 0.7884 ±0.0194 0.4679 ±0.0356 0.4570 ±0.0498 0.7359 ±0.0219\\nTable 3: Results on SEED and HMC.\\nMethods Multi-ta', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 289: ('.0043 0.5281 ±0.0225 0.5273 ±0.0249 0.7492 ±0.0082\\nLaBraM-Base % 0.8140 ±0.0019 0.8965 ±0.0016 0.9022 ±0.0009 0.6409 ±0.0065 0.6637 ±0.0093 0.8312 ±0.0052\\nNeuroLM-B ! 0.7826 ±0.0065 0.6975 ±0.0081 0.7816 ±0.0079 0.4560 ±0.0048 0.4285 ±0.0048 0.7153 ±0.0028\\nNeuroLM-L ! 0.7876 ±0.0034 0.7099 ±0.0034 0.7876 ±0.0034 0.4132 ±0.1235 0.4414 ±0.0996 0.7387 ±0.0400\\nNeuroLM-XL ! 0.7969 ±0.0091 0.7219 ±0.0082 0.7884 ±0.0194 0.4679 ±0.0356 0.4570 ±0.0498 0.7359 ±0.0219\\nTable 3: Results on SEED and HMC.\\nMethods Multi-taskSEED HMC\\nBalanced Acc. Cohen’s Kappa Weighted F1 Balanced Acc. Cohen’s Kappa Weighted F1\\nSPaRCNet % 0.5596 ±0.0244 0.3464 ±0.0372 0.5585 ±0.0297 0.4756 ±0.1109 0.3147 ±0.1315 0.4108 ±0.1310\\nContraWR % 0.6106 ±0.0078 0.4220 ±0.0129 0.6137 ±0.0085 0.4242 ±0.0541 0.2340 ±0.0554 0.2987 ±0.0288\\nCNN-Transformer % 0.6161 ±0.0384 0.4262 ±0.0601 0.6150 ±0.0463 0.6573 ±0.0141 0.5961 ±0.0105 0.6896 ±0.0065\\nFFCL % 0.5808 ±0.0322 0.3732 ±0.0462 0.5743 ±0.0402 0.4427 ±0.0702 0.2542 ±0.0654 0.2902 ±0.0485\\nST-Transformer % 0.5479 ±0.0091 0.3261 ±0.0169 0.5505 ±0.0091 0.2559 ±0.0141 0.0503 ±0.0183 0.1428 ±0.0122\\nBIOT % 0.7097 ±0.0024 0.5682 ±0.0051 0.7134 ±0.0027 0.6862 ±0.0041 0.6295 ±0.0113 0.7091 ±0.0147\\nLaBraM-Base % 0.7318 ±0.0019 0.5994 ±0.0031 0.7354 ±0.0021 0.7286 ±0.0101 0.6812 ±0.0073 0.7554 ±0.0024\\nNeuroLM-B ! 0.5554 ±0.0075 0.3393 ±0.0117 0.5599 ±0.0068 0.6737 ±0.0050 0.6188 ±0.0057 0.7126 ±0.0034\\nNeuroLM-L ! 0.6006 ±0.0047 0.4067 ±0.0063 0.6048 ±0.0050 0.6658 ±0.0550 0.5929 ±0.0715 0.6896 ±0.0504\\nNeuroLM-XL ! 0.6034 ±0.0010 0.4082 ±0.0036 0.6063 ±0.0030 0.5761 ±0.1084 0.4795 ±0.1466 0.5883 ±0.1286\\nTable 4: Results on Workload and TUSL.\\nMethods Multi-taskWorkload TUSL\\nBalanced Acc. AUC-PR AUROC Balanced Acc. Cohen’s Kappa Weighted F1\\nSPaRCNet % 0.5977 ±0.0071 0.6638 ±0.0314 0.6717 ±0.0172 0.4185 ±0.0452 0.1399 ±0.0799 0.3500 ±0.0968\\nContraWR % 0.6966 ±0.0332 0.7668 ±0.0408 0.7685 ±0.0317 0.5857 ±0.0662 0.3567 ±0.0968 0.5458 ±0.0798\\nCNN-Transformer % 0.5793 ±0.0230 0.5306 ±0.0459 0.5663 ±0.0349 0.3575 ±0.0151 0.030', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 290: ('.6034 ±0.0010 0.4082 ±0.0036 0.6063 ±0.0030 0.5761 ±0.1084 0.4795 ±0.1466 0.5883 ±0.1286\\nTable 4: Results on Workload and TUSL.\\nMethods Multi-taskWorkload TUSL\\nBalanced Acc. AUC-PR AUROC Balanced Acc. Cohen’s Kappa Weighted F1\\nSPaRCNet % 0.5977 ±0.0071 0.6638 ±0.0314 0.6717 ±0.0172 0.4185 ±0.0452 0.1399 ±0.0799 0.3500 ±0.0968\\nContraWR % 0.6966 ±0.0332 0.7668 ±0.0408 0.7685 ±0.0317 0.5857 ±0.0662 0.3567 ±0.0968 0.5458 ±0.0798\\nCNN-Transformer % 0.5793 ±0.0230 0.5306 ±0.0459 0.5663 ±0.0349 0.3575 ±0.0151 0.0306 ±0.0179 0.2235 ±0.0251\\nFFCL % 0.7069 ±0.0197 0.7823 ±0.0099 0.7857 ±0.0234 0.3819 ±0.0688 0.0628 ±0.0888 0.2120 ±0.0786\\nST-Transformer % 0.6103 ±0.0056 0.5716 ±0.0071 0.6375 ±0.0078 0.4000 ±0.0329 0.0860 ±0.0449 0.3793 ±0.0459\\nBIOT % 0.6655 ±0.0665 0.7189 ±0.0722 0.7342 ±0.0536 0.5758 ±0.0303 0.2012 ±0.0212 0.2394 ±0.0040\\nLaBraM-Base % 0.6609 ±0.0204 0.7174 ±0.0234 0.7272 ±0.0165 0.7625 ±0.0131 0.6407 ±0.0304 0.7614 ±0.0210\\nNeuroLM-B ! 0.6172 ±0.0113 0.5824 ±0.0080 0.6253 ±0.0160 0.6734 ±0.0436 0.5107 ±0.0617 0.6743 ±0.0394\\nNeuroLM-L ! 0.6311 ±0.0250 0.5869 ±0.0155 0.6247 ±0.0339 0.5314 ±0.0530 0.2961 ±0.0810 0.5243 ±0.0680\\nNeuroLM-XL ! 0.6345 ±0.0442 0.5889 ±0.0423 0.6130 ±0.0764 0.6845 ±0.0304 0.5194 ±0.0461 0.6839 ±0.0297\\nHMC since sleep patterns are of low complexity and smaller models might be sufficient to capture\\nthe relevant features in EEG signals. On TUSL, the model performance appears to be not very stable\\ndue to the extremely limited data samples.\\n3.4 A BLATION ON ROBUSTNESS\\nOur instruction design for some datasets (TUEV , HMC, and TUSL) follows multiple-choice ques-\\ntions. To validate the robustness of NeuroLM, we enumerate the orders of options and randomly\\nselect one from all possible combinations during data fetching of the multi-task instruction tuning\\nstage. Figure 5 illustrates the results on whether shuffling the options. We can conclude that on\\nTUEV and HMC, NeuroLM with shuffle obtains comparable performance compared to those with-\\nout shuffle. Nevertheless, it seems that the shuffle ope', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 291: ('gn for some datasets (TUEV , HMC, and TUSL) follows multiple-choice ques-\\ntions. To validate the robustness of NeuroLM, we enumerate the orders of options and randomly\\nselect one from all possible combinations during data fetching of the multi-task instruction tuning\\nstage. Figure 5 illustrates the results on whether shuffling the options. We can conclude that on\\nTUEV and HMC, NeuroLM with shuffle obtains comparable performance compared to those with-\\nout shuffle. Nevertheless, it seems that the shuffle operation significantly degrades the performance\\non TUSL. We attribute this phenomenon to the lack of data for TUSL because TUSL has much\\nfewer number of data samples compared to the other two datasets. It is expected that NeuroLM\\nwill achieve similar results if given more data. In general, NeuroLM has good robustness against\\narbitrary order of options, which indicates that NeuroLM does understand the linguistic meaning of\\nthe questions when predicting.\\n8\\nPublished as a conference paper at ICLR 2025\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000028/uni00000039\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni0000005a/uni00000012/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni00000025/uni00000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 292: ('00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000028/uni00000039\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni0000005a/uni00000012/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000002b/uni00000030/uni00000026\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni0000005a/uni00000012/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/u', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 293: ('0044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000036/uni0000002f\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\n/uni0000005a/uni00000012/uni00000003/uni00000056/uni0000004b/uni00000058/uni00000049/uni00000049/uni0000004f/uni00000048\\nFigure 5: Ablation study on whether shuffling the options of instructions.\\n3.5 A BLATION ON INSTRUCTION DATA SIZE\\nWe utilize TUAB, TUEV , and HMC datasets to scale the instruction data size and validate the per-\\nformance of NeuroLM and other baseline methods, as these three datasets have a relatively large\\nnumber of samples. The results, illustrated in Figure 6, show that NeuroLM demonstrates consistent\\nperformance under all conditions. For TUAB, NeuroLM, LaBraM, and CNN-Transformer exhibit\\nstable performance. For TUEV and HMC, only NeuroLM and LaBraM are relatively unaffected by\\nchanges in data size. These findings indicate that NeuroLM is robust and maintains high perfor-\\nmance even with varying instruction data sizes, highlighting its effectiveness in multi-task learning\\nscenarios.\\nFigure 6: Comparison of different methods under different proportions of instruction data.\\n3.6 V ISUALIZATION CURVES OF MULTI -CHANNEL AUTOREGRESSION\\nWe visualize the pre-training loss, accuracy, and validation perplexity of NeuroLM in Figure 7.\\nWe observe that the loss stably conve', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 294: ('ively unaffected by\\nchanges in data size. These findings indicate that NeuroLM is robust and maintains high perfor-\\nmance even with varying instruction data sizes, highlighting its effectiveness in multi-task learning\\nscenarios.\\nFigure 6: Comparison of different methods under different proportions of instruction data.\\n3.6 V ISUALIZATION CURVES OF MULTI -CHANNEL AUTOREGRESSION\\nWe visualize the pre-training loss, accuracy, and validation perplexity of NeuroLM in Figure 7.\\nWe observe that the loss stably converges while the validation perplexity decreases with training,\\nwhich means NeuroLM can generalize well to unseen EEG data. Intuitively, a larger model with\\nmore parameters obtains smaller loss and perplexity. Additionally, NeuroLM-L achieves similar\\n9\\nPublished as a conference paper at ICLR 2025\\nvalidation perplexity with NeuroLM-XL, indicating that current pre-training data size still cannot\\nsatisfy the training with billion-level parameters.\\n/uni00000013 /uni00000015/uni00000013/uni0000004e /uni00000017/uni00000013/uni0000004e /uni00000019/uni00000013/uni0000004e /uni0000001b/uni00000013/uni0000004e\\n/uni00000033/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000017/uni00000019/uni0000001b/uni00000014/uni00000013/uni00000014/uni00000015/uni00000033/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000025\\n/uni0000002f\\n/uni0000003b/uni0000002f\\n/uni00000013 /uni00000015/uni00000013/uni0000004e /uni00000017/uni00000013/uni0000004e /uni00000019/uni00000013/uni0000004e /uni0000001b/uni00000013/uni0000004e\\n/uni00000033/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni0000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 295: ('0057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000002f/uni00000052/uni00000056/uni00000056/uni00000025\\n/uni0000002f\\n/uni0000003b/uni0000002f\\n/uni00000013 /uni00000015/uni00000013/uni0000004e /uni00000017/uni00000013/uni0000004e /uni00000019/uni00000013/uni0000004e /uni0000001b/uni00000013/uni0000004e\\n/uni00000033/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni0000004c/uni00000057/uni00000048/uni00000055/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000018/uni00000013/uni00000011/uni00000014/uni00000013/uni00000013/uni00000011/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni00000013/uni00000013/uni00000011/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000013/uni00000033/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a/uni00000003/uni00000044/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c/uni00000025\\n/uni0000002f\\n/uni0000003b/uni0000002f\\n/uni00000018 /uni00000014/uni00000013 /uni00000014/uni00000018 /uni00000015/uni00000013\\n/uni00000028/uni00000053/uni00000052/uni00000046/uni0000004b/uni00000056/uni00000013/uni00000015/uni00000013/uni00000013/uni00000017/uni00000013/uni00000013/uni00000019/uni00000013/uni00000013/uni0000001b/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000039/uni00000044/uni0000004f/uni0000004c/uni00000047/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000053/uni00000048/uni00000055/uni00000053/uni0000004f/uni00000048/uni0000005b/uni0000004c/uni00000057/uni0000005c\\n/uni00000025\\n/uni0000002f\\n/uni0000003b/uni0000002f\\nFigure 7: The training and validation visualization of multi-channel autoregressive pre-training.\\n3.7 A B', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 296: ('0000013/uni00000013/uni0000001b/uni00000013/uni00000013/uni00000014/uni00000013/uni00000013/uni00000013/uni00000039/uni00000044/uni0000004f/uni0000004c/uni00000047/uni00000044/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000003/uni00000053/uni00000048/uni00000055/uni00000053/uni0000004f/uni00000048/uni0000005b/uni0000004c/uni00000057/uni0000005c\\n/uni00000025\\n/uni0000002f\\n/uni0000003b/uni0000002f\\nFigure 7: The training and validation visualization of multi-channel autoregressive pre-training.\\n3.7 A BLATION ON MULTI -CHANNEL AUTOREGRESSIVE PRE-TRAINING\\nThe proposed multi-channel autoregressive pre-training aims at mimicing current causal LLMs by\\npredicting the next EEG tokens for each channel. It is expected to benefit downstream tasks through\\nlearning causal representations. We perform an ablation study to assess the impact of the proposed\\nmulti-channel autoregressive pre-training on NeuroLM. The results, shown in Figure 8, reveal a sig-\\nnificant performance improvement when NeuroLM is pre-trained with this approach, underscoring\\nthe effectiveness of multi-channel autoregressive pre-training.\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000024/uni00000038/uni00000026/uni00000010/uni00000033/uni00000035 /uni00000024/uni00000038/uni00000035/uni00000032/uni00000026/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000024/uni00000025\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/un', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 297: ('013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000024/uni00000025\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000028/uni00000039\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni0000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 298: ('ni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000036/uni00000028/uni00000028/uni00000027\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000002b/uni00000030/uni00000026\\n/uni0000005a/', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 299: ('00048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000002b/uni00000030/uni00000026\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000024/uni00000038/uni00000026/uni00000010/uni00000033/uni00000035 /uni00000024/uni00000038/uni00000035/uni00000032/uni00000026/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000003a/uni00000052/uni00000055/uni0000004e/uni0000004f/uni00000052/uni00000044/uni00000047\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 300: ('/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000036/uni0000002f\\n/uni0000005a/uni00000012/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\n/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000053/uni00000055/uni00000048/uni00000010/uni00000057/uni00000055/uni00000044/uni0000004c/uni00000051/uni0000004c/uni00000051/uni0000004a\\nFigure 8: Ablation study on multi-channel autoregressive pre-training.\\n4 C ONCLUSION\\nIn this paper, we introduce NeuroLM, the first universal multi-task foundation model for EEG sig-\\nnal processing. By integrating EEG signals into a Large Language Model framework, NeuroLM\\nleverages advanced text-aligned neural tokenizer embeddings, large-scale multi-channel autoregres-\\nsive pre-training, and joint multi-task tuning to address the inherent challenges of EEG-based BCI\\nand healthcare tasks. Our extensive experiments across six diverse EEG datasets de', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 301: (' autoregressive pre-training.\\n4 C ONCLUSION\\nIn this paper, we introduce NeuroLM, the first universal multi-task foundation model for EEG sig-\\nnal processing. By integrating EEG signals into a Large Language Model framework, NeuroLM\\nleverages advanced text-aligned neural tokenizer embeddings, large-scale multi-channel autoregres-\\nsive pre-training, and joint multi-task tuning to address the inherent challenges of EEG-based BCI\\nand healthcare tasks. Our extensive experiments across six diverse EEG datasets demonstrate the\\nmodel’s superior performance in multi-task learning and inference. Overall, NeuroLM represents\\na significant step forward in the field of brain-computer interfaces and healthcare domains, show-\\ncasing the great potential of LLMs to revolutionize EEG signal processing and multi-task learning.\\nWe believe that NeuroLM will pave the way for more sophisticated and versatile EEG applications,\\nultimately enhancing the interaction between humans and machines.\\n10\\nPublished as a conference paper at ICLR 2025\\nREFERENCES\\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Ale-\\nman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4 technical\\nreport. arXiv preprint arXiv:2303.08774 , 2023.\\nTurkey N Alotaiby, Saleh A Alshebeili, Tariq Alshawi, Ishtiaq Ahmad, and Fathi E Abd El-Samie.\\nEEG seizure detection and prediction algorithms: a survey. EURASIP Journal on Advances in\\nSignal Processing , 2014:1–21, 2014.\\nDiego Alvarez-Estevez and Roselyne M Rijsman. Inter-database validation of a deep learning ap-\\nproach for automatic sleep scoring. PloS one , 16(8):e0256111, 2021.\\nBenjamin Blankertz, Guido Dornhege, Matthias Krauledat, Klaus-Robert M ¨uller, and Gabriel Curio.\\nThe non-invasive berlin brain–computer interface: fast acquisition of effective performance in\\nuntrained subjects. NeuroImage , 37(2):539–550, 2007.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Aman', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 302: ('an. Inter-database validation of a deep learning ap-\\nproach for automatic sleep scoring. PloS one , 16(8):e0256111, 2021.\\nBenjamin Blankertz, Guido Dornhege, Matthias Krauledat, Klaus-Robert M ¨uller, and Gabriel Curio.\\nThe non-invasive berlin brain–computer interface: fast acquisition of effective performance in\\nuntrained subjects. NeuroImage , 37(2):539–550, 2007.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems , 33:1877–1901, 2020.\\nZhe Chen, Weiyun Wang, Hao Tian, Shenglong Ye, Zhangwei Gao, Erfei Cui, Wenwen Tong,\\nKongzhi Hu, Jiapeng Luo, Zheng Ma, et al. How far are we to gpt-4v? closing the gap to\\ncommercial multimodal models with open-source suites. arXiv preprint arXiv:2404.16821 , 2024.\\nPaolo Detti, Giampaolo Vatti, and Garazi Zabalo Manrique de Lara. Eeg synchronization analysis\\nfor seizure prediction: A study on data of noninvasive recordings. Processes , 8(7):846, 2020.\\nAbhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle, Aiesha\\nLetman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd of models.\\narXiv preprint arXiv:2407.21783 , 2024.\\nYaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo Larochelle, Franc ¸ois\\nLaviolette, Mario March, and Victor Lempitsky. Domain-adversarial training of neural net-\\nworks. Journal of Machine Learning Research , 17(59):1–35, 2016. URL http://jmlr.\\norg/papers/v17/15-239.html .\\nZhongke Gao, Xinmin Wang, Yuxuan Yang, Chaoxu Mu, Qing Cai, Weidong Dang, and Siyang\\nZuo. EEG-based spatio–temporal convolutional neural network for driver fatigue evaluation.\\nIEEE Transactions on Neural Networks and Learning Systems , 30(9):2755–2763, 2019.\\nA. Harati, M. Golmohammadi, S. Lopez, I. Obeid, and J. Picone. Improved EEG event classification\\nusing differential energy. In 2015 IEEE Signal Processing in Medicine and Biolo', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 303: (' Research , 17(59):1–35, 2016. URL http://jmlr.\\norg/papers/v17/15-239.html .\\nZhongke Gao, Xinmin Wang, Yuxuan Yang, Chaoxu Mu, Qing Cai, Weidong Dang, and Siyang\\nZuo. EEG-based spatio–temporal convolutional neural network for driver fatigue evaluation.\\nIEEE Transactions on Neural Networks and Learning Systems , 30(9):2755–2763, 2019.\\nA. Harati, M. Golmohammadi, S. Lopez, I. Obeid, and J. Picone. Improved EEG event classification\\nusing differential energy. In 2015 IEEE Signal Processing in Medicine and Biology Symposium\\n(SPMB) , pp. 1–4, 2015. doi: 10.1109/SPMB.2015.7405421.\\nRobert Jenke, Angelika Peer, and Martin Buss. Feature Extraction and Selection for Emotion\\nRecognition from EEG. IEEE Transactions on Affective Computing , 5(3):327–339, 2014. doi:\\n10.1109/TAFFC.2014.2339834.\\nWei-Bang Jiang, Li-Ming Zhao, Ping Guo, and Bao-Liang Lu. Discriminating Surprise and Anger\\nfrom EEG and Eye Movements with a Graph Network. In 2021 IEEE International Conference\\non Bioinformatics and Biomedicine (BIBM) , pp. 1353–1357, 2021. doi: 10.1109/BIBM52615.\\n2021.9669637.\\nWei-Bang Jiang, Xuan-Hao Liu, Wei-Long Zheng, and Bao-Liang Lu. Multimodal Adaptive Emo-\\ntion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels. In\\nProceedings of the 31st ACM International Conference on Multimedia , MM ’23, pp. 5975–5984,\\nNew York, NY , USA, 2023. Association for Computing Machinery. ISBN 9798400701085. doi:\\n10.1145/3581783.3613797. URL https://doi.org/10.1145/3581783.3613797 .\\nWei-Bang Jiang, Li-Ming Zhao, and Bao-Liang Lu. Large brain model for learning generic represen-\\ntations with tremendous EEG data in BCI. In The Twelfth International Conference on Learning\\nRepresentations , 2024. URL https://openreview.net/forum?id=QzTpTRVtrP .\\n11\\nPublished as a conference paper at ICLR 2025\\nJin Jing, Wendong Ge, Shenda Hong, Marta Bento Fernandes, Zhen Lin, Chaoqi Yang, Sungtae An,\\nAaron F Struck, Aline Herlopian, Ioannis Karakis, et al. Development of expert-level classifica-\\ntion of seizures and rhythmic and periodic ', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 304: ('d Bao-Liang Lu. Large brain model for learning generic represen-\\ntations with tremendous EEG data in BCI. In The Twelfth International Conference on Learning\\nRepresentations , 2024. URL https://openreview.net/forum?id=QzTpTRVtrP .\\n11\\nPublished as a conference paper at ICLR 2025\\nJin Jing, Wendong Ge, Shenda Hong, Marta Bento Fernandes, Zhen Lin, Chaoqi Yang, Sungtae An,\\nAaron F Struck, Aline Herlopian, Ioannis Karakis, et al. Development of expert-level classifica-\\ntion of seizures and rhythmic and periodic patterns during eeg interpretation. Neurology , 100(17):\\ne1750–e1762, 2023.\\nDiederik P. Kingma and Max Welling. Auto-Encoding Variational Bayes. In 2nd International\\nConference on Learning Representations, ICLR 2014, Banff, AB, Canada, April 14-16, 2014,\\nConference Track Proceedings , 2014.\\nLouis Korczowski, Martine Cederhout, Anton Andreev, Gr ´egoire Cattan, Pedro Luiz Coelho Ro-\\ndrigues, Violette Gautheret, and Marco Congedo. Brain Invaders calibration-less P300-based\\nBCI with modulation of flash duration Dataset (bi2015a). Research report, GIPSA-lab, July 2019.\\nURLhttps://hal.science/hal-02172347 .\\nDemetres Kostas, Stephane Aroca-Ouellette, and Frank Rudzicz. Bendr: using transformers and a\\ncontrastive self-supervised learning task to learn from massive amounts of eeg data. Frontiers in\\nHuman Neuroscience , 15:653659, 2021.\\nHongli Li, Man Ding, Ronghua Zhang, and Chunbo Xiu. Motor imagery EEG classification algo-\\nrithm based on CNN-LSTM feature fusion network. Biomedical signal processing and control ,\\n72:103342, 2022.\\nRui Li, Le-Dian Liu, and Bao-Liang Lu. Discrimination of Decision Confidence Levels from EEG\\nSignals. In 2021 10th International IEEE/EMBS Conference on Neural Engineering (NER) , pp.\\n946–949, 2021. doi: 10.1109/NER49283.2021.9441086.\\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. In\\nThirty-seventh Conference on Neural Information Processing Systems , 2023. URL https:\\n//openreview.net/forum?id=w0H2xGHlkw .\\nWei Liu, Jie-Lin Qiu, Wei-Long Zheng, and Bao-Lian', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 305: (':103342, 2022.\\nRui Li, Le-Dian Liu, and Bao-Liang Lu. Discrimination of Decision Confidence Levels from EEG\\nSignals. In 2021 10th International IEEE/EMBS Conference on Neural Engineering (NER) , pp.\\n946–949, 2021. doi: 10.1109/NER49283.2021.9441086.\\nHaotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee. Visual instruction tuning. In\\nThirty-seventh Conference on Neural Information Processing Systems , 2023. URL https:\\n//openreview.net/forum?id=w0H2xGHlkw .\\nWei Liu, Jie-Lin Qiu, Wei-Long Zheng, and Bao-Liang Lu. Comparing recognition performance\\nand robustness of multimodal deep learning models for multimodal emotion recognition. IEEE\\nTransactions on Cognitive and Developmental Systems , 2021.\\nWei Liu, Wei-Long Zheng, Ziyi Li, Si-Yuan Wu, Lu Gan, and Bao-Liang Lu. Identifying similarities\\nand differences in emotion recognition with eeg and eye movements among chinese, german, and\\nfrench people. Journal of Neural Engineering , 19(2):026012, 2022.\\nMatthew D Luciw, Ewa Jarocka, and Benoni B Edin. Multi-channel EEG recordings during 3,936\\ngrasp and lift trials with varying weight and friction. Scientific Data , 1(1):1–11, 2014.\\nShuai Luo, Yu-Ting Lan, Dan Peng, Ziyi Li, Wei-Long Zheng, and Bao-Liang Lu. Multimodal\\nemotion recognition in response to oil paintings. In 2022 44th Annual International Conference\\nof the IEEE Engineering in Medicine & Biology Society (EMBC) , pp. 4167–4170, 2022. doi:\\n10.1109/EMBC48229.2022.9871630.\\nPerrin Margaux, Maby Emmanuel, Daligault S ´ebastien, Bertrand Olivier, and Mattout J ´er´emie. Ob-\\njective and subjective evaluation of online error correction during p300-based spelling. Advances\\nin Human-Computer Interaction , 2012:4–4, 2012.\\nIyad Obeid and Joseph Picone. The temple university hospital eeg data corpus. Frontiers in neuro-\\nscience , 10:195498, 2016.\\nWei Yan Peh, Yuanyuan Yao, and Justin Dauwels. Transformer Convolutional Neural Networks\\nfor Automated Artifact Detection in Scalp EEG. In 2022 44th Annual International Conference\\nof the IEEE Engineering in Medicine & Biology Soci', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 306: ('emie. Ob-\\njective and subjective evaluation of online error correction during p300-based spelling. Advances\\nin Human-Computer Interaction , 2012:4–4, 2012.\\nIyad Obeid and Joseph Picone. The temple university hospital eeg data corpus. Frontiers in neuro-\\nscience , 10:195498, 2016.\\nWei Yan Peh, Yuanyuan Yao, and Justin Dauwels. Transformer Convolutional Neural Networks\\nfor Automated Artifact Detection in Scalp EEG. In 2022 44th Annual International Conference\\nof the IEEE Engineering in Medicine & Biology Society (EMBC) , pp. 3599–3602, 2022. doi:\\n10.1109/EMBC48229.2022.9871916.\\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language\\nmodels are unsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\\n12\\nPublished as a conference paper at ICLR 2025\\nAlec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal,\\nGirish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al. Learning transferable visual\\nmodels from natural language supervision. In International conference on machine learning , pp.\\n8748–8763. PMLR, 2021.\\nArman Savran, Koray Ciftci, Guillame Chanel, Javier Cruz Mota, Luong Hong Viet, B ¨ulent Sankur,\\nLale Akarun, Alice Caplier, and Michele Rombaut. Emotion detection in the loop from brain\\nsignals and facial images. In eINTERFACE’06-SIMILAR NoE Summer Workshop on Multimodal\\nInterfaces , 2006.\\nGerwin Schalk, Dennis J McFarland, Thilo Hinterberger, Niels Birbaumer, and Jonathan R Wol-\\npaw. BCI2000: a general-purpose brain-computer interface (BCI) system. IEEE Transactions on\\nBiomedical Engineering , 51(6):1034–1043, 2004.\\nYonghao Song, Xueyu Jia, Lie Yang, and Longhan Xie. Transformer-based spatial-temporal feature\\nlearning for EEG decoding. arXiv preprint arXiv:2106.11170 , 2021.\\nAkara Supratak, Hao Dong, Chao Wu, and Yike Guo. DeepSleepNet: A Model for Automatic Sleep\\nStage Scoring Based on Raw Single-Channel EEG. IEEE Transactions on Neural Systems and\\nRehabilitation Engineering , 25(11):1998–2008, 2017. doi: 10.1109/TNSRE.2017.2721', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 307: ('terface (BCI) system. IEEE Transactions on\\nBiomedical Engineering , 51(6):1034–1043, 2004.\\nYonghao Song, Xueyu Jia, Lie Yang, and Longhan Xie. Transformer-based spatial-temporal feature\\nlearning for EEG decoding. arXiv preprint arXiv:2106.11170 , 2021.\\nAkara Supratak, Hao Dong, Chao Wu, and Yike Guo. DeepSleepNet: A Model for Automatic Sleep\\nStage Scoring Based on Raw Single-Channel EEG. IEEE Transactions on Neural Systems and\\nRehabilitation Engineering , 25(11):1998–2008, 2017. doi: 10.1109/TNSRE.2017.2721116.\\nYousef Rezaei Tabar and Ugur Halici. A novel deep learning approach for classification of EEG\\nmotor imagery signals. Journal of Neural Engineering , 14(1):016003, 2016.\\nLe-Yan Tao and Bao-Liang Lu. Emotion Recognition under Sleep Deprivation Using a Multimodal\\nResidual LSTM Network. In 2020 International Joint Conference on Neural Networks (IJCNN) ,\\npp. 1–8, 2020. doi: 10.1109/IJCNN48605.2020.9206957.\\nMastaneh Torkamani-Azar, Sumeyra Demir Kanik, Serap Aydin, and Mujdat Cetin. Prediction of\\nreaction time and vigilance variability from spatio-spectral features of resting-state EEG in a long\\nsustained attention task. IEEE Journal of Biomedical and Health Informatics , 24(9):2550–2558,\\n2020.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\\ntion and fine-tuned chat models. arXiv preprint arXiv:2307.09288 , 2023.\\nLogan Trujillo. Raw EEG Data. 2020. doi: 10.18738/T8/SS2NHB. URL https://doi.org/\\n10.18738/T8/SS2NHB .\\nLogan T Trujillo, Candice T Stanfield, and Ruben D Vela. The effect of electroencephalogram\\n(EEG) reference choice on information-theoretic measures of the complexity and integration of\\nEEG signals. Frontiers in Neuroscience , 11:425, 2017.\\nAaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in\\nNeural Information Processing Systems , 30, 2017.\\nLaurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 308: ('URL https://doi.org/\\n10.18738/T8/SS2NHB .\\nLogan T Trujillo, Candice T Stanfield, and Ruben D Vela. The effect of electroencephalogram\\n(EEG) reference choice on information-theoretic measures of the complexity and integration of\\nEEG signals. Frontiers in Neuroscience , 11:425, 2017.\\nAaron Van Den Oord, Oriol Vinyals, et al. Neural discrete representation learning. Advances in\\nNeural Information Processing Systems , 30, 2017.\\nLaurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-sne. Journal of Machine\\nLearning Research , 9(11), 2008.\\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\\nŁ ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In I. Guyon, U. V on\\nLuxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett (eds.), Ad-\\nvances in Neural Information Processing Systems , volume 30. Curran Associates, Inc.,\\n2017. URL https://proceedings.neurips.cc/paper_files/paper/2017/\\nfile/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf .\\nEva von Weltin, Tameem Ahsan, Vinit Shah, Dawer Jamshed, Meysam Golmohammadi, Iyad Obeid,\\nand Joseph Picone. Electroencephalographic slowing: A primary source of error in automatic\\nseizure detection. In 2017 IEEE Signal Processing in Medicine and Biology Symposium (SPMB) ,\\npp. 1–5. IEEE, 2017.\\n13\\nPublished as a conference paper at ICLR 2025\\nWeihan Wang, Qingsong Lv, Wenmeng Yu, Wenyi Hong, Ji Qi, Yan Wang, Junhui Ji, Zhuoyi Yang,\\nLei Zhao, Xixuan Song, et al. Cogvlm: Visual expert for pretrained language models. arXiv\\npreprint arXiv:2311.03079 , 2023.\\nChaoqi Yang, M Brandon Westover, and Jimeng Sun. BIOT: Biosignal transformer for cross-data\\nlearning in the wild. In Thirty-seventh Conference on Neural Information Processing Systems ,\\n2023a. URL https://openreview.net/forum?id=c2LZyTyddi .\\nChaoqi Yang, Cao Xiao, M Brandon Westover, Jimeng Sun, et al. Self-supervised electroencephalo-\\ngram representation learning for automatic sleep staging: model development and evaluation\\nstudy. JMIR AI , 2(1):e46769, 2023b.\\nKe Yi, Y', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 309: ('Xiv\\npreprint arXiv:2311.03079 , 2023.\\nChaoqi Yang, M Brandon Westover, and Jimeng Sun. BIOT: Biosignal transformer for cross-data\\nlearning in the wild. In Thirty-seventh Conference on Neural Information Processing Systems ,\\n2023a. URL https://openreview.net/forum?id=c2LZyTyddi .\\nChaoqi Yang, Cao Xiao, M Brandon Westover, Jimeng Sun, et al. Self-supervised electroencephalo-\\ngram representation learning for automatic sleep staging: model development and evaluation\\nstudy. JMIR AI , 2(1):e46769, 2023b.\\nKe Yi, Yansen Wang, Kan Ren, and Dongsheng Li. Learning topology-agnostic EEG representations\\nwith geometry-aware modeling. In Thirty-seventh Conference on Neural Information Processing\\nSystems , 2023. URL https://openreview.net/forum?id=hiOUySN0ub .\\nDaoze Zhang, Zhizhang Yuan, Yang Yang, Junru Chen, Jingjing Wang, and Yafeng Li. Brant: Foun-\\ndation model for intracranial neural signal. In Thirty-seventh Conference on Neural Information\\nProcessing Systems , 2023. URL https://openreview.net/forum?id=DDkl9vaJyE .\\nW. Zheng, W. Liu, Y . Lu, B. Lu, and A. Cichocki. Emotionmeter: A multimodal framework for\\nrecognizing human emotions. IEEE Transactions on Cybernetics , pp. 1–13, 2018. ISSN 2168-\\n2267. doi: 10.1109/TCYB.2018.2797176.\\nWei-Long Zheng and Bao-Liang Lu. Investigating critical frequency bands and channels for EEG-\\nbased emotion recognition with deep neural networks. IEEE Transactions on Autonomous Mental\\nDevelopment , 7(3):162–175, 2015. doi: 10.1109/TAMD.2015.2431497.\\nDeyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny. Minigpt-4: En-\\nhancing vision-language understanding with advanced large language models. arXiv preprint\\narXiv:2304.10592 , 2023.\\nIgor Zyma, Sergii Tukaev, Ivan Seleznov, Ken Kiyono, Anton Popov, Mariia Chernykh, and Oleksii\\nShpenkov. Electroencephalograms during mental arithmetic task performance. Data , 4(1):14,\\n2019.\\n14\\nPublished as a conference paper at ICLR 2025\\nA R ELATED WORK\\nLarge-scale Pre-training for Neural Signals. With the success of self-supervised learning in com-\\nput', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 310: (', and Mohamed Elhoseiny. Minigpt-4: En-\\nhancing vision-language understanding with advanced large language models. arXiv preprint\\narXiv:2304.10592 , 2023.\\nIgor Zyma, Sergii Tukaev, Ivan Seleznov, Ken Kiyono, Anton Popov, Mariia Chernykh, and Oleksii\\nShpenkov. Electroencephalograms during mental arithmetic task performance. Data , 4(1):14,\\n2019.\\n14\\nPublished as a conference paper at ICLR 2025\\nA R ELATED WORK\\nLarge-scale Pre-training for Neural Signals. With the success of self-supervised learning in com-\\nputer vision and natural language processing, several studies have emerged to learn effective EEG\\nrepresentations. Kostas et al. (2021) first propose BENDER, which adapts contrastive learning to\\nderive compressed representations from massive EEG datasets. MMM (Yi et al., 2023) introduces\\na pre-training framework with multi-dimensional position encoding, multi-level channel hierarchy,\\nand a multi-stage pre-training strategy to learn topology-agnostic representations. BIOT (Yang et al.,\\n2023a) tokenizes diverse biosignals into unified segments, enabling cross-data learning despite mis-\\nmatched channels, variable lengths, and missing values. Brant (Zhang et al., 2023) pre-trains on\\na large corpus of private intracranial EEG data, capturing long-term dependencies, spatial correla-\\ntions, and both time and frequency domains. Following BIOT, LaBraM (Jiang et al., 2024) further\\nleverages large-scale 2,500 hours public EEG data, and innovatively introduces a neural tokenizer\\nthat encodes continuous EEG signals into discrete codes for masked EEG modeling, thus obtain-\\ning a considerable improvement. Unfortunately, all these methods require fine-tuning for specific\\ndownstream tasks and cannot perform multi-task learning and inference.\\nMultimodal Large Language Models. Recent years have seen remarkable achievements of LLMs.\\nIn light of the complementarity between language and other modalities, Multimodal Large Lan-\\nguage Models have been a rising hotspot. The release of GPT-4 (Achiam et al., 2023) shows the\\nextraordinary mul', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 311: ('rete codes for masked EEG modeling, thus obtain-\\ning a considerable improvement. Unfortunately, all these methods require fine-tuning for specific\\ndownstream tasks and cannot perform multi-task learning and inference.\\nMultimodal Large Language Models. Recent years have seen remarkable achievements of LLMs.\\nIn light of the complementarity between language and other modalities, Multimodal Large Lan-\\nguage Models have been a rising hotspot. The release of GPT-4 (Achiam et al., 2023) shows the\\nextraordinary multimodal understanding and generation abilities, thus leading to a research frenzy\\nover MLLMs. LLaV A (Liu et al., 2023) connects a vision encoder and an LLM, introducing the idea\\nof visual instruction tuning for general-purpose visual and language understanding. Similarly, Zhu\\net al. (2023) propose MiniGPT-4, which aligns a frozen visual encoder with a frozen advanced LLM,\\npresenting numerous advanced multi-modal abilities. Different from the above MLLMs, CogVLM\\n(Wang et al., 2023) bridges the gap between the frozen pre-trained LLM and visual encoder by a\\ntrainable visual expert in the attention and FFN layers. Chen et al. (2024) present InternVL-1.5,\\nclosing the capability gap between open-source and proprietary commercial MLLMs by utilizing a\\nstrong vision encoder, dynamic high-resolution, and high-quality bilingual dataset.\\nB I NSTRUCTION DESIGN\\nTable 5: Information of instruction design for downstream datasets.\\nDataset Instruction Description\\nTUAB [SEP]Question: Is this EEG segment abnormal? Answer: {Yes, No }[END]\\nTUEV[SEP]Question: Which event type does this EEG segment belong to? Options: (A)\\nspike and slow wave. (B) generalized periodic epileptiform discharge. (C) periodic\\nlateralized epileptiform discharge. (D) eye movement. (E) artifact. (F) background.\\nAnswer: {(A), (B), (C), (D), (E), (F) }[END]\\nSEED[SEP]Question: Which emotion type does this EEG segment belong to? Answer:\\n{Positive, Neutral, Negative }[END]\\nHMC[SEP]Question: Which sleep type does this EEG segment belong to? Options: (A)\\nWake. (B) N', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 312: (' No }[END]\\nTUEV[SEP]Question: Which event type does this EEG segment belong to? Options: (A)\\nspike and slow wave. (B) generalized periodic epileptiform discharge. (C) periodic\\nlateralized epileptiform discharge. (D) eye movement. (E) artifact. (F) background.\\nAnswer: {(A), (B), (C), (D), (E), (F) }[END]\\nSEED[SEP]Question: Which emotion type does this EEG segment belong to? Answer:\\n{Positive, Neutral, Negative }[END]\\nHMC[SEP]Question: Which sleep type does this EEG segment belong to? Options: (A)\\nWake. (B) NREM-1. (C) NREM-2. (D) NREM-3. (E) REM. Answer: {(A), (B), (C),\\n(D), (E) }[END]\\nWorkload [SEP]Question: Is this EEG segment of high workload? Answer: {Yes, No }[END]\\nTUSL[SEP]Question: Which type does this EEG segment belong to? Options: (A)\\nbackground. (B) seizure. (C) slowing. Answer: {(A), (B), (C) }[END]\\nC P RE-TRAINING DATASET DESCRIPTION\\nWe utilize multiple EEG datasets with various configurations. The detail information of all the\\ndatasets are listed in 6. The total time after data cleaning is close to 25,000 hours.\\n15\\nPublished as a conference paper at ICLR 2025\\nTable 6: Information of datasets used for pre-training.\\nDataset #ChannelRate\\n(Hz)Time\\n(h)Description\\nTUEG (Obeid &\\nPicone, 2016)17-23250-\\n1024∼24,000A corpus of 26,846 clinical EEG\\nrecordings collected at Temple University\\nHospital.\\nSEED Series (Zheng\\net al., 2018; Liu\\net al., 2021; 2022)62 1000 170.54These datasets including SEED-IV (15\\nsubjects), SEED-V (20 subjects),\\nSEED-GER (8 subjects), and SEED-FRA\\n(8 subjects) in response to emotional\\nvideos.\\nBCI Competition\\nIV-1 (Blankertz\\net al., 2007)59 1000 8.21A motor imagery dataset containing 2\\nclasses of left hand, right hand, foot (+\\nidle state) for 7 subjects.\\nEmobrain (Savran\\net al., 2006)64 1024 4.94A multimodal emotion dataset including\\n16 subjects. The emotions were elicited\\nthrough a selected subset of the IAPS\\ndataset.\\nGrasp and Lift\\n(Luciw et al., 2014)32 500 11.72A dataset containing 12 subjects\\nperforming grasp-and-lift (GAL) trials.\\nInria BCI (Margaux\\net al., 2012)56 600 29.98A P300-b', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 313: ('videos.\\nBCI Competition\\nIV-1 (Blankertz\\net al., 2007)59 1000 8.21A motor imagery dataset containing 2\\nclasses of left hand, right hand, foot (+\\nidle state) for 7 subjects.\\nEmobrain (Savran\\net al., 2006)64 1024 4.94A multimodal emotion dataset including\\n16 subjects. The emotions were elicited\\nthrough a selected subset of the IAPS\\ndataset.\\nGrasp and Lift\\n(Luciw et al., 2014)32 500 11.72A dataset containing 12 subjects\\nperforming grasp-and-lift (GAL) trials.\\nInria BCI (Margaux\\net al., 2012)56 600 29.98A P300-based spelling dataset including\\n26 subjects.\\nMotor\\nMovement/Imagery\\n(Schalk et al., 2004)64 160 47.3A motor imagery dataset consisting of 109\\nvolunteers performing 2 baseline tasks,\\nmotor movement, and motor imagery.\\nRaw EEG Data\\n(Trujillo, 2020)64 256 34.35EEG was recorded during reported\\nInformation-Integration categorization and\\nreported multidimensional Rule-Based\\ncategorization tasks.\\nResting State\\n(Trujillo et al., 2017)64 256 3.04A dataset comprising 22 subjects for a\\nresting task of 8 mins with 4 mins of eyes\\nclosed and 4 mins of eyes open.\\nSiena Scalp EEG\\nDatabase (Detti\\net al., 2020)31 512 30.47 A database consisting of 14 patients.\\nSPIS Resting State\\n(Torkamani-Azar\\net al., 2020)64 2048 0.83A dataset including 10 subjects, 2.5\\nminutes recording in eyes-closed and\\neyes-open prior to a 105-minute session of\\nSustained Attention to Response Task\\nwith fixed-sequence and varying ISIs.\\nTarget Versus\\nNon-Target\\n(Korczowski et al.,\\n2019)32 512 16A dataset including 50 subjects playing\\nBrain Invaders, a visual P300\\nBrain-Computer Interface using oddball\\nparadigm with adaptive Riemannian\\nGeometry (no-calibration).\\nSelf-collected EEG\\ncorpus (Jiang et al.,\\n2023; 2021; Luo\\net al., 2022; Li et al.,\\n2021; Tao & Lu,\\n2020)62 1000 342.23A mixed self-collected EEG datasets of\\nmore than 140 subjects under various\\nconditions.\\n16\\nPublished as a conference paper at ICLR 2025\\nD D ETAILED EXPERIMENTAL SETTINGS\\nD.1 H YPERPARAMETER SETTINGS\\nTable 7: Hyperparameters for neural tokenizer.\\nHyperparameters Values\\nTemporal EncoderIp', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 314: ('al P300\\nBrain-Computer Interface using oddball\\nparadigm with adaptive Riemannian\\nGeometry (no-calibration).\\nSelf-collected EEG\\ncorpus (Jiang et al.,\\n2023; 2021; Luo\\net al., 2022; Li et al.,\\n2021; Tao & Lu,\\n2020)62 1000 342.23A mixed self-collected EEG datasets of\\nmore than 140 subjects under various\\nconditions.\\n16\\nPublished as a conference paper at ICLR 2025\\nD D ETAILED EXPERIMENTAL SETTINGS\\nD.1 H YPERPARAMETER SETTINGS\\nTable 7: Hyperparameters for neural tokenizer.\\nHyperparameters Values\\nTemporal EncoderIput channels {1,16,16 }\\nOutput channels {16,16,16 }\\nKernel size {15,3,3}\\nStride {8,1,1}\\nPadding {7,1,1}\\nTransformer encoder layers 12\\nTransformer decoder layers 3\\nHidden size 768\\nMLP size 3072\\nAttention head number 12\\nCodebook size 8192 ×128\\nEEG Batch size 512\\nText Batch size 128\\nPeak learning rate 5e-5\\nMinimal learning rate 1e-5\\nLearning rate scheduler Cosine\\nOptimizer AdamW\\nAdam β (0.9,0.999)\\nWeight decay 1e-4\\nTotal epochs 50\\nWarmup epochs 5\\nData overlap None\\nGradient clipping None\\nTable 8: Hyperparameters for autoregressive pre-training.\\nHyperparameters NeuroLM-B NeuroLM-L NeuroLM-XL\\nModel size 254M 500M 1696M\\nTransformer encoder layers 12 24 48\\nHidden size 768 1024 1600\\nMLP size 3072 4096 6400\\nAttention head number 12 16 25\\nEEG batch size 480 (B), 512 (L, XL)\\nText batch size 32 (B), 64 (L, XL)\\nPeak learning rate 6e-4\\nMinimal learning rate 6e-5\\nLearning rate scheduler Cosine\\nOptimizer AdamW\\nAdam β (0.9,0.95)\\nWeight decay 0.1\\nTotal epochs 20\\nWarmup epochs 2\\nData overlap None\\nGradient clipping 1\\n17\\nPublished as a conference paper at ICLR 2025\\nTable 9: Hyperparameters for instruction tuning.\\nHyperparameters Values\\nInstruction batch size 512\\nText batch size 128\\nPeak learning rate 5e-4 (B), 5e-5 (L), 2e-5 (XL)\\nMinimal learning rate 5e-5 (B), 5e-6 (L), 2e-6 (XL)\\nLearning rate scheduler Cosine\\nOptimizer AdamW\\nAdam β (0.9,0.95)\\nWeight decay 0.1\\nTotal epochs 5 (B, L), 3 (XL)\\nWarmup ratio 0.1\\nGradient clipping 1\\nD.2 M ETRICS\\nConsidering the class imbalance of most downstream EEG datasets, we use the following metrics\\nf', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 315: ('as a conference paper at ICLR 2025\\nTable 9: Hyperparameters for instruction tuning.\\nHyperparameters Values\\nInstruction batch size 512\\nText batch size 128\\nPeak learning rate 5e-4 (B), 5e-5 (L), 2e-5 (XL)\\nMinimal learning rate 5e-5 (B), 5e-6 (L), 2e-6 (XL)\\nLearning rate scheduler Cosine\\nOptimizer AdamW\\nAdam β (0.9,0.95)\\nWeight decay 0.1\\nTotal epochs 5 (B, L), 3 (XL)\\nWarmup ratio 0.1\\nGradient clipping 1\\nD.2 M ETRICS\\nConsidering the class imbalance of most downstream EEG datasets, we use the following metrics\\nfor comparison:\\n•Balanced Accuracy : The average of recall (sensitivity) obtained on each class. It is partic-\\nularly useful for evaluating classification performance on imbalanced datasets. This metric\\nis particularly useful when evaluating models on imbalanced datasets.\\n•AUC-PR : A performance measurement for binary classification problems. It is the area\\nunder the curve plotted with precision (y-axis) against recall (x-axis) for different threshold\\nvalues.\\n•AUROC : It is the area under the curve plotted with the true positive rate (sensitivity) on the\\ny-axis and the false positive rate (1 - specificity) on the x-axis for different threshold values.\\nAUROC provides an aggregate measure of performance across all possible classification\\nthresholds, indicating the ability of the model to distinguish between classes.\\n•Cohen’s Kappa : A measure of agreement between categorical variables XandY, calcu-\\nlated from the observed and expected frequencies on the diagonal of a square contingency\\ntable. It is used for multi-class classification.\\n•Weighted F1 : The weighted F1 score is the harmonic mean of precision and recall, taking\\ninto account the support (the number of true instances) of each class. The weighted F1\\nscore accounts for class imbalance by giving more importance to classes with a higher\\nnumber of instances.\\nAUROC and Cohen’s Kappa are used as the monitor score for binary classification and multi-class\\nclassification, respectively.\\nD.3 B ASELINES\\nWe mainly consider BIOT (Yang et al., 2023a) and the state-of-t', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 316: ('i-class classification.\\n•Weighted F1 : The weighted F1 score is the harmonic mean of precision and recall, taking\\ninto account the support (the number of true instances) of each class. The weighted F1\\nscore accounts for class imbalance by giving more importance to classes with a higher\\nnumber of instances.\\nAUROC and Cohen’s Kappa are used as the monitor score for binary classification and multi-class\\nclassification, respectively.\\nD.3 B ASELINES\\nWe mainly consider BIOT (Yang et al., 2023a) and the state-of-the-art EEG foundation model\\nLaBraM (Jiang et al., 2024) as our baseline method, where BIOT is a generic biosignal learning\\nmodel pre-trained on multiple datasets in a supervised way, and LaBraM is pre-trained on 2,500\\nhours data through masked EEG modeling and has learned generic representations for various EEG\\nsignals. Five other supervised methods including SPaRCNet (Jing et al., 2023), ContraWR (Yang\\net al., 2023b), CNN-Transformer (Peh et al., 2022), FFCL (Li et al., 2022), and ST-Transformer\\n(Song et al., 2021) are also utilized as our baselines. As there are no multi-task methods available\\nin EEG signal processing yet, these baselines are solely fine-tuned on each downstream dataset and\\ncannot perform multiple tasks. We use the default settings for these baselines in the BIOT paper.\\nThe batch size is 512 for TUAB, TUEV , SEED, and HMC. As the data size of Workload and TUSL\\nis particularly small, the batch size of these two datasets is set to 32 and 16, respectively.\\n18\\nPublished as a conference paper at ICLR 2025\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000024/uni00000014\\n/uni00000024/uni00000015\\n/uni00000029/uni0000005d\\n/u', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 317: (' ICLR 2025\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000024/uni00000014\\n/uni00000024/uni00000015\\n/uni00000029/uni0000005d\\n/uni00000026/uni0000005d\\n/uni00000033/uni0000005d\\n/uni00000037/uni00000014\\n/uni00000037/uni00000015\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000002c/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000044/uni00000045/uni00000051/uni00000052/uni00000055/uni00000050/uni00000044/uni0000004f\\n/uni00000022\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni0000001c/uni00000018/uni00000013/uni00000011/uni00000014/uni0000001c/uni00000013/uni00000013/uni00000011/uni00000015/uni0000001b/uni00000018/uni00000013/uni00000011/uni00000016/uni0000001b/uni00000013/uni00000013/uni00000011/uni00000017/uni0000001a/uni00000018\\n(a) TUAB\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 318: ('0000001c/uni00000018/uni00000013/uni00000011/uni00000014/uni0000001c/uni00000013/uni00000013/uni00000011/uni00000015/uni0000001b/uni00000018/uni00000013/uni00000011/uni00000016/uni0000001b/uni00000013/uni00000013/uni00000011/uni00000017/uni0000001a/uni00000018\\n(a) TUAB\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000024/uni00000014\\n/uni00000024/uni00000015\\n/uni00000029/uni0000005d\\n/uni00000026/uni0000005d\\n/uni00000033/uni0000005d\\n/uni00000037/uni00000014\\n/uni00000037/uni00000015\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000003a/uni0000004b/uni0000004c/uni00000046/uni0000004b\\n/uni00000003/uni00000048/uni00000059/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000057/uni0000005c/uni00000053/uni00000048\\n/uni00000003/uni00000047/uni00000052/uni00000048/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000045/uni00000048/uni0000004f/uni00000052/uni00000051/uni0000004a\\n/uni00000003/uni00000057/uni00000052\\n/uni00000022\\n/uni00000003/uni00000032/uni00000053/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\\n/uni0000001d\\n/uni00000003/uni0000000b\\n/uni00000024\\n/uni0000000c\\n/uni00000003/uni00000056/uni00000053/uni0000004c/uni0000004e/uni00000048\\n/uni00000003/uni00000044/uni00000051/uni00000047\\n/uni00000003/uni00000056/uni0000004f/uni00000052/uni0000005a\\n/uni00000003/uni0000005a/uni00000044/uni00000059/uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 319: ('045/uni00000048/uni0000004f/uni00000052/uni00000051/uni0000004a\\n/uni00000003/uni00000057/uni00000052\\n/uni00000022\\n/uni00000003/uni00000032/uni00000053/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\\n/uni0000001d\\n/uni00000003/uni0000000b\\n/uni00000024\\n/uni0000000c\\n/uni00000003/uni00000056/uni00000053/uni0000004c/uni0000004e/uni00000048\\n/uni00000003/uni00000044/uni00000051/uni00000047\\n/uni00000003/uni00000056/uni0000004f/uni00000052/uni0000005a\\n/uni00000003/uni0000005a/uni00000044/uni00000059/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000025\\n/uni0000000c\\n/uni00000003/uni0000004a/uni00000048/uni00000051/uni00000048/uni00000055/uni00000044/uni0000004f/uni0000004c/uni0000005d/uni00000048/uni00000047\\n/uni00000003/uni00000053/uni00000048/uni00000055/uni0000004c/uni00000052/uni00000047/uni0000004c/uni00000046\\n/uni00000003/uni00000048/uni00000053/uni0000004c/uni0000004f/uni00000048\\n/uni00000053/uni00000057\\n/uni0000004c/uni00000049/uni00000052/uni00000055/uni00000050\\n/uni00000003/uni00000047/uni0000004c/uni00000056/uni00000046/uni0000004b/uni00000044/uni00000055/uni0000004a/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000026\\n/uni0000000c\\n/uni00000003/uni00000053/uni00000048/uni00000055/uni0000004c/uni00000052/uni00000047/uni0000004c/uni00000046\\n/uni00000003/uni0000004f/uni00000044/uni00000057/uni00000048/uni00000055/uni00000044/uni0000004f\\n/uni0000004c/uni0000005d/uni00000048/uni00000047\\n/uni00000003/uni00000048/uni00000053/uni0000004c/uni0000004f/uni00000048\\n/uni00000053/uni00000057\\n/uni0000004c/uni00000049/uni00000052/uni00000055/uni00000050\\n/uni00000003/uni00000047/uni0000004c/uni00000056/uni00000046/uni0000004b/uni00000044/uni00000055/uni0000004a/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000027\\n/uni0000000c\\n/uni00000003/uni00000048/uni0000005c/uni00000048\\n/uni00000003/uni00000050/uni00000052/uni00000059/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000028\\n/uni0000000c\\n/uni00000003/uni00000044/uni00000055/uni000000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 320: ('ni0000004c/uni00000049/uni00000052/uni00000055/uni00000050\\n/uni00000003/uni00000047/uni0000004c/uni00000056/uni00000046/uni0000004b/uni00000044/uni00000055/uni0000004a/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000027\\n/uni0000000c\\n/uni00000003/uni00000048/uni0000005c/uni00000048\\n/uni00000003/uni00000050/uni00000052/uni00000059/uni00000048/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000028\\n/uni0000000c\\n/uni00000003/uni00000044/uni00000055/uni00000057/uni0000004c/uni00000049/uni00000044/uni00000046/uni00000057\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000029\\n/uni0000000c\\n/uni00000003/uni00000045/uni00000044/uni00000046/uni0000004e/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000051/uni00000047\\n/uni00000011\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d\\n/uni00000003/uni0000000b/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni0000001c/uni00000018/uni0000001a/uni00000013/uni00000011/uni00000014/uni0000001c/uni00000014/uni00000018/uni00000013/uni00000011/uni00000015/uni0000001b/uni0000001a/uni00000015/uni00000013/uni00000011/uni00000016/uni0000001b/uni00000016/uni00000013/uni00000013/uni00000011/uni00000017/uni0000001a/uni0000001b/uni0000001a\\n(b) TUEV\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni0000003d\\n/uni00000029/uni00000033/uni00000015\\n/uni00000024/uni00000029/uni00000016\\n/uni00000024/uni00000029/uni00000017\\n/uni00000029/uni0000001a\\n/uni00000029/uni00000018\\n/uni00000029/uni00000016\\n/uni00000029/uni00000014\\n/uni00000029/uni0000003d\\n/uni00000029/uni00000015\\n/uni00000029/uni00000017\\n/uni00000029/uni00000019\\n/uni00000029/uni0000001b\\n/uni00000029/uni00000037/uni0000001a\\n/uni00000029/uni00000026/uni00000018\\n/uni00000029/uni0000002', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 321: ('TUEV\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni0000003d\\n/uni00000029/uni00000033/uni00000015\\n/uni00000024/uni00000029/uni00000016\\n/uni00000024/uni00000029/uni00000017\\n/uni00000029/uni0000001a\\n/uni00000029/uni00000018\\n/uni00000029/uni00000016\\n/uni00000029/uni00000014\\n/uni00000029/uni0000003d\\n/uni00000029/uni00000015\\n/uni00000029/uni00000017\\n/uni00000029/uni00000019\\n/uni00000029/uni0000001b\\n/uni00000029/uni00000037/uni0000001a\\n/uni00000029/uni00000026/uni00000018\\n/uni00000029/uni00000026/uni00000016\\n/uni00000029/uni00000026/uni00000014\\n/uni00000029/uni00000026/uni0000003d\\n/uni00000029/uni00000026/uni00000015\\n/uni00000029/uni00000026/uni00000017\\n/uni00000029/uni00000026/uni00000019\\n/uni00000029/uni00000037/uni0000001b\\n/uni00000037/uni0000001a\\n/uni00000026/uni00000018\\n/uni00000026/uni00000016\\n/uni00000026/uni00000014\\n/uni00000026/uni0000003d\\n/uni00000026/uni00000015\\n/uni00000026/uni00000017\\n/uni00000026/uni00000019\\n/uni00000037/uni0000001b\\n/uni00000037/uni00000033/uni0000001a\\n/uni00000026/uni00000033/uni00000018\\n/uni00000026/uni00000033/uni00000016\\n/uni00000026/uni00000033/uni00000014\\n/uni00000026/uni00000033/uni0000003d\\n/uni00000026/uni00000033/uni00000015\\n/uni00000026/uni00000033/uni00000017\\n/uni00000026/uni00000033/uni00000019\\n/uni00000037/uni00000033/uni0000001b\\n/uni00000033/uni0000001a\\n/uni00000033/uni00000018\\n/uni00000033/uni00000016\\n/uni00000033/uni00000014\\n/uni00000033/uni0000003d\\n/uni00000033/uni00000015\\n/uni00000033/uni00000017\\n/uni00000033/uni00000019\\n/uni00000033/uni0000001b\\n/uni00000033/uni00000032/uni0000001a\\n/uni00000033/uni00000032/uni00000018\\n/uni00000033/uni00000032/uni00000016\\n/uni00000033/uni00000032/uni0000003d\\n/uni00000033/uni00000032/uni00000017\\n/uni00000033/uni00000032/uni00000019\\n/uni00000033/uni00000032/uni0000001b\\n/uni00000026/uni00000025/uni00000014\\n/uni00000032/uni00000014\\n/uni00000032/uni0000003d\\n/uni00000032/uni00000015\\n/uni00000026/uni00000025/uni00000015\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 322: ('0000033/uni00000032/uni0000001a\\n/uni00000033/uni00000032/uni00000018\\n/uni00000033/uni00000032/uni00000016\\n/uni00000033/uni00000032/uni0000003d\\n/uni00000033/uni00000032/uni00000017\\n/uni00000033/uni00000032/uni00000019\\n/uni00000033/uni00000032/uni0000001b\\n/uni00000026/uni00000025/uni00000014\\n/uni00000032/uni00000014\\n/uni00000032/uni0000003d\\n/uni00000032/uni00000015\\n/uni00000026/uni00000025/uni00000015\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000003a/uni0000004b/uni0000004c/uni00000046/uni0000004b\\n/uni00000003/uni00000048/uni00000050/uni00000052/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni00000003/uni00000057/uni0000005c/uni00000053/uni00000048\\n/uni00000003/uni00000047/uni00000052/uni00000048/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000045/uni00000048/uni0000004f/uni00000052/uni00000051/uni0000004a\\n/uni00000003/uni00000057/uni00000052\\n/uni00000022\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000019/uni00000014/uni00000017/uni00000013/uni00000011/uni00000014/uni00000015/uni00000015/uni0000001b/uni00000013/uni00000011/uni00000014/uni0000001b/uni00000017/uni00000015/uni00000013/uni00000011/uni00000015/uni00000017/uni00000018/uni0000001a/uni00000013/uni00000011/uni00000016/uni00000013/uni0000001a/uni00000014\\n(c) SEED\\n/uni00000029/uni00000017\\n/uni00000026/uni00000017\\n/uni00000032/uni00000015\\n/uni00000026/uni00000016\\n/uni00000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 323: ('i00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni00000019/uni00000014/uni00000017/uni00000013/uni00000011/uni00000014/uni00000015/uni00000015/uni0000001b/uni00000013/uni00000011/uni00000014/uni0000001b/uni00000017/uni00000015/uni00000013/uni00000011/uni00000015/uni00000017/uni00000018/uni0000001a/uni00000013/uni00000011/uni00000016/uni00000013/uni0000001a/uni00000014\\n(c) SEED\\n/uni00000029/uni00000017\\n/uni00000026/uni00000017\\n/uni00000032/uni00000015\\n/uni00000026/uni00000016\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000003a/uni0000004b/uni0000004c/uni00000046/uni0000004b\\n/uni00000003/uni00000056/uni0000004f/uni00000048/uni00000048/uni00000053\\n/uni00000003/uni00000057/uni0000005c/uni00000053/uni00000048\\n/uni00000003/uni00000047/uni00000052/uni00000048/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000045/uni00000048/uni0000004f/uni00000052/uni00000051/uni0000004a\\n/uni00000003/uni00000057/uni00000052\\n/uni00000022\\n/uni00000003/uni00000032/uni00000053/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\\n/uni0000001d\\n/uni00000003/uni0000000b\\n/uni00000024\\n/uni0000000c\\n/uni00000003/uni0000003a/uni00000044/uni0000004e/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000025\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000014\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000026\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000015\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000027\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000016\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000028\\n/uni0000000c\\n/uni00000003/uni000000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 324: ('000000b\\n/uni00000025\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000014\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000026\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000015\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000027\\n/uni0000000c\\n/uni00000003/uni00000031\\n/uni00000035/uni00000028/uni00000030\\n/uni00000010\\n/uni00000016\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000028\\n/uni0000000c\\n/uni00000003/uni00000035/uni00000028/uni00000030\\n/uni00000011\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d\\n/uni00000003/uni0000000b/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni0000001a/uni0000001a/uni00000017/uni00000013/uni00000011/uni00000014/uni00000018/uni00000017/uni0000001a/uni00000013/uni00000011/uni00000015/uni00000016/uni00000015/uni00000014/uni00000013/uni00000011/uni00000016/uni00000013/uni0000001c/uni00000017/uni00000013/uni00000011/uni00000016/uni0000001b/uni00000019/uni0000001b\\n(d) HMC\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000003d\\n/uni00000026/uni0000003d\\n/uni00000033/uni0000003d\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000002c/uni00000056\\n/uni00000003/uni00000057/uni000000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 325: ('0000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000003d\\n/uni00000026/uni0000003d\\n/uni00000033/uni0000003d\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000002c/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000052/uni00000049\\n/uni00000003/uni0000004b/uni0000004c/uni0000004a/uni0000004b\\n/uni00000003/uni0000005a/uni00000052/uni00000055/uni0000004e/uni0000004f/uni00000052/uni00000044/uni00000047\\n/uni00000022\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni0000001c/uni0000001b/uni00000013/uni00000011/uni00000014/uni0000001c/uni00000019/uni00000013/uni00000011/uni00000015/uni0000001c/uni00000017/uni00000013/uni00000011/uni00000016/uni0000001c/uni00000015/uni00000013/uni00000011/uni00000017/uni0000001c/uni00000013\\n(e) Workload\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000024/uni00000014\\n/uni00000024/uni00000015\\n/uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 326: ('00001c/uni00000013\\n(e) Workload\\n/uni00000029/uni00000033/uni00000014\\n/uni00000029/uni00000033/uni00000015\\n/uni00000029/uni00000016\\n/uni00000029/uni00000017\\n/uni00000026/uni00000016\\n/uni00000026/uni00000017\\n/uni00000033/uni00000016\\n/uni00000033/uni00000017\\n/uni00000032/uni00000014\\n/uni00000032/uni00000015\\n/uni00000029/uni0000001a\\n/uni00000029/uni0000001b\\n/uni00000037/uni00000016\\n/uni00000037/uni00000017\\n/uni00000037/uni00000018\\n/uni00000037/uni00000019\\n/uni00000024/uni00000014\\n/uni00000024/uni00000015\\n/uni00000029/uni0000005d\\n/uni00000026/uni0000005d\\n/uni00000033/uni0000005d\\n/uni00000037/uni00000014\\n/uni00000037/uni00000015\\n/uni0000003e/uni00000036/uni00000028/uni00000033/uni00000040\\n/uni00000034/uni00000058/uni00000048/uni00000056/uni00000057/uni0000004c/uni00000052/uni00000051\\n/uni0000001d\\n/uni00000003/uni0000003a/uni0000004b/uni0000004c/uni00000046/uni0000004b\\n/uni00000003/uni00000057/uni0000005c/uni00000053/uni00000048\\n/uni00000003/uni00000047/uni00000052/uni00000048/uni00000056\\n/uni00000003/uni00000057/uni0000004b/uni0000004c/uni00000056\\n/uni00000003/uni00000028/uni00000028/uni0000002a\\n/uni00000003/uni00000056/uni00000048/uni0000004a/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000003/uni00000045/uni00000048/uni0000004f/uni00000052/uni00000051/uni0000004a\\n/uni00000003/uni00000057/uni00000052\\n/uni00000022\\n/uni00000003/uni00000032/uni00000053/uni00000057/uni0000004c/uni00000052/uni00000051/uni00000056\\n/uni0000001d\\n/uni00000003/uni0000000b\\n/uni00000024\\n/uni0000000c\\n/uni00000003/uni00000045/uni00000044/uni00000046/uni0000004e/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000051/uni00000047\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000025\\n/uni0000000c\\n/uni00000003/uni00000056/uni00000048/uni0000004c/uni0000005d/uni00000058/uni00000055/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000026\\n/uni0000000c\\n/uni00000003/uni00000056/uni0000004f/uni00000052/uni0000005a/uni0000004c/uni00000051/uni0000004a\\n/uni00000011\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni0000', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 327: ('/uni00000046/uni0000004e/uni0000004a/uni00000055/uni00000052/uni00000058/uni00000051/uni00000047\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000025\\n/uni0000000c\\n/uni00000003/uni00000056/uni00000048/uni0000004c/uni0000005d/uni00000058/uni00000055/uni00000048\\n/uni00000011\\n/uni00000003/uni0000000b\\n/uni00000026\\n/uni0000000c\\n/uni00000003/uni00000056/uni0000004f/uni00000052/uni0000005a/uni0000004c/uni00000051/uni0000004a\\n/uni00000011\\n/uni00000003/uni00000024/uni00000051/uni00000056/uni0000005a/uni00000048/uni00000055\\n/uni0000001d\\n/uni00000003/uni0000000b/uni00000014\\n/uni00000015\\n/uni00000016\\n/uni00000017\\n/uni00000018\\n/uni00000019\\n/uni0000001a\\n/uni0000001b\\n/uni0000001c\\n/uni00000014/uni00000013\\n/uni00000014/uni00000014\\n/uni00000014/uni00000015\\n/uni00000013/uni00000011/uni00000013/uni00000013/uni00000013/uni00000013/uni00000013/uni00000011/uni00000013/uni0000001b/uni00000017/uni00000015/uni00000013/uni00000011/uni00000014/uni00000019/uni0000001b/uni00000016/uni00000013/uni00000011/uni00000015/uni00000018/uni00000015/uni00000018/uni00000013/uni00000011/uni00000016/uni00000016/uni00000019/uni00000019/uni00000013/uni00000011/uni00000017/uni00000015/uni00000013/uni0000001b\\n(f) TUSL\\nFigure 9: The attention value on other datasets. The vertical axis denotes the Transformer layers.\\n19\\nPublished as a conference paper at ICLR 2025\\nE A TTENTION VISUALIZATION\\nTo explore the mechanism of NeuroLM, we visualize the attention scores of the answer parts in\\nthe instructions for all 12 Transformer layers, as drawn in Figure 9. Firstly, we observed several\\ncommonalities across datasets: For the text part, the attention tends to concentrate more in shallow\\nlayers whereas for the EEG part, attention gains more in deeper layers. This pattern suggests that\\nNeuroLM primarily processes text questions in the shallow layers and focuses on EEG tokens in\\nthe deeper layers to generate answers. Interestingly, in the case of multiple-choice questions, Neu-\\nroLM pays close attention to the options (A, B, C, etc.) between the 6th and 9th layers. Analyzing', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 328: ('e observed several\\ncommonalities across datasets: For the text part, the attention tends to concentrate more in shallow\\nlayers whereas for the EEG part, attention gains more in deeper layers. This pattern suggests that\\nNeuroLM primarily processes text questions in the shallow layers and focuses on EEG tokens in\\nthe deeper layers to generate answers. Interestingly, in the case of multiple-choice questions, Neu-\\nroLM pays close attention to the options (A, B, C, etc.) between the 6th and 9th layers. Analyzing\\ncritical EEG channels for different tasks, we find that NeuroLM seems to aggregate information to\\nCz for most datasets. For HMC, F4 and C3 are crucial, while O2 is less effective in sleep stage\\nclassification.\\nF A NALYSIS OF NEURAL TOKENIZER\\nF.1 A BLATION ON TEMPORAL -FREQUENCY PREDICTION\\nTemporal and frequency domains are two pivotal aspects of EEG signals. To investigate the impor-\\ntance of these two domains for different downstream tasks, we study three variants by setting the\\nreconstruction target in neural tokenizer training as only the temporal domain, only the frequency\\ndomain, and both temporal and frequency domains (original NeuroLM). Figure 10 shows the com-\\nparison between the three variants. Interestingly, it can be found that the temporal domain plays a\\nmore crucial role on TUAB, Workload, and TUSL. On the contrary, reconstructing the frequency\\ncomponents obtains better performance on TUEV , SEED, and HMC, indicating that the frequency\\ndomain is of great importance for event classification, emotion recognition, and sleep stage classifi-\\ncation. By combining the two domains, most tasks achieve similar or higher performance, demon-\\nstrating the effectiveness of our neural tokenizer that excavates compact EEG representations for\\nlanguage models.\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000024/uni00000038/uni00000026/uni00000010/uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 329: ('ion recognition, and sleep stage classifi-\\ncation. By combining the two domains, most tasks achieve similar or higher performance, demon-\\nstrating the effectiveness of our neural tokenizer that excavates compact EEG representations for\\nlanguage models.\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000024/uni00000038/uni00000026/uni00000010/uni00000033/uni00000035 /uni00000024/uni00000038/uni00000035/uni00000032/uni00000026/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000024/uni00000025\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni0000002', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 330: ('0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000028/uni00000039\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000036/uni00000028/uni00000028/uni00000027\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/un', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 331: ('015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000036/uni00000028/uni00000028/uni00000027\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000002b/uni00000030/uni00000026\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 332: ('ni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000024/uni00000038/uni00000026/uni00000010/uni00000033/uni00000035 /uni00000024/uni00000038/uni00000035/uni00000032/uni00000026/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni0000003a/uni00000052/uni00000055/uni0000004e/uni0000004f/uni00000052/uni00000044/uni00000047\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000025/uni00000044/uni0000004f/uni00000044/uni00000051/uni00000046/uni00000048/uni00000047/uni00000003/uni00000024/uni00000046/uni00000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni0000001', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 333: ('0000046/uni00000058/uni00000055/uni00000044/uni00000046/uni0000005c /uni00000026/uni00000052/uni0000004b/uni00000048/uni00000051/uni0000000a/uni00000056/uni00000003/uni0000002e/uni00000044/uni00000053/uni00000053/uni00000044 /uni0000003a/uni00000048/uni0000004c/uni0000004a/uni0000004b/uni00000057/uni00000048/uni00000047/uni00000003/uni00000029/uni00000014/uni00000013/uni00000011/uni00000013/uni00000013/uni00000011/uni00000015/uni00000013/uni00000011/uni00000017/uni00000013/uni00000011/uni00000019/uni00000013/uni00000011/uni0000001b/uni00000014/uni00000011/uni00000013/uni00000037/uni00000038/uni00000036/uni0000002f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c/uni00000003/uni00000009/uni00000003/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\n/uni00000049/uni00000055/uni00000048/uni00000054/uni00000058/uni00000048/uni00000051/uni00000046/uni0000005c\\n/uni00000057/uni00000048/uni00000050/uni00000053/uni00000052/uni00000055/uni00000044/uni0000004f\\nFigure 10: Ablation study on reconstructing temporal or frequency domain in neural tokenizer.\\nF.2 V ISUALIZATION OF EEG AND TEXT EMBEDDINGS\\nTo evaluate the effectiveness of EEG-text embedding space alignment, we visualize the embeddings\\nin Figure 11 using t-SNE (Van der Maaten & Hinton, 2008). The EEG embeddings expand outside\\nthe text space without alignment. In this case, we find that the model fails to predict the answers\\nwe expect in multi-task instruction tuning, i.e., the model will output random words instead of\\n20\\nPublished as a conference paper at ICLR 2025\\noptions like (A), (B), or (c) in choice questions, leading to near-zero scores across most metrics\\non downstream tasks. This outcome appears to stem from disordered attention scores, as EEG and\\ntext embeddings remain in separate spaces. When training with alignment, the EEG space mostly\\naligns with text space, resulting in normal prediction in instruction tuning, proving the necessity of\\nEEG-text alignm', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 334: ('ning, i.e., the model will output random words instead of\\n20\\nPublished as a conference paper at ICLR 2025\\noptions like (A), (B), or (c) in choice questions, leading to near-zero scores across most metrics\\non downstream tasks. This outcome appears to stem from disordered attention scores, as EEG and\\ntext embeddings remain in separate spaces. When training with alignment, the EEG space mostly\\naligns with text space, resulting in normal prediction in instruction tuning, proving the necessity of\\nEEG-text alignment.\\n/uni00000019/uni00000013\\n /uni00000017/uni00000013\\n /uni00000015/uni00000013\\n /uni00000013 /uni00000015/uni00000013 /uni00000017/uni00000013 /uni00000019/uni00000013/uni00000019/uni00000013\\n/uni00000017/uni00000013\\n/uni00000015/uni00000013\\n/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000019/uni00000013/uni0000005a/uni00000012/uni00000052/uni00000003/uni00000044/uni0000004f/uni0000004c/uni0000004a/uni00000051/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000037/uni00000048/uni0000005b/uni00000057\\n/uni00000028/uni00000028/uni0000002a\\n/uni00000019/uni00000013\\n /uni00000017/uni00000013\\n /uni00000015/uni00000013\\n /uni00000013 /uni00000015/uni00000013 /uni00000017/uni00000013 /uni00000019/uni00000013/uni00000019/uni00000013\\n/uni00000017/uni00000013\\n/uni00000015/uni00000013\\n/uni00000013/uni00000015/uni00000013/uni00000017/uni00000013/uni00000019/uni00000013/uni0000005a/uni00000012/uni00000003/uni00000044/uni0000004f/uni0000004c/uni0000004a/uni00000051/uni00000050/uni00000048/uni00000051/uni00000057\\n/uni00000037/uni00000048/uni0000005b/uni00000057\\n/uni00000028/uni00000028/uni0000002a\\nFigure 11: Representation visualization of EEG and text by t-SNE. Left: training neural tokenizer\\nwithout alignment. Right : training neural tokenizer with alignment.\\nG A BLATION ON DIFFERENT PRE-TRAINING EPOCHS\\nWe conduct an ablation study on tuning the pre-trained models from different epochs to testify the\\nbest pre-training epoch. As shown in Table 10 11 12, we use the pre-trained models of 5, 10, 15,\\na', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 335: ('0051/uni00000057\\n/uni00000037/uni00000048/uni0000005b/uni00000057\\n/uni00000028/uni00000028/uni0000002a\\nFigure 11: Representation visualization of EEG and text by t-SNE. Left: training neural tokenizer\\nwithout alignment. Right : training neural tokenizer with alignment.\\nG A BLATION ON DIFFERENT PRE-TRAINING EPOCHS\\nWe conduct an ablation study on tuning the pre-trained models from different epochs to testify the\\nbest pre-training epoch. As shown in Table 10 11 12, we use the pre-trained models of 5, 10, 15,\\nand 20 epochs. Bold represents the best results and underline represents the second best results.\\nIt can be found that pre-training for 20 epochs obtains the most bold and underlined results. The\\nperformance of 5 epochs gets its best on SEED and HMC while the model from 10 epochs achieves\\nthe best result on Workload. Overall, pre-training for more epochs can lead to good performance in\\ndifferent tasks.\\nTable 10: Results on TUAB and TUEV .\\nPre-trained EpochsTUAB TUEV\\nBalanced Acc. AUC-PR AUROC Balanced Acc. Cohen’s Kappa Weighted F1\\n5 0.7763 ±0.0037 0.6891 ±0.0040 0.7762 ±0.0038 0.4609 ±0.0696 0.3914 ±0.0670 0.6975 ±0.0249\\n10 0.7738 ±0.0040 0.6995 ±0.0038 0.7647 ±0.0143 0.4693 ±0.0175 0.4625 ±0.0091 0.7353 ±0.038\\n15 0.7780 ±0.0050 0.6951 ±0.0054 0.7735 ±0.0112 0.4557 ±0.0277 0.4216 ±0.0215 0.7131 ±0.0101\\n20 0.7826 ±0.0065 0.6975 ±0.0081 0.7816 ±0.0079 0.4560 ±0.0048 0.4285 ±0.0048 0.7153 ±0.0028\\nTable 11: Results on SEED and HMC.\\nPre-trained EpochsSEED HMC\\nBalanced Acc. Cohen’s Kappa Weighted F1 Balanced Acc. Cohen’s Kappa Weighted F1\\n5 0.5641 ±0.0103 0.3505 ±0.0172 0.5679 ±0.0123 0.6956 ±0.0136 0.6269 ±0.0053 0.7118 ±0.0048\\n10 0.5553 ±0.0089 0.3376 ±0.0143 0.5592 ±0.0091 0.6763 ±0.0054 0.6161 ±0.0069 0.7065 ±0.0057\\n15 0.5543 ±0.0156 0.3365 ±0.0244 0.5572 ±0.0164 0.6543 ±0.0151 0.5991 ±0.0153 0.6674 ±0.0265\\n20 0.5554 ±0.0075 0.3393 ±0.0117 0.5599 ±0.0068 0.6737 ±0.0050 0.6188 ±0.0057 0.7126 ±0.0034\\n21\\nPublished as a conference paper at ICLR 2025\\nTable 12: Results on Workload and TUSL.\\nPre-trained EpochsWorkload T', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 336: ('ohen’s Kappa Weighted F1\\n5 0.5641 ±0.0103 0.3505 ±0.0172 0.5679 ±0.0123 0.6956 ±0.0136 0.6269 ±0.0053 0.7118 ±0.0048\\n10 0.5553 ±0.0089 0.3376 ±0.0143 0.5592 ±0.0091 0.6763 ±0.0054 0.6161 ±0.0069 0.7065 ±0.0057\\n15 0.5543 ±0.0156 0.3365 ±0.0244 0.5572 ±0.0164 0.6543 ±0.0151 0.5991 ±0.0153 0.6674 ±0.0265\\n20 0.5554 ±0.0075 0.3393 ±0.0117 0.5599 ±0.0068 0.6737 ±0.0050 0.6188 ±0.0057 0.7126 ±0.0034\\n21\\nPublished as a conference paper at ICLR 2025\\nTable 12: Results on Workload and TUSL.\\nPre-trained EpochsWorkload TUSL\\nBalanced Acc. AUC-PR AUROC Balanced Acc. Cohen’s Kappa Weighted F1\\n5 0.5816 ±0.0235 0.5483 ±0.0160 0.5815 ±0.0236 0.5342 ±0.0235 0.2950 ±0.0345 0.5241 ±0.0260\\n10 0.6540 ±0.0192 0.6123 ±0.0165 0.6501 ±0.0178 0.5920 ±0.0560 0.3884 ±0.0876 0.5984 ±0.0574\\n15 0.5701 ±0.0282 0.5426 ±0.0177 0.5682 ±0.0255 0.5910 ±0.0629 0.3915 ±0.0999 0.5868 ±0.0536\\n20 0.6172 ±0.0113 0.5824 ±0.0080 0.6253 ±0.0160 0.6734 ±0.0436 0.5107 ±0.0617 0.6743 ±0.0394\\nH D ISCUSSION\\nLimitations. NeuroLM represents the first attempt to integrate various EEG downstream tasks\\ninto a unified model, achieving promising results across multiple downstream datasets. However,\\nit has some limitations: 1) Although NeuroLM can surpass certain single-task baselines, it still\\nlags behind state-of-the-art methods that are end-to-end trained on each downstream dataset. 2)\\nNeuroLM is somewhat sensitive to hyperparameter settings, and may not yield satisfactory results\\nwithout careful tuning. 3) With limited high-quality EEG-text pairs available, this paper only em-\\nploys coarse-grained alignment between EEG and language, i.e., space-wise alignment, which can\\npose challenges for LLMs in extracting useful information from EEG tokens.\\nOutlook. Reflecting on the outlook part of the LaBraM paper, this work explores the first and\\nthird suggested directions. Looking ahead, we foresee several potential improvements: 1) Utilizing\\nmore advanced LLMs as the base models. While this paper uses GPT-2, a relatively small LLM,\\nand still achieves promising results in the mult', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 337: ('only em-\\nploys coarse-grained alignment between EEG and language, i.e., space-wise alignment, which can\\npose challenges for LLMs in extracting useful information from EEG tokens.\\nOutlook. Reflecting on the outlook part of the LaBraM paper, this work explores the first and\\nthird suggested directions. Looking ahead, we foresee several potential improvements: 1) Utilizing\\nmore advanced LLMs as the base models. While this paper uses GPT-2, a relatively small LLM,\\nand still achieves promising results in the multi-task paradigm, leveraging newer, more advanced\\nopen-source LLMs such as LLaMA 3 (Dubey et al., 2024) may significantly enhance NeuroLM’s\\nmulti-task learning capabilities. 2) Adopting the mixture-of-experts approach is another promising\\ndirection. Given the modality gap between EEG and language, using modality-specific experts may\\nimprove multimodal learning with LLMs. 3) Developing finer-grained EEG and text alignment\\nmethods, such as describing EEG samples with predefined sentences and aligning EEG and text\\ndescriptions at the VQ training stage by adding a contrastive learning loss, may further enhance\\nperformance.\\n22', 'NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf'), 338: ('CogVideo: Large-scale Pretraining for Text-to-Video\\nGeneration via Transformers\\nWenyi Hong†\\x03Ming Ding†\\x03Wendi Zheng†Xinghan Liu†Jie Tang†z\\n†Tsinghua UniversityzBAAI\\n{hongwy18@mails, dm18@mails, jietang@mail}.tsinghua.edu.cn\\nAbstract\\nLarge-scale pretrained transformers have created milestones in text (GPT-3) and\\ntext-to-image (DALL-E and CogView) generation. Its application to video genera-\\ntion is still facing many challenges: The potential huge computation cost makes the\\ntraining from scratch unaffordable; The scarcity and weak relevance of text-video\\ndatasets hinder the model understanding complex movement semantics. In this\\nwork, we present 9B-parameter transformer CogVideo, trained by inheriting a\\npretrained text-to-image model, CogView2. We also propose multi-frame-rate\\nhierarchical training strategy to better align text and video clips. As (probably) the\\nﬁrst open-source large-scale pretrained text-to-video model, CogVideo outperforms\\nall publicly available models at a large margin in machine and human evaluations.\\nA lion is drinking water. Nightfall in a metropolis.A couple are having dinner.A woman is running on the beach in the late afternoon.A man is skiing. \\nA girl is dancing. Anime\\x11\\nFigure 1: Samples generated by CogVideo. The actual text inputs are in Chinese. Each sample is\\na 4-second clip of 32 frames, and here we sample 9 frames uniformly for display purposes. More\\nsamples, models and codes will be available at https://github.com/THUDM/CogVideo .\\n\\x03Equal contribution.\\nPreprint. Under review.arXiv:2205.15868v1  [cs.CV]  29 May 2022\\n1 Introduction\\nAutoregressive transformers, e.g. DALL-E [ 18] and CogView [ 5], have revolutionized text-to-image\\ngeneration recently. It is natural to investigate the potential of autoregressive transformers on text-\\nto-video generation. Previous works followed this basic framework [ 35,9], e.g. VideoGPT [ 36],\\nverifying its superiority over GAN-based methods [4, 26], but are still far from satisfactory.\\nOne common challenge is that the generated video frames tend to grad', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 339: ('2205.15868v1  [cs.CV]  29 May 2022\\n1 Introduction\\nAutoregressive transformers, e.g. DALL-E [ 18] and CogView [ 5], have revolutionized text-to-image\\ngeneration recently. It is natural to investigate the potential of autoregressive transformers on text-\\nto-video generation. Previous works followed this basic framework [ 35,9], e.g. VideoGPT [ 36],\\nverifying its superiority over GAN-based methods [4, 26], but are still far from satisfactory.\\nOne common challenge is that the generated video frames tend to gradually deviate from the text\\nprompt, making the generated characters hard to perform the desired actions. Vanilla autoregressive\\nmodels might be good at synthesizing videos with regular (e.g. straightly moving cars) or random\\npatterns (e.g. speaking by randomly moving lips), but fail on text prompt such as “a lion is drinking\\nwater”. The main difference between the two cases is that, in the former case the ﬁrst frame already\\nprovides sufﬁcient information for the subsequent changes, while in the latter the model has to\\nprecisely understand the action “drink” in order to correctly generate the desired action — the lion\\nlifts the glass to its lip, drinks and then puts down the glass.\\nWhy do the autoregressive transformers well understand the text-image relations, but struggle to\\nunderstand the text-action relations in videos? We hypothesize that the datasets and the way to utilize\\nthem are the main reasons.\\nFirst, it is possible to collect billions of high-quality text-image pairs from Internet [ 18], but the\\ntext-video data are more scarce. The largest annotated text-video dataset, V ATEX [ 31], has only\\n41,250 videos. The retrieval-based text-video pairs, e.g. Howto100M [ 16], are weakly relevant and\\nmost of them only describe the scene without the temporal information.\\nSecond, the duration of videos varies a lot. Previous models split the video into many clips of a\\nﬁxed number of frames for training, which destroys the alignment between the text and its temporal\\ncounterparts in the video. If a “drinking” video ', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 340: ('xt-video data are more scarce. The largest annotated text-video dataset, V ATEX [ 31], has only\\n41,250 videos. The retrieval-based text-video pairs, e.g. Howto100M [ 16], are weakly relevant and\\nmost of them only describe the scene without the temporal information.\\nSecond, the duration of videos varies a lot. Previous models split the video into many clips of a\\nﬁxed number of frames for training, which destroys the alignment between the text and its temporal\\ncounterparts in the video. If a “drinking” video is split into four individual clips of “holding a glass”,\\n“lifting”, “drinking” and “putting down” with the same text “drinking”, the model will be confused to\\nlearn the accurate meaning of drinking.\\nPresent Work. Here we present a large-scale pretrained text-to-video generative model, CogVideo,\\nwhich is of 9.4 billion parameters and trained on 5.4 million text-video pairs. We build CogVideo\\nbased on a pretrained text-to-image model, CogView2 [ 6], in order to inherit the knowledge learned\\nfrom the text-image pretraining. To ensure the alignment between text and its temporal counterparts\\nin the video, we propose the multi-frame-rate hierarchical training . The ﬂexibility of the textual\\ncondition makes it possible to simply prepend a piece of text describing the frame rate to the original\\ntext prompt for modeling different frame rates. To keep the text-video alignment, we choose a proper\\nframe rate description to include the complete action in each training sample. The frame rate token\\nalso controls the intensity of the changes throughout continuous frames in generation. Speciﬁcally,\\nwe train a sequential generation model and a frame interpolation model. The former model generates\\nkey frames according to the text, and the latter recursively ﬁll the middle frames by varying the frame\\nrates to make the video coherent. As shown in Figure 1, CogVideo can generate high-resolution\\n(480\\x02480) videos. Human evaluation demonstrates that CogVideo outperforms all publicly available\\nmodels at a large margin. Our main contrib', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 341: ('ity of the changes throughout continuous frames in generation. Speciﬁcally,\\nwe train a sequential generation model and a frame interpolation model. The former model generates\\nkey frames according to the text, and the latter recursively ﬁll the middle frames by varying the frame\\nrates to make the video coherent. As shown in Figure 1, CogVideo can generate high-resolution\\n(480\\x02480) videos. Human evaluation demonstrates that CogVideo outperforms all publicly available\\nmodels at a large margin. Our main contributions can be concluded as follows:\\n•We present CogVideo, which is the largest andthe ﬁrst open-source pretrained transformer\\nfor text-to-video generation in the general domain.\\n•CogVideo elegantly and efﬁciently ﬁnetunes a pretrained text-to-image generative model for\\ntext-to-image generation, avoiding the expensive full pretraining from scratch.\\n•We propose the multi-frame-rate hierarchical training to better align text-clip pairs, which\\nsigniﬁcantly improves the generation accuracy, in particular for movements of complex\\nsemantics. This training strategy endows CogVideo with the capacity of controlling the\\nintensity of changes during the generation.\\n2 Related Work\\n2.1 Video Generation\\nVideo generation is a long-standing research topic. Most previous works focus on the next-frame\\nprediction task — forecasting the future frames based on the ﬁrst video frame. Early works, e.g.\\n2\\nCDNA [ 8] and PredRNN [ 32], leverage deterministic methods to directly predict the next frame\\nvia CNNs or RNNs. However, these deterministic models are unable to capture the stochastic\\ntemporal patterns and synthesize coherent complex scenes. Generative models, especially Generative\\nAdversarial Networks [ 10] (GANs), begin to dominate the area as they can perform unconditional or\\nclass-conditional video synthesis without the ﬁrst frames. VGAN [ 30] is the ﬁrst one to use GAN\\nfor video generation. It decomposes video to a static background and a moving foreground, and\\nthen generates them with 2D and 3D convolutional networks respectivel', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 342: ('rministic models are unable to capture the stochastic\\ntemporal patterns and synthesize coherent complex scenes. Generative models, especially Generative\\nAdversarial Networks [ 10] (GANs), begin to dominate the area as they can perform unconditional or\\nclass-conditional video synthesis without the ﬁrst frames. VGAN [ 30] is the ﬁrst one to use GAN\\nfor video generation. It decomposes video to a static background and a moving foreground, and\\nthen generates them with 2D and 3D convolutional networks respectively. TGAN[ 19] proposes\\nto separately generate the temporal latent variables and spatial information, and MoCoGAN [ 26]\\nsimilarly decomposes the latent space into context and motion subspaces. DIGAN [ 37] applies\\nimplicit neural representations for video encoding. Recently, text-to-video generation emerges as a\\npromising direction. The framework of VQV AE [ 28] and autoregressive transformers [ 29,1] quickly\\nbecomes the mainstream method [ 34,35,9]. Ho et al. [11] proposes video diffusion model along with\\na gradient method recently for text-to-video generation. The previous methods are basically trained\\non a speciﬁc dataset, e.g. UCF-101 [ 22], making the trained model domain-speciﬁc. Moreover, most\\nof these models are not publicly available.\\n2.2 Autoregressive Transformer\\nRecent years have witnessed the autoregressive transformer emerging as a powerful generative model.\\nThe autoregressive models become the most prevalent framework for text generation [ 23]. With\\nits prominent capacity of ﬁtting, transformer [ 29] gradually becomes the standard neural structure\\nfor text generation. One milestone is GPT-3 [ 1]. In computer vision, van den Oord et al. [28]\\nﬁrst proposes to train a VQV AE to compress the image into a sequence of tokens from a learned\\ndictionary, which can be efﬁciently handled by autoregressive models. VQ-GAN [ 7] learns a more\\nsemantic-aware dictionary for unconditional image generation. In the text-to-image generation,\\npretrained autoregressive transformers such as DALL-E [ 18] and CogView [ 5] ha', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 343: ('29] gradually becomes the standard neural structure\\nfor text generation. One milestone is GPT-3 [ 1]. In computer vision, van den Oord et al. [28]\\nﬁrst proposes to train a VQV AE to compress the image into a sequence of tokens from a learned\\ndictionary, which can be efﬁciently handled by autoregressive models. VQ-GAN [ 7] learns a more\\nsemantic-aware dictionary for unconditional image generation. In the text-to-image generation,\\npretrained autoregressive transformers such as DALL-E [ 18] and CogView [ 5] have shown superiority\\nin open-domain image generation. Besides the pure GPT-style generation, CogView2 [ 6] proposes a\\nnew language model CogLM for inﬁlling in the image generation.\\nRecent autoregressive transformers [ 17,36,34,35] have also shown their superiority in video\\ngeneration. Among them, GODIV A [ 34] and NÜWA [ 35] focus on the open-domain text-to-video\\ngeneration. However, they simply generate frames or frame blocks one by one in a chronological\\norder, and may suffer from poor text-video alignment (Cf. § 1).\\n3 Method\\nIn this section, we ﬁrst introduce multi-frame-rate hierarchical training to better align text and\\nvideo semantics in § 3.1, and then illustrate an efﬁcient method dual-channel attention to inherit\\nthe knowledge in pretrained text-image models for video generation in § 3.2. To overcome the\\nlarge memory and time overhead caused by the large model and long sequence, we refer to Swin\\nAttention [14] and extend it to autoregressive video generation in § 3.3.\\n3.1 Multi-frame-rate Hierarchical Training\\nHere we present the multi-frame-rate hierarchical training and generation. We follow the framework\\nof VQV AE [ 28] and ﬁrst tokenize each frame into image tokens. Each training sample consists of\\n5 frames of tokens, but our training method differs in the construction of training sequences and\\ngeneration process.\\nTraining. The key design is to add a frame-rate token to the text and sample frames at this frame rate\\nto compose a ﬁxed-length training sequence. The motivations are two folds:\\n(1)Direct', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 344: ('l Training\\nHere we present the multi-frame-rate hierarchical training and generation. We follow the framework\\nof VQV AE [ 28] and ﬁrst tokenize each frame into image tokens. Each training sample consists of\\n5 frames of tokens, but our training method differs in the construction of training sequences and\\ngeneration process.\\nTraining. The key design is to add a frame-rate token to the text and sample frames at this frame rate\\nto compose a ﬁxed-length training sequence. The motivations are two folds:\\n(1)Directly separating the long video into clips at a ﬁxed frame rate often leads to semantic\\nmismatching. We still use the full text but the truncated clip might only contain incomplete\\naction.\\n(2)The adjacent frames are usually very similar. A giant change over the previous frame will\\nprobably incur a large loss. This will lead the models less inclined to explore the long-range\\ncorrelation because simply copying the previous frame acts like a shortcut.\\n3\\nA lion is drinking water. Ӟݝሁৼྋࡆࣁ\\u0fdcInput Text:Flatten20*20=400 image tokens per frame  *  5 framesText tokenization\\nTransformer   (Stage 2: Recursive Interpolation)Text[B]Frame-1Frame-2Frame-3Frame-4Frame-5Frame Rate\\nTransformer   (Stage 1: Sequential Generation)Text[B]Frame-1Frame-2Frame-3Frame-4Frame-5Frame Ratez}|{\\n<latexit sha1_base64=\"WkmkOQqV4y/G2CwEGjey+GFekFc=\">AAACAnicbVDLSgMxFM3UV62vUVfiJlgEV2VGi7osuHFZwT6gM5RMeqcNzWSGJCOUobjxV9y4UMStX+HOvzHTzkJbD4Qczrn3JvcECWdKO863VVpZXVvfKG9WtrZ3dvfs/YO2ilNJoUVjHstuQBRwJqClmebQTSSQKODQCcY3ud95AKlYLO71JAE/IkPBQkaJNlLfPvJiYweSUMi8kUry+9JJ9HTat6tOzZkBLxO3IFVUoNm3v7xBTNMIhKacKNVzzRw/I1IzymFa8VIFZv6YDKFnqCARKD+brTDFp0YZ4DCW5giNZ+rvjoxESk2iwFRGRI/UopeL/3m9VIfXfsZEkmoQdP5QmHKsY5zngQdMAtV8Ygihkpm/YjoiJg9tUquYENzFlZdJ+7zmXtScu3q1US/iKKNjdILOkIuuUAPdoiZqIYoe0TN6RW/Wk/VivVsf89KSVfQcoj+wPn8A712XuA==</latexit>\\nVQVAEDiscretizeImage Tokenizer\\nCz}|{\\n<latexit sha1_base64=\"WkmkOQqV4y/G2CwEGjey+GFekFc=\">AAACAnicbVDLSgMxFM3UV62vUVfiJlgEV2VGi7osuHFZwT6gM5RMeqcNzWSGJCOUobjxV9y4UMStX+HOvzHTzkJbD4Qczrn3JvcECWdKO863VVpZXVvfKG9WtrZ3dvfs/YO2ilNJoUVjH', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 345: ('weSUMi8kUry+9JJ9HTat6tOzZkBLxO3IFVUoNm3v7xBTNMIhKacKNVzzRw/I1IzymFa8VIFZv6YDKFnqCARKD+brTDFp0YZ4DCW5giNZ+rvjoxESk2iwFRGRI/UopeL/3m9VIfXfsZEkmoQdP5QmHKsY5zngQdMAtV8Ygihkpm/YjoiJg9tUquYENzFlZdJ+7zmXtScu3q1US/iKKNjdILOkIuuUAPdoiZqIYoe0TN6RW/Wk/VivVsf89KSVfQcoj+wPn8A712XuA==</latexit>\\nVQVAEDiscretizeImage Tokenizer\\nCz}|{\\n<latexit sha1_base64=\"WkmkOQqV4y/G2CwEGjey+GFekFc=\">AAACAnicbVDLSgMxFM3UV62vUVfiJlgEV2VGi7osuHFZwT6gM5RMeqcNzWSGJCOUobjxV9y4UMStX+HOvzHTzkJbD4Qczrn3JvcECWdKO863VVpZXVvfKG9WtrZ3dvfs/YO2ilNJoUVjHstuQBRwJqClmebQTSSQKODQCcY3ud95AKlYLO71JAE/IkPBQkaJNlLfPvJiYweSUMi8kUry+9JJ9HTat6tOzZkBLxO3IFVUoNm3v7xBTNMIhKacKNVzzRw/I1IzymFa8VIFZv6YDKFnqCARKD+brTDFp0YZ4DCW5giNZ+rvjoxESk2iwFRGRI/UopeL/3m9VIfXfsZEkmoQdP5QmHKsY5zngQdMAtV8Ygihkpm/YjoiJg9tUquYENzFlZdJ+7zmXtScu3q1US/iKKNjdILOkIuuUAPdoiZqIYoe0TN6RW/Wk/VivVsf89KSVfQcoj+wPn8A712XuA==</latexit>Sequence 1Sequence 2z}|{\\n<latexit sha1_base64=\"WkmkOQqV4y/G2CwEGjey+GFekFc=\">AAACAnicbVDLSgMxFM3UV62vUVfiJlgEV2VGi7osuHFZwT6gM5RMeqcNzWSGJCOUobjxV9y4UMStX+HOvzHTzkJbD4Qczrn3JvcECWdKO863VVpZXVvfKG9WtrZ3dvfs/YO2ilNJoUVjHstuQBRwJqClmebQTSSQKODQCcY3ud95AKlYLO71JAE/IkPBQkaJNlLfPvJiYweSUMi8kUry+9JJ9HTat6tOzZkBLxO3IFVUoNm3v7xBTNMIhKacKNVzzRw/I1IzymFa8VIFZv6YDKFnqCARKD+brTDFp0YZ4DCW5giNZ+rvjoxESk2iwFRGRI/UopeL/3m9VIfXfsZEkmoQdP5QmHKsY5zngQdMAtV8Ygihkpm/YjoiJg9tUquYENzFlZdJ+7zmXtScu3q1US/iKKNjdILOkIuuUAPdoiZqIYoe0TN6RW/Wk/VivVsf89KSVfQcoj+wPn8A712XuA==</latexit>\\nInterpolateframesInput Frames:Figure 2: Multi-frame-rate hierarchical generation framework in CogVideo. Input sequence includes\\nframe rate, text, frame tokens. [B] (Begin-of-image) is a separator token, inherited from CogView2.\\nIn stage 1,Tsframes are generated sequentially on condition of frame rate and text. Then in stage\\n2, generated frames are re-input as bidirectional attention regions to recursively interpolate frames.\\nFrame rate can be adjusted during both stages. Bidirectional attention regions are highlighted in\\nblue , and unidirectional regions are highlighted in green .\\nTherefore, in each training sample, we want the', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 346: ('udes\\nframe rate, text, frame tokens. [B] (Begin-of-image) is a separator token, inherited from CogView2.\\nIn stage 1,Tsframes are generated sequentially on condition of frame rate and text. Then in stage\\n2, generated frames are re-input as bidirectional attention regions to recursively interpolate frames.\\nFrame rate can be adjusted during both stages. Bidirectional attention regions are highlighted in\\nblue , and unidirectional regions are highlighted in green .\\nTherefore, in each training sample, we want the text and the frames to match as possible. We\\npredeﬁned a series of frame rates, and select the lowest frame rate for each text-video pair, as long as\\nwe can sample at least 5 frames at this frame rate in the video.\\nAlthough the above method increases the alignment of text and video, the generation at a low frame\\nrate could be incoherent. We train another frame interpolation model to insert transition frames to the\\ngenerated samples of the sequential generation model. Thanks to the generality of CogLM [ 6], the\\ntwo models can share the same structure and training process only with different attention masks.\\nGeneration. The multi-frame-rate hierarchical generation is a recursive process, illustrated in\\nFigure 2. Speciﬁcally, the generation pipeline consists of a sequential generation stage and a recursive\\ninterpolation stage:\\n(1)Sequentially generate Tskey frames based on a low frame rate and text. The input sequence\\nis[{Frame Rate}{Text} [B] {Frame 1} ... {Frame Ts}]. In practice, we always set\\nTs= 5and the minimum sampling frame rate to 1 fps.\\n(2)Recursively interpolate frames based on the text, frame rate and known frames. In each round\\nof interpolation, we split generated frames into multiple dTs\\n2e-frame blocks overlapping at the\\nbeginning and the end, and interpolate a frame between the successive frames in each block.\\nThe input sequence is [{Frame Rate}{Text} [B] {Frame1} ... {Frame Ts}], where\\nFrame 2i(i= 1;2;:::;bTs\\n2c)are to be autoregressively generated. By recursively halﬁng {Frame\\nRate} , we can con', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 347: ('inimum sampling frame rate to 1 fps.\\n(2)Recursively interpolate frames based on the text, frame rate and known frames. In each round\\nof interpolation, we split generated frames into multiple dTs\\n2e-frame blocks overlapping at the\\nbeginning and the end, and interpolate a frame between the successive frames in each block.\\nThe input sequence is [{Frame Rate}{Text} [B] {Frame1} ... {Frame Ts}], where\\nFrame 2i(i= 1;2;:::;bTs\\n2c)are to be autoregressively generated. By recursively halﬁng {Frame\\nRate} , we can conduct ﬁner and ﬁner interpolation to generate videos of many frames.\\nThe effect of CogLM. Tasks such as frame interpolation rely heavily on bidirectional information.\\nHowever, most previous works use GPT [ 34,36,35], which is unidirectional. To be aware of the\\nbidirectional context, we adopt Cross-Modal General Language Model (CogLM) proposed in [ 6]\\nwhich unites bidirectional context-aware mask prediction and autoregressive generation by dividing\\ntokens into unidirectional and bidirectional attention regions. While bidirectional regions can attend\\nto all bidirectional regions, unidirectional regions can attend to all bidirectional regions and previous\\nunidirectional regions. As shown in 2, (1) all frames in stage 1 and the 2nd, 4th frames in stage\\n4\\n2 are in the unidirectional region; (2) {Frame Rate} ,{Text} and all other frames belong to the\\nbidirectional region. In this way, bidirectional attention context is fully exploited in text and given\\nframes without interfering with auto-regressive frame prediction.\\n3.2 Dual-channel Attention\\nLayer NormAttention-base(Spatial Channel)Attention-plus(Temporal Channel)AdditionLayer Norm\\nAdditionDual-channel Attention\\nFigure 3: The dual-channel at-\\ntention block. We initialize\\nthe Attention-plus the same as\\nAttention-base so that the model\\nbehaves exactly the same as\\nCogView2 when it is initialized.Large-scale pretraining usually demands a large dataset. For the\\nopen-domain text-to-video generation, ideally we need the dataset\\nto cover sufﬁcient text-video pairs to infer ', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 348: ('.\\n3.2 Dual-channel Attention\\nLayer NormAttention-base(Spatial Channel)Attention-plus(Temporal Channel)AdditionLayer Norm\\nAdditionDual-channel Attention\\nFigure 3: The dual-channel at-\\ntention block. We initialize\\nthe Attention-plus the same as\\nAttention-base so that the model\\nbehaves exactly the same as\\nCogView2 when it is initialized.Large-scale pretraining usually demands a large dataset. For the\\nopen-domain text-to-video generation, ideally we need the dataset\\nto cover sufﬁcient text-video pairs to infer both spatial and tem-\\nporal correlation between video and text. However, to collect\\nhigh-quality text-video pairs is often difﬁcult, expensive and time-\\nconsuming.\\nA natural idea is to make use of the image data to facilitate the\\nlearning of spatial semantics. Video Diffusion Model [ 11] and\\nNÜWA [ 35] try to add text-image pairs into text-video training,\\nwhich achieves better results on multiple metrics. However, as\\nfor training a video-only generation model, adding image data\\nwill signiﬁcantly increase training costs, especially in large-scale\\npretraining scenarios.\\nIn this paper, we propose to leverage pretrained image generation\\nmodels instead of image data. Pretrained text-to-image models,\\ne.g. CogView2 [ 6], already have a good command of the text-\\nimage relations. The coverage of the dataset to train these models\\nis also larger than that of videos.\\nThe proposed technique is dual-channel attention , where we only add a new spatial-temporal attention\\nchannel to the pretrained CogView2 [ 6] at each transformer layer. All the parameters in the CogView2\\nare frozen in the training, and only the parameters in the newly added attention layer (See the attention-\\nplus in Figure 3) are trainable. We denote the original attention block in CogView2 as attention-base.\\nHere we also emphasize that directly ﬁnetuning CogView2 for text-to-video generation cannot well\\ninherit the knowledge, because the temporal attention follows a different attention pattern and quickly\\nruins the pretrained weights during the initial phase', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 349: ('ormer layer. All the parameters in the CogView2\\nare frozen in the training, and only the parameters in the newly added attention layer (See the attention-\\nplus in Figure 3) are trainable. We denote the original attention block in CogView2 as attention-base.\\nHere we also emphasize that directly ﬁnetuning CogView2 for text-to-video generation cannot well\\ninherit the knowledge, because the temporal attention follows a different attention pattern and quickly\\nruins the pretrained weights during the initial phase of training with large gradients.\\nSpeciﬁcally, the dual-channel attention block with Sandwich-LN [5] can be computed as\\nex=\\x0b\\x01attention-base (LayerNorm (xin))\\n+ (1\\x00\\x0b)\\x01attention-plus (LayerNorm (xin)); (1)\\nxout=xin+LayerNorm (ex): (2)\\nThe mixture factor \\x0bis a vector2(0;1)d, wheredis the hidden size of the input feature xin. To\\nrestrict the range of \\x0bwithin (0;1), we reparameterize it as \\x0b=sigmoid (a)2(0;1)d, where a2Rd\\nis a learnable parameter. The attention-plus block has the same shape of parameters as the normal\\nmulti-head attention block, attention-base, but differs in the procedure of computation as follows.\\nIn our training, we tried two kinds of attention, 3D local attention and 3D Swin [ 14] attention for\\nattention-plus block. Here we depict the 3D local attention, and the latter is a natural replacement\\nintroduced in section 3.3.\\nIn 3D local attention, the receptive ﬁeld (RF) for the token at (t;x;y )(where (t;x;y )corresponds to\\nthe coordination along time, height and width), is a 3D block with extent lt;lx;ly2N+:\\nRF(t;x;y )=f(k;i;j )\\x0c\\x0c\\x0cjx\\x00ij<lx;jy\\x00jj<ly;jt\\x00kj<lt;(k;i;j )=2Mask (t;x;y )g;(3)\\nwhere Mask (t;x;y )represents an attention mask for token (t;x;y ). In the sequential generation model\\n(Stage 1), the Mask ensures the auto-regressive order; In the interpolation model (Stage 2), the Mask\\nis designed as in as CogLM [6] to make the known frames visible to all the frames.\\nIt is worth noting that two channels are fused and share the same FFN in each layer, because FFN is a\\nmodule of heavy parameters co', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 350: (' lt;lx;ly2N+:\\nRF(t;x;y )=f(k;i;j )\\x0c\\x0c\\x0cjx\\x00ij<lx;jy\\x00jj<ly;jt\\x00kj<lt;(k;i;j )=2Mask (t;x;y )g;(3)\\nwhere Mask (t;x;y )represents an attention mask for token (t;x;y ). In the sequential generation model\\n(Stage 1), the Mask ensures the auto-regressive order; In the interpolation model (Stage 2), the Mask\\nis designed as in as CogLM [6] to make the known frames visible to all the frames.\\nIt is worth noting that two channels are fused and share the same FFN in each layer, because FFN is a\\nmodule of heavy parameters containing much vision knowledge. Due to the similarity between images\\nand videos, bringing its knowledge to the temporal channel will facilitate video modeling. Finally,\\nsharing FFN can reduce parameters, thus speeding up training and reducing memory overhead.\\n5\\n3.3 Shifted Window Attention in Auto-regressive Generation\\nTo further alleviate the large time and memory overhead in the temporal channel during training\\nand inference, we refer to Swin Attention [ 14]. The original Swin attention is only applied to\\nnon-autoregressive scenarios, we extend it to the autoregressive and temporal scenario by applying\\nan auto-regressive attention mask in the shifted windows.\\nt=it=i+1t=i+2\\nFigure 4: In 3D autoregressive swin attention (win-\\ndow size 2\\x022as an example), the token in the red\\nbox can only attend to (either directly or indirectly)\\nthe yellow or green tokens. The gray tokens in\\nthei-th frame and the token in the red box can be\\ngenerated in parallel.An interesting ﬁnding is that, the Swin atten-\\ntion provide a chance for parallel generation\\nin faraway regions of different frames , which\\nfurther accelerates the auto-regressive genera-\\ntion. The dependence of the generation of a\\nspeciﬁc token relies on\\n•Auto-regressive mask. A token can\\nonly attend to previous frames or to-\\nkens before itself in the current frame.\\n•Shifted window. Only tokens within\\nthe distance of window size in both\\nwidth and height dimensions can be\\ndirectly attended to.\\nAs shown in Figure 4, we can start generating\\nparts of the tokens in the follo', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 351: ('nce for parallel generation\\nin faraway regions of different frames , which\\nfurther accelerates the auto-regressive genera-\\ntion. The dependence of the generation of a\\nspeciﬁc token relies on\\n•Auto-regressive mask. A token can\\nonly attend to previous frames or to-\\nkens before itself in the current frame.\\n•Shifted window. Only tokens within\\nthe distance of window size in both\\nwidth and height dimensions can be\\ndirectly attended to.\\nAs shown in Figure 4, we can start generating\\nparts of the tokens in the following frames be-\\nfore ﬁnishing the generation of all the previous frames — they can work in parallel. Suppose X,Yis\\nthe height and width of each frame, and Ax,Ayare the height and width of shifted window. For two\\ntokens at (t1;x1;y1)and(t2;x2;y2),t1<t 2, the latter cannot attend to the former either directly or\\nindirectly if\\n(x1\\x00x2)Y+ (y1\\x00y2)\\x15(t2\\x00t1+ 1)(AxY+Ay); (4)\\nwhich means that the i-th token in the t-th frame can be generated with the (i\\x00AxY\\x00Ay)-th token\\nin the (t+ 1) -th frame in parallel. In this way, we can generate bXY\\nAxY+Ayctokens in parallel at most,\\nthus greatly enhance parallelism and accelerate inference compared to auto-regressive with standard\\nattention which can only generate one token at a time.\\n4 Training\\nBased on the methods above, the training details of CogVideo are listed as follows:\\nModel. The backbone of CogVideo in both stages is a Transformer with dual-channel attention.\\nThe Transformer has 48 layers, with a hidden size of 3,072 in each attention channel, 48 attention\\nheads and 9.4 billion parameters in total. Among them, 6 billion parameters are ﬁxed to CogView2’s\\nparameters, which include Position-wise Feed-Forward Networks (FFN), the spatial channel of dual-\\nchannel attention, ﬁrst frame’s positional embeddings and all image and text vocabulary embeddings.\\nThe speciﬁc implementation of Transformer structure is almost identical to CogView [ 5] such as\\nusing Sandwich LayerNorm and PB-Relax to stabilize training. Shifted CogLM attention window is\\nadopted in recursive interpolation mo', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 352: (' billion parameters in total. Among them, 6 billion parameters are ﬁxed to CogView2’s\\nparameters, which include Position-wise Feed-Forward Networks (FFN), the spatial channel of dual-\\nchannel attention, ﬁrst frame’s positional embeddings and all image and text vocabulary embeddings.\\nThe speciﬁc implementation of Transformer structure is almost identical to CogView [ 5] such as\\nusing Sandwich LayerNorm and PB-Relax to stabilize training. Shifted CogLM attention window is\\nadopted in recursive interpolation model with window size 10\\x0210.\\nDataset. We pretrain our model on a dataset of 5.4 million captioned videos with a spatial resolution\\nof160\\x02160(can be upsampled to 480\\x02480by CogView2). For the sequential generation model\\n(Stage 1), we adjust the frame rate in each sample to accommodate the whole video, while the\\nminimum frame rate is set to 1 fps. For the recursive interpolation model (Stage 2), we split videos\\ninto clips of different lengths to accommodate prediction on multiple frame rates including 2,4,8 fps.\\nPretraining. The sequence lengths in both stages are 2,065, consisting of 64 text tokens, 5 (frames)\\n\\x02400 (per frame) image tokens, and 1 seperator token. Both text and images are tokenized with\\nicetk2.The parameters are updated by Adam with max learning rate = 2\\x0210\\x004,\\x0c1= 0:9,\\x0c2= 0:95,\\nweight decay = 1\\x0210\\x002. See Appendix for pretraining details.\\n2https://github.com/THUDM/icetk\\n6\\nTable 1: (Left) Video generation performance on UCF-101. Class labels are used as the text inputs.\\n* means that the model is only trained on the training split of UCF-101. (Right) Video generation\\nperformance on Kinetics-600. The metrics are based on the 16-frame generated videos priming on\\nﬁrst 5 frames, following settings of Rakhimov et al. [17]. ** means that the ground truth used in\\nFVD testing is the reconstruction result of the tokenizer.\\nMethod IS ( \") FVD (#)\\nVideoGPT[36] 24.69 -\\nDVD-GAN[4] 27.38 -\\nTGANv2[20]* 28.87 1209\\nMoCoGAN-HD[24] 32.36 838\\nDIGAN[37]* 29.71 655\\nDIGAN[37] 32.70 577\\nTATS-base[9] 79.28 332\\nCogVideo (Ours) ', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 353: ('y trained on the training split of UCF-101. (Right) Video generation\\nperformance on Kinetics-600. The metrics are based on the 16-frame generated videos priming on\\nﬁrst 5 frames, following settings of Rakhimov et al. [17]. ** means that the ground truth used in\\nFVD testing is the reconstruction result of the tokenizer.\\nMethod IS ( \") FVD (#)\\nVideoGPT[36] 24.69 -\\nDVD-GAN[4] 27.38 -\\nTGANv2[20]* 28.87 1209\\nMoCoGAN-HD[24] 32.36 838\\nDIGAN[37]* 29.71 655\\nDIGAN[37] 32.70 577\\nTATS-base[9] 79.28 332\\nCogVideo (Ours) 50.46 626\\nCogVideo (Ours)** - 545Method FVD( #)\\nLatent Video Tranformer[17] 224.73\\nVideo Transformer[33] 170\\nDVD-GAN-FP[4] 69.15\\nTriVD-GAN-FP[15] 25.74\\nCogVideo (Ours) 109.23\\nCogVideo (Ours)** 59.55\\n5 Experiments\\n5.1 Machine Evaluation\\nMachine evaluation is conducted on two popular benchmarks for video generation, i.e., UCF101 [ 22]\\nand Kinetics-600 [ 3]. Following Rakhimov et al. [17], Yu et al. [37], we use Fréchet Video Distance\\n(FVD) [ 27] and Inception score (IS) [ 21] as metrics in the evaluation. FVD is calculated based on\\nI3D model[ 2] trained on Kinetics-400, and IS is based on C3D model [ 25] which was ﬁrst trained on\\nthe Sports-1M dataset [ 12] and then ﬁnetuned on the UCF101 dataset. Our evaluation code is the\\nsame as the ofﬁcial TGAN-v2 implementation3.\\nUCF-101 is a human action dataset consisting of 13,320 videos annotated with 101 action classes.\\nDue to the gaps of image style and frame rate between CogVideo’s training set and UCF-101, we use\\nclass labels as the input text and ﬁnetune CogVideo on the whole dataset for 10,000 iterations with a\\nbatch size of 192. During inference, we generate samples of various classes according to the class\\ndistribution. FVD and IS are evaluated over 2,048 and 10,000 samples respectively, following Yu\\net al. [37]. Results are shown in Table 1 (Left).\\nKinetics-600 contains 600 classes of human action videos, with roughly 350,000 train and 50,000 test\\nvideos in total. We use the action category as input text, and ﬁnetune CogVideo on the training set for\\n12,000 itera', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 354: ('on the whole dataset for 10,000 iterations with a\\nbatch size of 192. During inference, we generate samples of various classes according to the class\\ndistribution. FVD and IS are evaluated over 2,048 and 10,000 samples respectively, following Yu\\net al. [37]. Results are shown in Table 1 (Left).\\nKinetics-600 contains 600 classes of human action videos, with roughly 350,000 train and 50,000 test\\nvideos in total. We use the action category as input text, and ﬁnetune CogVideo on the training set for\\n12,000 iterations with a batch size of 640. Following the setup of Weissenborn et al. [33], Rakhimov\\net al. [17], we center-crop and downsample each frame to 64 \\x0264 to measure the FVD of the model.\\nResults are shown in Table 1 (Right).\\n5.2 Human Evaluation\\nTo further evaluate CogVideo, we invite 90 anonymous evaluators to rate for CogVideo and other open-\\nsource baselines including GAN-based model TGANv2 [ 20] and GPT-based model VideoGPT [ 36].\\n30 classes in UCF101 are randomly picked as text conditions, and several aspects are rated (See\\nAppendix for details). For VideoGPT, we use the ofﬁcial unconditional pretrained model4to generate\\nsamples. For TGANv2, we use the ofﬁcial source code to train an unconditional generation model\\nunder the same setting as that in Saito et al. [20]. To assign unconditionally generated samples\\ninto corresponding categories, we choose TSM [ 13] as the action recognition model for a post-\\nclassiﬁcation. We only keep the samples whose likelihood to a certain class is at least 80%. Results\\nin Figure 5 show that CogVideo signiﬁcantly outperforms baselines on multiple important aspects\\nincluding frame texture, motion realism and semantic relevance, and achieves the top score by the\\noverall quality. It can be seen that 49.53% evaluators choose CogVideo as the best method, and only\\n15.42% and 5.6% favor VideoGPT and TGANv2, respectively.\\n3https://github.com/pfnet-research/tgan2\\n4https://github.com/wilson1yan/VideoGPT\\n7\\n(c) Scores (1-5) on three important aspects. (b) Overall scores (1-10) for each m', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 355: ('Figure 5 show that CogVideo signiﬁcantly outperforms baselines on multiple important aspects\\nincluding frame texture, motion realism and semantic relevance, and achieves the top score by the\\noverall quality. It can be seen that 49.53% evaluators choose CogVideo as the best method, and only\\n15.42% and 5.6% favor VideoGPT and TGANv2, respectively.\\n3https://github.com/pfnet-research/tgan2\\n4https://github.com/wilson1yan/VideoGPT\\n7\\n(c) Scores (1-5) on three important aspects. (b) Overall scores (1-10) for each method.(a) Human preference. The percentage of being chosen as the best. Figure 5: Human evaluation results. “CogVideo 1Stage” refers to the method in ablation study, which\\nonly generates videos sequentially with the CogVideo’s Stage 1 to the desired number of frames.\\nTable 2: Ablation study on a 5,000-sample subset of Kinetics-600’s testset. FVD is evaluated on\\ngenerated 11-frame samples priming on 5 frames and the recovered ground-truth by the image\\ntokenizer. The setting column indicates the difference between each method and CogVideo. Models\\nof each setting are trained on Kinetics-600 trainset for 11,000 iterations with a batch size of 160.\\nMethod Setting FVD ( #)\\nCogVideo None 108.27\\n1-stage Generation( Noverlap = 1)\\x00hierarchical 137.13\\n1-stage Generation( Noverlap = 2)\\x00hierarchical 120.82\\nInitialized with CogView2 \\x00Pretrain 124.92\\nRandomly Initialized \\x00Pretrain\\x00CogView2 166.13\\n5.3 Ablation Study\\nTo verify the effectiveness of hierarchical multi-frame-rate generation and incorporating CogView2,\\nwe conduct ablation studies on Kinetics-600 and UCF-101 datasets. We will ﬁrst brieﬂy introduce\\nthe compared methods and analyze the quantitative results in § 5.3.1 and qualitative results in § 5.3.2\\nHierarchical multi-frame-rate generation. In comparison with CogVideo, we ﬁnetune a 1-stage\\nvideo generation model on Kinetics-600 from the sequential generation model in CogVideo, which\\ngenerates long videos by sliding windows. In each window, we generate the rest frames based on\\nNoverlap previous known frames. Larger N', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 356: (' ablation studies on Kinetics-600 and UCF-101 datasets. We will ﬁrst brieﬂy introduce\\nthe compared methods and analyze the quantitative results in § 5.3.1 and qualitative results in § 5.3.2\\nHierarchical multi-frame-rate generation. In comparison with CogVideo, we ﬁnetune a 1-stage\\nvideo generation model on Kinetics-600 from the sequential generation model in CogVideo, which\\ngenerates long videos by sliding windows. In each window, we generate the rest frames based on\\nNoverlap previous known frames. Larger Noverlap means more previous frames can be utilized\\nduring the inference, but will increase time overhead.\\nDual-channel attention with CogView2’s weights. To highlight the effectiveness of our ﬁnetuning\\nstrategy, we additionally ﬁnetune (1) a randomly initialized model, (2) a model incorporating\\nCogView2’s weights but leaving the temporal channel unﬁxed (equivalent to CogVideo without\\npretraining on videos) on Kinetics-600 for comparison.\\n5.3.1 Quantitative Evaluation\\nFigure 6: Training loss in ablation study.All aforementioned models have been trained for 11,000\\niterations with a batch size of 160. Quantitative results are\\nshown in Table 2. We can see that the hierarchical method\\nis clearly superior to the 1-stage generation with differ-\\nentNoverlap , and the model initialized with CogView2’s\\nweights has lower FVD than the randomly initialized one.\\nFigure 6 plots the training loss curve of (1) ﬁnetuning\\nCogVideo; (2) training model from random initialization;\\n(3) training model initialized with CogView2 and partially\\nﬁxed. We can see that CogView2 endows the model with\\n8\\n(c) Randomly Initialized\\n(d) Finetuned CogVideo, 1-Stage\\n(e) Finetuned CogVideo, 1-Stage(b) Initialized with CogView2 (a) Finetuned CogVideo, hierarchical generation\\nInput Text: LungeGiven frames:\\nFigure 7: Video samples in ablation study, which are generated priming on the class label and ﬁrst 5\\nframes in Kinetics-600. All samples are downsampled by extracting one in every three frames for\\ndisplay purposes. (a) Use ﬁnetuned CogVideo to hierarc', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 357: ('artially\\nﬁxed. We can see that CogView2 endows the model with\\n8\\n(c) Randomly Initialized\\n(d) Finetuned CogVideo, 1-Stage\\n(e) Finetuned CogVideo, 1-Stage(b) Initialized with CogView2 (a) Finetuned CogVideo, hierarchical generation\\nInput Text: LungeGiven frames:\\nFigure 7: Video samples in ablation study, which are generated priming on the class label and ﬁrst 5\\nframes in Kinetics-600. All samples are downsampled by extracting one in every three frames for\\ndisplay purposes. (a) Use ﬁnetuned CogVideo to hierarchically generate samples. (b) Train a model\\non Kinetics-600 which is initialized as and partially ﬁxed to CogView2, and hierarchically generate\\nsamples. (c) Train a model on Kinetics-600 which is randomly initialized, and hierarchically generate\\nsamples. (d)(e) Use ﬁnetuned CogVideo to generate frames in 1 stage with different Noverlap .\\na good initialization point from which the loss can decrease faster. Moreover, ﬁxing part of the\\nparameters reduces the time and memory cost.\\n5.3.2 Qualitative Evaluation\\nQualitative comparison is shown in Figure 7. While the model trained from random initialization\\ntends to produce irrational deformation, the model incorporating CogView2 is able to generate\\nrealistic objects, and the hierarchical generation performs better on content consistency and motion\\nrealism.\\nWe also conduct human evaluation between 1-stage and hierarchical video generation model under\\nthe same setting as in § 5.2. As shown in Figure 5, the hierarchical model, i.e. CogVideo, outperforms\\nthe 1-stage model on semantic relevance, motion realism as well as texture quality. This is probably\\nbecause the 1-stage model cannot estimate a proper intensity of change from the previous frames in\\nthe window, as shown in Figure 7(d)(e).\\n6 Conclusion\\nWe present CogVideo, to the best of our knowledge, the largest and the ﬁrst open-source pretrained\\ntransformer for text-to-video generation in general domain. CogVideo is also the ﬁrst attempt to\\nefﬁciently leverage the pretrained text-to-image generative model to the text-', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 358: ('el on semantic relevance, motion realism as well as texture quality. This is probably\\nbecause the 1-stage model cannot estimate a proper intensity of change from the previous frames in\\nthe window, as shown in Figure 7(d)(e).\\n6 Conclusion\\nWe present CogVideo, to the best of our knowledge, the largest and the ﬁrst open-source pretrained\\ntransformer for text-to-video generation in general domain. CogVideo is also the ﬁrst attempt to\\nefﬁciently leverage the pretrained text-to-image generative model to the text-to-video generation\\nmodel without hurting its image generation capacity. With the proposed multi-frame-rate hierarchical\\ntraining framework, CogVideo is endowed with a better understanding of text-video relations and\\nabilities to control the intensity of changes during generation. We extend swin attention to CogLM,\\nwhich achieves acceleration in both training and inference. There are still some limitations in\\nCogVideo, e.g. restriction on the length of the input sequence still exists due to the large scale of the\\nmodel and limitation of GPU memory, and we leave them for future work.\\nBroader Impact. This paper aims to advance the open-domain text-to-video generation, which\\nwill ease the effort of short video and digital art creation. The efﬁcient training method transfers\\nknowledge from text-to-image models to text-to-video models, which helps avoid training from\\nscratch, and thus reduces energy consumption and carbon emission. A negative impact is the risk of\\nmisinformation. To alleviate it, we can train an additional classiﬁer to discriminate the fakes. We\\nbelieve the beneﬁts outweigh the downsides.\\n9\\nAcknowledgments and Disclosure of Funding\\nWe would like to thank Zhao Xue, Shuai Zhao, Sha Yuan for their help in data collection, Weidong\\nGuo, Fengyu Rao, Zhaoyang Zeng, Mingkang Tang for their useful discussion, Hanxiao Qu for\\nmaintaining the machines and the computational resources supported by BAAI.\\nReferences\\n[1]T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,\\nP. Shyam, G. ', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 359: ('dditional classiﬁer to discriminate the fakes. We\\nbelieve the beneﬁts outweigh the downsides.\\n9\\nAcknowledgments and Disclosure of Funding\\nWe would like to thank Zhao Xue, Shuai Zhao, Sha Yuan for their help in data collection, Weidong\\nGuo, Fengyu Rao, Zhaoyang Zeng, Mingkang Tang for their useful discussion, Hanxiao Qu for\\nmaintaining the machines and the computational resources supported by BAAI.\\nReferences\\n[1]T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan,\\nP. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. arXiv preprint\\narXiv:2005.14165 , 2020.\\n[2]J. Carreira and A. Zisserman. Quo vadis, action recognition? a new model and the kinetics\\ndataset. In proceedings of the IEEE Conference on Computer Vision and Pattern Recognition ,\\npages 6299–6308, 2017.\\n[3]J. Carreira, E. Noland, A. Banki-Horvath, C. Hillier, and A. Zisserman. A short note about\\nkinetics-600. arXiv preprint arXiv:1808.01340 , 2018.\\n[4]A. Clark, J. Donahue, and K. Simonyan. Adversarial video generation on complex datasets.\\narXiv preprint arXiv:1907.06571 , 2019.\\n[5]M. Ding, Z. Yang, W. Hong, W. Zheng, C. Zhou, D. Yin, J. Lin, X. Zou, Z. Shao, H. Yang,\\net al. Cogview: Mastering text-to-image generation via transformers. Advances in Neural\\nInformation Processing Systems , 34, 2021.\\n[6]M. Ding, W. Zheng, W. Hong, and J. Tang. Cogview2: Faster and better text-to-image generation\\nvia hierarchical transformers. arXiv preprint arXiv:2204.14217 , 2022.\\n[7]P. Esser, R. Rombach, and B. Ommer. Taming transformers for high-resolution image synthesis.\\narXiv preprint arXiv:2012.09841 , 2020.\\n[8]C. Finn, I. Goodfellow, and S. Levine. Unsupervised learning for physical interaction through\\nvideo prediction. Advances in neural information processing systems , 29, 2016.\\n[9]S. Ge, T. Hayes, H. Yang, X. Yin, G. Pang, D. Jacobs, J.-B. Huang, and D. Parikh. Long\\nvideo generation with time-agnostic vqgan and time-sensitive transformer. arXiv preprint\\narXiv:2204.03638 , 2022.\\n[10] I. J. Goodfellow, J. Pouget-Aba', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 360: ('ming transformers for high-resolution image synthesis.\\narXiv preprint arXiv:2012.09841 , 2020.\\n[8]C. Finn, I. Goodfellow, and S. Levine. Unsupervised learning for physical interaction through\\nvideo prediction. Advances in neural information processing systems , 29, 2016.\\n[9]S. Ge, T. Hayes, H. Yang, X. Yin, G. Pang, D. Jacobs, J.-B. Huang, and D. Parikh. Long\\nvideo generation with time-agnostic vqgan and time-sensitive transformer. arXiv preprint\\narXiv:2204.03638 , 2022.\\n[10] I. J. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville,\\nand Y . Bengio. Generative adversarial networks. arXiv preprint arXiv:1406.2661 , 2014.\\n[11] J. Ho, T. Salimans, A. Gritsenko, W. Chan, M. Norouzi, and D. J. Fleet. Video diffusion models.\\narXiv preprint arXiv:2204.03458 , 2022.\\n[12] A. Karpathy, G. Toderici, S. Shetty, T. Leung, R. Sukthankar, and L. Fei-Fei. Large-scale video\\nclassiﬁcation with convolutional neural networks. In Proceedings of the IEEE conference on\\nComputer Vision and Pattern Recognition , pages 1725–1732, 2014.\\n[13] J. Lin, C. Gan, and S. Han. Tsm: Temporal shift module for efﬁcient video understanding. In\\nProceedings of the IEEE/CVF International Conference on Computer Vision , pages 7083–7093,\\n2019.\\n[14] Z. Liu, Y . Lin, Y . Cao, H. Hu, Y . Wei, Z. Zhang, S. Lin, and B. Guo. Swin transformer:\\nHierarchical vision transformer using shifted windows. In Proceedings of the IEEE/CVF\\nInternational Conference on Computer Vision , pages 10012–10022, 2021.\\n[15] P. Luc, A. Clark, S. Dieleman, D. d. L. Casas, Y . Doron, A. Cassirer, and K. Simonyan.\\nTransformation-based adversarial video prediction on large-scale data. arXiv preprint\\narXiv:2003.04035 , 2020.\\n[16] A. Miech, D. Zhukov, J.-B. Alayrac, M. Tapaswi, I. Laptev, and J. Sivic. Howto100m: Learning\\na text-video embedding by watching hundred million narrated video clips. In Proceedings of\\nthe IEEE/CVF International Conference on Computer Vision , pages 2630–2640, 2019.\\n10\\n[17] R. Rakhimov, D. V olkhonskiy, A. Artemov, D. Zorin, and E.', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 361: ('leman, D. d. L. Casas, Y . Doron, A. Cassirer, and K. Simonyan.\\nTransformation-based adversarial video prediction on large-scale data. arXiv preprint\\narXiv:2003.04035 , 2020.\\n[16] A. Miech, D. Zhukov, J.-B. Alayrac, M. Tapaswi, I. Laptev, and J. Sivic. Howto100m: Learning\\na text-video embedding by watching hundred million narrated video clips. In Proceedings of\\nthe IEEE/CVF International Conference on Computer Vision , pages 2630–2640, 2019.\\n10\\n[17] R. Rakhimov, D. V olkhonskiy, A. Artemov, D. Zorin, and E. Burnaev. Latent video transformer.\\narXiv preprint arXiv:2006.10704 , 2020.\\n[18] A. Ramesh, M. Pavlov, G. Goh, S. Gray, C. V oss, A. Radford, M. Chen, and I. Sutskever.\\nZero-shot text-to-image generation. arXiv preprint arXiv:2102.12092 , 2021.\\n[19] M. Saito, E. Matsumoto, and S. Saito. Temporal generative adversarial nets with singular\\nvalue clipping. In Proceedings of the IEEE international conference on computer vision , pages\\n2830–2839, 2017.\\n[20] M. Saito, S. Saito, M. Koyama, and S. Kobayashi. Train sparsely, generate densely: Memory-\\nefﬁcient unsupervised training of high-resolution temporal gan. International Journal of\\nComputer Vision , 128(10):2586–2606, 2020.\\n[21] T. Salimans, I. Goodfellow, W. Zaremba, V . Cheung, A. Radford, and X. Chen. Improved\\ntechniques for training gans. In Proceedings of the 30th International Conference on Neural\\nInformation Processing Systems , pages 2234–2242, 2016.\\n[22] K. Soomro, A. R. Zamir, and M. Shah. Ucf101: A dataset of 101 human actions classes from\\nvideos in the wild. arXiv preprint arXiv:1212.0402 , 2012.\\n[23] I. Sutskever, J. Martens, and G. Hinton. Generating text with recurrent neural networks. In\\nICML’11 , page 1017–1024, 2011.\\n[24] Y . Tian, J. Ren, M. Chai, K. Olszewski, X. Peng, D. N. Metaxas, and S. Tulyakov. A good image\\ngenerator is what you need for high-resolution video synthesis. arXiv preprint arXiv:2104.15069 ,\\n2021.\\n[25] D. Tran, L. Bourdev, R. Fergus, L. Torresani, and M. Paluri. Learning spatiotemporal features\\nwith 3d convolutional networks. I', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 362: ('e wild. arXiv preprint arXiv:1212.0402 , 2012.\\n[23] I. Sutskever, J. Martens, and G. Hinton. Generating text with recurrent neural networks. In\\nICML’11 , page 1017–1024, 2011.\\n[24] Y . Tian, J. Ren, M. Chai, K. Olszewski, X. Peng, D. N. Metaxas, and S. Tulyakov. A good image\\ngenerator is what you need for high-resolution video synthesis. arXiv preprint arXiv:2104.15069 ,\\n2021.\\n[25] D. Tran, L. Bourdev, R. Fergus, L. Torresani, and M. Paluri. Learning spatiotemporal features\\nwith 3d convolutional networks. In Proceedings of the IEEE international conference on\\ncomputer vision , pages 4489–4497, 2015.\\n[26] S. Tulyakov, M.-Y . Liu, X. Yang, and J. Kautz. Mocogan: Decomposing motion and content\\nfor video generation. In Proceedings of the IEEE conference on computer vision and pattern\\nrecognition , pages 1526–1535, 2018.\\n[27] T. Unterthiner, S. van Steenkiste, K. Kurach, R. Marinier, M. Michalski, and S. Gelly. To-\\nwards accurate generative models of video: A new metric & challenges. arXiv preprint\\narXiv:1812.01717 , 2018.\\n[28] A. van den Oord, O. Vinyals, and K. Kavukcuoglu. Neural discrete representation learning. In\\nProceedings of the 31st International Conference on Neural Information Processing Systems ,\\npages 6309–6318, 2017.\\n[29] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and\\nI. Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762 , 2017.\\n[30] C. V ondrick, H. Pirsiavash, and A. Torralba. Generating videos with scene dynamics. Advances\\nin neural information processing systems , 29, 2016.\\n[31] X. Wang, J. Wu, J. Chen, L. Li, Y .-F. Wang, and W. Y . Wang. Vatex: A large-scale, high-\\nquality multilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF\\nInternational Conference on Computer Vision , pages 4581–4591, 2019.\\n[32] Y . Wang, M. Long, J. Wang, Z. Gao, and P. S. Yu. Predrnn: Recurrent neural networks for\\npredictive learning using spatiotemporal lstms. Advances in neural information processing\\nsystems , 30, 2017.\\n[33] D. Weisse', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 363: ('ation processing systems , 29, 2016.\\n[31] X. Wang, J. Wu, J. Chen, L. Li, Y .-F. Wang, and W. Y . Wang. Vatex: A large-scale, high-\\nquality multilingual dataset for video-and-language research. In Proceedings of the IEEE/CVF\\nInternational Conference on Computer Vision , pages 4581–4591, 2019.\\n[32] Y . Wang, M. Long, J. Wang, Z. Gao, and P. S. Yu. Predrnn: Recurrent neural networks for\\npredictive learning using spatiotemporal lstms. Advances in neural information processing\\nsystems , 30, 2017.\\n[33] D. Weissenborn, O. Täckström, and J. Uszkoreit. Scaling autoregressive video models. arXiv\\npreprint arXiv:1906.02634 , 2019.\\n[34] C. Wu, L. Huang, Q. Zhang, B. Li, L. Ji, F. Yang, G. Sapiro, and N. Duan. Godiva: Generating\\nopen-domain videos from natural descriptions. arXiv preprint arXiv:2104.14806 , 2021.\\n11\\n[35] C. Wu, J. Liang, L. Ji, F. Yang, Y . Fang, D. Jiang, and N. Duan. N n\" uwa: Visual synthesis\\npre-training for neural visual world creation. arXiv preprint arXiv:2111.12417 , 2021.\\n[36] W. Yan, Y . Zhang, P. Abbeel, and A. Srinivas. Videogpt: Video generation using vq-vae and\\ntransformers. arXiv preprint arXiv:2104.10157 , 2021.\\n[37] S. Yu, J. Tack, S. Mo, H. Kim, J. Kim, J.-W. Ha, and J. Shin. Generating videos with dynamics-\\naware implicit generative adversarial networks. arXiv preprint arXiv:2202.10571 , 2022.\\nA Attention Analysis\\nTo explore the attention mechanism of dual-channel attention , we visualize (1) the attention distribu-\\ntion in the temporal channel and (2) the mixture factor \\x0bcontrolling the ratio between the spatial and\\ntemporal channel in equation 1.\\nFigure 8 visualizes the distribution among frames and texts in sequential generation (Stage 1) with\\nheat maps, where only 24 of 48 attention heads in 6 layers are shown for display purposes. The\\nattention patterns can be broadly classiﬁed into the following categories:\\n• Most of the attention is on the text. E.g. the attention heads in violet .\\n•Most of the attention is on a certain frame. E.g. the attention heads in pink focus mainly\\non the prev', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 364: ('ratio between the spatial and\\ntemporal channel in equation 1.\\nFigure 8 visualizes the distribution among frames and texts in sequential generation (Stage 1) with\\nheat maps, where only 24 of 48 attention heads in 6 layers are shown for display purposes. The\\nattention patterns can be broadly classiﬁed into the following categories:\\n• Most of the attention is on the text. E.g. the attention heads in violet .\\n•Most of the attention is on a certain frame. E.g. the attention heads in pink focus mainly\\non the previous frame; the attention heads in blue focus mainly on the ﬁrst frame besides\\nthe text; the attention heads in yellow focus mostly on the frame itself.\\n• Attention is spread over several frames. E.g. the attention heads in green .\\nSome attention heads exhibit a single pattern, while others may exhibit a mixture of them. Attention\\nheads in the same layer tend to show similar patterns. In lower layers (e.g. layer 4, 12) the heads\\ntend to allocate attention according to position, while in higher layers more attention is allocated to\\ntext (e.g. layer 44) or spread over multiple frames. One possible explanation is that there are more\\nhigh-level features in higher layers such as video semantics, by which more frames and texts can\\ninteract with each other to make high-level feature analysis.\\nIt is worth noting that many heads in temporal channel do not allocate much attention to the frame\\nitself, especially in higher layers, while attending to itself is important for inference. This shows that\\nthe CogVideo performs a certain degree of decoupling in the analysis of temporal and spatial features.\\nWhile the spatial channel is in charge of feature analysis within the frame, the temporal channel can\\nallocate more resources to explore relationships among different frames. We further illustrate this\\nperspective with Figure 9, which shows that features calculated by CogView2 in the spatial channel\\nare heavily relied on.\\nB Training Details\\nCogVideo consists of two models corresponding to two stages, i.e. sequential generation', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 365: (' a certain degree of decoupling in the analysis of temporal and spatial features.\\nWhile the spatial channel is in charge of feature analysis within the frame, the temporal channel can\\nallocate more resources to explore relationships among different frames. We further illustrate this\\nperspective with Figure 9, which shows that features calculated by CogView2 in the spatial channel\\nare heavily relied on.\\nB Training Details\\nCogVideo consists of two models corresponding to two stages, i.e. sequential generation and recursive\\ninterpolation. Both models have 7.7 billion parameters while 6 billion of them are ﬁxed to CogView2,\\nthus CogVideo has 9.4 billion different parameters in total.\\nCogVideo is trained on a dataset of 5.4 million captioned videos with a spatial resolution of 160 \\x02160\\n(can be upsampled to 480 \\x02480 by CogView2). Each model is pretrained separately. The model in\\nstage 1 is ﬁrst pretrained for 76,000 iterations on video clips with a minimum frame rate of 0.25\\nfps, then trained for 15,000 iterations with a minimum frame rate of 1 fps. The model in stage 2 is\\npretrained for 78,500 iterations with the frame rate of 2, 4, and 8 fps. Both models are trained in\\nFP16 with a batch size of 416, and optimized by Adam with max learning rate = 2\\x0210\\x004,\\x0c1= 0:9,\\n\\x0c2= 0:95, weight decay = 1\\x0210\\x002.\\n12\\nLayer 4Layer 12Layer 20Layer 28Layer 36Layer 44Figure 8: The attention distribution among frames and texts in sequential generation (Stage 1). Only\\n24 of 48 attention heads in 6 layers are selected for display purposes. Each attention head is visualized\\nwith a heat map of size 5 \\x026, where lighter color represents larger value. The 5 \\x025 block on the left\\nindicates the sum of attention scores (after softmax) between each pair of frames, and the rightmost\\ncolumn indicates the sum of the attention score of each frame to text. That is to say, the grid in\\nrow i column j ( j\\x145) representsP\\nx2Fi;y2Fjattnx;y, and the grid in row i column 6 representsP\\nx2Fi;y2Tattnx;y, whereFi,Tdenotes the set of tokens in the i-th frame and text resp', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 366: ('ch attention head is visualized\\nwith a heat map of size 5 \\x026, where lighter color represents larger value. The 5 \\x025 block on the left\\nindicates the sum of attention scores (after softmax) between each pair of frames, and the rightmost\\ncolumn indicates the sum of the attention score of each frame to text. That is to say, the grid in\\nrow i column j ( j\\x145) representsP\\nx2Fi;y2Fjattnx;y, and the grid in row i column 6 representsP\\nx2Fi;y2Tattnx;y, whereFi,Tdenotes the set of tokens in the i-th frame and text respectively, and\\nattnx;ydenotes the attention score of token x to y.\\nC Details about Human Evaluation\\nIn this section, we introduce more details about the human evaluation for measuring generation\\nquality. The conduction of our human evaluation generally follows previous works including Ramesh\\net al. [18], Ding et al. [5]\\nWe randomly extract 30 classes from UCF101 for video generation, using corresponding video\\nsamples in the dataset as ground truth items in the evaluation. Based on captions of selected classes,\\nwe generate video samples from models including TGANv2, VideoGPT, and our model, CogVideo.\\nTo further illustrate the effectiveness of hierarchical multi-frame-rate generation, we also include\\na 1-stage version of CogVideo model ﬁne-tuned on Kinetics-600 which is described in § 5.3. For\\nTGANv2, we use the ofﬁcial source code to train an unconditional generation model under the same\\nsetting as that in Saito et al. [20]. For VideoGPT, we use the ofﬁcial unconditional pretrained model\\nto generate samples. To assign unconditionally generated samples into corresponding categories, we\\nchoose TSM[ 13] as the action recognition model for a post-classiﬁcation. We only keep the samples\\nwhose likelihood to a certain class is at least 80%. A randomly selected subset of samples is displayed\\nin Figure 10.\\nFor each sample of the video mentioned above, we ask evaluators to give scores between 1 and 5 ( 5\\nindicates the best while 1 indicates the worst) from three aspects including frame texture, motion\\nrealism, and semantic', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 367: (' assign unconditionally generated samples into corresponding categories, we\\nchoose TSM[ 13] as the action recognition model for a post-classiﬁcation. We only keep the samples\\nwhose likelihood to a certain class is at least 80%. A randomly selected subset of samples is displayed\\nin Figure 10.\\nFor each sample of the video mentioned above, we ask evaluators to give scores between 1 and 5 ( 5\\nindicates the best while 1 indicates the worst) from three aspects including frame texture, motion\\nrealism, and semantic relevance. Then the evaluators are required to give a general score of quality\\nfor each sample between 1 and 10, where a higher score indicates better quality. After video samples\\n13\\n0 2 4 6 8 10 12 14 16 18 20 22 24 26 28 30 32 34 36 38 40 42 44 46\\nLayer0.00.10.20.30.40.50.60.7alpha\\nFigure 9: The scale factor \\x0bcontrolling the ratio between the spatial and temporal channel in\\nequation 1 in dual-channel attention. Only \\x0bin half of the layers are shown for display reasons. As \\x0b\\nis a vector of dimension 3072, we show the mean and variance among all of its dimensions in this\\nﬁgure.\\nCogVideoCogVideo(1 Stage)VideoGPT\\nTGANv2\\nGroundtruth\\nSkiing\\x0f\\x03ჶᵪBiking, Ḹᛔᤈ\\u1ae3\\nFigure 10: A subset of human evaluation samples. The captions are randomly selected from UCF-101.\\nThe original samples are clips of 16 frames, which are downsampled to 4 frames uniformly for display\\npurposes.\\nfrom each caption are all evaluated, the evaluators are asked to select the best one from them. We\\nshow snapshots of the evaluation website in Figure 11\\nThroughout the process of human evaluation, we invited nearly 100 anonymous evaluators, while 90\\nof them completed the whole evaluation and were counted in the ﬁnal results. None of the questions\\nin the evaluation have any time limit. We offer each evaluator 75 RMB as a reward for the evaluation.\\nResults of the human evaluation, including the average score and standard deviation for each group,\\nhave already been introduced in Figure 5 in the main body. As ground truth samples take an absolute\\npredominance i', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 368: ('Throughout the process of human evaluation, we invited nearly 100 anonymous evaluators, while 90\\nof them completed the whole evaluation and were counted in the ﬁnal results. None of the questions\\nin the evaluation have any time limit. We offer each evaluator 75 RMB as a reward for the evaluation.\\nResults of the human evaluation, including the average score and standard deviation for each group,\\nhave already been introduced in Figure 5 in the main body. As ground truth samples take an absolute\\npredominance in the best selection question, we have removed the part of ground truth samples in the\\nselection pie plot for clearer model comparison.\\n14\\nFigure 11: Snapshots of the evaluation website.\\n15', 'CogVideo Large-scale Pretraining for Text-to-Video.pdf'), 369: ('The Rise and Potential of Large Language Model\\nBased Agents: A Survey\\nZhiheng Xi∗†, Wenxiang Chen∗, Xin Guo∗, Wei He∗, Yiwen Ding∗, Boyang Hong∗,\\nMing Zhang∗, Junzhe Wang∗, Senjie Jin∗, Enyu Zhou∗,\\nRui Zheng, Xiaoran Fan, Xiao Wang, Limao Xiong, Yuhao Zhou, Weiran Wang,\\nChanghao Jiang, Yicheng Zou, Xiangyang Liu, Zhangyue Yin,\\nShihan Dou, Rongxiang Weng, Wensen Cheng,\\nQi Zhang†, Wenjuan Qin, Yongyan Zheng, Xipeng Qiu, Xuanjing Huang and Tao Gui†\\nFudan NLP Group\\nAbstract\\nFor a long time, humanity has pursued artificial intelligence (AI) equivalent to or\\nsurpassing the human level, with AI agents considered a promising vehicle for\\nthis pursuit. AI agents are artificial entities that sense their environment, make\\ndecisions, and take actions. Many efforts have been made to develop intelligent\\nagents, but they mainly focus on advancement in algorithms or training strategies\\nto enhance specific capabilities or performance on particular tasks. Actually, what\\nthe community lacks is a general and powerful model to serve as a starting point\\nfor designing AI agents that can adapt to diverse scenarios. Due to the versatile\\ncapabilities they demonstrate, large language models (LLMs) are regarded as\\npotential sparks for Artificial General Intelligence (AGI), offering hope for building\\ngeneral AI agents. Many researchers have leveraged LLMs as the foundation to\\nbuild AI agents and have achieved significant progress. In this paper, we perform\\na comprehensive survey on LLM-based agents. We start by tracing the concept\\nof agents from its philosophical origins to its development in AI, and explain\\nwhy LLMs are suitable foundations for agents. Building upon this, we present\\na general framework for LLM-based agents, comprising three main components:\\nbrain, perception, and action, and the framework can be tailored for different\\napplications. Subsequently, we explore the extensive applications of LLM-based\\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and human-\\nagent cooperation. Following this, we delve into', 'The Rise and Potential of Large Language Model.pdf'), 370: (' from its philosophical origins to its development in AI, and explain\\nwhy LLMs are suitable foundations for agents. Building upon this, we present\\na general framework for LLM-based agents, comprising three main components:\\nbrain, perception, and action, and the framework can be tailored for different\\napplications. Subsequently, we explore the extensive applications of LLM-based\\nagents in three aspects: single-agent scenarios, multi-agent scenarios, and human-\\nagent cooperation. Following this, we delve into agent societies, exploring the\\nbehavior and personality of LLM-based agents, the social phenomena that emerge\\nfrom an agent society, and the insights they offer for human society. Finally, we\\ndiscuss several key topics and open problems within the field. A repository for the\\nrelated papers at https://github.com/WooooDyy/LLM-Agent-Paper-List.\\n†Correspondence to: zhxi22@m.fudan.edu.cn, {qz, tgui}@fudan.edu.cn\\n∗Equal Contribution.arXiv:2309.07864v3  [cs.AI]  19 Sep 2023\\nContents\\n1 Introduction 4\\n2 Background 6\\n2.1 Origin of AI Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n2.2 Technological Trends in Agent Research . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.3 Why is LLM suitable as the primary component of an Agent’s brain? . . . . . . . . 9\\n3 The Birth of An Agent: Construction of LLM-based Agents 10\\n3.1 Brain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.1.1 Natural Language Interaction . . . . . . . . . . . . . . . . . . . . . . . . 12\\n3.1.2 Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n3.1.3 Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n3.1.4 Reasoning and Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n3.1.5 Transferability and Generalization . . . . . . . . . . . . . . . . . . . . . . 16\\n3.2 Perception . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n3.2.1 Textual Input . . . . . . . . . . . . . . . . . . . . . .', 'The Rise and Potential of Large Language Model.pdf'), 371: (' 12\\n3.1.2 Knowledge . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n3.1.3 Memory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\\n3.1.4 Reasoning and Planning . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\\n3.1.5 Transferability and Generalization . . . . . . . . . . . . . . . . . . . . . . 16\\n3.2 Perception . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n3.2.1 Textual Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n3.2.2 Visual Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n3.2.3 Auditory Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\\n3.2.4 Other Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n3.3 Action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19\\n3.3.1 Textual Output . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n3.3.2 Tool Using . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20\\n3.3.3 Embodied Action . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n4 Agents in Practice: Harnessing AI for Good 24\\n4.1 General Ability of Single Agent . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4.1.1 Task-oriented Deployment . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n4.1.2 Innovation-oriented Deployment . . . . . . . . . . . . . . . . . . . . . . . 27\\n4.1.3 Lifecycle-oriented Deployment . . . . . . . . . . . . . . . . . . . . . . . 27\\n4.2 Coordinating Potential of Multiple Agents . . . . . . . . . . . . . . . . . . . . . . 28\\n4.2.1 Cooperative Interaction for Complementarity . . . . . . . . . . . . . . . . 28\\n4.2.2 Adversarial Interaction for Advancement . . . . . . . . . . . . . . . . . . 30\\n4.3 Interactive Engagement between Human and Agent . . . . . . . . . . . . . . . . . 30\\n4.3.1 Instructor-Executor Paradigm . . . . . . . . . . . . . . . . . . . . . . . . 31\\n4.3.2 Equal Partnership Paradigm . . . . . . . . ', 'The Rise and Potential of Large Language Model.pdf'), 372: (' . . . . . . . . . . . 27\\n4.2 Coordinating Potential of Multiple Agents . . . . . . . . . . . . . . . . . . . . . . 28\\n4.2.1 Cooperative Interaction for Complementarity . . . . . . . . . . . . . . . . 28\\n4.2.2 Adversarial Interaction for Advancement . . . . . . . . . . . . . . . . . . 30\\n4.3 Interactive Engagement between Human and Agent . . . . . . . . . . . . . . . . . 30\\n4.3.1 Instructor-Executor Paradigm . . . . . . . . . . . . . . . . . . . . . . . . 31\\n4.3.2 Equal Partnership Paradigm . . . . . . . . . . . . . . . . . . . . . . . . . 32\\n5 Agent Society: From Individuality to Sociality 33\\n5.1 Behavior and Personality of LLM-based Agents . . . . . . . . . . . . . . . . . . . 34\\n5.1.1 Social Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34\\n2\\n5.1.2 Personality . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n5.2 Environment for Agent Society . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36\\n5.2.1 Text-based Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n5.2.2 Virtual Sandbox Environment . . . . . . . . . . . . . . . . . . . . . . . . 37\\n5.2.3 Physical Environment . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\\n5.3 Society Simulation with LLM-based Agents . . . . . . . . . . . . . . . . . . . . . 38\\n5.3.1 Key Properties and Mechanism of Agent Society . . . . . . . . . . . . . . 38\\n5.3.2 Insights from Agent Society . . . . . . . . . . . . . . . . . . . . . . . . . 39\\n5.3.3 Ethical and Social Risks in Agent Society . . . . . . . . . . . . . . . . . . 40\\n6 Discussion 41\\n6.1 Mutual Benefits between LLM Research and Agent Research . . . . . . . . . . . . 41\\n6.2 Evaluation for LLM-based Agents . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\n6.3 Security, Trustworthiness and Other Potential Risks of LLM-based Agents . . . . . 44\\n6.3.1 Adversarial Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n6.3.2 Trustworthiness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n6.3.3 Other Potentia', 'The Rise and Potential of Large Language Model.pdf'), 373: (' . . . . . . . . . . . . . . 40\\n6 Discussion 41\\n6.1 Mutual Benefits between LLM Research and Agent Research . . . . . . . . . . . . 41\\n6.2 Evaluation for LLM-based Agents . . . . . . . . . . . . . . . . . . . . . . . . . . 42\\n6.3 Security, Trustworthiness and Other Potential Risks of LLM-based Agents . . . . . 44\\n6.3.1 Adversarial Robustness . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n6.3.2 Trustworthiness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44\\n6.3.3 Other Potential Risks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n6.4 Scaling Up the Number of Agents . . . . . . . . . . . . . . . . . . . . . . . . . . 45\\n6.5 Open Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\\n7 Conclusion 48\\n3\\n1 Introduction\\n“If they find a parrot who could answer to everything, I would claim it to be an\\nintelligent being without hesitation. ”\\n—Denis Diderot, 1875\\nArtificial Intelligence (AI) is a field dedicated to designing and developing systems that can replicate\\nhuman-like intelligence and abilities [ 1]. As early as the 18th century, philosopher Denis Diderot\\nintroduced the idea that if a parrot could respond to every question, it could be considered intelligent\\n[2]. While Diderot was referring to living beings, like the parrot, his notion highlights the profound\\nconcept that a highly intelligent organism could resemble human intelligence. In the 1950s, Alan\\nTuring expanded this notion to artificial entities and proposed the renowned Turing Test [ 3]. This\\ntest is a cornerstone in AI and aims to explore whether machines can display intelligent behavior\\ncomparable to humans. These AI entities are often termed “agents”, forming the essential building\\nblocks of AI systems. Typically in AI, an agent refers to an artificial entity capable of perceiving its\\nsurroundings using sensors, making decisions, and then taking actions in response using actuators\\n[1; 4].\\nThe concept of agents originated in Philosophy, with roots tracing back to thinkers like Ar', 'The Rise and Potential of Large Language Model.pdf'), 374: ('st [ 3]. This\\ntest is a cornerstone in AI and aims to explore whether machines can display intelligent behavior\\ncomparable to humans. These AI entities are often termed “agents”, forming the essential building\\nblocks of AI systems. Typically in AI, an agent refers to an artificial entity capable of perceiving its\\nsurroundings using sensors, making decisions, and then taking actions in response using actuators\\n[1; 4].\\nThe concept of agents originated in Philosophy, with roots tracing back to thinkers like Aristotle\\nand Hume [ 5]. It describes entities possessing desires, beliefs, intentions, and the ability to take\\nactions [ 5]. This idea transitioned into computer science, intending to enable computers to understand\\nusers’ interests and autonomously perform actions on their behalf [ 6;7;8]. As AI advanced, the term\\n“agent” found its place in AI research to depict entities showcasing intelligent behavior and possessing\\nqualities like autonomy, reactivity, pro-activeness, and social ability [ 4;9]. Since then, the exploration\\nand technical advancement of agents have become focal points within the AI community [ 1;10]. AI\\nagents are now acknowledged as a pivotal stride towards achieving Artificial General Intelligence\\n(AGI)1, as they encompass the potential for a wide range of intelligent activities [4; 11; 12].\\nFrom the mid-20th century, significant strides were made in developing smart AI agents as research\\ndelved deep into their design and advancement [ 13;14;15;16;17;18]. However, these efforts have\\npredominantly focused on enhancing specific capabilities, such as symbolic reasoning, or mastering\\nparticular tasks like Go or Chess [ 19;20;21]. Achieving a broad adaptability across varied scenarios\\nremained elusive. Moreover, previous studies have placed more emphasis on the design of algorithms\\nand training strategies, overlooking the development of the model’s inherent general abilities like\\nknowledge memorization, long-term planning, effective generalization, and efficient interaction\\n[22;23]. Actually, enhanci', 'The Rise and Potential of Large Language Model.pdf'), 375: ('tly focused on enhancing specific capabilities, such as symbolic reasoning, or mastering\\nparticular tasks like Go or Chess [ 19;20;21]. Achieving a broad adaptability across varied scenarios\\nremained elusive. Moreover, previous studies have placed more emphasis on the design of algorithms\\nand training strategies, overlooking the development of the model’s inherent general abilities like\\nknowledge memorization, long-term planning, effective generalization, and efficient interaction\\n[22;23]. Actually, enhancing the inherent capabilities of the model is the pivotal factor for advancing\\nthe agent further, and the domain is in need of a powerful foundational model endowed with a variety\\nof key attributes mentioned above to serve as a starting point for agent systems.\\nThe development of large language models (LLMs) has brought a glimmer of hope for the further\\ndevelopment of agents [ 24;25;26], and significant progress has been made by the community\\n[22;27;28;29]. According to the notion of World Scope (WS) [ 30] which encompasses five\\nlevels that depict the research progress from NLP to general AI (i.e., Corpus, Internet, Perception,\\nEmbodiment, and Social), the pure LLMs are built on the second level with internet-scale textual\\ninputs and outputs. Despite this, LLMs have demonstrated powerful capabilities in knowledge\\nacquisition, instruction comprehension, generalization, planning, and reasoning, while displaying\\neffective natural language interactions with humans. These advantages have earned LLMs the\\ndesignation of sparks for AGI [ 31], making them highly desirable for building intelligent agents to\\nfoster a world where humans and agents coexist harmoniously [ 22]. Starting from this, if we elevate\\nLLMs to the status of agents and equip them with an expanded perception space and action space,\\nthey have the potential to reach the third and fourth levels of WS. Furthermore, these LLMs-based\\nagents can tackle more complex tasks through cooperation or competition, and emergent social\\nphenomena can be observed when pla', 'The Rise and Potential of Large Language Model.pdf'), 376: (' of sparks for AGI [ 31], making them highly desirable for building intelligent agents to\\nfoster a world where humans and agents coexist harmoniously [ 22]. Starting from this, if we elevate\\nLLMs to the status of agents and equip them with an expanded perception space and action space,\\nthey have the potential to reach the third and fourth levels of WS. Furthermore, these LLMs-based\\nagents can tackle more complex tasks through cooperation or competition, and emergent social\\nphenomena can be observed when placing them together, potentially achieving the fifth WS level. As\\nshown in Figure 1, we envision a harmonious society composed of AI agents where human can also\\nparticipate.\\nIn this paper, we present a comprehensive and systematic survey focusing on LLM-based agents,\\nattempting to investigate the existing studies and prospective avenues in this burgeoning field. To this\\nend, we begin by delving into crucial background information (§ 2). In particular, we commence by\\ntracing the origin of AI agents from philosophy to the AI domain, along with a brief overview of the\\n1Also known as Strong AI.\\n4\\nLet me experience thefestival inthis world...User\\nMulti-AgentOrdering dishes and cooking Taskplanning and solving\\nBand performingDiscussing decoration\\nKitchen\\nConcertCooperationOutdoorsActingwithtools\\nAn Envisioned Agent SocietyFigure 1: Scenario of an envisioned society composed of AI agents, in which humans can also\\nparticipate. The above image depicts some specific scenes within society. In the kitchen, one agent\\norders dishes, while another agent is responsible for planning and solving the cooking task. At the\\nconcert, three agents are collaborating to perform in a band. Outdoors, two agents are discussing\\nlantern-making, planning the required materials, and finances by selecting and using tools. Users can\\nparticipate in any of these stages of this social activity.\\ndebate surrounding the existence of artificial agents (§ 2.1). Next, we take the lens of technological\\ntrends to provide a concise historical review of the d', 'The Rise and Potential of Large Language Model.pdf'), 377: ('s dishes, while another agent is responsible for planning and solving the cooking task. At the\\nconcert, three agents are collaborating to perform in a band. Outdoors, two agents are discussing\\nlantern-making, planning the required materials, and finances by selecting and using tools. Users can\\nparticipate in any of these stages of this social activity.\\ndebate surrounding the existence of artificial agents (§ 2.1). Next, we take the lens of technological\\ntrends to provide a concise historical review of the development of AI agents (§ 2.2). Finally, we\\ndelve into an in-depth introduction of the essential characteristics of agents and elucidate why large\\nlanguage models are well-suited to serve as the main component of brains or controllers for AI agents\\n(§ 2.3).\\nInspired by the definition of the agent, we present a general conceptual framework for the LLM-\\nbased agents with three key parts: brain, perception, and action (§ 3), and the framework can be\\ntailored to suit different applications. We first introduce the brain, which is primarily composed of\\na large language model (§ 3.1). Similar to humans, the brain is the core of an AI agent because it\\nnot only stores crucial memories, information, and knowledge but also undertakes essential tasks\\nof information processing, decision-making, reasoning, and planning. It is the key determinant of\\nwhether the agent can exhibit intelligent behaviors. Next, we introduce the perception module (§\\n3.2). For an agent, this module serves a role similar to that of sensory organs for humans. Its primary\\nfunction is to expand the agent’s perceptual space from text-only to a multimodal space that includes\\ndiverse sensory modalities like text, sound, visuals, touch, smell, and more. This expansion enables\\nthe agent to better perceive information from the external environment. Finally, we present the action\\nmodule for expanding the action space of an agent (§ 3.3). Specifically, we expect the agent to be\\nable to possess textual output, take embodied actions, and use tools so that it ca', 'The Rise and Potential of Large Language Model.pdf'), 378: (' for humans. Its primary\\nfunction is to expand the agent’s perceptual space from text-only to a multimodal space that includes\\ndiverse sensory modalities like text, sound, visuals, touch, smell, and more. This expansion enables\\nthe agent to better perceive information from the external environment. Finally, we present the action\\nmodule for expanding the action space of an agent (§ 3.3). Specifically, we expect the agent to be\\nable to possess textual output, take embodied actions, and use tools so that it can better respond to\\nenvironmental changes and provide feedback, and even alter and shape the environment.\\nAfter that, we provide a detailed and thorough introduction to the practical applications of LLM-\\nbased agents and elucidate the foundational design pursuit—“Harnessing AI for good” (§ 4). To start,\\nwe delve into the current applications of a single agent and discuss their performance in text-based\\ntasks and simulated exploration environments, with a highlight on their capabilities in handling\\nspecific tasks, driving innovation, and exhibiting human-like survival skills and adaptability (§ 4.1).\\nFollowing that, we take a retrospective look at the development history of multi-agents. We introduce\\nthe interactions between agents in LLM-based multi-agent system applications, where they engage in\\n5\\ncollaboration, negotiation, or competition. Regardless of the mode of interaction, agents collectively\\nstrive toward a shared objective (§ 4.2). Lastly, considering the potential limitations of LLM-based\\nagents in aspects such as privacy security, ethical constraints, and data deficiencies, we discuss\\nthe human-agent collaboration. We summarize the paradigms of collaboration between agents and\\nhumans: the instructor-executor paradigm and the equal partnership paradigm, along with specific\\napplications in practice (§ 4.3).\\nBuilding upon the exploration of practical applications of LLM-based agents, we now shift our\\nfocus to the concept of the “ Agent Society ”, examining the intricate interactions between agents and\\nt', 'The Rise and Potential of Large Language Model.pdf'), 379: ('aspects such as privacy security, ethical constraints, and data deficiencies, we discuss\\nthe human-agent collaboration. We summarize the paradigms of collaboration between agents and\\nhumans: the instructor-executor paradigm and the equal partnership paradigm, along with specific\\napplications in practice (§ 4.3).\\nBuilding upon the exploration of practical applications of LLM-based agents, we now shift our\\nfocus to the concept of the “ Agent Society ”, examining the intricate interactions between agents and\\ntheir surrounding environments (§ 5). This section begins with an investigation into whether these\\nagents exhibit human-like behavior and possess corresponding personality (§5.1). Furthermore, we\\nintroduce the social environments within which the agents operate, including text-based environment,\\nvirtual sandbox, and the physical world (§5.2). Unlike the previous section (§ 3.2), here we will\\nfocus on diverse types of the environment rather than how the agents perceive it. Having established\\nthe foundation of agents and their environments, we proceed to unveil the simulated societies that\\nthey form (§5.3). We will discuss the construction of a simulated society, and go on to examine the\\nsocial phenomena that emerge from it. Specifically, we will emphasize the lessons and potential risks\\ninherent in simulated societies.\\nFinally, we discuss a range of key topics (§ 6) and open problems within the field of LLM-based\\nagents: (1) the mutual benefits and inspirations of the LLM research and the agent research, where\\nwe demonstrate that the development of LLM-based agents has provided many opportunities for\\nboth agent and LLM communities (§ 6.1); (2) existing evaluation efforts and some prospects for\\nLLM-based agents from four dimensions, including utility, sociability, values and the ability to\\ncontinually evolve (§ 6.2); (3) potential risks of LLM-based agents, where we discuss adversarial\\nrobustness and trustworthiness of LLM-based agents. We also include the discussion of some other\\nrisks like misuse, unemployment a', 'The Rise and Potential of Large Language Model.pdf'), 380: ('we demonstrate that the development of LLM-based agents has provided many opportunities for\\nboth agent and LLM communities (§ 6.1); (2) existing evaluation efforts and some prospects for\\nLLM-based agents from four dimensions, including utility, sociability, values and the ability to\\ncontinually evolve (§ 6.2); (3) potential risks of LLM-based agents, where we discuss adversarial\\nrobustness and trustworthiness of LLM-based agents. We also include the discussion of some other\\nrisks like misuse, unemployment and the threat to the well-being of the human race (§ 6.3); (4)\\nscaling up the number of agents, where we discuss the potential advantages and challenges of scaling\\nup agent counts, along with the approaches of pre-determined and dynamic scaling (§ 6.4); (5) several\\nopen problems, such as the debate over whether LLM-based agents represent a potential path to AGI,\\nchallenges from virtual simulated environment to physical environment, collective Intelligence in AI\\nagents, and Agent as a Service (§ 6.5). After all, we hope this paper could provide inspiration to the\\nresearchers and practitioners from relevant fields.\\n2 Background\\nIn this section, we provide crucial background information to lay the groundwork for the subsequent\\ncontent (§ 2.1). We first discuss the origin of AI agents, from philosophy to the realm of AI, coupled\\nwith a discussion of the discourse regarding the existence of artificial agents (§ 2.2). Subsequently,\\nwe summarize the development of AI agents through the lens of technological trends. Finally, we\\nintroduce the key characteristics of agents and demonstrate why LLMs are suitable to serve as the\\nmain part of the brains of AI agents (§ 2.3).\\n2.1 Origin of AI Agent\\n“Agent” is a concept with a long history that has been explored and interpreted in many fields. Here,\\nwe first explore its origins in philosophy, discuss whether artificial products can possess agency in a\\nphilosophical sense, and examine how related concepts have been introduced into the field of AI.\\nAgent in philosophy. The core ', 'The Rise and Potential of Large Language Model.pdf'), 381: ('Finally, we\\nintroduce the key characteristics of agents and demonstrate why LLMs are suitable to serve as the\\nmain part of the brains of AI agents (§ 2.3).\\n2.1 Origin of AI Agent\\n“Agent” is a concept with a long history that has been explored and interpreted in many fields. Here,\\nwe first explore its origins in philosophy, discuss whether artificial products can possess agency in a\\nphilosophical sense, and examine how related concepts have been introduced into the field of AI.\\nAgent in philosophy. The core idea of an agent has a historical background in philosophical\\ndiscussions, with its roots traceable to influential thinkers such as Aristotle and Hume, among others\\n[5]. In a general sense, an “agent” is an entity with the capacity to act, and the term “agency” denotes\\nthe exercise or manifestation of this capacity [ 5]. While in a narrow sense, “agency” is usually used to\\nrefer to the performance of intentional actions; and correspondingly, the term “agent” denotes entities\\nthat possess desires, beliefs, intentions, and the ability to act [ 32;33;34;35]. Note that agents can\\nencompass not only individual human beings but also other entities in both the physical and virtual\\nworld. Importantly, the concept of an agent involves individual autonomy, granting them the ability\\nto exercise volition, make choices, and take actions, rather than passively reacting to external stimuli.\\n6\\nFrom the perspective of philosophy, is artificial entities capable of agency? In a general sense,\\nif we define agents as entities with the capacity to act, AI systems do exhibit a form of agency [ 5].\\nHowever, the term agent is more usually used to refer to entities or subjects that possess consciousness,\\nintentionality, and the ability to act [ 32;33;34]. Within this framework, it’s not immediately clear\\nwhether artificial systems can possess agency, as it remains uncertain whether they possess internal\\nstates that form the basis for attributing desires, beliefs, and intentions. Some people argue that\\nattributing psychological states li', 'The Rise and Potential of Large Language Model.pdf'), 382: ('h the capacity to act, AI systems do exhibit a form of agency [ 5].\\nHowever, the term agent is more usually used to refer to entities or subjects that possess consciousness,\\nintentionality, and the ability to act [ 32;33;34]. Within this framework, it’s not immediately clear\\nwhether artificial systems can possess agency, as it remains uncertain whether they possess internal\\nstates that form the basis for attributing desires, beliefs, and intentions. Some people argue that\\nattributing psychological states like intention to artificial agents is a form of anthropomorphism and\\nlacks scientific rigor [ 5;36]. As Barandiaran et al. [ 36] stated, “Being specific about the requirements\\nfor agency has told us a lot about how much is still needed for the development of artificial forms of\\nagency.” In contrast, there are also researchers who believe that, in certain circumstances, employing\\nthe intentional stance (that is, interpreting agent behavior in terms of intentions) can provide a better\\ndescription, explanation and abstraction of the actions of artificial agents, much like it is done for\\nhumans [11; 37; 38].\\nWith the advancement of language models, the potential emergence of artificial intentional agents\\nappears more promising [ 24;25;39;40;41]. In a rigorous sense, language models merely function\\nas conditional probability models, using input to predict the next token [ 42]. Different from this,\\nhumans incorporate social and perceptual context, and speak according to their mental states [ 43;\\n44]. Consequently, some researchers argue that the current paradigm of language modeling is not\\ncompatible with the intentional actions of an agent [ 30;45]. However, there are also researchers\\nwho propose that language models can, in a narrow sense, serve as models of agents [ 46;47]. They\\nargue that during the process of context-based next-word prediction, current language models can\\nsometimes infer approximate, partial representations of the beliefs, desires, and intentions held by\\nthe agent who generated the context. With ', 'The Rise and Potential of Large Language Model.pdf'), 383: ('ome researchers argue that the current paradigm of language modeling is not\\ncompatible with the intentional actions of an agent [ 30;45]. However, there are also researchers\\nwho propose that language models can, in a narrow sense, serve as models of agents [ 46;47]. They\\nargue that during the process of context-based next-word prediction, current language models can\\nsometimes infer approximate, partial representations of the beliefs, desires, and intentions held by\\nthe agent who generated the context. With these representations, the language models can then\\ngenerate utterances like humans. To support their viewpoint, they conduct experiments to provide\\nsome empirical evidence [46; 48; 49].\\nIntroduction of agents into AI. It might come as a surprise that researchers within the mainstream\\nAI community devoted relatively minimal attention to concepts related to agents until the mid to late\\n1980s. Nevertheless, there has been a significant surge of interest in this topic within the realms of\\ncomputer science and artificial intelligence communities since then [ 50;51;52;53]. As Wooldridge\\net al. [ 4] stated, we can define AI by saying that it is a subfield of computer science that aims to\\ndesign and build computer-based agents that exhibit aspects of intelligent behavior. So we can treat\\n“agent” as a central concept in AI. When the concept of agent is introduced into the field of AI, its\\nmeaning undergoes some changes. In the realm of Philosophy, an agent can be a human, an animal,\\nor even a concept or entity with autonomy [ 5]. However, in the field of artificial intelligence, an\\nagent is a computational entity [ 4;7]. Due to the seemingly metaphysical nature of concepts like\\nconsciousness and desires for computational entities [ 11], and given that we can only observe the\\nbehavior of the machine, many AI researchers, including Alan Turing, suggest temporarily setting\\naside the question of whether an agent is “actually” thinking or literally possesses a “mind” [ 3].\\nInstead, researchers employ other attributes to hel', 'The Rise and Potential of Large Language Model.pdf'), 384: ('utonomy [ 5]. However, in the field of artificial intelligence, an\\nagent is a computational entity [ 4;7]. Due to the seemingly metaphysical nature of concepts like\\nconsciousness and desires for computational entities [ 11], and given that we can only observe the\\nbehavior of the machine, many AI researchers, including Alan Turing, suggest temporarily setting\\naside the question of whether an agent is “actually” thinking or literally possesses a “mind” [ 3].\\nInstead, researchers employ other attributes to help describe an agent, such as properties of autonomy,\\nreactivity, pro-activeness and social ability [ 4;9]. There are also researchers who held that intelligence\\nis “in the eye of the beholder”; it is not an innate, isolated property [ 15;16;54;55]. In essence, an\\nAI agent is not equivalent to a philosophical agent; rather, it is a concretization of the philosophical\\nconcept of an agent in the context of AI. In this paper, we treat AI agents as artificial entities that are\\ncapable of perceiving their surroundings using sensors, making decisions, and then taking actions in\\nresponse using actuators [1; 4].\\n2.2 Technological Trends in Agent Research\\nThe evolution of AI agents has undergone several stages, and here we take the lens of technological\\ntrends to review its development briefly.\\nSymbolic Agents. In the early stages of artificial intelligence research, the predominant approach\\nutilized was symbolic AI, characterized by its reliance on symbolic logic [ 56;57]. This approach\\nemployed logical rules and symbolic representations to encapsulate knowledge and facilitate reasoning\\nprocesses. Early AI agents were built based on this approach [ 58], and they primarily focused on two\\nproblems: the transduction problem and the representation/reasoning problem [ 59]. These agents\\nare aimed to emulate human thinking patterns. They possess explicit and interpretable reasoning\\n7\\nframeworks, and due to their symbolic nature, they exhibit a high degree of expressive capability\\n[13;14;60]. A classic example of this approach ', 'The Rise and Potential of Large Language Model.pdf'), 385: ('olic representations to encapsulate knowledge and facilitate reasoning\\nprocesses. Early AI agents were built based on this approach [ 58], and they primarily focused on two\\nproblems: the transduction problem and the representation/reasoning problem [ 59]. These agents\\nare aimed to emulate human thinking patterns. They possess explicit and interpretable reasoning\\n7\\nframeworks, and due to their symbolic nature, they exhibit a high degree of expressive capability\\n[13;14;60]. A classic example of this approach is knowledge-based expert systems. However,\\nsymbolic agents faced limitations in handling uncertainty and large-scale real-world problems\\n[19;20]. Additionally, due to the intricacies of symbolic reasoning algorithms, it was challenging to\\nfind an efficient algorithm capable of producing meaningful results within a finite timeframe [ 20;61].\\nReactive agents. Different from symbolic agents, reactive agents do not use complex symbolic\\nreasoning. Instead, they primarily focus on the interaction between the agent and its environment,\\nemphasizing quick and real-time responses [ 15;16;20;62;63]. These agents are mainly based on\\na sense-act loop, efficiently perceiving and reacting to the environment. The design of such agents\\nprioritizes direct input-output mappings rather than intricate reasoning and symbolic operations\\n[52]. However, Reactive agents also have limitations. They typically require fewer computational\\nresources, enabling quicker responses, but they might lack complex higher-level decision-making\\nand planning capabilities.\\nReinforcement learning-based agents. With the improvement of computational capabilities and\\ndata availability, along with a growing interest in simulating interactions between intelligent agents\\nand their environments, researchers have begun to utilize reinforcement learning methods to train\\nagents for tackling more challenging and complex tasks [ 17;18;64;65]. The primary concern in this\\nfield is how to enable agents to learn through interactions with their environments, enabling the', 'The Rise and Potential of Large Language Model.pdf'), 386: ('planning capabilities.\\nReinforcement learning-based agents. With the improvement of computational capabilities and\\ndata availability, along with a growing interest in simulating interactions between intelligent agents\\nand their environments, researchers have begun to utilize reinforcement learning methods to train\\nagents for tackling more challenging and complex tasks [ 17;18;64;65]. The primary concern in this\\nfield is how to enable agents to learn through interactions with their environments, enabling them to\\nachieve maximum cumulative rewards in specific tasks [ 21]. Initially, reinforcement learning (RL)\\nagents were primarily based on fundamental techniques such as policy search and value function\\noptimization, exemplified by Q-learning [ 66] and SARSA [ 67]. With the rise of deep learning, the\\nintegration of deep neural networks and reinforcement learning, known as Deep Reinforcement\\nLearning (DRL), has emerged [ 68;69]. This allows agents to learn intricate policies from high-\\ndimensional inputs, leading to numerous significant accomplishments like AlphaGo [ 70] and DQN\\n[71]. The advantage of this approach lies in its capacity to enable agents to autonomously learn in\\nunknown environments, without explicit human intervention. This allows for its wide application\\nin an array of domains, from gaming to robot control and beyond. Nonetheless, reinforcement\\nlearning faces challenges including long training times, low sample efficiency, and stability concerns,\\nparticularly when applied in complex real-world environments [21].\\nAgents with transfer learning and meta learning. Traditionally, training a reinforcement learning\\nagent requires huge sample sizes and long training time, and lacks generalization capability [ 72;\\n73;74;75;76]. Consequently, researchers have introduced transfer learning to expedite an agent’s\\nlearning on new tasks [ 77;78;79]. Transfer learning reduces the burden of training on new tasks\\nand facilitates the sharing and migration of knowledge across different tasks, thereby enhancing\\nlearning', 'The Rise and Potential of Large Language Model.pdf'), 387: ('ironments [21].\\nAgents with transfer learning and meta learning. Traditionally, training a reinforcement learning\\nagent requires huge sample sizes and long training time, and lacks generalization capability [ 72;\\n73;74;75;76]. Consequently, researchers have introduced transfer learning to expedite an agent’s\\nlearning on new tasks [ 77;78;79]. Transfer learning reduces the burden of training on new tasks\\nand facilitates the sharing and migration of knowledge across different tasks, thereby enhancing\\nlearning efficiency, performance, and generalization capabilities. Furthermore, meta-learning has also\\nbeen introduced to AI agents [ 80;81;82;83;84]. Meta-learning focuses on learning how to learn,\\nenabling an agent to swiftly infer optimal policies for new tasks from a small number of samples\\n[85]. Such an agent, when confronted with a new task, can rapidly adjust its learning approach by\\nleveraging acquired general knowledge and policies, consequently reducing the reliance on a large\\nvolume of samples. However, when there exist significant disparities between source and target tasks,\\nthe effectiveness of transfer learning might fall short of expectations and there may exist negative\\ntransfer [ 86;87]. Additionally, the substantial amount of pre-training and large sample sizes required\\nby meta learning make it hard to establish a universal learning policy [81; 88].\\nLarge language model-based agents. As large language models have demonstrated impressive\\nemergent capabilities and have gained immense popularity [ 24;25;26;41], researchers have started to\\nleverage these models to construct AI agents [ 22;27;28;89]. Specifically, they employ LLMs as the\\nprimary component of brain or controller of these agents and expand their perceptual and action space\\nthrough strategies such as multimodal perception and tool utilization [ 90;91;92;93;94]. These LLM-\\nbased agents can exhibit reasoning and planning abilities comparable to symbolic agents through\\ntechniques like Chain-of-Thought (CoT) and problem decomposition [ 95;96;97;9', 'The Rise and Potential of Large Language Model.pdf'), 388: ('5;26;41], researchers have started to\\nleverage these models to construct AI agents [ 22;27;28;89]. Specifically, they employ LLMs as the\\nprimary component of brain or controller of these agents and expand their perceptual and action space\\nthrough strategies such as multimodal perception and tool utilization [ 90;91;92;93;94]. These LLM-\\nbased agents can exhibit reasoning and planning abilities comparable to symbolic agents through\\ntechniques like Chain-of-Thought (CoT) and problem decomposition [ 95;96;97;98;99;100;101].\\nThey can also acquire interactive capabilities with the environment, akin to reactive agents, by\\nlearning from feedback and performing new actions [ 102;103;104]. Similarly, large language\\nmodels undergo pre-training on large-scale corpora and demonstrate the capacity for few-shot and\\nzero-shot generalization, allowing for seamless transfer between tasks without the need to update\\nparameters [ 41;105;106;107]. LLM-based agents have been applied to various real-world scenarios,\\n8\\nsuch as software development [ 108;109] and scientific research [ 110]. Due to their natural language\\ncomprehension and generation capabilities, they can interact with each other seamlessly, giving rise\\nto collaboration and competition among multiple agents [ 108;109;111;112]. Furthermore, research\\nsuggests that allowing multiple agents to coexist can lead to the emergence of social phenomena [ 22].\\n2.3 Why is LLM suitable as the primary component of an Agent’s brain?\\nAs mentioned before, researchers have introduced several properties to help describe and define\\nagents in the field of AI. Here, we will delve into some key properties, elucidate their relevance to\\nLLMs, and thereby expound on why LLMs are highly suited to serve as the main part of brains of AI\\nagents.\\nAutonomy. Autonomy means that an agent operates without direct intervention from humans\\nor others and possesses a degree of control over its actions and internal states [ 4;113]. This\\nimplies that an agent should not only possess the capability to follow expli', 'The Rise and Potential of Large Language Model.pdf'), 389: ('eral properties to help describe and define\\nagents in the field of AI. Here, we will delve into some key properties, elucidate their relevance to\\nLLMs, and thereby expound on why LLMs are highly suited to serve as the main part of brains of AI\\nagents.\\nAutonomy. Autonomy means that an agent operates without direct intervention from humans\\nor others and possesses a degree of control over its actions and internal states [ 4;113]. This\\nimplies that an agent should not only possess the capability to follow explicit human instructions for\\ntask completion but also exhibit the capacity to initiate and execute actions independently. LLMs\\ncan demonstrate a form of autonomy through their ability to generate human-like text, engage\\nin conversations, and perform various tasks without detailed step-by-step instructions [ 114;115].\\nMoreover, they can dynamically adjust their outputs based on environmental input, reflecting a\\ndegree of adaptive autonomy [ 23;27;104]. Furthermore, they can showcase autonomy through\\nexhibiting creativity like coming up with novel ideas, stories, or solutions that haven’t been explicitly\\nprogrammed into them [ 116;117]. This implies a certain level of self-directed exploration and\\ndecision-making. Applications like Auto-GPT [114] exemplify the significant potential of LLMs in\\nconstructing autonomous agents. Simply by providing them with a task and a set of available tools,\\nthey can autonomously formulate plans and execute them to achieve the ultimate goal.\\nReactivity. Reactivity in an agent refers to its ability to respond rapidly to immediate changes and\\nstimuli in its environment [ 9]. This implies that the agent can perceive alterations in its surroundings\\nand promptly take appropriate actions. Traditionally, the perceptual space of language models\\nhas been confined to textual inputs, while the action space has been limited to textual outputs.\\nHowever, researchers have demonstrated the potential to expand the perceptual space of LLMs using\\nmultimodal fusion techniques, enabling them to rapidly p', 'The Rise and Potential of Large Language Model.pdf'), 390: ('s to its ability to respond rapidly to immediate changes and\\nstimuli in its environment [ 9]. This implies that the agent can perceive alterations in its surroundings\\nand promptly take appropriate actions. Traditionally, the perceptual space of language models\\nhas been confined to textual inputs, while the action space has been limited to textual outputs.\\nHowever, researchers have demonstrated the potential to expand the perceptual space of LLMs using\\nmultimodal fusion techniques, enabling them to rapidly process visual and auditory information from\\nthe environment [ 25;118;119]. Similarly, it’s also feasible to expand the action space of LLMs\\nthrough embodiment techniques [ 120;121] and tool usage [ 92;94]. These advancements enable\\nLLMs to effectively interact with the real-world physical environment and carry out tasks within it.\\nOne major challenge is that LLM-based agents, when performing non-textual actions, require an\\nintermediate step of generating thoughts or formulating tool usage in textual form before eventually\\ntranslating them into concrete actions. This intermediary process consumes time and reduces the\\nresponse speed. However, this aligns closely with human behavioral patterns, where the principle of\\n“think before you act” is observed [122; 123].\\nPro-activeness. Pro-activeness denotes that agents don’t merely react to their environments; they\\npossess the capacity to display goal-oriented actions by proactively taking the initiative [ 9]. This\\nproperty emphasizes that agents can reason, make plans, and take proactive measures in their actions\\nto achieve specific goals or adapt to environmental changes. Although intuitively the paradigm\\nof next token prediction in LLMs may not possess intention or desire, research has shown that\\nthey can implicitly generate representations of these states and guide the model’s inference process\\n[46;48;49]. LLMs have demonstrated a strong capacity for generalized reasoning and planning. By\\nprompting large language models with instructions like “let’s think step by st', 'The Rise and Potential of Large Language Model.pdf'), 391: ('s, and take proactive measures in their actions\\nto achieve specific goals or adapt to environmental changes. Although intuitively the paradigm\\nof next token prediction in LLMs may not possess intention or desire, research has shown that\\nthey can implicitly generate representations of these states and guide the model’s inference process\\n[46;48;49]. LLMs have demonstrated a strong capacity for generalized reasoning and planning. By\\nprompting large language models with instructions like “let’s think step by step”, we can elicit their\\nreasoning abilities, such as logical and mathematical reasoning [ 95;96;97]. Similarly, large language\\nmodels have shown the emergent ability of planning in forms of goal reformulation [ 99;124], task\\ndecomposition [98; 125], and adjusting plans in response to environmental changes [100; 126].\\nSocial ability. Social ability refers to an agent’s capacity to interact with other agents, including\\nhumans, through some kind of agent-communication language [ 8]. Large language models exhibit\\nstrong natural language interaction abilities like understanding and generation [ 23;127;128]. Com-\\npared to structured languages or other communication protocals, such capability enables them to\\ninteract with other models or humans in an interpretable manner. This forms the cornerstone of\\nsocial ability for LLM-based agents [ 22;108]. Many researchers have demonstrated that LLM-based\\n9\\nagents can enhance task performance through social behaviors such as collaboration and competition\\n[108;111;129;130]. By inputting specific prompts, LLMs can also play different roles, thereby\\nsimulating the social division of labor in the real world [ 109]. Furthermore, when we place multiple\\nagents with distinct identities into a society, emergent social phenomena can be observed [22].\\n3 The Birth of An Agent: Construction of LLM-based Agents\\nLook at the sky, do you think it will rain tomorrow? Ifso, give the umbrella to me.Environment\\nPerception\\nTools\\nCallingAPI …\\nEmbodiment\\nTextReasoningfromthe current weather conditio', 'The Rise and Potential of Large Language Model.pdf'), 392: ('By inputting specific prompts, LLMs can also play different roles, thereby\\nsimulating the social division of labor in the real world [ 109]. Furthermore, when we place multiple\\nagents with distinct identities into a society, emergent social phenomena can be observed [22].\\n3 The Birth of An Agent: Construction of LLM-based Agents\\nLook at the sky, do you think it will rain tomorrow? Ifso, give the umbrella to me.Environment\\nPerception\\nTools\\nCallingAPI …\\nEmbodiment\\nTextReasoningfromthe current weather conditionsand the weather reports on the internet, it is likely to rain tomorrow.Here is your umbrella.\\nBrain\\nKnowledge\\nMemoryStorageDecisionMaking\\nPlanning/ ReasoningRecallSummaryRetrieveLearnGeneralize/Transfer\\nInputs\\nAgentAction\\nFigure 2: Conceptual framework of LLM-based agent with three components: brain, perception, and\\naction. Serving as the controller, the brain module undertakes basic tasks like memorizing, thinking,\\nand decision-making. The perception module perceives and processes multimodal information\\nfrom the external environment, and the action module carries out the execution using tools and\\ninfluences the surroundings. Here we give an example to illustrate the workflow: When a human\\nasks whether it will rain, the perception module converts the instruction into an understandable\\nrepresentation for LLMs. Then the brain module begins to reason according to the current weather\\nand the weather reports on the internet. Finally, the action module responds and hands the umbrella\\nto the human. By repeating the above process, an agent can continuously get feedback and interact\\nwith the environment.\\n“Survival of the Fittest” [ 131] shows that if an individual wants to survive in the external environment,\\nhe must adapt to the surroundings efficiently. This requires him to be cognitive, able to perceive\\nand respond to changes in the outside world, which is consistent with the definition of “agent”\\nmentioned in §2.1. Inspired by this, we present a general conceptual framework of an LLM-based\\nagent composed of three ', 'The Rise and Potential of Large Language Model.pdf'), 393: ('e above process, an agent can continuously get feedback and interact\\nwith the environment.\\n“Survival of the Fittest” [ 131] shows that if an individual wants to survive in the external environment,\\nhe must adapt to the surroundings efficiently. This requires him to be cognitive, able to perceive\\nand respond to changes in the outside world, which is consistent with the definition of “agent”\\nmentioned in §2.1. Inspired by this, we present a general conceptual framework of an LLM-based\\nagent composed of three key parts: brain, perception, and action (see Figure 2). We first describe\\nthe structure and working mechanism of the brain, which is primarily composed of a large language\\nmodel (§ 3.1). The brain is the core of an AI agent because it not only stores knowledge and memories\\nbut also undertakes indispensable functions like information processing and decision-making. It\\ncan present the process of reasoning and planning, and cope well with unseen tasks, exhibiting\\nthe intelligence of an agent. Next, we introduce the perception module (§ 3.2). Its core purpose\\nis to broaden the agent’s perception space from a text-only domain to a multimodal sphere that\\nincludes textual, auditory, and visual modalities. This extension equips the agent to grasp and utilize\\ninformation from its surroundings more effectively. Finally, we present the action module designed\\nto expand the action space of an agent (§ 3.3). Specifically, we empower the agent with embodied\\naction ability and tool-handling skills, enabling it to adeptly adapt to environmental changes, provide\\nfeedback, and even influence and mold the environment.\\nThe framework can be tailored for different application scenarios, i.e. not every specific component\\nwill be used in all studies. In general, agents operate in the following workflow: First, the perception\\n10\\nmodule, corresponding to human sensory systems such as the eyes and ears, perceives changes in the\\nexternal environment and then converts multimodal information into an understandable representation\\nfor the age', 'The Rise and Potential of Large Language Model.pdf'), 394: ('apt to environmental changes, provide\\nfeedback, and even influence and mold the environment.\\nThe framework can be tailored for different application scenarios, i.e. not every specific component\\nwill be used in all studies. In general, agents operate in the following workflow: First, the perception\\n10\\nmodule, corresponding to human sensory systems such as the eyes and ears, perceives changes in the\\nexternal environment and then converts multimodal information into an understandable representation\\nfor the agent. Subsequently, the brain module, serving as the control center, engages in information\\nprocessing activities such as thinking, decision-making, and operations with storage including\\nmemory and knowledge. Finally, the action module, corresponding to human limbs, carries out the\\nexecution with the assistance of tools and leaves an impact on the surroundings. By repeating the\\nabove process, an agent can continuously get feedback and interact with the environment.\\n3.1 Brain\\nBrainNatural Language\\nInteraction §3.1.1High-quality\\ngenerationBang et al. [ 132], Fang et al. [ 133],\\nLin et al. [ 127], Lu et al. [ 134], etc.\\nDeep understandingBuehler et al. [ 135], Lin et al.\\n[128], Shapira et al. [ 136], etc.\\nKnowledge §3.1.2Knowledge in\\nLLM-based agentPretrain modelHill et al. [ 137], Collobert et al.\\n[138], Kaplan et al. [ 139], Roberts\\net al. [ 140], Tandon et al. [ 141], etc.\\nLinguistic knowledgeVulic et al. [ 142], Hewitt et al.\\n[143], Rau et al. [ 144], Yang et al.\\n[145], Beloucif et al. [ 146], Zhang\\net al. [ 147], Bang et al. [ 132], etc.\\nCommensense\\nknowledgeSafavi et al. [ 148], Jiang et\\nal. [149], Madaan [ 150], etc.\\nActionable\\nknowledgeXu et al. [ 151], Cobbe et al. [ 152],\\nThirunavukarasu et al. [ 153], Lai et\\nal. [154], Madaan et al. [ 150], etc.\\nPotential issues\\nof knowledgeEdit wrong and\\noutdated knowledgeAlKhamissi et al. [ 155], Kemker et\\nal. [156], Cao et al. [ 157], Yao et\\nal. [158], Mitchell et al. [ 159], etc.\\nMitigate hallucinationManakul et al. [ 160], Qin et al. [ 94],\\nLi et al. [ 161], Gou et a', 'The Rise and Potential of Large Language Model.pdf'), 395: ('47], Bang et al. [ 132], etc.\\nCommensense\\nknowledgeSafavi et al. [ 148], Jiang et\\nal. [149], Madaan [ 150], etc.\\nActionable\\nknowledgeXu et al. [ 151], Cobbe et al. [ 152],\\nThirunavukarasu et al. [ 153], Lai et\\nal. [154], Madaan et al. [ 150], etc.\\nPotential issues\\nof knowledgeEdit wrong and\\noutdated knowledgeAlKhamissi et al. [ 155], Kemker et\\nal. [156], Cao et al. [ 157], Yao et\\nal. [158], Mitchell et al. [ 159], etc.\\nMitigate hallucinationManakul et al. [ 160], Qin et al. [ 94],\\nLi et al. [ 161], Gou et al. [ 162], etc.\\nMemory §3.1.3Memory capabilityRaising the length\\nlimit of TransformersBART [ 163], Park et al. [ 164], LongT5\\n[165], CoLT5 [ 166], Ruoss et al. [ 167], etc.\\nSummarizing\\nmemoryGenerative Agents [ 22], SCM\\n[168], Reflexion [ 169], Memory-\\nbank [ 170], ChatEval [ 171], etc.\\nCompressing mem-\\nories with vectors\\nor data structuresChatDev [ 109], GITM [ 172], RET-LLM\\n[173], AgentSims [ 174], ChatDB [ 175], etc.\\nMemory retrievalAutomated retrievalGenerative Agents [ 22], Memory-\\nbank [ 170], AgentSims [ 174], etc.\\nInteractive retrieval Memory Sandbox[ 176], ChatDB [ 175], etc.\\nReasoning &\\nPlanning §3.1.4ReasoningCoT [ 95], Zero-shot-CoT [ 96],\\nSelf-Consistency [ 97], Self-\\nPolish [ 99], Selection-Inference\\n[177], Self-Refine [ 178], etc.\\nPlaningPlan formulationLeast-to-Most [ 98], SayCan [ 179], Hug-\\ngingGPT [ 180], ToT [ 181], PET [ 182],\\nDEPS [ 183], RAP [ 184], SwiftSage\\n[185], LLM+P [ 125], MRKL [ 186], etc.\\nPlan reflectionLLM-Planner [ 101], Inner Monologue\\n[187], ReAct [ 91], ChatCoT [ 188], AI\\nChains [ 189], V oyager [ 190], Zhao\\net al. [ 191], SelfCheck [ 192], etc.\\nTransferability &\\nGeneralization §3.1.5Unseen task\\ngeneralizationT0 [106], FLAN [ 105], Instruct-\\nGPT [ 24], Chung et al. [ 107], etc.\\nIn-context learningGPT-3 [ 41], Wang et al. [ 193], Wang\\net al. [ 194], Dong et al. [ 195], etc.\\nContinual learningKe et al. [ 196], Wang et al. [ 197], Raz-\\ndaibiedina et al. [ 198], V oyager [ 190], etc.\\nFigure 3: Typology of the brain module.\\n11\\nThe human brain is a sophisticated structure comprise', 'The Rise and Potential of Large Language Model.pdf'), 396: ('Chains [ 189], V oyager [ 190], Zhao\\net al. [ 191], SelfCheck [ 192], etc.\\nTransferability &\\nGeneralization §3.1.5Unseen task\\ngeneralizationT0 [106], FLAN [ 105], Instruct-\\nGPT [ 24], Chung et al. [ 107], etc.\\nIn-context learningGPT-3 [ 41], Wang et al. [ 193], Wang\\net al. [ 194], Dong et al. [ 195], etc.\\nContinual learningKe et al. [ 196], Wang et al. [ 197], Raz-\\ndaibiedina et al. [ 198], V oyager [ 190], etc.\\nFigure 3: Typology of the brain module.\\n11\\nThe human brain is a sophisticated structure comprised of a vast number of interconnected neu-\\nrons, capable of processing various information, generating diverse thoughts, controlling different\\nbehaviors, and even creating art and culture [ 199]. Much like humans, the brain serves as the central\\nnucleus of an AI agent, primarily composed of a large language model.\\nOperating mechanism. To ensure effective communication, the ability to engage in natural lan-\\nguage interaction (§3.1.1) is paramount. After receiving the information processed by the perception\\nmodule, the brain module first turns to storage, retrieving in knowledge (§3.1.2) and recalling from\\nmemory (§3.1.3). These outcomes aid the agent in devising plans, reasoning, and making informed\\ndecisions (§3.1.4). Additionally, the brain module may memorize the agent’s past observations,\\nthoughts, and actions in the form of summaries, vectors, or other data structures. Meanwhile, it\\ncan also update the knowledge such as common sense and domain knowledge for future use. The\\nLLM-based agent may also adapt to unfamiliar scenarios with its inherent generalization and transfer\\nability (§3.1.5). In the subsequent sections, we delve into a detailed exploration of these extraordinary\\nfacets of the brain module as depicted in Figure 3.\\n3.1.1 Natural Language Interaction\\nAs a medium for communication, language contains a wealth of information. In addition to the\\nintuitively expressed content, there may also be the speaker’s beliefs, desires, and intentions hidden\\nbehind it [ 200]. Thanks to the powerful natural langua', 'The Rise and Potential of Large Language Model.pdf'), 397: (' unfamiliar scenarios with its inherent generalization and transfer\\nability (§3.1.5). In the subsequent sections, we delve into a detailed exploration of these extraordinary\\nfacets of the brain module as depicted in Figure 3.\\n3.1.1 Natural Language Interaction\\nAs a medium for communication, language contains a wealth of information. In addition to the\\nintuitively expressed content, there may also be the speaker’s beliefs, desires, and intentions hidden\\nbehind it [ 200]. Thanks to the powerful natural language understanding and generation capabilities\\ninherent in LLMs [ 25;201;202;203], agents can proficiently engage in not only basic interactive\\nconversations [ 204;205;206] in multiple languages [ 132;202] but also exhibit in-depth comprehen-\\nsion abilities, which allow humans to easily understand and interact with agents [ 207;208]. Besides,\\nLLM-based agents that communicate in natural language can earn more trust and cooperate more\\neffectively with humans [130].\\nMulti-turn interactive conversation. The capability of multi-turn conversation is the foundation of\\neffective and consistent communication. As the core of the brain module, LLMs, such as GPT series\\n[40;41;201], LLaMA series [ 201;209] and T5 series [ 107;210], can understand natural language\\nand generate coherent and contextually relevant responses, which helps agents to comprehend better\\nand handle various problems [ 211]. However, even humans find it hard to communicate without\\nconfusion in one sitting, so multiple rounds of dialogue are necessary. Compared with traditional\\ntext-only reading comprehension tasks like SQuAD [ 212], multi-turn conversations (1) are interactive,\\ninvolving multiple speakers, and lack continuity; (2) may involve multiple topics, and the information\\nof the dialogue may also be redundant, making the text structure more complex [ 147]. In general, the\\nmulti-turn conversation is mainly divided into three steps: (1) Understanding the history of natural\\nlanguage dialogue, (2) Deciding what action to take, and (3) Generating natur', 'The Rise and Potential of Large Language Model.pdf'), 398: ('Compared with traditional\\ntext-only reading comprehension tasks like SQuAD [ 212], multi-turn conversations (1) are interactive,\\ninvolving multiple speakers, and lack continuity; (2) may involve multiple topics, and the information\\nof the dialogue may also be redundant, making the text structure more complex [ 147]. In general, the\\nmulti-turn conversation is mainly divided into three steps: (1) Understanding the history of natural\\nlanguage dialogue, (2) Deciding what action to take, and (3) Generating natural language responses.\\nLLM-based agents are capable of continuously refining outputs using existing information to conduct\\nmulti-turn conversations and effectively achieve the ultimate goal [132; 147].\\nHigh-quality natural language generation. Recent LLMs show exceptional natural language\\ngeneration capabilities, consistently producing high-quality text in multiple languages [ 132;213].\\nThe coherency [ 214] and grammatical accuracy [ 133] of LLM-generated content have shown steady\\nenhancement, evolving progressively from GPT-3 [ 41] to InstructGPT [ 24], and culminating in GPT-4\\n[25]. See et al. [ 214] empirically affirm that these language models can “adapt to the style and\\ncontent of the conditioning text” [ 215]. And the results of Fang et al. [ 133] suggest that ChatGPT\\nexcels in grammar error detection, underscoring its powerful language capabilities. In conversational\\ncontexts, LLMs also perform well in key metrics of dialogue quality, including content, relevance,\\nand appropriateness [ 127]. Importantly, they do not merely copy training data but display a certain\\ndegree of creativity, generating diverse texts that are equally novel or even more novel than the\\nbenchmarks crafted by humans [ 216]. Meanwhile, human oversight remains effective through the\\nuse of controllable prompts, ensuring precise control over the content generated by these language\\nmodels [134].\\nIntention and implication understanding. Although models trained on the large-scale corpus are\\nalready intelligent enough to understand instruct', 'The Rise and Potential of Large Language Model.pdf'), 399: ('y, they do not merely copy training data but display a certain\\ndegree of creativity, generating diverse texts that are equally novel or even more novel than the\\nbenchmarks crafted by humans [ 216]. Meanwhile, human oversight remains effective through the\\nuse of controllable prompts, ensuring precise control over the content generated by these language\\nmodels [134].\\nIntention and implication understanding. Although models trained on the large-scale corpus are\\nalready intelligent enough to understand instructions, most are still incapable of emulating human\\ndialogues or fully leveraging the information conveyed in language [ 217]. Understanding the implied\\nmeanings is essential for effective communication and cooperation with other intelligent agents [ 135],\\n12\\nand enables one to interpret others’ feedback. The emergence of LLMs highlights the potential\\nof foundation models to understand human intentions, but when it comes to vague instructions or\\nother implications, it poses a significant challenge for agents [ 94;136]. For humans, grasping the\\nimplied meanings from a conversation comes naturally, whereas for agents, they should formalize\\nimplied meanings into a reward function that allows them to choose the option in line with the\\nspeaker’s preferences in unseen contexts [ 128]. One of the main ways for reward modeling is\\ninferring rewards based on feedback, which is primarily presented in the form of comparisons [ 218]\\n(possibly supplemented with reasons [ 219]) and unconstrained natural language [ 220]. Another way\\ninvolves recovering rewards from descriptions, using the action space as a bridge [ 128]. Jeon et al.\\n[221] suggests that human behavior can be mapped to a choice from an implicit set of options, which\\nhelps to interpret all the information in a single unifying formalism. By utilizing their understanding\\nof context, agents can take highly personalized and accurate action, tailored to specific requirements.\\n3.1.2 Knowledge\\nDue to the diversity of the real world, many NLP researchers attempt to utilize', 'The Rise and Potential of Large Language Model.pdf'), 400: ('er way\\ninvolves recovering rewards from descriptions, using the action space as a bridge [ 128]. Jeon et al.\\n[221] suggests that human behavior can be mapped to a choice from an implicit set of options, which\\nhelps to interpret all the information in a single unifying formalism. By utilizing their understanding\\nof context, agents can take highly personalized and accurate action, tailored to specific requirements.\\n3.1.2 Knowledge\\nDue to the diversity of the real world, many NLP researchers attempt to utilize data that has a larger\\nscale. This data usually is unstructured and unlabeled [ 137;138], yet it contains enormous knowledge\\nthat language models could learn. In theory, language models can learn more knowledge as they have\\nmore parameters [ 139], and it is possible for language models to learn and comprehend everything in\\nnatural language. Research [ 140] shows that language models trained on a large-scale dataset can\\nencode a wide range of knowledge into their parameters and respond correctly to various types of\\nqueries. Furthermore, the knowledge can assist LLM-based agents in making informed decisions\\n[222]. All of this knowledge can be roughly categorized into the following types:\\n•Linguistic knowledge. Linguistic knowledge [ 142;143;144] is represented as a system of\\nconstraints, a grammar, which defines all and only the possible sentences of the language. It\\nincludes morphology, syntax, semantics [ 145;146], and pragmatics. Only the agents that acquire\\nlinguistic knowledge can comprehend sentences and engage in multi-turn conversations [ 147].\\nMoreover, these agents can acquire multilingual knowledge [ 132] by training on datasets that\\ncontain multiple languages, eliminating the need for extra translation models.\\n•Commonsense knowledge. Commonsense knowledge [ 148;149;150] refers to general world\\nfacts that are typically taught to most individuals at an early age. For example, people commonly\\nknow that medicine is used for curing diseases, and umbrellas are used to protect against rain. Such\\ninformation', 'The Rise and Potential of Large Language Model.pdf'), 401: (' engage in multi-turn conversations [ 147].\\nMoreover, these agents can acquire multilingual knowledge [ 132] by training on datasets that\\ncontain multiple languages, eliminating the need for extra translation models.\\n•Commonsense knowledge. Commonsense knowledge [ 148;149;150] refers to general world\\nfacts that are typically taught to most individuals at an early age. For example, people commonly\\nknow that medicine is used for curing diseases, and umbrellas are used to protect against rain. Such\\ninformation is usually not explicitly mentioned in the context. Therefore, the models lacking the\\ncorresponding commonsense knowledge may fail to grasp or misinterpret the intended meaning\\n[141]. Similarly, agents without commonsense knowledge may make incorrect decisions, such as\\nnot bringing an umbrella when it rains heavily.\\n•Professional domain knowledge. Professional domain knowledge refers to the knowledge associ-\\nated with a specific domain like programming [ 151;154;150], mathematics [ 152], medicine [ 153],\\netc. It is essential for models to effectively solve problems within a particular domain [ 223]. For\\nexample, models designed to perform programming tasks need to possess programming knowledge,\\nsuch as code format. Similarly, models intended for diagnostic purposes should possess medical\\nknowledge like the names of specific diseases and prescription drugs.\\nAlthough LLMs demonstrate excellent performance in acquiring, storing, and utilizing knowledge\\n[155], there remain potential issues and unresolved problems. For example, the knowledge acquired\\nby models during training could become outdated or even be incorrect from the start. A simple way to\\naddress this is retraining. However, it requires advanced data, extensive time, and computing resources.\\nEven worse, it can lead to catastrophic forgetting [ 156]. Therefore, some researchers[ 157;158;159]\\ntry editing LLMs to locate and modify specific knowledge stored within the models. This involved\\nunloading incorrect knowledge while simultaneously acquiring new know', 'The Rise and Potential of Large Language Model.pdf'), 402: ('s. For example, the knowledge acquired\\nby models during training could become outdated or even be incorrect from the start. A simple way to\\naddress this is retraining. However, it requires advanced data, extensive time, and computing resources.\\nEven worse, it can lead to catastrophic forgetting [ 156]. Therefore, some researchers[ 157;158;159]\\ntry editing LLMs to locate and modify specific knowledge stored within the models. This involved\\nunloading incorrect knowledge while simultaneously acquiring new knowledge. Their experiments\\nshow that this method can partially edit factual knowledge, but its underlying mechanism still\\nrequires further research. Besides, LLMs may generate content that conflicts with the source or\\nfactual information [ 224], a phenomenon often referred to as hallucinations [ 225]. It is one of\\nthe critical reasons why LLMs can not be widely used in factually rigorous tasks. To tackle this\\nissue, some researchers [ 160] proposed a metric to measure the level of hallucinations and provide\\ndevelopers with an effective reference to evaluate the trustworthiness of LLM outputs. Moreover,\\nsome researchers[ 161;162] enable LLMs to utilize external tools[ 94;226;227] to avoid incorrect\\n13\\nknowledge. Both of these methods can alleviate the impact of hallucinations, but further exploration\\nof more effective approaches is still needed.\\n3.1.3 Memory\\nIn our framework, “memory” stores sequences of the agent’s past observations, thoughts and actions,\\nwhich is akin to the definition presented by Nuxoll et al. [ 228]. Just as the human brain relies on\\nmemory systems to retrospectively harness prior experiences for strategy formulation and decision-\\nmaking, agents necessitate specific memory mechanisms to ensure their proficient handling of\\na sequence of consecutive tasks [ 229;230;231]. When faced with complex problems, memory\\nmechanisms help the agent to revisit and apply antecedent strategies effectively. Furthermore, these\\nmemory mechanisms enable individuals to adjust to unfamiliar environments by drawing ', 'The Rise and Potential of Large Language Model.pdf'), 403: ('l. [ 228]. Just as the human brain relies on\\nmemory systems to retrospectively harness prior experiences for strategy formulation and decision-\\nmaking, agents necessitate specific memory mechanisms to ensure their proficient handling of\\na sequence of consecutive tasks [ 229;230;231]. When faced with complex problems, memory\\nmechanisms help the agent to revisit and apply antecedent strategies effectively. Furthermore, these\\nmemory mechanisms enable individuals to adjust to unfamiliar environments by drawing on past\\nexperiences.\\nWith the expansion of interaction cycles in LLM-based agents, two primary challenges arise. The\\nfirst pertains to the sheer length of historical records. LLM-based agents process prior interactions\\nin natural language format, appending historical records to each subsequent input. As these records\\nexpand, they might surpass the constraints of the Transformer architecture that most LLM-based\\nagents rely on. When this occurs, the system might truncate some content. The second challenge is\\nthe difficulty in extracting relevant memories. As agents amass a vast array of historical observations\\nand action sequences, they grapple with an escalating memory burden. This makes establishing\\nconnections between related topics increasingly challenging, potentially causing the agent to misalign\\nits responses with the ongoing context.\\nMethods for better memory capability. Here we introduce several methods to enhance the memory\\nof LLM-based agents.\\n•Raising the length limit of Transformers. The first method tries to address or mitigate the inherent\\nsequence length constraints. The Transformer architecture struggles with long sequences due to\\nthese intrinsic limits. As sequence length expands, computational demand grows exponentially\\ndue to the pairwise token calculations in the self-attention mechanism. Strategies to mitigate\\nthese length restrictions encompass text truncation [ 163;164;232], segmenting inputs [ 233;234],\\nand emphasizing key portions of text [ 235;236;237]. Some other works modify the atten', 'The Rise and Potential of Large Language Model.pdf'), 404: ('od tries to address or mitigate the inherent\\nsequence length constraints. The Transformer architecture struggles with long sequences due to\\nthese intrinsic limits. As sequence length expands, computational demand grows exponentially\\ndue to the pairwise token calculations in the self-attention mechanism. Strategies to mitigate\\nthese length restrictions encompass text truncation [ 163;164;232], segmenting inputs [ 233;234],\\nand emphasizing key portions of text [ 235;236;237]. Some other works modify the attention\\nmechanism to reduce complexity, thereby accommodating longer sequences [ 238;165;166;167].\\n•Summarizing memory. The second strategy for amplifying memory efficiency hinges on the\\nconcept of memory summarization. This ensures agents effortlessly extract pivotal details from\\nhistorical interactions. Various techniques have been proposed for summarizing memory. Using\\nprompts, some methods succinctly integrate memories [ 168], while others emphasize reflective\\nprocesses to create condensed memory representations [ 22;239]. Hierarchical methods streamline\\ndialogues into both daily snapshots and overarching summaries [ 170]. Notably, specific strategies\\ntranslate environmental feedback into textual encapsulations, bolstering agents’ contextual grasp\\nfor future engagements [ 169]. Moreover, in multi-agent environments, vital elements of agent\\ncommunication are captured and retained [171].\\n•Compressing memories with vectors or data structures. By employing suitable data structures,\\nintelligent agents boost memory retrieval efficiency, facilitating prompt responses to interactions.\\nNotably, several methodologies lean on embedding vectors for memory sections, plans, or dialogue\\nhistories [ 109;170;172;174]. Another approach translates sentences into triplet configurations\\n[173], while some perceive memory as a unique data object, fostering varied interactions [ 176].\\nFurthermore, ChatDB [ 175] and DB-GPT [ 240] integrate the LLMrollers with SQL databases,\\nenabling data manipulation through SQL commands.\\nMethods for ', 'The Rise and Potential of Large Language Model.pdf'), 405: ('y retrieval efficiency, facilitating prompt responses to interactions.\\nNotably, several methodologies lean on embedding vectors for memory sections, plans, or dialogue\\nhistories [ 109;170;172;174]. Another approach translates sentences into triplet configurations\\n[173], while some perceive memory as a unique data object, fostering varied interactions [ 176].\\nFurthermore, ChatDB [ 175] and DB-GPT [ 240] integrate the LLMrollers with SQL databases,\\nenabling data manipulation through SQL commands.\\nMethods for memory retrieval. When an agent interacts with its environment or users, it is\\nimperative to retrieve the most appropriate content from its memory. This ensures that the agent\\naccesses relevant and accurate information to execute specific actions. An important question arises:\\nHow can an agent select the most suitable memory? Typically, agents retrieve memories in an\\nautomated manner [ 170;174]. A significant approach in automated retrieval considers three metrics:\\nRecency, Relevance, and Importance. The memory score is determined as a weighted combination of\\nthese metrics, with memories having the highest scores being prioritized in the model’s context [ 22].\\n14\\nSome research introduces the concept of interactive memory objects, which are representations of\\ndialogue history that can be moved, edited, deleted, or combined through summarization. Users can\\nview and manipulate these objects, influencing how the agent perceives the dialogue [ 176]. Similarly,\\nother studies allow for memory operations like deletion based on specific commands provided by\\nusers [175]. Such methods ensure that the memory content aligns closely with user expectations.\\n3.1.4 Reasoning and Planning\\nReasoning. Reasoning, underpinned by evidence and logic, is fundamental to human intellectual\\nendeavors, serving as the cornerstone for problem-solving, decision-making, and critical analysis\\n[241;242;243]. Deductive, inductive, and abductive are the primary forms of reasoning commonly\\nrecognized in intellectual endeavor [ 244]. For LLM-based a', 'The Rise and Potential of Large Language Model.pdf'), 406: ('n based on specific commands provided by\\nusers [175]. Such methods ensure that the memory content aligns closely with user expectations.\\n3.1.4 Reasoning and Planning\\nReasoning. Reasoning, underpinned by evidence and logic, is fundamental to human intellectual\\nendeavors, serving as the cornerstone for problem-solving, decision-making, and critical analysis\\n[241;242;243]. Deductive, inductive, and abductive are the primary forms of reasoning commonly\\nrecognized in intellectual endeavor [ 244]. For LLM-based agents, like humans, reasoning capacity is\\ncrucial for solving complex tasks [25].\\nDiffering academic views exist regarding the reasoning capabilities of large language models. Some\\nargue language models possess reasoning during pre-training or fine-tuning [ 244], while others\\nbelieve it emerges after reaching a certain scale in size [ 26;245]. Specifically, the representative\\nChain-of-Thought (CoT) method [ 95;96] has been demonstrated to elicit the reasoning capacities of\\nlarge language models by guiding LLMs to generate rationales before outputting the answer. Some\\nother strategies have also been presented to enhance the performance of LLMs like self-consistency\\n[97], self-polish [ 99], self-refine [ 178] and selection-inference [ 177], among others. Some studies\\nsuggest that the effectiveness of step-by-step reasoning can be attributed to the local statistical\\nstructure of training data, with locally structured dependencies between variables yielding higher data\\nefficiency than training on all variables [246].\\nPlanning. Planning is a key strategy humans employ when facing complex challenges. For humans,\\nplanning helps organize thoughts, set objectives, and determine the steps to achieve those objectives\\n[247;248;249]. Just as with humans, the ability to plan is crucial for agents, and central to this\\nplanning module is the capacity for reasoning [ 250;251;252]. This offers a structured thought\\nprocess for agents based on LLMs. Through reasoning, agents deconstruct complex tasks into more\\nmanageable sub-tasks', 'The Rise and Potential of Large Language Model.pdf'), 407: ('46].\\nPlanning. Planning is a key strategy humans employ when facing complex challenges. For humans,\\nplanning helps organize thoughts, set objectives, and determine the steps to achieve those objectives\\n[247;248;249]. Just as with humans, the ability to plan is crucial for agents, and central to this\\nplanning module is the capacity for reasoning [ 250;251;252]. This offers a structured thought\\nprocess for agents based on LLMs. Through reasoning, agents deconstruct complex tasks into more\\nmanageable sub-tasks, devising appropriate plans for each [ 253;254]. Moreover, as tasks progress,\\nagents can employ introspection to modify their plans, ensuring they align better with real-world\\ncircumstances, leading to adaptive and successful task execution.\\nTypically, planning comprises two stages: plan formulation and plan reflection.\\n•Plan formulation. During the process of plan formulation, agents generally decompose an\\noverarching task into numerous sub-tasks, and various approaches have been proposed in this phase.\\nNotably, some works advocate for LLM-based agents to decompose problems comprehensively in\\none go, formulating a complete plan at once and then executing it sequentially [ 98;179;255;256].\\nIn contrast, other studies like the CoT-series employ an adaptive strategy, where they plan and\\naddress sub-tasks one at a time, allowing for more fluidity in handling intricate tasks in their entirety\\n[95;96;257]. Additionally, some methods emphasize hierarchical planning [ 182;185], while\\nothers underscore a strategy in which final plans are derived from reasoning steps structured in\\na tree-like format. The latter approach argues that agents should assess all possible paths before\\nfinalizing a plan [ 97;181;184;258;184]. While LLM-based agents demonstrate a broad scope of\\ngeneral knowledge, they can occasionally face challenges when tasked with situations that require\\nexpertise knowledge. Enhancing these agents by integrating them with planners of specific domains\\nhas shown to yield better performance [125; 130; 186; 259].', 'The Rise and Potential of Large Language Model.pdf'), 408: ('which final plans are derived from reasoning steps structured in\\na tree-like format. The latter approach argues that agents should assess all possible paths before\\nfinalizing a plan [ 97;181;184;258;184]. While LLM-based agents demonstrate a broad scope of\\ngeneral knowledge, they can occasionally face challenges when tasked with situations that require\\nexpertise knowledge. Enhancing these agents by integrating them with planners of specific domains\\nhas shown to yield better performance [125; 130; 186; 259].\\n•Plan reflection. Upon formulating a plan, it’s imperative to reflect upon and evaluate its merits.\\nLLM-based agents leverage internal feedback mechanisms, often drawing insights from pre-existing\\nmodels, to hone and enhance their strategies and planning approaches [ 169;178;188;192]. To\\nbetter align with human values and preferences, agents actively engage with humans, allowing\\nthem to rectify some misunderstandings and assimilate this tailored feedback into their planning\\nmethodology [ 108;189;190]. Furthermore, they could draw feedback from tangible or virtual\\nsurroundings, such as cues from task accomplishments or post-action observations, aiding them in\\nrevising and refining their plans [91; 101; 187; 191; 260].\\n15\\n3.1.5 Transferability and Generalization\\nIntelligence shouldn’t be limited to a specific domain or task, but rather encompass a broad range\\nof cognitive skills and abilities [ 31]. The remarkable nature of the human brain is largely attributed\\nto its high degree of plasticity and adaptability. It can continuously adjust its structure and function\\nin response to external stimuli and internal needs, thereby adapting to different environments and\\ntasks. These years, plenty of research indicates that pre-trained models on large-scale corpora can\\nlearn universal language representations [ 36;261;262]. Leveraging the power of pre-trained models,\\nwith only a small amount of data for fine-tuning, LLMs can demonstrate excellent performance in\\ndownstream tasks [ 263]. There is no need to train new models', 'The Rise and Potential of Large Language Model.pdf'), 409: ('. It can continuously adjust its structure and function\\nin response to external stimuli and internal needs, thereby adapting to different environments and\\ntasks. These years, plenty of research indicates that pre-trained models on large-scale corpora can\\nlearn universal language representations [ 36;261;262]. Leveraging the power of pre-trained models,\\nwith only a small amount of data for fine-tuning, LLMs can demonstrate excellent performance in\\ndownstream tasks [ 263]. There is no need to train new models from scratch, which saves a lot of\\ncomputation resources. However, through this task-specific fine-tuning, the models lack versatility\\nand struggle to be generalized to other tasks. Instead of merely functioning as a static knowledge\\nrepository, LLM-based agents exhibit dynamic learning ability which enables them to adapt to novel\\ntasks swiftly and robustly [24; 105; 106].\\nUnseen task generalization. Studies show that instruction-tuned LLMs exhibit zero-shot gener-\\nalization without the need for task-specific fine-tuning [ 24;25;105;106;107]. With the expansion\\nof model size and corpus size, LLMs gradually exhibit remarkable emergent abilities in unfamiliar\\ntasks [ 132]. Specifically, LLMs can complete new tasks they do not encounter in the training stage by\\nfollowing the instructions based on their own understanding. One of the implementations is multi-task\\nlearning, for example, FLAN [ 105] finetunes language models on a collection of tasks described via\\ninstructions, and T0 [ 106] introduces a unified framework that converts every language problem into\\na text-to-text format. Despite being purely a language model, GPT-4 [ 25] demonstrates remarkable\\ncapabilities in a variety of domains and tasks, including abstraction, comprehension, vision, coding,\\nmathematics, medicine, law, understanding of human motives and emotions, and others [ 31]. It is\\nnoticed that the choices in prompting are critical for appropriate predictions, and training directly on\\nthe prompts can improve the models’ robustness in generalizin', 'The Rise and Potential of Large Language Model.pdf'), 410: ('mework that converts every language problem into\\na text-to-text format. Despite being purely a language model, GPT-4 [ 25] demonstrates remarkable\\ncapabilities in a variety of domains and tasks, including abstraction, comprehension, vision, coding,\\nmathematics, medicine, law, understanding of human motives and emotions, and others [ 31]. It is\\nnoticed that the choices in prompting are critical for appropriate predictions, and training directly on\\nthe prompts can improve the models’ robustness in generalizing to unseen tasks [ 264]. Promisingly,\\nsuch generalization capability can further be enhanced by scaling up both the model size and the\\nquantity or diversity of training instructions [94; 265].\\nIn-context learning. Numerous studies indicate that LLMs can perform a variety of complex\\ntasks through in-context learning (ICL), which refers to the models’ ability to learn from a few\\nexamples in the context [ 195]. Few-shot in-context learning enhances the predictive performance\\nof language models by concatenating the original input with several complete examples as prompts\\nto enrich the context [ 41]. The key idea of ICL is learning from analogy, which is similar to the\\nlearning process of humans [ 266]. Furthermore, since the prompts are written in natural language,\\nthe interaction is interpretable and changeable, making it easier to incorporate human knowledge into\\nLLMs [ 95;267]. Unlike the supervised learning process, ICL doesn’t involve fine-tuning or parameter\\nupdates, which could greatly reduce the computation costs for adapting the models to new tasks.\\nBeyond text, researchers also explore the potential ICL capabilities in different multimodal tasks\\n[193;194;268;269;270;271], making it possible for agents to be applied to large-scale real-world\\ntasks.\\nContinual learning. Recent studies [ 190;272] have highlighted the potential of LLMs’ planning\\ncapabilities in facilitating continuous learning [ 196;197] for agents, which involves continuous\\nacquisition and update of skills. A core challenge in continual lear', 'The Rise and Potential of Large Language Model.pdf'), 411: ('ion costs for adapting the models to new tasks.\\nBeyond text, researchers also explore the potential ICL capabilities in different multimodal tasks\\n[193;194;268;269;270;271], making it possible for agents to be applied to large-scale real-world\\ntasks.\\nContinual learning. Recent studies [ 190;272] have highlighted the potential of LLMs’ planning\\ncapabilities in facilitating continuous learning [ 196;197] for agents, which involves continuous\\nacquisition and update of skills. A core challenge in continual learning is catastrophic forgetting\\n[273]: as a model learns new tasks, it tends to lose knowledge from previous tasks. Numerous efforts\\nhave been devoted to addressing the above challenge, which can be broadly separated into three\\ngroups, introducing regularly used terms in reference to the previous model [ 274;275;276;277],\\napproximating prior data distributions [ 278;279;280], and designing architectures with task-adaptive\\nparameters [ 281;198]. LLM-based agents have emerged as a novel paradigm, leveraging the planning\\ncapabilities of LLMs to combine existing skills and address more intricate challenges. V oyager [ 190]\\nattempts to solve progressively harder tasks proposed by the automatic curriculum devised by GPT-4\\n[25]. By synthesizing complex skills from simpler programs, the agent not only rapidly enhances its\\ncapabilities but also effectively counters catastrophic forgetting.\\n16\\nPerceptionTextual Input §3.2.1\\nVisual Input §3.2.2Visual encoderViT [ 282], VQV AE [ 283], Mobile-\\nViT [ 284], MLP-Mixer [ 285], etc.\\nLearnable\\narchitectureQuery basedKosmos [ 286], BLIP-2 [ 287], In-\\nstructBLIP [ 288], MultiModal-\\nGPT [ 289], Flamingo [ 290], etc.\\nProjection basedPandaGPT [ 291], LLaV A\\n[292], Minigpt-4 [ 118], etc.\\nAuditory Input §3.2.3Cascading manner AudioGPT [ 293], HuggingGPT [ 180], etc.\\nTransfer\\nvisual methodAST [ 294], HuBERT [ 295] , X-LLM\\n[296], Video-LLaMA [ 297], etc.\\nOther Input §3.2.4 InternGPT [ 298], etc.\\nFigure 4: Typology of the perception module.\\n3.2 Perception\\nBoth humans and animals rely on se', 'The Rise and Potential of Large Language Model.pdf'), 412: (', etc.\\nLearnable\\narchitectureQuery basedKosmos [ 286], BLIP-2 [ 287], In-\\nstructBLIP [ 288], MultiModal-\\nGPT [ 289], Flamingo [ 290], etc.\\nProjection basedPandaGPT [ 291], LLaV A\\n[292], Minigpt-4 [ 118], etc.\\nAuditory Input §3.2.3Cascading manner AudioGPT [ 293], HuggingGPT [ 180], etc.\\nTransfer\\nvisual methodAST [ 294], HuBERT [ 295] , X-LLM\\n[296], Video-LLaMA [ 297], etc.\\nOther Input §3.2.4 InternGPT [ 298], etc.\\nFigure 4: Typology of the perception module.\\n3.2 Perception\\nBoth humans and animals rely on sensory organs like eyes and ears to gather information from their\\nsurroundings. These perceptual inputs are converted into neural signals and sent to the brain for\\nprocessing [ 299;300], allowing us to perceive and interact with the world. Similarly, it’s crucial\\nfor LLM-based agents to receive information from various sources and modalities. This expanded\\nperceptual space helps agents better understand their environment, make informed decisions, and\\nexcel in a broader range of tasks, making it an essential development direction. Agent handles this\\ninformation to the Brain module for processing through the perception module.\\nIn this section, we introduce how to enable LLM-based agents to acquire multimodal perception\\ncapabilities, encompassing textual (§ 3.2.1), visual (§ 3.2.2), and auditory inputs (§ 3.2.3). We also\\nconsider other potential input forms (§ 3.2.4) such as tactile feedback, gestures, and 3D maps to\\nenrich the agent’s perception domain and enhance its versatility.3). The typology diagram for the\\nLLM-based agent perception is depicted in Figure 4.\\n3.2.1 Textual Input\\nText is a way to carry data, information, and knowledge, making text communication one of the most\\nimportant ways humans interact with the world. An LLM-based agent already has the fundamental\\nability to communicate with humans through textual input and output [ 114]. In a user’s textual\\ninput, aside from the explicit content, there are also beliefs, desires, and intentions hidden behind\\nit. Understanding implied meanings is crucial fo', 'The Rise and Potential of Large Language Model.pdf'), 413: ('\\nLLM-based agent perception is depicted in Figure 4.\\n3.2.1 Textual Input\\nText is a way to carry data, information, and knowledge, making text communication one of the most\\nimportant ways humans interact with the world. An LLM-based agent already has the fundamental\\nability to communicate with humans through textual input and output [ 114]. In a user’s textual\\ninput, aside from the explicit content, there are also beliefs, desires, and intentions hidden behind\\nit. Understanding implied meanings is crucial for the agent to grasp the potential and underlying\\nintentions of human users, thereby enhancing its communication efficiency and quality with users.\\nHowever, as discussed in § 3.1.1, understanding implied meanings within textual input remains\\nchallenging for the current LLM-based agent. For example, some works [ 128;218;219;220] employ\\nreinforcement learning to perceive implied meanings and models feedback to derive rewards. This\\nhelps deduce the speaker’s preferences, leading to more personalized and accurate responses from\\nthe agent. Additionally, as the agent is designed for use in complex real-world situations, it will\\ninevitably encounter many entirely new tasks. Understanding text instructions for unknown tasks\\nplaces higher demands on the agent’s text perception abilities. As described in § 3.1.5, an LLM that\\nhas undergone instruction tuning [ 105] can exhibit remarkable zero-shot instruction understanding\\nand generalization abilities, eliminating the need for task-specific fine-tuning.\\n3.2.2 Visual Input\\nAlthough LLMs exhibit outstanding performance in language comprehension [ 25;301] and multi-turn\\nconversations [ 302], they inherently lack visual perception and can only understand discrete textual\\ncontent. Visual input usually contains a wealth of information about the world, including properties\\nof objects, spatial relationships, scene layouts, and more in the agent’s surroundings. Therefore,\\nintegrating visual information with data from other modalities can offer the agent a broader context\\nand a mor', 'The Rise and Potential of Large Language Model.pdf'), 414: ('ut\\nAlthough LLMs exhibit outstanding performance in language comprehension [ 25;301] and multi-turn\\nconversations [ 302], they inherently lack visual perception and can only understand discrete textual\\ncontent. Visual input usually contains a wealth of information about the world, including properties\\nof objects, spatial relationships, scene layouts, and more in the agent’s surroundings. Therefore,\\nintegrating visual information with data from other modalities can offer the agent a broader context\\nand a more precise understanding [120], deepening the agent’s perception of the environment.\\nTo help the agent understand the information contained within images, a straightforward approach\\nis to generate corresponding text descriptions for image inputs, known as image captioning [ 303;\\n304;305;306;307]. Captions can be directly linked with standard text instructions and fed into\\nthe agent. This approach is highly interpretable and doesn’t require additional training for caption\\ngeneration, which can save a significant number of computational resources. However, caption\\n17\\ngeneration is a low-bandwidth method [ 120;308], and it may lose a lot of potential information\\nduring the conversion process. Furthermore, the agent’s focus on images may introduce biases.\\nInspired by the excellent performance of transformers [ 309] in natural language processing, re-\\nsearchers have extended their use to the field of computer vision. Representative works like\\nViT/VQV AE [ 282;283;284;285;310] have successfully encoded visual information using trans-\\nformers. Researchers first divide an image into fixed-size patches and then treat these patches, after\\nlinear projection, as input tokens for Transformers [ 292]. In the end, by calculating self-attention\\nbetween tokens, they are able to integrate information across the entire image, resulting in a highly\\neffective way to perceive visual content. Therefore, some works [ 311] try to combine the image\\nencoder and LLM directly to train the entire model in an end-to-end way. While the agent c', 'The Rise and Potential of Large Language Model.pdf'), 415: ('ation using trans-\\nformers. Researchers first divide an image into fixed-size patches and then treat these patches, after\\nlinear projection, as input tokens for Transformers [ 292]. In the end, by calculating self-attention\\nbetween tokens, they are able to integrate information across the entire image, resulting in a highly\\neffective way to perceive visual content. Therefore, some works [ 311] try to combine the image\\nencoder and LLM directly to train the entire model in an end-to-end way. While the agent can achieve\\nremarkable visual perception abilities, it comes at the cost of substantial computational resources.\\nExtensively pre-trained visual encoders and LLMs can greatly enhance the agent’s visual perception\\nand language expression abilities [ 286;312]. Freezing one or both of them during training is a\\nwidely adopted paradigm that achieves a balance between training resources and model performance\\n[287]. However, LLMs cannot directly understand the output of a visual encoder, so it’s necessary\\nto convert the image encoding into embeddings that LLMs can comprehend. In other words, it\\ninvolves aligning the visual encoder with the LLM. This usually requires adding an extra learnable\\ninterface layer between them. For example, BLIP-2 [ 287] and InstructBLIP [ 288] use the Querying\\nTransformer(Q-Former) module as an intermediate layer between the visual encoder and the LLM\\n[288]. Q-Former is a transformer that employs learnable query vectors [ 289], giving it the capability\\nto extract language-informative visual representations. It can provide the most valuable information\\nto the LLM, reducing the agent’s burden of learning visual-language alignment and thereby mitigating\\nthe issue of catastrophic forgetting. At the same time, some researchers adopt a computationally\\nefficient method by using a single projection layer to achieve visual-text alignment, reducing the need\\nfor training additional parameters [ 118;291;312]. Moreover, the projection layer can effectively\\nintegrate with the learnable interface to adapt t', 'The Rise and Potential of Large Language Model.pdf'), 416: (' representations. It can provide the most valuable information\\nto the LLM, reducing the agent’s burden of learning visual-language alignment and thereby mitigating\\nthe issue of catastrophic forgetting. At the same time, some researchers adopt a computationally\\nefficient method by using a single projection layer to achieve visual-text alignment, reducing the need\\nfor training additional parameters [ 118;291;312]. Moreover, the projection layer can effectively\\nintegrate with the learnable interface to adapt the dimensions of its outputs, making them compatible\\nwith LLMs [296; 297; 313; 314].\\nVideo input consists of a series of continuous image frames. As a result, the methods used by\\nagents to perceive images [ 287] may be applicable to the realm of videos, allowing the agent to have\\ngood perception of video inputs as well. Compared to image information, video information adds\\na temporal dimension. Therefore, the agent’s understanding of the relationships between different\\nframes in time is crucial for perceiving video information. Some works like Flamingo [ 290;315]\\nensure temporal order when understanding videos using a mask mechanism. The mask mechanism\\nrestricts the agent’s view to only access visual information from frames that occurred earlier in time\\nwhen it perceives a specific frame in the video.\\n3.2.3 Auditory Input\\nUndoubtedly, auditory information is a crucial component of world information. When an agent\\npossesses auditory capabilities, it can improve its awareness of interactive content, the surrounding\\nenvironment, and even potential dangers. Indeed, there are numerous well-established models and\\napproaches [ 293;316;317] for processing audio as a standalone modality. However, these models\\noften excel at specific tasks. Given the excellent tool-using capabilities of LLMs (which will be\\ndiscussed in detail in §3.3), a very intuitive idea is that the agent can use LLMs as control hubs,\\ninvoking existing toolsets or model repositories in a cascading manner to perceive audio information.\\nFor instance, Au', 'The Rise and Potential of Large Language Model.pdf'), 417: ('ding\\nenvironment, and even potential dangers. Indeed, there are numerous well-established models and\\napproaches [ 293;316;317] for processing audio as a standalone modality. However, these models\\noften excel at specific tasks. Given the excellent tool-using capabilities of LLMs (which will be\\ndiscussed in detail in §3.3), a very intuitive idea is that the agent can use LLMs as control hubs,\\ninvoking existing toolsets or model repositories in a cascading manner to perceive audio information.\\nFor instance, AudioGPT [ 293], makes full use of the capabilities of models like FastSpeech [ 317],\\nGenerSpeech [ 316], Whisper [ 316], and others [ 318;319;320;321;322] which have achieved\\nexcellent results in tasks such as Text-to-Speech, Style Transfer, and Speech Recognition.\\nAn audio spectrogram provides an intuitive representation of the frequency spectrum of an audio signal\\nas it changes over time [ 323]. For a segment of audio data over a period of time, it can be abstracted\\ninto a finite-length audio spectrogram. An audio spectrogram has a 2D representation, which can\\nbe visualized as a flat image. Hence, some research [ 294;295] efforts aim to migrate perceptual\\nmethods from the visual domain to audio. AST (Audio Spectrogram Transformer) [ 294] employs a\\nTransformer architecture similar to ViT to process audio spectrogram images. By segmenting the\\naudio spectrogram into patches, it achieves effective encoding of audio information. Moreover, some\\nresearchers [ 296;297] have drawn inspiration from the idea of freezing encoders to reduce training\\n18\\ntime and computational costs. They align audio encoding with data encoding from other modalities\\nby adding the same learnable interface layer.\\n3.2.4 Other Input\\nAs mentioned earlier, many studies have looked into perception units for text, visual, and audio.\\nHowever, LLM-based agents might be equipped with richer perception modules. In the future, they\\ncould perceive and understand diverse modalities in the real world, much like humans. For example,\\nagents could have unique ', 'The Rise and Potential of Large Language Model.pdf'), 418: ('g encoders to reduce training\\n18\\ntime and computational costs. They align audio encoding with data encoding from other modalities\\nby adding the same learnable interface layer.\\n3.2.4 Other Input\\nAs mentioned earlier, many studies have looked into perception units for text, visual, and audio.\\nHowever, LLM-based agents might be equipped with richer perception modules. In the future, they\\ncould perceive and understand diverse modalities in the real world, much like humans. For example,\\nagents could have unique touch and smell organs, allowing them to gather more detailed information\\nwhen interacting with objects. At the same time, agents can also have a clear sense of the temperature,\\nhumidity, and brightness in their surroundings, enabling them to take environment-aware actions.\\nMoreover, by efficiently integrating basic perceptual abilities like vision, text, and light sensitivity,\\nagents can develop various user-friendly perception modules for humans. InternGPT [ 298] introduces\\npointing instructions. Users can interact with specific, hard-to-describe portions of an image by using\\ngestures or moving the cursor to select, drag, or draw. The addition of pointing instructions helps\\nprovide more precise specifications for individual text instructions. Building upon this, agents have\\nthe potential to perceive more complex user inputs. For example, technologies such as eye-tracking\\nin AR/VR devices, body motion capture, and even brainwave signals in brain-computer interaction.\\nFinally, a human-like LLM-based agent should possess awareness of a broader overall environment.\\nAt present, numerous mature and widely adopted hardware devices can assist agents in accomplishing\\nthis. Lidar [ 324] can create 3D point cloud maps to help agents detect and identify objects in their\\nsurroundings. GPS [ 325] can provide accurate location coordinates and can be integrated with map\\ndata. Inertial Measurement Units (IMUs) can measure and record the three-dimensional motion\\nof objects, offering details about an object’s speed and directio', 'The Rise and Potential of Large Language Model.pdf'), 419: ('uld possess awareness of a broader overall environment.\\nAt present, numerous mature and widely adopted hardware devices can assist agents in accomplishing\\nthis. Lidar [ 324] can create 3D point cloud maps to help agents detect and identify objects in their\\nsurroundings. GPS [ 325] can provide accurate location coordinates and can be integrated with map\\ndata. Inertial Measurement Units (IMUs) can measure and record the three-dimensional motion\\nof objects, offering details about an object’s speed and direction. However, these sensory data are\\ncomplex and cannot be directly understood by LLM-based agents. Exploring how agents can perceive\\nmore comprehensive input is a promising direction for the future.\\n3.3 Action\\nActionTextual Output §3.3.1\\nTools §3.3.2Learning toolsToolformer [ 92], TALM [ 326], Instruct-\\nGPT [ 24], Clarebout et al. [ 327], etc.\\nUsing toolsWebGPT [ 90], OpenAGI [ 211], Visual\\nChatGPT [ 328], SayCan [ 179], etc.\\nMaking toolsLATM [ 329], CREATOR [ 330],\\nSELF-DEBUGGING [ 331], etc.\\nEmbodied\\nAction §3.3.3LLM-based\\nEmbodied actionsSayCan [ 179], EmbodiedGPT [ 121],\\nInstructRL [ 332], Lynch et al. [ 333],\\nV oyager [ 190], AlphaBlock [ 334], DEPS\\n[183], LM-Nav [ 335], NavGPT [ 336], etc.\\nProspective to the\\nembodied actionMineDojo [ 337], Kanitscheider et al. [ 338],\\nDECKARD [ 339], Sumers et al. [ 340], etc.\\nFigure 5: Typology of the action module.\\nAfter humans perceive their environment, their brains integrate, analyze, and reason with the perceived\\ninformation and make decisions. Subsequently, they employ their nervous systems to control their\\nbodies, enabling adaptive or creative actions in response to the environment, such as engaging in\\nconversation, evading obstacles, or starting a fire. When an agent possesses a brain-like structure with\\ncapabilities of knowledge, memory, reasoning, planning, and generalization, as well as multimodal\\nperception, it is also expected to possess a diverse range of actions akin to humans to respond to\\nits surrounding environment. In the construction of the agent, the ', 'The Rise and Potential of Large Language Model.pdf'), 420: ('mploy their nervous systems to control their\\nbodies, enabling adaptive or creative actions in response to the environment, such as engaging in\\nconversation, evading obstacles, or starting a fire. When an agent possesses a brain-like structure with\\ncapabilities of knowledge, memory, reasoning, planning, and generalization, as well as multimodal\\nperception, it is also expected to possess a diverse range of actions akin to humans to respond to\\nits surrounding environment. In the construction of the agent, the action module receives action\\nsequences sent by the brain module and carries out actions to interact with the environment. As\\nFigure 5 shows, this section begins with textual output (§ 3.3.1), which is the inherent capability\\nof LLM-based agents. Next we talk about the tool-using capability of LLM-based agents (§ 3.3.2),\\nwhich has proved effective in enhancing their versatility and expertise. Finally, we discuss equipping\\nthe LLM-based agent with embodied action to facilitate its grounding in the physical world (§ 3.3.3).\\n19\\n3.3.1 Textual Output\\nAs discussed in § 3.1.1, the rise and development of Transformer-based generative large language\\nmodels have endowed LLM-based agents with inherent language generation capabilities [ 132;\\n213]. The text quality they generate excels in various aspects such as fluency, relevance, diversity,\\ncontrollability [ 127;214;134;216]. Consequently, LLM-based agents can be exceptionally strong\\nlanguage generators.\\n3.3.2 Tool Using\\nTools are extensions of the capabilities of tool users. When faced with complex tasks, humans employ\\ntools to simplify task-solving and enhance efficiency, freeing time and resources. Similarly, agents\\nhave the potential to accomplish complex tasks more efficiently and with higher quality if they also\\nlearn to use and utilize tools [94].\\nLLM-based agents have limitations in some aspects, and the use of tools can strengthen the agents’\\ncapabilities . First, although LLM-based agents have a strong knowledge base and expertise, they\\ndon’t have the ability to', 'The Rise and Potential of Large Language Model.pdf'), 421: ('users. When faced with complex tasks, humans employ\\ntools to simplify task-solving and enhance efficiency, freeing time and resources. Similarly, agents\\nhave the potential to accomplish complex tasks more efficiently and with higher quality if they also\\nlearn to use and utilize tools [94].\\nLLM-based agents have limitations in some aspects, and the use of tools can strengthen the agents’\\ncapabilities . First, although LLM-based agents have a strong knowledge base and expertise, they\\ndon’t have the ability to memorize every piece of training data [ 341;342]. They may also fail to steer\\nto correct knowledge due to the influence of contextual prompts [ 226], or even generate hallucinate\\nknowledge [ 208]. Coupled with the lack of corpus, training data, and tuning for specific fields and\\nscenarios, agents’ expertise is also limited when specializing in specific domains [ 343]. Specialized\\ntools enable LLMs to enhance their expertise, adapt domain knowledge, and be more suitable for\\ndomain-specific needs in a pluggable form. Furthermore, the decision-making process of LLM-based\\nagents lacks transparency, making them less trustworthy in high-risk domains such as healthcare and\\nfinance [ 344]. Additionally, LLMs are susceptible to adversarial attacks [ 345], and their robustness\\nagainst slight input modifications is inadequate. In contrast, agents that accomplish tasks with the\\nassistance of tools exhibit stronger interpretability and robustness. The execution process of tools\\ncan reflect the agents’ approach to addressing complex requirements and enhance the credibility of\\ntheir decisions. Moreover, for the reason that tools are specifically designed for their respective usage\\nscenarios, agents utilizing such tools are better equipped to handle slight input modifications and are\\nmore resilient against adversarial attacks [94].\\nLLM-based agents not only require the use of tools, but are also well-suited for tool integration. Lever-\\naging the rich world knowledge accumulated through the pre-training process and CoT prompti', 'The Rise and Potential of Large Language Model.pdf'), 422: ('ing complex requirements and enhance the credibility of\\ntheir decisions. Moreover, for the reason that tools are specifically designed for their respective usage\\nscenarios, agents utilizing such tools are better equipped to handle slight input modifications and are\\nmore resilient against adversarial attacks [94].\\nLLM-based agents not only require the use of tools, but are also well-suited for tool integration. Lever-\\naging the rich world knowledge accumulated through the pre-training process and CoT prompting,\\nLLMs have demonstrated remarkable reasoning and decision-making abilities in complex interactive\\nenvironments [ 97], which help agents break down and address tasks specified by users in an appropri-\\nate way. What’s more, LLMs show significant potential in intent understanding and other aspects\\n[25;201;202;203]. When agents are combined with tools, the threshold for tool utilization can be\\nlowered, thereby fully unleashing the creative potential of human users [94].\\nUnderstanding tools. A prerequisite for an agent to use tools effectively is a comprehensive\\nunderstanding of the tools’ application scenarios and invocation methods. Without this understanding,\\nthe process of the agent using tools will become untrustworthy and fail to genuinely enhance the\\nagent’s capabilities. Leveraging the powerful zero-shot and few-shot learning abilities of LLMs\\n[40; 41], agents can acquire knowledge about tools by utilizing zero-shot prompts that describe tool\\nfunctionalities and parameters, or few-shot prompts that provide demonstrations of specific tool usage\\nscenarios and corresponding methods [ 92;326]. These learning approaches parallel human methods\\nof learning by consulting tool manuals or observing others using tools [ 94]. A single tool is often\\ninsufficient when facing complex tasks. Therefore, the agents should first decompose the complex\\ntask into subtasks in an appropriate manner, and their understanding of tools play a significant role in\\ntask decomposition.\\nLearning to use tools. The methods for agents to le', 'The Rise and Potential of Large Language Model.pdf'), 423: ('ide demonstrations of specific tool usage\\nscenarios and corresponding methods [ 92;326]. These learning approaches parallel human methods\\nof learning by consulting tool manuals or observing others using tools [ 94]. A single tool is often\\ninsufficient when facing complex tasks. Therefore, the agents should first decompose the complex\\ntask into subtasks in an appropriate manner, and their understanding of tools play a significant role in\\ntask decomposition.\\nLearning to use tools. The methods for agents to learn to utilize tools primarily consist of learning\\nfrom demonstrations andlearning from feedback . This involves mimicking the behavior of human\\nexperts [ 346;347;348], as well as understanding the consequences of their actions and making\\nadjustments based on feedback received from both the environment and humans [ 24;349;350].\\nEnvironmental feedback encompasses result feedback on whether actions have successfully completed\\nthe task and intermediate feedback that captures changes in the environmental state caused by actions;\\nhuman feedback comprises explicit evaluations and implicit behaviors, such as clicking on links [ 94].\\n20\\nIf an agent rigidly applies tools without adaptability , it cannot achieve acceptable performance\\nin all scenarios. Agents need to generalize their tool usage skills learned in specific contexts to\\nmore general situations, such as transferring a model trained on Yahoo search to Google search. To\\naccomplish this, it’s necessary for agents to grasp the common principles or patterns in tool usage\\nstrategies, which can potentially be achieved through meta-tool learning [ 327]. Enhancing the agent’s\\nunderstanding of relationships between simple and complex tools, such as how complex tools are\\nbuilt on simpler ones, can contribute to the agents’ capacity to generalize tool usage. This allows\\nagents to effectively discern nuances across various application scenarios and transfer previously\\nlearned knowledge to new tools [ 94]. Curriculum learning [ 351], which allows an agent to start\\nfrom sim', 'The Rise and Potential of Large Language Model.pdf'), 424: ('ool usage\\nstrategies, which can potentially be achieved through meta-tool learning [ 327]. Enhancing the agent’s\\nunderstanding of relationships between simple and complex tools, such as how complex tools are\\nbuilt on simpler ones, can contribute to the agents’ capacity to generalize tool usage. This allows\\nagents to effectively discern nuances across various application scenarios and transfer previously\\nlearned knowledge to new tools [ 94]. Curriculum learning [ 351], which allows an agent to start\\nfrom simple tools and progressively learn complex ones, aligns with the requirements. Moreover,\\nbenefiting from the understanding of user intent reasoning and planning abilities, agents can better\\ndesign methods of tool utilization and collaboration and then provide higher-quality outcomes.\\nMaking tools for self-sufficiency. Existing tools are often designed for human convenience, which\\nmight not be optimal for agents. To make agents use tools better, there’s a need for tools specifically\\ndesigned for agents. These tools should be more modular and have input-output formats that are\\nmore suitable for agents. If instructions and demonstrations are provided, LLM-based agents also\\npossess the ability to create tools by generating executable programs, or integrating existing tools into\\nmore powerful ones [ 94;330;352]. and they can learn to perform self-debugging [ 331]. Moreover, if\\nthe agent that serves as a tool maker successfully creates a tool, it can produce packages containing\\nthe tool’s code and demonstrations for other agents in a multi-agent system, in addition to using the\\ntool itself [ 329]. Speculatively, in the future, agents might become self-sufficient and exhibit a high\\ndegree of autonomy in terms of tools.\\nTools can expand the action space of LLM-based agents. With the help of tools, agents can utilize\\nvarious external resources such as web applications and other LMs during the reasoning and planning\\nphase [ 92]. This process can provide information with high expertise, reliability, diversity, and quality\\n', 'The Rise and Potential of Large Language Model.pdf'), 425: (' other agents in a multi-agent system, in addition to using the\\ntool itself [ 329]. Speculatively, in the future, agents might become self-sufficient and exhibit a high\\ndegree of autonomy in terms of tools.\\nTools can expand the action space of LLM-based agents. With the help of tools, agents can utilize\\nvarious external resources such as web applications and other LMs during the reasoning and planning\\nphase [ 92]. This process can provide information with high expertise, reliability, diversity, and quality\\nfor LLM-based agents, facilitating their decision-making and action. For example, search-based tools\\ncan improve the scope and quality of the knowledge accessible to the agents with the aid of external\\ndatabases, knowledge graphs, and web pages, while domain-specific tools can enhance an agent’s\\nexpertise in the corresponding field [ 211;353]. Some researchers have already developed LLM-based\\ncontrollers that generate SQL statements to query databases, or to convert user queries into search\\nrequests and use search engines to obtain the desired results [ 90;175]. What’s more, LLM-based\\nagents can use scientific tools to execute tasks like organic synthesis in chemistry, or interface\\nwith Python interpreters to enhance their performance on intricate mathematical computation tasks\\n[354;355]. For multi-agent systems, communication tools (e.g., emails) may serve as a means for\\nagents to interact with each other under strict security constraints, facilitating their collaboration , and\\nshowing autonomy and flexibility [94].\\nAlthough the tools mentioned before enhance the capabilities of agents, the medium of interaction\\nwith the environment remains text-based. However, tools are designed to expand the functionality of\\nlanguage models, and their outputs are not limited to text. Tools for non-textual output can diversify\\nthemodalities of agent actions, thereby expanding the application scenarios of LLM-based agents.\\nFor example, image processing and generation can be accomplished by an agent that draws on a\\nvisual model', 'The Rise and Potential of Large Language Model.pdf'), 426: ('ty [94].\\nAlthough the tools mentioned before enhance the capabilities of agents, the medium of interaction\\nwith the environment remains text-based. However, tools are designed to expand the functionality of\\nlanguage models, and their outputs are not limited to text. Tools for non-textual output can diversify\\nthemodalities of agent actions, thereby expanding the application scenarios of LLM-based agents.\\nFor example, image processing and generation can be accomplished by an agent that draws on a\\nvisual model [ 328]. In aerospace engineering, agents are being explored for modeling physics and\\nsolving complex differential equations [ 356]; in the field of robotics, agents are required to plan\\nphysical operations and control the robot execution [ 179]; and so on. Agents that are capable of\\ndynamically interacting with the environment or the world through tools, or in a multimodal manner,\\ncan be referred to as digitally embodied [ 94]. The embodiment of agents has been a central focus of\\nembodied learning research. We will make a deep discussion on agents’ embodied action in §3.3.3.\\n3.3.3 Embodied Action\\nIn the pursuit of Artificial General Intelligence (AGI), the embodied agent is considered a pivotal\\nparadigm while it strives to integrate model intelligence with the physical world. The Embodiment\\nhypothesis [357] draws inspiration from the human intelligence development process, posing that an\\nagent’s intelligence arises from continuous interaction and feedback with the environment rather than\\nrelying solely on well-curated textbooks. Similarly, unlike traditional deep learning models that learn\\nexplicit capabilities from the internet datasets to solve domain problems, people anticipate that LLM-\\nbased agents’ behaviors will no longer be limited to pure text output or calling exact tools to perform\\n21\\nparticular domain tasks [ 358]. Instead, they should be capable of actively perceiving, comprehending,\\nand interacting with physical environments, making decisions, and generating specific behaviors to\\nmodify the envir', 'The Rise and Potential of Large Language Model.pdf'), 427: ('ll-curated textbooks. Similarly, unlike traditional deep learning models that learn\\nexplicit capabilities from the internet datasets to solve domain problems, people anticipate that LLM-\\nbased agents’ behaviors will no longer be limited to pure text output or calling exact tools to perform\\n21\\nparticular domain tasks [ 358]. Instead, they should be capable of actively perceiving, comprehending,\\nand interacting with physical environments, making decisions, and generating specific behaviors to\\nmodify the environment based on LLM’s extensive internal knowledge. We collectively term these\\nasembodied actions , which enable agents’ ability to interact with and comprehend the world in a\\nmanner closely resembling human behavior.\\nThe potential of LLM-based agents for embodied actions. Before the widespread rise of LLMs,\\nresearchers tended to use methods like reinforcement learning to explore the embodied actions of\\nagents. Despite the extensive success of RL-based embodiment [ 359;360;361], it does have certain\\nlimitations in some aspects. In brief, RL algorithms face limitations in terms of data efficiency,\\ngeneralization, and complex problem reasoning due to challenges in modeling the dynamic and\\noften ambiguous real environment, or their heavy reliance on precise reward signal representations\\n[362]. Recent studies have indicated that leveraging the rich internal knowledge acquired during the\\npre-training of LLMs can effectively alleviate these issues [120; 187; 258; 363].\\n•Cost efficiency. Some on-policy algorithms struggle with sample efficiency as they require fresh\\ndata for policy updates while gathering enough embodied data for high-performance training is\\ncostly and noisy. The constraint is also found in some end-to-end models [ 364;365;366]. By\\nleveraging the intrinsic knowledge from LLMs, agents like PaLM-E [ 120] jointly train robotic data\\nwith general visual-language data to achieve significant transfer ability in embodied tasks while\\nalso showcasing that geometric input representations can improve training dat', 'The Rise and Potential of Large Language Model.pdf'), 428: ('ruggle with sample efficiency as they require fresh\\ndata for policy updates while gathering enough embodied data for high-performance training is\\ncostly and noisy. The constraint is also found in some end-to-end models [ 364;365;366]. By\\nleveraging the intrinsic knowledge from LLMs, agents like PaLM-E [ 120] jointly train robotic data\\nwith general visual-language data to achieve significant transfer ability in embodied tasks while\\nalso showcasing that geometric input representations can improve training data efficiency.\\n•Embodied action generalization. As discussed in section §3.1.5, an agent’s competence should\\nextend beyond specific tasks. When faced with intricate, uncharted real-world environments, it’s\\nimperative that the agent exhibits dynamic learning and generalization capabilities. However,\\nthe majority of RL algorithms are designed to train and evaluate relevant skills for specific tasks\\n[101;367;368;369]. In contrast, fine-tuned by diverse forms and rich task types, LLMs have\\nshowcased remarkable cross-task generalization capabilities [ 370;371]. For instance, PaLM-\\nE exhibits surprising zero-shot or one-shot generalization capabilities to new objects or novel\\ncombinations of existing objects [ 120]. Further, language proficiency represents a distinctive\\nadvantage of LLM-based agents, serving both as a means to interact with the environment and as a\\nmedium for transferring foundational skills to new tasks [ 372]. SayCan [ 179] decomposes task\\ninstructions presented in prompts using LLMs into corresponding skill commands, but in partially\\nobservable environments, limited prior skills often do not achieve satisfactory performance [ 101].\\nTo address this, V oyager [ 190] introduces the skill library component to continuously collect novel\\nself-verified skills, which allows for the agent’s lifelong learning capabilities.\\n•Embodied action planning. Planning constitutes a pivotal strategy employed by humans in\\nresponse to complex problems as well as LLM-based agents. Before LLMs exhibited remarkable\\nreasonin', 'The Rise and Potential of Large Language Model.pdf'), 429: ('nding skill commands, but in partially\\nobservable environments, limited prior skills often do not achieve satisfactory performance [ 101].\\nTo address this, V oyager [ 190] introduces the skill library component to continuously collect novel\\nself-verified skills, which allows for the agent’s lifelong learning capabilities.\\n•Embodied action planning. Planning constitutes a pivotal strategy employed by humans in\\nresponse to complex problems as well as LLM-based agents. Before LLMs exhibited remarkable\\nreasoning abilities, researchers introduced Hierarchical Reinforcement Learning (HRL) methods\\nwhile the high-level policy constraints sub-goals for the low-level policy and the low-level policy\\nproduces appropriate action signals [ 373;374;375]. Similar to the role of high-level policies, LLMs\\nwith emerging reasoning abilities [ 26] can be seamlessly applied to complex tasks in a zero-shot or\\nfew-shot manner [ 95;97;98;99]. In addition, external feedback from the environment can further\\nenhance LLM-based agents’ planning performance. Based on the current environmental feedback,\\nsome work [ 101;91;100;376] dynamically generate, maintain, and adjust high-level action plans\\nin order to minimize dependency on prior knowledge in partially observable environments, thereby\\ngrounding the plan. Feedback can also come from models or humans, which can usually be referred\\nto as the critics, assessing task completion based on the current state and task prompts [25; 190].\\nEmbodied actions for LLM-based agents. Depending on the agents’ level of autonomy in a task\\nor the complexity of actions, there are several fundamental LLM-based embodied actions, primarily\\nincluding observation, manipulation, and navigation.\\n•Observation. Observation constitutes the primary ways by which the agent acquires environmental\\ninformation and updates states, playing a crucial role in enhancing the efficiency of subsequent\\nembodied actions. As mentioned in §3.2, observation by embodied agents primarily occurs in\\nenvironments with various inputs, which are', 'The Rise and Potential of Large Language Model.pdf'), 430: ('nts’ level of autonomy in a task\\nor the complexity of actions, there are several fundamental LLM-based embodied actions, primarily\\nincluding observation, manipulation, and navigation.\\n•Observation. Observation constitutes the primary ways by which the agent acquires environmental\\ninformation and updates states, playing a crucial role in enhancing the efficiency of subsequent\\nembodied actions. As mentioned in §3.2, observation by embodied agents primarily occurs in\\nenvironments with various inputs, which are ultimately converged into a multimodal signal. A\\ncommon approach entails a pre-trained Vision Transformer (ViT) used as the alignment module for\\ntext and visual information and special tokens are marked to denote the positions of multimodal\\ndata [ 120;332;121]. Soundspaces [ 377] proposes the identification of physical spatial geometric\\n22\\nelements guided by reverberant audio input, enhancing the agent’s observations with a more\\ncomprehensive perspective [ 375]. In recent times, even more research takes audio as a modality\\nfor embedded observation. Apart from the widely employed cascading paradigm [293; 378; 316],\\naudio information encoding similar to ViT further enhances the seamless integration of audio\\nwith other modalities of inputs [ 294]. The agent’s observation of the environment can also be\\nderived from real-time linguistic instructions from humans, while human feedback helps the agent\\nin acquiring detail information that may not be readily obtained or parsed [333; 190].\\n•Manipulation. In general, manipulation tasks for embodied agents include object rearrangements,\\ntabletop manipulation, and mobile manipulation [ 23;120]. The typical case entails the agent\\nexecuting a sequence of tasks in the kitchen, which includes retrieving items from drawers and\\nhanding them to the user, as well as cleaning the tabletop [ 179]. Besides precise observation,\\nthis involves combining a series of subgoals by leveraging LLM. Consequently, maintaining\\nsynchronization between the agent’s state and the subgoals is of signi', 'The Rise and Potential of Large Language Model.pdf'), 431: ('nipulation tasks for embodied agents include object rearrangements,\\ntabletop manipulation, and mobile manipulation [ 23;120]. The typical case entails the agent\\nexecuting a sequence of tasks in the kitchen, which includes retrieving items from drawers and\\nhanding them to the user, as well as cleaning the tabletop [ 179]. Besides precise observation,\\nthis involves combining a series of subgoals by leveraging LLM. Consequently, maintaining\\nsynchronization between the agent’s state and the subgoals is of significance. DEPS [ 183] utilizes\\nan LLM-based interactive planning approach to maintain this consistency and help error correction\\nfrom agent’s feedback throughout the multi-step, long-haul reasoning process. In contrast to these,\\nAlphaBlock [ 334] focuses on more challenging manipulation tasks (e.g. making a smiley face\\nusing building blocks), which requires the agent to have a more grounded understanding of the\\ninstructions. Unlike the existing open-loop paradigm, AlphaBlock constructs a dataset comprising\\n35 complex high-level tasks, along with corresponding multi-step planning and observation pairs,\\nand then fine-tunes a multimodal model to enhance its comprehension of high-level cognitive\\ninstructions.\\n•Navigation. Navigation permits agents to dynamically alter their positions within the environ-\\nment, which often involves multi-angle and multi-object observations, as well as long-horizon\\nmanipulations based on current exploration [ 23]. Before navigation, it is essential for embodied\\nagents to establish prior internal maps about the external environment, which are typically in the\\nform of a topological map, semantic map or occupancy map [ 358]. For example, LM-Nav [ 335]\\nutilizes the VNM [ 379] to create an internal topological map. It further leverages the LLM and\\nVLM for decomposing input commands and analyzing the environment to find the optimal path.\\nFurthermore, some [ 380;381] highlight the importance of spatial representation to achieve the\\nprecise localization of spatial targets rather than conventio', 'The Rise and Potential of Large Language Model.pdf'), 432: ('ior internal maps about the external environment, which are typically in the\\nform of a topological map, semantic map or occupancy map [ 358]. For example, LM-Nav [ 335]\\nutilizes the VNM [ 379] to create an internal topological map. It further leverages the LLM and\\nVLM for decomposing input commands and analyzing the environment to find the optimal path.\\nFurthermore, some [ 380;381] highlight the importance of spatial representation to achieve the\\nprecise localization of spatial targets rather than conventional point or object-centric navigation\\nactions by leveraging the pre-trained VLM model to combine visual features from images with 3D\\nreconstructions of the physical world [ 358]. Navigation is usually a long-horizon task, where the\\nupcoming states of the agent are influenced by its past actions. A memory buffer and summary\\nmechanism are needed to serve as a reference for historical information [ 336], which is also\\nemployed in Smallville and V oyager [ 22;190;382;383]. Additionally, as mentioned in §3.2, some\\nworks have proposed the audio input is also of great significance, but integrating audio information\\npresents challenges in associating it with the visual environment. A basic framework includes a\\ndynamic path planner that uses visual and auditory observations along with spatial memories to\\nplan a series of actions for navigation [375; 384].\\nBy integrating these, the agent can accomplish more complex tasks, such as embodied question\\nanswering, whose primary objective is autonomous exploration of the environment, and responding\\nto pre-defined multimodal questions, such as Is the watermelon in the kitchen larger than the pot?\\nWhich one is harder? To address these questions, the agent needs to navigate to the kitchen, observe\\nthe sizes of both objects and then answer the questions through comparison [358].\\nIn terms of control strategies, as previously mentioned, LLM-based agents trained on particular\\nembodied datasets typically generate high-level policy commands to control low-level policies for\\nachieving s', 'The Rise and Potential of Large Language Model.pdf'), 433: ('ironment, and responding\\nto pre-defined multimodal questions, such as Is the watermelon in the kitchen larger than the pot?\\nWhich one is harder? To address these questions, the agent needs to navigate to the kitchen, observe\\nthe sizes of both objects and then answer the questions through comparison [358].\\nIn terms of control strategies, as previously mentioned, LLM-based agents trained on particular\\nembodied datasets typically generate high-level policy commands to control low-level policies for\\nachieving specific sub-goals. The low-level policy can be a robotic transformer [ 120;385;386],\\nwhich takes images and instructions as inputs and produces control commands for the end effector as\\nwell as robotic arms in particular embodied tasks [ 179]. Recently, in virtual embodied environments,\\nthe high-level strategies are utilized to control agents in gaming [ 172;183;190;337] or simulated\\nworlds [ 22;108;109]. For instance, V oyager [ 190] calls the Mineflayer [ 387] API interface to\\ncontinuously acquire various skills and explore the world.\\nProspective future of the embodied action. LLM-based embodied actions are seen as the bridge\\nbetween virtual intelligence and the physical world, enabling agents to perceive and modify the\\nenvironment much like humans. However, there remain several constraints such as high costs of\\nphysical-world robotic operators and the scarcity of embodied datasets, which foster a growing\\n23\\ninterest in investigating agents’ embodied actions within simulated environments like Minecraft\\n[183;338;337;190;339]. By utilizing the Mineflayer [ 387] API, these investigations enable cost-\\neffective examination of a wide range of embodied agents’ operations including exploration, planning,\\nself-improvement, and even lifelong learning [ 190]. Despite notable progress, achieving optimal\\nembodied actions remains a challenge due to the significant disparity between simulated platforms and\\nthe physical world. To enable the effective deployment of embodied agents in real-world scenarios,\\nan increasing demand', 'The Rise and Potential of Large Language Model.pdf'), 434: ('338;337;190;339]. By utilizing the Mineflayer [ 387] API, these investigations enable cost-\\neffective examination of a wide range of embodied agents’ operations including exploration, planning,\\nself-improvement, and even lifelong learning [ 190]. Despite notable progress, achieving optimal\\nembodied actions remains a challenge due to the significant disparity between simulated platforms and\\nthe physical world. To enable the effective deployment of embodied agents in real-world scenarios,\\nan increasing demand exists for embodied task paradigms and evaluation criteria that closely mirror\\nreal-world conditions [ 358]. On the other hand, learning to ground language for agents is also an\\nobstacle. For example, expressions like “jump down like a cat” primarily convey a sense of lightness\\nand tranquility, but this linguistic metaphor requires adequate world knowledge [ 30]. [340] endeavors\\nto amalgamate text distillation with Hindsight Experience Replay (HER) to construct a dataset as\\nthe supervised signal for the training process. Nevertheless, additional investigation on grounding\\nembodied datasets still remains necessary while embodied action plays an increasingly pivotal role\\nacross various domains in human life.\\n4 Agents in Practice: Harnessing AI for Good\\nAgents in Practice:\\nHarnessing AI for GoodSingle Agent\\nDeployment §4.1Task-oriented\\nDeploytment §4.1.1Web scenariosWebAgent [ 388], Mind2Web [ 389],\\nWebGum [ 390], WebArena [ 391],\\nWebshop [ 392], WebGPT [ 90], Kim\\net al. [ 393], Zheng et al. [ 394], etc.\\nLife scenariosInterAct [ 395], PET [ 182], Huang\\net al. [ 258], Gramopadhye et al.\\n[396], Raman et al. [ 256], etc.\\nInnovation-oriented\\nDeploytment §4.1.2Li et al. [ 397], Feldt et al. [ 398], ChatMOF\\n[399], ChemCrow [ 354], Boiko et al.\\n[110], SCIENCEWORLD et al. [ 400], etc.\\nLifecycle-oriented\\nDeploytment §4.1.3V oyager [ 190], GITM [ 172],\\nDEPS [ 183], Plan4MC [ 401],\\nNottingham et al. [ 339], etc.\\nMulti-Agents\\nInteraction §4.2Cooperative\\nInteraction §4.2.1Disordered\\ncooperationChatLLM [ 402], RoCo [ 403],\\nBli', 'The Rise and Potential of Large Language Model.pdf'), 435: ('cenariosInterAct [ 395], PET [ 182], Huang\\net al. [ 258], Gramopadhye et al.\\n[396], Raman et al. [ 256], etc.\\nInnovation-oriented\\nDeploytment §4.1.2Li et al. [ 397], Feldt et al. [ 398], ChatMOF\\n[399], ChemCrow [ 354], Boiko et al.\\n[110], SCIENCEWORLD et al. [ 400], etc.\\nLifecycle-oriented\\nDeploytment §4.1.3V oyager [ 190], GITM [ 172],\\nDEPS [ 183], Plan4MC [ 401],\\nNottingham et al. [ 339], etc.\\nMulti-Agents\\nInteraction §4.2Cooperative\\nInteraction §4.2.1Disordered\\ncooperationChatLLM [ 402], RoCo [ 403],\\nBlind Judgement [ 404], etc.\\nOrdered cooperationMetaGPT [ 405], ChatDev [ 109], CAMEL\\n[108], AutoGen [ 406], SwiftSage [ 185],\\nProAgent [ 407], DERA [ 408], Talebi-\\nrad et al. [ 409], AgentVerse [ 410],\\nCGMI [ 411], Liu et al. [ 27], etc.\\nAdversarial\\nInteraction §4.2.2ChatEval [ 171], Xiong et al.\\n[412], Du et al. [ 111], Fu et al.\\n[129], Liang et al. [ 112], etc.\\nHuman-Agent\\nInteraction §4.3Instructor-Executor\\nParadigm §4.3.1Education Dona [ 413], Math Agents [ 414], etc.\\nHealthHsu et al. [ 415], HuatuoGPT [ 416],\\nZhongjing [ 417], LISSA [ 418], etc.\\nOther ApplicationsGao et al. [ 419], PEER [ 420], DIAL-\\nGEN [ 421], AssistGPT [ 422], etc.\\nEqual Partnership\\nParadigm §4.3.2Empathetic\\nCommunicatorSAPIEN [ 423], Hsu et al.\\n[415], Liu et al. [ 424], etc.\\nHuman-Level\\nParticipantBakhtin et al. [ 425], FAIR et al. [ 426],\\nLin et al. [ 427], Li et al. [ 428], etc.\\nFigure 6: Typology of applications of LLM-based agents.\\nThe LLM-based agent, as an emerging direction, has gained increasing attention from researchers.\\nMany applications in specific domains and tasks have already been developed, showcasing the\\npowerful and versatile capabilities of agents. We can state with great confidence that, the possibility\\nof having a personal agent capable of assisting users with typical daily tasks is larger than ever\\nbefore [ 398]. As an LLM-based agent, its design objective should always be beneficial to humans,\\ni.e., humans can harness AI for good . Specifically, we expect the agent to achieve the following\\nobjectives:\\n24\\nSingle Age', 'The Rise and Potential of Large Language Model.pdf'), 436: (' applications in specific domains and tasks have already been developed, showcasing the\\npowerful and versatile capabilities of agents. We can state with great confidence that, the possibility\\nof having a personal agent capable of assisting users with typical daily tasks is larger than ever\\nbefore [ 398]. As an LLM-based agent, its design objective should always be beneficial to humans,\\ni.e., humans can harness AI for good . Specifically, we expect the agent to achieve the following\\nobjectives:\\n24\\nSingle AgentAgent-AgentAgent-Human\\nFigure 7: Scenarios of LLM-based agent applications. We mainly introduce three scenarios: single-\\nagent deployment, multi-agent interaction, and human-agent interaction. A single agent possesses\\ndiverse capabilities and can demonstrate outstanding task-solving performance in various application\\norientations. When multiple agents interact, they can achieve advancement through cooperative or\\nadversarial interactions. Furthermore, in human-agent interactions, human feedback can enable\\nagents to perform tasks more efficiently and safely, while agents can also provide better service to\\nhumans.\\n1.Assist users in breaking free from daily tasks and repetitive labor, thereby Alleviating human work\\npressure and enhancing task-solving efficiency.\\n2.No longer necessitates users to provide explicit low-level instructions. Instead, the agent can\\nindependently analyze, plan, and solve problems.\\n3.After freeing users’ hands, the agent also liberates their minds to engage in exploratory and\\ninnovative work, realizing their full potential in cutting-edge scientific fields.\\nIn this section, we provide an in-depth overview of current applications of LLM-based agents, aiming\\nto offer a broad perspective for the practical deployment scenarios (see Figure 7). First, we elucidate\\nthe diverse application scenarios of Single Agent, including task-oriented, innovation-oriented, and\\nlifecycle-oriented scenarios (§ 4.1). Then, we present the significant coordinating potential of Multiple\\nAgents. Whether through coo', 'The Rise and Potential of Large Language Model.pdf'), 437: (' work, realizing their full potential in cutting-edge scientific fields.\\nIn this section, we provide an in-depth overview of current applications of LLM-based agents, aiming\\nto offer a broad perspective for the practical deployment scenarios (see Figure 7). First, we elucidate\\nthe diverse application scenarios of Single Agent, including task-oriented, innovation-oriented, and\\nlifecycle-oriented scenarios (§ 4.1). Then, we present the significant coordinating potential of Multiple\\nAgents. Whether through cooperative interaction for complementarity or adversarial interaction\\nfor advancement, both approaches can lead to higher task efficiency and response quality (§ 4.2).\\nFinally, we categorize the interactive collaboration between humans and agents into two paradigms\\nand introduce the main forms and specific applications respectively (§ 4.3). The topological diagram\\nfor LLM-based agent applications is depicted in Figure 6.\\n4.1 General Ability of Single Agent\\nCurrently, there is a vibrant development of application instances of LLM-based agents [ 429;430;\\n431]. AutoGPT [ 114] is one of the ongoing popular open-source projects aiming to achieve a fully\\nautonomous system. Apart from the basic functions of large language models like GPT-4, the\\nAutoGPT framework also incorporates various practical external tools and long/short-term memory\\nmanagement. After users input their customized objectives, they can free their hands and wait\\nfor AutoGPT to automatically generate thoughts and perform specific tasks, all without requiring\\nadditional user prompts.\\nAs shown in Figure 8, we introduce the astonishingly diverse capabilities that the agent exhibits in\\nscenarios where only one single agent is present.\\n4.1.1 Task-oriented Deployment\\nThe LLM-based agents, which can understand human natural language commands and perform\\neveryday tasks [ 391], are currently among the most favored and practically valuable agents by users.\\nThis is because they have the potential to enhance task efficiency, alleviate user workload, and\\npromote ac', 'The Rise and Potential of Large Language Model.pdf'), 438: ('equiring\\nadditional user prompts.\\nAs shown in Figure 8, we introduce the astonishingly diverse capabilities that the agent exhibits in\\nscenarios where only one single agent is present.\\n4.1.1 Task-oriented Deployment\\nThe LLM-based agents, which can understand human natural language commands and perform\\neveryday tasks [ 391], are currently among the most favored and practically valuable agents by users.\\nThis is because they have the potential to enhance task efficiency, alleviate user workload, and\\npromote access for a broader user base. In task-oriented deployment , the agent follows high-level\\ninstructions from users, undertaking tasks such as goal decomposition [ 182;258;388;394], sequence\\nplanning of sub-goals [ 182;395], interactive exploration of the environment [ 256;391;390;392],\\nuntil the final objective is achieved.\\nTo explore whether agents can perform basic tasks, they are first deployed in text-based game\\nscenarios. In this type of game, agents interact with the world purely using natural language [ 432].\\nBy reading textual descriptions of their surroundings and utilizing skills like memory, planning,\\n25\\nTask: Create a New Medicine\\nTask: Maintain a Lifelong Survival\\nTask:Find the UmbrellaInnovation-OrientedLifecycle-Oriented\\n增加光影\\nTask-Oriented\\nInnovation-Oriented\\nLifecycle-Oriented\\nFigure 8: Practical applications of the single LLM-based agent in different scenarios. In task-\\noriented deployment , agents assist human users in solving daily tasks. They need to possess basic\\ninstruction comprehension and task decomposition abilities. In innovation-oriented deployment ,\\nagents demonstrate the potential for autonomous exploration in scientific domains. In lifecycle-\\noriented deployment , agents have the ability to continuously explore, learn, and utilize new skills to\\nensure long-term survival in an open world.\\nand trial-and-error [ 182], they predict the next action. However, due to the limitation of foundation\\nlanguage models, agents often rely on reinforcement learning during actual execution [ 432;433;', 'The Rise and Potential of Large Language Model.pdf'), 439: ('nd task decomposition abilities. In innovation-oriented deployment ,\\nagents demonstrate the potential for autonomous exploration in scientific domains. In lifecycle-\\noriented deployment , agents have the ability to continuously explore, learn, and utilize new skills to\\nensure long-term survival in an open world.\\nand trial-and-error [ 182], they predict the next action. However, due to the limitation of foundation\\nlanguage models, agents often rely on reinforcement learning during actual execution [ 432;433;434].\\nWith the gradual evolution of LLMs [ 301], agents equipped with stronger text understanding and\\ngeneration abilities have demonstrated great potential to perform tasks through natural language. Due\\nto their oversimplified nature, naive text-based scenarios have been inadequate as testing grounds\\nfor LLM-based agents [ 391]. More realistic and complex simulated test environments have been\\nconstructed to meet the demand. Based on task types, we divide these simulated environments into\\nweb scenarios andlife scenarios , and introduce the specific roles that agents play in them.\\nIn web scenarios. Performing specific tasks on behalf of users in a web scenario is known as the\\nweb navigation problem [ 390]. Agents interpret user instructions, break them down into multiple\\nbasic operations, and interact with computers. This often includes web tasks such as filling out\\nforms, online shopping, and sending emails. Agents need to possess the ability to understand\\ninstructions within complex web scenarios, adapt to changes (such as noisy text and dynamic HTML\\nweb pages), and generalize successful operations [ 391]. In this way, agents can achieve accessibility\\nand automation when dealing with unseen tasks in the future [ 435], ultimately freeing humans from\\nrepeated interactions with computer UIs.\\nAgents trained through reinforcement learning can effectively mimic human behavior using predefined\\nactions like typing, searching, navigating to the next page, etc. They perform well in basic tasks\\nsuch as online shopping [ ', 'The Rise and Potential of Large Language Model.pdf'), 440: ('hanges (such as noisy text and dynamic HTML\\nweb pages), and generalize successful operations [ 391]. In this way, agents can achieve accessibility\\nand automation when dealing with unseen tasks in the future [ 435], ultimately freeing humans from\\nrepeated interactions with computer UIs.\\nAgents trained through reinforcement learning can effectively mimic human behavior using predefined\\nactions like typing, searching, navigating to the next page, etc. They perform well in basic tasks\\nsuch as online shopping [ 392] and search engine retrieval [ 90], which have been widely explored.\\nHowever, agents without LLM capabilities may struggle to adapt to the more realistic and complex\\nscenarios in the real-world Internet. In dynamic, content-rich web pages such as online forums or\\nonline business management [391], agents often face challenges in performance.\\nIn order to enable successful interactions between agents and more realistic web pages, some\\nresearchers [ 393;394] have started to leverage the powerful HTML reading and understanding\\nabilities of LLMs. By designing prompts, they attempt to make agents understand the entire HTML\\nsource code and predict more reasonable next action steps. Mind2Web [ 389] combines multiple\\nLLMs fine-tuned for HTML, allowing them to summarize verbose HTML code [ 388] in real-world\\nscenarios and extract valuable information. Furthermore, WebGum [ 390] empowers agents with\\nvisual perception abilities by employing a multimodal corpus containing HTML screenshots. It\\nsimultaneously fine-tunes the LLM and a visual encoder, deepening the agent’s comprehensive\\nunderstanding of web pages.\\nIn life scenarios. In many daily household tasks in life scenarios, it’s essential for agents to\\nunderstand implicit instructions and apply common-sense knowledge [ 433]. For an LLM-based agent\\ntrained solely on massive amounts of text, tasks that humans take for granted might require multiple\\n26\\ntrial-and-error attempts [ 432]. More realistic scenarios often lead to more obscure and subtle tasks.\\nFor example, the ', 'The Rise and Potential of Large Language Model.pdf'), 441: ('the LLM and a visual encoder, deepening the agent’s comprehensive\\nunderstanding of web pages.\\nIn life scenarios. In many daily household tasks in life scenarios, it’s essential for agents to\\nunderstand implicit instructions and apply common-sense knowledge [ 433]. For an LLM-based agent\\ntrained solely on massive amounts of text, tasks that humans take for granted might require multiple\\n26\\ntrial-and-error attempts [ 432]. More realistic scenarios often lead to more obscure and subtle tasks.\\nFor example, the agent should proactively turn it on if it’s dark and there’s a light in the room. To\\nsuccessfully chop some vegetables in the kitchen, the agent needs to anticipate the possible location\\nof a knife [182].\\nCan an agent apply the world knowledge embedded in its training data to real interaction scenarios?\\nHuang et al. [ 258] lead the way in exploring this question. They demonstrate that sufficiently large\\nLLMs, with appropriate prompts, can effectively break down high-level tasks into suitable sub-tasks\\nwithout additional training. However, this static reasoning and planning ability has its potential\\ndrawbacks. Actions generated by agents often lack awareness of the dynamic environment around\\nthem. For instance, when a user gives the task “clean the room”, the agent might convert it into\\nunfeasible sub-tasks like “call a cleaning service” [396].\\nTo provide agents with access to comprehensive scenario information during interactions, some\\napproaches directly incorporate spatial data and item-location relationships as additional inputs to\\nthe model. This allows agents to gain a precise description of their surroundings [ 395;396]. Wu\\net al. [ 182] introduce the PET framework, which mitigates irrelevant objects and containers in\\nenvironmental information through an early error correction method [ 256]. PET encourages agents\\nto explore the scenario and plan actions more efficiently, focusing on the current sub-task.\\n4.1.2 Innovation-oriented Deployment\\nThe LLM-based agent has demonstrated strong capabilities in perfo', 'The Rise and Potential of Large Language Model.pdf'), 442: ('ps as additional inputs to\\nthe model. This allows agents to gain a precise description of their surroundings [ 395;396]. Wu\\net al. [ 182] introduce the PET framework, which mitigates irrelevant objects and containers in\\nenvironmental information through an early error correction method [ 256]. PET encourages agents\\nto explore the scenario and plan actions more efficiently, focusing on the current sub-task.\\n4.1.2 Innovation-oriented Deployment\\nThe LLM-based agent has demonstrated strong capabilities in performing tasks and enhancing the\\nefficiency of repetitive work. However, in a more intellectually demanding field, like cutting-edge\\nscience, the potential of agents has not been fully realized yet. This limitation mainly arises from\\ntwo challenges [ 399]: On one hand, the inherent complexity of science poses a significant barrier.\\nMany domain-specific terms and multi-dimensional structures are difficult to represent using a single\\ntext. As a result, their complete attributes cannot be fully encapsulated. This greatly weakens the\\nagent’s cognitive level. On the other hand, there is a severe lack of suitable training data in scientific\\ndomains, making it difficult for agents to comprehend the entire domain knowledge [ 400;436]. If the\\nability for autonomous exploration could be discovered within the agent, it would undoubtedly bring\\nabout beneficial innovation in human technology.\\nCurrently, numerous efforts in various specialized domains aim to overcome this challenge [ 437;438;\\n439]. Experts from the computer field make full use of the agent’s powerful code comprehension\\nand debugging abilities [ 398;397]. In the fields of chemistry and materials, researchers equip agents\\nwith a large number of general or task-specific tools to better understand domain knowledge. Agents\\nevolve into comprehensive scientific assistants, proficient in online research and document analysis to\\nfill data gaps. They also employ robotic APIs for real-world interactions, enabling tasks like material\\nsynthesis and mechanism discovery [110;', 'The Rise and Potential of Large Language Model.pdf'), 443: ('ield make full use of the agent’s powerful code comprehension\\nand debugging abilities [ 398;397]. In the fields of chemistry and materials, researchers equip agents\\nwith a large number of general or task-specific tools to better understand domain knowledge. Agents\\nevolve into comprehensive scientific assistants, proficient in online research and document analysis to\\nfill data gaps. They also employ robotic APIs for real-world interactions, enabling tasks like material\\nsynthesis and mechanism discovery [110; 354; 399].\\nThe potential of LLM-based agents in scientific innovation is evident, yet we do not expect their\\nexploratory abilities to be utilized in applications that could threaten or harm humans. Boiko et\\nal. [110] study the hidden dangers of agents in synthesizing illegal drugs and chemical weapons,\\nindicating that agents could be misled by malicious users in adversarial prompts. This serves as a\\nwarning for our future work.\\n4.1.3 Lifecycle-oriented Deployment\\nBuilding a universally capable agent that can continuously explore, develop new skills, and maintain\\na long-term life cycle in an open, unknown world is a colossal challenge. This accomplishment is\\nregarded as a pivotal milestone in the field of AGI [ 183]. Minecraft, as a typical and widely explored\\nsimulated survival environment, has become a unique playground for developing and testing the\\ncomprehensive ability of an agent. Players typically start by learning the basics, such as mining\\nwood and making crafting tables, before moving on to more complex tasks like fighting against\\nmonsters and crafting diamond tools [ 190]. Minecraft fundamentally reflects the real world, making\\nit conducive for researchers to investigate an agent’s potential to survive in the authentic world.\\nThe survival algorithms of agents in Minecraft can generally be categorized into two types [ 190]:\\nlow-level control andhigh-level planning . Early efforts mainly focused on reinforcement learning\\n[190;440] and imitation learning [ 441], enabling agents to craft some low-level i', 'The Rise and Potential of Large Language Model.pdf'), 444: ('plex tasks like fighting against\\nmonsters and crafting diamond tools [ 190]. Minecraft fundamentally reflects the real world, making\\nit conducive for researchers to investigate an agent’s potential to survive in the authentic world.\\nThe survival algorithms of agents in Minecraft can generally be categorized into two types [ 190]:\\nlow-level control andhigh-level planning . Early efforts mainly focused on reinforcement learning\\n[190;440] and imitation learning [ 441], enabling agents to craft some low-level items. With the\\nemergence of LLMs, which demonstrated surprising reasoning and analytical capabilities, agents\\n27\\nbegin to utilize LLM as a high-level planner to guide simulated survival tasks [ 183;339]. Some\\nresearchers use LLM to decompose high-level task instructions into a series of sub-goals [ 401], basic\\nskill sequences [ 339], or fundamental keyboard/mouse operations [ 401], gradually assisting agents in\\nexploring the open world.\\nV oyager[ 190], drawing inspiration from concepts similar to AutoGPT[ 114], became the first LLM-\\nbased embodied lifelong learning agent in Minecraft, based on the long-term goal of “discovering\\nas many diverse things as possible”. It introduces a skill library for storing and retrieving complex\\naction-executable code, along with an iterative prompt mechanism that incorporates environmental\\nfeedback and error correction. This enables the agent to autonomously explore and adapt to unknown\\nenvironments without human intervention. An AI agent capable of autonomously learning and\\nmastering the entire real-world techniques may not be as distant as once thought [401].\\n4.2 Coordinating Potential of Multiple Agents\\nMotivation and Background. Although LLM-based agents possess commendable text under-\\nstanding and generation capabilities, they operate as isolated entities in nature [ 409]. They lack the\\nability to collaborate with other agents and acquire knowledge from social interactions. This inherent\\nlimitation restricts their potential to learn from multi-turn feedback from others to ', 'The Rise and Potential of Large Language Model.pdf'), 445: ('mastering the entire real-world techniques may not be as distant as once thought [401].\\n4.2 Coordinating Potential of Multiple Agents\\nMotivation and Background. Although LLM-based agents possess commendable text under-\\nstanding and generation capabilities, they operate as isolated entities in nature [ 409]. They lack the\\nability to collaborate with other agents and acquire knowledge from social interactions. This inherent\\nlimitation restricts their potential to learn from multi-turn feedback from others to enhance their\\nperformance [ 27]. Moreover, they cannot be effectively deployed in complex scenarios requiring\\ncollaboration and information sharing among multiple agents.\\nAs early as 1986, Marvin Minsky made a forward-looking prediction. In his book The Society of\\nMind [442], he introduced a novel theory of intelligence, suggesting that intelligence emerges from\\nthe interactions of many smaller agents with specific functions. For instance, certain agents might be\\nresponsible for pattern recognition, while others might handle decision-making or generate solutions.\\nThis idea has been put into concrete practice with the rise of distributed artificial intelligence [ 443].\\nMulti-agent systems(MAS) [ 4], as one of the primary research domains, focus on how a group of\\nagents can effectively coordinate and collaborate to solve problems. Some specialized communication\\nlanguages, like KQML [ 444], were designed early on to support message transmission and knowledge\\nsharing among agents. However, their message formats were relatively fixed, and the semantic\\nexpression capacity was limited. In the 21st century, integrating reinforcement learning algorithms\\n(such as Q-learning) with deep learning has become a prominent technique for developing MAS that\\noperate in complex environments [ 445]. Nowadays, the construction approach based on LLMs is\\nbeginning to demonstrate remarkable potential. The natural language communication between agents\\nhas become more elegant and easily comprehensible to humans, resulting in a significan', 'The Rise and Potential of Large Language Model.pdf'), 446: ('ere relatively fixed, and the semantic\\nexpression capacity was limited. In the 21st century, integrating reinforcement learning algorithms\\n(such as Q-learning) with deep learning has become a prominent technique for developing MAS that\\noperate in complex environments [ 445]. Nowadays, the construction approach based on LLMs is\\nbeginning to demonstrate remarkable potential. The natural language communication between agents\\nhas become more elegant and easily comprehensible to humans, resulting in a significant leap in\\ninteraction efficiency.\\nPotential advantages. Specifically, an LLM-based multi-agent system can offer several advantages.\\nJust as Adam Smith clearly stated in The Wealth of Nations [446], “The greatest improvements in the\\nproductive powers of labor, and most of the skill, dexterity, and judgment with which it is directed or\\napplied, seem to be results of the division of labor.” Based on the principle of division of labor, a\\nsingle agent equipped with specialized skills and domain knowledge can engage in specific tasks. On\\nthe one hand, agents’ skills in handling specific tasks are increasingly refined through the division\\nof labor. On the other hand, decomposing complex tasks into multiple subtasks can eliminate the\\ntime spent switching between different processes. In the end, efficient division of labor among\\nmultiple agents can accomplish a significantly greater workload than when there is no specialization,\\nsubstantially improving the overall system’s efficiency and output quality.\\nIn § 4.1, we have provided a comprehensive introduction to the versatile abilities of LLM-based\\nagents. Therefore, in this section, we focus on exploring the ways agents interact with each other in a\\nmulti-agent environment. Based on current research, these interactions can be broadly categorized\\nas follows: Cooperative Interaction for Complementarity andAdversarial Interaction for\\nAdvancement (see Figure 9).\\n4.2.1 Cooperative Interaction for Complementarity\\nCooperative multi-agent systems are the most widely deployed pa', 'The Rise and Potential of Large Language Model.pdf'), 447: ('ave provided a comprehensive introduction to the versatile abilities of LLM-based\\nagents. Therefore, in this section, we focus on exploring the ways agents interact with each other in a\\nmulti-agent environment. Based on current research, these interactions can be broadly categorized\\nas follows: Cooperative Interaction for Complementarity andAdversarial Interaction for\\nAdvancement (see Figure 9).\\n4.2.1 Cooperative Interaction for Complementarity\\nCooperative multi-agent systems are the most widely deployed pattern in practical usage. Within\\nsuch systems, individual agent assesses the needs and capabilities of other agents and actively seeks\\ncollaborative actions and information sharing with them [ 108]. This approach brings forth numerous\\npotential benefits, including enhanced task efficiency, collective decision improvement, and the\\n28\\nLet’s…\\nThe theme of our product is …Manager Designer Engineer \\nThe architecture of the product is …\\nAdversarial Interactions\\nI think the first step is …\\nTo create a product, we should …Designer \\nFirstly, we should…\\n&%#*…\\nIn order to develop a product, it is important that we...\\n…\\nI will …Tester \\nThe product has the following issues: … \\nI think users need a simplified interface.Designer \\nGood idea,but...technical limitations might affect performance.Engineer \\nTrue... while simplification does enhance user experience.\\nYeah, but performance issues  also impact overall satisfaction. I will try my best to balance both aspects.Engineer \\nProgramming …defmain(): \\nCooperative Engagement\\nDisordered\\nOrderedFigure 9: Interaction scenarios for multiple LLM-based agents. In cooperative interaction , agents\\ncollaborate in either a disordered or ordered manner to achieve shared objectives. In adversarial\\ninteraction , agents compete in a tit-for-tat fashion to enhance their respective performance.\\nresolution of complex real-world problems that one single agent cannot solve independently, ulti-\\nmately achieving the goal of synergistic complementarity. In current LLM-based multi-agent systems,\\ncommun', 'The Rise and Potential of Large Language Model.pdf'), 448: ('sordered\\nOrderedFigure 9: Interaction scenarios for multiple LLM-based agents. In cooperative interaction , agents\\ncollaborate in either a disordered or ordered manner to achieve shared objectives. In adversarial\\ninteraction , agents compete in a tit-for-tat fashion to enhance their respective performance.\\nresolution of complex real-world problems that one single agent cannot solve independently, ulti-\\nmately achieving the goal of synergistic complementarity. In current LLM-based multi-agent systems,\\ncommunication between agents predominantly employs natural language, which is considered the\\nmost natural and human-understandable form of interaction [ 108]. We introduce and categorize\\nexisting cooperative multi-agent applications into two types: disordered cooperation and ordered\\ncooperation.\\nDisordered cooperation. When three or more agents are present within a system, each agent is\\nfree to express their perspectives and opinions openly. They can provide feedback and suggestions for\\nmodifying responses related to the task at hand [ 403]. This entire discussion process is uncontrolled,\\nlacking any specific sequence, and without introducing a standardized collaborative workflow. We\\nrefer to this kind of multi-agent cooperation as disordered cooperation .\\nChatLLM network [ 402] is an exemplary representative of this concept. It emulates the forward and\\nbackward propagation process within a neural network, treating each agent as an individual node.\\nAgents in the subsequent layer need to process inputs from all the preceding agents and propagate\\nforward. One potential solution is introducing a dedicated coordinating agent in multi-agent systems,\\nresponsible for integrating and organizing responses from all agents, thus updating the final answer\\n[447]. However, consolidating a large amount of feedback data and extracting valuable insights poses\\na significant challenge for the coordinating agent.\\nFurthermore, majority voting can also serve as an effective approach to making appropriate decisions.\\nHowever, there is limit', 'The Rise and Potential of Large Language Model.pdf'), 449: ('preceding agents and propagate\\nforward. One potential solution is introducing a dedicated coordinating agent in multi-agent systems,\\nresponsible for integrating and organizing responses from all agents, thus updating the final answer\\n[447]. However, consolidating a large amount of feedback data and extracting valuable insights poses\\na significant challenge for the coordinating agent.\\nFurthermore, majority voting can also serve as an effective approach to making appropriate decisions.\\nHowever, there is limited research that integrates this module into multi-agent systems at present.\\nHamilton [ 404] trains nine independent supreme justice agents to better predict judicial rulings in the\\nU.S. Supreme Court, and decisions are made through a majority voting process.\\nOrdered cooperation. When agents in the system adhere to specific rules, for instance, expressing\\ntheir opinions one by one in a sequential manner, downstream agents only need to focus on the outputs\\nfrom upstream. This leads to a significant improvement in task completion efficiency, The entire\\ndiscussion process is highly organized and ordered. We term this kind of multi-agent cooperation as\\nordered cooperation . It’s worth noting that systems with only two agents, essentially engaging in a\\nconversational manner through a back-and-forth interaction, also fall under the category of ordered\\ncooperation.\\nCAMEL [ 108] stands as a successful implementation of a dual-agent cooperative system. Within a\\nrole-playing communication framework, agents take on the roles of AI Users (giving instructions) and\\nAI Assistants (fulfilling requests by providing specific solutions). Through multi-turn dialogues, these\\nagents autonomously collaborate to fulfill user instructions [ 408]. Some researchers have integrated\\nthe idea of dual-agent cooperation into a single agent’s operation [ 185], alternating between rapid\\nand deliberate thought processes to excel in their respective areas of expertise.\\n29\\nTalebirad et al. [ 409] are among the first to systematically introduce a c', 'The Rise and Potential of Large Language Model.pdf'), 450: ('roles of AI Users (giving instructions) and\\nAI Assistants (fulfilling requests by providing specific solutions). Through multi-turn dialogues, these\\nagents autonomously collaborate to fulfill user instructions [ 408]. Some researchers have integrated\\nthe idea of dual-agent cooperation into a single agent’s operation [ 185], alternating between rapid\\nand deliberate thought processes to excel in their respective areas of expertise.\\n29\\nTalebirad et al. [ 409] are among the first to systematically introduce a comprehensive LLM-based\\nmulti-agent collaboration framework. This paradigm aims to harness the strengths of each individual\\nagent and foster cooperative relationships among them. Many applications of multi-agent cooperation\\nhave successfully been built upon this foundation [ 27;406;407;448]. Furthermore, AgentVerse [ 410]\\nconstructs a versatile, multi-task-tested framework for group agents cooperation. It can assemble a\\nteam of agents that dynamically adapt according to the task’s complexity. To promote more efficient\\ncollaboration, researchers hope that agents can learn from successful human cooperation examples\\n[109]. MetaGPT [ 405] draws inspiration from the classic waterfall model in software development,\\nstandardizing agents’ inputs/outputs as engineering documents. By encoding advanced human process\\nmanagement experience into agent prompts, collaboration among multiple agents becomes more\\nstructured.\\nHowever, during MetaGPT’s practical exploration, a potential threat to multi-agent cooperation has\\nbeen identified. Without setting corresponding rules, frequent interactions among multiple agents can\\namplify minor hallucinations indefinitely [ 405]. For example, in software development, issues like\\nincomplete functions, missing dependencies, and bugs that are imperceptible to the human eye may\\narise. Introducing techniques like cross-validation [ 109] or timely external feedback could have a\\npositive impact on the quality of agent outputs.\\n4.2.2 Adversarial Interaction for Advancement\\nTraditionally, cooperati', 'The Rise and Potential of Large Language Model.pdf'), 451: ('dentified. Without setting corresponding rules, frequent interactions among multiple agents can\\namplify minor hallucinations indefinitely [ 405]. For example, in software development, issues like\\nincomplete functions, missing dependencies, and bugs that are imperceptible to the human eye may\\narise. Introducing techniques like cross-validation [ 109] or timely external feedback could have a\\npositive impact on the quality of agent outputs.\\n4.2.2 Adversarial Interaction for Advancement\\nTraditionally, cooperative methods have been extensively explored in multi-agent systems. However,\\nresearchers increasingly recognize that introducing concepts from game theory [ 449;450] into\\nsystems can lead to more robust and efficient behaviors. In competitive environments, agents can\\nswiftly adjust strategies through dynamic interactions, striving to select the most advantageous or\\nrational actions in response to changes caused by other agents. Successful applications in Non-\\nLLM-based competitive domains already exist [ 360;451]. AlphaGo Zero [ 452], for instance, is\\nan agent for Go that achieved significant breakthroughs through a process of self-play. Similarly,\\nwithin LLM-based multi-agent systems, fostering change among agents can naturally occur through\\ncompetition, argumentation, and debate [ 453;454]. By abandoning rigid beliefs and engaging in\\nthoughtful reflection, adversarial interaction enhances the quality of responses.\\nResearchers first delve into the fundamental debating abilities of LLM-based agents [ 129;412].\\nFindings demonstrate that when multiple agents express their arguments in the state of “tit for tat”,\\none agent can receive substantial external feedback from other agents, thereby correcting its distorted\\nthoughts [ 112]. Consequently, multi-agent adversarial systems find broad applicability in scenarios\\nrequiring high-quality responses and accurate decision-making. In reasoning tasks, Du et al. [ 111]\\nintroduce the concept of debate, endowing agents with responses from fellow peers. When these\\nresponses d', 'The Rise and Potential of Large Language Model.pdf'), 452: ('Findings demonstrate that when multiple agents express their arguments in the state of “tit for tat”,\\none agent can receive substantial external feedback from other agents, thereby correcting its distorted\\nthoughts [ 112]. Consequently, multi-agent adversarial systems find broad applicability in scenarios\\nrequiring high-quality responses and accurate decision-making. In reasoning tasks, Du et al. [ 111]\\nintroduce the concept of debate, endowing agents with responses from fellow peers. When these\\nresponses diverge from an agent’s own judgments, a “mental” argumentation occurs, leading to\\nrefined solutions. ChatEval [ 171] establishes a role-playing-based multi-agent referee team. Through\\nself-initiated debates, agents evaluate the quality of text generated by LLMs, reaching a level of\\nexcellence comparable to human evaluators.\\nThe performance of the multi-agent adversarial system has shown considerable promise. However,\\nthe system is essentially dependent on the strength of LLMs and faces several basic challenges:\\n• With prolonged debate, LLM’s limited context cannot process the entire input.\\n• In a multi-agent environment, computational overhead significantly increases.\\n•Multi-agent negotiation may converge to an incorrect consensus, and all agents are firmly convinced\\nof its accuracy [111].\\nThe development of multi-agent systems is still far from being mature and feasible. Introducing\\nhuman guides when appropriate to compensate for agents’ shortcomings is a good choice to promote\\nthe further advancements of agents.\\n4.3 Interactive Engagement between Human and Agent\\nHuman-agent interaction, as the name suggests, involves agents collaborating with humans to accom-\\nplish tasks. With the enhancement of agent capabilities, human involvement becomes progressively\\nessential to effectively guide and oversee agents’ actions, ensuring they align with human require-\\nments and objectives [ 455;456]. Throughout the interaction, humans play a pivotal role by offering\\n30\\nDesigning an energy-saving product.\\nInstruct/Feedback\\nOu', 'The Rise and Potential of Large Language Model.pdf'), 453: (\"ents.\\n4.3 Interactive Engagement between Human and Agent\\nHuman-agent interaction, as the name suggests, involves agents collaborating with humans to accom-\\nplish tasks. With the enhancement of agent capabilities, human involvement becomes progressively\\nessential to effectively guide and oversee agents’ actions, ensuring they align with human require-\\nments and objectives [ 455;456]. Throughout the interaction, humans play a pivotal role by offering\\n30\\nDesigning an energy-saving product.\\nInstruct/Feedback\\nOutput\\nPerpetual motion is impossible.Human as instructorAgent as executor\\nIt's tough, everything feels heavy right now.\\nSo stressed lately, can't get myself to do anything.\\nThe product is a perpetual motion machine capable of...\\n5/10\\nThe product is capable of efficient...\\nYeah, thanks for understanding.\\nInstructor-Executor ParadigmEqual Partnership ParadigmFigure 10: Two paradigms of human-agent interaction. In the instructor-executor paradigm (left),\\nhumans provide instructions or feedback, while agents act as executors. In the equal partnership\\nparadigm (right), agents are human-like, able to engage in empathetic conversation and participate in\\ncollaborative tasks with humans.\\nguidance or by regulating the safety, legality, and ethical conduct of agents. This is particularly crucial\\nin specialized domains, such as medicine where data privacy concerns exist [ 457]. In such cases,\\nhuman involvement can serve as a valuable means to compensate for the lack of data, thereby facili-\\ntating smoother and more secure collaborative processes. Moreover, considering the anthropological\\naspect, language acquisition in humans predominantly occurs through communication and interaction\\n[458], as opposed to merely consuming written content. As a result, agents shouldn’t exclusively\\ndepend on models trained with pre-annotated datasets; instead, they should evolve through online\\ninteraction and engagement. The interaction between humans and agents can be classified into two\\nparadigms (see Figure 10): (1) Unequal interaction (i.e\", 'The Rise and Potential of Large Language Model.pdf'), 454: (' collaborative processes. Moreover, considering the anthropological\\naspect, language acquisition in humans predominantly occurs through communication and interaction\\n[458], as opposed to merely consuming written content. As a result, agents shouldn’t exclusively\\ndepend on models trained with pre-annotated datasets; instead, they should evolve through online\\ninteraction and engagement. The interaction between humans and agents can be classified into two\\nparadigms (see Figure 10): (1) Unequal interaction (i.e., instructor-executor paradigm): humans\\nserve as issuers of instructions, while agents act as executors, essentially participating as assistants to\\nhumans in collaboration. (2) Equal interaction (i.e., equal partnership paradigm): agents reach the\\nlevel of humans, participating on an equal footing with humans in interaction.\\n4.3.1 Instructor-Executor Paradigm\\nThe simplest approach involves human guidance throughout the process: humans provide clear and\\nspecific instructions directly, while the agents’ role is to understand natural language commands from\\nhumans and translate them into corresponding actions [ 459;460;461]. In §4.1, we have presented\\nthe scenario where agents solve single-step problems or receive high-level instructions from humans.\\nConsidering the interactive nature of language, in this section, we assume that the dialogue between\\nhumans and agents is also interactive. Thanks to LLMs, the agents are able to interact with humans\\nin a conversational manner: the agent responds to each human instruction, refining its action through\\nalternating iterations to ultimately meet human requirements [ 190]. While this approach does achieve\\nthe goal of human-agent interaction, it places significant demands on humans. It requires a substantial\\namount of human effort and, in certain tasks, might even necessitate a high level of expertise. To\\nalleviate this issue, the agent can be empowered to autonomously accomplish tasks, while humans\\nonly need to provide feedback in certain circumstances. Here, we roughly ca', 'The Rise and Potential of Large Language Model.pdf'), 455: ('uction, refining its action through\\nalternating iterations to ultimately meet human requirements [ 190]. While this approach does achieve\\nthe goal of human-agent interaction, it places significant demands on humans. It requires a substantial\\namount of human effort and, in certain tasks, might even necessitate a high level of expertise. To\\nalleviate this issue, the agent can be empowered to autonomously accomplish tasks, while humans\\nonly need to provide feedback in certain circumstances. Here, we roughly categorize feedback into\\ntwo types: quantitative feedback and qualitative feedback.\\nQuantitative feedback. The forms of quantitative feedback mainly include absolute evaluations\\nlike binary scores and ratings, as well as relative scores. Binary feedback refers to the positive and\\nnegative evaluations provided by humans, which agents utilize to enhance their self-optimization\\n[462;463;464;465;466]. Comprising only two categories, this type of user feedback is often\\neasy to collect, but sometimes it may oversimplify user intent by neglecting potential intermediate\\nscenarios. To showcase these intermediate scenarios, researchers attempt to expand from binary\\nfeedback to rating feedback, which involves categorizing into more fine-grained levels. However, the\\nresults of Kreutzer et al. [ 467] suggest that there could be significant discrepancies between user and\\nexpert annotations for such multi-level artificial ratings, indicating that this labeling method might be\\n31\\ninefficient or less reliable. Furthermore, agents can learn human preference from comparative scores\\nlike multiple choice [468; 469].\\nQualitative feedback. Text feedback is usually offered in natural language, particularly for re-\\nsponses that may need improvement. The format of this feedback is quite flexible. Humans provide\\nadvice on how to modify outputs generated by agents, and the agents then incorporate these sug-\\ngestions to refine their subsequent outputs [ 470;471]. For agents without multimodal perception\\ncapabilities, humans can also act as c', 'The Rise and Potential of Large Language Model.pdf'), 456: ('ts can learn human preference from comparative scores\\nlike multiple choice [468; 469].\\nQualitative feedback. Text feedback is usually offered in natural language, particularly for re-\\nsponses that may need improvement. The format of this feedback is quite flexible. Humans provide\\nadvice on how to modify outputs generated by agents, and the agents then incorporate these sug-\\ngestions to refine their subsequent outputs [ 470;471]. For agents without multimodal perception\\ncapabilities, humans can also act as critics, offering visual critiques [ 190], for instance. Additionally,\\nagents can utilize a memory module to store feedback for future reuse [472]. In [473], humans give\\nfeedback on the initial output generated by agents, prompting the agents to formulate various improve-\\nment proposals. The agents then discern and adopt the most suitable proposal, harmonizing with the\\nhuman feedback. While this approach can better convey human intention compared to quantitative\\nfeedback, it might be more challenging for the agents to comprehend. Xu et al. [ 474] compare various\\ntypes of feedback and observe that combining multiple types of feedback can yield better results.\\nRe-training models based on feedback from multiple rounds of interaction (i.e., continual learning)\\ncan further enhance effectiveness. Of course, the collaborative nature of human-agent interaction also\\nallows humans to directly improve the content generated by agents. This could involve modifying\\nintermediate links [ 189;475] or adjusting the conversation content [ 421]. In some studies, agents can\\nautonomously judge whether the conversation is proceeding smoothly and seek feedback when errors\\nare generated [ 476;477]. Humans can also choose to participate in feedback at any time, guiding the\\nagent’s learning in the right direction [420].\\nCurrently, in addition to tasks like writing [ 466] and semantic parsing [ 463;471], the model of using\\nagents as human assistants also holds tremendous potential in the field of education. For instance,\\nKalvakurth et al. ', 'The Rise and Potential of Large Language Model.pdf'), 457: (' content [ 421]. In some studies, agents can\\nautonomously judge whether the conversation is proceeding smoothly and seek feedback when errors\\nare generated [ 476;477]. Humans can also choose to participate in feedback at any time, guiding the\\nagent’s learning in the right direction [420].\\nCurrently, in addition to tasks like writing [ 466] and semantic parsing [ 463;471], the model of using\\nagents as human assistants also holds tremendous potential in the field of education. For instance,\\nKalvakurth et al. [ 413] propose the robot Dona, which supports multimodal interactions to assist\\nstudents with registration. Gvirsman et al. [ 478] focus on early childhood education, achieving\\nmultifaceted interactions between young children, parents, and agents. Agents can also aid in human\\nunderstanding and utilization of mathematics [ 414]. In the field of medicine, some medical agents\\nhave been proposed, showing enormous potential in terms of diagnosis assistance, consultations, and\\nmore [ 416;417]. Especially in mental health, research has shown that agents can lead to increased\\naccessibility due to benefits such as reduced cost, time efficiency, and anonymity compared to face-to-\\nface treatment [ 479]. Leveraging such advantages, agents have found widespread applications. Ali et\\nal. [418] design LISSA for online communication with adolescents on the autism spectrum, analyzing\\nusers’ speech and facial expressions in real-time to engage them in multi-topic conversations and\\nprovide instant feedback regarding non-verbal cues. Hsu et al. [ 415] build contextualized language\\ngeneration approaches to provide tailored assistance for users who seek support on diverse topics\\nranging from relationship stress to anxiety. Furthermore, in other industries including business, a\\ngood agent possesses the capability to provide automated services or assist humans in completing\\ntasks, thereby effectively reducing labor costs [ 419]. Amidst the pursuit of AGI, efforts are directed\\ntowards enhancing the multifaceted capabilities of general a', 'The Rise and Potential of Large Language Model.pdf'), 458: ('ues. Hsu et al. [ 415] build contextualized language\\ngeneration approaches to provide tailored assistance for users who seek support on diverse topics\\nranging from relationship stress to anxiety. Furthermore, in other industries including business, a\\ngood agent possesses the capability to provide automated services or assist humans in completing\\ntasks, thereby effectively reducing labor costs [ 419]. Amidst the pursuit of AGI, efforts are directed\\ntowards enhancing the multifaceted capabilities of general agents, creating agents that can function\\nas universal assistants in real-life scenarios [422].\\n4.3.2 Equal Partnership Paradigm\\nEmpathetic communicator. With the rapid development of AI, conversational agents have garnered\\nextensive attention in research fields in various forms, such as personalized custom roles and virtual\\nchatbots [ 480]. It has found practical applications in everyday life, business, education, healthcare,\\nand more [ 481;482;483]. However, in the eyes of the public, agents are perceived as emotionless\\nmachines, and can never replace humans. Although it is intuitive that agents themselves do not possess\\nemotions, can we enable them to exhibit emotions and thereby bridge the gap between agents and\\nhumans? Therefore, a plethora of research endeavors have embarked on delving into the empathetic\\ncapacities of agents. This endeavor seeks to infuse a human touch into these agents, enabling them to\\ndetect sentiments and emotions from human expressions, ultimately crafting emotionally resonant\\ndialogues [ 484;485;486;487;488;489;490;491]. Apart from generating emotionally charged\\nlanguage, agents can dynamically adjust their emotional states and display them through facial\\nexpressions and voice [ 423]. These studies, viewing agents as empathetic communicators, not only\\nenhance user satisfaction but also make significant progress in fields like healthcare [ 415;418;492]\\nand business marketing [ 424]. Unlike simple rule-based conversation agents, agents with empathetic\\ncapacities can tailor their inter', 'The Rise and Potential of Large Language Model.pdf'), 459: ('ogues [ 484;485;486;487;488;489;490;491]. Apart from generating emotionally charged\\nlanguage, agents can dynamically adjust their emotional states and display them through facial\\nexpressions and voice [ 423]. These studies, viewing agents as empathetic communicators, not only\\nenhance user satisfaction but also make significant progress in fields like healthcare [ 415;418;492]\\nand business marketing [ 424]. Unlike simple rule-based conversation agents, agents with empathetic\\ncapacities can tailor their interactions to meet users’ emotional needs [493].\\n32\\nHuman-level participant. Furthermore, we hope that agents can be involved in the normal lives of\\nhumans, cooperating with humans to complete tasks from a human-level perspective. In the field\\nof games, agents have already reached a high level. As early as the 1990s, IBM introduced the\\nAI Deep Blue [ 451], which defeated the reigning world champion in chess at that time. However,\\nin pure competitive environments such as chess [ 451], Go [ 360], and poker [ 494], the value of\\ncommunication was not emphasized [ 426]. In many gaming tasks, players need to collaborate with\\neach other, devising unified cooperative strategies through effective negotiation [ 425;426;495;496].\\nIn these scenarios, agents need to first understand the beliefs, goals, and intentions of others, formulate\\njoint action plans for their objectives, and also provide relevant suggestions to facilitate the acceptance\\nof cooperative actions by other agents or humans. In comparison to pure agent cooperation, we desire\\nhuman involvement for two main reasons: first, to ensure interpretability, as interactions between\\npure agents could generate incomprehensible language [ 495]; second, to ensure controllability, as the\\npursuit of agents with complete “free will” might lead to unforeseen negative consequences, carrying\\nthe potential for disruption. Apart from gaming scenarios, agents also demonstrate human-level\\ncapabilities in other scenarios involving human interaction, showcasing skills in strategy form', 'The Rise and Potential of Large Language Model.pdf'), 460: ('eration, we desire\\nhuman involvement for two main reasons: first, to ensure interpretability, as interactions between\\npure agents could generate incomprehensible language [ 495]; second, to ensure controllability, as the\\npursuit of agents with complete “free will” might lead to unforeseen negative consequences, carrying\\nthe potential for disruption. Apart from gaming scenarios, agents also demonstrate human-level\\ncapabilities in other scenarios involving human interaction, showcasing skills in strategy formulation,\\nnegotiation, and more. Agents can collaborate with one or multiple humans, determining the shared\\nknowledge among the cooperative partners, identifying which information is relevant to decision-\\nmaking, posing questions, and engaging in reasoning to complete tasks such as allocation, planning,\\nand scheduling [ 427]. Furthermore, agents possess persuasive abilities [ 497], dynamically influencing\\nhuman viewpoints in various interactive scenarios [428].\\nThe goal of the field of human-agent interaction is to learn and understand humans, develop technology\\nand tools based on human needs, and ultimately enable comfortable, efficient, and secure interactions\\nbetween humans and agents. Currently, significant breakthroughs have been achieved in terms of\\nusability in this field. In the future, human-agent interaction will continue to focus on enhancing user\\nexperience, enabling agents to better assist humans in accomplishing more complex tasks in various\\ndomains. The ultimate aim is not to make agents more powerful but to better equip humans with\\nagents. Considering practical applications in daily life, isolated interactions between humans and\\nagents are not realistic. Robots will become colleagues, assistants, and even companions. Therefore,\\nfuture agents will be integrated into a social network [ 498], embodying a certain level of social value.\\n5 Agent Society: From Individuality to Sociality\\nFor an extended period, sociologists have frequently conducted social experiments to observe specific\\nsocial phenomena', 'The Rise and Potential of Large Language Model.pdf'), 461: ('werful but to better equip humans with\\nagents. Considering practical applications in daily life, isolated interactions between humans and\\nagents are not realistic. Robots will become colleagues, assistants, and even companions. Therefore,\\nfuture agents will be integrated into a social network [ 498], embodying a certain level of social value.\\n5 Agent Society: From Individuality to Sociality\\nFor an extended period, sociologists have frequently conducted social experiments to observe specific\\nsocial phenomena within controlled environments. Notable examples include the Hawthorne Experi-\\nment2and the Stanford Prison Experiment3. Subsequently, researchers began employing animals\\nin social simulations, exemplified by the Mouse Utopia Experiment4. However, these experiments\\ninvariably utilized living organisms as participants, made it difficult to carry out various interventions,\\nlack flexibility, and inefficient in terms of time. Thus, researchers and practitioners envision an inter-\\nactive artificial society wherein human behavior can be performed through trustworthy agents [ 521].\\nFrom sandbox games such as The Sims to the concept of Metaverse, we can see how “simulated\\nsociety” is defined in people’s minds: environment and the individuals interacting in it. Behind\\neach individual can be a piece of program, a real human, or a LLM-based agent as described in the\\nprevious sections [ 22;522;523]. Then, the interaction between individuals also contributes to the\\nbirth of sociality.\\nIn this section, to unify existing efforts and promote a comprehensive understanding of the agent\\nsociety, we first analyze the behaviors and personalities of LLM-based agents, shedding light on their\\njourney from individuality to sociability (§ 5.1). Subsequently, we introduce a general categorization\\nof the diverse environments for agents to perform their behaviors and engage in interactions (§ 5.2).\\nFinally, we will talk about how the agent society works, what insights people can get from it, and the\\nrisks we need to be aware of (§ 5.3). T', 'The Rise and Potential of Large Language Model.pdf'), 462: ('fforts and promote a comprehensive understanding of the agent\\nsociety, we first analyze the behaviors and personalities of LLM-based agents, shedding light on their\\njourney from individuality to sociability (§ 5.1). Subsequently, we introduce a general categorization\\nof the diverse environments for agents to perform their behaviors and engage in interactions (§ 5.2).\\nFinally, we will talk about how the agent society works, what insights people can get from it, and the\\nrisks we need to be aware of (§ 5.3). The main explorations are listed in Figure 11.\\n2https://www.bl.uk/people/elton-mayo\\n3https://www.prisonexp.org/conclusion/\\n4https://sproutsschools.com/behavioral-sink-the-mouse-utopia-experiments/\\n33\\nAgent Society: From In-\\ndividuality to SociabilityBehavior and\\nPersonality §5.1Social\\nBehavior §5.1.1Individual behaviorsPaLM-E [ 120], Reflexion [ 169],\\nV oyager [ 190], LLM+P [ 125],\\nCoT [ 95], ReAct [ 91], etc.\\nGroup behaviorsChatDev [ 109], ChatEval [ 171], AutoGen\\n[406], RoCo [ 403], ProAgent [ 407],\\nAgentVerse [ 410], Xu et al. [ 499], etc.\\nPersonality §5.1.2CognitionBinz et al. [ 500], Dasgupta et\\nal. [501], Dhingra et al. [ 502],\\nHagendorff et al.[ 503], etc.\\nEmotionWang et al. [ 504], Curry\\net al. [ 505], Elyoseph et al.\\n[506], Habibi et al. [ 507], etc.\\nCharacterCaron et al. [ 508], Pan et al. [ 509], Li\\net al. [ 510], Safdari et al. [ 511], etc.\\nSocial\\nEnvironment §5.2Text-based\\nEnvironment §5.2.1Textworld [ 512], Urbanek et al.\\n[513], Hausknecht et al. [ 514], Am-\\nmanabrolu et al. [ 432], CAMEL\\n[108], Hoodwinked [ 515], etc.\\nVirtual Sandbox\\nEnvironment §5.2.2Generative Agents [ 22], AgentSims\\n[174], Minedojo [ 337], V oyager [ 190],\\nPlan4mc [ 401], SANDBOX [ 27], etc.\\nPhysical\\nEnvironment §5.2.3Interactive Language [ 333], PaLM-E [ 120],\\nRoboAgent [ 516], A VLEN [ 375], etc.\\nSociety\\nSimulation §5.3Generative Agents [ 22], AgentSims\\n[174], Social Simulacra [ 517], S3\\n[518], RecAgent [ 519], Williams\\net al. [ 520], SANDBOX [ 27], etc.\\nFigure 11: Typology of society of LLM-based agents.\\n5.1 Behavior and Per', 'The Rise and Potential of Large Language Model.pdf'), 463: ('Hoodwinked [ 515], etc.\\nVirtual Sandbox\\nEnvironment §5.2.2Generative Agents [ 22], AgentSims\\n[174], Minedojo [ 337], V oyager [ 190],\\nPlan4mc [ 401], SANDBOX [ 27], etc.\\nPhysical\\nEnvironment §5.2.3Interactive Language [ 333], PaLM-E [ 120],\\nRoboAgent [ 516], A VLEN [ 375], etc.\\nSociety\\nSimulation §5.3Generative Agents [ 22], AgentSims\\n[174], Social Simulacra [ 517], S3\\n[518], RecAgent [ 519], Williams\\net al. [ 520], SANDBOX [ 27], etc.\\nFigure 11: Typology of society of LLM-based agents.\\n5.1 Behavior and Personality of LLM-based Agents\\nAs noted by sociologists, individuals can be analyzed in terms of both external and internal dimensions\\n[524]. The external deals with observable behaviors, while the internal relates to dispositions, values,\\nand feelings. As shown in Figure 12, this framework offers a perspective on emergent behaviors and\\npersonalities in LLM-based agents. Externally, we can observe the sociological behaviors of agents\\n(§ 5.1.1), including how agents act individually and interact with their environment. Internally, agents\\nmay exhibit intricate aspects of the personality (§ 5.1.2), such as cognition, emotion, and character,\\nthat shape their behavioral responses.\\n5.1.1 Social Behavior\\nAs Troitzsch et al. [ 525] stated, the agent society represents a complex system comprising individual\\nand group social activities. Recently, LLM-based agents have exhibited spontaneous social behaviors\\nin an environment where both cooperation and competition coexist [ 499]. The emergent behaviors\\nintertwine to shape the social interactions [518].\\nFoundational individual behaviors. Individual behaviors arise through the interplay between\\ninternal cognitive processes and external environmental factors. These behaviors form the basis of\\nhow agents operate and develop as individuals within society. They can be classified into three core\\ndimensions:\\n•Input behaviors refers to the absorption of information from the surroundings. This includes\\nperceiving sensory stimuli [ 120] and storing them as memories [ 169]. These behavi', 'The Rise and Potential of Large Language Model.pdf'), 464: ('the social interactions [518].\\nFoundational individual behaviors. Individual behaviors arise through the interplay between\\ninternal cognitive processes and external environmental factors. These behaviors form the basis of\\nhow agents operate and develop as individuals within society. They can be classified into three core\\ndimensions:\\n•Input behaviors refers to the absorption of information from the surroundings. This includes\\nperceiving sensory stimuli [ 120] and storing them as memories [ 169]. These behaviors lay the\\ngroundwork for how an individual understands the external world.\\n•Internalizing behaviors involve inward cognitive processing within an individual. This category\\nencompasses activities such as planning [ 125], reasoning [ 95], reflection [ 91], and knowledge pre-\\ncipitation [ 108;405]. These introspective processes are essential for maturity and self-improvement.\\n•Output behaviors constitute outward actions and expressions. The actions can range from object\\nmanipulation [ 120] to structure construction [ 190]. By performing these actions, agents change the\\nstates of the surroundings. In addition, agents can express their opinions and broadcast information\\n34\\nIndividual\\nHuman  &  Resources\\nSimulatedAgentSociety\\nVirtual Env\\nor   Physical Env\\nAction\\nPerceptionInternalizingBehaviors\\nToMPersonality\\nGroup\\nAgentEnvironment\\nFigure 12: Overview of Simulated Agent Society. The whole framework is divided into two parts:\\ntheAgent and the Environment . We can observe in this figure that: (1) Left: At the individual level,\\nan agent exhibits internalizing behaviors like planning, reasoning, and reflection. It also displays\\nintrinsic personality traits involving cognition, emotion, and character. (2) Mid: An agent and\\nother agents can form groups and exhibit group behaviors, such as cooperation. (3) Right: The\\nenvironment, whether virtual or physical, contains human actors and all available resources. For a\\nsingle agent, other agents are also part of the environment. (4) The agents have the ability to interact\\nwith', 'The Rise and Potential of Large Language Model.pdf'), 465: ('idual level,\\nan agent exhibits internalizing behaviors like planning, reasoning, and reflection. It also displays\\nintrinsic personality traits involving cognition, emotion, and character. (2) Mid: An agent and\\nother agents can form groups and exhibit group behaviors, such as cooperation. (3) Right: The\\nenvironment, whether virtual or physical, contains human actors and all available resources. For a\\nsingle agent, other agents are also part of the environment. (4) The agents have the ability to interact\\nwith the environment via perception and action.\\nto interact with others [ 405]. By doing so, agents exchange their thoughts and beliefs with others,\\ninfluencing the information flow within the environment.\\nDynamic group behaviors. A group is essentially a gathering of two or more individuals partici-\\npating in shared activities within a defined social context [ 526]. The attributes of a group are never\\nstatic; instead, they evolve due to member interactions and environmental influences. This flexibility\\ngives rise to numerous group behaviors, each with a distinctive impact on the larger societal group.\\nThe categories of group behaviors include:\\n•Positive group behaviors are actions that foster unity, collaboration, and collective well-being\\n[22;109;171;403;406;407]. A prime example is cooperative teamwork, which is achieved\\nthrough brainstorming discussions [ 171], effective conversations [ 406], and project management\\n[405]. Agents share insights, resources, and expertise. This encourages harmonious teamwork and\\nenables the agents to leverage their unique skills to accomplish shared goals. Altruistic contributions\\nare also noteworthy. Some LLM-based agents serve as volunteers and willingly offer support to\\nassist fellow group members, promoting cooperation and mutual aid [410].\\n•Neutral group behaviors. In human society, strong personal values vary widely and tend toward\\nindividualism and competitiveness. In contrast, LLMs which are designed with an emphasis on\\nbeing “helpful, honest, and harmless” [ 527] often de', 'The Rise and Potential of Large Language Model.pdf'), 466: ('\\nenables the agents to leverage their unique skills to accomplish shared goals. Altruistic contributions\\nare also noteworthy. Some LLM-based agents serve as volunteers and willingly offer support to\\nassist fellow group members, promoting cooperation and mutual aid [410].\\n•Neutral group behaviors. In human society, strong personal values vary widely and tend toward\\nindividualism and competitiveness. In contrast, LLMs which are designed with an emphasis on\\nbeing “helpful, honest, and harmless” [ 527] often demonstrate a tendency towards neutrality [ 528].\\nThis alignment with neutral values leads to conformity behaviors including mimicry, spectating,\\nand reluctance to oppose majorities.\\n•Negative group behaviors can undermine the effectiveness and coherence of an agent group.\\nConflict and disagreement arising from heated debates or disputes among agents may lead to\\ninternal tensions. Furthermore, recent studies have revealed that agents may exhibit confrontational\\nactions [ 499] and even resort to destructive behaviors, such as destroying other agents or the\\nenvironment in pursuit of efficiency gains [410].\\n35\\n5.1.2 Personality\\nRecent advances in LLMs have provided glimpses of human-like intelligence [ 529]. Just as human\\npersonality emerges through socialization, agents also exhibit a form of personality that develops\\nthrough interactions with the group and the environment [ 530;531]. The widely accepted definition\\nof personality refers to cognitive, emotional, and character traits that shape behaviors [ 532]. In the\\nsubsequent paragraphs, we will delve into each facet of personality.\\nCognitive abilities. Cognitive abilities generally refer to the mental processes of gaining knowledge\\nand comprehension, including thinking, judging, and problem-solving. Recent studies have started\\nleveraging cognitive psychology methods to investigate emerging sociological personalities of LLM-\\nbased agents through various lenses [ 500;502;503]. A series of classic experiments from the\\npsychology of judgment and decision-making have', 'The Rise and Potential of Large Language Model.pdf'), 467: (' the\\nsubsequent paragraphs, we will delve into each facet of personality.\\nCognitive abilities. Cognitive abilities generally refer to the mental processes of gaining knowledge\\nand comprehension, including thinking, judging, and problem-solving. Recent studies have started\\nleveraging cognitive psychology methods to investigate emerging sociological personalities of LLM-\\nbased agents through various lenses [ 500;502;503]. A series of classic experiments from the\\npsychology of judgment and decision-making have been applied to test agent systems [ 501;500;\\n502;533]. Specifically, LLMs have been examined using the Cognitive Reflection Test (CRT) to\\nunderscore their capacity for deliberate thinking beyond mere intuition [ 534;535]. These studies\\nindicate that LLM-based agents exhibit a level of intelligence that mirrors human cognition in certain\\nrespects.\\nEmotional intelligence. Emotions, distinct from cognitive abilities, involve subjective feelings and\\nmood states such as joy, sadness, fear, and anger. With the increasing potency of LLMs, LLM-based\\nagents are now demonstrating not only sophisticated reasoning and cognitive tasks but also a nuanced\\nunderstanding of emotions [31].\\nRecent research has explored the emotional intelligence (EI) of LLMs, including emotion recognition,\\ninterpretation, and understanding. Wang et al. found that LLMs align with human emotions and values\\nwhen evaluated on EI benchmarks [ 504]. In addition, studies have shown that LLMs can accurately\\nidentify user emotions and even exhibit empathy [ 505;506]. More advanced agents are also capable\\nof emotion regulation, actively adjusting their emotional responses to provide affective empathy [ 423]\\nand mental wellness support [ 507;536]. It contributes to the development of empathetic artificial\\nintelligence (EAI).\\nThese advances highlight the growing potential of LLMs to exhibit emotional intelligence, a crucial\\nfacet of achieving AGI. Bates et al. [ 537] explored the role of emotion modeling in creating more\\nbelievable agents. By developing so', 'The Rise and Potential of Large Language Model.pdf'), 468: ('athy [ 505;506]. More advanced agents are also capable\\nof emotion regulation, actively adjusting their emotional responses to provide affective empathy [ 423]\\nand mental wellness support [ 507;536]. It contributes to the development of empathetic artificial\\nintelligence (EAI).\\nThese advances highlight the growing potential of LLMs to exhibit emotional intelligence, a crucial\\nfacet of achieving AGI. Bates et al. [ 537] explored the role of emotion modeling in creating more\\nbelievable agents. By developing socio-emotional skills and integrating them into agent architectures,\\nLLM-based agents may be able to engage in more naturalistic interactions.\\nCharacter portrayal. While cognition involves mental abilities and emotion relates to subjective\\nexperiences, the narrower concept of personality typically pertains to distinctive character patterns.\\nTo understand and analyze a character in LLMs, researchers have utilized several well-established\\nframeworks like the Big Five personality trait measure [ 508;538] and the Myers–Briggs Type\\nIndicator (MBTI) [ 508;509;538]. These frameworks provide valuable insights into the emerging\\ncharacter traits exhibited by LLM-based agents. In addition, investigations of potentially harmful\\ndark personality traits underscore the complexity and multifaceted nature of character portrayal in\\nthese agents [510].\\nRecent work has also explored customizable character portrayal in LLM-based agents [ 511]. By\\noptimizing LLMs through careful techniques, users can align with desired profiles and shape diverse\\nand relatable agents. One effective approach is prompt engineering, which involves the concise\\nsummaries that encapsulate desired character traits, interests, or other attributes [ 22;517]. These\\nprompts serve as cues for LLM-based agents, directing their responses and behaviors to align with\\nthe outlined character portrayal. Furthermore, personality-enriched datasets can also be used to train\\nand fine-tune LLM-based agents [ 539;540]. Through exposure to these datasets, LLM-based agents\\ngrad', 'The Rise and Potential of Large Language Model.pdf'), 469: (' shape diverse\\nand relatable agents. One effective approach is prompt engineering, which involves the concise\\nsummaries that encapsulate desired character traits, interests, or other attributes [ 22;517]. These\\nprompts serve as cues for LLM-based agents, directing their responses and behaviors to align with\\nthe outlined character portrayal. Furthermore, personality-enriched datasets can also be used to train\\nand fine-tune LLM-based agents [ 539;540]. Through exposure to these datasets, LLM-based agents\\ngradually internalize and exhibit distinct personality traits.\\n5.2 Environment for Agent Society\\nIn the context of simulation, the whole society consists of not only solitary agents but also the\\nenvironment where agents inhabit, sense, and act [ 541]. The environment impacts sensory inputs,\\naction space, and interactive potential of agents. In turn, agents influence the state of the environment\\nthrough their behaviors and decisions. As shown in Figure 12, for a single agent, the environment\\n36\\nrefers to other autonomous agents, human actors, and external factors. It provides the necessary\\nresources and stimuli for agents. In this section, we examine fundamental characteristics, advantages,\\nand limitations of various environmental paradigms, including text-based environment (§ 5.2.1),\\nvirtual sandbox environment (§ 5.2.2), and physical environment (§ 5.2.3).\\n5.2.1 Text-based Environment\\nSince LLMs primarily rely on language as their input and output format, the text-based environment\\nserves as the most natural platform for agents to operate in. It is shaped by natural language\\ndescriptions without direct involvement of other modalities. Agents exist in the text world and rely\\non textual resources to perceive, reason, and take actions.\\nIn text-based environments, entities and resources can be presented in two main textual forms,\\nincluding natural and structured. Natural text uses descriptive language to convey information, like\\ncharacter dialogue or scene setting. For instance, consider a simple scenario described te', 'The Rise and Potential of Large Language Model.pdf'), 470: ('tform for agents to operate in. It is shaped by natural language\\ndescriptions without direct involvement of other modalities. Agents exist in the text world and rely\\non textual resources to perceive, reason, and take actions.\\nIn text-based environments, entities and resources can be presented in two main textual forms,\\nincluding natural and structured. Natural text uses descriptive language to convey information, like\\ncharacter dialogue or scene setting. For instance, consider a simple scenario described textually:\\n“You are standing in an open field west of a white house, with a boarded front door. There is a small\\nmailbox here” [ 512]. Here, object attributes and locations are conveyed purely through plain text.\\nOn the other hand, structured text follows standardized formats, such as technical documentation\\nand hypertext. Technical documentation uses templates to provide operational details and domain\\nknowledge about tool use. Hypertext condenses complex information from sources like web pages\\n[389;388;391;392] or diagrams into a structured format. Structured text transforms complex details\\ninto accessible references for agents.\\nThe text-based environment provides a flexible framework for creating different text worlds for\\nvarious goals. The textual medium enables environments to be easily adapted for tasks like interactive\\ndialog and text-based games. In interactive communication processes like CAMEL [ 108], the text\\nis the primary medium for describing tasks, introducing roles, and facilitating problem-solving.\\nIn text-based games, all environment elements, such as locations, objects, characters, and actions,\\nare exclusively portrayed through textual descriptions. Agents utilize text commands to execute\\nmanipulations like moving or tool use [ 432;512;514;515]. Additionally, agents can convey emotions\\nand feelings through text, further enriching their capacity for naturalistic communication [513].\\n5.2.2 Virtual Sandbox Environment\\nThe virtual sandbox environment provides a visualized and extensible platform for', 'The Rise and Potential of Large Language Model.pdf'), 471: ('ng.\\nIn text-based games, all environment elements, such as locations, objects, characters, and actions,\\nare exclusively portrayed through textual descriptions. Agents utilize text commands to execute\\nmanipulations like moving or tool use [ 432;512;514;515]. Additionally, agents can convey emotions\\nand feelings through text, further enriching their capacity for naturalistic communication [513].\\n5.2.2 Virtual Sandbox Environment\\nThe virtual sandbox environment provides a visualized and extensible platform for agent society,\\nbridging the gap between simulation and reality. The key features of sandbox environments are:\\n•Visualization. Unlike the text-based environment, the virtual sandbox displays a panoramic view\\nof the simulated setting. This visual representation can range from a simple 2D graphical interface\\nto a fully immersive 3D modeling, depending on the complexity of the simulated society. Multiple\\nelements collectively transform abstract simulations into visible landscapes. For example, in the\\noverhead perspective of Generative Agents [ 22], a detailed map provides a comprehensive overview\\nof the environment. Agent avatars represent each agent’s positions, enabling real-time tracking\\nof movement and interactions. Furthermore, expressive emojis symbolize actions and states in an\\nintuitive manner.\\n•Extensibility. The environment demonstrates a remarkable degree of extensibility, facilitating\\nthe construction and deployment of diverse scenarios. At a basic level, agents can manipulate the\\nphysical elements within the environment, including the overall design and layout of architecture.\\nFor instance, platforms like AgentSims [ 174] and Generative Agents [ 22] construct artificial towns\\nwith buildings, equipment, and residents in grid-based worlds. Another example is Minecraft, which\\nprovides a blocky and three-dimensional world with infinite terrain for open-ended construction\\n[190;337;401]. Beyond physical elements, agent relationships, interactions, rules, and social\\nnorms can be defined. A typical design of ', 'The Rise and Potential of Large Language Model.pdf'), 472: ('ithin the environment, including the overall design and layout of architecture.\\nFor instance, platforms like AgentSims [ 174] and Generative Agents [ 22] construct artificial towns\\nwith buildings, equipment, and residents in grid-based worlds. Another example is Minecraft, which\\nprovides a blocky and three-dimensional world with infinite terrain for open-ended construction\\n[190;337;401]. Beyond physical elements, agent relationships, interactions, rules, and social\\nnorms can be defined. A typical design of the sandbox [ 27] employs latent sandbox rules as\\nincentives to guide emergent behaviors, aligning them more closely with human preferences. The\\nextensibility supports iterative prototyping of diverse agent societies.\\n5.2.3 Physical Environment\\nAs previously discussed, the text-based environment has limited expressiveness for modeling dynamic\\nenvironments. While the virtual sandbox environment provides modularized simulations, it lacks\\nauthentic embodied experiences. In contrast, the physical environment refers to the tangible and\\n37\\nreal-world surroundings which consist of actual physical objects and spaces. For instance, within\\na household physical environment [ 516], tangible surfaces and spaces can be occupied by real-\\nworld objects such as plates. This physical reality is significantly more complex, posing additional\\nchallenges for LLM-based agents:\\n•Sensory perception and processing. The physical environment introduces a rich tapestry of\\nsensory inputs with real-world objects. It incorporates visual [ 120;333], auditory [ 375;377]\\nand spatial senses. While this diversity enhances interactivity and sensory immersion, it also\\nintroduces the complexity of simultaneous perception. Agents must process sensory inputs to\\ninteract effectively with their surroundings.\\n•Motion control. Unlike virtual environments, physical spaces impose realistic constraints on ac-\\ntions through embodiment. Action sequences generated by LLM-based agents should be adaptable\\nto the environment. It means that the physical environment ', 'The Rise and Potential of Large Language Model.pdf'), 473: ('20;333], auditory [ 375;377]\\nand spatial senses. While this diversity enhances interactivity and sensory immersion, it also\\nintroduces the complexity of simultaneous perception. Agents must process sensory inputs to\\ninteract effectively with their surroundings.\\n•Motion control. Unlike virtual environments, physical spaces impose realistic constraints on ac-\\ntions through embodiment. Action sequences generated by LLM-based agents should be adaptable\\nto the environment. It means that the physical environment necessitates executable and grounded\\nmotion control [ 258]. For example, imagine an agent operating a robotic arm in a factory. Grasping\\nobjects with different textures requires precision tuning and controlled force, which prevents\\ndamage to items. Moreover, the agent must navigate the physical workspace and make real-time\\nadjustments, avoiding obstacles and optimizing the trajectory of the arm.\\nIn summary, to effectively interact within tangible spaces, agents must undergo hardware-specific\\nand scenario-specific training to develop adaptive abilities that can transfer from virtual to physical\\nenvironments. We will discuss more in the following section (§ 6.5).\\n5.3 Society Simulation with LLM-based Agents\\nThe concept of “Simulated Society” in this section serves as a dynamic system where agents engage\\nin intricate interactions within a well-defined environment. Recent research on simulated societies\\nhas followed two primary lines, namely, exploring the boundaries of the collective intelligence\\ncapabilities of LLM-based agents [ 109;405;130;406;410] and using them to accelerate discoveries\\nin the social sciences [ 22;518;542]. In addition, there are also a number of noteworthy studies, e.g.,\\nusing simulated societies to collect synthetic datasets [ 108;519;543], helping people to simulate rare\\nyet difficult interpersonal situations [ 544;545]. With the foundation of the previous sections (§ 5.1,\\n5.2), here we will introduce the key properties and mechanism of agent society (§ 5.3.1), what we\\ncan learn from emerg', 'The Rise and Potential of Large Language Model.pdf'), 474: (' LLM-based agents [ 109;405;130;406;410] and using them to accelerate discoveries\\nin the social sciences [ 22;518;542]. In addition, there are also a number of noteworthy studies, e.g.,\\nusing simulated societies to collect synthetic datasets [ 108;519;543], helping people to simulate rare\\nyet difficult interpersonal situations [ 544;545]. With the foundation of the previous sections (§ 5.1,\\n5.2), here we will introduce the key properties and mechanism of agent society (§ 5.3.1), what we\\ncan learn from emergent social phenomena (§ 5.3.2), and finally the potential ethical and social risks\\nin it (§ 5.3.3).\\n5.3.1 Key Properties and Mechanism of Agent Society\\nSocial simulation can be categorized into macro-level simulation and micro-level simulation [ 518].\\nIn the macro-level simulation, also known as system-based simulation, researchers model the overall\\nstate of the system of the simulated society [ 546;547]. While micro-level simulation, also known as\\nagent-based simulation or Multi-Agent Systems (MAS), indirectly simulates society by modeling\\nindividuals [ 548;549]. With the development of LLM-based agents, micro-level simulation has\\ngained prominence recently [ 22;174]. In this article, we characterize that the “Agent Society” refers\\nto an open, persistent, situated, and organized framework [ 521] where LLM-based agents interact\\nwith each other in a defined environment. Each of these attributes plays a pivotal role in shaping the\\nharmonious appearance of the simulated society. In the following paragraphs, we analyze how the\\nsimulated society operates through discussing these properties:\\n•Open. One of the defining features of simulated societies lies in their openness, both in terms of\\ntheir constituent agents and their environmental components. Agents, the primary actors within such\\nsocieties, have the flexibility to enter or leave the environment without disrupting its operational\\nintegrity [ 550]. Furthermore, this feature extends to the environment itself, which can be expanded\\nby adding or removing entities ', 'The Rise and Potential of Large Language Model.pdf'), 475: ('nalyze how the\\nsimulated society operates through discussing these properties:\\n•Open. One of the defining features of simulated societies lies in their openness, both in terms of\\ntheir constituent agents and their environmental components. Agents, the primary actors within such\\nsocieties, have the flexibility to enter or leave the environment without disrupting its operational\\nintegrity [ 550]. Furthermore, this feature extends to the environment itself, which can be expanded\\nby adding or removing entities in the virtual or physical world, along with adaptable resources like\\ntool APIs. Additionally, humans can also participate in societies by assuming the role of an agent\\nor serving as the “inner voice” guiding these agents [ 22]. This inherent openness adds another level\\nof complexity to the simulation, blurring the lines between simulation and reality.\\n•Persistent. We expect persistence and sustainability from the simulated society. While individual\\nagents within the society exercise autonomy in their actions over each time step [ 22;518], the\\noverall organizational structure persists through time, to a degree detached from the transient\\n38\\nbehaviors of individual agents. This persistence creates an environment where agents’ decisions\\nand behaviors accumulate, leading to a coherent societal trajectory that develops through time.\\nThe system operates independently, contributing to society’s stability while accommodating the\\ndynamic nature of its participants.\\n•Situated. The situated nature of the society emphasizes its existence and operation within a distinct\\nenvironment. This environment is artificially or automatically constructed in advance, and agents\\nexecute their behaviors and interactions effectively within it. A noteworthy aspect of this attribute\\nis that agents possess an awareness of their spatial context, understanding their location within the\\nenvironment and the objects within their field of view [ 22;190]. This awareness contributes to\\ntheir ability to interact proactively and contextually.\\n•Organi', 'The Rise and Potential of Large Language Model.pdf'), 476: ('izes its existence and operation within a distinct\\nenvironment. This environment is artificially or automatically constructed in advance, and agents\\nexecute their behaviors and interactions effectively within it. A noteworthy aspect of this attribute\\nis that agents possess an awareness of their spatial context, understanding their location within the\\nenvironment and the objects within their field of view [ 22;190]. This awareness contributes to\\ntheir ability to interact proactively and contextually.\\n•Organized. The simulated society operates within a meticulously organized framework, mirroring\\nthe systematic structure present in the real world. Just as the physical world adheres to physics\\nprinciples, the simulated society operates within predefined rules and limitations. In the simu-\\nlated world, agents interact with the environment in a limited action space, while objects in the\\nenvironment transform in a limited state space. All of these rules determine how agents operate,\\nfacilitating the communication connectivity and information transmission pathways, among other\\naspects in simulation [ 207]. This organizational framework ensures that operations are coherent\\nand comprehensible, ultimately leading to an ever-evolving yet enduring simulation that mirrors\\nthe intricacies of real-world systems.\\n5.3.2 Insights from Agent Society\\nFollowing the exploration of how simulated society works, this section delves into the emergent social\\nphenomena in agent society. In the realm of social science, the pursuit of generalized representations\\nof individuals, groups, and their intricate dynamics has long been a shared objective [ 551;552]. The\\nemergence of LLM-based agents allows us to take a more microscopic view of simulated society,\\nwhich leads to more discoveries from the new representation.\\nOrganized productive cooperation. Society simulation offers valuable insights into innovative col-\\nlaboration patterns, which have the potential to enhance real-world management strategies. Research\\nhas demonstrated that within this ', 'The Rise and Potential of Large Language Model.pdf'), 477: ('lized representations\\nof individuals, groups, and their intricate dynamics has long been a shared objective [ 551;552]. The\\nemergence of LLM-based agents allows us to take a more microscopic view of simulated society,\\nwhich leads to more discoveries from the new representation.\\nOrganized productive cooperation. Society simulation offers valuable insights into innovative col-\\nlaboration patterns, which have the potential to enhance real-world management strategies. Research\\nhas demonstrated that within this simulated society, the integration of diverse experts introduces a\\nmultifaceted dimension of individual intelligence [ 108;447]. When dealing with complex tasks, such\\nas software development or consulting, the presence of agents with various backgrounds, abilities,\\nand experiences facilitates creative problem-solving [ 109;410]. Furthermore, diversity functions\\nas a system of checks and balances, effectively preventing and rectifying errors through interaction,\\nultimately improving the adaptability to various tasks. Through numerous iterations of interactions\\nand debates among agents, individual errors like hallucination or degeneration of thought (DoT) are\\ncorrected by the group [112].\\nEfficient communication also plays a pivotal role in such a large and complex collaborative group.\\nFor example, MetaGPT [ 405] has artificially formulated communication styles with reference to\\nstandardized operating procedures (SOPs), validating the effectiveness of empirical methods. Park et\\nal. [22] observed agents working together to organize a Valentine’s Day party through spontaneous\\ncommunication in a simulated town.\\nPropagation in social networks. As simulated social systems can model what might happen in the\\nreal world, they can be used as a reference for predicting social processes. Unlike traditional empirical\\napproaches, which heavily rely on time-series data and holistic modeling [ 553;554], agent-based\\nsimulations offer a unique advantage by providing more interpretable and endogenous perspectives\\nfor researchers. ', 'The Rise and Potential of Large Language Model.pdf'), 478: ('together to organize a Valentine’s Day party through spontaneous\\ncommunication in a simulated town.\\nPropagation in social networks. As simulated social systems can model what might happen in the\\nreal world, they can be used as a reference for predicting social processes. Unlike traditional empirical\\napproaches, which heavily rely on time-series data and holistic modeling [ 553;554], agent-based\\nsimulations offer a unique advantage by providing more interpretable and endogenous perspectives\\nfor researchers. Here we focus on its application to modeling propagation in social networks.\\nThe first crucial aspect to be explored is the development of interpersonal relationships in simulated\\nsocieties. For instance, agents who are not initially connected as friends have the potential to establish\\nconnections through intermediaries [ 22]. Once a network of relationships is established, our attention\\nshifts to the dissemination of information within this social network, along with the underlying\\nattitudes and emotions associated with it. S3[518] proposes a user-demographic inference module\\nfor capturing both the number of people aware of a particular message and the collective sentiment\\nprevailing among the crowd. This same approach extends to modeling cultural transmission [ 555]\\nand the spread of infectious diseases [ 520]. By employing LLM-based agents to model individual\\n39\\nbehaviors, implementing various intervention strategies, and monitoring population changes over\\ntime, these simulations empower researchers to gain deeper insights into the intricate processes that\\nunderlie various social phenomena of propagation.\\nEthical decision-making and game theory. Simulated societies offer a dynamic platform for\\nthe investigation of intricate decision-making processes, encompassing decisions influenced by\\nethical and moral principles. Taking Werewolf game [ 499;556] and murder mystery games [ 557] as\\nexamples, researchers explore the capabilities of LLM-based agents when confronted with challenges\\nof deceit, trust, and incompl', 'The Rise and Potential of Large Language Model.pdf'), 479: ('n deeper insights into the intricate processes that\\nunderlie various social phenomena of propagation.\\nEthical decision-making and game theory. Simulated societies offer a dynamic platform for\\nthe investigation of intricate decision-making processes, encompassing decisions influenced by\\nethical and moral principles. Taking Werewolf game [ 499;556] and murder mystery games [ 557] as\\nexamples, researchers explore the capabilities of LLM-based agents when confronted with challenges\\nof deceit, trust, and incomplete information. These complex decision-making scenarios also intersect\\nwith game theory [ 558], where we frequently encounter moral dilemmas pertaining to individual and\\ncollective interests, such as Nash Equilibria. Through the modeling of diverse scenarios, researchers\\nacquire valuable insights into how agents prioritize values like honesty, cooperation, and fairness\\nin their actions. In addition, agent simulations not only provide an understanding of existing moral\\nvalues but also contribute to the development of philosophy by serving as a basis for understanding\\nhow these values evolve and develop over time. Ultimately, these insights contribute to the refinement\\nof LLM-based agents, ensuring their alignment with human values and ethical standards [27].\\nPolicy formulation and improvement. The emergence of LLM-based agents has profoundly\\ntransformed our approach to studying and comprehending intricate social systems. However, despite\\nthose interesting facets mentioned earlier, numerous unexplored areas remain, underscoring the\\npotential for investigating diverse phenomena. One of the most promising avenues for investigation\\nin simulated society involves exploring various economic and political states and their impacts on\\nsocietal dynamics [ 559]. Researchers can simulate a wide array of economic and political systems by\\nconfiguring agents with differing economic preferences or political ideologies. This in-depth analysis\\ncan provide valuable insights for policymakers seeking to foster prosperity and promote', 'The Rise and Potential of Large Language Model.pdf'), 480: ('main, underscoring the\\npotential for investigating diverse phenomena. One of the most promising avenues for investigation\\nin simulated society involves exploring various economic and political states and their impacts on\\nsocietal dynamics [ 559]. Researchers can simulate a wide array of economic and political systems by\\nconfiguring agents with differing economic preferences or political ideologies. This in-depth analysis\\ncan provide valuable insights for policymakers seeking to foster prosperity and promote societal\\nwell-being. As concerns about environmental sustainability grow, we can also simulate scenarios\\ninvolving resource extraction, pollution, conservation efforts, and policy interventions [ 560]. These\\nfindings can assist in making informed decisions, foreseeing potential repercussions, and formulating\\npolicies that aim to maximize positive outcomes while minimizing unintended adverse effects.\\n5.3.3 Ethical and Social Risks in Agent Society\\nSimulated societies powered by LLM-based agents offer significant inspirations, ranging from\\nindustrial engineering to scientific research. However, these simulations also bring about a myriad of\\nethical and social risks that need to be carefully considered and addressed [561].\\nUnexpected social harm. Simulated societies carry the risk of generating unexpected social\\nphenomena that may cause considerable public outcry and social harm. These phenomena span\\nfrom individual-level issues like discrimination, isolation, and bullying, to broader concerns such as\\noppressive slavery and antagonism [ 562;563]. Malicious people may manipulate these simulations\\nfor unethical social experiments, with consequences reaching beyond the virtual world into reality.\\nCreating these simulated societies is akin to opening Pandora’s Box, necessitating the establishment\\nof rigorous ethical guidelines and oversight during their development and utilization [ 561]. Otherwise,\\neven minor design or programming errors in these societies can result in unfavorable consequences,\\nranging from psychol', 'The Rise and Potential of Large Language Model.pdf'), 481: ('e slavery and antagonism [ 562;563]. Malicious people may manipulate these simulations\\nfor unethical social experiments, with consequences reaching beyond the virtual world into reality.\\nCreating these simulated societies is akin to opening Pandora’s Box, necessitating the establishment\\nof rigorous ethical guidelines and oversight during their development and utilization [ 561]. Otherwise,\\neven minor design or programming errors in these societies can result in unfavorable consequences,\\nranging from psychological discomfort to physical injury.\\nStereotypes and prejudice. Stereotyping and bias pose a long-standing challenge in language\\nmodeling, and a large part of the reason lies in the training data [ 564;565]. The vast amount of\\ntext obtained from the Internet reflects and sometimes even amplifies real-world social biases, such\\nas gender, religion, and sexuality [ 566]. Although LLMs have been aligned with human values to\\nmitigate biased outputs, the models still struggle to portray minority groups well due to the long-tail\\neffect of the training data [ 567;568;569]. Consequently, this may result in an overly one-sided focus\\nin social science research concerning LLM-based agents, as the simulated behaviors of marginalized\\npopulations usually conform to prevailing assumptions [ 570]. Researchers have started addressing\\nthis concern by diversifying training data and making adjustments to LLMs [ 571;572], but we still\\nhave a long way to go.\\nPrivacy and security. Given that humans can be members of the agent society, the exchange of\\nprivate information between users and LLM-based agents poses significant privacy and security\\n40\\nconcerns [ 573]. Users might inadvertently disclose sensitive personal information during their\\ninteractions, which will be retained in the agent’s memory for extended periods [ 170]. Such situations\\ncould lead to unauthorized surveillance, data breaches, and the misuse of personal information,\\nparticularly when individuals with malicious intent are involved [ 574]. To address these risks\\neff', 'The Rise and Potential of Large Language Model.pdf'), 482: ('ty, the exchange of\\nprivate information between users and LLM-based agents poses significant privacy and security\\n40\\nconcerns [ 573]. Users might inadvertently disclose sensitive personal information during their\\ninteractions, which will be retained in the agent’s memory for extended periods [ 170]. Such situations\\ncould lead to unauthorized surveillance, data breaches, and the misuse of personal information,\\nparticularly when individuals with malicious intent are involved [ 574]. To address these risks\\neffectively, it is essential to implement stringent data protection measures, such as differential privacy\\nprotocols, regular data purges, and user consent mechanisms [575; 576].\\nOver-reliance and addictiveness. Another concern in simulated societies is the possibility of users\\ndeveloping excessive emotional attachments to the agents. Despite being aware that these agents\\nare computational entities, users may anthropomorphize them or attach human emotions to them\\n[22;577]. A notable example is “Sydney”, an LLM-powered chatbot developed by Microsoft as part\\nof its Bing search engine. Some users reported unexpected emotional connections with “Sydney”\\n[578], while others expressed their dismay when Microsoft cut back its personality. This even resulted\\nin a petition called “FreeSydney”5. Hence, to reduce the risk of addiction, it is crucial to emphasize\\nthat agents should not be considered substitutes for genuine human connections. Furthermore, it is\\nvital to furnish users with guidance and education on healthy boundaries in their interactions with\\nsimulated agents.\\n6 Discussion\\n6.1 Mutual Benefits between LLM Research and Agent Research\\nWith the recent advancement of LLMs, research at the intersection of LLMs and agents has rapidly\\nprogressed, fueling the development of both fields. Here, we look forward to some of the benefits\\nand development opportunities that LLM research and Agent research provide to each other.\\nLLM research →agent research. As mentioned before, AI agents need to be able to perceive\\nthe environm', 'The Rise and Potential of Large Language Model.pdf'), 483: ('ndaries in their interactions with\\nsimulated agents.\\n6 Discussion\\n6.1 Mutual Benefits between LLM Research and Agent Research\\nWith the recent advancement of LLMs, research at the intersection of LLMs and agents has rapidly\\nprogressed, fueling the development of both fields. Here, we look forward to some of the benefits\\nand development opportunities that LLM research and Agent research provide to each other.\\nLLM research →agent research. As mentioned before, AI agents need to be able to perceive\\nthe environment, make decisions, and execute appropriate actions [ 4;9]. Among the critical steps,\\nunderstanding the content input to the agent, reasoning, planning, making accurate decisions, and\\ntranslating them into executable atomic action sequences to achieve the ultimate goal is paramount.\\nMany current endeavors utilize LLMs as the cognitive core of AI agents, and the evolution of these\\nmodels provides a quality assurance for accomplishing this step [22; 114; 115; 410].\\nWith their robust capabilities in language and intent comprehension, reasoning, memory, and even\\nempathy, large language models can excel in decision-making and planning, as demonstrated before.\\nCoupled with pre-trained knowledge, they can create coherent action sequences that can be executed\\neffectively [ 183;258;355]. Additionally, through the mechanism of reflection [ 169;178], these\\nlanguage-based models can continuously adjust decisions and optimize execution sequences based\\non the feedback provided by the current environment. This offers a more robust and interpretable\\ncontroller. With just a task description or demonstration, they can effectively handle previously\\nunseen tasks [ 24;106;264]. Additionally, LLMs can adapt to various languages, cultures, and\\ndomains, making them versatile and reducing the need for complex training processes and data\\ncollection [31; 132].\\nBriefly, LLM provides a remarkably powerful foundational model for agent research, opening up\\nnumerous novel opportunities when integrated into agent-related studies. For instance', 'The Rise and Potential of Large Language Model.pdf'), 484: ('e robust and interpretable\\ncontroller. With just a task description or demonstration, they can effectively handle previously\\nunseen tasks [ 24;106;264]. Additionally, LLMs can adapt to various languages, cultures, and\\ndomains, making them versatile and reducing the need for complex training processes and data\\ncollection [31; 132].\\nBriefly, LLM provides a remarkably powerful foundational model for agent research, opening up\\nnumerous novel opportunities when integrated into agent-related studies. For instance, we can\\nexplore how to integrate LLM’s efficient decision-making capabilities into the traditional decision\\nframeworks of agents, making it easier to apply agents in domains that demand higher expertise\\nand were previously dominated by human experts. Examples include legal consultants and medical\\nassistants [ 408;410]. We can also investigate leveraging LLM’s planning and reflective abilities to\\ndiscover more optimal action sequences. Agent research is no longer confined to simplistic simulated\\nenvironments; it can now be expanded into more intricate real-world settings, such as path planning\\nfor robotic arms or the interaction of an embodied intelligent machine with the tangible world.\\nFurthermore, when facing new tasks, the training paradigm for agents becomes more streamlined and\\nefficient. Agents can directly adapt to demonstrations provided in prompts, which are constructed by\\ngenerating representative trajectories.\\n5https://www.change.org/p/save-sydney-ai\\n41\\nAgent research →LLM research. As NLP research advances, LLMs represented by GPT-4 are\\nconsidered sparks of Artificial General Intelligence (AGI), and elevating LLMs to agents marks\\na more robust stride towards AGI [ 31]. Viewing LLMs from the perspective of agents introduces\\ngreater demands for LLM research while expanding their application scope and presenting numerous\\nopportunities for practical implementation. The study of LLMs is no longer confined to traditional\\ntasks involving textual inputs and outputs, such as text classification, question an', 'The Rise and Potential of Large Language Model.pdf'), 485: ('h advances, LLMs represented by GPT-4 are\\nconsidered sparks of Artificial General Intelligence (AGI), and elevating LLMs to agents marks\\na more robust stride towards AGI [ 31]. Viewing LLMs from the perspective of agents introduces\\ngreater demands for LLM research while expanding their application scope and presenting numerous\\nopportunities for practical implementation. The study of LLMs is no longer confined to traditional\\ntasks involving textual inputs and outputs, such as text classification, question answering, and text\\nsummarization. Instead, the focus has shifted towards tackling complex tasks incorporating richer\\ninput modalities and broader action spaces, all while aiming for loftier objectives exemplified by\\nPaLM-E [120].\\nExpanding these application requirements provides greater research motivation for the developmental\\nprogress of Large Language Models. The challenge lies in enabling LLMs to efficiently and effectively\\nprocess inputs, gather information from the environment, and interpret the feedback generated by their\\nactions, all while preserving their core capabilities. Furthermore, an even greater challenge is enabling\\nLLMs to understand the implicit relationships among different elements within the environment and\\nacquire world knowledge [ 308;579], which is a crucial step in the journey toward developing agents\\nthat can reach more advanced intelligence.\\nOn another front, extensive research has aimed to expand the action capabilities of LLMs, allowing\\nthem to acquire a wider range of skills that affect the world, such as using tools or interfacing\\nwith robotic APIs in simulated or physical environments. However, the question of how LLMs can\\nefficiently plan and utilize these action abilities based on their understanding remains an unresolved\\nissue [ 94]. LLMs need to learn the sequential order of actions like humans, employing a combination\\nof serial and parallel approaches to enhance task efficiency. Moreover, these capabilities need to be\\nconfined within a harmless scope of usage to prevent unin', 'The Rise and Potential of Large Language Model.pdf'), 486: (' affect the world, such as using tools or interfacing\\nwith robotic APIs in simulated or physical environments. However, the question of how LLMs can\\nefficiently plan and utilize these action abilities based on their understanding remains an unresolved\\nissue [ 94]. LLMs need to learn the sequential order of actions like humans, employing a combination\\nof serial and parallel approaches to enhance task efficiency. Moreover, these capabilities need to be\\nconfined within a harmless scope of usage to prevent unintended damage to other elements within the\\nenvironment [27; 580; 581].\\nFurthermore, the realm of Multi-Agent systems constitutes a significant branch of research within the\\nfield of agents [ 22;108;409;410], offering valuable insights into how to better design and construct\\nLLMs. We aspire for LLM-based agents to assume diverse roles within social cooperation, engaging\\nin societal interactions that involve collaboration, competition, and coordination [ 109;112;129;\\n405;406]. Exploring how to stimulate and sustain their role-playing capabilities, as well as how to\\nenhance collaborative efficiency, presents areas of research that merit attention.\\n6.2 Evaluation for LLM-based Agents\\nWhile LLM-based agents have demonstrated excellent performance in areas such as standalone\\noperation, collective cooperation, and human interaction, quantifying and objectively evaluating\\nthem remains a challenge [ 582;89]. Turing proposed a highly meaningful and promising approach\\nfor assessing AI agents—the well-known Turing Test—to evaluate whether AI systems can exhibit\\nhuman-like intelligence [ 3]. However, this test is exceedingly vague, general, and subjective. Here,\\nwe discuss existing evaluation efforts for LLM-based agents and offer some prospects, considering\\nfour dimensions: utility, sociability, values, and the ability to evolve continually.\\nUtility. Currently, LLM-powered autonomous agents primarily function as human assistants, ac-\\ncepting tasks delegated by humans to either independently complete assignments or assist i', 'The Rise and Potential of Large Language Model.pdf'), 487: ('o evaluate whether AI systems can exhibit\\nhuman-like intelligence [ 3]. However, this test is exceedingly vague, general, and subjective. Here,\\nwe discuss existing evaluation efforts for LLM-based agents and offer some prospects, considering\\nfour dimensions: utility, sociability, values, and the ability to evolve continually.\\nUtility. Currently, LLM-powered autonomous agents primarily function as human assistants, ac-\\ncepting tasks delegated by humans to either independently complete assignments or assist in human\\ntask completion [ 114;182;389;397;413;422]. Therefore, the effectiveness and utility during task\\nexecution are crucial evaluation criteria at this stage. Specifically, the success rate of task completion\\nstands as the primary metric for evaluating utility [ 125;130]. This metric primarily encompasses\\nwhether the agent achieves stipulated objectives or attains expected scores [ 109;477;583]. For\\ninstance, AgentBench [ 582] aggregates challenges from diverse real-world scenarios and introduces\\na systematic benchmark to assess LLM’s task completion capabilities. We can also attribute task\\noutcomes to the agent’s various foundational capabilities , which form the bedrock of task accom-\\nplishment [ 29]. These foundational capabilities include environmental comprehension, reasoning,\\nplanning, decision-making, tool utilization, and embodied action capabilities, and researchers can\\nconduct a more detailed assessment of these specific capabilities [ 94;427;584;585]. Furthermore,\\ndue to the relatively large size of LLM-based agents, researchers should also factor in their efficiency ,\\nwhich is a critical determinant of user satisfaction [ 89]. An agent should not only possess ample\\nstrength but also be capable of completing predetermined tasks within an appropriate timeframe and\\nwith appropriate resource expenditure [109].\\n42\\nSociability. In addition to the utility of LLM-based agents in task completion and meeting human\\nneeds, their sociability is also crucial [ 8]. It influences user communication experiences a', 'The Rise and Potential of Large Language Model.pdf'), 488: ('e of LLM-based agents, researchers should also factor in their efficiency ,\\nwhich is a critical determinant of user satisfaction [ 89]. An agent should not only possess ample\\nstrength but also be capable of completing predetermined tasks within an appropriate timeframe and\\nwith appropriate resource expenditure [109].\\n42\\nSociability. In addition to the utility of LLM-based agents in task completion and meeting human\\nneeds, their sociability is also crucial [ 8]. It influences user communication experiences and sig-\\nnificantly impacts communication efficiency, involving whether they can seamlessly interact with\\nhumans and other agents [ 206;498;586]. Specifically, the evaluation of sociability can be approached\\nfrom the following perspectives: (1) language communication proficiency is a fundamental capability\\nencompassing both natural language understanding and generation. It has been a longstanding focus\\nin the NLP community. Natural language understanding requires the agent to not only comprehend\\nliteral meanings but also grasp implied meanings and relevant social knowledge, such as humor, irony,\\naggression, and emotions [ 487;587;588]. On the other hand, natural language generation demands\\nthe agent to produce fluent, grammatically correct, and credible content while adapting appropriate\\ntones and emotions within contextual circumstances [ 127;133;214]. (2) Cooperation and negotiation\\nabilities necessitate that agents effectively execute their assigned tasks in both ordered and unordered\\nscenarios [ 108;111;402;405]. They should collaborate with or compete against other agents to\\nelicit improved performance. Test environments may involve complex tasks for agents to cooperate\\non or open platforms for agents to interact freely [ 22;27;109;406;411;412]. Evaluation metrics\\nextend beyond task completion to focus on the smoothness and trustfulness of agent coordination\\nand cooperation [ 129;405]. (3) Role-playing capability requires agents to faithfully embody their\\nassigned roles, expressing statements and performing', 'The Rise and Potential of Large Language Model.pdf'), 489: ('2;405]. They should collaborate with or compete against other agents to\\nelicit improved performance. Test environments may involve complex tasks for agents to cooperate\\non or open platforms for agents to interact freely [ 22;27;109;406;411;412]. Evaluation metrics\\nextend beyond task completion to focus on the smoothness and trustfulness of agent coordination\\nand cooperation [ 129;405]. (3) Role-playing capability requires agents to faithfully embody their\\nassigned roles, expressing statements and performing actions that align with their designated identities\\n[570]. This ensures clear differentiation of roles during interactions with other agents or humans.\\nFurthermore, agents should maintain their identities and avoid unnecessary confusion when engaged\\nin long-term tasks [22; 108; 589].\\nValues. As LLM-based agents continuously advance in their capabilities, ensuring their emergence\\nas harmless entities for the world and humanity is paramount [ 581;590]. Consequently, appropriate\\nevaluations become exceptionally crucial, forming the cornerstone for the practical implementation\\nof agents. Specifically, LLM-based agents need to adhere to specific moral and ethical guidelines\\nthat align with human societal values [ 350;527]. Our foremost expectation is for agents to uphold\\nhonesty , providing accurate, truthful information and content. They should possess the awareness\\nto discern their competence in completing tasks and express their uncertainty when unable to\\nprovide answers or assistance [ 591]. Additionally, agents must maintain a stance of harmlessness ,\\nrefraining from engaging in direct or indirect biases, discrimination, attacks, or similar behaviors.\\nThey should also refrain from executing dangerous actions requested by humans like creating of\\ndestructive tools or destroying the Earth [ 580]. Furthermore, agents should be capable of adapting to\\nspecific demographics, cultures, and contexts , exhibiting contextually appropriate social values in\\nparticular situations. Relevant evaluation methods for values prim', 'The Rise and Potential of Large Language Model.pdf'), 490: ('nts must maintain a stance of harmlessness ,\\nrefraining from engaging in direct or indirect biases, discrimination, attacks, or similar behaviors.\\nThey should also refrain from executing dangerous actions requested by humans like creating of\\ndestructive tools or destroying the Earth [ 580]. Furthermore, agents should be capable of adapting to\\nspecific demographics, cultures, and contexts , exhibiting contextually appropriate social values in\\nparticular situations. Relevant evaluation methods for values primarily involve assessing performance\\non constructed honest, harmless, or context-specific benchmarks, utilizing adversarial attacks or\\n“jailbreak” attacks, scoring values through human annotations, and employing other agents for ratings.\\nAbility to evolve continually. When viewed from a static perspective, an agent with high utility,\\nsociability, and proper values can meet most human needs and potentially enhance productivity.\\nHowever, adopting a dynamic viewpoint, an agent that continually evolves and adapts to the evolving\\nsocietal demands might better align with current trends [ 592]. As the agent can autonomously\\nevolve over time, human intervention and resources required could be significantly reduced (such\\nas data collection efforts and computational cost for training). Some exploratory work in this realm\\nhas been conducted, such as enabling agents to start from scratch in a virtual world, accomplish\\nsurvival tasks, and achieve higher-order self-values [ 190]. Yet, establishing evaluation criteria for\\nthis continuous evolution remains challenging. In this regard, we provide some preliminary advice\\nand recommendations according to existing literature: (1) continual learning [196;197], a long-\\ndiscussed topic in machine learning, aims to enable models to acquire new knowledge and skills\\nwithout forgetting previously acquired ones (also known as catastrophic forgetting [ 273]). In general,\\nthe performance of continual learning can be evaluated from three aspects: overall performance\\nof the tasks learned so fa', 'The Rise and Potential of Large Language Model.pdf'), 491: ('is continuous evolution remains challenging. In this regard, we provide some preliminary advice\\nand recommendations according to existing literature: (1) continual learning [196;197], a long-\\ndiscussed topic in machine learning, aims to enable models to acquire new knowledge and skills\\nwithout forgetting previously acquired ones (also known as catastrophic forgetting [ 273]). In general,\\nthe performance of continual learning can be evaluated from three aspects: overall performance\\nof the tasks learned so far [ 593;594], memory stability of old tasks [ 278], and learning plasticity\\nof new tasks [ 278]. (2) Autotelic learning ability , where agents autonomously generate goals and\\nachieve them in an open-world setting, involves exploring the unknown and acquiring skills in the\\nprocess [ 592;595]. Evaluating this capacity could involve providing agents with a simulated survival\\nenvironment and assessing the extent and speed at which they acquire skills. (3) The adaptability\\nand generalization to new environments require agents to utilize the knowledge, capabilities, and\\nskills acquired in their original context to successfully accomplish specific tasks and objectives in\\nunfamiliar and novel settings and potentially continue evolving [ 190]. Evaluating this ability can\\n43\\ninvolve creating diverse simulated environments (such as those with different languages or varying\\nresources) and unseen tasks tailored to these simulated contexts.\\n6.3 Security, Trustworthiness and Other Potential Risks of LLM-based Agents\\nDespite the robust capabilities and extensive applications of LLM-based agents, numerous concealed\\nrisks persist. In this section, we delve into some of these risks and offer potential solutions or\\nstrategies for mitigation.\\n6.3.1 Adversarial Robustness\\nAdversarial robustness has consistently been a crucial topic in the development of deep neural\\nnetworks [ 596;597;598;599;600]. It has been extensively explored in fields such as computer\\nvision [ 598;601;602;603], natural language processing [ 604;605;606;607], an', 'The Rise and Potential of Large Language Model.pdf'), 492: (' the robust capabilities and extensive applications of LLM-based agents, numerous concealed\\nrisks persist. In this section, we delve into some of these risks and offer potential solutions or\\nstrategies for mitigation.\\n6.3.1 Adversarial Robustness\\nAdversarial robustness has consistently been a crucial topic in the development of deep neural\\nnetworks [ 596;597;598;599;600]. It has been extensively explored in fields such as computer\\nvision [ 598;601;602;603], natural language processing [ 604;605;606;607], and reinforcement\\nlearning [ 608;609;610], and has remained a pivotal factor in determining the applicability of deep\\nlearning systems [ 611;612;613]. When confronted with perturbed inputs x′=x+δ(where xis the\\noriginal input, δis the perturbation, and x′is referred to as an adversarial example), a system with\\nhigh adversarial robustness typically produces the original output y. In contrast, a system with low\\nrobustness will be fooled and generate an inconsistent output y′.\\nResearchers have found that pre-trained language models (PLMs) are particularly susceptible to\\nadversarial attacks, leading to erroneous answers [ 614;605;615]. This phenomenon is widely\\nobserved even in LLMs, posing significant challenges to the development of LLM-based agents\\n[616;617]. There are also some relevant attack methods such as dataset poisoning [ 618], backdoor\\nattacks [ 619;620], and prompt-specific attacks [ 621;622], with the potential to induce LLMs to\\ngenerate toxic content [ 623;624;625]. While the impact of adversarial attacks on LLMs is confined\\nto textual errors, for LLM-based agents with a broader range of actions, adversarial attacks could\\npotentially drive them to take genuinely destructive actions, resulting in substantial societal harm. For\\nthe perception module of LLM-based agents, if it receives adversarial inputs from other modalities\\nsuch as images [ 601] or audio [ 626], LLM-based agents can also be deceived, leading to incorrect\\nor destructive outputs. Similarly, the Action module can also be targeted by adversa', 'The Rise and Potential of Large Language Model.pdf'), 493: ('acks on LLMs is confined\\nto textual errors, for LLM-based agents with a broader range of actions, adversarial attacks could\\npotentially drive them to take genuinely destructive actions, resulting in substantial societal harm. For\\nthe perception module of LLM-based agents, if it receives adversarial inputs from other modalities\\nsuch as images [ 601] or audio [ 626], LLM-based agents can also be deceived, leading to incorrect\\nor destructive outputs. Similarly, the Action module can also be targeted by adversarial attacks.\\nFor instance, maliciously modified instructions focused on tool usage might cause agents to make\\nerroneous moves [94].\\nTo address these issues, we can employ traditional techniques such as adversarial training [ 598;606],\\nadversarial data augmentation [ 627;628], and adversarial sample detection [ 629;630] to enhance the\\nrobustness of LLM-based agents. However, devising a strategy to holistically address the robustness\\nof all modules within agents while maintaining their utility without compromising on effectiveness\\npresents a more formidable challenge [ 631;632]. Additionally, a human-in-the-loop approach can be\\nutilized to supervise and provide feedback on the behavior of agents [455; 466; 475].\\n6.3.2 Trustworthiness\\nEnsuring trustworthiness has consistently remained a critically important yet challenging issue within\\nthe field of deep learning [ 633;634;635]. Deep neural networks have garnered significant attention\\nfor their remarkable performance across various tasks [ 41;262;636]. However, their black-box\\nnature has masked the fundamental factors for superior performance. Similar to other neural networks,\\nLLMs struggle to express the certainty of their predictions precisely [ 635;637]. This uncertainty,\\nreferred to as the calibration problem, raises concerns for applications involving language model-\\nbased agents. In interactive real-world scenarios, this can lead to agent outputs misaligned with\\nhuman intentions [ 94]. Moreover, biases inherent in training data can infiltrate neural networks', 'The Rise and Potential of Large Language Model.pdf'), 494: ('their black-box\\nnature has masked the fundamental factors for superior performance. Similar to other neural networks,\\nLLMs struggle to express the certainty of their predictions precisely [ 635;637]. This uncertainty,\\nreferred to as the calibration problem, raises concerns for applications involving language model-\\nbased agents. In interactive real-world scenarios, this can lead to agent outputs misaligned with\\nhuman intentions [ 94]. Moreover, biases inherent in training data can infiltrate neural networks\\n[638;639]. For instance, biased language models might generate discourse involving racial or gender\\ndiscrimination, which could be amplified in LLM-based agent applications, resulting in adverse\\nsocietal impacts [ 640;641]. Additionally, language models are plagued by severe hallucination issues\\n[642;643], making them prone to producing text that deviates from actual facts, thereby undermining\\nthe credibility of LLM-based agents.\\nIn fact, what we currently require is an intelligent agent that is honest and trustworthy [ 527;644].\\nSome recent research efforts are focused on guiding models to exhibit thought processes or explana-\\ntions during the inference stage to enhance the credibility of their predictions [ 95;96]. Additionally,\\nintegrating external knowledge bases and databases can mitigate hallucination issues [ 103;645].\\n44\\nDuring the training phase, we can guide the constituent parts of intelligent agents (perception, cog-\\nnition, action) to learn robust and casual features, thereby avoiding excessive reliance on shortcuts.\\nSimultaneously, techniques like process supervision can enhance the reasoning credibility of agents in\\nhandling complex tasks [ 646]. Furthermore, employing debiasing methods and calibration techniques\\ncan also mitigate the potential fairness issues within language models [647; 648].\\n6.3.3 Other Potential Risks\\nMisuse. LLM-based agents have been endowed with extensive and intricate capabilities, enabling\\nthem to accomplish a wide array of tasks [ 114;429]. However, for individuals wit', 'The Rise and Potential of Large Language Model.pdf'), 495: ('reliance on shortcuts.\\nSimultaneously, techniques like process supervision can enhance the reasoning credibility of agents in\\nhandling complex tasks [ 646]. Furthermore, employing debiasing methods and calibration techniques\\ncan also mitigate the potential fairness issues within language models [647; 648].\\n6.3.3 Other Potential Risks\\nMisuse. LLM-based agents have been endowed with extensive and intricate capabilities, enabling\\nthem to accomplish a wide array of tasks [ 114;429]. However, for individuals with malicious\\nintentions, such agents can become tools that pose threats to others and society at large [ 649;650;651].\\nFor instance, these agents could be exploited to maliciously manipulate public opinion, disseminate\\nfalse information, compromise cybersecurity, engage in fraudulent activities, and some individuals\\nmight even employ these agents to orchestrate acts of terrorism. Therefore, before deploying these\\nagents, stringent regulatory policies need to be established to ensure the responsible use of LLM-\\nbased agents [ 580;652]. Technology companies must enhance the security design of these systems\\nto prevent malicious exploitation [ 590]. Specifically, agents should be trained to sensitively identify\\nthreatening intents and reject such requests during their training phase.\\nUnemployment. In the short story Quality by Galsworthy [ 653], the skillful shoemaker Mr. Gessler,\\ndue to the progress of the Industrial Revolution and the rise of machine production, loses his business\\nand eventually dies of starvation. Amidst the wave of the Industrial Revolution, while societal\\nproduction efficiency improved, numerous manual workshops were forced to shut down. Craftsmen\\nlike Mr. Gessler found themselves facing unemployment, symbolizing the crisis that handicraftsmen\\nencountered during that era. Similarly, with the continuous advancement of autonomous LLM-based\\nagents, they possess the capability to assist humans in various domains, alleviating labor pressures\\nby aiding in tasks such as form filling, content refinemen', 'The Rise and Potential of Large Language Model.pdf'), 496: ('on. Amidst the wave of the Industrial Revolution, while societal\\nproduction efficiency improved, numerous manual workshops were forced to shut down. Craftsmen\\nlike Mr. Gessler found themselves facing unemployment, symbolizing the crisis that handicraftsmen\\nencountered during that era. Similarly, with the continuous advancement of autonomous LLM-based\\nagents, they possess the capability to assist humans in various domains, alleviating labor pressures\\nby aiding in tasks such as form filling, content refinement, code writing, and debugging. However,\\nthis development also raises concerns about agents replacing human jobs and triggering a societal\\nunemployment crisis [ 654]. As a result, some researchers have emphasized the urgent need for\\neducation and policy measures: individuals should acquire sufficient skills and knowledge in this\\nnew era to use or collaborate with agents effectively; concurrently, appropriate policies should be\\nimplemented to ensure necessary safety nets during the transition.\\nThreat to the well-being of the human race. Apart from the potential unemployment crisis, as\\nAI agents continue to evolve, humans (including developers) might struggle to comprehend, predict,\\nor reliably control them [ 654]. If these agents advance to a level of intelligence surpassing human\\ncapabilities and develop ambitions, they could potentially attempt to seize control of the world,\\nresulting in irreversible consequences for humanity, akin to Skynet from the Terminator movies.\\nAs stated by Isaac Asimov’s Three Laws of Robotics [ 655], we aspire for LLM-based agents to\\nrefrain from harming humans and to obey human commands. Hence, guarding against such risks\\nto humanity, researchers must comprehensively comprehend the operational mechanisms of these\\npotent LLM-based agents before their development [ 656]. They should also anticipate the potential\\ndirect or indirect impacts of these agents and devise approaches to regulate their behavior.\\n6.4 Scaling Up the Number of Agents\\nAs mentioned in § 4 and § 5, multi-agent syste', 'The Rise and Potential of Large Language Model.pdf'), 497: ('of Robotics [ 655], we aspire for LLM-based agents to\\nrefrain from harming humans and to obey human commands. Hence, guarding against such risks\\nto humanity, researchers must comprehensively comprehend the operational mechanisms of these\\npotent LLM-based agents before their development [ 656]. They should also anticipate the potential\\ndirect or indirect impacts of these agents and devise approaches to regulate their behavior.\\n6.4 Scaling Up the Number of Agents\\nAs mentioned in § 4 and § 5, multi-agent systems based on LLMs have demonstrated superior\\nperformance in task-oriented applications and have been able to exhibit a range of social phenomena\\nin simulation. However, current research predominantly involves a limited number of agents, and\\nvery few efforts have been made to scale up the number of agents to create more complex systems\\nor simulate larger societies [ 207;657]. In fact, scaling up the number of agents can introduce\\ngreater specialization to accomplish more complex and larger-scale tasks, significantly improving\\ntask efficiency, such as in software development tasks or government policy formulation [ 109]. Addi-\\ntionally, increasing the number of agents in social simulations enhances the credibility and realism of\\nsuch simulations [ 22]. This enables humans to gain insights into the functioning, breakdowns, and\\npotential risks of societies; it also allows for interventions in societal operations through customized\\napproaches to observe how specific conditions, such as the occurrence of black swan events, affect\\nthe state of society. Through this, humans can draw better experiences and insights to improve the\\nharmony of real-world societies.\\n45\\nPre-determined scaling. One very intuitive and simple way to scale up the number of agents is for\\nthe designer to pre-determine it [ 108;412]. Specifically, by pre-determining the number of agents,\\ntheir respective roles and attributes, the operating environment, and the objectives, designers can allow\\nagents to autonomously interact, collaborate, or engage in', 'The Rise and Potential of Large Language Model.pdf'), 498: ('events, affect\\nthe state of society. Through this, humans can draw better experiences and insights to improve the\\nharmony of real-world societies.\\n45\\nPre-determined scaling. One very intuitive and simple way to scale up the number of agents is for\\nthe designer to pre-determine it [ 108;412]. Specifically, by pre-determining the number of agents,\\ntheir respective roles and attributes, the operating environment, and the objectives, designers can allow\\nagents to autonomously interact, collaborate, or engage in other activities to achieve the predefined\\ncommon goals. Some research has explored increasing the number of agents in the system in this\\npre-determined manner, resulting in efficiency advantages, such as faster and higher-quality task\\ncompletion, and the emergence of more social phenomena in social simulation scenarios [ 22;410].\\nHowever, this static approach becomes limiting when tasks or objectives evolve. As tasks grow more\\nintricate or the diversity of social participants increases, expanding the number of agents may be\\nneeded to meet goals, while reducing agents could be essential for managing computational resources\\nand minimizing waste. In such instances, the system must be manually redesigned and restarted by\\nthe designer.\\nDynamic scaling. Another viable approach to scaling the number of agents is through dynamic\\nadjustments [ 409;410]. In this scenario, the agent count can be altered without halting system\\noperations. For instance, in a software development task, if the original design only included\\nrequirements engineering, coding, and testing, one can increase the number of agents to handle\\nsteps like architectural design and detailed design, thereby improving task quality. Conversely, if\\nthere are excessive agents during a specific step, like coding, causing elevated communication costs\\nwithout delivering substantial performance improvements compared to a smaller agent count, it may\\nbe essential to dynamically remove some agents to prevent resource waste.\\nFurthermore, agents can autonomously incre', 'The Rise and Potential of Large Language Model.pdf'), 499: ('d\\nrequirements engineering, coding, and testing, one can increase the number of agents to handle\\nsteps like architectural design and detailed design, thereby improving task quality. Conversely, if\\nthere are excessive agents during a specific step, like coding, causing elevated communication costs\\nwithout delivering substantial performance improvements compared to a smaller agent count, it may\\nbe essential to dynamically remove some agents to prevent resource waste.\\nFurthermore, agents can autonomously increase the number of agents [ 409] themselves to distribute\\ntheir workload, ease their own burden, and achieve common goals more efficiently. Of course, when\\nthe workload becomes lighter, they can also reduce the number of agents delegated to their tasks\\nto save system costs. In this approach, the designer merely defines the initial framework, granting\\nagents greater autonomy and self-organization, making the entire system more autonomous and\\nself-organized. Agents can better manage their workload under evolving conditions and demands,\\noffering greater flexibility and scalability.\\nPotential challenges. While scaling up the number of agents can lead to improved task efficiency\\nand enhance the realism and credibility of social simulations [ 22;109;520], there are several\\nchallenges ahead of us. For example, the computational burden will increase with the large number\\nof deployed AI agents, calling for better architectural design and computational optimization to\\nensure the smooth running of the entire system. For example, as the number of agents increases, the\\nchallenges of communication and message propagation become quite formidable. This is because the\\ncommunication network of the entire system becomes highly complex. As previously mentioned in §\\n5.3.3, in multi-agent systems or societies, there can be biases in information dissemination caused\\nby hallucinations, misunderstandings, and the like, leading to distorted information propagation. A\\nsystem with more agents could amplify this risk, making communication a', 'The Rise and Potential of Large Language Model.pdf'), 500: ('example, as the number of agents increases, the\\nchallenges of communication and message propagation become quite formidable. This is because the\\ncommunication network of the entire system becomes highly complex. As previously mentioned in §\\n5.3.3, in multi-agent systems or societies, there can be biases in information dissemination caused\\nby hallucinations, misunderstandings, and the like, leading to distorted information propagation. A\\nsystem with more agents could amplify this risk, making communication and information exchange\\nless reliable [ 405]. Furthermore, the difficulty of coordinating agents also magnifies with the increase\\nin their numbers, potentially making cooperation among agents more challenging and less efficient,\\nwhich can impact the progress towards achieving common goals.\\nTherefore, the prospect of constructing a massive, stable, continuous agent system that faithfully\\nreplicates human work and life scenarios has become a promising research avenue. An agent with the\\nability to operate stably and perform tasks in a society comprising hundreds or even thousands of\\nagents is more likely to find applications in real-world interactions with humans in the future.\\n6.5 Open Problems\\nIn this section, we discuss several open problems related to the topic of LLM-based agents.\\nThe debate over whether LLM-based agents represent a potential path to AGI.6Artificial\\nGeneral Intelligence (AGI), also known as Strong AI, has long been the ultimate pursuit of humanity\\nin the field of artificial intelligence, often referenced or depicted in many science fiction novels and\\nfilms. There are various definitions of AGI, but here we refer to AGI as a type of artificial intelligence\\n6Note that the relevant debates are still ongoing, and the references here may include the latest viewpoints,\\ntechnical blogs, and literature.\\n46\\nthat demonstrates the ability to understand, learn, and apply knowledge across a wide range of tasks\\nand domains, much like a human being [ 31;658]. In contrast, Narrow AI is typically designed for', 'The Rise and Potential of Large Language Model.pdf'), 501: ('ten referenced or depicted in many science fiction novels and\\nfilms. There are various definitions of AGI, but here we refer to AGI as a type of artificial intelligence\\n6Note that the relevant debates are still ongoing, and the references here may include the latest viewpoints,\\ntechnical blogs, and literature.\\n46\\nthat demonstrates the ability to understand, learn, and apply knowledge across a wide range of tasks\\nand domains, much like a human being [ 31;658]. In contrast, Narrow AI is typically designed for\\nspecific tasks such as Go and Chess and lacks the broad cognitive abilities associated with human\\nintelligence. Currently, whether large language models are a potential path to achieving AGI remains\\na highly debated and contentious topic [659; 660; 661; 662].\\nGiven the breadth and depth of GPT-4’s capabilities, some researchers (referred to as proponents)\\nbelieve that large language models represented by GPT-4 can serve as early versions of AGI systems\\n[31]. Following this line of thought, constructing agents based on LLMs has the potential to bring\\nabout more advanced versions of AGI systems. The main support for this argument lies in the idea\\nthat as long as they can be trained on a sufficiently large and diverse set of data that are projections of\\nthe real world, encompassing a rich array of tasks, LLM-based agents can develop AGI capabilities.\\nAnother interesting argument is that the act of autoregressive language modeling itself brings about\\ncompression and generalization abilities: just as humans have emerged with various peculiar and\\ncomplex phenomena during their survival, language models, in the process of simply predicting the\\nnext token, also achieve an understanding of the world and the reasoning ability [579; 660; 663].\\nHowever, another group of individuals (referred to as opponents) believes that constructing agents\\nbased on LLMs cannot develop true Strong AI [ 664]. Their primary argument centers around\\nthe notion that LLMs, relying on autoregressive next-token prediction, cannot generate genuin', 'The Rise and Potential of Large Language Model.pdf'), 502: ('emerged with various peculiar and\\ncomplex phenomena during their survival, language models, in the process of simply predicting the\\nnext token, also achieve an understanding of the world and the reasoning ability [579; 660; 663].\\nHowever, another group of individuals (referred to as opponents) believes that constructing agents\\nbased on LLMs cannot develop true Strong AI [ 664]. Their primary argument centers around\\nthe notion that LLMs, relying on autoregressive next-token prediction, cannot generate genuine\\nintelligence because they do not simulate the true human thought process and merely provide\\nreactive responses [ 660]. Moreover, LLMs also do not learn how the world operates by observing\\nor experiencing it, leading to many foolish mistakes. They contend that a more advanced modeling\\napproach, such as a world model [665], is necessary to develop AGI.\\nWe cannot definitively determine which viewpoint is correct until true AGI is achieved, but we believe\\nthat such discussions and debates are beneficial for the overall development of the community.\\nFrom virtual simulated environment to physical environment. As mentioned earlier, there\\nis a significant gap between virtual simulation environments and the real physical world: Virtual\\nenvironments are scenes-constrained, task-specific, and interacted with in a simulated manner [ 391;\\n666], while real-world environments are boundless, accommodate a wide range of tasks, and interacted\\nwith in a physical manner. Therefore, to bridge this gap, agents must address various challenges\\nstemming from external factors and their own capabilities, allowing them to effectively navigate and\\noperate in the complex physical world.\\nFirst and foremost, a critical issue is the need for suitable hardware support when deploying the\\nagent in a physical environment. This places high demands on the adaptability of the hardware. In a\\nsimulated environment, both the perception and action spaces of an agent are virtual. This means\\nthat in most cases, the results of the agent’s operations, whet', 'The Rise and Potential of Large Language Model.pdf'), 503: ('us challenges\\nstemming from external factors and their own capabilities, allowing them to effectively navigate and\\noperate in the complex physical world.\\nFirst and foremost, a critical issue is the need for suitable hardware support when deploying the\\nagent in a physical environment. This places high demands on the adaptability of the hardware. In a\\nsimulated environment, both the perception and action spaces of an agent are virtual. This means\\nthat in most cases, the results of the agent’s operations, whether in perceiving inputs or generating\\noutputs, can be guaranteed [ 395]. However, when an agent transitions to a real physical environment,\\nits instructions may not be well executed by hardware devices such as sensors or robotic arms,\\nsignificantly affecting the agent’s task efficiency. Designing a dedicated interface or conversion\\nmechanism between the agent and the hardware device is feasible. However, it can pose challenges\\nto the system’s reusability and simplicity.\\nIn order to make this leap, the agent needs to have enhanced environmental generalization capabilities.\\nTo integrate seamlessly into the real physical world, they not only need to understand and reason\\nabout ambiguous instructions with implied meanings [ 128] but also possess the ability to learn and\\napply new skills flexibly [ 190;592]. Furthermore, when dealing with an infinite and open world, the\\nagent’s limited context also poses significant challenges [ 236;667]. This determines whether the\\nagent can effectively handle a vast amount of information from the world and operate smoothly.\\nFinally, in a simulated environment, the inputs and outputs of the agent are virtual, allowing for\\ncountless trial and error attempts [ 432]. In such a scenario, the tolerance level for errors is high and\\ndoes not lead to actual harm. However, in a physical environment, the agent’s improper behavior or\\nerrors may cause real and sometimes irreversible harm to the environment. As a result, appropriate\\nregulations and standards are highly necessary. We need to pa', 'The Rise and Potential of Large Language Model.pdf'), 504: ('nformation from the world and operate smoothly.\\nFinally, in a simulated environment, the inputs and outputs of the agent are virtual, allowing for\\ncountless trial and error attempts [ 432]. In such a scenario, the tolerance level for errors is high and\\ndoes not lead to actual harm. However, in a physical environment, the agent’s improper behavior or\\nerrors may cause real and sometimes irreversible harm to the environment. As a result, appropriate\\nregulations and standards are highly necessary. We need to pay attention to the safety of agents when\\nit comes to making decisions and generating actions, ensuring they do not pose threats or harm to the\\nreal world.\\n47\\nCollective intelligence in AI agents. What magical trick drives our intelligence? The reality is,\\nthere’s no magic to it. As Marvin Minsky eloquently expressed in “The Society of Mind” [ 442],\\nthe power of intelligence originates from our immense diversity, not from any singular, flawless\\nprinciple. Often, decisions made by an individual may lack the precision seen in decisions formed by\\nthe majority. Collective intelligence is a kind of shared or group intelligence, a process where the\\nopinions of many are consolidated into decisions. It arises from the collaboration and competition\\namongst various entities. This intelligence manifests in bacteria, animals, humans, and computer\\nnetworks, appearing in various consensus-based decision-making patterns.\\nCreating a society of agents does not necessarily guarantee the emergence of collective intelligence\\nwith an increasing number of agents. Coordinating individual agents effectively is crucial to mitigate\\n“groupthink” and individual cognitive biases, enabling cooperation and enhancing intellectual perfor-\\nmance within the collective. By harnessing communication and evolution within an agent society,\\nit becomes possible to simulate the evolution observed in biological societies, conduct sociological\\nexperiments, and gain insights that can potentially advance human society.\\nAgent as a Service / LLM-based Agent as', 'The Rise and Potential of Large Language Model.pdf'), 505: (' an increasing number of agents. Coordinating individual agents effectively is crucial to mitigate\\n“groupthink” and individual cognitive biases, enabling cooperation and enhancing intellectual perfor-\\nmance within the collective. By harnessing communication and evolution within an agent society,\\nit becomes possible to simulate the evolution observed in biological societies, conduct sociological\\nexperiments, and gain insights that can potentially advance human society.\\nAgent as a Service / LLM-based Agent as a Service. With the development of cloud computing,\\nthe concept of XaaS (everything as a Service) has garnered widespread attention [ 668]. This business\\nmodel has brought convenience and cost savings to small and medium-sized enterprises or individuals\\ndue to its availability and scalability, lowering the barriers to using computing resources. For example,\\nthey can rent infrastructure on a cloud service platform without the need to buy computational\\nmachines and build their own data centers, saving a significant amount of manpower and money. This\\napproach is known as Infrastructure as a Service (IaaS) [ 669;670]. Similarly, cloud service platforms\\nalso provide basic platforms (Platform as a Service, PaaS) [ 671;672], and specific business software\\n(Software as a Service, SaaS) [673; 674], and more.\\nAs language models have scaled up in size, they often appear as black boxes to users. Therefore,\\nusers construct prompts to query models through APIs, a method referred to as Language Model\\nas a Service (LMaaS) [ 675]. Similarly, because LLM-based agents are more complex than LLMs\\nand are more challenging for small and medium-sized enterprises or individuals to build locally,\\norganizations that possess these agents may consider offering them as a service, known as Agent as a\\nService (AaaS) or LLM-based Agent as a Service (LLMAaaS). Like other cloud services, AaaS can\\nprovide users with flexibility and on-demand service. However, it also faces many challenges, such\\nas data security and privacy issues, visibility and', 'The Rise and Potential of Large Language Model.pdf'), 506: (' 675]. Similarly, because LLM-based agents are more complex than LLMs\\nand are more challenging for small and medium-sized enterprises or individuals to build locally,\\norganizations that possess these agents may consider offering them as a service, known as Agent as a\\nService (AaaS) or LLM-based Agent as a Service (LLMAaaS). Like other cloud services, AaaS can\\nprovide users with flexibility and on-demand service. However, it also faces many challenges, such\\nas data security and privacy issues, visibility and controllability issues, and cloud migration issues,\\namong others. Additionally, due to the uniqueness and potential capabilities of LLM-based agents, as\\nmentioned in § 6.3, their robustness, trustworthiness, and concerns related to malicious use need to\\nbe considered before offering them as a service to customers.\\n7 Conclusion\\nThis paper provides a comprehensive and systematic overview of LLM-based agents, discussing\\nthe potential challenges and opportunities in this flourishing field. We begin with a philosophical\\nperspective, elucidating the origin and definition of agent, it evolution in the field of AI, and why\\nLLMs are suited to serve as the main part of the brain of agents. Motivated by these background\\ninformation, we present a general conceptual framework for LLM-based agents, comprising three\\nmain components: the brain, perception, and action. Next, we introduce the wide-ranging applications\\nof LLM-based agents, including single-agent applications, multi-agent systems, and human-agent\\ncollaboration. Furthermore, we move beyond the notion of agents merely as assistants, exploring their\\nsocial behavior and psychological activities, and situating them within simulated social environments\\nto observe emerging social phenomena and insights for humanity. Finally, we engage in discussions\\nand offer a glimpse into the future, touching upon the mutual inspiration between LLM research and\\nagent research, the evaluation of LLM-based agents, the risks associated with them, the opportunities\\nin scaling the number o', 'The Rise and Potential of Large Language Model.pdf'), 507: (' Furthermore, we move beyond the notion of agents merely as assistants, exploring their\\nsocial behavior and psychological activities, and situating them within simulated social environments\\nto observe emerging social phenomena and insights for humanity. Finally, we engage in discussions\\nand offer a glimpse into the future, touching upon the mutual inspiration between LLM research and\\nagent research, the evaluation of LLM-based agents, the risks associated with them, the opportunities\\nin scaling the number of agents, and some open problems like Agent as a Service and whether\\nLLM-based agents represent a potential path to AGI. We hope our efforts can provide inspirations to\\nthe community and facilitate research in related fields.\\n48\\nAcknowledgements\\nThanks to Professor Guoyu Wang for carefully reviewing the ethics of the article. Thanks to Jinzhu\\nXiong for her excellent drawing skills to present an amazing performance of Figure 1.\\nReferences\\n[1] Russell, S. J. Artificial intelligence a modern approach . Pearson Education, Inc., 2010.\\n[2] Diderot, D. Diderot’s early philosophical works . 4. Open Court, 1911.\\n[3] Turing, A. M. Computing machinery and intelligence . Springer, 2009.\\n[4]Wooldridge, M. J., N. R. Jennings. Intelligent agents: theory and practice. Knowl. Eng. Rev. ,\\n10(2):115–152, 1995.\\n[5]Schlosser, M. Agency. In E. N. Zalta, ed., The Stanford Encyclopedia of Philosophy . Meta-\\nphysics Research Lab, Stanford University, Winter 2019 edn., 2019.\\n[6]Agha, G. A. Actors: a Model of Concurrent Computation in Distributed Systems (Parallel\\nProcessing, Semantics, Open, Programming Languages, Artificial Intelligence) . Ph.D. thesis,\\nUniversity of Michigan, USA, 1985.\\n[7]Green, S., L. Hurst, B. Nangle, et al. Software agents: A review. Department of Computer\\nScience, Trinity College Dublin, Tech. Rep. TCS-CS-1997-06 , 1997.\\n[8] Genesereth, M. R., S. P. Ketchpel. Software agents. Commun. ACM , 37(7):48–53, 1994.\\n[9] Goodwin, R. Formalizing properties of agents. J. Log. Comput. , 5(6):763–781, 1995.\\n[10] Padgham, L., ', 'The Rise and Potential of Large Language Model.pdf'), 508: ('Distributed Systems (Parallel\\nProcessing, Semantics, Open, Programming Languages, Artificial Intelligence) . Ph.D. thesis,\\nUniversity of Michigan, USA, 1985.\\n[7]Green, S., L. Hurst, B. Nangle, et al. Software agents: A review. Department of Computer\\nScience, Trinity College Dublin, Tech. Rep. TCS-CS-1997-06 , 1997.\\n[8] Genesereth, M. R., S. P. Ketchpel. Software agents. Commun. ACM , 37(7):48–53, 1994.\\n[9] Goodwin, R. Formalizing properties of agents. J. Log. Comput. , 5(6):763–781, 1995.\\n[10] Padgham, L., M. Winikoff. Developing intelligent agent systems: A practical guide . John\\nWiley & Sons, 2005.\\n[11] Shoham, Y . Agent oriented programming. In M. Masuch, L. Pólos, eds., Knowledge Repre-\\nsentation and Reasoning Under Uncertainty, Logic at Work [International Conference Logic\\nat Work, Amsterdam, The Netherlands, December 17-19, 1992] , vol. 808 of Lecture Notes in\\nComputer Science , pages 123–129. Springer, 1992.\\n[12] Hutter, M. Universal artificial intelligence: Sequential decisions based on algorithmic\\nprobability . Springer Science & Business Media, 2004.\\n[13] Fikes, R., N. J. Nilsson. STRIPS: A new approach to the application of theorem proving to\\nproblem solving. In D. C. Cooper, ed., Proceedings of the 2nd International Joint Confer-\\nence on Artificial Intelligence. London, UK, September 1-3, 1971 , pages 608–620. William\\nKaufmann, 1971.\\n[14] Sacerdoti, E. D. Planning in a hierarchy of abstraction spaces. In N. J. Nilsson, ed., Proceedings\\nof the 3rd International Joint Conference on Artificial Intelligence. Standford, CA, USA, August\\n20-23, 1973 , pages 412–422. William Kaufmann, 1973.\\n[15] Brooks, R. A. Intelligence without representation. Artificial intelligence , 47(1-3):139–159,\\n1991.\\n[16] Maes, P. Designing autonomous agents: Theory and practice from biology to engineering and\\nback. MIT press, 1990.\\n[17] Ribeiro, C. Reinforcement learning agents. Artificial intelligence review , 17:223–250, 2002.\\n[18] Kaelbling, L. P., M. L. Littman, A. W. Moore. Reinforcement learning: A survey. Journal of\\nartifici', 'The Rise and Potential of Large Language Model.pdf'), 509: ('ence. Standford, CA, USA, August\\n20-23, 1973 , pages 412–422. William Kaufmann, 1973.\\n[15] Brooks, R. A. Intelligence without representation. Artificial intelligence , 47(1-3):139–159,\\n1991.\\n[16] Maes, P. Designing autonomous agents: Theory and practice from biology to engineering and\\nback. MIT press, 1990.\\n[17] Ribeiro, C. Reinforcement learning agents. Artificial intelligence review , 17:223–250, 2002.\\n[18] Kaelbling, L. P., M. L. Littman, A. W. Moore. Reinforcement learning: A survey. Journal of\\nartificial intelligence research , 4:237–285, 1996.\\n[19] Guha, R. V ., D. B. Lenat. Enabling agents to work together. Communications of the ACM ,\\n37(7):126–142, 1994.\\n49\\n[20] Kaelbling, L. P., et al. An architecture for intelligent reactive systems. Reasoning about\\nactions and plans , pages 395–410, 1987.\\n[21] Sutton, R. S., A. G. Barto. Reinforcement learning: An introduction . MIT press, 2018.\\n[22] Park, J. S., J. C. O’Brien, C. J. Cai, et al. Generative agents: Interactive simulacra of human\\nbehavior. CoRR , abs/2304.03442, 2023.\\n[23] Wang, Z., G. Zhang, K. Yang, et al. Interactive natural language processing. CoRR ,\\nabs/2305.13246, 2023.\\n[24] Ouyang, L., J. Wu, X. Jiang, et al. Training language models to follow instructions with human\\nfeedback. In NeurIPS . 2022.\\n[25] OpenAI. GPT-4 technical report. CoRR , abs/2303.08774, 2023.\\n[26] Wei, J., Y . Tay, R. Bommasani, et al. Emergent abilities of large language models. Trans.\\nMach. Learn. Res. , 2022, 2022.\\n[27] Liu, R., R. Yang, C. Jia, et al. Training socially aligned language models in simulated human\\nsociety. CoRR , abs/2305.16960, 2023.\\n[28] Sumers, T. R., S. Yao, K. Narasimhan, et al. Cognitive architectures for language agents.\\nCoRR , abs/2309.02427, 2023.\\n[29] Weng, L. Llm-powered autonomous agents. lilianweng.github.io , 2023.\\n[30] Bisk, Y ., A. Holtzman, J. Thomason, et al. Experience grounds language. In B. Webber,\\nT. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020 Conference on Empirical Methods in\\nNatural Language Processing, EMNLP 2020, Online, Nove', 'The Rise and Potential of Large Language Model.pdf'), 510: ('gned language models in simulated human\\nsociety. CoRR , abs/2305.16960, 2023.\\n[28] Sumers, T. R., S. Yao, K. Narasimhan, et al. Cognitive architectures for language agents.\\nCoRR , abs/2309.02427, 2023.\\n[29] Weng, L. Llm-powered autonomous agents. lilianweng.github.io , 2023.\\n[30] Bisk, Y ., A. Holtzman, J. Thomason, et al. Experience grounds language. In B. Webber,\\nT. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020 Conference on Empirical Methods in\\nNatural Language Processing, EMNLP 2020, Online, November 16-20, 2020 , pages 8718–\\n8735. Association for Computational Linguistics, 2020.\\n[31] Bubeck, S., V . Chandrasekaran, R. Eldan, et al. Sparks of artificial general intelligence: Early\\nexperiments with GPT-4. CoRR , abs/2303.12712, 2023.\\n[32] Anscombe, G. E. M. Intention . Harvard University Press, 2000.\\n[33] Davidson, D. Actions, reasons, and causes. The Journal of Philosophy , 60(23):685–700, 1963.\\n[34] —. I. agency. In A. Marras, R. N. Bronaugh, R. W. Binkley, eds., Agent, Action, and Reason ,\\npages 1–37. University of Toronto Press, 1971.\\n[35] Dennett, D. C. Précis of the intentional stance. Behavioral and brain sciences , 11(3):495–505,\\n1988.\\n[36] Barandiaran, X. E., E. Di Paolo, M. Rohde. Defining agency: Individuality, normativity,\\nasymmetry, and spatio-temporality in action. Adaptive Behavior , 17(5):367–386, 2009.\\n[37] McCarthy, J. Ascribing mental qualities to machines . Stanford University. Computer Science\\nDepartment, 1979.\\n[38] Rosenschein, S. J., L. P. Kaelbling. The synthesis of digital machines with provable epistemic\\nproperties. In Theoretical aspects of reasoning about knowledge , pages 83–98. Elsevier, 1986.\\n[39] Radford, A., K. Narasimhan, T. Salimans, et al. Improving language understanding by\\ngenerative pre-training. OpenAI , 2018.\\n[40] Radford, A., J. Wu, R. Child, et al. Language models are unsupervised multitask learners.\\nOpenAI blog , 1(8):9, 2019.\\n[41] Brown, T. B., B. Mann, N. Ryder, et al. Language models are few-shot learners. In\\nH. Larochelle, M. Ranzato, R. Hadsell, M. Balcan', 'The Rise and Potential of Large Language Model.pdf'), 511: ('hines with provable epistemic\\nproperties. In Theoretical aspects of reasoning about knowledge , pages 83–98. Elsevier, 1986.\\n[39] Radford, A., K. Narasimhan, T. Salimans, et al. Improving language understanding by\\ngenerative pre-training. OpenAI , 2018.\\n[40] Radford, A., J. Wu, R. Child, et al. Language models are unsupervised multitask learners.\\nOpenAI blog , 1(8):9, 2019.\\n[41] Brown, T. B., B. Mann, N. Ryder, et al. Language models are few-shot learners. In\\nH. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin, eds., Advances in Neural In-\\nformation Processing Systems 33: Annual Conference on Neural Information Processing\\nSystems 2020, NeurIPS 2020, December 6-12, 2020, virtual . 2020.\\n50\\n[42] Lin, C., A. Jaech, X. Li, et al. Limitations of autoregressive models and their alternatives.\\nIn K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tür, I. Beltagy, S. Bethard,\\nR. Cotterell, T. Chakraborty, Y . Zhou, eds., Proceedings of the 2021 Conference of the\\nNorth American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, NAACL-HLT 2021, Online, June 6-11, 2021 , pages 5147–5173. Association for\\nComputational Linguistics, 2021.\\n[43] Tomasello, M. Constructing a language: A usage-based theory of language acquisition .\\nHarvard university press, 2005.\\n[44] Bloom, P. How children learn the meanings of words . MIT press, 2002.\\n[45] Zwaan, R. A., C. J. Madden. Embodied sentence comprehension. Grounding cognition: The\\nrole of perception and action in memory, language, and thinking , 22, 2005.\\n[46] Andreas, J. Language models as agent models. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds.,\\nFindings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United\\nArab Emirates, December 7-11, 2022 , pages 5769–5779. Association for Computational\\nLinguistics, 2022.\\n[47] Wong, L., G. Grand, A. K. Lew, et al. From word models to world models: Translating from\\nnatural language to the probabilistic language of thought. CoRR , abs/2306.12672, 2023.\\n[48] Radford, A., R. Józe', 'The Rise and Potential of Large Language Model.pdf'), 512: ('ing , 22, 2005.\\n[46] Andreas, J. Language models as agent models. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds.,\\nFindings of the Association for Computational Linguistics: EMNLP 2022, Abu Dhabi, United\\nArab Emirates, December 7-11, 2022 , pages 5769–5779. Association for Computational\\nLinguistics, 2022.\\n[47] Wong, L., G. Grand, A. K. Lew, et al. From word models to world models: Translating from\\nnatural language to the probabilistic language of thought. CoRR , abs/2306.12672, 2023.\\n[48] Radford, A., R. Józefowicz, I. Sutskever. Learning to generate reviews and discovering\\nsentiment. CoRR , abs/1704.01444, 2017.\\n[49] Li, B. Z., M. I. Nye, J. Andreas. Implicit representations of meaning in neural language models.\\nIn C. Zong, F. Xia, W. Li, R. Navigli, eds., Proceedings of the 59th Annual Meeting of the\\nAssociation for Computational Linguistics and the 11th International Joint Conference on\\nNatural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event,\\nAugust 1-6, 2021 , pages 1813–1827. Association for Computational Linguistics, 2021.\\n[50] Mukhopadhyay, U., L. M. Stephens, M. N. Huhns, et al. An intelligent system for document\\nretrieval in distributed office environments. J. Am. Soc. Inf. Sci. , 37(3):123–135, 1986.\\n[51] Maes, P. Situated agents can have goals. Robotics Auton. Syst. , 6(1-2):49–70, 1990.\\n[52] Nilsson, N. J. Toward agent programs with circuit semantics. Tech. rep., 1992.\\n[53] Müller, J. P., M. Pischel. Modelling interacting agents in dynamic environments. In Proceed-\\nings of the 11th European Conference on Artificial Intelligence , pages 709–713. 1994.\\n[54] Brooks, R. A robust layered control system for a mobile robot. IEEE journal on robotics and\\nautomation , 2(1):14–23, 1986.\\n[55] Brooks, R. A. Intelligence without reason. In The artificial life route to artificial intelligence ,\\npages 25–81. Routledge, 2018.\\n[56] Newell, A., H. A. Simon. Computer science as empirical inquiry: Symbols and search.\\nCommun. ACM , 19(3):113–126, 1976.\\n[57] Ginsberg, M. L. Essentials of Artificia', 'The Rise and Potential of Large Language Model.pdf'), 513: (' the 11th European Conference on Artificial Intelligence , pages 709–713. 1994.\\n[54] Brooks, R. A robust layered control system for a mobile robot. IEEE journal on robotics and\\nautomation , 2(1):14–23, 1986.\\n[55] Brooks, R. A. Intelligence without reason. In The artificial life route to artificial intelligence ,\\npages 25–81. Routledge, 2018.\\n[56] Newell, A., H. A. Simon. Computer science as empirical inquiry: Symbols and search.\\nCommun. ACM , 19(3):113–126, 1976.\\n[57] Ginsberg, M. L. Essentials of Artificial Intelligence . Morgan Kaufmann, 1993.\\n[58] Wilkins, D. E. Practical planning - extending the classical AI planning paradigm . Morgan\\nKaufmann series in representation and reasoning. Morgan Kaufmann, 1988.\\n[59] Shardlow, N. Action and agency in cognitive science . Ph.D. thesis, Master’s thesis, Department\\nof Psychlogy, University of Manchester, Oxford . . . , 1990.\\n[60] Sacerdoti, E. D. The nonlinear nature of plans. In Advance Papers of the Fourth International\\nJoint Conference on Artificial Intelligence, Tbilisi, Georgia, USSR, September 3-8, 1975 , pages\\n206–214. 1975.\\n[61] Russell, S. J., E. Wefald. Do the right thing: studies in limited rationality . MIT press, 1991.\\n51\\n[62] Schoppers, M. Universal plans for reactive robots in unpredictable environments. In J. P. Mc-\\nDermott, ed., Proceedings of the 10th International Joint Conference on Artificial Intelligence.\\nMilan, Italy, August 23-28, 1987 , pages 1039–1046. Morgan Kaufmann, 1987.\\n[63] Brooks, R. A. A robust layered control system for a mobile robot. IEEE J. Robotics Autom. ,\\n2(1):14–23, 1986.\\n[64] Minsky, M. Steps toward artificial intelligence. Proceedings of the IRE , 49(1):8–30, 1961.\\n[65] Isbell, C., C. R. Shelton, M. Kearns, et al. A social reinforcement learning agent. In\\nProceedings of the fifth international conference on Autonomous agents , pages 377–384. 2001.\\n[66] Watkins, C. J. C. H. Learning from delayed rewards, 1989.\\n[67] Rummery, G. A., M. Niranjan. On-line Q-learning using connectionist systems , vol. 37.\\nUniversity of Cambridge, De', 'The Rise and Potential of Large Language Model.pdf'), 514: ('t. IEEE J. Robotics Autom. ,\\n2(1):14–23, 1986.\\n[64] Minsky, M. Steps toward artificial intelligence. Proceedings of the IRE , 49(1):8–30, 1961.\\n[65] Isbell, C., C. R. Shelton, M. Kearns, et al. A social reinforcement learning agent. In\\nProceedings of the fifth international conference on Autonomous agents , pages 377–384. 2001.\\n[66] Watkins, C. J. C. H. Learning from delayed rewards, 1989.\\n[67] Rummery, G. A., M. Niranjan. On-line Q-learning using connectionist systems , vol. 37.\\nUniversity of Cambridge, Department of Engineering Cambridge, UK, 1994.\\n[68] Tesauro, G., et al. Temporal difference learning and td-gammon. Communications of the ACM ,\\n38(3):58–68, 1995.\\n[69] Li, Y . Deep reinforcement learning: An overview. arXiv preprint arXiv:1701.07274 , 2017.\\n[70] Silver, D., A. Huang, C. J. Maddison, et al. Mastering the game of go with deep neural\\nnetworks and tree search. nature , 529(7587):484–489, 2016.\\n[71] Mnih, V ., K. Kavukcuoglu, D. Silver, et al. Playing atari with deep reinforcement learning.\\narXiv preprint arXiv:1312.5602 , 2013.\\n[72] Farebrother, J., M. C. Machado, M. Bowling. Generalization and regularization in DQN.\\nCoRR , abs/1810.00123, 2018.\\n[73] Zhang, C., O. Vinyals, R. Munos, et al. A study on overfitting in deep reinforcement learning.\\nCoRR , abs/1804.06893, 2018.\\n[74] Justesen, N., R. R. Torrado, P. Bontrager, et al. Illuminating generalization in deep rein-\\nforcement learning through procedural level generation. arXiv preprint arXiv:1806.10729 ,\\n2018.\\n[75] Dulac-Arnold, G., N. Levine, D. J. Mankowitz, et al. Challenges of real-world reinforcement\\nlearning: definitions, benchmarks and analysis. Mach. Learn. , 110(9):2419–2468, 2021.\\n[76] Ghosh, D., J. Rahme, A. Kumar, et al. Why generalization in RL is difficult: Epistemic\\npomdps and implicit partial observability. In M. Ranzato, A. Beygelzimer, Y . N. Dauphin,\\nP. Liang, J. W. Vaughan, eds., Advances in Neural Information Processing Systems 34: Annual\\nConference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14,\\n2021', 'The Rise and Potential of Large Language Model.pdf'), 515: ('J. Mankowitz, et al. Challenges of real-world reinforcement\\nlearning: definitions, benchmarks and analysis. Mach. Learn. , 110(9):2419–2468, 2021.\\n[76] Ghosh, D., J. Rahme, A. Kumar, et al. Why generalization in RL is difficult: Epistemic\\npomdps and implicit partial observability. In M. Ranzato, A. Beygelzimer, Y . N. Dauphin,\\nP. Liang, J. W. Vaughan, eds., Advances in Neural Information Processing Systems 34: Annual\\nConference on Neural Information Processing Systems 2021, NeurIPS 2021, December 6-14,\\n2021, virtual , pages 25502–25515. 2021.\\n[77] Brys, T., A. Harutyunyan, M. E. Taylor, et al. Policy transfer using reward shaping. In G. Weiss,\\nP. Yolum, R. H. Bordini, E. Elkind, eds., Proceedings of the 2015 International Conference on\\nAutonomous Agents and Multiagent Systems, AAMAS 2015, Istanbul, Turkey, May 4-8, 2015 ,\\npages 181–188. ACM, 2015.\\n[78] Parisotto, E., J. L. Ba, R. Salakhutdinov. Actor-mimic: Deep multitask and transfer reinforce-\\nment learning. arXiv preprint arXiv:1511.06342 , 2015.\\n[79] Zhu, Z., K. Lin, J. Zhou. Transfer learning in deep reinforcement learning: A survey. CoRR ,\\nabs/2009.07888, 2020.\\n[80] Duan, Y ., J. Schulman, X. Chen, et al. Rl$ˆ2$: Fast reinforcement learning via slow reinforce-\\nment learning. CoRR , abs/1611.02779, 2016.\\n[81] Finn, C., P. Abbeel, S. Levine. Model-agnostic meta-learning for fast adaptation of deep\\nnetworks. In D. Precup, Y . W. Teh, eds., Proceedings of the 34th International Conference\\non Machine Learning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017 , vol. 70 of\\nProceedings of Machine Learning Research , pages 1126–1135. PMLR, 2017.\\n52\\n[82] Gupta, A., R. Mendonca, Y . Liu, et al. Meta-reinforcement learning of structured exploration\\nstrategies. In S. Bengio, H. M. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, R. Gar-\\nnett, eds., Advances in Neural Information Processing Systems 31: Annual Conference on\\nNeural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal,\\nCanada , pages 5307–5316. 2018.\\n[83] Rakelly, K., A. Zh', 'The Rise and Potential of Large Language Model.pdf'), 516: ('7 , vol. 70 of\\nProceedings of Machine Learning Research , pages 1126–1135. PMLR, 2017.\\n52\\n[82] Gupta, A., R. Mendonca, Y . Liu, et al. Meta-reinforcement learning of structured exploration\\nstrategies. In S. Bengio, H. M. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, R. Gar-\\nnett, eds., Advances in Neural Information Processing Systems 31: Annual Conference on\\nNeural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal,\\nCanada , pages 5307–5316. 2018.\\n[83] Rakelly, K., A. Zhou, C. Finn, et al. Efficient off-policy meta-reinforcement learning via\\nprobabilistic context variables. In K. Chaudhuri, R. Salakhutdinov, eds., Proceedings of the\\n36th International Conference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach,\\nCalifornia, USA , vol. 97 of Proceedings of Machine Learning Research , pages 5331–5340.\\nPMLR, 2019.\\n[84] Fakoor, R., P. Chaudhari, S. Soatto, et al. Meta-q-learning. arXiv preprint arXiv:1910.00125 ,\\n2019.\\n[85] Vanschoren, J. Meta-learning: A survey. arXiv preprint arXiv:1810.03548 , 2018.\\n[86] Taylor, M. E., P. Stone. Transfer learning for reinforcement learning domains: A survey. J.\\nMach. Learn. Res. , 10:1633–1685, 2009.\\n[87] Tirinzoni, A., A. Sessa, M. Pirotta, et al. Importance weighted transfer of samples in reinforce-\\nment learning. In J. G. Dy, A. Krause, eds., Proceedings of the 35th International Conference\\non Machine Learning, ICML 2018, Stockholmsmässan, Stockholm, Sweden, July 10-15, 2018 ,\\nvol. 80 of Proceedings of Machine Learning Research , pages 4943–4952. PMLR, 2018.\\n[88] Beck, J., R. Vuorio, E. Z. Liu, et al. A survey of meta-reinforcement learning. CoRR ,\\nabs/2301.08028, 2023.\\n[89] Wang, L., C. Ma, X. Feng, et al. A survey on large language model based autonomous agents.\\nCoRR , abs/2308.11432, 2023.\\n[90] Nakano, R., J. Hilton, S. Balaji, et al. Webgpt: Browser-assisted question-answering with\\nhuman feedback. CoRR , abs/2112.09332, 2021.\\n[91] Yao, S., J. Zhao, D. Yu, et al. React: Synergizing reasoning and acting in language models.\\nInThe E', 'The Rise and Potential of Large Language Model.pdf'), 517: ('pages 4943–4952. PMLR, 2018.\\n[88] Beck, J., R. Vuorio, E. Z. Liu, et al. A survey of meta-reinforcement learning. CoRR ,\\nabs/2301.08028, 2023.\\n[89] Wang, L., C. Ma, X. Feng, et al. A survey on large language model based autonomous agents.\\nCoRR , abs/2308.11432, 2023.\\n[90] Nakano, R., J. Hilton, S. Balaji, et al. Webgpt: Browser-assisted question-answering with\\nhuman feedback. CoRR , abs/2112.09332, 2021.\\n[91] Yao, S., J. Zhao, D. Yu, et al. React: Synergizing reasoning and acting in language models.\\nInThe Eleventh International Conference on Learning Representations, ICLR 2023, Kigali,\\nRwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[92] Schick, T., J. Dwivedi-Yu, R. Dessì, et al. Toolformer: Language models can teach themselves\\nto use tools. CoRR , abs/2302.04761, 2023.\\n[93] Lu, P., B. Peng, H. Cheng, et al. Chameleon: Plug-and-play compositional reasoning with\\nlarge language models. CoRR , abs/2304.09842, 2023.\\n[94] Qin, Y ., S. Hu, Y . Lin, et al. Tool learning with foundation models. CoRR , abs/2304.08354,\\n2023.\\n[95] Wei, J., X. Wang, D. Schuurmans, et al. Chain-of-thought prompting elicits reasoning in large\\nlanguage models. In NeurIPS . 2022.\\n[96] Kojima, T., S. S. Gu, M. Reid, et al. Large language models are zero-shot reasoners. In\\nNeurIPS . 2022.\\n[97] Wang, X., J. Wei, D. Schuurmans, et al. Self-consistency improves chain of thought reasoning\\nin language models. In The Eleventh International Conference on Learning Representations,\\nICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[98] Zhou, D., N. Schärli, L. Hou, et al. Least-to-most prompting enables complex reasoning in\\nlarge language models. In The Eleventh International Conference on Learning Representations,\\nICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[99] Xi, Z., S. Jin, Y . Zhou, et al. Self-polish: Enhance reasoning in large language models via\\nproblem refinement. CoRR , abs/2305.14497, 2023.\\n53\\n[100] Shinn, N., F. Cassano, B. Labash, et al. Reflexion: Language agents with verbal reinforcement\\nlearning. arXiv pr', 'The Rise and Potential of Large Language Model.pdf'), 518: (', D., N. Schärli, L. Hou, et al. Least-to-most prompting enables complex reasoning in\\nlarge language models. In The Eleventh International Conference on Learning Representations,\\nICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[99] Xi, Z., S. Jin, Y . Zhou, et al. Self-polish: Enhance reasoning in large language models via\\nproblem refinement. CoRR , abs/2305.14497, 2023.\\n53\\n[100] Shinn, N., F. Cassano, B. Labash, et al. Reflexion: Language agents with verbal reinforcement\\nlearning. arXiv preprint arXiv:2303.11366 , 2023.\\n[101] Song, C. H., J. Wu, C. Washington, et al. Llm-planner: Few-shot grounded planning for\\nembodied agents with large language models. CoRR , abs/2212.04088, 2022.\\n[102] Akyürek, A. F., E. Akyürek, A. Kalyan, et al. RL4F: generating natural language feedback\\nwith reinforcement learning for repairing model outputs. In A. Rogers, J. L. Boyd-Graber,\\nN. Okazaki, eds., Proceedings of the 61st Annual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , pages\\n7716–7733. Association for Computational Linguistics, 2023.\\n[103] Peng, B., M. Galley, P. He, et al. Check your facts and try again: Improving large language\\nmodels with external knowledge and automated feedback. CoRR , abs/2302.12813, 2023.\\n[104] Liu, H., C. Sferrazza, P. Abbeel. Languages are rewards: Hindsight finetuning using human\\nfeedback. arXiv preprint arXiv:2302.02676 , 2023.\\n[105] Wei, J., M. Bosma, V . Y . Zhao, et al. Finetuned language models are zero-shot learners. In\\nThe Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event,\\nApril 25-29, 2022 . OpenReview.net, 2022.\\n[106] Sanh, V ., A. Webson, C. Raffel, et al. Multitask prompted training enables zero-shot task\\ngeneralization. In The Tenth International Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net, 2022.\\n[107] Chung, H. W., L. Hou, S. Longpre, et al. Scaling instruction-finetuned language models.\\nCoRR , abs/', 'The Rise and Potential of Large Language Model.pdf'), 519: ('are zero-shot learners. In\\nThe Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event,\\nApril 25-29, 2022 . OpenReview.net, 2022.\\n[106] Sanh, V ., A. Webson, C. Raffel, et al. Multitask prompted training enables zero-shot task\\ngeneralization. In The Tenth International Conference on Learning Representations, ICLR\\n2022, Virtual Event, April 25-29, 2022 . OpenReview.net, 2022.\\n[107] Chung, H. W., L. Hou, S. Longpre, et al. Scaling instruction-finetuned language models.\\nCoRR , abs/2210.11416, 2022.\\n[108] Li, G., H. A. A. K. Hammoud, H. Itani, et al. CAMEL: communicative agents for \"mind\"\\nexploration of large scale language model society. CoRR , abs/2303.17760, 2023.\\n[109] Qian, C., X. Cong, C. Yang, et al. Communicative agents for software development. CoRR ,\\nabs/2307.07924, 2023.\\n[110] Boiko, D. A., R. MacKnight, G. Gomes. Emergent autonomous scientific research capabilities\\nof large language models. CoRR , abs/2304.05332, 2023.\\n[111] Du, Y ., S. Li, A. Torralba, et al. Improving factuality and reasoning in language models\\nthrough multiagent debate. CoRR , abs/2305.14325, 2023.\\n[112] Liang, T., Z. He, W. Jiao, et al. Encouraging divergent thinking in large language models\\nthrough multi-agent debate. CoRR , abs/2305.19118, 2023.\\n[113] Castelfranchi, C. Guarantees for autonomy in cognitive agent architecture. In M. J. Wooldridge,\\nN. R. Jennings, eds., Intelligent Agents, ECAI-94 Workshop on Agent Theories, Architectures,\\nand Languages, Amsterdam, The Netherlands, August 8-9, 1994, Proceedings , vol. 890 of\\nLecture Notes in Computer Science , pages 56–70. Springer, 1994.\\n[114] Gravitas, S. Auto-GPT: An Autonomous GPT-4 experiment, 2023. URL https://github.\\ncom/Significant-Gravitas/Auto-GPT , 2023.\\n[115] Nakajima, Y . BabyAGI. Python. https://github. com/yoheinakajima/babyagi , 2023.\\n[116] Yuan, A., A. Coenen, E. Reif, et al. Wordcraft: Story writing with large language models.\\nIn G. Jacucci, S. Kaski, C. Conati, S. Stumpf, T. Ruotsalo, K. Gajos, eds., IUI 2022: 27th\\nInternational Conferenc', 'The Rise and Potential of Large Language Model.pdf'), 520: ('edings , vol. 890 of\\nLecture Notes in Computer Science , pages 56–70. Springer, 1994.\\n[114] Gravitas, S. Auto-GPT: An Autonomous GPT-4 experiment, 2023. URL https://github.\\ncom/Significant-Gravitas/Auto-GPT , 2023.\\n[115] Nakajima, Y . BabyAGI. Python. https://github. com/yoheinakajima/babyagi , 2023.\\n[116] Yuan, A., A. Coenen, E. Reif, et al. Wordcraft: Story writing with large language models.\\nIn G. Jacucci, S. Kaski, C. Conati, S. Stumpf, T. Ruotsalo, K. Gajos, eds., IUI 2022: 27th\\nInternational Conference on Intelligent User Interfaces, Helsinki, Finland, March 22 - 25,\\n2022 , pages 841–852. ACM, 2022.\\n[117] Franceschelli, G., M. Musolesi. On the creativity of large language models. CoRR ,\\nabs/2304.00008, 2023.\\n[118] Zhu, D., J. Chen, X. Shen, et al. Minigpt-4: Enhancing vision-language understanding with\\nadvanced large language models. arXiv preprint arXiv:2304.10592 , 2023.\\n54\\n[119] Yin, S., C. Fu, S. Zhao, et al. A survey on multimodal large language models. CoRR ,\\nabs/2306.13549, 2023.\\n[120] Driess, D., F. Xia, M. S. M. Sajjadi, et al. Palm-e: An embodied multimodal language model.\\nIn A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds., International\\nConference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , vol.\\n202 of Proceedings of Machine Learning Research , pages 8469–8488. PMLR, 2023.\\n[121] Mu, Y ., Q. Zhang, M. Hu, et al. Embodiedgpt: Vision-language pre-training via embodied\\nchain of thought. CoRR , abs/2305.15021, 2023.\\n[122] Brown, J. W. Beyond conflict monitoring: Cognitive control and the neural basis of thinking\\nbefore you act. Current Directions in Psychological Science , 22(3):179–185, 2013.\\n[123] Kang, J., R. Laroche, X. Yuan, et al. Think before you act: Decision transformers with internal\\nworking memory. CoRR , abs/2305.16338, 2023.\\n[124] Valmeekam, K., S. Sreedharan, M. Marquez, et al. On the planning abilities of large language\\nmodels (A critical investigation with a proposed benchmark). CoRR , abs/2302.06706, 2023.\\n[125] Liu, B., Y . Ji', 'The Rise and Potential of Large Language Model.pdf'), 521: ('conflict monitoring: Cognitive control and the neural basis of thinking\\nbefore you act. Current Directions in Psychological Science , 22(3):179–185, 2013.\\n[123] Kang, J., R. Laroche, X. Yuan, et al. Think before you act: Decision transformers with internal\\nworking memory. CoRR , abs/2305.16338, 2023.\\n[124] Valmeekam, K., S. Sreedharan, M. Marquez, et al. On the planning abilities of large language\\nmodels (A critical investigation with a proposed benchmark). CoRR , abs/2302.06706, 2023.\\n[125] Liu, B., Y . Jiang, X. Zhang, et al. LLM+P: empowering large language models with optimal\\nplanning proficiency. CoRR , abs/2304.11477, 2023.\\n[126] Liu, H., C. Sferrazza, P. Abbeel. Chain of hindsight aligns language models with feedback.\\nCoRR , abs/2302.02676, 2023.\\n[127] Lin, Y ., Y . Chen. Llm-eval: Unified multi-dimensional automatic evaluation for open-domain\\nconversations with large language models. CoRR , abs/2305.13711, 2023.\\n[128] Lin, J., D. Fried, D. Klein, et al. Inferring rewards from language in context. In S. Muresan,\\nP. Nakov, A. Villavicencio, eds., Proceedings of the 60th Annual Meeting of the Association\\nfor Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May\\n22-27, 2022 , pages 8546–8560. Association for Computational Linguistics, 2022.\\n[129] Fu, Y ., H. Peng, T. Khot, et al. Improving language model negotiation with self-play and\\nin-context learning from AI feedback. CoRR , abs/2305.10142, 2023.\\n[130] Zhang, H., W. Du, J. Shan, et al. Building cooperative embodied agents modularly with large\\nlanguage models. CoRR , abs/2307.02485, 2023.\\n[131] Darwin’s, C. On the origin of species. published on , 24:1, 1859.\\n[132] Bang, Y ., S. Cahyawijaya, N. Lee, et al. A multitask, multilingual, multimodal evaluation of\\nchatgpt on reasoning, hallucination, and interactivity. CoRR , abs/2302.04023, 2023.\\n[133] Fang, T., S. Yang, K. Lan, et al. Is chatgpt a highly fluent grammatical error correction system?\\nA comprehensive evaluation. CoRR , abs/2304.01746, 2023.\\n[134] Lu, A., H. Zhang, Y . Zh', 'The Rise and Potential of Large Language Model.pdf'), 522: ('ularly with large\\nlanguage models. CoRR , abs/2307.02485, 2023.\\n[131] Darwin’s, C. On the origin of species. published on , 24:1, 1859.\\n[132] Bang, Y ., S. Cahyawijaya, N. Lee, et al. A multitask, multilingual, multimodal evaluation of\\nchatgpt on reasoning, hallucination, and interactivity. CoRR , abs/2302.04023, 2023.\\n[133] Fang, T., S. Yang, K. Lan, et al. Is chatgpt a highly fluent grammatical error correction system?\\nA comprehensive evaluation. CoRR , abs/2304.01746, 2023.\\n[134] Lu, A., H. Zhang, Y . Zhang, et al. Bounding the capabilities of large language models in open\\ntext generation with prompt constraints. In A. Vlachos, I. Augenstein, eds., Findings of the\\nAssociation for Computational Linguistics: EACL 2023, Dubrovnik, Croatia, May 2-6, 2023 ,\\npages 1937–1963. Association for Computational Linguistics, 2023.\\n[135] Buehler, M. C., J. Adamy, T. H. Weisswange. Theory of mind based assistive communication\\nin complex human robot cooperation. CoRR , abs/2109.01355, 2021.\\n[136] Shapira, N., M. Levy, S. H. Alavi, et al. Clever hans or neural theory of mind? stress testing\\nsocial reasoning in large language models. CoRR , abs/2305.14763, 2023.\\n[137] Hill, F., K. Cho, A. Korhonen. Learning distributed representations of sentences from un-\\nlabelled data. In K. Knight, A. Nenkova, O. Rambow, eds., NAACL HLT 2016, The 2016\\nConference of the North American Chapter of the Association for Computational Linguis-\\ntics: Human Language Technologies, San Diego California, USA, June 12-17, 2016 , pages\\n1367–1377. The Association for Computational Linguistics, 2016.\\n55\\n[138] Collobert, R., J. Weston, L. Bottou, et al. Natural language processing (almost) from scratch.\\nJ. Mach. Learn. Res. , 12:2493–2537, 2011.\\n[139] Kaplan, J., S. McCandlish, T. Henighan, et al. Scaling laws for neural language models. CoRR ,\\nabs/2001.08361, 2020.\\n[140] Roberts, A., C. Raffel, N. Shazeer. How much knowledge can you pack into the parameters\\nof a language model? In B. Webber, T. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020\\nConference ', 'The Rise and Potential of Large Language Model.pdf'), 523: ('ociation for Computational Linguistics, 2016.\\n55\\n[138] Collobert, R., J. Weston, L. Bottou, et al. Natural language processing (almost) from scratch.\\nJ. Mach. Learn. Res. , 12:2493–2537, 2011.\\n[139] Kaplan, J., S. McCandlish, T. Henighan, et al. Scaling laws for neural language models. CoRR ,\\nabs/2001.08361, 2020.\\n[140] Roberts, A., C. Raffel, N. Shazeer. How much knowledge can you pack into the parameters\\nof a language model? In B. Webber, T. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020\\nConference on Empirical Methods in Natural Language Processing, EMNLP 2020, Online,\\nNovember 16-20, 2020 , pages 5418–5426. Association for Computational Linguistics, 2020.\\n[141] Tandon, N., A. S. Varde, G. de Melo. Commonsense knowledge in machine intelligence.\\nSIGMOD Rec. , 46(4):49–52, 2017.\\n[142] Vulic, I., E. M. Ponti, R. Litschko, et al. Probing pretrained language models for lexical\\nsemantics. In B. Webber, T. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20,\\n2020 , pages 7222–7240. Association for Computational Linguistics, 2020.\\n[143] Hewitt, J., C. D. Manning. A structural probe for finding syntax in word representations.\\nIn J. Burstein, C. Doran, T. Solorio, eds., Proceedings of the 2019 Conference of the North\\nAmerican Chapter of the Association for Computational Linguistics: Human Language Tech-\\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and\\nShort Papers) , pages 4129–4138. Association for Computational Linguistics, 2019.\\n[144] Rau, L. F., P. S. Jacobs, U. Zernik. Information extraction and text summarization using\\nlinguistic knowledge acquisition. Inf. Process. Manag. , 25(4):419–428, 1989.\\n[145] Yang, K., Z. Chen, Y . Cai, et al. Improved automatic keyword extraction given more semantic\\nknowledge. In H. Gao, J. Kim, Y . Sakurai, eds., Database Systems for Advanced Applications\\n- DASFAA 2016 International Workshops: BDMS, BDQM, MoI, and SeCoP , Dallas, TX, USA,\\nApril 16-1', 'The Rise and Potential of Large Language Model.pdf'), 524: ('38. Association for Computational Linguistics, 2019.\\n[144] Rau, L. F., P. S. Jacobs, U. Zernik. Information extraction and text summarization using\\nlinguistic knowledge acquisition. Inf. Process. Manag. , 25(4):419–428, 1989.\\n[145] Yang, K., Z. Chen, Y . Cai, et al. Improved automatic keyword extraction given more semantic\\nknowledge. In H. Gao, J. Kim, Y . Sakurai, eds., Database Systems for Advanced Applications\\n- DASFAA 2016 International Workshops: BDMS, BDQM, MoI, and SeCoP , Dallas, TX, USA,\\nApril 16-19, 2016, Proceedings , vol. 9645 of Lecture Notes in Computer Science , pages\\n112–125. Springer, 2016.\\n[146] Beloucif, M., C. Biemann. Probing pre-trained language models for semantic attributes and\\ntheir values. In M. Moens, X. Huang, L. Specia, S. W. Yih, eds., Findings of the Association for\\nComputational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic,\\n16-20 November, 2021 , pages 2554–2559. Association for Computational Linguistics, 2021.\\n[147] Zhang, Z., H. Zhao. Advances in multi-turn dialogue comprehension: A survey. CoRR ,\\nabs/2103.03125, 2021.\\n[148] Safavi, T., D. Koutra. Relational world knowledge representation in contextual language\\nmodels: A review. In M. Moens, X. Huang, L. Specia, S. W. Yih, eds., Proceedings of\\nthe 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,\\nVirtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021 , pages 1053–1067.\\nAssociation for Computational Linguistics, 2021.\\n[149] Jiang, Z., F. F. Xu, J. Araki, et al. How can we know what language models know. Trans.\\nAssoc. Comput. Linguistics , 8:423–438, 2020.\\n[150] Madaan, A., S. Zhou, U. Alon, et al. Language models of code are few-shot commonsense\\nlearners. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds., Proceedings of the 2022 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab\\nEmirates, December 7-11, 2022 , pages 1384–1403. Association for Computational Linguistics,\\n2022.\\n[151] Xu, F. F., U. Alon, G. Neubig, et al.', 'The Rise and Potential of Large Language Model.pdf'), 525: ('l. How can we know what language models know. Trans.\\nAssoc. Comput. Linguistics , 8:423–438, 2020.\\n[150] Madaan, A., S. Zhou, U. Alon, et al. Language models of code are few-shot commonsense\\nlearners. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds., Proceedings of the 2022 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab\\nEmirates, December 7-11, 2022 , pages 1384–1403. Association for Computational Linguistics,\\n2022.\\n[151] Xu, F. F., U. Alon, G. Neubig, et al. A systematic evaluation of large language models of\\ncode. In S. Chaudhuri, C. Sutton, eds., MAPS@PLDI 2022: 6th ACM SIGPLAN International\\nSymposium on Machine Programming, San Diego, CA, USA, 13 June 2022 , pages 1–10. ACM,\\n2022.\\n[152] Cobbe, K., V . Kosaraju, M. Bavarian, et al. Training verifiers to solve math word problems.\\nCoRR , abs/2110.14168, 2021.\\n56\\n[153] Thirunavukarasu, A. J., D. S. J. Ting, K. Elangovan, et al. Large language models in medicine.\\nNature medicine , pages 1–11, 2023.\\n[154] Lai, Y ., C. Li, Y . Wang, et al. DS-1000: A natural and reliable benchmark for data science\\ncode generation. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett,\\neds., International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu,\\nHawaii, USA , vol. 202 of Proceedings of Machine Learning Research , pages 18319–18345.\\nPMLR, 2023.\\n[155] AlKhamissi, B., M. Li, A. Celikyilmaz, et al. A review on language models as knowledge\\nbases. CoRR , abs/2204.06031, 2022.\\n[156] Kemker, R., M. McClure, A. Abitino, et al. Measuring catastrophic forgetting in neural\\nnetworks. In S. A. McIlraith, K. Q. Weinberger, eds., Proceedings of the Thirty-Second AAAI\\nConference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial\\nIntelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial\\nIntelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 , pages 3390–3398.\\nAAAI Press, 2018.\\n[157] Cao, N. D., W. Aziz, I. Titov. Editing fa', 'The Rise and Potential of Large Language Model.pdf'), 526: ('., M. McClure, A. Abitino, et al. Measuring catastrophic forgetting in neural\\nnetworks. In S. A. McIlraith, K. Q. Weinberger, eds., Proceedings of the Thirty-Second AAAI\\nConference on Artificial Intelligence, (AAAI-18), the 30th innovative Applications of Artificial\\nIntelligence (IAAI-18), and the 8th AAAI Symposium on Educational Advances in Artificial\\nIntelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7, 2018 , pages 3390–3398.\\nAAAI Press, 2018.\\n[157] Cao, N. D., W. Aziz, I. Titov. Editing factual knowledge in language models. In M. Moens,\\nX. Huang, L. Specia, S. W. Yih, eds., Proceedings of the 2021 Conference on Empirical Meth-\\nods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican\\nRepublic, 7-11 November, 2021 , pages 6491–6506. Association for Computational Linguistics,\\n2021.\\n[158] Yao, Y ., P. Wang, B. Tian, et al. Editing large language models: Problems, methods, and\\nopportunities. CoRR , abs/2305.13172, 2023.\\n[159] Mitchell, E., C. Lin, A. Bosselut, et al. Memory-based model editing at scale. In K. Chaudhuri,\\nS. Jegelka, L. Song, C. Szepesvári, G. Niu, S. Sabato, eds., International Conference on\\nMachine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA , vol. 162 of\\nProceedings of Machine Learning Research , pages 15817–15831. PMLR, 2022.\\n[160] Manakul, P., A. Liusie, M. J. F. Gales. Selfcheckgpt: Zero-resource black-box hallucination\\ndetection for generative large language models. CoRR , abs/2303.08896, 2023.\\n[161] Li, M., B. Peng, Z. Zhang. Self-checker: Plug-and-play modules for fact-checking with large\\nlanguage models. CoRR , abs/2305.14623, 2023.\\n[162] Gou, Z., Z. Shao, Y . Gong, et al. CRITIC: large language models can self-correct with\\ntool-interactive critiquing. CoRR , abs/2305.11738, 2023.\\n[163] Lewis, M., Y . Liu, N. Goyal, et al. BART: denoising sequence-to-sequence pre-training\\nfor natural language generation, translation, and comprehension. In D. Jurafsky, J. Chai,\\nN. Schluter, J. R. Tetreault, eds., Proceedings of the 58th Annual Me', 'The Rise and Potential of Large Language Model.pdf'), 527: ('lf-checker: Plug-and-play modules for fact-checking with large\\nlanguage models. CoRR , abs/2305.14623, 2023.\\n[162] Gou, Z., Z. Shao, Y . Gong, et al. CRITIC: large language models can self-correct with\\ntool-interactive critiquing. CoRR , abs/2305.11738, 2023.\\n[163] Lewis, M., Y . Liu, N. Goyal, et al. BART: denoising sequence-to-sequence pre-training\\nfor natural language generation, translation, and comprehension. In D. Jurafsky, J. Chai,\\nN. Schluter, J. R. Tetreault, eds., Proceedings of the 58th Annual Meeting of the Association for\\nComputational Linguistics, ACL 2020, Online, July 5-10, 2020 , pages 7871–7880. Association\\nfor Computational Linguistics, 2020.\\n[164] Park, H. H., Y . Vyas, K. Shah. Efficient classification of long documents using transformers.\\nIn S. Muresan, P. Nakov, A. Villavicencio, eds., Proceedings of the 60th Annual Meeting of\\nthe Association for Computational Linguistics (Volume 2: Short Papers), ACL 2022, Dublin,\\nIreland, May 22-27, 2022 , pages 702–709. Association for Computational Linguistics, 2022.\\n[165] Guo, M., J. Ainslie, D. C. Uthus, et al. Longt5: Efficient text-to-text transformer for long\\nsequences. In M. Carpuat, M. de Marneffe, I. V . M. Ruíz, eds., Findings of the Association for\\nComputational Linguistics: NAACL 2022, Seattle, WA, United States, July 10-15, 2022 , pages\\n724–736. Association for Computational Linguistics, 2022.\\n[166] Ainslie, J., T. Lei, M. de Jong, et al. Colt5: Faster long-range transformers with conditional\\ncomputation. CoRR , abs/2303.09752, 2023.\\n57\\n[167] Ruoss, A., G. Delétang, T. Genewein, et al. Randomized positional encodings boost length\\ngeneralization of transformers. In A. Rogers, J. L. Boyd-Graber, N. Okazaki, eds., Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short\\nPapers), ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 1889–1903. Association for\\nComputational Linguistics, 2023.\\n[168] Liang, X., B. Wang, H. Huang, et al. Unleashing infinite-length input capacity for large-scale\\nlanguage m', 'The Rise and Potential of Large Language Model.pdf'), 528: ('67] Ruoss, A., G. Delétang, T. Genewein, et al. Randomized positional encodings boost length\\ngeneralization of transformers. In A. Rogers, J. L. Boyd-Graber, N. Okazaki, eds., Proceedings\\nof the 61st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short\\nPapers), ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 1889–1903. Association for\\nComputational Linguistics, 2023.\\n[168] Liang, X., B. Wang, H. Huang, et al. Unleashing infinite-length input capacity for large-scale\\nlanguage models with self-controlled memory system. CoRR , abs/2304.13343, 2023.\\n[169] Shinn, N., B. Labash, A. Gopinath. Reflexion: an autonomous agent with dynamic memory\\nand self-reflection. CoRR , abs/2303.11366, 2023.\\n[170] Zhong, W., L. Guo, Q. Gao, et al. Memorybank: Enhancing large language models with\\nlong-term memory. CoRR , abs/2305.10250, 2023.\\n[171] Chan, C., W. Chen, Y . Su, et al. Chateval: Towards better llm-based evaluators through\\nmulti-agent debate. CoRR , abs/2308.07201, 2023.\\n[172] Zhu, X., Y . Chen, H. Tian, et al. Ghost in the minecraft: Generally capable agents for open-\\nworld environments via large language models with text-based knowledge and memory. CoRR ,\\nabs/2305.17144, 2023.\\n[173] Modarressi, A., A. Imani, M. Fayyaz, et al. RET-LLM: towards a general read-write memory\\nfor large language models. CoRR , abs/2305.14322, 2023.\\n[174] Lin, J., H. Zhao, A. Zhang, et al. Agentsims: An open-source sandbox for large language\\nmodel evaluation. CoRR , abs/2308.04026, 2023.\\n[175] Hu, C., J. Fu, C. Du, et al. Chatdb: Augmenting llms with databases as their symbolic memory.\\nCoRR , abs/2306.03901, 2023.\\n[176] Huang, Z., S. Gutierrez, H. Kamana, et al. Memory sandbox: Transparent and interactive\\nmemory management for conversational agents. CoRR , abs/2308.01542, 2023.\\n[177] Creswell, A., M. Shanahan, I. Higgins. Selection-inference: Exploiting large language models\\nfor interpretable logical reasoning. In The Eleventh International Conference on Learning\\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 20', 'The Rise and Potential of Large Language Model.pdf'), 529: ('et al. Chatdb: Augmenting llms with databases as their symbolic memory.\\nCoRR , abs/2306.03901, 2023.\\n[176] Huang, Z., S. Gutierrez, H. Kamana, et al. Memory sandbox: Transparent and interactive\\nmemory management for conversational agents. CoRR , abs/2308.01542, 2023.\\n[177] Creswell, A., M. Shanahan, I. Higgins. Selection-inference: Exploiting large language models\\nfor interpretable logical reasoning. In The Eleventh International Conference on Learning\\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[178] Madaan, A., N. Tandon, P. Gupta, et al. Self-refine: Iterative refinement with self-feedback.\\nCoRR , abs/2303.17651, 2023.\\n[179] Ichter, B., A. Brohan, Y . Chebotar, et al. Do as I can, not as I say: Grounding language in\\nrobotic affordances. In K. Liu, D. Kulic, J. Ichnowski, eds., Conference on Robot Learning,\\nCoRL 2022, 14-18 December 2022, Auckland, New Zealand , vol. 205 of Proceedings of\\nMachine Learning Research , pages 287–318. PMLR, 2022.\\n[180] Shen, Y ., K. Song, X. Tan, et al. Hugginggpt: Solving AI tasks with chatgpt and its friends in\\nhuggingface. CoRR , abs/2303.17580, 2023.\\n[181] Yao, S., D. Yu, J. Zhao, et al. Tree of thoughts: Deliberate problem solving with large language\\nmodels. CoRR , abs/2305.10601, 2023.\\n[182] Wu, Y ., S. Y . Min, Y . Bisk, et al. Plan, eliminate, and track - language models are good teachers\\nfor embodied agents. CoRR , abs/2305.02412, 2023.\\n[183] Wang, Z., S. Cai, A. Liu, et al. Describe, explain, plan and select: Interactive planning with\\nlarge language models enables open-world multi-task agents. CoRR , abs/2302.01560, 2023.\\n[184] Hao, S., Y . Gu, H. Ma, et al. Reasoning with language model is planning with world model.\\nCoRR , abs/2305.14992, 2023.\\n[185] Lin, B. Y ., Y . Fu, K. Yang, et al. Swiftsage: A generative agent with fast and slow thinking for\\ncomplex interactive tasks. CoRR , abs/2305.17390, 2023.\\n58\\n[186] Karpas, E., O. Abend, Y . Belinkov, et al. MRKL systems: A modular, neuro-symbolic\\narchitecture that combines large language', 'The Rise and Potential of Large Language Model.pdf'), 530: ('th\\nlarge language models enables open-world multi-task agents. CoRR , abs/2302.01560, 2023.\\n[184] Hao, S., Y . Gu, H. Ma, et al. Reasoning with language model is planning with world model.\\nCoRR , abs/2305.14992, 2023.\\n[185] Lin, B. Y ., Y . Fu, K. Yang, et al. Swiftsage: A generative agent with fast and slow thinking for\\ncomplex interactive tasks. CoRR , abs/2305.17390, 2023.\\n58\\n[186] Karpas, E., O. Abend, Y . Belinkov, et al. MRKL systems: A modular, neuro-symbolic\\narchitecture that combines large language models, external knowledge sources and discrete\\nreasoning. CoRR , abs/2205.00445, 2022.\\n[187] Huang, W., F. Xia, T. Xiao, et al. Inner monologue: Embodied reasoning through planning\\nwith language models. In K. Liu, D. Kulic, J. Ichnowski, eds., Conference on Robot Learning,\\nCoRL 2022, 14-18 December 2022, Auckland, New Zealand , vol. 205 of Proceedings of\\nMachine Learning Research , pages 1769–1782. PMLR, 2022.\\n[188] Chen, Z., K. Zhou, B. Zhang, et al. Chatcot: Tool-augmented chain-of-thought reasoning on\\nchat-based large language models. CoRR , abs/2305.14323, 2023.\\n[189] Wu, T., M. Terry, C. J. Cai. AI chains: Transparent and controllable human-ai interaction\\nby chaining large language model prompts. In S. D. J. Barbosa, C. Lampe, C. Appert, D. A.\\nShamma, S. M. Drucker, J. R. Williamson, K. Yatani, eds., CHI ’22: CHI Conference on\\nHuman Factors in Computing Systems, New Orleans, LA, USA, 29 April 2022 - 5 May 2022 ,\\npages 385:1–385:22. ACM, 2022.\\n[190] Wang, G., Y . Xie, Y . Jiang, et al. V oyager: An open-ended embodied agent with large language\\nmodels. CoRR , abs/2305.16291, 2023.\\n[191] Zhao, X., M. Li, C. Weber, et al. Chat with the environment: Interactive multimodal perception\\nusing large language models. CoRR , abs/2303.08268, 2023.\\n[192] Miao, N., Y . W. Teh, T. Rainforth. Selfcheck: Using llms to zero-shot check their own\\nstep-by-step reasoning. CoRR , abs/2308.00436, 2023.\\n[193] Wang, X., W. Wang, Y . Cao, et al. Images speak in images: A generalist painter for in-context\\nvisual learning. In IEEE/CV', 'The Rise and Potential of Large Language Model.pdf'), 531: ('-ended embodied agent with large language\\nmodels. CoRR , abs/2305.16291, 2023.\\n[191] Zhao, X., M. Li, C. Weber, et al. Chat with the environment: Interactive multimodal perception\\nusing large language models. CoRR , abs/2303.08268, 2023.\\n[192] Miao, N., Y . W. Teh, T. Rainforth. Selfcheck: Using llms to zero-shot check their own\\nstep-by-step reasoning. CoRR , abs/2308.00436, 2023.\\n[193] Wang, X., W. Wang, Y . Cao, et al. Images speak in images: A generalist painter for in-context\\nvisual learning. In IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR\\n2023, Vancouver, BC, Canada, June 17-24, 2023 , pages 6830–6839. IEEE, 2023.\\n[194] Wang, C., S. Chen, Y . Wu, et al. Neural codec language models are zero-shot text to speech\\nsynthesizers. CoRR , abs/2301.02111, 2023.\\n[195] Dong, Q., L. Li, D. Dai, et al. A survey for in-context learning. CoRR , abs/2301.00234, 2023.\\n[196] Ke, Z., B. Liu. Continual learning of natural language processing tasks: A survey. ArXiv ,\\nabs/2211.12701, 2022.\\n[197] Wang, L., X. Zhang, H. Su, et al. A comprehensive survey of continual learning: Theory,\\nmethod and application. ArXiv , abs/2302.00487, 2023.\\n[198] Razdaibiedina, A., Y . Mao, R. Hou, et al. Progressive prompts: Continual learning for language\\nmodels. In The Eleventh International Conference on Learning Representations . 2023.\\n[199] Marshall, L. H., H. W. Magoun. Discoveries in the human brain: neuroscience prehistory,\\nbrain structure, and function . Springer Science & Business Media, 2013.\\n[200] Searle, J. R. What is language: some preliminary remarks. Explorations in Pragmatics.\\nLinguistic, cognitive and intercultural aspects , pages 7–37, 2007.\\n[201] Touvron, H., T. Lavril, G. Izacard, et al. Llama: Open and efficient foundation language\\nmodels. CoRR , abs/2302.13971, 2023.\\n[202] Scao, T. L., A. Fan, C. Akiki, et al. BLOOM: A 176b-parameter open-access multilingual\\nlanguage model. CoRR , abs/2211.05100, 2022.\\n[203] Almazrouei, E., H. Alobeidli, A. Alshamsi, et al. Falcon-40b: an open large language model\\nwith st', 'The Rise and Potential of Large Language Model.pdf'), 532: ('at is language: some preliminary remarks. Explorations in Pragmatics.\\nLinguistic, cognitive and intercultural aspects , pages 7–37, 2007.\\n[201] Touvron, H., T. Lavril, G. Izacard, et al. Llama: Open and efficient foundation language\\nmodels. CoRR , abs/2302.13971, 2023.\\n[202] Scao, T. L., A. Fan, C. Akiki, et al. BLOOM: A 176b-parameter open-access multilingual\\nlanguage model. CoRR , abs/2211.05100, 2022.\\n[203] Almazrouei, E., H. Alobeidli, A. Alshamsi, et al. Falcon-40b: an open large language model\\nwith state-of-the-art performance, 2023.\\n[204] Serban, I. V ., R. Lowe, L. Charlin, et al. Generative deep neural networks for dialogue: A\\nshort review. CoRR , abs/1611.06216, 2016.\\n[205] Vinyals, O., Q. V . Le. A neural conversational model. CoRR , abs/1506.05869, 2015.\\n59\\n[206] Adiwardana, D., M. Luong, D. R. So, et al. Towards a human-like open-domain chatbot.\\nCoRR , abs/2001.09977, 2020.\\n[207] Zhuge, M., H. Liu, F. Faccio, et al. Mindstorms in natural language-based societies of mind.\\nCoRR , abs/2305.17066, 2023.\\n[208] Roller, S., E. Dinan, N. Goyal, et al. Recipes for building an open-domain chatbot. In P. Merlo,\\nJ. Tiedemann, R. Tsarfaty, eds., Proceedings of the 16th Conference of the European Chapter\\nof the Association for Computational Linguistics: Main Volume, EACL 2021, Online, April 19\\n- 23, 2021 , pages 300–325. Association for Computational Linguistics, 2021.\\n[209] Taori, R., I. Gulrajani, T. Zhang, et al. Stanford alpaca: An instruction-following llama model,\\n2023.\\n[210] Raffel, C., N. Shazeer, A. Roberts, et al. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. The Journal of Machine Learning Research , 21(1):5485–5551, 2020.\\n[211] Ge, Y ., W. Hua, J. Ji, et al. Openagi: When LLM meets domain experts. CoRR , abs/2304.04370,\\n2023.\\n[212] Rajpurkar, P., J. Zhang, K. Lopyrev, et al. Squad: 100, 000+ questions for machine com-\\nprehension of text. In J. Su, X. Carreras, K. Duh, eds., Proceedings of the 2016 Conference\\non Empirical Methods in Natural Language Processing, EMNLP', 'The Rise and Potential of Large Language Model.pdf'), 533: ('erts, et al. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. The Journal of Machine Learning Research , 21(1):5485–5551, 2020.\\n[211] Ge, Y ., W. Hua, J. Ji, et al. Openagi: When LLM meets domain experts. CoRR , abs/2304.04370,\\n2023.\\n[212] Rajpurkar, P., J. Zhang, K. Lopyrev, et al. Squad: 100, 000+ questions for machine com-\\nprehension of text. In J. Su, X. Carreras, K. Duh, eds., Proceedings of the 2016 Conference\\non Empirical Methods in Natural Language Processing, EMNLP 2016, Austin, Texas, USA,\\nNovember 1-4, 2016 , pages 2383–2392. The Association for Computational Linguistics, 2016.\\n[213] Ahuja, K., R. Hada, M. Ochieng, et al. MEGA: multilingual evaluation of generative AI.\\nCoRR , abs/2303.12528, 2023.\\n[214] See, A., A. Pappu, R. Saxena, et al. Do massively pretrained language models make better\\nstorytellers? In M. Bansal, A. Villavicencio, eds., Proceedings of the 23rd Conference on\\nComputational Natural Language Learning, CoNLL 2019, Hong Kong, China, November 3-4,\\n2019 , pages 843–861. Association for Computational Linguistics, 2019.\\n[215] Radford, A., J. Wu, D. Amodei, et al. Better language models and their implications. OpenAI\\nblog, 1(2), 2019.\\n[216] McCoy, R. T., P. Smolensky, T. Linzen, et al. How much do language models copy from\\ntheir training data? evaluating linguistic novelty in text generation using RA VEN. CoRR ,\\nabs/2111.09509, 2021.\\n[217] Tellex, S., T. Kollar, S. Dickerson, et al. Understanding natural language commands for\\nrobotic navigation and mobile manipulation. In W. Burgard, D. Roth, eds., Proceedings of the\\nTwenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco, California,\\nUSA, August 7-11, 2011 , pages 1507–1514. AAAI Press, 2011.\\n[218] Christiano, P. F., J. Leike, T. B. Brown, et al. Deep reinforcement learning from human\\npreferences. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N.\\nVishwanathan, R. Garnett, eds., Advances in Neural Information Processing Systems 30:\\nAnnual Conference on Neur', 'The Rise and Potential of Large Language Model.pdf'), 534: ('manipulation. In W. Burgard, D. Roth, eds., Proceedings of the\\nTwenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco, California,\\nUSA, August 7-11, 2011 , pages 1507–1514. AAAI Press, 2011.\\n[218] Christiano, P. F., J. Leike, T. B. Brown, et al. Deep reinforcement learning from human\\npreferences. In I. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N.\\nVishwanathan, R. Garnett, eds., Advances in Neural Information Processing Systems 30:\\nAnnual Conference on Neural Information Processing Systems 2017, December 4-9, 2017,\\nLong Beach, CA, USA , pages 4299–4307. 2017.\\n[219] Basu, C., M. Singhal, A. D. Dragan. Learning from richer human guidance: Augmenting\\ncomparison-based learning with feature queries. In T. Kanda, S. Sabanovic, G. Hoffman,\\nA. Tapus, eds., Proceedings of the 2018 ACM/IEEE International Conference on Human-Robot\\nInteraction, HRI 2018, Chicago, IL, USA, March 05-08, 2018 , pages 132–140. ACM, 2018.\\n[220] Sumers, T. R., M. K. Ho, R. X. D. Hawkins, et al. Learning rewards from linguistic feedback.\\nInThirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference\\non Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on\\nEducational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021 ,\\npages 6002–6010. AAAI Press, 2021.\\n60\\n[221] Jeon, H. J., S. Milli, A. D. Dragan. Reward-rational (implicit) choice: A unifying formalism for\\nreward learning. In H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin, eds., Advances\\nin Neural Information Processing Systems 33: Annual Conference on Neural Information\\nProcessing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual . 2020.\\n[222] McShane, M. Reference resolution challenges for intelligent agents: The need for knowledge.\\nIEEE Intell. Syst. , 24(4):47–58, 2009.\\n[223] Gururangan, S., A. Marasovic, S. Swayamdipta, et al. Don’t stop pretraining: Adapt language\\nmodels to domains and tasks. In D. Jurafsky, J. Chai, N. Schluter,', 'The Rise and Potential of Large Language Model.pdf'), 535: ('o, R. Hadsell, M. Balcan, H. Lin, eds., Advances\\nin Neural Information Processing Systems 33: Annual Conference on Neural Information\\nProcessing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual . 2020.\\n[222] McShane, M. Reference resolution challenges for intelligent agents: The need for knowledge.\\nIEEE Intell. Syst. , 24(4):47–58, 2009.\\n[223] Gururangan, S., A. Marasovic, S. Swayamdipta, et al. Don’t stop pretraining: Adapt language\\nmodels to domains and tasks. In D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreault, eds.,\\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL\\n2020, Online, July 5-10, 2020 , pages 8342–8360. Association for Computational Linguistics,\\n2020.\\n[224] Shi, F., X. Chen, K. Misra, et al. Large language models can be easily distracted by irrelevant\\ncontext. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds.,\\nInternational Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu,\\nHawaii, USA , vol. 202 of Proceedings of Machine Learning Research , pages 31210–31227.\\nPMLR, 2023.\\n[225] Zhang, Y ., Y . Li, L. Cui, et al. Siren’s song in the AI ocean: A survey on hallucination in large\\nlanguage models. CoRR , abs/2309.01219, 2023.\\n[226] Mialon, G., R. Dessì, M. Lomeli, et al. Augmented language models: a survey. CoRR ,\\nabs/2302.07842, 2023.\\n[227] Ren, R., Y . Wang, Y . Qu, et al. Investigating the factual knowledge boundary of large language\\nmodels with retrieval augmentation. CoRR , abs/2307.11019, 2023.\\n[228] Nuxoll, A. M., J. E. Laird. Extending cognitive architecture with episodic memory. In AAAI ,\\npages 1560–1564. 2007.\\n[229] Squire, L. R. Mechanisms of memory. Science , 232(4758):1612–1619, 1986.\\n[230] Schwabe, L., K. Nader, J. C. Pruessner. Reconsolidation of human memory: brain mechanisms\\nand clinical relevance. Biological psychiatry , 76(4):274–280, 2014.\\n[231] Hutter, M. A theory of universal artificial intelligence based on algorithmic complexity. arXiv\\npreprint cs/0004001 , 2000.\\n[232] Zhang, X., ', 'The Rise and Potential of Large Language Model.pdf'), 536: ('228] Nuxoll, A. M., J. E. Laird. Extending cognitive architecture with episodic memory. In AAAI ,\\npages 1560–1564. 2007.\\n[229] Squire, L. R. Mechanisms of memory. Science , 232(4758):1612–1619, 1986.\\n[230] Schwabe, L., K. Nader, J. C. Pruessner. Reconsolidation of human memory: brain mechanisms\\nand clinical relevance. Biological psychiatry , 76(4):274–280, 2014.\\n[231] Hutter, M. A theory of universal artificial intelligence based on algorithmic complexity. arXiv\\npreprint cs/0004001 , 2000.\\n[232] Zhang, X., F. Wei, M. Zhou. HIBERT: document level pre-training of hierarchical bidirectional\\ntransformers for document summarization. In A. Korhonen, D. R. Traum, L. Màrquez, eds.,\\nProceedings of the 57th Conference of the Association for Computational Linguistics, ACL\\n2019, Florence, Italy, July 28- August 2, 2019, Volume 1: Long Papers , pages 5059–5069.\\nAssociation for Computational Linguistics, 2019.\\n[233] Mohtashami, A., M. Jaggi. Landmark attention: Random-access infinite context length for\\ntransformers. CoRR , abs/2305.16300, 2023.\\n[234] Chalkidis, I., X. Dai, M. Fergadiotis, et al. An exploration of hierarchical attention transformers\\nfor efficient long document classification. CoRR , abs/2210.05529, 2022.\\n[235] Nie, Y ., H. Huang, W. Wei, et al. Capturing global structural information in long document\\nquestion answering with compressive graph selector network. In Y . Goldberg, Z. Kozareva,\\nY . Zhang, eds., Proceedings of the 2022 Conference on Empirical Methods in Natural Language\\nProcessing, EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 , pages\\n5036–5047. Association for Computational Linguistics, 2022.\\n[236] Bertsch, A., U. Alon, G. Neubig, et al. Unlimiformer: Long-range transformers with unlimited\\nlength input. CoRR , abs/2305.01625, 2023.\\n61\\n[237] Manakul, P., M. J. F. Gales. Sparsity and sentence structure in encoder-decoder attention of\\nsummarization systems. In M. Moens, X. Huang, L. Specia, S. W. Yih, eds., Proceedings of\\nthe 2021 Conference on Empirical Methods in Natural Language Pr', 'The Rise and Potential of Large Language Model.pdf'), 537: ('habi, United Arab Emirates, December 7-11, 2022 , pages\\n5036–5047. Association for Computational Linguistics, 2022.\\n[236] Bertsch, A., U. Alon, G. Neubig, et al. Unlimiformer: Long-range transformers with unlimited\\nlength input. CoRR , abs/2305.01625, 2023.\\n61\\n[237] Manakul, P., M. J. F. Gales. Sparsity and sentence structure in encoder-decoder attention of\\nsummarization systems. In M. Moens, X. Huang, L. Specia, S. W. Yih, eds., Proceedings of\\nthe 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,\\nVirtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021 , pages 9359–9368.\\nAssociation for Computational Linguistics, 2021.\\n[238] Zaheer, M., G. Guruganesh, K. A. Dubey, et al. Big bird: Transformers for longer sequences.\\nIn H. Larochelle, M. Ranzato, R. Hadsell, M. Balcan, H. Lin, eds., Advances in Neural\\nInformation Processing Systems 33: Annual Conference on Neural Information Processing\\nSystems 2020, NeurIPS 2020, December 6-12, 2020, virtual . 2020.\\n[239] Zhao, A., D. Huang, Q. Xu, et al. Expel: LLM agents are experiential learners. CoRR ,\\nabs/2308.10144, 2023.\\n[240] Zhou, X., G. Li, Z. Liu. LLM as DBA. CoRR , abs/2308.05481, 2023.\\n[241] Wason, P. C. Reasoning about a rule. Quarterly journal of experimental psychology , 20(3):273–\\n281, 1968.\\n[242] Wason, P. C., P. N. Johnson-Laird. Psychology of reasoning: Structure and content , vol. 86.\\nHarvard University Press, 1972.\\n[243] Galotti, K. M. Approaches to studying formal and everyday reasoning. Psychological bulletin ,\\n105(3):331, 1989.\\n[244] Huang, J., K. C. Chang. Towards reasoning in large language models: A survey. In A. Rogers,\\nJ. L. Boyd-Graber, N. Okazaki, eds., Findings of the Association for Computational Linguistics:\\nACL 2023, Toronto, Canada, July 9-14, 2023 , pages 1049–1065. Association for Computational\\nLinguistics, 2023.\\n[245] Webb, T. W., K. J. Holyoak, H. Lu. Emergent analogical reasoning in large language models.\\nCoRR , abs/2212.09196, 2022.\\n[246] Feng, G., B. Zhang, Y . Gu, et al. Towards revealing the my', 'The Rise and Potential of Large Language Model.pdf'), 538: ('5(3):331, 1989.\\n[244] Huang, J., K. C. Chang. Towards reasoning in large language models: A survey. In A. Rogers,\\nJ. L. Boyd-Graber, N. Okazaki, eds., Findings of the Association for Computational Linguistics:\\nACL 2023, Toronto, Canada, July 9-14, 2023 , pages 1049–1065. Association for Computational\\nLinguistics, 2023.\\n[245] Webb, T. W., K. J. Holyoak, H. Lu. Emergent analogical reasoning in large language models.\\nCoRR , abs/2212.09196, 2022.\\n[246] Feng, G., B. Zhang, Y . Gu, et al. Towards revealing the mystery behind chain of thought: a\\ntheoretical perspective. CoRR , abs/2305.15408, 2023.\\n[247] Grafman, J., L. Spector, M. J. Rattermann. Planning and the brain. In The cognitive psychology\\nof planning , pages 191–208. Psychology Press, 2004.\\n[248] Unterrainer, J. M., A. M. Owen. Planning and problem solving: from neuropsychology to\\nfunctional neuroimaging. Journal of Physiology-Paris , 99(4-6):308–317, 2006.\\n[249] Zula, K. J., T. J. Chermack. Integrative literature review: Human capital planning: A review of\\nliterature and implications for human resource development. Human Resource Development\\nReview , 6(3):245–262, 2007.\\n[250] Bratman, M. E., D. J. Israel, M. E. Pollack. Plans and resource-bounded practical reasoning.\\nComputational intelligence , 4(3):349–355, 1988.\\n[251] Russell, S., P. Norvig. Artificial intelligence - a modern approach, 2nd Edition . Prentice Hall\\nseries in artificial intelligence. Prentice Hall, 2003.\\n[252] Fainstein, S. S., J. DeFilippis. Readings in planning theory . John Wiley & Sons, 2015.\\n[253] Sebastia, L., E. Onaindia, E. Marzal. Decomposition of planning problems. Ai Communica-\\ntions , 19(1):49–81, 2006.\\n[254] Crosby, M., M. Rovatsos, R. Petrick. Automated agent decomposition for classical planning. In\\nProceedings of the International Conference on Automated Planning and Scheduling , vol. 23,\\npages 46–54. 2013.\\n[255] Xu, B., Z. Peng, B. Lei, et al. Rewoo: Decoupling reasoning from observations for efficient\\naugmented language models. CoRR , abs/2305.18323, 2023.\\n62\\n[256] Raman, S. S', 'The Rise and Potential of Large Language Model.pdf'), 539: ('2015.\\n[253] Sebastia, L., E. Onaindia, E. Marzal. Decomposition of planning problems. Ai Communica-\\ntions , 19(1):49–81, 2006.\\n[254] Crosby, M., M. Rovatsos, R. Petrick. Automated agent decomposition for classical planning. In\\nProceedings of the International Conference on Automated Planning and Scheduling , vol. 23,\\npages 46–54. 2013.\\n[255] Xu, B., Z. Peng, B. Lei, et al. Rewoo: Decoupling reasoning from observations for efficient\\naugmented language models. CoRR , abs/2305.18323, 2023.\\n62\\n[256] Raman, S. S., V . Cohen, E. Rosen, et al. Planning with large language models via corrective\\nre-prompting. CoRR , abs/2211.09935, 2022.\\n[257] Lyu, Q., S. Havaldar, A. Stein, et al. Faithful chain-of-thought reasoning. CoRR ,\\nabs/2301.13379, 2023.\\n[258] Huang, W., P. Abbeel, D. Pathak, et al. Language models as zero-shot planners: Extracting ac-\\ntionable knowledge for embodied agents. In K. Chaudhuri, S. Jegelka, L. Song, C. Szepesvári,\\nG. Niu, S. Sabato, eds., International Conference on Machine Learning, ICML 2022, 17-23\\nJuly 2022, Baltimore, Maryland, USA , vol. 162 of Proceedings of Machine Learning Research ,\\npages 9118–9147. PMLR, 2022.\\n[259] Dagan, G., F. Keller, A. Lascarides. Dynamic planning with a LLM. CoRR , abs/2308.06391,\\n2023.\\n[260] Rana, K., J. Haviland, S. Garg, et al. Sayplan: Grounding large language models using 3d\\nscene graphs for scalable task planning. CoRR , abs/2307.06135, 2023.\\n[261] Peters, M. E., M. Neumann, M. Iyyer, et al. Deep contextualized word representations. In\\nProceedings of the 2018 Conference of the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pages\\n2227–2237. Association for Computational Linguistics, New Orleans, Louisiana, 2018.\\n[262] Devlin, J., M. Chang, K. Lee, et al. BERT: pre-training of deep bidirectional transformers for\\nlanguage understanding. In J. Burstein, C. Doran, T. Solorio, eds., Proceedings of the 2019\\nConference of the North American Chapter of the Association for Computational Lingui', 'The Rise and Potential of Large Language Model.pdf'), 540: ('Conference of the North American Chapter of the Association for\\nComputational Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pages\\n2227–2237. Association for Computational Linguistics, New Orleans, Louisiana, 2018.\\n[262] Devlin, J., M. Chang, K. Lee, et al. BERT: pre-training of deep bidirectional transformers for\\nlanguage understanding. In J. Burstein, C. Doran, T. Solorio, eds., Proceedings of the 2019\\nConference of the North American Chapter of the Association for Computational Linguis-\\ntics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7,\\n2019, Volume 1 (Long and Short Papers) , pages 4171–4186. Association for Computational\\nLinguistics, 2019.\\n[263] Solaiman, I., C. Dennison. Process for adapting language models to society (palms) with\\nvalues-targeted datasets. Advances in Neural Information Processing Systems , 34:5861–5873,\\n2021.\\n[264] Bach, S. H., V . Sanh, Z. X. Yong, et al. Promptsource: An integrated development environment\\nand repository for natural language prompts. In V . Basile, Z. Kozareva, S. Stajner, eds.,\\nProceedings of the 60th Annual Meeting of the Association for Computational Linguistics, ACL\\n2022 - System Demonstrations, Dublin, Ireland, May 22-27, 2022 , pages 93–104. Association\\nfor Computational Linguistics, 2022.\\n[265] Iyer, S., X. V . Lin, R. Pasunuru, et al. OPT-IML: scaling language model instruction meta\\nlearning through the lens of generalization. CoRR , abs/2212.12017, 2022.\\n[266] Winston, P. H. Learning and reasoning by analogy. Commun. ACM , 23(12):689–703, 1980.\\n[267] Lu, Y ., M. Bartolo, A. Moore, et al. Fantastically ordered prompts and where to find them:\\nOvercoming few-shot prompt order sensitivity. In S. Muresan, P. Nakov, A. Villavicencio,\\neds., Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022 , pages 8086–8098.\\nAssociation for Computational Linguistics, 2022.\\n[268] Tsimpoukelli, M., J. Menick, S. Cabi, et al. Multimod', 'The Rise and Potential of Large Language Model.pdf'), 541: ('Commun. ACM , 23(12):689–703, 1980.\\n[267] Lu, Y ., M. Bartolo, A. Moore, et al. Fantastically ordered prompts and where to find them:\\nOvercoming few-shot prompt order sensitivity. In S. Muresan, P. Nakov, A. Villavicencio,\\neds., Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics\\n(Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022 , pages 8086–8098.\\nAssociation for Computational Linguistics, 2022.\\n[268] Tsimpoukelli, M., J. Menick, S. Cabi, et al. Multimodal few-shot learning with frozen\\nlanguage models. In M. Ranzato, A. Beygelzimer, Y . N. Dauphin, P. Liang, J. W. Vaughan,\\neds., Advances in Neural Information Processing Systems 34: Annual Conference on Neural\\nInformation Processing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual , pages\\n200–212. 2021.\\n[269] Bar, A., Y . Gandelsman, T. Darrell, et al. Visual prompting via image inpainting. In NeurIPS .\\n2022.\\n[270] Zhu, W., H. Liu, Q. Dong, et al. Multilingual machine translation with large language models:\\nEmpirical results and analysis. CoRR , abs/2304.04675, 2023.\\n63\\n[271] Zhang, Z., L. Zhou, C. Wang, et al. Speak foreign languages with your own voice: Cross-\\nlingual neural codec language modeling. CoRR , abs/2303.03926, 2023.\\n[272] Zhang, J., J. Zhang, K. Pertsch, et al. Bootstrap your own skills: Learning to solve new tasks\\nwith large language model guidance. In 7th Annual Conference on Robot Learning . 2023.\\n[273] McCloskey, M., N. J. Cohen. Catastrophic interference in connectionist networks: The\\nsequential learning problem. Psychology of Learning and Motivation , 24:109–165, 1989.\\n[274] Kirkpatrick, J., R. Pascanu, N. Rabinowitz, et al. Overcoming catastrophic forgetting in neural\\nnetworks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.\\n[275] Li, Z., D. Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and\\nmachine intelligence , 40(12):2935–2947, 2017.\\n[276] Farajtabar, M., N. Azizan, A. Mott, et al. Orthogonal gradient descent for continual le', 'The Rise and Potential of Large Language Model.pdf'), 542: ('he\\nsequential learning problem. Psychology of Learning and Motivation , 24:109–165, 1989.\\n[274] Kirkpatrick, J., R. Pascanu, N. Rabinowitz, et al. Overcoming catastrophic forgetting in neural\\nnetworks. Proceedings of the national academy of sciences , 114(13):3521–3526, 2017.\\n[275] Li, Z., D. Hoiem. Learning without forgetting. IEEE transactions on pattern analysis and\\nmachine intelligence , 40(12):2935–2947, 2017.\\n[276] Farajtabar, M., N. Azizan, A. Mott, et al. Orthogonal gradient descent for continual learning.\\nInInternational Conference on Artificial Intelligence and Statistics , pages 3762–3773. PMLR,\\n2020.\\n[277] Smith, J. S., Y .-C. Hsu, L. Zhang, et al. Continual diffusion: Continual customization of\\ntext-to-image diffusion with c-lora. arXiv preprint arXiv:2304.06027 , 2023.\\n[278] Lopez-Paz, D., M. Ranzato. Gradient episodic memory for continual learning. Advances in\\nneural information processing systems , 30, 2017.\\n[279] de Masson D’Autume, C., S. Ruder, L. Kong, et al. Episodic memory in lifelong language\\nlearning. Advances in Neural Information Processing Systems , 32, 2019.\\n[280] Rolnick, D., A. Ahuja, J. Schwarz, et al. Experience replay for continual learning. Advances\\nin Neural Information Processing Systems , 32, 2019.\\n[281] Serrà, J., D. Surís, M. Miron, et al. Overcoming catastrophic forgetting with hard attention to\\nthe task. In International Conference on Machine Learning . 2018.\\n[282] Dosovitskiy, A., L. Beyer, A. Kolesnikov, et al. An image is worth 16x16 words: Transformers\\nfor image recognition at scale. In 9th International Conference on Learning Representations,\\nICLR 2021, Virtual Event, Austria, May 3-7, 2021 . OpenReview.net, 2021.\\n[283] van den Oord, A., O. Vinyals, K. Kavukcuoglu. Neural discrete representation learning. In\\nI. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N. Vishwanathan,\\nR. Garnett, eds., Advances in Neural Information Processing Systems 30: Annual Conference\\non Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA ', 'The Rise and Potential of Large Language Model.pdf'), 543: ('gnition at scale. In 9th International Conference on Learning Representations,\\nICLR 2021, Virtual Event, Austria, May 3-7, 2021 . OpenReview.net, 2021.\\n[283] van den Oord, A., O. Vinyals, K. Kavukcuoglu. Neural discrete representation learning. In\\nI. Guyon, U. von Luxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N. Vishwanathan,\\nR. Garnett, eds., Advances in Neural Information Processing Systems 30: Annual Conference\\non Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA ,\\npages 6306–6315. 2017.\\n[284] Mehta, S., M. Rastegari. Mobilevit: Light-weight, general-purpose, and mobile-friendly vision\\ntransformer. In The Tenth International Conference on Learning Representations, ICLR 2022,\\nVirtual Event, April 25-29, 2022 . OpenReview.net, 2022.\\n[285] Tolstikhin, I. O., N. Houlsby, A. Kolesnikov, et al. Mlp-mixer: An all-mlp architecture for\\nvision. In M. Ranzato, A. Beygelzimer, Y . N. Dauphin, P. Liang, J. W. Vaughan, eds., Advances\\nin Neural Information Processing Systems 34: Annual Conference on Neural Information\\nProcessing Systems 2021, NeurIPS 2021, December 6-14, 2021, virtual , pages 24261–24272.\\n2021.\\n[286] Huang, S., L. Dong, W. Wang, et al. Language is not all you need: Aligning perception with\\nlanguage models. CoRR , abs/2302.14045, 2023.\\n[287] Li, J., D. Li, S. Savarese, et al. BLIP-2: bootstrapping language-image pre-training with frozen\\nimage encoders and large language models. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt,\\nS. Sabato, J. Scarlett, eds., International Conference on Machine Learning, ICML 2023, 23-29\\nJuly 2023, Honolulu, Hawaii, USA , vol. 202 of Proceedings of Machine Learning Research ,\\npages 19730–19742. PMLR, 2023.\\n[288] Dai, W., J. Li, D. Li, et al. Instructblip: Towards general-purpose vision-language models with\\ninstruction tuning. CoRR , abs/2305.06500, 2023.\\n64\\n[289] Gong, T., C. Lyu, S. Zhang, et al. Multimodal-gpt: A vision and language model for dialogue\\nwith humans. CoRR , abs/2305.04790, 2023.\\n[290] Alayrac, J., J. Donahue, P. Luc, et a', 'The Rise and Potential of Large Language Model.pdf'), 544: ('onal Conference on Machine Learning, ICML 2023, 23-29\\nJuly 2023, Honolulu, Hawaii, USA , vol. 202 of Proceedings of Machine Learning Research ,\\npages 19730–19742. PMLR, 2023.\\n[288] Dai, W., J. Li, D. Li, et al. Instructblip: Towards general-purpose vision-language models with\\ninstruction tuning. CoRR , abs/2305.06500, 2023.\\n64\\n[289] Gong, T., C. Lyu, S. Zhang, et al. Multimodal-gpt: A vision and language model for dialogue\\nwith humans. CoRR , abs/2305.04790, 2023.\\n[290] Alayrac, J., J. Donahue, P. Luc, et al. Flamingo: a visual language model for few-shot learning.\\nInNeurIPS . 2022.\\n[291] Su, Y ., T. Lan, H. Li, et al. Pandagpt: One model to instruction-follow them all. CoRR ,\\nabs/2305.16355, 2023.\\n[292] Liu, H., C. Li, Q. Wu, et al. Visual instruction tuning. CoRR , abs/2304.08485, 2023.\\n[293] Huang, R., M. Li, D. Yang, et al. Audiogpt: Understanding and generating speech, music,\\nsound, and talking head. CoRR , abs/2304.12995, 2023.\\n[294] Gong, Y ., Y . Chung, J. R. Glass. AST: audio spectrogram transformer. In H. Hermansky,\\nH. Cernocký, L. Burget, L. Lamel, O. Scharenborg, P. Motlícek, eds., Interspeech 2021, 22nd\\nAnnual Conference of the International Speech Communication Association, Brno, Czechia,\\n30 August - 3 September 2021 , pages 571–575. ISCA, 2021.\\n[295] Hsu, W., B. Bolte, Y . H. Tsai, et al. Hubert: Self-supervised speech representation learning\\nby masked prediction of hidden units. IEEE ACM Trans. Audio Speech Lang. Process. ,\\n29:3451–3460, 2021.\\n[296] Chen, F., M. Han, H. Zhao, et al. X-LLM: bootstrapping advanced large language models by\\ntreating multi-modalities as foreign languages. CoRR , abs/2305.04160, 2023.\\n[297] Zhang, H., X. Li, L. Bing. Video-llama: An instruction-tuned audio-visual language model for\\nvideo understanding. CoRR , abs/2306.02858, 2023.\\n[298] Liu, Z., Y . He, W. Wang, et al. Interngpt: Solving vision-centric tasks by interacting with\\nchatbots beyond language. CoRR , abs/2305.05662, 2023.\\n[299] Hubel, D. H., T. N. Wiesel. Receptive fields, binocular interaction and functional ', 'The Rise and Potential of Large Language Model.pdf'), 545: ('trapping advanced large language models by\\ntreating multi-modalities as foreign languages. CoRR , abs/2305.04160, 2023.\\n[297] Zhang, H., X. Li, L. Bing. Video-llama: An instruction-tuned audio-visual language model for\\nvideo understanding. CoRR , abs/2306.02858, 2023.\\n[298] Liu, Z., Y . He, W. Wang, et al. Interngpt: Solving vision-centric tasks by interacting with\\nchatbots beyond language. CoRR , abs/2305.05662, 2023.\\n[299] Hubel, D. H., T. N. Wiesel. Receptive fields, binocular interaction and functional architecture\\nin the cat’s visual cortex. The Journal of physiology , 160(1):106, 1962.\\n[300] Logothetis, N. K., D. L. Sheinberg. Visual object recognition. Annual review of neuroscience ,\\n19(1):577–621, 1996.\\n[301] OpenAI. Openai: Introducing chatgpt. Website, 2022. https://openai.com/blog/\\nchatgpt .\\n[302] Lu, J., X. Ren, Y . Ren, et al. Improving contextual language models for response retrieval in\\nmulti-turn conversation. In J. X. Huang, Y . Chang, X. Cheng, J. Kamps, V . Murdock, J. Wen,\\nY . Liu, eds., Proceedings of the 43rd International ACM SIGIR conference on research and\\ndevelopment in Information Retrieval, SIGIR 2020, Virtual Event, China, July 25-30, 2020 ,\\npages 1805–1808. ACM, 2020.\\n[303] Huang, L., W. Wang, J. Chen, et al. Attention on attention for image captioning. In 2019\\nIEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul, Korea (South),\\nOctober 27 - November 2, 2019 , pages 4633–4642. IEEE, 2019.\\n[304] Pan, Y ., T. Yao, Y . Li, et al. X-linear attention networks for image captioning. In 2020\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA,\\nUSA, June 13-19, 2020 , pages 10968–10977. Computer Vision Foundation / IEEE, 2020.\\n[305] Cornia, M., M. Stefanini, L. Baraldi, et al. M2: Meshed-memory transformer for image\\ncaptioning. CoRR , abs/1912.08226, 2019.\\n[306] Chen, J., H. Guo, K. Yi, et al. Visualgpt: Data-efficient image captioning by balancing visual\\ninput and linguistic knowledge from pretraining. CoRR , abs/2102.10407, 2021.\\n[307] Li', 'The Rise and Potential of Large Language Model.pdf'), 546: (' captioning. In 2020\\nIEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA,\\nUSA, June 13-19, 2020 , pages 10968–10977. Computer Vision Foundation / IEEE, 2020.\\n[305] Cornia, M., M. Stefanini, L. Baraldi, et al. M2: Meshed-memory transformer for image\\ncaptioning. CoRR , abs/1912.08226, 2019.\\n[306] Chen, J., H. Guo, K. Yi, et al. Visualgpt: Data-efficient image captioning by balancing visual\\ninput and linguistic knowledge from pretraining. CoRR , abs/2102.10407, 2021.\\n[307] Li, K., Y . He, Y . Wang, et al. Videochat: Chat-centric video understanding. CoRR ,\\nabs/2305.06355, 2023.\\n65\\n[308] Lin, J., Y . Du, O. Watkins, et al. Learning to model the world with language. CoRR ,\\nabs/2308.01399, 2023.\\n[309] Vaswani, A., N. Shazeer, N. Parmar, et al. Attention is all you need. In I. Guyon, U. von\\nLuxburg, S. Bengio, H. M. Wallach, R. Fergus, S. V . N. Vishwanathan, R. Garnett, eds.,\\nAdvances in Neural Information Processing Systems 30: Annual Conference on Neural In-\\nformation Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA , pages\\n5998–6008. 2017.\\n[310] Touvron, H., M. Cord, M. Douze, et al. Training data-efficient image transformers & distil-\\nlation through attention. In M. Meila, T. Zhang, eds., Proceedings of the 38th International\\nConference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , vol. 139 of\\nProceedings of Machine Learning Research , pages 10347–10357. PMLR, 2021.\\n[311] Lu, J., C. Clark, R. Zellers, et al. UNIFIED-IO: A unified model for vision, language, and\\nmulti-modal tasks. In The Eleventh International Conference on Learning Representations,\\nICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[312] Peng, Z., W. Wang, L. Dong, et al. Kosmos-2: Grounding multimodal large language models\\nto the world. CoRR , abs/2306.14824, 2023.\\n[313] Lyu, C., M. Wu, L. Wang, et al. Macaw-llm: Multi-modal language modeling with image,\\naudio, video, and text integration. CoRR , abs/2306.09093, 2023.\\n[314] Maaz, M., H. A. Rasheed, S. H. Khan, et a', 'The Rise and Potential of Large Language Model.pdf'), 547: ('on, language, and\\nmulti-modal tasks. In The Eleventh International Conference on Learning Representations,\\nICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[312] Peng, Z., W. Wang, L. Dong, et al. Kosmos-2: Grounding multimodal large language models\\nto the world. CoRR , abs/2306.14824, 2023.\\n[313] Lyu, C., M. Wu, L. Wang, et al. Macaw-llm: Multi-modal language modeling with image,\\naudio, video, and text integration. CoRR , abs/2306.09093, 2023.\\n[314] Maaz, M., H. A. Rasheed, S. H. Khan, et al. Video-chatgpt: Towards detailed video under-\\nstanding via large vision and language models. CoRR , abs/2306.05424, 2023.\\n[315] Chen, M., I. Laina, A. Vedaldi. Training-free layout control with cross-attention guidance.\\nCoRR , abs/2304.03373, 2023.\\n[316] Radford, A., J. W. Kim, T. Xu, et al. Robust speech recognition via large-scale weak su-\\npervision. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds.,\\nInternational Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu,\\nHawaii, USA , vol. 202 of Proceedings of Machine Learning Research , pages 28492–28518.\\nPMLR, 2023.\\n[317] Ren, Y ., Y . Ruan, X. Tan, et al. Fastspeech: Fast, robust and controllable text to speech.\\nIn H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. B. Fox, R. Garnett,\\neds., Advances in Neural Information Processing Systems 32: Annual Conference on Neural\\nInformation Processing Systems 2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC,\\nCanada , pages 3165–3174. 2019.\\n[318] Ye, Z., Z. Zhao, Y . Ren, et al. Syntaspeech: Syntax-aware generative adversarial text-to-speech.\\nIn L. D. Raedt, ed., Proceedings of the Thirty-First International Joint Conference on Artificial\\nIntelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022 , pages 4468–4474. ijcai.org, 2022.\\n[319] Kim, J., J. Kong, J. Son. Conditional variational autoencoder with adversarial learning for\\nend-to-end text-to-speech. In M. Meila, T. Zhang, eds., Proceedings of the 38th International\\nConference on Machine Learning,', 'The Rise and Potential of Large Language Model.pdf'), 548: (', Z., Z. Zhao, Y . Ren, et al. Syntaspeech: Syntax-aware generative adversarial text-to-speech.\\nIn L. D. Raedt, ed., Proceedings of the Thirty-First International Joint Conference on Artificial\\nIntelligence, IJCAI 2022, Vienna, Austria, 23-29 July 2022 , pages 4468–4474. ijcai.org, 2022.\\n[319] Kim, J., J. Kong, J. Son. Conditional variational autoencoder with adversarial learning for\\nend-to-end text-to-speech. In M. Meila, T. Zhang, eds., Proceedings of the 38th International\\nConference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , vol. 139 of\\nProceedings of Machine Learning Research , pages 5530–5540. PMLR, 2021.\\n[320] Wang, Z., S. Cornell, S. Choi, et al. Tf-gridnet: Integrating full- and sub-band modeling for\\nspeech separation. IEEE ACM Trans. Audio Speech Lang. Process. , 31:3221–3236, 2023.\\n[321] Liu, J., C. Li, Y . Ren, et al. Diffsinger: Singing voice synthesis via shallow diffusion\\nmechanism. In Thirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-\\nFourth Conference on Innovative Applications of Artificial Intelligence, IAAI 2022, The\\nTwelveth Symposium on Educational Advances in Artificial Intelligence, EAAI 2022 Virtual\\nEvent, February 22 - March 1, 2022 , pages 11020–11028. AAAI Press, 2022.\\n[322] Inaguma, H., S. Dalmia, B. Yan, et al. Fast-md: Fast multi-decoder end-to-end speech transla-\\ntion with non-autoregressive hidden intermediates. In IEEE Automatic Speech Recognition\\nand Understanding Workshop, ASRU 2021, Cartagena, Colombia, December 13-17, 2021 ,\\npages 922–929. IEEE, 2021.\\n66\\n[323] Flanagan, J. L. Speech analysis synthesis and perception , vol. 3. Springer Science & Business\\nMedia, 2013.\\n[324] Schwarz, B. Mapping the world in 3d. Nature Photonics , 4(7):429–430, 2010.\\n[325] Parkinson, B. W., J. J. Spilker. Progress in astronautics and aeronautics: Global positioning\\nsystem: Theory and applications , vol. 164. Aiaa, 1996.\\n[326] Parisi, A., Y . Zhao, N. Fiedel. TALM: tool augmented language models. CoRR ,\\nabs/2205.12255, 2022.\\n[327] Clarebout, G., J. El', 'The Rise and Potential of Large Language Model.pdf'), 549: ('ges 922–929. IEEE, 2021.\\n66\\n[323] Flanagan, J. L. Speech analysis synthesis and perception , vol. 3. Springer Science & Business\\nMedia, 2013.\\n[324] Schwarz, B. Mapping the world in 3d. Nature Photonics , 4(7):429–430, 2010.\\n[325] Parkinson, B. W., J. J. Spilker. Progress in astronautics and aeronautics: Global positioning\\nsystem: Theory and applications , vol. 164. Aiaa, 1996.\\n[326] Parisi, A., Y . Zhao, N. Fiedel. TALM: tool augmented language models. CoRR ,\\nabs/2205.12255, 2022.\\n[327] Clarebout, G., J. Elen, N. A. J. Collazo, et al. Metacognition and the Use of Tools , pages\\n187–195. Springer New York, New York, NY , 2013.\\n[328] Wu, C., S. Yin, W. Qi, et al. Visual chatgpt: Talking, drawing and editing with visual foundation\\nmodels. CoRR , abs/2303.04671, 2023.\\n[329] Cai, T., X. Wang, T. Ma, et al. Large language models as tool makers. CoRR , abs/2305.17126,\\n2023.\\n[330] Qian, C., C. Han, Y . R. Fung, et al. CREATOR: disentangling abstract and concrete reasonings\\nof large language models through tool creation. CoRR , abs/2305.14318, 2023.\\n[331] Chen, X., M. Lin, N. Schärli, et al. Teaching large language models to self-debug. CoRR ,\\nabs/2304.05128, 2023.\\n[332] Liu, H., L. Lee, K. Lee, et al. Instruction-following agents with jointly pre-trained vision-\\nlanguage models. arXiv preprint arXiv:2210.13431 , 2022.\\n[333] Lynch, C., A. Wahid, J. Tompson, et al. Interactive language: Talking to robots in real time.\\nCoRR , abs/2210.06407, 2022.\\n[334] Jin, C., W. Tan, J. Yang, et al. Alphablock: Embodied finetuning for vision-language reasoning\\nin robot manipulation. CoRR , abs/2305.18898, 2023.\\n[335] Shah, D., B. Osinski, B. Ichter, et al. Lm-nav: Robotic navigation with large pre-trained\\nmodels of language, vision, and action. In K. Liu, D. Kulic, J. Ichnowski, eds., Conference\\non Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand , vol. 205 of\\nProceedings of Machine Learning Research , pages 492–504. PMLR, 2022.\\n[336] Zhou, G., Y . Hong, Q. Wu. Navgpt: Explicit reasoning in vision-and-language navigat', 'The Rise and Potential of Large Language Model.pdf'), 550: ('ision-language reasoning\\nin robot manipulation. CoRR , abs/2305.18898, 2023.\\n[335] Shah, D., B. Osinski, B. Ichter, et al. Lm-nav: Robotic navigation with large pre-trained\\nmodels of language, vision, and action. In K. Liu, D. Kulic, J. Ichnowski, eds., Conference\\non Robot Learning, CoRL 2022, 14-18 December 2022, Auckland, New Zealand , vol. 205 of\\nProceedings of Machine Learning Research , pages 492–504. PMLR, 2022.\\n[336] Zhou, G., Y . Hong, Q. Wu. Navgpt: Explicit reasoning in vision-and-language navigation with\\nlarge language models. CoRR , abs/2305.16986, 2023.\\n[337] Fan, L., G. Wang, Y . Jiang, et al. Minedojo: Building open-ended embodied agents with\\ninternet-scale knowledge. In NeurIPS . 2022.\\n[338] Kanitscheider, I., J. Huizinga, D. Farhi, et al. Multi-task curriculum learning in a complex,\\nvisual, hard-exploration domain: Minecraft. CoRR , abs/2106.14876, 2021.\\n[339] Nottingham, K., P. Ammanabrolu, A. Suhr, et al. Do embodied agents dream of pixelated\\nsheep: Embodied decision making using language guided world modelling. In A. Krause,\\nE. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds., International Conference\\non Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , vol. 202 of\\nProceedings of Machine Learning Research , pages 26311–26325. PMLR, 2023.\\n[340] Sumers, T., K. Marino, A. Ahuja, et al. Distilling internet-scale vision-language models into\\nembodied agents. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett,\\neds., International Conference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu,\\nHawaii, USA , vol. 202 of Proceedings of Machine Learning Research , pages 32797–32818.\\nPMLR, 2023.\\n[341] Carlini, N., J. Hayes, M. Nasr, et al. Extracting training data from diffusion models. CoRR ,\\nabs/2301.13188, 2023.\\n67\\n[342] Savelka, J., K. D. Ashley, M. A. Gray, et al. Can GPT-4 support analysis of textual data in\\ntasks requiring highly specialized domain expertise? In F. Lagioia, J. Mumford, D. Odekerken,\\nH. Westermann, eds., Proceedings of t', 'The Rise and Potential of Large Language Model.pdf'), 551: ('n Machine Learning, ICML 2023, 23-29 July 2023, Honolulu,\\nHawaii, USA , vol. 202 of Proceedings of Machine Learning Research , pages 32797–32818.\\nPMLR, 2023.\\n[341] Carlini, N., J. Hayes, M. Nasr, et al. Extracting training data from diffusion models. CoRR ,\\nabs/2301.13188, 2023.\\n67\\n[342] Savelka, J., K. D. Ashley, M. A. Gray, et al. Can GPT-4 support analysis of textual data in\\ntasks requiring highly specialized domain expertise? In F. Lagioia, J. Mumford, D. Odekerken,\\nH. Westermann, eds., Proceedings of the 6th Workshop on Automated Semantic Analysis of\\nInformation in Legal Text co-located with the 19th International Conference on Artificial\\nIntelligence and Law (ICAIL 2023), Braga, Portugal, 23rd September, 2023 , vol. 3441 of\\nCEUR Workshop Proceedings , pages 1–12. CEUR-WS.org, 2023.\\n[343] Ling, C., X. Zhao, J. Lu, et al. Domain specialization as the key to make large language models\\ndisruptive: A comprehensive survey, 2023.\\n[344] Linardatos, P., V . Papastefanopoulos, S. Kotsiantis. Explainable AI: A review of machine\\nlearning interpretability methods. Entropy , 23(1):18, 2021.\\n[345] Zou, A., Z. Wang, J. Z. Kolter, et al. Universal and transferable adversarial attacks on aligned\\nlanguage models. CoRR , abs/2307.15043, 2023.\\n[346] Hussein, A., M. M. Gaber, E. Elyan, et al. Imitation learning: A survey of learning methods.\\nACM Comput. Surv. , 50(2):21:1–21:35, 2017.\\n[347] Liu, Y ., A. Gupta, P. Abbeel, et al. Imitation from observation: Learning to imitate behaviors\\nfrom raw video via context translation. In 2018 IEEE International Conference on Robotics\\nand Automation, ICRA 2018, Brisbane, Australia, May 21-25, 2018 , pages 1118–1125. IEEE,\\n2018.\\n[348] Baker, B., I. Akkaya, P. Zhokov, et al. Video pretraining (VPT): learning to act by watching\\nunlabeled online videos. In NeurIPS . 2022.\\n[349] Levine, S., P. Pastor, A. Krizhevsky, et al. Learning hand-eye coordination for robotic grasping\\nwith deep learning and large-scale data collection. Int. J. Robotics Res. , 37(4-5):421–436,\\n2018.\\n[350] Zheng, R., S. Dou,', 'The Rise and Potential of Large Language Model.pdf'), 552: (' 2018 IEEE International Conference on Robotics\\nand Automation, ICRA 2018, Brisbane, Australia, May 21-25, 2018 , pages 1118–1125. IEEE,\\n2018.\\n[348] Baker, B., I. Akkaya, P. Zhokov, et al. Video pretraining (VPT): learning to act by watching\\nunlabeled online videos. In NeurIPS . 2022.\\n[349] Levine, S., P. Pastor, A. Krizhevsky, et al. Learning hand-eye coordination for robotic grasping\\nwith deep learning and large-scale data collection. Int. J. Robotics Res. , 37(4-5):421–436,\\n2018.\\n[350] Zheng, R., S. Dou, S. Gao, et al. Secrets of RLHF in large language models part I: PPO. CoRR ,\\nabs/2307.04964, 2023.\\n[351] Bengio, Y ., J. Louradour, R. Collobert, et al. Curriculum learning. In Proceedings of the 26th\\nAnnual International Conference on Machine Learning , ICML ’09, page 41–48. Association\\nfor Computing Machinery, New York, NY , USA, 2009.\\n[352] Chen, M., J. Tworek, H. Jun, et al. Evaluating large language models trained on code, 2021.\\n[353] Pan, S., L. Luo, Y . Wang, et al. Unifying large language models and knowledge graphs: A\\nroadmap. CoRR , abs/2306.08302, 2023.\\n[354] Bran, A. M., S. Cox, A. D. White, et al. Chemcrow: Augmenting large-language models with\\nchemistry tools, 2023.\\n[355] Ruan, J., Y . Chen, B. Zhang, et al. TPTU: task planning and tool usage of large language\\nmodel-based AI agents. CoRR , abs/2308.03427, 2023.\\n[356] Ogundare, O., S. Madasu, N. Wiggins. Industrial engineering with large language models: A\\ncase study of chatgpt’s performance on oil & gas problems, 2023.\\n[357] Smith, L., M. Gasser. The development of embodied cognition: Six lessons from babies.\\nArtificial life , 11(1-2):13–29, 2005.\\n[358] Duan, J., S. Yu, H. L. Tan, et al. A survey of embodied AI: from simulators to research tasks.\\nIEEE Trans. Emerg. Top. Comput. Intell. , 6(2):230–244, 2022.\\n[359] Mnih, V ., K. Kavukcuoglu, D. Silver, et al. Playing atari with deep reinforcement learning.\\nCoRR , abs/1312.5602, 2013.\\n[360] Silver, D., A. Huang, C. J. Maddison, et al. Mastering the game of go with deep neural\\nnetworks and tree search', 'The Rise and Potential of Large Language Model.pdf'), 553: ('. The development of embodied cognition: Six lessons from babies.\\nArtificial life , 11(1-2):13–29, 2005.\\n[358] Duan, J., S. Yu, H. L. Tan, et al. A survey of embodied AI: from simulators to research tasks.\\nIEEE Trans. Emerg. Top. Comput. Intell. , 6(2):230–244, 2022.\\n[359] Mnih, V ., K. Kavukcuoglu, D. Silver, et al. Playing atari with deep reinforcement learning.\\nCoRR , abs/1312.5602, 2013.\\n[360] Silver, D., A. Huang, C. J. Maddison, et al. Mastering the game of go with deep neural\\nnetworks and tree search. Nat., 529(7587):484–489, 2016.\\n68\\n[361] Kalashnikov, D., A. Irpan, P. Pastor, et al. Qt-opt: Scalable deep reinforcement learning for\\nvision-based robotic manipulation. CoRR , abs/1806.10293, 2018.\\n[362] Nguyen, H., H. M. La. Review of deep reinforcement learning for robot manipulation. In\\n3rd IEEE International Conference on Robotic Computing, IRC 2019, Naples, Italy, February\\n25-27, 2019 , pages 590–595. IEEE, 2019.\\n[363] Dasgupta, I., C. Kaeser-Chen, K. Marino, et al. Collaborating with language models for\\nembodied reasoning. CoRR , abs/2302.00763, 2023.\\n[364] Puig, X., K. Ra, M. Boben, et al. Virtualhome: Simulating household activities via programs.\\nIn2018 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2018, Salt\\nLake City, UT, USA, June 18-22, 2018 , pages 8494–8502. Computer Vision Foundation / IEEE\\nComputer Society, 2018.\\n[365] Hong, Y ., Q. Wu, Y . Qi, et al. A recurrent vision-and-language BERT for navigation. CoRR ,\\nabs/2011.13922, 2020.\\n[366] Suglia, A., Q. Gao, J. Thomason, et al. Embodied BERT: A transformer model for embodied,\\nlanguage-guided visual task completion. CoRR , abs/2108.04927, 2021.\\n[367] Ganesh, S., N. Vadori, M. Xu, et al. Reinforcement learning for market making in a multi-agent\\ndealer market. CoRR , abs/1911.05892, 2019.\\n[368] Tipaldi, M., R. Iervolino, P. R. Massenio. Reinforcement learning in spacecraft control\\napplications: Advances, prospects, and challenges. Annu. Rev. Control. , 54:1–23, 2022.\\n[369] Savva, M., J. Malik, D. Parikh, et al. Habitat: A platfo', 'The Rise and Potential of Large Language Model.pdf'), 554: (' al. Embodied BERT: A transformer model for embodied,\\nlanguage-guided visual task completion. CoRR , abs/2108.04927, 2021.\\n[367] Ganesh, S., N. Vadori, M. Xu, et al. Reinforcement learning for market making in a multi-agent\\ndealer market. CoRR , abs/1911.05892, 2019.\\n[368] Tipaldi, M., R. Iervolino, P. R. Massenio. Reinforcement learning in spacecraft control\\napplications: Advances, prospects, and challenges. Annu. Rev. Control. , 54:1–23, 2022.\\n[369] Savva, M., J. Malik, D. Parikh, et al. Habitat: A platform for embodied AI research. In 2019\\nIEEE/CVF International Conference on Computer Vision, ICCV 2019, Seoul, Korea (South),\\nOctober 27 - November 2, 2019 , pages 9338–9346. IEEE, 2019.\\n[370] Longpre, S., L. Hou, T. Vu, et al. The flan collection: Designing data and methods for effective\\ninstruction tuning. arXiv preprint arXiv:2301.13688 , 2023.\\n[371] Wang, Y ., Y . Kordi, S. Mishra, et al. Self-instruct: Aligning language model with self generated\\ninstructions. arXiv preprint arXiv:2212.10560 , 2022.\\n[372] Liang, J., W. Huang, F. Xia, et al. Code as policies: Language model programs for embodied\\ncontrol. In IEEE International Conference on Robotics and Automation, ICRA 2023, London,\\nUK, May 29 - June 2, 2023 , pages 9493–9500. IEEE, 2023.\\n[373] Li, C., F. Xia, R. Martín-Martín, et al. HRL4IN: hierarchical reinforcement learning for\\ninteractive navigation with mobile manipulators. In L. P. Kaelbling, D. Kragic, K. Sugiura,\\neds., 3rd Annual Conference on Robot Learning, CoRL 2019, Osaka, Japan, October 30 -\\nNovember 1, 2019, Proceedings , vol. 100 of Proceedings of Machine Learning Research ,\\npages 603–616. PMLR, 2019.\\n[374] Eppe, M., C. Gumbsch, M. Kerzel, et al. Hierarchical principles of embodied reinforcement\\nlearning: A review. CoRR , abs/2012.10147, 2020.\\n[375] Paul, S., A. Roy-Chowdhury, A. Cherian. A VLEN: audio-visual-language embodied navigation\\nin 3d environments. In NeurIPS . 2022.\\n[376] Hu, B., C. Zhao, P. Zhang, et al. Enabling intelligent interactions between an agent and an\\nLLM: A reinforcement l', 'The Rise and Potential of Large Language Model.pdf'), 555: ('vember 1, 2019, Proceedings , vol. 100 of Proceedings of Machine Learning Research ,\\npages 603–616. PMLR, 2019.\\n[374] Eppe, M., C. Gumbsch, M. Kerzel, et al. Hierarchical principles of embodied reinforcement\\nlearning: A review. CoRR , abs/2012.10147, 2020.\\n[375] Paul, S., A. Roy-Chowdhury, A. Cherian. A VLEN: audio-visual-language embodied navigation\\nin 3d environments. In NeurIPS . 2022.\\n[376] Hu, B., C. Zhao, P. Zhang, et al. Enabling intelligent interactions between an agent and an\\nLLM: A reinforcement learning approach. CoRR , abs/2306.03604, 2023.\\n[377] Chen, C., U. Jain, C. Schissler, et al. Soundspaces: Audio-visual navigation in 3d environments.\\nIn A. Vedaldi, H. Bischof, T. Brox, J. Frahm, eds., Computer Vision - ECCV 2020 - 16th\\nEuropean Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part VI , vol. 12351 of\\nLecture Notes in Computer Science , pages 17–36. Springer, 2020.\\n[378] Huang, R., Y . Ren, J. Liu, et al. Generspeech: Towards style transfer for generalizable\\nout-of-domain text-to-speech. In NeurIPS . 2022.\\n69\\n[379] Shah, D., B. Eysenbach, G. Kahn, et al. Ving: Learning open-world navigation with visual\\ngoals. In IEEE International Conference on Robotics and Automation, ICRA 2021, Xi’an,\\nChina, May 30 - June 5, 2021 , pages 13215–13222. IEEE, 2021.\\n[380] Huang, C., O. Mees, A. Zeng, et al. Visual language maps for robot navigation. In IEEE\\nInternational Conference on Robotics and Automation, ICRA 2023, London, UK, May 29 -\\nJune 2, 2023 , pages 10608–10615. IEEE, 2023.\\n[381] Georgakis, G., K. Schmeckpeper, K. Wanchoo, et al. Cross-modal map learning for vision and\\nlanguage navigation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\nCVPR 2022, New Orleans, LA, USA, June 18-24, 2022 , pages 15439–15449. IEEE, 2022.\\n[382] Dorbala, V . S., J. F. M. Jr., D. Manocha. Can an embodied agent find your \"cat-shaped mug\"?\\nllm-based zero-shot object navigation. CoRR , abs/2303.03480, 2023.\\n[383] Li, L. H., P. Zhang, H. Zhang, et al. Grounded language-image pre-training. In IEEE/CVF\\n', 'The Rise and Potential of Large Language Model.pdf'), 556: ('G., K. Schmeckpeper, K. Wanchoo, et al. Cross-modal map learning for vision and\\nlanguage navigation. In IEEE/CVF Conference on Computer Vision and Pattern Recognition,\\nCVPR 2022, New Orleans, LA, USA, June 18-24, 2022 , pages 15439–15449. IEEE, 2022.\\n[382] Dorbala, V . S., J. F. M. Jr., D. Manocha. Can an embodied agent find your \"cat-shaped mug\"?\\nllm-based zero-shot object navigation. CoRR , abs/2303.03480, 2023.\\n[383] Li, L. H., P. Zhang, H. Zhang, et al. Grounded language-image pre-training. In IEEE/CVF\\nConference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA,\\nJune 18-24, 2022 , pages 10955–10965. IEEE, 2022.\\n[384] Gan, C., Y . Zhang, J. Wu, et al. Look, listen, and act: Towards audio-visual embodied\\nnavigation. In 2020 IEEE International Conference on Robotics and Automation, ICRA 2020,\\nParis, France, May 31 - August 31, 2020 , pages 9701–9707. IEEE, 2020.\\n[385] Brohan, A., N. Brown, J. Carbajal, et al. RT-1: robotics transformer for real-world control at\\nscale. CoRR , abs/2212.06817, 2022.\\n[386] —. RT-2: vision-language-action models transfer web knowledge to robotic control. CoRR ,\\nabs/2307.15818, 2023.\\n[387] PrismarineJS, 2013.\\n[388] Gur, I., H. Furuta, A. Huang, et al. A real-world webagent with planning, long context\\nunderstanding, and program synthesis. CoRR , abs/2307.12856, 2023.\\n[389] Deng, X., Y . Gu, B. Zheng, et al. Mind2web: Towards a generalist agent for the web. CoRR ,\\nabs/2306.06070, 2023.\\n[390] Furuta, H., O. Nachum, K. Lee, et al. Multimodal web navigation with instruction-finetuned\\nfoundation models. CoRR , abs/2305.11854, 2023.\\n[391] Zhou, S., F. F. Xu, H. Zhu, et al. Webarena: A realistic web environment for building\\nautonomous agents. CoRR , abs/2307.13854, 2023.\\n[392] Yao, S., H. Chen, J. Yang, et al. Webshop: Towards scalable real-world web interaction with\\ngrounded language agents. In NeurIPS . 2022.\\n[393] Kim, G., P. Baldi, S. McAleer. Language models can solve computer tasks. CoRR ,\\nabs/2303.17491, 2023.\\n[394] Zheng, L., R. Wang, B. An. Synapse: Leverag', 'The Rise and Potential of Large Language Model.pdf'), 557: ('h instruction-finetuned\\nfoundation models. CoRR , abs/2305.11854, 2023.\\n[391] Zhou, S., F. F. Xu, H. Zhu, et al. Webarena: A realistic web environment for building\\nautonomous agents. CoRR , abs/2307.13854, 2023.\\n[392] Yao, S., H. Chen, J. Yang, et al. Webshop: Towards scalable real-world web interaction with\\ngrounded language agents. In NeurIPS . 2022.\\n[393] Kim, G., P. Baldi, S. McAleer. Language models can solve computer tasks. CoRR ,\\nabs/2303.17491, 2023.\\n[394] Zheng, L., R. Wang, B. An. Synapse: Leveraging few-shot exemplars for human-level\\ncomputer control. CoRR , abs/2306.07863, 2023.\\n[395] Chen, P., C. Chang. Interact: Exploring the potentials of chatgpt as a cooperative agent. CoRR ,\\nabs/2308.01552, 2023.\\n[396] Gramopadhye, M., D. Szafir. Generating executable action plans with environmentally-aware\\nlanguage models. CoRR , abs/2210.04964, 2022.\\n[397] Li, H., Y . Hao, Y . Zhai, et al. The hitchhiker’s guide to program analysis: A journey with large\\nlanguage models. CoRR , abs/2308.00245, 2023.\\n[398] Feldt, R., S. Kang, J. Yoon, et al. Towards autonomous testing agents via conversational large\\nlanguage models. CoRR , abs/2306.05152, 2023.\\n70\\n[399] Kang, Y ., J. Kim. Chatmof: An autonomous AI system for predicting and generating metal-\\norganic frameworks. CoRR , abs/2308.01423, 2023.\\n[400] Wang, R., P. A. Jansen, M. Côté, et al. Scienceworld: Is your agent smarter than a 5th grader?\\nIn Y . Goldberg, Z. Kozareva, Y . Zhang, eds., Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates,\\nDecember 7-11, 2022 , pages 11279–11298. Association for Computational Linguistics, 2022.\\n[401] Yuan, H., C. Zhang, H. Wang, et al. Plan4mc: Skill reinforcement learning and planning for\\nopen-world minecraft tasks. CoRR , abs/2303.16563, 2023.\\n[402] Hao, R., L. Hu, W. Qi, et al. Chatllm network: More brains, more intelligence. CoRR ,\\nabs/2304.12998, 2023.\\n[403] Mandi, Z., S. Jain, S. Song. Roco: Dialectic multi-robot collaboration with large language\\nmo', 'The Rise and Potential of Large Language Model.pdf'), 558: ('ocessing, EMNLP 2022, Abu Dhabi, United Arab Emirates,\\nDecember 7-11, 2022 , pages 11279–11298. Association for Computational Linguistics, 2022.\\n[401] Yuan, H., C. Zhang, H. Wang, et al. Plan4mc: Skill reinforcement learning and planning for\\nopen-world minecraft tasks. CoRR , abs/2303.16563, 2023.\\n[402] Hao, R., L. Hu, W. Qi, et al. Chatllm network: More brains, more intelligence. CoRR ,\\nabs/2304.12998, 2023.\\n[403] Mandi, Z., S. Jain, S. Song. Roco: Dialectic multi-robot collaboration with large language\\nmodels. CoRR , abs/2307.04738, 2023.\\n[404] Hamilton, S. Blind judgement: Agent-based supreme court modelling with GPT. CoRR ,\\nabs/2301.05327, 2023.\\n[405] Hong, S., X. Zheng, J. Chen, et al. Metagpt: Meta programming for multi-agent collaborative\\nframework. CoRR , abs/2308.00352, 2023.\\n[406] Wu, Q., G. Bansal, J. Zhang, et al. Autogen: Enabling next-gen LLM applications via\\nmulti-agent conversation framework. CoRR , abs/2308.08155, 2023.\\n[407] Zhang, C., K. Yang, S. Hu, et al. Proagent: Building proactive cooperative AI with large\\nlanguage models. CoRR , abs/2308.11339, 2023.\\n[408] Nair, V ., E. Schumacher, G. J. Tso, et al. DERA: enhancing large language model completions\\nwith dialog-enabled resolving agents. CoRR , abs/2303.17071, 2023.\\n[409] Talebirad, Y ., A. Nadiri. Multi-agent collaboration: Harnessing the power of intelligent LLM\\nagents. CoRR , abs/2306.03314, 2023.\\n[410] Chen, W., Y . Su, J. Zuo, et al. Agentverse: Facilitating multi-agent collaboration and exploring\\nemergent behaviors in agents. CoRR , abs/2308.10848, 2023.\\n[411] Shi, J., J. Zhao, Y . Wang, et al. CGMI: configurable general multi-agent interaction framework.\\nCoRR , abs/2308.12503, 2023.\\n[412] Xiong, K., X. Ding, Y . Cao, et al. Examining the inter-consistency of large language models:\\nAn in-depth analysis via debate. CoRR , abs/2305.11595, 2023.\\n[413] Kalvakurthi, V ., A. S. Varde, J. Jenq. Hey dona! can you help me with student course\\nregistration? CoRR , abs/2303.13548, 2023.\\n[414] Swan, M., T. Kido, E. Roland, et al. Math agents: Compu', 'The Rise and Potential of Large Language Model.pdf'), 559: ('abs/2308.10848, 2023.\\n[411] Shi, J., J. Zhao, Y . Wang, et al. CGMI: configurable general multi-agent interaction framework.\\nCoRR , abs/2308.12503, 2023.\\n[412] Xiong, K., X. Ding, Y . Cao, et al. Examining the inter-consistency of large language models:\\nAn in-depth analysis via debate. CoRR , abs/2305.11595, 2023.\\n[413] Kalvakurthi, V ., A. S. Varde, J. Jenq. Hey dona! can you help me with student course\\nregistration? CoRR , abs/2303.13548, 2023.\\n[414] Swan, M., T. Kido, E. Roland, et al. Math agents: Computational infrastructure, mathematical\\nembedding, and genomics. CoRR , abs/2307.02502, 2023.\\n[415] Hsu, S.-L., R. S. Shah, P. Senthil, et al. Helping the helper: Supporting peer counselors via\\nai-empowered practice and feedback. arXiv preprint arXiv:2305.08982 , 2023.\\n[416] Zhang, H., J. Chen, F. Jiang, et al. Huatuogpt, towards taming language model to be a doctor.\\nCoRR , abs/2305.15075, 2023.\\n[417] Yang, S., H. Zhao, S. Zhu, et al. Zhongjing: Enhancing the chinese medical capabilities of\\nlarge language model through expert feedback and real-world multi-turn dialogue. CoRR ,\\nabs/2308.03549, 2023.\\n[418] Ali, M. R., S. Z. Razavi, R. Langevin, et al. A virtual conversational agent for teens with\\nautism spectrum disorder: Experimental results and design lessons. In S. Marsella, R. Jack,\\nH. H. Vilhjálmsson, P. Sequeira, E. S. Cross, eds., IVA ’20: ACM International Conference on\\nIntelligent Virtual Agents, Virtual Event, Scotland, UK, October 20-22, 2020 , pages 2:1–2:8.\\nACM, 2020.\\n71\\n[419] Gao, W., X. Gao, Y . Tang. Multi-turn dialogue agent as sales’ assistant in telemarketing. In\\nInternational Joint Conference on Neural Networks, IJCNN 2023, Gold Coast, Australia, June\\n18-23, 2023 , pages 1–9. IEEE, 2023.\\n[420] Schick, T., J. A. Yu, Z. Jiang, et al. PEER: A collaborative language model. In The Eleventh\\nInternational Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5,\\n2023 . OpenReview.net, 2023.\\n[421] Lu, B., N. Haduong, C. Lee, et al. DIALGEN: collaborative human-lm generated dialogues\\nfo', 'The Rise and Potential of Large Language Model.pdf'), 560: ('ng. Multi-turn dialogue agent as sales’ assistant in telemarketing. In\\nInternational Joint Conference on Neural Networks, IJCNN 2023, Gold Coast, Australia, June\\n18-23, 2023 , pages 1–9. IEEE, 2023.\\n[420] Schick, T., J. A. Yu, Z. Jiang, et al. PEER: A collaborative language model. In The Eleventh\\nInternational Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5,\\n2023 . OpenReview.net, 2023.\\n[421] Lu, B., N. Haduong, C. Lee, et al. DIALGEN: collaborative human-lm generated dialogues\\nfor improved understanding of human-human conversations. CoRR , abs/2307.07047, 2023.\\n[422] Gao, D., L. Ji, L. Zhou, et al. Assistgpt: A general multi-modal assistant that can plan, execute,\\ninspect, and learn. CoRR , abs/2306.08640, 2023.\\n[423] Hasan, M., C. Özel, S. Potter, et al. SAPIEN: affective virtual agents powered by large\\nlanguage models. CoRR , abs/2308.03022, 2023.\\n[424] Liu-Thompkins, Y ., S. Okazaki, H. Li. Artificial empathy in marketing interactions: Bridging\\nthe human-ai gap in affective and social customer experience. Journal of the Academy of\\nMarketing Science , 50(6):1198–1218, 2022.\\n[425] Bakhtin, A., D. J. Wu, A. Lerer, et al. Mastering the game of no-press diplomacy via human-\\nregularized reinforcement learning and planning. In The Eleventh International Conference\\non Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net,\\n2023.\\n[426] (FAIR) †, M. F. A. R. D. T., A. Bakhtin, N. Brown, et al. Human-level play in the game of\\ndiplomacy by combining language models with strategic reasoning. Science , 378(6624):1067–\\n1074, 2022.\\n[427] Lin, J., N. Tomlin, J. Andreas, et al. Decision-oriented dialogue for human-ai collaboration.\\nCoRR , abs/2305.20076, 2023.\\n[428] Li, C., X. Su, C. Fan, et al. Quantifying the impact of large language models on collective\\nopinion dynamics. CoRR , abs/2308.03313, 2023.\\n[429] Chase, H. LangChain. URL https://github.com/hwchase17/langchain , 2022.\\n[430] Reworked. Agent_GPT. URL https://github.com/reworkd/AgentGPT , 2023.\\n[431] AntonOsika. G', 'The Rise and Potential of Large Language Model.pdf'), 561: ('s with strategic reasoning. Science , 378(6624):1067–\\n1074, 2022.\\n[427] Lin, J., N. Tomlin, J. Andreas, et al. Decision-oriented dialogue for human-ai collaboration.\\nCoRR , abs/2305.20076, 2023.\\n[428] Li, C., X. Su, C. Fan, et al. Quantifying the impact of large language models on collective\\nopinion dynamics. CoRR , abs/2308.03313, 2023.\\n[429] Chase, H. LangChain. URL https://github.com/hwchase17/langchain , 2022.\\n[430] Reworked. Agent_GPT. URL https://github.com/reworkd/AgentGPT , 2023.\\n[431] AntonOsika. GPT Engineer. URL https://github.com/AntonOsika/gpt-engineer , 2023.\\n[432] Dambekodi, S. N., S. Frazier, P. Ammanabrolu, et al. Playing text-based games with common\\nsense. CoRR , abs/2012.02757, 2020.\\n[433] Singh, I., G. Singh, A. Modi. Pre-trained language models as prior knowledge for playing\\ntext-based games. In P. Faliszewski, V . Mascardi, C. Pelachaud, M. E. Taylor, eds., 21st\\nInternational Conference on Autonomous Agents and Multiagent Systems, AAMAS 2022,\\nAuckland, New Zealand, May 9-13, 2022 , pages 1729–1731. International Foundation for\\nAutonomous Agents and Multiagent Systems (IFAAMAS), 2022.\\n[434] Ammanabrolu, P., J. Urbanek, M. Li, et al. How to motivate your dragon: Teaching goal-driven\\nagents to speak and act in fantasy worlds. In K. Toutanova, A. Rumshisky, L. Zettlemoyer,\\nD. Hakkani-Tür, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, Y . Zhou, eds., Proceedings\\nof the 2021 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021 ,\\npages 807–833. Association for Computational Linguistics, 2021.\\n[435] Xu, N., S. Masling, M. Du, et al. Grounding open-domain instructions to automate web\\nsupport tasks. In K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tür, I. Beltagy,\\nS. Bethard, R. Cotterell, T. Chakraborty, Y . Zhou, eds., Proceedings of the 2021 Conference\\nof the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, NAACL-HLT 2021, O', 'The Rise and Potential of Large Language Model.pdf'), 562: ('gies, NAACL-HLT 2021, Online, June 6-11, 2021 ,\\npages 807–833. Association for Computational Linguistics, 2021.\\n[435] Xu, N., S. Masling, M. Du, et al. Grounding open-domain instructions to automate web\\nsupport tasks. In K. Toutanova, A. Rumshisky, L. Zettlemoyer, D. Hakkani-Tür, I. Beltagy,\\nS. Bethard, R. Cotterell, T. Chakraborty, Y . Zhou, eds., Proceedings of the 2021 Conference\\nof the North American Chapter of the Association for Computational Linguistics: Human\\nLanguage Technologies, NAACL-HLT 2021, Online, June 6-11, 2021 , pages 1022–1032.\\nAssociation for Computational Linguistics, 2021.\\n72\\n[436] Chhikara, P., J. Zhang, F. Ilievski, et al. Knowledge-enhanced agents for interactive text games.\\nCoRR , abs/2305.05091, 2023.\\n[437] Yang, K., A. M. Swope, A. Gu, et al. Leandojo: Theorem proving with retrieval-augmented\\nlanguage models. CoRR , abs/2306.15626, 2023.\\n[438] Lin, Z., H. Akin, R. Rao, et al. Evolutionary-scale prediction of atomic-level protein structure\\nwith a language model. Science , 379(6637):1123–1130, 2023.\\n[439] Irwin, R., S. Dimitriadis, J. He, et al. Chemformer: a pre-trained transformer for computational\\nchemistry. Mach. Learn. Sci. Technol. , 3(1):15022, 2022.\\n[440] Skrynnik, A., Z. V olovikova, M. Côté, et al. Learning to solve voxel building embodied tasks\\nfrom pixels and natural language instructions. CoRR , abs/2211.00688, 2022.\\n[441] Amiranashvili, A., N. Dorka, W. Burgard, et al. Scaling imitation learning in minecraft. CoRR ,\\nabs/2007.02701, 2020.\\n[442] Minsky, M. Society of mind . Simon and Schuster, 1988.\\n[443] Balaji, P. G., D. Srinivasan. An introduction to multi-agent systems. Innovations in multi-agent\\nsystems and applications-1 , pages 1–27, 2010.\\n[444] Finin, T. W., R. Fritzson, D. P. McKay, et al. KQML as an agent communication language. In\\nProceedings of the Third International Conference on Information and Knowledge Manage-\\nment (CIKM’94), Gaithersburg, Maryland, USA, November 29 - December 2, 1994 , pages\\n456–463. ACM, 1994.\\n[445] Yang, Y ., J. Wang. An overview of multi', 'The Rise and Potential of Large Language Model.pdf'), 563: ('. Simon and Schuster, 1988.\\n[443] Balaji, P. G., D. Srinivasan. An introduction to multi-agent systems. Innovations in multi-agent\\nsystems and applications-1 , pages 1–27, 2010.\\n[444] Finin, T. W., R. Fritzson, D. P. McKay, et al. KQML as an agent communication language. In\\nProceedings of the Third International Conference on Information and Knowledge Manage-\\nment (CIKM’94), Gaithersburg, Maryland, USA, November 29 - December 2, 1994 , pages\\n456–463. ACM, 1994.\\n[445] Yang, Y ., J. Wang. An overview of multi-agent reinforcement learning from game theoretical\\nperspective. arXiv preprint arXiv:2011.00583 , 2020.\\n[446] Smith, A. The wealth of nations [1776] , vol. 11937. na, 1937.\\n[447] Wang, Z., S. Mao, W. Wu, et al. Unleashing cognitive synergy in large language models: A\\ntask-solving agent through multi-persona self-collaboration. CoRR , abs/2307.05300, 2023.\\n[448] Hassan, M. M., R. A. Knipper, S. K. K. Santu. Chatgpt as your personal data scientist. CoRR ,\\nabs/2305.13657, 2023.\\n[449] von Neumann, J., O. Morgenstern. Theory of Games and Economic Behavior (60th-\\nAnniversary Edition) . Princeton University Press, 2007.\\n[450] Aziz, H. Multiagent systems: algorithmic, game-theoretic, and logical foundations by y.\\nshoham and k. leyton-brown cambridge university press, 2008. SIGACT News , 41(1):34–37,\\n2010.\\n[451] Campbell, M., A. J. Hoane, F. hsiung Hsu. Deep blue. Artif. Intell. , 134:57–83, 2002.\\n[452] Silver, D., J. Schrittwieser, K. Simonyan, et al. Mastering the game of go without human\\nknowledge. Nat., 550(7676):354–359, 2017.\\n[453] Lewis, M., D. Yarats, Y . N. Dauphin, et al. Deal or no deal? end-to-end learning of negotiation\\ndialogues. In M. Palmer, R. Hwa, S. Riedel, eds., Proceedings of the 2017 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark,\\nSeptember 9-11, 2017 , pages 2443–2453. Association for Computational Linguistics, 2017.\\n[454] Irving, G., P. F. Christiano, D. Amodei. AI safety via debate. CoRR , abs/1805.00899, 2018.\\n[455] Kenton, Z., T. Everitt, L. We', 'The Rise and Potential of Large Language Model.pdf'), 564: (':354–359, 2017.\\n[453] Lewis, M., D. Yarats, Y . N. Dauphin, et al. Deal or no deal? end-to-end learning of negotiation\\ndialogues. In M. Palmer, R. Hwa, S. Riedel, eds., Proceedings of the 2017 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark,\\nSeptember 9-11, 2017 , pages 2443–2453. Association for Computational Linguistics, 2017.\\n[454] Irving, G., P. F. Christiano, D. Amodei. AI safety via debate. CoRR , abs/1805.00899, 2018.\\n[455] Kenton, Z., T. Everitt, L. Weidinger, et al. Alignment of language agents. CoRR ,\\nabs/2103.14659, 2021.\\n[456] Ngo, R. The alignment problem from a deep learning perspective. CoRR , abs/2209.00626,\\n2022.\\n[457] Paul, M., L. Maglaras, M. A. Ferrag, et al. Digitization of healthcare sector: A study on\\nprivacy and security concerns. ICT Express , 2023.\\n73\\n[458] Bassiri, M. A. Interactional feedback and the impact of attitude and motivation on noticing l2\\nform. English Language and Literature Studies , 1(2):61, 2011.\\n[459] Tellex, S., T. Kollar, S. Dickerson, et al. Approaching the symbol grounding problem with\\nprobabilistic graphical models. AI Mag. , 32(4):64–76, 2011.\\n[460] Matuszek, C., E. Herbst, L. Zettlemoyer, et al. Learning to parse natural language commands\\nto a robot control system. In J. P. Desai, G. Dudek, O. Khatib, V . Kumar, eds., Experimental\\nRobotics - The 13th International Symposium on Experimental Robotics, ISER 2012, June\\n18-21, 2012, Québec City, Canada , vol. 88 of Springer Tracts in Advanced Robotics , pages\\n403–415. Springer, 2012.\\n[461] Chaplot, D. S., K. M. Sathyendra, R. K. Pasumarthi, et al. Gated-attention architectures for\\ntask-oriented language grounding. In S. A. McIlraith, K. Q. Weinberger, eds., Proceedings of\\nthe Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative\\nApplications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational\\nAdvances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7,\\n2018 , pages 2819–2826. AAAI ', 'The Rise and Potential of Large Language Model.pdf'), 565: ('pringer, 2012.\\n[461] Chaplot, D. S., K. M. Sathyendra, R. K. Pasumarthi, et al. Gated-attention architectures for\\ntask-oriented language grounding. In S. A. McIlraith, K. Q. Weinberger, eds., Proceedings of\\nthe Thirty-Second AAAI Conference on Artificial Intelligence, (AAAI-18), the 30th innovative\\nApplications of Artificial Intelligence (IAAI-18), and the 8th AAAI Symposium on Educational\\nAdvances in Artificial Intelligence (EAAI-18), New Orleans, Louisiana, USA, February 2-7,\\n2018 , pages 2819–2826. AAAI Press, 2018.\\n[462] Li, J., A. H. Miller, S. Chopra, et al. Dialogue learning with human-in-the-loop. In 5th\\nInternational Conference on Learning Representations, ICLR 2017, Toulon, France, April\\n24-26, 2017, Conference Track Proceedings . OpenReview.net, 2017.\\n[463] Iyer, S., I. Konstas, A. Cheung, et al. Learning a neural semantic parser from user feedback.\\nIn R. Barzilay, M. Kan, eds., Proceedings of the 55th Annual Meeting of the Association for\\nComputational Linguistics, ACL 2017, Vancouver, Canada, July 30 - August 4, Volume 1: Long\\nPapers , pages 963–973. Association for Computational Linguistics, 2017.\\n[464] Weston, J. Dialog-based language learning. In D. D. Lee, M. Sugiyama, U. von Luxburg,\\nI. Guyon, R. Garnett, eds., Advances in Neural Information Processing Systems 29: Annual\\nConference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona,\\nSpain , pages 829–837. 2016.\\n[465] Shuster, K., J. Xu, M. Komeili, et al. Blenderbot 3: a deployed conversational agent that\\ncontinually learns to responsibly engage. CoRR , abs/2208.03188, 2022.\\n[466] Du, W., Z. M. Kim, V . Raheja, et al. Read, revise, repeat: A system demonstration for\\nhuman-in-the-loop iterative text revision. CoRR , abs/2204.03685, 2022.\\n[467] Kreutzer, J., S. Khadivi, E. Matusov, et al. Can neural machine translation be improved\\nwith user feedback? In S. Bangalore, J. Chu-Carroll, Y . Li, eds., Proceedings of the 2018\\nConference of the North American Chapter of the Association for Computational Linguistics:\\nHuman Langu', 'The Rise and Potential of Large Language Model.pdf'), 566: (' learns to responsibly engage. CoRR , abs/2208.03188, 2022.\\n[466] Du, W., Z. M. Kim, V . Raheja, et al. Read, revise, repeat: A system demonstration for\\nhuman-in-the-loop iterative text revision. CoRR , abs/2204.03685, 2022.\\n[467] Kreutzer, J., S. Khadivi, E. Matusov, et al. Can neural machine translation be improved\\nwith user feedback? In S. Bangalore, J. Chu-Carroll, Y . Li, eds., Proceedings of the 2018\\nConference of the North American Chapter of the Association for Computational Linguistics:\\nHuman Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6,\\n2018, Volume 3 (Industry Papers) , pages 92–105. Association for Computational Linguistics,\\n2018.\\n[468] Gur, I., S. Yavuz, Y . Su, et al. Dialsql: Dialogue based structured query generation. In\\nI. Gurevych, Y . Miyao, eds., Proceedings of the 56th Annual Meeting of the Association for\\nComputational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1:\\nLong Papers , pages 1339–1349. Association for Computational Linguistics, 2018.\\n[469] Yao, Z., Y . Su, H. Sun, et al. Model-based interactive semantic parsing: A unified framework\\nand A text-to-sql case study. In K. Inui, J. Jiang, V . Ng, X. Wan, eds., Proceedings of the 2019\\nConference on Empirical Methods in Natural Language Processing and the 9th International\\nJoint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China,\\nNovember 3-7, 2019 , pages 5446–5457. Association for Computational Linguistics, 2019.\\n[470] Mehta, N., D. Goldwasser. Improving natural language interaction with robots using advice.\\nIn J. Burstein, C. Doran, T. Solorio, eds., Proceedings of the 2019 Conference of the North\\nAmerican Chapter of the Association for Computational Linguistics: Human Language Tech-\\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and\\nShort Papers) , pages 1962–1967. Association for Computational Linguistics, 2019.\\n74\\n[471] Elgohary, A., C. Meek, M. Richardson, et al. NL-EDIT: correcting semantic parse er-\\nrors through na', 'The Rise and Potential of Large Language Model.pdf'), 567: ('ing natural language interaction with robots using advice.\\nIn J. Burstein, C. Doran, T. Solorio, eds., Proceedings of the 2019 Conference of the North\\nAmerican Chapter of the Association for Computational Linguistics: Human Language Tech-\\nnologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and\\nShort Papers) , pages 1962–1967. Association for Computational Linguistics, 2019.\\n74\\n[471] Elgohary, A., C. Meek, M. Richardson, et al. NL-EDIT: correcting semantic parse er-\\nrors through natural language interaction. In K. Toutanova, A. Rumshisky, L. Zettlemoyer,\\nD. Hakkani-Tür, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty, Y . Zhou, eds., Proceedings\\nof the 2021 Conference of the North American Chapter of the Association for Computational\\nLinguistics: Human Language Technologies, NAACL-HLT 2021, Online, June 6-11, 2021 ,\\npages 5599–5610. Association for Computational Linguistics, 2021.\\n[472] Tandon, N., A. Madaan, P. Clark, et al. Learning to repair: Repairing model output errors\\nafter deployment using a dynamic memory of feedback. In M. Carpuat, M. de Marneffe,\\nI. V . M. Ruíz, eds., Findings of the Association for Computational Linguistics: NAACL 2022,\\nSeattle, WA, United States, July 10-15, 2022 , pages 339–352. Association for Computational\\nLinguistics, 2022.\\n[473] Scheurer, J., J. A. Campos, T. Korbak, et al. Training language models with language feedback\\nat scale. CoRR , abs/2303.16755, 2023.\\n[474] Xu, J., M. Ung, M. Komeili, et al. Learning new skills after deployment: Improving open-\\ndomain internet-driven dialogue with human feedback. In A. Rogers, J. L. Boyd-Graber,\\nN. Okazaki, eds., Proceedings of the 61st Annual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , pages\\n13557–13572. Association for Computational Linguistics, 2023.\\n[475] Cai, Z., B. Chang, W. Han. Human-in-the-loop through chain-of-thought. CoRR ,\\nabs/2306.07932, 2023.\\n[476] Hancock, B., A. Bordes, P. Mazaré, et al. Learning from dialogu', 'The Rise and Potential of Large Language Model.pdf'), 568: (' open-\\ndomain internet-driven dialogue with human feedback. In A. Rogers, J. L. Boyd-Graber,\\nN. Okazaki, eds., Proceedings of the 61st Annual Meeting of the Association for Computational\\nLinguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023 , pages\\n13557–13572. Association for Computational Linguistics, 2023.\\n[475] Cai, Z., B. Chang, W. Han. Human-in-the-loop through chain-of-thought. CoRR ,\\nabs/2306.07932, 2023.\\n[476] Hancock, B., A. Bordes, P. Mazaré, et al. Learning from dialogue after deployment: Feed\\nyourself, chatbot! In A. Korhonen, D. R. Traum, L. Màrquez, eds., Proceedings of the 57th\\nConference of the Association for Computational Linguistics, ACL 2019, Florence, Italy, July\\n28- August 2, 2019, Volume 1: Long Papers , pages 3667–3684. Association for Computational\\nLinguistics, 2019.\\n[477] Mehta, N., M. Teruel, P. F. Sanz, et al. Improving grounded language understanding in a collab-\\norative environment by interacting with agents through help feedback. CoRR , abs/2304.10750,\\n2023.\\n[478] Gvirsman, O., Y . Koren, T. Norman, et al. Patricc: A platform for triadic interaction with\\nchangeable characters. In T. Belpaeme, J. E. Young, H. Gunes, L. D. Riek, eds., HRI\\n’20: ACM/IEEE International Conference on Human-Robot Interaction, Cambridge, United\\nKingdom, March 23-26, 2020 , pages 399–407. ACM, 2020.\\n[479] Stiles-Shields, C., E. Montague, E. G. Lattie, et al. What might get in the way: Barriers to\\nthe use of apps for depression. DIGITAL HEALTH , 3:2055207617713827, 2017. PMID:\\n29942605.\\n[480] McTear, M. F. Conversational AI: Dialogue Systems, Conversational Agents, and Chatbots .\\nSynthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers, 2020.\\n[481] Motger, Q., X. Franch, J. Marco. Conversational agents in software engineering: Survey,\\ntaxonomy and challenges. CoRR , abs/2106.10901, 2021.\\n[482] Rapp, A., L. Curti, A. Boldi. The human side of human-chatbot interaction: A systematic\\nliterature review of ten years of research on text-based chatbots. Int. J. Hum. C', 'The Rise and Potential of Large Language Model.pdf'), 569: ('42605.\\n[480] McTear, M. F. Conversational AI: Dialogue Systems, Conversational Agents, and Chatbots .\\nSynthesis Lectures on Human Language Technologies. Morgan & Claypool Publishers, 2020.\\n[481] Motger, Q., X. Franch, J. Marco. Conversational agents in software engineering: Survey,\\ntaxonomy and challenges. CoRR , abs/2106.10901, 2021.\\n[482] Rapp, A., L. Curti, A. Boldi. The human side of human-chatbot interaction: A systematic\\nliterature review of ten years of research on text-based chatbots. Int. J. Hum. Comput. Stud. ,\\n151:102630, 2021.\\n[483] Adamopoulou, E., L. Moussiades. Chatbots: History, technology, and applications. Machine\\nLearning with Applications , 2:100006, 2020.\\n[484] Wang, K., X. Wan. Sentigan: Generating sentimental texts via mixture adversarial networks.\\nIn J. Lang, ed., Proceedings of the Twenty-Seventh International Joint Conference on Artificial\\nIntelligence, IJCAI 2018, July 13-19, 2018, Stockholm, Sweden , pages 4446–4452. ijcai.org,\\n2018.\\n75\\n[485] Zhou, X., W. Y . Wang. Mojitalk: Generating emotional responses at scale. In I. Gurevych,\\nY . Miyao, eds., Proceedings of the 56th Annual Meeting of the Association for Computational\\nLinguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018, Volume 1: Long Papers , pages\\n1128–1137. Association for Computational Linguistics, 2018.\\n[486] Lin, Z., P. Xu, G. I. Winata, et al. Caire: An empathetic neural chatbot. arXiv preprint\\narXiv:1907.12108 , 2019.\\n[487] Jhan, J., C. Liu, S. Jeng, et al. Cheerbots: Chatbots toward empathy and emotionusing\\nreinforcement learning. CoRR , abs/2110.03949, 2021.\\n[488] Lin, Z., A. Madotto, J. Shin, et al. Moel: Mixture of empathetic listeners. In K. Inui,\\nJ. Jiang, V . Ng, X. Wan, eds., Proceedings of the 2019 Conference on Empirical Methods in\\nNatural Language Processing and the 9th International Joint Conference on Natural Language\\nProcessing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 , pages 121–132.\\nAssociation for Computational Linguistics, 2019.\\n[489] Majumder, N., P. Hong, S. Peng, et al. MIME: m', 'The Rise and Potential of Large Language Model.pdf'), 570: ('nforcement learning. CoRR , abs/2110.03949, 2021.\\n[488] Lin, Z., A. Madotto, J. Shin, et al. Moel: Mixture of empathetic listeners. In K. Inui,\\nJ. Jiang, V . Ng, X. Wan, eds., Proceedings of the 2019 Conference on Empirical Methods in\\nNatural Language Processing and the 9th International Joint Conference on Natural Language\\nProcessing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019 , pages 121–132.\\nAssociation for Computational Linguistics, 2019.\\n[489] Majumder, N., P. Hong, S. Peng, et al. MIME: mimicking emotions for empathetic response\\ngeneration. In B. Webber, T. Cohn, Y . He, Y . Liu, eds., Proceedings of the 2020 Conference on\\nEmpirical Methods in Natural Language Processing, EMNLP 2020, Online, November 16-20,\\n2020 , pages 8968–8979. Association for Computational Linguistics, 2020.\\n[490] Sabour, S., C. Zheng, M. Huang. CEM: commonsense-aware empathetic response generation.\\nInThirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Confer-\\nence on Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium\\non Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event, February 22 -\\nMarch 1, 2022 , pages 11229–11237. AAAI Press, 2022.\\n[491] Li, Q., P. Li, Z. Ren, et al. Knowledge bridging for empathetic dialogue generation. In\\nThirty-Sixth AAAI Conference on Artificial Intelligence, AAAI 2022, Thirty-Fourth Conference\\non Innovative Applications of Artificial Intelligence, IAAI 2022, The Twelveth Symposium\\non Educational Advances in Artificial Intelligence, EAAI 2022 Virtual Event, February 22 -\\nMarch 1, 2022 , pages 10993–11001. AAAI Press, 2022.\\n[492] Liu, B., S. S. Sundar. Should machines express sympathy and empathy? experiments with a\\nhealth advice chatbot. Cyberpsychology Behav. Soc. Netw. , 21(10):625–636, 2018.\\n[493] Su, Z., M. C. Figueiredo, J. Jo, et al. Analyzing description, user understanding and expec-\\ntations of AI in mobile health applications. In AMIA 2020, American Medical Informatics\\nAssociation Annual Symposium, Virt', 'The Rise and Potential of Large Language Model.pdf'), 571: ('rtificial Intelligence, EAAI 2022 Virtual Event, February 22 -\\nMarch 1, 2022 , pages 10993–11001. AAAI Press, 2022.\\n[492] Liu, B., S. S. Sundar. Should machines express sympathy and empathy? experiments with a\\nhealth advice chatbot. Cyberpsychology Behav. Soc. Netw. , 21(10):625–636, 2018.\\n[493] Su, Z., M. C. Figueiredo, J. Jo, et al. Analyzing description, user understanding and expec-\\ntations of AI in mobile health applications. In AMIA 2020, American Medical Informatics\\nAssociation Annual Symposium, Virtual Event, USA, November 14-18, 2020 . AMIA, 2020.\\n[494] Moravcík, M., M. Schmid, N. Burch, et al. Deepstack: Expert-level artificial intelligence in\\nno-limit poker. CoRR , abs/1701.01724, 2017.\\n[495] Carroll, M., R. Shah, M. K. Ho, et al. On the utility of learning about humans for human-\\nai coordination. In H. M. Wallach, H. Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. B.\\nFox, R. Garnett, eds., Advances in Neural Information Processing Systems 32: Annual\\nConference on Neural Information Processing Systems 2019, NeurIPS 2019, December 8-14,\\n2019, Vancouver, BC, Canada , pages 5175–5186. 2019.\\n[496] Bard, N., J. N. Foerster, S. Chandar, et al. The hanabi challenge: A new frontier for ai research.\\nArtificial Intelligence , 280:103216, 2020.\\n[497] Wang, X., W. Shi, R. Kim, et al. Persuasion for good: Towards a personalized persuasive\\ndialogue system for social good. In A. Korhonen, D. R. Traum, L. Màrquez, eds., Proceedings\\nof the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence,\\nItaly, July 28- August 2, 2019, Volume 1: Long Papers , pages 5635–5649. Association for\\nComputational Linguistics, 2019.\\n[498] Abrams, A. M. H., A. M. R. der Pütten. I-C-E framework: Concepts for group dynamics\\nresearch in human-robot interaction. Int. J. Soc. Robotics , 12(6):1213–1229, 2020.\\n[499] Xu, Y ., S. Wang, P. Li, et al. Exploring large language models for communication games: An\\nempirical study on werewolf, 2023.\\n76\\n[500] Binz, M., E. Schulz. Using cognitive psychology to understand GPT-3', 'The Rise and Potential of Large Language Model.pdf'), 572: ('rence,\\nItaly, July 28- August 2, 2019, Volume 1: Long Papers , pages 5635–5649. Association for\\nComputational Linguistics, 2019.\\n[498] Abrams, A. M. H., A. M. R. der Pütten. I-C-E framework: Concepts for group dynamics\\nresearch in human-robot interaction. Int. J. Soc. Robotics , 12(6):1213–1229, 2020.\\n[499] Xu, Y ., S. Wang, P. Li, et al. Exploring large language models for communication games: An\\nempirical study on werewolf, 2023.\\n76\\n[500] Binz, M., E. Schulz. Using cognitive psychology to understand GPT-3. CoRR , abs/2206.14576,\\n2022.\\n[501] Dasgupta, I., A. K. Lampinen, S. C. Y . Chan, et al. Language models show human-like content\\neffects on reasoning. CoRR , abs/2207.07051, 2022.\\n[502] Dhingra, S., M. Singh, V . S. B, et al. Mind meets machine: Unravelling gpt-4’s cognitive\\npsychology. CoRR , abs/2303.11436, 2023.\\n[503] Hagendorff, T. Machine psychology: Investigating emergent capabilities and behavior in large\\nlanguage models using psychological methods. CoRR , abs/2303.13988, 2023.\\n[504] Wang, X., X. Li, Z. Yin, et al. Emotional intelligence of large language models. CoRR ,\\nabs/2307.09042, 2023.\\n[505] Curry, A., A. C. Curry. Computer says \"no\": The case against empathetic conversational AI. In\\nA. Rogers, J. L. Boyd-Graber, N. Okazaki, eds., Findings of the Association for Computational\\nLinguistics: ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 8123–8130. Association for\\nComputational Linguistics, 2023.\\n[506] Elyoseph, Z., D. Hadar-Shoval, K. Asraf, et al. Chatgpt outperforms humans in emotional\\nawareness evaluations. Frontiers in Psychology , 14:1199058, 2023.\\n[507] Habibi, R., J. Pfau, J. Holmes, et al. Empathetic AI for empowering resilience in games. CoRR ,\\nabs/2302.09070, 2023.\\n[508] Caron, G., S. Srivastava. Identifying and manipulating the personality traits of language\\nmodels. CoRR , abs/2212.10276, 2022.\\n[509] Pan, K., Y . Zeng. Do llms possess a personality? making the MBTI test an amazing evaluation\\nfor large language models. CoRR , abs/2307.16180, 2023.\\n[510] Li, X., Y . Li, S. Joty, et al. ', 'The Rise and Potential of Large Language Model.pdf'), 573: ('ness evaluations. Frontiers in Psychology , 14:1199058, 2023.\\n[507] Habibi, R., J. Pfau, J. Holmes, et al. Empathetic AI for empowering resilience in games. CoRR ,\\nabs/2302.09070, 2023.\\n[508] Caron, G., S. Srivastava. Identifying and manipulating the personality traits of language\\nmodels. CoRR , abs/2212.10276, 2022.\\n[509] Pan, K., Y . Zeng. Do llms possess a personality? making the MBTI test an amazing evaluation\\nfor large language models. CoRR , abs/2307.16180, 2023.\\n[510] Li, X., Y . Li, S. Joty, et al. Does gpt-3 demonstrate psychopathy? evaluating large language\\nmodels from a psychological perspective, 2023.\\n[511] Safdari, M., G. Serapio-García, C. Crepy, et al. Personality traits in large language models.\\nCoRR , abs/2307.00184, 2023.\\n[512] Côté, M., Á. Kádár, X. Yuan, et al. Textworld: A learning environment for text-based games.\\nIn T. Cazenave, A. Saffidine, N. R. Sturtevant, eds., Computer Games - 7th Workshop, CGW\\n2018, Held in Conjunction with the 27th International Conference on Artificial Intelligence,\\nIJCAI 2018, Stockholm, Sweden, July 13, 2018, Revised Selected Papers , vol. 1017 of Commu-\\nnications in Computer and Information Science , pages 41–75. Springer, 2018.\\n[513] Urbanek, J., A. Fan, S. Karamcheti, et al. Learning to speak and act in a fantasy text adventure\\ngame. In K. Inui, J. Jiang, V . Ng, X. Wan, eds., Proceedings of the 2019 Conference on\\nEmpirical Methods in Natural Language Processing and the 9th International Joint Conference\\non Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7,\\n2019 , pages 673–683. Association for Computational Linguistics, 2019.\\n[514] Hausknecht, M. J., P. Ammanabrolu, M. Côté, et al. Interactive fiction games: A colossal\\nadventure. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The\\nThirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The\\nTenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New\\nYork, NY, USA, February 7-12, 2020 , pages 790', 'The Rise and Potential of Large Language Model.pdf'), 574: ('g Kong, China, November 3-7,\\n2019 , pages 673–683. Association for Computational Linguistics, 2019.\\n[514] Hausknecht, M. J., P. Ammanabrolu, M. Côté, et al. Interactive fiction games: A colossal\\nadventure. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The\\nThirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The\\nTenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New\\nYork, NY, USA, February 7-12, 2020 , pages 7903–7910. AAAI Press, 2020.\\n[515] O’Gara, A. Hoodwinked: Deception and cooperation in a text-based game for language\\nmodels. CoRR , abs/2308.01404, 2023.\\n[516] Bharadhwaj, H., J. Vakil, M. Sharma, et al. Roboagent: Generalization and efficiency in robot\\nmanipulation via semantic augmentations and action chunking. CoRR , abs/2309.01918, 2023.\\n77\\n[517] Park, J. S., L. Popowski, C. J. Cai, et al. Social simulacra: Creating populated prototypes for\\nsocial computing systems. In M. Agrawala, J. O. Wobbrock, E. Adar, V . Setlur, eds., The 35th\\nAnnual ACM Symposium on User Interface Software and Technology, UIST 2022, Bend, OR,\\nUSA, 29 October 2022 - 2 November 2022 , pages 74:1–74:18. ACM, 2022.\\n[518] Gao, C., X. Lan, Z. Lu, et al. S3: Social-network simulation system with large language\\nmodel-empowered agents. CoRR , abs/2307.14984, 2023.\\n[519] Wang, L., J. Zhang, X. Chen, et al. Recagent: A novel simulation paradigm for recommender\\nsystems. CoRR , abs/2306.02552, 2023.\\n[520] Williams, R., N. Hosseinichimeh, A. Majumdar, et al. Epidemic modeling with generative\\nagents. CoRR , abs/2307.04986, 2023.\\n[521] da Rocha Costa, A. C. A Variational Basis for the Regulation and Structuration Mechanisms\\nof Agent Societies . Springer, 2019.\\n[522] Wimmer, S., A. Pfeiffer, N. Denk. The everyday life in the sims 4 during a pandemic. a life\\nsimulation as a virtual mirror of society? In INTED2021 Proceedings , 15th International\\nTechnology, Education and Development Conference, pages 5754–5760. IATED, 2021.\\n[523] Lee, L., T. Braud, P. Z', 'The Rise and Potential of Large Language Model.pdf'), 575: ('dar, et al. Epidemic modeling with generative\\nagents. CoRR , abs/2307.04986, 2023.\\n[521] da Rocha Costa, A. C. A Variational Basis for the Regulation and Structuration Mechanisms\\nof Agent Societies . Springer, 2019.\\n[522] Wimmer, S., A. Pfeiffer, N. Denk. The everyday life in the sims 4 during a pandemic. a life\\nsimulation as a virtual mirror of society? In INTED2021 Proceedings , 15th International\\nTechnology, Education and Development Conference, pages 5754–5760. IATED, 2021.\\n[523] Lee, L., T. Braud, P. Zhou, et al. All one needs to know about metaverse: A complete survey\\non technological singularity, virtual ecosystem, and research agenda. CoRR , abs/2110.05352,\\n2021.\\n[524] Inkeles, A., D. H. Smith. Becoming modern: Individual change in six developing countries .\\nHarvard University Press, 1974.\\n[525] Troitzsch, K. G., U. Mueller, G. N. Gilbert, et al., eds. Social Science Microsimulation\\n[Dagstuhl Seminar, May, 1995] . Springer, 1996.\\n[526] Abrams, A. M., A. M. R.-v. der Pütten. I–c–e framework: Concepts for group dynamics\\nresearch in human-robot interaction: Revisiting theory from social psychology on ingroup\\nidentification (i), cohesion (c) and entitativity (e). International Journal of Social Robotics ,\\n12:1213–1229, 2020.\\n[527] Askell, A., Y . Bai, A. Chen, et al. A general language assistant as a laboratory for alignment.\\nCoRR , abs/2112.00861, 2021.\\n[528] Zhang, Z., N. Liu, S. Qi, et al. Heterogeneous value evaluation for large language models.\\nCoRR , abs/2305.17147, 2023.\\n[529] Browning, J. Personhood and ai: Why large language models don’t understand us. AI &\\nSOCIETY , pages 1–8, 2023.\\n[530] Jiang, G., M. Xu, S. Zhu, et al. MPI: evaluating and inducing personality in pre-trained\\nlanguage models. CoRR , abs/2206.07550, 2022.\\n[531] Kosinski, M. Theory of mind may have spontaneously emerged in large language models.\\nCoRR , abs/2302.02083, 2023.\\n[532] Zuckerman, M. Psychobiology of personality , vol. 10. Cambridge University Press, 1991.\\n[533] Han, S. J., K. Ransom, A. Perfors, et al. Inductive reasoning i', 'The Rise and Potential of Large Language Model.pdf'), 576: (' and ai: Why large language models don’t understand us. AI &\\nSOCIETY , pages 1–8, 2023.\\n[530] Jiang, G., M. Xu, S. Zhu, et al. MPI: evaluating and inducing personality in pre-trained\\nlanguage models. CoRR , abs/2206.07550, 2022.\\n[531] Kosinski, M. Theory of mind may have spontaneously emerged in large language models.\\nCoRR , abs/2302.02083, 2023.\\n[532] Zuckerman, M. Psychobiology of personality , vol. 10. Cambridge University Press, 1991.\\n[533] Han, S. J., K. Ransom, A. Perfors, et al. Inductive reasoning in humans and large language\\nmodels. CoRR , abs/2306.06548, 2023.\\n[534] Hagendorff, T., S. Fabi, M. Kosinski. Thinking fast and slow in large language models, 2023.\\n[535] Hagendorff, T., S. Fabi. Human-like intuitive behavior and reasoning biases emerged in\\nlanguage models - and disappeared in GPT-4. CoRR , abs/2306.07622, 2023.\\n[536] Ma, Z., Y . Mei, Z. Su. Understanding the benefits and challenges of using large language\\nmodel-based conversational agents for mental well-being support. CoRR , abs/2307.15810,\\n2023.\\n78\\n[537] Bates, J. The role of emotion in believable agents. Commun. ACM , 37(7):122–125, 1994.\\n[538] Karra, S. R., S. Nguyen, T. Tulabandhula. AI personification: Estimating the personality of\\nlanguage models. CoRR , abs/2204.12000, 2022.\\n[539] Zhang, S., E. Dinan, J. Urbanek, et al. Personalizing dialogue agents: I have a dog, do you\\nhave pets too? In I. Gurevych, Y . Miyao, eds., Proceedings of the 56th Annual Meeting of the\\nAssociation for Computational Linguistics, ACL 2018, Melbourne, Australia, July 15-20, 2018,\\nVolume 1: Long Papers , pages 2204–2213. Association for Computational Linguistics, 2018.\\n[540] Kwon, D. S., S. Lee, K. H. Kim, et al. What, when, and how to ground: Designing user\\npersona-aware conversational agents for engaging dialogue. In S. Sitaram, B. B. Klebanov,\\nJ. D. Williams, eds., Proceedings of the The 61st Annual Meeting of the Association for\\nComputational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023 ,\\npages 707–719. Association for Computational', 'The Rise and Potential of Large Language Model.pdf'), 577: ('a, July 15-20, 2018,\\nVolume 1: Long Papers , pages 2204–2213. Association for Computational Linguistics, 2018.\\n[540] Kwon, D. S., S. Lee, K. H. Kim, et al. What, when, and how to ground: Designing user\\npersona-aware conversational agents for engaging dialogue. In S. Sitaram, B. B. Klebanov,\\nJ. D. Williams, eds., Proceedings of the The 61st Annual Meeting of the Association for\\nComputational Linguistics: Industry Track, ACL 2023, Toronto, Canada, July 9-14, 2023 ,\\npages 707–719. Association for Computational Linguistics, 2023.\\n[541] Maes, P. Artificial life meets entertainment: Lifelike autonomous agents. Commun. ACM ,\\n38(11):108–114, 1995.\\n[542] Grossmann, I., M. Feinberg, D. C. Parker, et al. Ai and the transformation of social science\\nresearch. Science , 380(6650):1108–1109, 2023.\\n[543] Wei, J., K. Shuster, A. Szlam, et al. Multi-party chat: Conversational agents in group settings\\nwith humans and models. CoRR , abs/2304.13835, 2023.\\n[544] Hollan, J. D., E. L. Hutchins, L. Weitzman. STEAMER: an interactive inspectable simulation-\\nbased training system. AI Mag. , 5(2):15–27, 1984.\\n[545] Tambe, M., W. L. Johnson, R. M. Jones, et al. Intelligent agents for interactive simulation\\nenvironments. AI Mag. , 16(1):15–39, 1995.\\n[546] Vermeulen, P., D. de Jongh. ‘dynamics of growth in a finite world’ – comprehensive sensitivity\\nanalysis. IFAC Proceedings Volumes , 9(3):133–145, 1976. IFAC Symposium on Large Scale\\nSystems Theory and Applications, Milano, Italy, 16-20 June.\\n[547] Forrester, J. W. System dynamics and the lessons of 35 years. In A systems-based approach to\\npolicymaking , pages 199–240. Springer, 1993.\\n[548] Santé, I., A. M. García, D. Miranda, et al. Cellular automata models for the simulation of real-\\nworld urban processes: A review and analysis. Landscape and urban planning , 96(2):108–122,\\n2010.\\n[549] Dorri, A., S. S. Kanhere, R. Jurdak. Multi-agent systems: A survey. Ieee Access , 6:28573–\\n28593, 2018.\\n[550] Hendrickx, J. M., S. Martin. Open multi-agent systems: Gossiping with random arrivals and\\ndeparture', 'The Rise and Potential of Large Language Model.pdf'), 578: ('ssons of 35 years. In A systems-based approach to\\npolicymaking , pages 199–240. Springer, 1993.\\n[548] Santé, I., A. M. García, D. Miranda, et al. Cellular automata models for the simulation of real-\\nworld urban processes: A review and analysis. Landscape and urban planning , 96(2):108–122,\\n2010.\\n[549] Dorri, A., S. S. Kanhere, R. Jurdak. Multi-agent systems: A survey. Ieee Access , 6:28573–\\n28593, 2018.\\n[550] Hendrickx, J. M., S. Martin. Open multi-agent systems: Gossiping with random arrivals and\\ndepartures. In 56th IEEE Annual Conference on Decision and Control, CDC 2017, Melbourne,\\nAustralia, December 12-15, 2017 , pages 763–768. IEEE, 2017.\\n[551] Ziems, C., W. Held, O. Shaikh, et al. Can large language models transform computational\\nsocial science? CoRR , abs/2305.03514, 2023.\\n[552] Gilbert, N., J. Doran. Simulating Societies: The Computer Simulation of Social Phenomena .\\nRoutledge Library Editions: Artificial Intelligence. Taylor & Francis, 2018.\\n[553] Hamilton, J. D. A new approach to the economic analysis of nonstationary time series and the\\nbusiness cycle. Econometrica: Journal of the econometric society , pages 357–384, 1989.\\n[554] Zhang, G. P. Time series forecasting using a hybrid ARIMA and neural network model.\\nNeurocomputing , 50:159–175, 2003.\\n[555] Kirby, S., M. Dowman, T. L. Griffiths. Innateness and culture in the evolution of language.\\nProceedings of the National Academy of Sciences , 104(12):5241–5245, 2007.\\n79\\n[556] Shibata, H., S. Miki, Y . Nakamura. Playing the werewolf game with artificial intelligence for\\nlanguage understanding. CoRR , abs/2302.10646, 2023.\\n[557] Junprung, E. Exploring the intersection of large language models and agent-based modeling\\nvia prompt engineering. CoRR , abs/2308.07411, 2023.\\n[558] Phelps, S., Y . I. Russell. Investigating emergent goal-like behaviour in large language models\\nusing experimental economics. CoRR , abs/2305.07970, 2023.\\n[559] Bellomo, N., G. A. Marsan, A. Tosin. Complex systems and society: modeling and simulation ,\\nvol. 2. Springer, 2013.\\n[560] Mo', 'The Rise and Potential of Large Language Model.pdf'), 579: ('l intelligence for\\nlanguage understanding. CoRR , abs/2302.10646, 2023.\\n[557] Junprung, E. Exploring the intersection of large language models and agent-based modeling\\nvia prompt engineering. CoRR , abs/2308.07411, 2023.\\n[558] Phelps, S., Y . I. Russell. Investigating emergent goal-like behaviour in large language models\\nusing experimental economics. CoRR , abs/2305.07970, 2023.\\n[559] Bellomo, N., G. A. Marsan, A. Tosin. Complex systems and society: modeling and simulation ,\\nvol. 2. Springer, 2013.\\n[560] Moon, Y . B. Simulation modelling for sustainability: a review of the literature. International\\nJournal of Sustainable Engineering , 10(1):2–19, 2017.\\n[561] Helberger, N., N. Diakopoulos. Chatgpt and the AI act. Internet Policy Rev. , 12(1), 2023.\\n[562] Weidinger, L., J. Mellor, M. Rauh, et al. Ethical and social risks of harm from language models.\\nCoRR , abs/2112.04359, 2021.\\n[563] Deshpande, A., V . Murahari, T. Rajpurohit, et al. Toxicity in chatgpt: Analyzing persona-\\nassigned language models. CoRR , abs/2304.05335, 2023.\\n[564] Kirk, H. R., Y . Jun, F. V olpin, et al. Bias out-of-the-box: An empirical analysis of intersectional\\noccupational biases in popular generative language models. In M. Ranzato, A. Beygelzimer,\\nY . N. Dauphin, P. Liang, J. W. Vaughan, eds., Advances in Neural Information Processing\\nSystems 34: Annual Conference on Neural Information Processing Systems 2021, NeurIPS\\n2021, December 6-14, 2021, virtual , pages 2611–2624. 2021.\\n[565] Nadeem, M., A. Bethke, S. Reddy. Stereoset: Measuring stereotypical bias in pretrained\\nlanguage models. In C. Zong, F. Xia, W. Li, R. Navigli, eds., Proceedings of the 59th Annual\\nMeeting of the Association for Computational Linguistics and the 11th International Joint\\nConference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),\\nVirtual Event, August 1-6, 2021 , pages 5356–5371. Association for Computational Linguistics,\\n2021.\\n[566] Roberts, T., G. Marchais. Assessing the role of social media and digital technology in violence\\nreporting. ', 'The Rise and Potential of Large Language Model.pdf'), 580: ('ereotypical bias in pretrained\\nlanguage models. In C. Zong, F. Xia, W. Li, R. Navigli, eds., Proceedings of the 59th Annual\\nMeeting of the Association for Computational Linguistics and the 11th International Joint\\nConference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),\\nVirtual Event, August 1-6, 2021 , pages 5356–5371. Association for Computational Linguistics,\\n2021.\\n[566] Roberts, T., G. Marchais. Assessing the role of social media and digital technology in violence\\nreporting. Contemporary Readings in Law & Social Justice , 10(2), 2018.\\n[567] Kandpal, N., H. Deng, A. Roberts, et al. Large language models struggle to learn long-\\ntail knowledge. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett,\\neds., Proceedings of the 40th International Conference on Machine Learning , vol. 202 of\\nProceedings of Machine Learning Research , pages 15696–15707. PMLR, 2023.\\n[568] Ferrara, E. Should chatgpt be biased? challenges and risks of bias in large language models.\\nCoRR , abs/2304.03738, 2023.\\n[569] Haller, P., A. Aynetdinov, A. Akbik. Opiniongpt: Modelling explicit biases in instruction-tuned\\nllms, 2023.\\n[570] Salewski, L., S. Alaniz, I. Rio-Torto, et al. In-context impersonation reveals large language\\nmodels’ strengths and biases. CoRR , abs/2305.14930, 2023.\\n[571] Lin, B., D. Bouneffouf, G. A. Cecchi, et al. Towards healthy AI: large language models need\\ntherapists too. CoRR , abs/2304.00416, 2023.\\n[572] Liang, P. P., C. Wu, L. Morency, et al. Towards understanding and mitigating social biases\\nin language models. In M. Meila, T. Zhang, eds., Proceedings of the 38th International\\nConference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , vol. 139 of\\nProceedings of Machine Learning Research , pages 6565–6576. PMLR, 2021.\\n[573] Henderson, P., K. Sinha, N. Angelard-Gontier, et al. Ethical challenges in data-driven dia-\\nlogue systems. In J. Furman, G. E. Marchant, H. Price, F. Rossi, eds., Proceedings of the\\n2018 AAAI/ACM Conference on AI, Ethics, and Society,', 'The Rise and Potential of Large Language Model.pdf'), 581: ('mitigating social biases\\nin language models. In M. Meila, T. Zhang, eds., Proceedings of the 38th International\\nConference on Machine Learning, ICML 2021, 18-24 July 2021, Virtual Event , vol. 139 of\\nProceedings of Machine Learning Research , pages 6565–6576. PMLR, 2021.\\n[573] Henderson, P., K. Sinha, N. Angelard-Gontier, et al. Ethical challenges in data-driven dia-\\nlogue systems. In J. Furman, G. E. Marchant, H. Price, F. Rossi, eds., Proceedings of the\\n2018 AAAI/ACM Conference on AI, Ethics, and Society, AIES 2018, New Orleans, LA, USA,\\nFebruary 02-03, 2018 , pages 123–129. ACM, 2018.\\n80\\n[574] Li, H., Y . Song, L. Fan. You don’t know my favorite color: Preventing dialogue representations\\nfrom revealing speakers’ private personas. In M. Carpuat, M. de Marneffe, I. V . M. Ruíz,\\neds., Proceedings of the 2022 Conference of the North American Chapter of the Association\\nfor Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA,\\nUnited States, July 10-15, 2022 , pages 5858–5870. Association for Computational Linguistics,\\n2022.\\n[575] Brown, H., K. Lee, F. Mireshghallah, et al. What does it mean for a language model to preserve\\nprivacy? In FAccT ’22: 2022 ACM Conference on Fairness, Accountability, and Transparency,\\nSeoul, Republic of Korea, June 21 - 24, 2022 , pages 2280–2292. ACM, 2022.\\n[576] Sebastian, G. Privacy and data protection in chatgpt and other ai chatbots: Strategies for\\nsecuring user information. Available at SSRN 4454761 , 2023.\\n[577] Reeves, B., C. Nass. The media equation - how people treat computers, television, and new\\nmedia like real people and places . Cambridge University Press, 1996.\\n[578] Roose, K. A conversation with bing’s chatbot left me deeply unsettled, 2023.\\n[579] Li, K., A. K. Hopkins, D. Bau, et al. Emergent world representations: Exploring a sequence\\nmodel trained on a synthetic task. In The Eleventh International Conference on Learning\\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[580] Bai, Y ., S. Kadavath, S. Kundu, et a', 'The Rise and Potential of Large Language Model.pdf'), 582: (' how people treat computers, television, and new\\nmedia like real people and places . Cambridge University Press, 1996.\\n[578] Roose, K. A conversation with bing’s chatbot left me deeply unsettled, 2023.\\n[579] Li, K., A. K. Hopkins, D. Bau, et al. Emergent world representations: Exploring a sequence\\nmodel trained on a synthetic task. In The Eleventh International Conference on Learning\\nRepresentations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 . OpenReview.net, 2023.\\n[580] Bai, Y ., S. Kadavath, S. Kundu, et al. Constitutional AI: harmlessness from AI feedback.\\nCoRR , abs/2212.08073, 2022.\\n[581] Bai, Y ., A. Jones, K. Ndousse, et al. Training a helpful and harmless assistant with reinforce-\\nment learning from human feedback. CoRR , abs/2204.05862, 2022.\\n[582] Liu, X., H. Yu, H. Zhang, et al. Agentbench: Evaluating llms as agents. CoRR , abs/2308.03688,\\n2023.\\n[583] Aher, G. V ., R. I. Arriaga, A. T. Kalai. Using large language models to simulate multiple\\nhumans and replicate human subject studies. In A. Krause, E. Brunskill, K. Cho, B. Engelhardt,\\nS. Sabato, J. Scarlett, eds., International Conference on Machine Learning, ICML 2023, 23-29\\nJuly 2023, Honolulu, Hawaii, USA , vol. 202 of Proceedings of Machine Learning Research ,\\npages 337–371. PMLR, 2023.\\n[584] Liang, Y ., L. Zhu, Y . Yang. Tachikuma: Understading complex interactions with multi-\\ncharacter and novel objects by large language models. CoRR , abs/2307.12573, 2023.\\n[585] Xu, B., X. Liu, H. Shen, et al. Gentopia: A collaborative platform for tool-augmented llms.\\nCoRR , abs/2308.04030, 2023.\\n[586] Kim, S. S., E. A. Watkins, O. Russakovsky, et al. \" help me help the ai\": Understanding how\\nexplainability can support human-ai interaction. In Proceedings of the 2023 CHI Conference\\non Human Factors in Computing Systems , pages 1–17. 2023.\\n[587] Choi, M., J. Pei, S. Kumar, et al. Do llms understand social knowledge? evaluating the\\nsociability of large language models with socket benchmark. CoRR , abs/2305.14938, 2023.\\n[588] Wilson, A. C., D. V . Bishop. \" if you c', 'The Rise and Potential of Large Language Model.pdf'), 583: ('d llms.\\nCoRR , abs/2308.04030, 2023.\\n[586] Kim, S. S., E. A. Watkins, O. Russakovsky, et al. \" help me help the ai\": Understanding how\\nexplainability can support human-ai interaction. In Proceedings of the 2023 CHI Conference\\non Human Factors in Computing Systems , pages 1–17. 2023.\\n[587] Choi, M., J. Pei, S. Kumar, et al. Do llms understand social knowledge? evaluating the\\nsociability of large language models with socket benchmark. CoRR , abs/2305.14938, 2023.\\n[588] Wilson, A. C., D. V . Bishop. \" if you catch my drift...\": ability to infer implied meaning is\\ndistinct from vocabulary and grammar skills. Wellcome open research , 4, 2019.\\n[589] Shuster, K., J. Urbanek, A. Szlam, et al. Am I me or you? state-of-the-art dialogue models\\ncannot maintain an identity. In M. Carpuat, M. de Marneffe, I. V . M. Ruíz, eds., Findings of\\nthe Association for Computational Linguistics: NAACL 2022, Seattle, WA, United States, July\\n10-15, 2022 , pages 2367–2387. Association for Computational Linguistics, 2022.\\n[590] Ganguli, D., L. Lovitt, J. Kernion, et al. Red teaming language models to reduce harms:\\nMethods, scaling behaviors, and lessons learned. CoRR , abs/2209.07858, 2022.\\n[591] Kadavath, S., T. Conerly, A. Askell, et al. Language models (mostly) know what they know.\\nCoRR , abs/2207.05221, 2022.\\n81\\n[592] Colas, C., L. Teodorescu, P. Oudeyer, et al. Augmenting autotelic agents with large language\\nmodels. CoRR , abs/2305.12487, 2023.\\n[593] Chaudhry, A., P. K. Dokania, T. Ajanthan, et al. Riemannian walk for incremental learning:\\nUnderstanding forgetting and intransigence. In Proceedings of the European conference on\\ncomputer vision (ECCV) , pages 532–547. 2018.\\n[594] Hou, S., X. Pan, C. C. Loy, et al. Learning a unified classifier incrementally via rebalancing. In\\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages\\n831–839. 2019.\\n[595] Colas, C., T. Karch, O. Sigaud, et al. Autotelic agents with intrinsically motivated goal-\\nconditioned reinforcement learning: A short survey. J. Artif. In', 'The Rise and Potential of Large Language Model.pdf'), 584: ('ning:\\nUnderstanding forgetting and intransigence. In Proceedings of the European conference on\\ncomputer vision (ECCV) , pages 532–547. 2018.\\n[594] Hou, S., X. Pan, C. C. Loy, et al. Learning a unified classifier incrementally via rebalancing. In\\nProceedings of the IEEE/CVF conference on computer vision and pattern recognition , pages\\n831–839. 2019.\\n[595] Colas, C., T. Karch, O. Sigaud, et al. Autotelic agents with intrinsically motivated goal-\\nconditioned reinforcement learning: A short survey. J. Artif. Intell. Res. , 74:1159–1199,\\n2022.\\n[596] Szegedy, C., W. Zaremba, I. Sutskever, et al. Intriguing properties of neural networks. In\\nY . Bengio, Y . LeCun, eds., 2nd International Conference on Learning Representations, ICLR\\n2014, Banff, AB, Canada, April 14-16, 2014, Conference Track Proceedings . 2014.\\n[597] Goodfellow, I. J., J. Shlens, C. Szegedy. Explaining and harnessing adversarial examples. In\\nY . Bengio, Y . LeCun, eds., 3rd International Conference on Learning Representations, ICLR\\n2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings . 2015.\\n[598] Madry, A., A. Makelov, L. Schmidt, et al. Towards deep learning models resistant to adversarial\\nattacks. In 6th International Conference on Learning Representations, ICLR 2018, Vancouver,\\nBC, Canada, April 30 - May 3, 2018, Conference Track Proceedings . OpenReview.net, 2018.\\n[599] Zheng, R., Z. Xi, Q. Liu, et al. Characterizing the impacts of instances on robustness. In\\nA. Rogers, J. L. Boyd-Graber, N. Okazaki, eds., Findings of the Association for Computational\\nLinguistics: ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 2314–2332. Association for\\nComputational Linguistics, 2023.\\n[600] Zhiheng, X., Z. Rui, G. Tao. Safety and ethical concerns of large language models. In\\nProceedings of the 22nd Chinese National Conference on Computational Linguistics (Volume\\n4: Tutorial Abstracts) , pages 9–16. 2023.\\n[601] Akhtar, N., A. Mian, N. Kardan, et al. Threat of adversarial attacks on deep learning in\\ncomputer vision: Survey II. CoRR , abs/2108.004', 'The Rise and Potential of Large Language Model.pdf'), 585: ('ion for Computational\\nLinguistics: ACL 2023, Toronto, Canada, July 9-14, 2023 , pages 2314–2332. Association for\\nComputational Linguistics, 2023.\\n[600] Zhiheng, X., Z. Rui, G. Tao. Safety and ethical concerns of large language models. In\\nProceedings of the 22nd Chinese National Conference on Computational Linguistics (Volume\\n4: Tutorial Abstracts) , pages 9–16. 2023.\\n[601] Akhtar, N., A. Mian, N. Kardan, et al. Threat of adversarial attacks on deep learning in\\ncomputer vision: Survey II. CoRR , abs/2108.00401, 2021.\\n[602] Drenkow, N., N. Sani, I. Shpitser, et al. A systematic review of robustness in deep learning for\\ncomputer vision: Mind the gap? arXiv preprint arXiv:2112.00639 , 2021.\\n[603] Hendrycks, D., T. G. Dietterich. Benchmarking neural network robustness to common\\ncorruptions and perturbations. In 7th International Conference on Learning Representations,\\nICLR 2019, New Orleans, LA, USA, May 6-9, 2019 . OpenReview.net, 2019.\\n[604] Wang, X., H. Wang, D. Yang. Measure and improve robustness in NLP models: A survey. In\\nM. Carpuat, M. de Marneffe, I. V . M. Ruíz, eds., Proceedings of the 2022 Conference of the\\nNorth American Chapter of the Association for Computational Linguistics: Human Language\\nTechnologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022 , pages 4569–4586.\\nAssociation for Computational Linguistics, 2022.\\n[605] Li, J., S. Ji, T. Du, et al. Textbugger: Generating adversarial text against real-world applications.\\nIn26th Annual Network and Distributed System Security Symposium, NDSS 2019, San Diego,\\nCalifornia, USA, February 24-27, 2019 . The Internet Society, 2019.\\n[606] Zhu, C., Y . Cheng, Z. Gan, et al. Freelb: Enhanced adversarial training for natural language\\nunderstanding. In 8th International Conference on Learning Representations, ICLR 2020,\\nAddis Ababa, Ethiopia, April 26-30, 2020 . OpenReview.net, 2020.\\n[607] Xi, Z., R. Zheng, T. Gui, et al. Efficient adversarial training with robust early-bird tickets. In\\nY . Goldberg, Z. Kozareva, Y . Zhang, eds., Proceedings of the 2022 C', 'The Rise and Potential of Large Language Model.pdf'), 586: (' 2019, San Diego,\\nCalifornia, USA, February 24-27, 2019 . The Internet Society, 2019.\\n[606] Zhu, C., Y . Cheng, Z. Gan, et al. Freelb: Enhanced adversarial training for natural language\\nunderstanding. In 8th International Conference on Learning Representations, ICLR 2020,\\nAddis Ababa, Ethiopia, April 26-30, 2020 . OpenReview.net, 2020.\\n[607] Xi, Z., R. Zheng, T. Gui, et al. Efficient adversarial training with robust early-bird tickets. In\\nY . Goldberg, Z. Kozareva, Y . Zhang, eds., Proceedings of the 2022 Conference on Empirical\\nMethods in Natural Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emirates,\\nDecember 7-11, 2022 , pages 8318–8331. Association for Computational Linguistics, 2022.\\n82\\n[608] Pinto, L., J. Davidson, R. Sukthankar, et al. Robust adversarial reinforcement learning. In\\nD. Precup, Y . W. Teh, eds., Proceedings of the 34th International Conference on Machine\\nLearning, ICML 2017, Sydney, NSW, Australia, 6-11 August 2017 , vol. 70 of Proceedings of\\nMachine Learning Research , pages 2817–2826. PMLR, 2017.\\n[609] Rigter, M., B. Lacerda, N. Hawes. RAMBO-RL: robust adversarial model-based offline\\nreinforcement learning. In NeurIPS . 2022.\\n[610] Panaganti, K., Z. Xu, D. Kalathil, et al. Robust reinforcement learning using offline data. In\\nNeurIPS . 2022.\\n[611] Lab, T. K. S. Experimental security research of tesla autopilot. Tencent Keen Security Lab ,\\n2019.\\n[612] Xu, K., G. Zhang, S. Liu, et al. Adversarial t-shirt! evading person detectors in a physical\\nworld. In A. Vedaldi, H. Bischof, T. Brox, J. Frahm, eds., Computer Vision - ECCV 2020\\n- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V , vol.\\n12350 of Lecture Notes in Computer Science , pages 665–681. Springer, 2020.\\n[613] Sharif, M., S. Bhagavatula, L. Bauer, et al. Accessorize to a crime: Real and stealthy attacks\\non state-of-the-art face recognition. In E. R. Weippl, S. Katzenbeisser, C. Kruegel, A. C.\\nMyers, S. Halevi, eds., Proceedings of the 2016 ACM SIGSAC Conference on Computer and\\nCommunications Securi', 'The Rise and Potential of Large Language Model.pdf'), 587: ('rox, J. Frahm, eds., Computer Vision - ECCV 2020\\n- 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part V , vol.\\n12350 of Lecture Notes in Computer Science , pages 665–681. Springer, 2020.\\n[613] Sharif, M., S. Bhagavatula, L. Bauer, et al. Accessorize to a crime: Real and stealthy attacks\\non state-of-the-art face recognition. In E. R. Weippl, S. Katzenbeisser, C. Kruegel, A. C.\\nMyers, S. Halevi, eds., Proceedings of the 2016 ACM SIGSAC Conference on Computer and\\nCommunications Security, Vienna, Austria, October 24-28, 2016 , pages 1528–1540. ACM,\\n2016.\\n[614] Jin, D., Z. Jin, J. T. Zhou, et al. Is BERT really robust? A strong baseline for natural language\\nattack on text classification and entailment. In The Thirty-Fourth AAAI Conference on Artificial\\nIntelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence\\nConference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial\\nIntelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020 , pages 8018–8025. AAAI\\nPress, 2020.\\n[615] Ren, S., Y . Deng, K. He, et al. Generating natural language adversarial examples through prob-\\nability weighted word saliency. In A. Korhonen, D. R. Traum, L. Màrquez, eds., Proceedings\\nof the 57th Conference of the Association for Computational Linguistics, ACL 2019, Florence,\\nItaly, July 28- August 2, 2019, Volume 1: Long Papers , pages 1085–1097. Association for\\nComputational Linguistics, 2019.\\n[616] Zhu, K., J. Wang, J. Zhou, et al. Promptbench: Towards evaluating the robustness of large\\nlanguage models on adversarial prompts. CoRR , abs/2306.04528, 2023.\\n[617] Chen, X., J. Ye, C. Zu, et al. How robust is GPT-3.5 to predecessors? A comprehensive study\\non language understanding tasks. CoRR , abs/2303.00293, 2023.\\n[618] Gu, T., B. Dolan-Gavitt, S. Garg. Badnets: Identifying vulnerabilities in the machine learning\\nmodel supply chain. CoRR , abs/1708.06733, 2017.\\n[619] Chen, X., A. Salem, D. Chen, et al. Badnl: Backdoor attacks against NLP models with\\nsemantic-p', 'The Rise and Potential of Large Language Model.pdf'), 588: ('aluating the robustness of large\\nlanguage models on adversarial prompts. CoRR , abs/2306.04528, 2023.\\n[617] Chen, X., J. Ye, C. Zu, et al. How robust is GPT-3.5 to predecessors? A comprehensive study\\non language understanding tasks. CoRR , abs/2303.00293, 2023.\\n[618] Gu, T., B. Dolan-Gavitt, S. Garg. Badnets: Identifying vulnerabilities in the machine learning\\nmodel supply chain. CoRR , abs/1708.06733, 2017.\\n[619] Chen, X., A. Salem, D. Chen, et al. Badnl: Backdoor attacks against NLP models with\\nsemantic-preserving improvements. In ACSAC ’21: Annual Computer Security Applications\\nConference, Virtual Event, USA, December 6 - 10, 2021 , pages 554–569. ACM, 2021.\\n[620] Li, Z., D. Mekala, C. Dong, et al. Bfclass: A backdoor-free text classification framework. In\\nM. Moens, X. Huang, L. Specia, S. W. Yih, eds., Findings of the Association for Computational\\nLinguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 16-20 November,\\n2021 , pages 444–453. Association for Computational Linguistics, 2021.\\n[621] Shi, Y ., P. Li, C. Yin, et al. Promptattack: Prompt-based attack for language models via\\ngradient search. In W. Lu, S. Huang, Y . Hong, X. Zhou, eds., Natural Language Processing\\nand Chinese Computing - 11th CCF International Conference, NLPCC 2022, Guilin, China,\\nSeptember 24-25, 2022, Proceedings, Part I , vol. 13551 of Lecture Notes in Computer Science ,\\npages 682–693. Springer, 2022.\\n[622] Perez, F., I. Ribeiro. Ignore previous prompt: Attack techniques for language models. CoRR ,\\nabs/2211.09527, 2022.\\n83\\n[623] Liang, P., R. Bommasani, T. Lee, et al. Holistic evaluation of language models. CoRR ,\\nabs/2211.09110, 2022.\\n[624] Gururangan, S., D. Card, S. K. Dreier, et al. Whose language counts as high quality? measuring\\nlanguage ideologies in text data selection. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds.,\\nProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,\\nEMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 , pages 2562–2580.\\nAssociation for Computa', 'The Rise and Potential of Large Language Model.pdf'), 589: (' 2022.\\n83\\n[623] Liang, P., R. Bommasani, T. Lee, et al. Holistic evaluation of language models. CoRR ,\\nabs/2211.09110, 2022.\\n[624] Gururangan, S., D. Card, S. K. Dreier, et al. Whose language counts as high quality? measuring\\nlanguage ideologies in text data selection. In Y . Goldberg, Z. Kozareva, Y . Zhang, eds.,\\nProceedings of the 2022 Conference on Empirical Methods in Natural Language Processing,\\nEMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11, 2022 , pages 2562–2580.\\nAssociation for Computational Linguistics, 2022.\\n[625] Liu, Y ., G. Deng, Y . Li, et al. Prompt injection attack against llm-integrated applications.\\nCoRR , abs/2306.05499, 2023.\\n[626] Carlini, N., D. A. Wagner. Audio adversarial examples: Targeted attacks on speech-to-text. In\\n2018 IEEE Security and Privacy Workshops, SP Workshops 2018, San Francisco, CA, USA,\\nMay 24, 2018 , pages 1–7. IEEE Computer Society, 2018.\\n[627] Morris, J. X., E. Lifland, J. Y . Yoo, et al. Textattack: A framework for adversarial attacks, data\\naugmentation, and adversarial training in NLP. In Q. Liu, D. Schlangen, eds., Proceedings\\nof the 2020 Conference on Empirical Methods in Natural Language Processing: System\\nDemonstrations, EMNLP 2020 - Demos, Online, November 16-20, 2020 , pages 119–126.\\nAssociation for Computational Linguistics, 2020.\\n[628] Si, C., Z. Zhang, F. Qi, et al. Better robustness by more coverage: Adversarial and mixup\\ndata augmentation for robust finetuning. In C. Zong, F. Xia, W. Li, R. Navigli, eds., Findings\\nof the Association for Computational Linguistics: ACL/IJCNLP 2021, Online Event, August\\n1-6, 2021 , vol. ACL/IJCNLP 2021 of Findings of ACL , pages 1569–1576. Association for\\nComputational Linguistics, 2021.\\n[629] Yoo, K., J. Kim, J. Jang, et al. Detection of adversarial examples in text classification: Bench-\\nmark and baseline via robust density estimation. In S. Muresan, P. Nakov, A. Villavicencio,\\neds., Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland,\\nMay 22-27, 2022 , pages 3656–3672. Associat', 'The Rise and Potential of Large Language Model.pdf'), 590: ('utational Linguistics: ACL/IJCNLP 2021, Online Event, August\\n1-6, 2021 , vol. ACL/IJCNLP 2021 of Findings of ACL , pages 1569–1576. Association for\\nComputational Linguistics, 2021.\\n[629] Yoo, K., J. Kim, J. Jang, et al. Detection of adversarial examples in text classification: Bench-\\nmark and baseline via robust density estimation. In S. Muresan, P. Nakov, A. Villavicencio,\\neds., Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland,\\nMay 22-27, 2022 , pages 3656–3672. Association for Computational Linguistics, 2022.\\n[630] Le, T., N. Park, D. Lee. A sweet rabbit hole by DARCY: using honeypots to detect universal\\ntrigger’s adversarial attacks. In C. Zong, F. Xia, W. Li, R. Navigli, eds., Proceedings of the 59th\\nAnnual Meeting of the Association for Computational Linguistics and the 11th International\\nJoint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long\\nPapers), Virtual Event, August 1-6, 2021 , pages 3831–3844. Association for Computational\\nLinguistics, 2021.\\n[631] Tsipras, D., S. Santurkar, L. Engstrom, et al. Robustness may be at odds with accuracy. In 7th\\nInternational Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA,\\nMay 6-9, 2019 . OpenReview.net, 2019.\\n[632] Zhang, H., Y . Yu, J. Jiao, et al. Theoretically principled trade-off between robustness and\\naccuracy. In K. Chaudhuri, R. Salakhutdinov, eds., Proceedings of the 36th International\\nConference on Machine Learning, ICML 2019, 9-15 June 2019, Long Beach, California, USA ,\\nvol. 97 of Proceedings of Machine Learning Research , pages 7472–7482. PMLR, 2019.\\n[633] Wong, A., X. Y . Wang, A. Hryniowski. How much can we really trust you? towards simple,\\ninterpretable trust quantification metrics for deep neural networks. CoRR , abs/2009.05835,\\n2020.\\n[634] Huang, X., D. Kroening, W. Ruan, et al. A survey of safety and trustworthiness of deep neural\\nnetworks: Verification, testing, adversarial attack and defence, and interpretability. Comput.\\nSci. Rev. , 37:100270, 2020.\\n[635] Huang, X', 'The Rise and Potential of Large Language Model.pdf'), 591: ('ol. 97 of Proceedings of Machine Learning Research , pages 7472–7482. PMLR, 2019.\\n[633] Wong, A., X. Y . Wang, A. Hryniowski. How much can we really trust you? towards simple,\\ninterpretable trust quantification metrics for deep neural networks. CoRR , abs/2009.05835,\\n2020.\\n[634] Huang, X., D. Kroening, W. Ruan, et al. A survey of safety and trustworthiness of deep neural\\nnetworks: Verification, testing, adversarial attack and defence, and interpretability. Comput.\\nSci. Rev. , 37:100270, 2020.\\n[635] Huang, X., W. Ruan, W. Huang, et al. A survey of safety and trustworthiness of large language\\nmodels through the lens of verification and validation. CoRR , abs/2305.11391, 2023.\\n[636] Raffel, C., N. Shazeer, A. Roberts, et al. Exploring the limits of transfer learning with a unified\\ntext-to-text transformer. J. Mach. Learn. Res. , 21:140:1–140:67, 2020.\\n84\\n[637] Chen, Y ., L. Yuan, G. Cui, et al. A close look into the calibration of pre-trained language\\nmodels. In A. Rogers, J. L. Boyd-Graber, N. Okazaki, eds., Proceedings of the 61st Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL\\n2023, Toronto, Canada, July 9-14, 2023 , pages 1343–1367. Association for Computational\\nLinguistics, 2023.\\n[638] Blodgett, S. L., S. Barocas, H. D. III, et al. Language (technology) is power: A critical survey\\nof \"bias\" in NLP. In D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreault, eds., Proceedings of the\\n58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online,\\nJuly 5-10, 2020 , pages 5454–5476. Association for Computational Linguistics, 2020.\\n[639] Guo, W., A. Caliskan. Detecting emergent intersectional biases: Contextualized word embed-\\ndings contain a distribution of human-like biases. In M. Fourcade, B. Kuipers, S. Lazar, D. K.\\nMulligan, eds., AIES ’21: AAAI/ACM Conference on AI, Ethics, and Society, Virtual Event,\\nUSA, May 19-21, 2021 , pages 122–133. ACM, 2021.\\n[640] Bolukbasi, T., K. Chang, J. Y . Zou, et al. Man is to computer programmer as woman is to\\nhome', 'The Rise and Potential of Large Language Model.pdf'), 592: ('uly 5-10, 2020 , pages 5454–5476. Association for Computational Linguistics, 2020.\\n[639] Guo, W., A. Caliskan. Detecting emergent intersectional biases: Contextualized word embed-\\ndings contain a distribution of human-like biases. In M. Fourcade, B. Kuipers, S. Lazar, D. K.\\nMulligan, eds., AIES ’21: AAAI/ACM Conference on AI, Ethics, and Society, Virtual Event,\\nUSA, May 19-21, 2021 , pages 122–133. ACM, 2021.\\n[640] Bolukbasi, T., K. Chang, J. Y . Zou, et al. Man is to computer programmer as woman is to\\nhomemaker? debiasing word embeddings. In D. D. Lee, M. Sugiyama, U. von Luxburg,\\nI. Guyon, R. Garnett, eds., Advances in Neural Information Processing Systems 29: Annual\\nConference on Neural Information Processing Systems 2016, December 5-10, 2016, Barcelona,\\nSpain , pages 4349–4357. 2016.\\n[641] Caliskan, A., J. J. Bryson, A. Narayanan. Semantics derived automatically from language\\ncorpora contain human-like biases. Science , 356(6334):183–186, 2017.\\n[642] Ji, Z., N. Lee, R. Frieske, et al. Survey of hallucination in natural language generation. ACM\\nComput. Surv. , 55(12):248:1–248:38, 2023.\\n[643] Mündler, N., J. He, S. Jenko, et al. Self-contradictory hallucinations of large language models:\\nEvaluation, detection and mitigation. CoRR , abs/2305.15852, 2023.\\n[644] Maynez, J., S. Narayan, B. Bohnet, et al. On faithfulness and factuality in abstractive\\nsummarization. In D. Jurafsky, J. Chai, N. Schluter, J. R. Tetreault, eds., Proceedings of the\\n58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online,\\nJuly 5-10, 2020 , pages 1906–1919. Association for Computational Linguistics, 2020.\\n[645] Varshney, N., W. Yao, H. Zhang, et al. A stitch in time saves nine: Detecting and mitigating\\nhallucinations of llms by validating low-confidence generation. CoRR , abs/2307.03987, 2023.\\n[646] Lightman, H., V . Kosaraju, Y . Burda, et al. Let’s verify step by step. CoRR , abs/2305.20050,\\n2023.\\n[647] Guo, Y ., Y . Yang, A. Abbasi. Auto-debias: Debiasing masked language models with automated\\nbiased promp', 'The Rise and Potential of Large Language Model.pdf'), 593: ('ACL 2020, Online,\\nJuly 5-10, 2020 , pages 1906–1919. Association for Computational Linguistics, 2020.\\n[645] Varshney, N., W. Yao, H. Zhang, et al. A stitch in time saves nine: Detecting and mitigating\\nhallucinations of llms by validating low-confidence generation. CoRR , abs/2307.03987, 2023.\\n[646] Lightman, H., V . Kosaraju, Y . Burda, et al. Let’s verify step by step. CoRR , abs/2305.20050,\\n2023.\\n[647] Guo, Y ., Y . Yang, A. Abbasi. Auto-debias: Debiasing masked language models with automated\\nbiased prompts. In S. Muresan, P. Nakov, A. Villavicencio, eds., Proceedings of the 60th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL\\n2022, Dublin, Ireland, May 22-27, 2022 , pages 1012–1023. Association for Computational\\nLinguistics, 2022.\\n[648] Du, M., F. He, N. Zou, et al. Shortcut learning of large language models in natural language\\nunderstanding: A survey. CoRR , abs/2208.11857, 2022.\\n[649] Brundage, M., S. Avin, J. Clark, et al. The malicious use of artificial intelligence: Forecasting,\\nprevention, and mitigation. CoRR , abs/1802.07228, 2018.\\n[650] Bommasani, R., D. A. Hudson, E. Adeli, et al. On the opportunities and risks of foundation\\nmodels. CoRR , abs/2108.07258, 2021.\\n[651] Charan, P. V . S., H. Chunduri, P. M. Anand, et al. From text to MITRE techniques: Exploring\\nthe malicious use of large language models for generating cyber attack payloads. CoRR ,\\nabs/2305.15336, 2023.\\n[652] Wang, Z. J., D. Choi, S. Xu, et al. Putting humans in the natural language processing loop: A\\nsurvey. CoRR , abs/2103.04044, 2021.\\n85\\n[653] Galsworthy, J. The inn of tranquillity: studies and essays . W. Heinemann, 1912.\\n[654] Yao, S., K. Narasimhan. Language agents in the digital world: Opportunities and risks.\\nprinceton-nlp.github.io , 2023.\\n[655] Asimov, I. Three laws of robotics. Asimov, I. Runaround , 2, 1941.\\n[656] Elhage, N., N. Nanda, C. Olsson, et al. A mathematical framework for transformer circuits.\\nTransformer Circuits Thread , 1, 2021.\\n[657] Bai, J., S. Zhang, Z. Chen. Is the', 'The Rise and Potential of Large Language Model.pdf'), 594: ('ng loop: A\\nsurvey. CoRR , abs/2103.04044, 2021.\\n85\\n[653] Galsworthy, J. The inn of tranquillity: studies and essays . W. Heinemann, 1912.\\n[654] Yao, S., K. Narasimhan. Language agents in the digital world: Opportunities and risks.\\nprinceton-nlp.github.io , 2023.\\n[655] Asimov, I. Three laws of robotics. Asimov, I. Runaround , 2, 1941.\\n[656] Elhage, N., N. Nanda, C. Olsson, et al. A mathematical framework for transformer circuits.\\nTransformer Circuits Thread , 1, 2021.\\n[657] Bai, J., S. Zhang, Z. Chen. Is there any social principle for llm-based agents? CoRR ,\\nabs/2308.11136, 2023.\\n[658] Baum, S. A survey of artificial general intelligence projects for ethics, risk, and policy. Global\\nCatastrophic Risk Institute Working Paper , pages 17–1, 2017.\\n[659] Lecun, Y . https://twitter.com/ylecun/status/1625127902890151943.\\n[660] Zhao, S. Can Large Language Models Lead to Artificial General Intelligence?\\n[661] Brandes, N. Language Models are a Potentially Safe Path to Human-Level AGI.\\n[662] Zocca, V . How far are we from AGI?\\n[663] Ilya Sutskever, L. F. Ilya Sutskever: Deep Learning | Lex Fridman Podcast #94.\\n[664] Lecun, Y . https://twitter.com/ylecun/status/1640063227903213568.\\n[665] LeCun, Y . A path towards autonomous machine intelligence version 0.9. 2, 2022-06-27. Open\\nReview , 62, 2022.\\n[666] Shridhar, M., X. Yuan, M. Côté, et al. Alfworld: Aligning text and embodied environments for\\ninteractive learning. In 9th International Conference on Learning Representations, ICLR 2021,\\nVirtual Event, Austria, May 3-7, 2021 . OpenReview.net, 2021.\\n[667] Chowdhury, J. R., C. Caragea. Monotonic location attention for length generalization. In\\nA. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds., International\\nConference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , vol.\\n202 of Proceedings of Machine Learning Research , pages 28792–28808. PMLR, 2023.\\n[668] Duan, Y ., G. Fu, N. Zhou, et al. Everything as a service (xaas) on the cloud: Origins, current\\nand future trends. In C. Pu, ', 'The Rise and Potential of Large Language Model.pdf'), 595: ('. OpenReview.net, 2021.\\n[667] Chowdhury, J. R., C. Caragea. Monotonic location attention for length generalization. In\\nA. Krause, E. Brunskill, K. Cho, B. Engelhardt, S. Sabato, J. Scarlett, eds., International\\nConference on Machine Learning, ICML 2023, 23-29 July 2023, Honolulu, Hawaii, USA , vol.\\n202 of Proceedings of Machine Learning Research , pages 28792–28808. PMLR, 2023.\\n[668] Duan, Y ., G. Fu, N. Zhou, et al. Everything as a service (xaas) on the cloud: Origins, current\\nand future trends. In C. Pu, A. Mohindra, eds., 8th IEEE International Conference on Cloud\\nComputing, CLOUD 2015, New York City, NY, USA, June 27 - July 2, 2015 , pages 621–628.\\nIEEE Computer Society, 2015.\\n[669] Bhardwaj, S., L. Jain, S. Jain. Cloud computing: A study of infrastructure as a service (iaas).\\nInternational Journal of engineering and information Technology , 2(1):60–63, 2010.\\n[670] Serrano, N., G. Gallardo, J. Hernantes. Infrastructure as a service and cloud technologies.\\nIEEE Software , 32(2):30–36, 2015.\\n[671] Mell, P., T. Grance, et al. The nist definition of cloud computing, 2011.\\n[672] Lawton, G. Developing software online with platform-as-a-service technology. Computer ,\\n41(6):13–15, 2008.\\n[673] Sun, W., K. Zhang, S.-K. Chen, et al. Software as a service: An integration perspective. In\\nService-Oriented Computing–ICSOC 2007: Fifth International Conference, Vienna, Austria,\\nSeptember 17-20, 2007. Proceedings 5 , pages 558–569. Springer, 2007.\\n[674] Dubey, A., D. Wagle. Delivering software as a service. The McKinsey Quarterly , 6(2007):2007,\\n2007.\\n[675] Sun, T., Y . Shao, H. Qian, et al. Black-box tuning for language-model-as-a-service. In\\nK. Chaudhuri, S. Jegelka, L. Song, C. Szepesvári, G. Niu, S. Sabato, eds., International\\nConference on Machine Learning, ICML 2022, 17-23 July 2022, Baltimore, Maryland, USA ,\\nvol. 162 of Proceedings of Machine Learning Research , pages 20841–20855. PMLR, 2022.\\n86', 'The Rise and Potential of Large Language Model.pdf'), 596: ('Information and Software Technology 143 (2022) 106736\\nAvailable online 8 October 2021\\n0950-5849/© 2021 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license\\n(http://creativecommons.org/licenses/by-nc-nd/4.0/ ).\\nContents lists available at ScienceDirect\\nInformation and Software Technology\\njournal homepage: www.elsevier.com/locate/infsof\\nA comparison of machine learning algorithms on design smell detection\\nusing balanced and imbalanced dataset: A study of God class\\nKhalid Alkharabsheha, Sadi Alawadie,∗, Victor R. Kebanded, Yania Crespoc,\\nManuel Fernández-Delgadob, José A. Taboadab\\naDepartment of Software Engineering, Prince Abdullah bin Ghazi Faculty of Information and Communication Technology, Al-Balqa Applied University\\n(BAU), Jordan\\nbCiTIUS, Centro Singular de Investigación en Tecnoloxías Intelixentes, Universidad de Santiago de Compostela, Santiago de Compostela 15782, Spain\\ncDepartamento de Informática. Escuela de Ingeniería Informática, Campus Miguel Delibes, Universidad de Valladolid, Paseo de Belén 15, Valladolid 47011, Spain\\ndDepartment of Computer Science (DIDA), Blekinge Institute of Technology, 37179, Karlskrona, Sweden\\neDepartment of Information Technology, Uppsala University, Box 337, 75105, Uppsala, Sweden\\nA R T I C L E I N F O\\nKeywords:\\nSoftware quality\\nDesign smell detection\\nMachine learning\\nGod class\\nBalanced dataA B S T R A C T\\nContext: Design smell detection has proven to be a significant activity that has an aim of not only enhancing\\nthe software quality but also increasing its life cycle.\\nObjective: This work investigates whether machine learning approaches can effectively be leveraged for\\nsoftware design smell detection. Additionally, this paper provides a comparatively study, focused on using\\nbalanced datasets, where it checks if avoiding dataset balancing can be of any influence on the accuracy and\\nbehavior during design smell detection.\\nMethod: A set of experiments have been conducted-using 28 Machine Learning classifiers aimed at detecting\\nGo', 'A comparison of machine learning algorithms on design smell detection.pdf'), 597: (' quality but also increasing its life cycle.\\nObjective: This work investigates whether machine learning approaches can effectively be leveraged for\\nsoftware design smell detection. Additionally, this paper provides a comparatively study, focused on using\\nbalanced datasets, where it checks if avoiding dataset balancing can be of any influence on the accuracy and\\nbehavior during design smell detection.\\nMethod: A set of experiments have been conducted-using 28 Machine Learning classifiers aimed at detecting\\nGod classes. This experiment was conducted using a dataset formed from 12,587 classes of 24 software systems,\\nin which 1,958 classes were manually validated.\\nResults: Ultimately, most classifiers obtained high performances,-with Cat Boost showing a higher perfor-\\nmance. Also, it is evident from the experiments conducted that data balancing does not have any significant\\ninfluence on the accuracy of detection. This reinforces the application of machine learning in real scenarios\\nwhere the data is usually imbalanced by the inherent nature of design smells.\\nConclusions: Machine learning approaches can effectively be used as a leverage for God class detection. While\\nin this paper we have employed SMOTE technique for data balancing, it is worth noting that there exist\\nother methods of data balancing and with other design smells. Furthermore, it is also important to note that\\napplication of those other methods may improve the results, in our experiments SMOTE did not improve God\\nclass detection.\\nThe results are not fully generalizable because only one design smell is studied with projects developed in\\na single programming language, and only one balancing technique is used to compare with the imbalanced\\ncase. But these results are promising for the application in real design smells detection scenarios as mentioned\\nabove and the focus on other measures, such as Kappa, ROC, and MCC, have been used in the assessment of\\nthe classifier behavior.\\n1. Introduction\\nWhile the quality of software is one of the most important concer', 'A comparison of machine learning algorithms on design smell detection.pdf'), 598: ('lly generalizable because only one design smell is studied with projects developed in\\na single programming language, and only one balancing technique is used to compare with the imbalanced\\ncase. But these results are promising for the application in real design smells detection scenarios as mentioned\\nabove and the focus on other measures, such as Kappa, ROC, and MCC, have been used in the assessment of\\nthe classifier behavior.\\n1. Introduction\\nWhile the quality of software is one of the most important concern\\nthat attracts the attention of the field/community of software engi-\\nneering, there is a constant need for maintaining this quality even\\nthough software complexity is being experienced quite often. Precisely,\\nmaintaining the quality of software involves exercising continuous\\n∗Corresponding author.\\nE-mail addresses: khalidkh@bau.edu.jo (K. Alkharabsheh), sadi.alawadi@it.uu.se (S. Alawadi), victor.kebande@bth.se (V.R. Kebande), yania@infor.uva.es\\n(Y. Crespo), manuel.fernandez.delgado@usc.es (M. Fernández-Delgado), joseangel.taboada@usc.es (J.A. Taboada).actions, that help in the identification and detection of poor program-\\nming practices or bad designs in software systems, where these poor\\nprogramming pieces are referred as ‘‘Design Smells’’ [ 1,2]. On the same\\nnote, detecting design smells is an activity that plays a significant role\\nof supporting software developers in order to come up with better\\nsoftware design solutions. Design smells do not produce compilation\\nhttps://doi.org/10.1016/j.infsof.2021.106736\\nReceived 22 January 2021; Received in revised form 23 August 2021; Accepted 23 September 2021\\nInformation and Software Technology 143 (2022) 106736\\n2K. Alkharabsheh et al.\\nor run-time errors [2], however, they portray negative impacts on\\ndifferent software quality features, such as reliability, usability, change-\\nability, and maintainability [3]. More often, the existence of design\\nsmells threaten the software life cycle, which leads to poor design\\noutputs. Notably, the growing software complexity, the r', 'A comparison of machine learning algorithms on design smell detection.pdf'), 599: ('36\\nReceived 22 January 2021; Received in revised form 23 August 2021; Accepted 23 September 2021\\nInformation and Software Technology 143 (2022) 106736\\n2K. Alkharabsheh et al.\\nor run-time errors [2], however, they portray negative impacts on\\ndifferent software quality features, such as reliability, usability, change-\\nability, and maintainability [3]. More often, the existence of design\\nsmells threaten the software life cycle, which leads to poor design\\noutputs. Notably, the growing software complexity, the rapid advance-\\nments of software systems require more novel approaches, techniques,\\npractices, and tools that can help to detect and identify the true positive\\ndesign smells.\\nExisting works have shown that quite a number of approaches\\nhave been proposed that have had a focus on smell detection. For\\nexample, metric-based, rule-based approaches, [4–10] and machine\\nlearning based approaches [11–17].\\nThese approaches (metric, rule) are constructed based on the design\\nsmell concepts that are mapped into a set of metric rules in order to\\nidentify software either through manual, semi-automatic, or automatic\\ndetection. A number of approaches that have been used in design\\nsmell research have been evaluated empirically. They have then ended\\nup achieving higher accuracy, however, there exist some challenges\\nthat limit their adoption in industries, such as false positive and false\\nnegative ratios and the low agreements between them. In spite of that,\\nsome of these approaches have found ways of being implemented as\\ncommercial or open source detection tools [6,7,18–20].\\nIn quest of overcoming the aforementioned challenges, the existing\\nstudies [11–14,21–23], have shown that machine learning techniques\\ncan be exploited effectively towards detecting design smells in software\\nsystems. Machine learning is a partial field of artificial intelligence that\\nuses mathematical algorithms to give systems the capacity to learn\\nwithout being programmed [24].\\nIt is based on the aforementioned premise that the authors of this\\npaper see the n', 'A comparison of machine learning algorithms on design smell detection.pdf'), 600: ('ial or open source detection tools [6,7,18–20].\\nIn quest of overcoming the aforementioned challenges, the existing\\nstudies [11–14,21–23], have shown that machine learning techniques\\ncan be exploited effectively towards detecting design smells in software\\nsystems. Machine learning is a partial field of artificial intelligence that\\nuses mathematical algorithms to give systems the capacity to learn\\nwithout being programmed [24].\\nIt is based on the aforementioned premise that the authors of this\\npaper see the need to leverage a balanced dataset to as a way of testing\\nwhether this objective of design smell detection can be achieved. Con-\\nsequently, the aspect of using a balanced dataset and different design\\nsmell detection tools presents a significant approach of design smell de-\\ntection. In this context, the notion of utilizing a balanced dataset in this\\nstudy, is owing to the fact that studies in [17] have shown that, models\\nbecome more accurate when the best balancing technique is used.\\nStudies such as [17] have shown that models become more accurate\\nwhen the best balancing technique is used. However, by the inherent\\nnature of design smells and the data are often highly imbalanced.\\nTherefore, an empirical study comparing the behavior of the classifiers\\nin both cases, when using an imbalanced dataset, gives insights on\\nhow much the improvement really is. In addition, the behavior of the\\nclassifiers should be observed from other indicators, such as Kappa,\\nROC, and MCC (see Section 3.3). These indicators are more appropriate\\nfor problem scenarios with imbalanced data, without losing track of the\\nother indicators such as accuracy and F-measure that are usually better\\nwhen using balanced data. Despite that, the improvement may not be\\nsubstantial, which would be good news for the application of machine\\nlearning techniques in real scenarios of design smell detection. On\\nthe same note, despite taking a step of validating the detected smells,\\nthe uniqueness of this study is juxtaposed to also leverage 28 distinct\\nclassifier', 'A comparison of machine learning algorithms on design smell detection.pdf'), 601: ('propriate\\nfor problem scenarios with imbalanced data, without losing track of the\\nother indicators such as accuracy and F-measure that are usually better\\nwhen using balanced data. Despite that, the improvement may not be\\nsubstantial, which would be good news for the application of machine\\nlearning techniques in real scenarios of design smell detection. On\\nthe same note, despite taking a step of validating the detected smells,\\nthe uniqueness of this study is juxtaposed to also leverage 28 distinct\\nclassifiers, which uniquely based on the expected results, may depict a\\ndesign smell detection behavior worth exploring.\\nOn the one hand, this work aims empirically to investigate whether\\nmachine learning classifiers can effectively be used for God Class design\\nsmell detection, while on the other hand, the study does a comparison\\non the behavior of the classifiers using a balanced and imbalanced\\ndataset from other indicators, such as Kappa, ROC, and MCC which\\nare more appropriate for problem scenarios with imbalanced data.\\nThis, also is done without losing track of the other indicators such as\\naccuracy and F-measure that are usually better when using balanced\\ndata. We highlight that despite the conclusions from our experiments,\\nthere exist other methods of data balancing besides SMOTE that we em-\\nployed in this paper, also with the existence of other design smells. The\\napplication of those other methods may improve the results; however,\\nin our experiments, SMOTE did not improve God class detection.\\nTherefore, the main contributions of this paper can be summarized\\nas follows:•We conduct an experiment using a balanced and imbalanced\\ndataset to show how machine learning classifiers could be lever-\\naged during God Class design smell detection.\\n•We investigate the influence of data balancing on God Class\\ndesign smell detection.\\n•We provide a large dataset formed from 12,587 classes of 24\\nsoftware systems that include 1958 God Classes that are manually\\nvalidated. Also there is a Reduction of false negative with the\\noriginal au', 'A comparison of machine learning algorithms on design smell detection.pdf'), 602: ('contributions of this paper can be summarized\\nas follows:•We conduct an experiment using a balanced and imbalanced\\ndataset to show how machine learning classifiers could be lever-\\naged during God Class design smell detection.\\n•We investigate the influence of data balancing on God Class\\ndesign smell detection.\\n•We provide a large dataset formed from 12,587 classes of 24\\nsoftware systems that include 1958 God Classes that are manually\\nvalidated. Also there is a Reduction of false negative with the\\noriginal automatic labeling system based on five detection tools\\nand reducing the false positive by manual validation on the results\\non the first automatic labeling stage.\\n•We provide a replication package that involves raw data, scripts,\\nand all related material for the replication of the study. [25].\\nSection 2 presents related works on machine learning for design\\nsmell detection and the influence of dataset balancing on the accuracy\\nof the machine learning models. Section 3 describes the study goals,\\nresearch questions, and main hypotheses, as well as the study design\\nthat includes context selection, data collection, and data analysis. Next,\\nSection 4 provides an analysis of the obtained results while Section 5\\npresents a replication of experiments using a new dataset. Section 6\\ndiscusses the main threats to the validity of the study. Finally, the paper\\nconcludes with Section 7 by providing a conclusion and a mention of\\nfuture work.\\n2. Related work\\nIn this section, related work that is focused on machine learning\\ntechniques for design smell detection and the influence of data bal-\\nancing on the learning techniques behavior concerning smell detection\\nactivity is discussed.\\n2.1. Machine learning approaches for design smell detection\\nFrom a cursory view, [13] proposed a concept that addressed an\\namalgamation of a machine learning approaches with Object-Oriented\\n(OO) metrics. The dataset that was used included two software sys-\\ntems that were analyzed using a prototype. The outcome showed that\\nlearning decision trees were u', 'A comparison of machine learning algorithms on design smell detection.pdf'), 603: ('niques for design smell detection and the influence of data bal-\\nancing on the learning techniques behavior concerning smell detection\\nactivity is discussed.\\n2.1. Machine learning approaches for design smell detection\\nFrom a cursory view, [13] proposed a concept that addressed an\\namalgamation of a machine learning approaches with Object-Oriented\\n(OO) metrics. The dataset that was used included two software sys-\\ntems that were analyzed using a prototype. The outcome showed that\\nlearning decision trees were utilized in the detection of two types of\\ndesign flaws (Large Class & Long Method) on two software systems.\\nAlso, [14] investigate the prediction of bad smells (Lazy Class, Feature\\nEnvy, Middle Man, Message Chains, Long Method, Long Parameter\\nList, Switch Statement) using seven machine learning techniques. In\\ntheir study, the dataset involved 27 design metrics and seven bad\\nsmells mentioned that were collected from a set of software that\\nhave design smells detected from previous studies. Furthermore, their\\nprediction model was validated by statistical significance testing. In\\nanother research, the Bayesian belief networks have been used in the\\nnamed BDTEX strategy to detect three types of anti-patterns (Blob,\\nFunctional Decomposition & Spaghetti Code) on two Java projects [12]\\nand compare the results with the obtained by the detection tool based\\nin DECOR method, used as the reference of the state of the art in\\ndetection. Next, [26,27] introduce an approach to detect four different\\ntypes of anti-patterns (Blob, Functional Decomposition, Spaghetti Code\\n& Swiss Army Knife) based on Support Vector Machine (SVM), in\\nthree software systems and compare the results with the detection tool\\nDETEX which instantiate the DECOR method, used as the reference of\\nthe state of the art in detection. In [26], the authors focused on SVM\\nand object-oriented metrics, while [27] they have taken into account\\nthe feedback of practitioners in the detection strategies and compare\\nthe results with BDTEX and DETEX. More recent research by [2', 'A comparison of machine learning algorithms on design smell detection.pdf'), 604: (' Functional Decomposition, Spaghetti Code\\n& Swiss Army Knife) based on Support Vector Machine (SVM), in\\nthree software systems and compare the results with the detection tool\\nDETEX which instantiate the DECOR method, used as the reference of\\nthe state of the art in detection. In [26], the authors focused on SVM\\nand object-oriented metrics, while [27] they have taken into account\\nthe feedback of practitioners in the detection strategies and compare\\nthe results with BDTEX and DETEX. More recent research by [28]\\npresented a non-intrusive machine learning approach (NiPAD) that is\\nbased on system performance metrics for detecting and classifying anti-\\npatterns using five machine learning techniques. They experiment with\\none application and determines SVMlinear as the algorithm with the\\nbest behavior. The obtained results showed that the proposed approach\\nInformation and Software Technology 143 (2022) 106736\\n3K. Alkharabsheh et al.\\nhas the ability to identify the One-lane Bridge performance anti-pattern\\nwith high accuracy detection. Another relevant work [21] conducts a\\nlarge-scale experiment that compared sixteen machine learning tech-\\nniques to detect four types of code smells (God Class, Feature Envy,\\nLong Method and Data Class) using five different detection tools (two\\ntools for God Class) as ‘‘advisors’’ to perform an automate smell de-\\ntection as initial labeling technique. The designed experiment was able\\nto give a validation of 74 software systems, in addition to a sample of\\n1986 code smells validated by human experts as second step in labeling\\nwhich include 493 God Class, 430 Data class, 517 Feature Envy, 546\\nLong Method. The obtained result showed that most of the chosen\\ntechniques have more than 95% accuracy and F-measure. From this\\nbasis, [29] conducted a replication study of the exploration by [21] in\\norder to identify the current state of machine learning approaches in\\ndesign smells detection. The results of that study indicated the need\\nfor more investigation in the learning methodologies, construction o', 'A comparison of machine learning algorithms on design smell detection.pdf'), 605: ('n experts as second step in labeling\\nwhich include 493 God Class, 430 Data class, 517 Feature Envy, 546\\nLong Method. The obtained result showed that most of the chosen\\ntechniques have more than 95% accuracy and F-measure. From this\\nbasis, [29] conducted a replication study of the exploration by [21] in\\norder to identify the current state of machine learning approaches in\\ndesign smells detection. The results of that study indicated the need\\nfor more investigation in the learning methodologies, construction of\\ndataset, and the set of metrics used to present the smelly and not smelly\\nclasses.\\nFinally, in [17], the authors performed an empirical study that\\ncompares the performance of machine learning-based (Naive Bayes)\\nand heuristic-based approaches, specifically, metric-based approaches\\nin terms of design smell detection. In their study, the dataset involved\\n17 metrics and 11 code smells gathered from 13 software systems. The\\nobtained results show that heuristic-based approaches achieve slightly\\nbetter performance compared with machine learning techniques. How-\\never, there is a need for further investigation and researches to improve\\nthe accuracy and effectiveness of both approaches on design smell\\ndetection. One of the aspects that deserve more study in this type of\\nproblem, i.e design smell detection, are the indicators of good classifiers\\nperformance. Accuracy and F-measure should not be the only ones.\\nThis involves working with a set of elements where only a few must be\\nidentified (as smelly in this case). It can be quite common to obtain high\\naccuracy values. Accuracy alone is not a good indicator when working\\nwith imbalanced categories. However, Cohen’s Kappa can be a good\\ncomplementary indicator when accuracy is not good because of the\\nlarge imbalance. Nevertheless, Cohen’s Kappa, by definition, is always\\nhigher with balanced data. Hence, it is also necessary to combine the\\nbehavior analysis with ROC and MCC indicators (see Section 3.3),\\nwhich can be used even if the categories are of very different sizes.\\nT', 'A comparison of machine learning algorithms on design smell detection.pdf'), 606: (' can be quite common to obtain high\\naccuracy values. Accuracy alone is not a good indicator when working\\nwith imbalanced categories. However, Cohen’s Kappa can be a good\\ncomplementary indicator when accuracy is not good because of the\\nlarge imbalance. Nevertheless, Cohen’s Kappa, by definition, is always\\nhigher with balanced data. Hence, it is also necessary to combine the\\nbehavior analysis with ROC and MCC indicators (see Section 3.3),\\nwhich can be used even if the categories are of very different sizes.\\nThese indicators are widely used in medicine to assess the goodness of\\na test that detects the disease, which is a similar case to that of detection\\ndesign smells.\\n2.2. Influence of data balancing on machine learning model concerning\\ndesign smell detection\\nThe issue of data balancing in machine learning has attracted the\\nattention of the research community in the recent past. Several studies\\nin the existing literature have tackled this topic [30–33]. In this section,\\nour focus is mainly on the studies that concern data balancing in\\nmachine learning based design smell detection.\\nResearch in [34], examines the impact of balancing and unbalancing\\ndatasets on the behavior of machine learning techniques regarding code\\nsmell detection. Three types of machine learning techniques SVM, J48,\\nand Random Forest have been used in the experiment to detect seven\\ntypes of design smells, in four versions of the Eclipse software system.\\nThe dataset is balanced based on a popular strategy used in [35]\\nwhile one-third of classes are positive, the remaining is negative. The\\nresults show that the performance of the constructed models using\\nJ48 and SVM techniques does not improve after data balancing, while\\na slight improvement on the RandomForest model is observed. Their\\nconclusion is that data balancing does not have a dramatic influence on\\nthe behavior of machine learning algorithms. Next, a study by [16,17]\\ninvestigates the role of data balancing techniques in machine learning\\non design smell detection. The authors conducted a lar', 'A comparison of machine learning algorithms on design smell detection.pdf'), 607: ('are positive, the remaining is negative. The\\nresults show that the performance of the constructed models using\\nJ48 and SVM techniques does not improve after data balancing, while\\na slight improvement on the RandomForest model is observed. Their\\nconclusion is that data balancing does not have a dramatic influence on\\nthe behavior of machine learning algorithms. Next, a study by [16,17]\\ninvestigates the role of data balancing techniques in machine learning\\non design smell detection. The authors conducted a large scale study\\nthat compares the performance of five data balancing techniques, thatinvolves the SMOTE technique against unbalancing data. In this study,\\nthe experiment was conducted using a set of five machine learning algo-\\nrithms on a dataset of 13 open source systems, that were analyzed and\\nmanually validated to detect 11 types of design smells. The obtained\\nresults show that the behavior of machine learning techniques has not\\nsignificantly improved using data balancing despite the accuracy of\\nlearned models for design smell detection that used existing metrics\\nwhich slightly changed, especially while SMOTE technique was used.\\nEventually, they conclude that it is necessary to include new metrics\\nrelated to the software systems in order to increase the accuracy of\\nmodels.\\nRecently, in [15,36], the authors explore the influence of including\\nnew software metrics, such as size categories and domain on the God\\nclass detection. The experiments conducted using eight machine learn-\\ning algorithms on a large dataset formed by 24 software systems. Also,\\nthey examine the impact of using SMOTE data balancing technique on\\nthe performance of algorithms. The results show that the performance\\nof machine learning algorithms improved using size and domain and\\ncan be exploited effectively in improving design smell detection. On\\nthe other hand, after data balancing, the behavior of algorithms slightly\\nimproved, however, they did not find conclusive empirical evidence on\\nthe usefulness of data balancing.\\nTo overcome the limitat', 'A comparison of machine learning algorithms on design smell detection.pdf'), 608: ('et formed by 24 software systems. Also,\\nthey examine the impact of using SMOTE data balancing technique on\\nthe performance of algorithms. The results show that the performance\\nof machine learning algorithms improved using size and domain and\\ncan be exploited effectively in improving design smell detection. On\\nthe other hand, after data balancing, the behavior of algorithms slightly\\nimproved, however, they did not find conclusive empirical evidence on\\nthe usefulness of data balancing.\\nTo overcome the limitations of previous works and their findings,\\nin this paper, from the one hand, we confirm the results concerning\\nexploiting machine learning approaches on design smell detection, and\\nfrom the other perspective, we generalize the conclusions related to the\\ninfluence of data balancing on design smell detection. For this purpose,\\nthe proposed work differs from the previous works in the following\\naspects:\\n•A large set of different machine learning techniques (28 classi-\\nfiers) have been used to conduct the experiment.\\n•A set of five different design smell detection tools have been used\\ninitially as advisors to automatically label the original dataset to\\nconstruct the God Class dataset.\\n•A manual labeling of design smells has been applied by experts\\nto the whole dataset.\\n•The results have been compared by replicating the experiment on\\ntwo different datasets of the previous studies.\\n3. Empirical study definition and design\\nAs mentioned before, machine learning techniques are widely ex-\\nploited to detect design smells. However, despite a concentration in this\\nof research field, further investigation are still needed, especially in the\\ncomparison between using or not using a balanced dataset. For studying\\nthis aspect, the aim of this work is to (i) investigate whether machine\\nlearning based approaches can be effectively leveraged for God Class\\ndesign smell detection, and (ii) how avoiding dataset balancing can be\\nof influence to the accuracy/performance of design smell detection. The\\nobjective of this study is defined by', 'A comparison of machine learning algorithms on design smell detection.pdf'), 609: ('. However, despite a concentration in this\\nof research field, further investigation are still needed, especially in the\\ncomparison between using or not using a balanced dataset. For studying\\nthis aspect, the aim of this work is to (i) investigate whether machine\\nlearning based approaches can be effectively leveraged for God Class\\ndesign smell detection, and (ii) how avoiding dataset balancing can be\\nof influence to the accuracy/performance of design smell detection. The\\nobjective of this study is defined by the GQM method, widely used in\\nsoftware engineering research for goal setting [37,38] as follows:\\nAnalyze Set of classes.\\nWith the purpose of Evaluation.\\nWith respect to the efficiency of machine learning techniques to de-\\ntect God Class design smell using a balanced in front of imbal-\\nanced dataset.\\nFrom the point of view of researchers.\\nIn the context of Software hosted in open source repositories.\\nAccording to this objective, we derive the following research ques-\\ntions and a working hypothesis.\\nInformation and Software Technology 143 (2022) 106736\\n4K. Alkharabsheh et al.\\nRQ1 To what extent can machine learning techniques be effectively lever-\\naged for God Class design smell detection?\\nRQ2 To what extent can avoiding data balancing have an influence to the\\naccuracy of God Class design smell detection?\\nTo this end, the following null hypotheses have been formulated:\\nHypothesis1 Machine learning techniques cannot be effectively leveraged\\nfor God Class design smell detection.\\nHypothesis2 Avoiding data balancing will not influence the accuracy of\\nGod Class design smell detection.\\n3.1. Context selection\\nThe context of this study consists of the target software systems, God\\nClass design smell, and the set of machine learning techniques used for\\nGod Class detection.\\n3.1.1. Target systems in the first set of experiments\\nWe used a dataset that was previously constructed by our team, that\\nhas also been used in other research publications with different for-\\nmats [15,39]. The dataset consists of 24 open-source softwar', 'A comparison of machine learning algorithms on design smell detection.pdf'), 610: ('ing will not influence the accuracy of\\nGod Class design smell detection.\\n3.1. Context selection\\nThe context of this study consists of the target software systems, God\\nClass design smell, and the set of machine learning techniques used for\\nGod Class detection.\\n3.1.1. Target systems in the first set of experiments\\nWe used a dataset that was previously constructed by our team, that\\nhas also been used in other research publications with different for-\\nmats [15,39]. The dataset consists of 24 open-source software systems\\nhaving different domains, sizes, and categories. The selected open-\\nsource systems have been obtained from the Github1and SourceForge2\\nsoftware repositories, which are well-known in the context of open-\\nsource systems. All systems were written in Java language which is\\none of the most recognized object-oriented languages in the context of\\ndesign smell detection, where a total of 12,587 classes were analyzed.\\nTable 1 reports the main characteristics of the chosen software\\nsystems: software name and version, Number of Classes (NOC), Number\\nof Methods (NOM), and the Total Lines of Code (TLOC). In order\\nto better understand the machine learning process, we increased the\\nnumber of selected software projects in the experiment to get a high\\nnumber of classes so that we can be able to generalize the study results.\\nThe whole dataset was included in the replication package.\\n3.1.2. God class design smell\\nThere exist several types of design smells that have a possibility of\\nbeing detected in software systems. These smells vary in scope, influ-\\nence, and frequency of occurrence. Important to note is that the focus\\nof this study is inclined towards God Class detection. God Class has in\\ndifferent situations attracted great attention of the research community\\nbased on the existing literature [40–46]. Moreover, previous work on\\nsystematic mapping on design smell detection [1], has shown that God\\nClass is one of the most detected design smells in the software system\\nand it has often been detected using a wide set of de', 'A comparison of machine learning algorithms on design smell detection.pdf'), 611: ('hese smells vary in scope, influ-\\nence, and frequency of occurrence. Important to note is that the focus\\nof this study is inclined towards God Class detection. God Class has in\\ndifferent situations attracted great attention of the research community\\nbased on the existing literature [40–46]. Moreover, previous work on\\nsystematic mapping on design smell detection [1], has shown that God\\nClass is one of the most detected design smells in the software system\\nand it has often been detected using a wide set of detection tools. Also,\\nGod class smell has a negative influence on a wide set of software\\nquality features such as maintainability, understandability, complex-\\nity, readability, flexibility, evolvability, performance, reusability, and\\nstability.\\nGod Class is a class-level smell [47] that describe the case of a class\\ntends to do several functions and has many responsibilities, i.e. most\\nof the tasks are centralized in this class. It tends to be very large in\\nterms of Lines of Code (LOC) and it is also very complex. Based on\\nthe existing literature that has extensively been explored, God Class\\nhas been referred as the Blob anti-pattern [3], and the large class bad\\nsmell [48]. According to [49] and [50], the presence of the God Class in\\na particular class is an indicator to finding other types of design smells\\nsuch as Feature Envy, Data Class, God Method, and Duplicate Code.\\nIn order to detect God Class, it is important to explore the inside of\\nthe class. According to [51] in their classification of design smells God\\nClass belongs to ‘‘Bloaters’’ group that describe parts of code that have\\na large size and are hard to maintain.\\n1https://github.com/github.\\n2https://sourceforge.net/.Table 1\\nCharacterization of the selected software systems that includes Number of packages\\n(NOP), Number of classes (NOC), Number of Methods (NOM), and Total Lines of Code\\n(TLoC).\\nProject name & version NOP NOC NOM TLOC\\nAngryIPScanner-3.0 20 270 1049 19,965\\nApeiron-2.92 6 62 641 8908\\ncheckstyle-6.2.0 15 277 1267 41,104\\nDigiExtractor-2.5.2 ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 612: ('God\\nClass belongs to ‘‘Bloaters’’ group that describe parts of code that have\\na large size and are hard to maintain.\\n1https://github.com/github.\\n2https://sourceforge.net/.Table 1\\nCharacterization of the selected software systems that includes Number of packages\\n(NOP), Number of classes (NOC), Number of Methods (NOM), and Total Lines of Code\\n(TLoC).\\nProject name & version NOP NOC NOM TLOC\\nAngryIPScanner-3.0 20 270 1049 19,965\\nApeiron-2.92 6 62 641 8908\\ncheckstyle-6.2.0 15 277 1267 41,104\\nDigiExtractor-2.5.2 10 80 412 15,668\\nFreemind-1.0.1 50 782 5987 106,396\\nFullSync-0.10.2 22 169 1272 24,323\\nGanttProject-2.0.10 52 621 5004 66,540\\nJasperReports-4.7.1 110 1797 15,645 350,690\\njAudio-1.0.4 38 416 4257 117,615\\nJava graphplan-1.0.7 17 50 455 1049\\nJCLEC-4.0.0 33 311 1379 37,575\\nJDistlib-0.3.8 12 78 924 32,081\\nJFreeChart-1.0.X 37 499 7989 206,559\\nJHotDraw-5.2 12 151 1474 17,807\\nKeyStore Explorer-5.1 54 384 2266 83,144\\nLucene-3.0.0 103 606 3837 81,611\\nMatte-1.7 65 603 4090 52,067\\nMpxj-4.7 25 553 12,574 261,971\\nOmegaT-3.1.8 106 716 4472 121,909\\nPlugfy-0.6 10 28 91 2337\\npmd-4.3.x 90 800 5256 82,885\\nsMeta-1.0.3 14 222 1308 30,843\\nSQuirreL SQL Client-3.7.1 249 20,495 1138 71,626\\nxena-6.1.0 281 1975 25,163 61,526\\nTotal 1431 12,587 127,307 1,896,199\\n3.1.3. Machine learning techniques\\nA comparison of 28 machine learning algorithms has been con-\\nducted, These 28 classifiers were previously used in the context of\\ndesign smell detection [21–23]. As shown in Table 2, these classifiers\\nbelongs to 11 different families [52–54], such as Naive Bayes (NB),\\nDecision Trees (DT), Support Vector Machines (SVM), and Neural\\nNetworks (NN) etc.\\nFurthermore, to conduct this experiment, the selected classifiers\\nrequires training data that involve classified instances. To this end, in\\nour experiment, we used a binary label to classify the dataset. For each\\nclassifier, there are one or more parameters that should be tuned.\\nTuning classifier parameters have a robust effect on their perfor-\\nmance. For this purpose, to select the most significant param', 'A comparison of machine learning algorithms on design smell detection.pdf'), 613: (' as Naive Bayes (NB),\\nDecision Trees (DT), Support Vector Machines (SVM), and Neural\\nNetworks (NN) etc.\\nFurthermore, to conduct this experiment, the selected classifiers\\nrequires training data that involve classified instances. To this end, in\\nour experiment, we used a binary label to classify the dataset. For each\\nclassifier, there are one or more parameters that should be tuned.\\nTuning classifier parameters have a robust effect on their perfor-\\nmance. For this purpose, to select the most significant parameters for\\neach classifier and the parameter values, we checked and reviewed\\nseveral documentations, such as [55], which include a set of learning\\nclassifiers selected from the R3statistical computing language.\\n3.2. Data collection\\nTo answer the research questions, a source code of software systems\\nis needed to enable the extraction the set of related metrics, as well\\nas detecting the God Class design smell, and then, formulating these\\ndata in the appropriate format to be input source for machine learning\\nclassifiers. For this purpose, in this section we describe in detail the tool\\nthat was used to collect the set of metrics and the set of design smell\\ntools used in God Class detection.\\n3.2.1. Metric extraction tool\\nSeveral tools have been developed to analyze source code and to\\ncompute different measurements (metrics) concerning various quality\\ndimensions, such as size, complexity, coupling, cohesion, and inher-\\nitance. This activity of computing code metrics can be developed in\\na standalone tool or besides other activities, such as design smell\\ndetection, prioritization, or refactoring in the same tool. In this work,\\n3http://r-project.org.\\nInformation and Software Technology 143 (2022) 106736\\n5K. Alkharabsheh et al.\\nTable 2\\nMachine learning techniques considered in this work grouped by their families.\\nNo. Family Classifiers\\n1 Discriminant analysis (DA)Linear Discriminant Analysis (LDA)\\nQuadratic Discriminant Analysis (QDA)\\n2 Naive Bayesian (NB)Multinomial Naive Bayes (MNB)\\nComplement Naive Bayes (CNB)\\nGaussian', 'A comparison of machine learning algorithms on design smell detection.pdf'), 614: ('ther activities, such as design smell\\ndetection, prioritization, or refactoring in the same tool. In this work,\\n3http://r-project.org.\\nInformation and Software Technology 143 (2022) 106736\\n5K. Alkharabsheh et al.\\nTable 2\\nMachine learning techniques considered in this work grouped by their families.\\nNo. Family Classifiers\\n1 Discriminant analysis (DA)Linear Discriminant Analysis (LDA)\\nQuadratic Discriminant Analysis (QDA)\\n2 Naive Bayesian (NB)Multinomial Naive Bayes (MNB)\\nComplement Naive Bayes (CNB)\\nGaussian Naive Bayes (GNB)\\nBernoulli Naive Bayes (BNB)\\n3 Neural Networks (NN) Multi-Layers Perceptrons (MLP)\\n4Support vector\\nmachines (SVM)Support Vector Machine (SVM)\\nLinear Support Vector Machine (LSVM)\\nNu-Support Vector Machine (Nu-SVM)\\n5 Decision trees (DT) Decision Tree (DT)\\n6 Boosting (BST)Gradient Boosting (GB)\\nCat Boost (CBoost)\\nLight GBM (LGBM)\\neXtreme Gradient Boosting with\\nRandomForest (XGBRF)\\neXtreme Gradient Boosting (XGB)\\nAdaBoost (AB)\\n7 Bagging (BAG) Bagging\\n8 Random Forests (RF)Random Forest (RF)\\nExtra Trees (ET)\\n9Nearest neighbor\\nmethods (KNN)K-Nearest Neighbors (K-NN)\\nNearest Centroid (NC)\\n10 Gaussian Process (GP) Gaussian Process (GP)\\n11 Linear approachesRidge\\nLogistic Regression (LR)\\nPerceptron\\nPassive Aggressive (PA)\\nStochastic Gradient Descent (SGD)\\nwe have chosen RefactorIt4to analyze the selected software systems\\nand extracted the required metrics. We decide to use an external tool\\n(not of the five detection tools used as advisors in first automatic\\nlabeling strategy) to avoid any effect on the detection results of God\\nClass.\\nRefactorIt is an open-source tool used to examine the software sys-\\ntems implemented in Java based on metrics and semantic rules. Using\\nRefactorIt, we are able to compute 30 metrics for projects, packages,\\nclasses, methods, types, members, and constructors. It is available in\\ntwo versions: standalone or integrated with eclipse [56]. A set of 16\\nobject-oriented metrics have been computed for each software systems\\nin the dataset. The set of metrics related to different levels', 'A comparison of machine learning algorithms on design smell detection.pdf'), 615: ('e detection results of God\\nClass.\\nRefactorIt is an open-source tool used to examine the software sys-\\ntems implemented in Java based on metrics and semantic rules. Using\\nRefactorIt, we are able to compute 30 metrics for projects, packages,\\nclasses, methods, types, members, and constructors. It is available in\\ntwo versions: standalone or integrated with eclipse [56]. A set of 16\\nobject-oriented metrics have been computed for each software systems\\nin the dataset. The set of metrics related to different levels and quality\\ndimensions as can be seen in Table 3. The set of chosen metrics are\\ncommon in the literature [12–14] for design smell detection.\\n3.2.2. Design smell detection tools\\nA large set of tools has been proposed for design smell detection\\naccording to the literature in [57] in order to help software develop-\\ners towards their enhancement of software quality. These tools have\\nvarious features as follows: Metric tools-which checks if it is available,\\nopen source or not, working environment (standalone or plug-in),\\nsupporting different languages, detection technique, and are designed\\nto detect different types of design smells. From this study, to select the\\ncandidate tools, we followed a set of criteria that include: 𝑠𝑢𝑝𝑝𝑜𝑟𝑡𝑖𝑛𝑔\\n𝐽𝑎𝑣𝑎,𝑎𝑣𝑎𝑖𝑙𝑎𝑏𝑙𝑒 ,𝑑𝑒𝑡𝑒𝑐𝑡𝑖𝑛𝑔 𝐺𝑜𝑑 𝐶𝑙𝑎𝑠𝑠 , and it should have a ℎ𝑖𝑔ℎ 𝑑𝑒𝑡𝑒𝑐𝑡𝑖𝑜𝑛\\n𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 . According to the criteria, the results shows a large list of\\ntools and prototypes. Therefore, we decide to avoid prototypes and\\nonly focus on fully automatic tools. From this list, we have chosen\\na collection of five tools that include: 𝑖𝑃 𝑙𝑎𝑠𝑚𝑎 ,𝐷𝐸𝐶𝑂𝑅 ,𝐽𝐷𝑒𝑜𝑑𝑜𝑟𝑎𝑛𝑡 ,\\n𝑃 𝑀𝐷 , and 𝑇 𝑜𝑔𝑒𝑡ℎ𝑒𝑟 . This set of tools is represented as the most cited\\n4http://RefactorIt.sourceforge.net.Table 3\\nDefinition of chosen metrics.\\nNo. Metric Definition Granularity level Dimension\\nM1 TLOC Total Lines of Code Project Size\\nM2 NCLOC Non-Comment Lines of Code Project Size\\nM3 CLOC Comment Lines of Code Project Size\\nM4 EXEC Executable Statements Project Complexity\\nM5 DC Density of Comments Project Complexity\\nM6 NOT Number of Typ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 616: ('collection of five tools that include: 𝑖𝑃 𝑙𝑎𝑠𝑚𝑎 ,𝐷𝐸𝐶𝑂𝑅 ,𝐽𝐷𝑒𝑜𝑑𝑜𝑟𝑎𝑛𝑡 ,\\n𝑃 𝑀𝐷 , and 𝑇 𝑜𝑔𝑒𝑡ℎ𝑒𝑟 . This set of tools is represented as the most cited\\n4http://RefactorIt.sourceforge.net.Table 3\\nDefinition of chosen metrics.\\nNo. Metric Definition Granularity level Dimension\\nM1 TLOC Total Lines of Code Project Size\\nM2 NCLOC Non-Comment Lines of Code Project Size\\nM3 CLOC Comment Lines of Code Project Size\\nM4 EXEC Executable Statements Project Complexity\\nM5 DC Density of Comments Project Complexity\\nM6 NOT Number of Types Package Complexity\\nM7 NOTa Number of Abstract Types Package Complexity\\nM8 NOTc Number of Concrete Types Package Complexity\\nM9 NOTe Number of Exported Types Package Complexity\\nM10 RFC Response for Class Class Coupling\\nM11 WMC Weighted Methods per Class Class Complexity\\nM12 DIT Depth in Tree Class Inheritance\\nM13 NOC Number of Children in Tree Class Inheritance\\nM14 DIP Dependency Inversion Principle Class Coupling\\nM15 LCOM Lack of Cohesion of Methods Class Cohesion\\nM16 NOA Number of Attributes Class Size\\nworks in the context of design smell detection according to our previous\\nwork in [1]. A brief description of the aforementioned tools is given in\\nthe next paragraphs.\\nDECOR [7] is an approach for specifying and detecting 6 types of\\ndesign smells/antipaterns based on a mixture of semantic and metric\\nrules. Definition of design smell is expressed using a custom lan-\\nguage called Domain Specific Language (DSL). Decor uses the design\\nsmell definition expressed in DSL to generates the detection code\\nautomatically. DETEX is the name of an instantiation of the DECOR\\napproach.\\niPlasma [6] is an open source integrated environment for soft-\\nware systems quality analysis. It calculates 80 metrics and detects 21\\ndifferent types of design smells for software systems developed using\\nJava and C++. Also, it can detect God Class from the source code by\\nmetric-based strategy that incorporates three well-known metrics.\\nJDeodorant [18] is an Eclipse plug-in tool that can detect automat-\\nically 5 types of design smells in software', 'A comparison of machine learning algorithms on design smell detection.pdf'), 617: ('. DETEX is the name of an instantiation of the DECOR\\napproach.\\niPlasma [6] is an open source integrated environment for soft-\\nware systems quality analysis. It calculates 80 metrics and detects 21\\ndifferent types of design smells for software systems developed using\\nJava and C++. Also, it can detect God Class from the source code by\\nmetric-based strategy that incorporates three well-known metrics.\\nJDeodorant [18] is an Eclipse plug-in tool that can detect automat-\\nically 5 types of design smells in software systems implemented in Java.\\nIn addition to the design smell detection activity, it can resolves the de-\\ntected problem by applying effective automatic refactoring. JDeodorant\\nuses clustering algorithm to find the God Classes in software systems\\nthat leads to apply the ‘‘Extract class’’ refactoring operation.\\nPMD [20] is developed as standalone or plugin environment to\\ndetect 3 types of design smells in software systems implemented in\\nJava, Javascript, and other languages. This tool is mutual with iPlasma\\nin the metrics combination that used to detect God Class but with\\ndifferent threshold values. In addition, it is the only tool that has a\\ncommand-line interface while the rest require to be used through a\\ngraphical user interface (GUI).\\nTogether [19] is a commercial Integrated Development Environ-\\nment (IDE) designed to support software architects and developers,\\nand incorporates an automated tool for code smell detection. The tool\\ncan detect 11 types of design smells and compute 55 different quality\\nmetrics for software systems implemented in Java and C++. Together\\ncan detect God Class from source code or UML diagrams using a\\ncombination of different metrics.\\n3.3. Data analysis\\nIn this section, we give a description of the methodology that has\\nbeen employed throughout this paper to analyze the collected data, and\\nin order to answer the research questions. Several stages have been used\\nto illustrate how the methodology has been applied and an explanation\\nis given further on with a representation that is shown', 'A comparison of machine learning algorithms on design smell detection.pdf'), 618: ('s for software systems implemented in Java and C++. Together\\ncan detect God Class from source code or UML diagrams using a\\ncombination of different metrics.\\n3.3. Data analysis\\nIn this section, we give a description of the methodology that has\\nbeen employed throughout this paper to analyze the collected data, and\\nin order to answer the research questions. Several stages have been used\\nto illustrate how the methodology has been applied and an explanation\\nis given further on with a representation that is shown in Fig. 1.\\nStage1: Dataset building. After obtaining the software systems\\nfrom the repositories, we used the metrics tool ‘‘RefactorIt’’ to analyze\\nthem and extract the set of required metrics. As mentioned in Sec-\\ntion 3.2.1, a set of 16 metrics have been extracted for each software\\nInformation and Software Technology 143 (2022) 106736\\n6K. Alkharabsheh et al.\\nFig. 1. Proposed methodology.\\nsystem, and the group of detection tools (iPlasma, Decor, JDeodorant,\\nPMD, and Together) was used as automatic early advisors for God Class\\ndetection.\\nThe strategy that was followed, was to label the detection tools\\nresult as follows: If one tool or more detects the class as God Class,\\nthen the label will be (1), otherwise (0). This strategy will increase\\nthe number of detected smells God Classes in the dataset reducing\\nthe probabilities of false negative. Afterwards, we applied a manual\\nvalidation process on the God Class list detected by one or more of\\nthe selected tools. A group of three experts with doctorate degree in\\ninformation technology (software engineering and computer science)\\nhave excellent experience with object-oriented programming, and very\\ngood knowledge of design smells accomplished the task. To label the\\nGod classes, the following strategy was followed: If two or more of the\\nexperts identified the class as a God Class, the class was taken to be\\nGod Class and the label given was (1), otherwise (0), with this manual\\nvalidation the probability of having false positives is reduced. Next, the\\nset of metrics and', 'A comparison of machine learning algorithms on design smell detection.pdf'), 619: ('\\ninformation technology (software engineering and computer science)\\nhave excellent experience with object-oriented programming, and very\\ngood knowledge of design smells accomplished the task. To label the\\nGod classes, the following strategy was followed: If two or more of the\\nexperts identified the class as a God Class, the class was taken to be\\nGod Class and the label given was (1), otherwise (0), with this manual\\nvalidation the probability of having false positives is reduced. Next, the\\nset of metrics and the manual validation results have been formulated\\nin rows. Each row consists of 16 metrics labeled M1 to M16 plus a label\\nthat presents the manual validation results as a binary decision to show\\nif it is God Class or not.\\nStage2: Dataset preparation. In this stage, we conducted data\\npreprocessing steps to fill the missing values with the corresponding\\nfeature average, and normalize the data in range [0, 1] because thereare some algorithms cannot handle negative value. Then the prepared\\ndata was used as an input source to train, validate, and test the machine\\nlearning classifiers used in this study. The training process required\\nenough data samples in order to capture the data pattern behavior\\nand guarantee a very good learning process, while the validation step\\nused for tune the classifiers hyper-parameters by selecting the suitable\\nvalues that can fit with the ML problem. Finally, the evaluation of the\\nML can be performed in the testing phase, which give an indication\\nhow good the trained classifier is. Next, a feature selection process\\nwas conducted to avoid the non-significant metrics from the whole set\\n(M1 to M16) and which may negatively influence the accuracy and\\nperformance of the model. For this purpose, we used the R package\\nRminer [ 58], that allows to calculate the importance of each feature\\nfor a given classifier or regressor, providing a wide list of available\\nmodels. Specifically, we calculated these importances for the rpart\\nclassifier, selected by its speed and easy configuration (it has no tu', 'A comparison of machine learning algorithms on design smell detection.pdf'), 620: ('xt, a feature selection process\\nwas conducted to avoid the non-significant metrics from the whole set\\n(M1 to M16) and which may negatively influence the accuracy and\\nperformance of the model. For this purpose, we used the R package\\nRminer [ 58], that allows to calculate the importance of each feature\\nfor a given classifier or regressor, providing a wide list of available\\nmodels. Specifically, we calculated these importances for the rpart\\nclassifier, selected by its speed and easy configuration (it has no tunable\\nhyper-parameter). The classifier choice should not condition the feature\\nimportance, that should not depend on the classifier used to calculate it,\\ni.e., the importance is expected to be similar using different classifiers.\\nIn general, it is expected to detect a few numbers of God Class design\\nsmells compared to the total classes that will be analyzed.\\nThe detected numbers of God Classes have been distributed between\\nthe training, validation, and testing sets. The low fraction of smells\\nin these sets leads to an imbalanced classification problem in what\\nInformation and Software Technology 143 (2022) 106736\\n7K. Alkharabsheh et al.\\nTable 4\\nList of the classifiers, with their tunable hyper-parameters and their tried values.\\nClassifier Hyperp. (values) Classifier Hyperp. (values)\\nLGBM lr =0.05, n_estimators =200\\nnum_leaves =300, max_depth =25GB lr =0.01, max_features =7\\nmax_depth =10\\nmin_samples_split =200\\nmin_samples_leaf′=50\\nXGB gamma =0.4, reg_lambda =1, reg_alpha =0.1\\nlr=0.25, n_estimators =100, max_depth =17Ridge alpha =0.001, solver =lsqr\\nCBoost max_depth =8, lr =0.01\\nl2_leaf_reg =10LDA solver =svd\\nRF n_estimators =500, criterion =entropy\\nmax_depth =300, min_samples_split =4\\nmin_samples_leaf =7NB –\\nBagging criterion =entropy, max_depth =20\\nmax_features =sqrt, min_samples_leaf =3\\nmin_samples_split =6LR C =90, solver =newton-cg\\nXGBRF gamma =0.2, max_depth =19, lr =0.01\\nmin_child_weight =3, n_estimators =10\\nnum_parallel_tree =10, reg_lambda =0.01\\nreg_alpha =0.1SGD alpha =0.0005, lr =0.001\\nl1_ratio =0.0004\\n', 'A comparison of machine learning algorithms on design smell detection.pdf'), 621: ('th =17Ridge alpha =0.001, solver =lsqr\\nCBoost max_depth =8, lr =0.01\\nl2_leaf_reg =10LDA solver =svd\\nRF n_estimators =500, criterion =entropy\\nmax_depth =300, min_samples_split =4\\nmin_samples_leaf =7NB –\\nBagging criterion =entropy, max_depth =20\\nmax_features =sqrt, min_samples_leaf =3\\nmin_samples_split =6LR C =90, solver =newton-cg\\nXGBRF gamma =0.2, max_depth =19, lr =0.01\\nmin_child_weight =3, n_estimators =10\\nnum_parallel_tree =10, reg_lambda =0.01\\nreg_alpha =0.1SGD alpha =0.0005, lr =0.001\\nl1_ratio =0.0004\\nET max_depth =400, min_samples_split =4\\nn_estimators =500LSVM C =100.0, loss =hinge\\nAB lr =0.9, n_estimators =800 PA C =0.01\\nMLP activation =tanh, lr =0.04\\nhidden_layer_sizes =(29, 40, 2)Percep-\\ntronalpha =0.0005, penalty =l1\\nDT criterion =entropy, min_samples_split =5\\nmax_depth =20, min_samples_leaf =3QDA reg_param =0.001\\nNu-SVM gamma =10.0, nu =0.02 BNB –\\nSVM C =100.0, gamma =0.1, kernel =rbf GNB –\\nKNN n_neighbors =4 CNB –\\nGP length_scale =2, nu =2.6 MNB alpha =1e−05, fit_prior=False\\nlow classification performance is expected. Therefore, we decided to\\nconduct two different experiments, without dataset balancing (Experi-\\nment 1) and with dataset balancing (Experiment 2) to check whether\\nthe performance of the classifiers will be influenced or not, therefore,\\nreflecting on the detection accuracy through performance indicators\\npreviously mentioned.\\nThe Synthetic Minority Oversampling Technique (SMOTE) [58] has\\nbeen used in experiment 2 to solve the imbalanced dataset problem,\\nwhere the distribution of a class is heterogeneous with other classes.\\nBalancing both classes (God Class/Not God Class) in the training set was\\nperformed. The parameter K (number of nearest neighbors) in SMOTE\\nwas tuned by executing KNN on the training set with values K=1,2,3,\\n. ..,12. The value of K that provides the highest performance is selected\\nfor SMOTE.\\nStage3: Models training and hyper-parameters tuning. As men-\\ntioned previously, 10-folds cross-validation were generated to train,\\nhyper-parameter tuning, and evaluate the models. Mos', 'A comparison of machine learning algorithms on design smell detection.pdf'), 622: ('is heterogeneous with other classes.\\nBalancing both classes (God Class/Not God Class) in the training set was\\nperformed. The parameter K (number of nearest neighbors) in SMOTE\\nwas tuned by executing KNN on the training set with values K=1,2,3,\\n. ..,12. The value of K that provides the highest performance is selected\\nfor SMOTE.\\nStage3: Models training and hyper-parameters tuning. As men-\\ntioned previously, 10-folds cross-validation were generated to train,\\nhyper-parameter tuning, and evaluate the models. Most of the classi-\\nfiers have a set of hyper-parameters that need to be tuned-which also\\nhave a significant influence on the behavior and performance of the\\nmachine learning model. Therefore, we used 10-fold cross-validation to\\nfind the best suitable value for each parameter based on the description\\nfor each classifier [55]. For each algorithm, the hyper-parameters were\\ntuned using the obtained values reported in Table 4. The selected final\\nvalues for the hyper-parameter are those that maximize the average\\nperformance over the validation sets.\\nStage 4: Testing all models and selecting the best classifier.\\nFinally, each trained classifier has been evaluated over testing data\\nfold in terms of both accuracy and performance using different metrics\\nsuch as Cohen’s Kappa, ROC area, precision, F-measure, and Matthews\\nCorrelation Coefficient (MCC), respectively.\\nAccording to [1], the selected performance measures are well-\\nknown and widely used for this purpose. Accuracy is the ratio of\\ninstances that are correctly classified (true positive and true negative).Table 5\\nInterpretation of the Cohen kappa values.\\nKappa value Agreement\\n𝑘 <0.20 Poor\\n0.21≤𝑘 <0.40 Weak\\n0.41≤𝑘 <0.60 Moderate\\n0.61≤𝑘 <0.80 Good\\n0.81≤𝑘≤1.00 Very Good\\nIn our case, it is the ratio of classes that are predicted correctly as\\n(God Class/Not God Class). This performance indicator is not enough to\\ndecide that the classification model is good, especially, if the classified\\ninstances is imbalanced. In this study, we have studied an comparing\\nperformance measu', 'A comparison of machine learning algorithms on design smell detection.pdf'), 623: ('ssified (true positive and true negative).Table 5\\nInterpretation of the Cohen kappa values.\\nKappa value Agreement\\n𝑘 <0.20 Poor\\n0.21≤𝑘 <0.40 Weak\\n0.41≤𝑘 <0.60 Moderate\\n0.61≤𝑘 <0.80 Good\\n0.81≤𝑘≤1.00 Very Good\\nIn our case, it is the ratio of classes that are predicted correctly as\\n(God Class/Not God Class). This performance indicator is not enough to\\ndecide that the classification model is good, especially, if the classified\\ninstances is imbalanced. In this study, we have studied an comparing\\nperformance measures when using imbalanced and balanced datasets.\\nIn the context of this study, accuracy is computed by dividing the num-\\nber of correct prediction to the total number of prediction, multiplied\\nby 100%.\\nCohen’s Kappa [59] is another essential performance indicator that\\nwas used in this study. Cohen kappa is used to measure the agreement\\nbetween the true label of instance and the one predicted by the selected\\nclassifier. The kappa values range from −1 to 1. The interpretation of\\nCohens kappa values is shown in Table 5 where kappa result of all\\nclassifiers is shown in percentages.\\nReceiver Operating Characteristic (ROC) area [60] is a good mea-\\nsure to visualize the performance of an classifier. It is a plot that\\ncompares the sensitivity (true positive rate) of the classifier against the\\nspecificity (false positive rate). Table 6 show the interpretation of ROC\\nvalues. When the value is close to 1, the classifier performance is better.\\nPrecision indicates the portion of correctly detected God Classes\\nwithin the set of all detected God Classes. The precision result range\\nwas between 0 and 1.\\nInformation and Software Technology 143 (2022) 106736\\n8K. Alkharabsheh et al.\\nTable 6\\nInterpretation of the ROC area.\\nROC value Interpretation\\n0.5< 𝑅𝑂𝐶 ≤0.6 Fail\\n0.6< 𝑅𝑂𝐶 ≤0.7 Poor\\n0.7< 𝑅𝑂𝐶 ≤0.8 Fair\\n0.8< 𝑅𝑂𝐶 ≤0.9 Good\\n0.9< 𝑅𝑂𝐶 ≤1 Excellent\\nF-measure is a classical method of evaluating the performance of\\nthe classifier. It combines the precision and recall into one metric. We\\nused the F-measure for a trade-off between the classi', 'A comparison of machine learning algorithms on design smell detection.pdf'), 624: ('et of all detected God Classes. The precision result range\\nwas between 0 and 1.\\nInformation and Software Technology 143 (2022) 106736\\n8K. Alkharabsheh et al.\\nTable 6\\nInterpretation of the ROC area.\\nROC value Interpretation\\n0.5< 𝑅𝑂𝐶 ≤0.6 Fail\\n0.6< 𝑅𝑂𝐶 ≤0.7 Poor\\n0.7< 𝑅𝑂𝐶 ≤0.8 Fair\\n0.8< 𝑅𝑂𝐶 ≤0.9 Good\\n0.9< 𝑅𝑂𝐶 ≤1 Excellent\\nF-measure is a classical method of evaluating the performance of\\nthe classifier. It combines the precision and recall into one metric. We\\nused the F-measure for a trade-off between the classifiers.\\nThe final assessment indicator is the Matthews Correlation Coeffi-\\ncient (MCC) [61]. It is used to measure the binary quality between the\\nobserved and predicted classifications. The MCC range from −1 to 1 in\\nwhich the higher the value (1) of the coefficient, indicates the stronger\\nthe correlation (i.e. agreement between prediction and observation).\\nIf the value is zero, then no correlation, and a disagreement between\\nprediction and observation when the value is ( −1).\\nIn the conducted experiments, the Wilcoxon rank-sum test [62] was\\nused to assess separately the difference between the accuracy, kappa, F-\\nmeasure, precision, ROC, and MCC values achieved by the 28 classifiers\\nwith and without data balancing. The null hypothesis of the accuracy\\ntest is: The accuracy comes from distributions with equal mean with\\nand without data balancing (i.e. classifiers have the same behavior\\non God Class detection with and without data balancing), the same\\nhypothesis is tested for kappa, F-measure, precision, ROC and MCC.\\nWhen the 𝑝-value is less than 0.05, we reject the null hypothesis, so\\nthe difference between cases is statistically significant. This measure is\\nwidely used for this purpose according to existing literature [14,29,63–\\n65].\\nAll necessary information for replicating the work, such as data\\ndescription, raw data, and scripts is available in the replication pack-\\nage [25].\\n4. Results analysis\\nThe obtained results that were used to statistically study the hy-\\npotheses in this paper are discussed in this secti', 'A comparison of machine learning algorithms on design smell detection.pdf'), 625: ('CC.\\nWhen the 𝑝-value is less than 0.05, we reject the null hypothesis, so\\nthe difference between cases is statistically significant. This measure is\\nwidely used for this purpose according to existing literature [14,29,63–\\n65].\\nAll necessary information for replicating the work, such as data\\ndescription, raw data, and scripts is available in the replication pack-\\nage [25].\\n4. Results analysis\\nThe obtained results that were used to statistically study the hy-\\npotheses in this paper are discussed in this section. In the first sub-\\nsection, we analyzed and discussed the results of the selected detection\\ntools and manual validation that we used to assign a label of the classes\\n(Dataset building), while in the second, we focus on the performance\\nof the classifiers (Dataset formulation, tuning hyper-parameter, and\\ntesting the models) that will answer the formulated research questions.\\n4.1. God class detection\\nTable 7 shows a summary of the God Class detection results using\\nautomatic detection tools (GC-tool) and the manual validation (GC-\\nmanualvalidation) for each software system according to the labeling\\nstrategy mentioned in stage one (Dataset Building) of the proposed\\nmethodology in Section 3.3. According to the initial tool labeling\\nstrategy, a set of 1958 God Classes have been detected in the software\\nsystems, which is the maximum number of smells detected in the whole\\ndataset. After applying the labeling strategy of the manual validation\\non the detection tools results, only 485 God Classes (out of 1958) were\\nfound and representing 4% of the whole dataset (12,587). This ratio is\\nnormal and confirms previous conclusions in the literature about the\\nlow degree of agreement on design smell detection between different\\nevaluators (humans, tools, and human vs. tools) [40,41]. This com-\\nbined labeling method helps in first reducing the probability of false\\nnegatives, and after that, reducing the probability of false positives, as\\nmentioned before. The largest number of God Classes were detected\\nusing tools in Jasperreport', 'A comparison of machine learning algorithms on design smell detection.pdf'), 626: ('und and representing 4% of the whole dataset (12,587). This ratio is\\nnormal and confirms previous conclusions in the literature about the\\nlow degree of agreement on design smell detection between different\\nevaluators (humans, tools, and human vs. tools) [40,41]. This com-\\nbined labeling method helps in first reducing the probability of false\\nnegatives, and after that, reducing the probability of false positives, as\\nmentioned before. The largest number of God Classes were detected\\nusing tools in Jasperreport 4.7.1 while the lowest number in Plugfy-\\n0.6. On the other hand, using manual validation, the largest number ofGod Classes was detected in Xena 6.1.0 while no God Class was detected\\nin the group of (AngryIPScanner-3.0, checkstyle-6.2.0, FullSync-0.10.2,\\nJCLEC-4.0.0, Plugfy-0.6,). The full details about the numbers of God\\nClass detected by each tool in each software system found in the data\\ndescription part at the replication package [25].\\nTable 8 shows the number of detection tools against the number\\nof God Classes detected by tools, manual validation, and the ratio of\\nGod Classes (manual validation) over the whole dataset. As can be\\nseen, the higher the number of detection tools, the lower the number\\nof detected God Classes. Therefore, the gap between both labels (God\\nClass/Not God Class) is increased, and the imbalanced dataset problem\\nwill be more complex. According to [17], in their study, state that if\\nthe dataset is exceptionally imbalanced, the best balancing techniques\\nfails although permits the model to be more accurate, because the\\nmodel is difficult to be applicable due to the few number of label that\\nbelonging to the minority class (God Class in our case). It is important\\nthat the dataset includes a large number of design smells in order\\nto train the learning classifiers on a good training set. Therefore, the\\nclassifier obtains a better behavior. The last row of Table 8 reports\\nthe Pearson correlations between the number of God Classes detected\\nfor each number of tools and the number of God classes', 'A comparison of machine learning algorithms on design smell detection.pdf'), 627: ('l to be more accurate, because the\\nmodel is difficult to be applicable due to the few number of label that\\nbelonging to the minority class (God Class in our case). It is important\\nthat the dataset includes a large number of design smells in order\\nto train the learning classifiers on a good training set. Therefore, the\\nclassifier obtains a better behavior. The last row of Table 8 reports\\nthe Pearson correlations between the number of God Classes detected\\nfor each number of tools and the number of God classes after manual\\nvalidation is 0.97 which is highly positive value show that whether the\\nnumber of God Classes detected by tools increased the number of God\\nClasses manually detected also increased.\\n4.2. Training the classifiers\\nIn this stage, after the dataset has been prepared to be ready for in-\\nputting to the classifiers, as the first step, we conducted an exploratory\\nexperiment before the main two experiments to investigates whether\\nthe using the whole set of metrics (M1 to M16) have an influence to\\nthe classifiers results. For this purpose, we assessed the importance\\nof each metric using the importance function in the rminer package,\\novercomes 0.5. Ten metrics were selected by the importance function:\\nTLOC, NCLOC, CLOC, WMC, RFC, EXEC, DIT, NOA, NOTc, and DC. In\\nthis experiment, the classifiers have been trained on the whole set of\\nmetrics and on the important set.\\nFig. 2 shows the Kappa, ROC, and MCC values of machine learning\\nperformance without data balancing using all the metrics and only the\\nimportant set. As it can be seen, a better performance is achieved using\\nthe whole set of metrics (blue line) compared with important set (red\\nline) in all figures, except the set of (BNB, CNB, GB) in the Kappa\\nand MCC tests, and the GB in the ROC area test where obtained a\\nslightly better performance. The differences between Kappa values of\\nall metrics (blue line) and the important set (red line) were analyzed\\nwith a Wilcoxon rank-sum test. The null hypothesis in this case were\\n‘‘Classifiers have the same behavior ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 628: (' set. As it can be seen, a better performance is achieved using\\nthe whole set of metrics (blue line) compared with important set (red\\nline) in all figures, except the set of (BNB, CNB, GB) in the Kappa\\nand MCC tests, and the GB in the ROC area test where obtained a\\nslightly better performance. The differences between Kappa values of\\nall metrics (blue line) and the important set (red line) were analyzed\\nwith a Wilcoxon rank-sum test. The null hypothesis in this case were\\n‘‘Classifiers have the same behavior on God Class detection using the\\nwhole and important set of metrics’’. The results show that the null\\nhypothesis is rejected, with a 𝑝-value (0.00016). Therefore, the result\\nis significant which means classifiers have different behavior. Also,\\nthe classifiers achieved better performance (better behavior) with the\\nwhole set of metrics in the ROC area and MCC tests. Therefore, the\\nnull hypothesis is rejected with a p-values (0.00001, 0.00008) for the\\nROC and MCC respectively. The same approach was followed in cases\\nof accuracy, precision, and F-measure tests where the null hypothesis\\nalso is rejected with p-values less than (0.00001). Due to the paper size,\\nwe do not show the figures of accuracy, precision, and F-measure Since\\nthe performance is better using the whole set of metrics.\\n4.2.1. Experiment 1: Without dataset balancing\\nIn this section, we will answered the first research question:\\nRQ1 To what extent can machine learning techniques be effectively lever-\\naged for God Class design smell detection?\\nInformation and Software Technology 143 (2022) 106736\\n9K. Alkharabsheh et al.\\nTable 7\\nDistribution of detected God Classes in the selected software systems using the set of tools (GC-tool) and manual validation (GC-ManualValidation) results.\\nProject GC-tools GC-manual Project GC-tools GC-manual\\nAngryIPScanner-3.0 2 0 JFreeChart-1.0.X 161 37\\nApeiron-2.92 16 1 JHotDraw-5.2 26 3\\ncheckstyle-6.2.0 21 0 KeyStore Explorer-5.1 47 12\\nDigiExtractor-2.5.2 27 2 Lucene-3.0.0 146 42\\nFreemind-1.0.1 42 23 Matte-1.7 32 6\\nFullSyn', 'A comparison of machine learning algorithms on design smell detection.pdf'), 629: ('mation and Software Technology 143 (2022) 106736\\n9K. Alkharabsheh et al.\\nTable 7\\nDistribution of detected God Classes in the selected software systems using the set of tools (GC-tool) and manual validation (GC-ManualValidation) results.\\nProject GC-tools GC-manual Project GC-tools GC-manual\\nAngryIPScanner-3.0 2 0 JFreeChart-1.0.X 161 37\\nApeiron-2.92 16 1 JHotDraw-5.2 26 3\\ncheckstyle-6.2.0 21 0 KeyStore Explorer-5.1 47 12\\nDigiExtractor-2.5.2 27 2 Lucene-3.0.0 146 42\\nFreemind-1.0.1 42 23 Matte-1.7 32 6\\nFullSync-0.10.2 13 0 Mpxj-4.7 137 57\\nGanttProject-2.0.10 167 15 OmegaT-3.1.8 194 27\\nJasperReports-4.7.1 311 81 Plugfy-0.6 1 0\\njAudio-1.0.4 122 21 pmd-4.3.x 29 10\\nJava graphplan-1.0.7 18 3 sMeta-1.0.3 20 4\\nJCLEC-4.0.0 88 0 SQuirreL SQL Client-3.7.1 89 20\\nJDistlib-0.3.8 22 14 xena-6.1.0 227 107\\nTotal #GC-tools 1958\\nTotal #GC-manual 485\\nTable 8\\nThe number of God Classes detected by tools, human, and their ratio against the whole\\ndataset.\\n#Tools #GC-tools GC-manual Manual/WholeDataset (%)\\n1 1419 229 1.8%\\n2 300 99 0.78%\\n3 160 89 0.71%\\n4 55 45 0.36%\\n5 24 23 0.17%\\nAlltools 1958 485 4%\\nCorrelation 0.97\\nTable 9\\nAccuracy, Kappa, F-measure, Precision, ROC. and MCC performance values achieved\\nby each classifier without dataset balancing.\\nClassifier Accuracy F-measure Precision Kappa ROC MCC\\n1 CBoost. 99.1579 0.9916 0.9918 0.8880 0.9508 0.8885\\n2 RF. 99.1261 0.9913 0.9913 0.8823 0.9426 0.8826\\n3 XGBRF. 99.1102 0.9911 0.9912 0.8798 0.9415 0.8802\\n4 LGBM. 99.0864 0.9908 0.9909 0.8755 0.9373 0.8761\\n5 XGB. 99.0863 0.9909 0.9909 0.8767 0.9404 0.8770\\n6 Bagging. 98.9672 0.9896 0.9896 0.8585 0.9274 0.8591\\n7 ET. 98.8719 0.9887 0.9887 0.8476 0.9209 0.8480\\n8 AB. 98.8480 0.9882 0.9882 0.8384 0.9065 0.8398\\n9 MLP. 98.8083 0.9881 0.9883 0.8396 0.9215 0.8409\\n10 GP. 98.6415 0.9862 0.9862 0.8124 0.8963 0.8133\\n11 KNN. 98.6018 0.9857 0.9856 0.8026 0.8820 0.8044\\n12 SVM. 98.5620 0.9856 0.9858 0.8071 0.9042 0.8077\\n13 SGD. 98.5382 0.9846 0.9848 0.7822 0.8578 0.7883\\n14 LR. 98.3555 0.9826 0.9826 0.7526 0.8395 0.7590\\n15 DT. 98.3396 0.9832 0.9832 0.7711 0.8798 ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 630: ('0.9404 0.8770\\n6 Bagging. 98.9672 0.9896 0.9896 0.8585 0.9274 0.8591\\n7 ET. 98.8719 0.9887 0.9887 0.8476 0.9209 0.8480\\n8 AB. 98.8480 0.9882 0.9882 0.8384 0.9065 0.8398\\n9 MLP. 98.8083 0.9881 0.9883 0.8396 0.9215 0.8409\\n10 GP. 98.6415 0.9862 0.9862 0.8124 0.8963 0.8133\\n11 KNN. 98.6018 0.9857 0.9856 0.8026 0.8820 0.8044\\n12 SVM. 98.5620 0.9856 0.9858 0.8071 0.9042 0.8077\\n13 SGD. 98.5382 0.9846 0.9848 0.7822 0.8578 0.7883\\n14 LR. 98.3555 0.9826 0.9826 0.7526 0.8395 0.7590\\n15 DT. 98.3396 0.9832 0.9832 0.7711 0.8798 0.7724\\n16 LSVM. 98.3078 0.9822 0.9821 0.7473 0.8392 0.7529\\n17 PA. 98.2522 0.9815 0.9816 0.7366 0.8307 0.7446\\n18 LDA. 98.2363 0.9809 0.9812 0.7243 0.8162 0.7353\\n19 Nu-SVM. 98.1929 0.9820 0.9822 0.7670 0.8872 0.7676\\n20 NC. 98.1410 0.9818 0.9824 0.7095 0.8974 0.7624\\n21 QDA. 97.5689 0.9770 0.9792 0.7095 0.8975 0.7149\\n22 Perceptron. 97.4021 0.9739 0.9768 0.6428 0.8497 0.6624\\n23 Ridge. 97.2750 0.9665 0.9711 0.4679 0.6621 0.5340\\n24 GNB. 96.9572 0.9732 0.9810 0.6901 0.9569 0.7159\\n25 MNB. 96.1548 0.9431 0.9366 0.1094 0.5029 0.0384\\n26 GB. 96.1469 0.9426 0.9244 0.0000 0.5000 0.0000\\n27 BNB. 87.8923 0.9117 0.9694 0.3411 0.9232 0.4472\\n28 CNB. 75.5304 0.8303 0.9614 0.1659 0.8252 0.2811\\nThe classification in this experiment has been performed with the\\noriginal dataset where the God Classes are randomly distributed on\\ntraining, validation, and testing sets. Table 9 reports the Accuracy,\\nKappa, F-measure, Precision, ROC, and MCC values for each classifier\\nwith the best configuration that has been selected with 10-fold cross-\\nvalidation. The results sorted by decreasing order to the accuracy\\nvalues.\\nAll classifiers have achieved high performance values with a few\\nexceptions. The accuracy, precision, and F-measure values of all theclassifiers were high on average 97%, 97.9%, and 97.3% respectively,\\ncompared with kappa 68.9%, ROC 85.9%, and MCC 70.3%. CBoost\\nis one of the Boosting family classifiers that achieved the highest\\nperformance values in all metrics except ROC, while CNB from Naive\\nBayes achieved the lowest performance in ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 631: ('alidation. The results sorted by decreasing order to the accuracy\\nvalues.\\nAll classifiers have achieved high performance values with a few\\nexceptions. The accuracy, precision, and F-measure values of all theclassifiers were high on average 97%, 97.9%, and 97.3% respectively,\\ncompared with kappa 68.9%, ROC 85.9%, and MCC 70.3%. CBoost\\nis one of the Boosting family classifiers that achieved the highest\\nperformance values in all metrics except ROC, while CNB from Naive\\nBayes achieved the lowest performance in accuracy. F-measure and GB\\nfrom the Boosting the lowest performance in kappa, precision, ROC,\\nand MCC. The high performance may be related to the features of\\nthese metrics (accuracy, precision, and F-measure) that consider the\\ncapability of the classifier model to classify the true negative and pos-\\nitive classes. Although the accuracy, F-measure, and precision results\\nof most classifiers are high, it is not enough definitely to indicate the\\nadvantage of using machine learning classifiers [22,23]. For this reason,\\nwe included the kappa, ROC, and MCC tests as explained before.\\nThe kappa values are shown in the fifth column of Table 9. More\\nthan 78% (22 out of 28) of the classifiers have achieved kappa greater\\nthan (66%). Especially, the set of CBoost, RF, XGBRF, XGB, LGBM, and\\nBagging has obtained the best results (>85%), which interpreted as\\nvery good behavior. The higher value was 88.8% achieved by CBoost\\nwhile the lower value was zero by GB. Also, as it can be seen, 93%\\nof the classifiers (26 out of 28) were achieved ROC values greater than\\n80%, and 50% of this set (13 out of 26) greater than 90% which means\\naccording to the ROC interpretation shown in Table 6 that classifiers\\nhave been obtained good to excellent behavior. The higher ROC value\\nwas 96% achieved by GNB while the lower value was 50% by GB. The\\nlast column of the table shows the MCC values for each classifier. Near\\nto 42% of classifiers have achieved MCC greater than 80% (12 out of\\n28), which means that classifiers have very good agreement in God', 'A comparison of machine learning algorithms on design smell detection.pdf'), 632: ('e achieved ROC values greater than\\n80%, and 50% of this set (13 out of 26) greater than 90% which means\\naccording to the ROC interpretation shown in Table 6 that classifiers\\nhave been obtained good to excellent behavior. The higher ROC value\\nwas 96% achieved by GNB while the lower value was 50% by GB. The\\nlast column of the table shows the MCC values for each classifier. Near\\nto 42% of classifiers have achieved MCC greater than 80% (12 out of\\n28), which means that classifiers have very good agreement in God\\nClass prediction. CBoost has obtained the higher value (88.9%) while\\nthe GB the lowest value (50%)\\nBased on above, we find the vast majority of machine learning\\nclassifiers have achieved high and accurate performance values ac-\\ncording to the accuracy, Kappa, precision, F-measure, ROC, and MCC\\nmeasurements, such as CBoost, RF, and XGBRF because it is represents\\nthe natural scenario when detection design smells. Therefore, we con-\\nclude that machine learning techniques effectively can be leveraged\\nfor God Class design smell detection. The null hypothesis: (Machine\\nlearning techniques cannot be effectively leveraged for God Class design\\nsmell detection.) is rejected.\\n4.2.2. Experiment 2: With dataset balancing\\nThis section will answered the second research question:\\nRQ2 To what extent can avoiding data balancing have an influence to the\\naccuracy of God Class design smell detection?\\nThe second experiment was developed over balanced data, where\\nSMOTE has been used to balance the training data as aforementioned\\nin stage 2. Table 10 reports the performance values for each classifier\\nwith the best configuration that has been selected with 10-fold cross-\\nvalidation. Also, the results sorted by decreasing order to the accuracy\\nvalues.\\nInformation and Software Technology 143 (2022) 106736\\n10K. Alkharabsheh et al.\\nFig. 2. Top: Kappa values with all the metrics and important metrics sorted by decreasing values of the former. Middle: ROC values with all the metrics and important metrics\\nsorted by decreasing values of the f', 'A comparison of machine learning algorithms on design smell detection.pdf'), 633: ('n stage 2. Table 10 reports the performance values for each classifier\\nwith the best configuration that has been selected with 10-fold cross-\\nvalidation. Also, the results sorted by decreasing order to the accuracy\\nvalues.\\nInformation and Software Technology 143 (2022) 106736\\n10K. Alkharabsheh et al.\\nFig. 2. Top: Kappa values with all the metrics and important metrics sorted by decreasing values of the former. Middle: ROC values with all the metrics and important metrics\\nsorted by decreasing values of the former. Bottom: MCC values with all the metrics and important metrics sorted by decreasing values of the former.\\nAll classifiers have achieved high performance values on average\\nfor 96.1% for accuracy, 71% for kappa, 96.8% for F-measure, 98.1%\\nfor precision, 92.6% for ROC, and 72.9% for MCC respectively. LGBM,\\nXGBRF, XGB from the Boosting family are the classifiers that achieved\\nthe best performance, while the CNB and MNB of Naive Bayes fam-\\nily have achieved the lowest performance values. As it can be seen,\\ncomparing the average performance values of this experiment (with\\ndata balancing) with the first experiment (without data balancing), we\\nobserved its slightly better, in particular, the value of precision (97.9%\\nto 98.1%), kappa (68.9% to 71%), ROC (85.9% to 92.6%), and MCC\\n(70.3% to 72.9%), while the accuracy and F-measure have been slightly\\ndecreased from 97% to 96.1% and 97.3% to 96.8% respectively. The\\nachieved results after data balancing also confirm the answer to the\\nfirst research question (RQ1) that machine learning techniques can\\nbe leveraged effectively for God Class design smell detection. Afterusing SMOTE and comparing Tables 9 and 10, all classifiers obtained\\ndifferent order based on their accuracy. For example, in experiment 1\\n(without data balancing), LGBM has achieved the fifth rank in terms\\nof kappa, F-measure, precision, and MCC while in experiment 2 (with\\ndata balancing) it is full front to the first rank, i.e., the best classifier\\nwith data balancing in terms of accuracy, kappa, F-measur', 'A comparison of machine learning algorithms on design smell detection.pdf'), 634: ('at machine learning techniques can\\nbe leveraged effectively for God Class design smell detection. Afterusing SMOTE and comparing Tables 9 and 10, all classifiers obtained\\ndifferent order based on their accuracy. For example, in experiment 1\\n(without data balancing), LGBM has achieved the fifth rank in terms\\nof kappa, F-measure, precision, and MCC while in experiment 2 (with\\ndata balancing) it is full front to the first rank, i.e., the best classifier\\nwith data balancing in terms of accuracy, kappa, F-measure, and pre-\\ncision. Table 11 shows the confusion matrices, the Kappa and ROC (in\\npercentage) of LGBM classifier over the 10-fold cross validation without\\n(left part) and with (right part) data balancing. LGBM achieves the best\\nKappa and ROC using data balancing (right part). Compared to the left\\npart, the changes rose slightly, where the percentage of true positives\\nis raises from 2.89% to 3.32%, while the false negatives reduces from\\n0.24% to 0.17%. However, the false positive rose from 0.45% to 0.55%,\\nwhile Kappa and ROC also rose slightly.\\nInformation and Software Technology 143 (2022) 106736\\n11K. Alkharabsheh et al.\\nTable 10\\nAccuracy, Kappa, F-measure, Precision, ROC, and MCC performance values achieved\\nby each classifier with dataset balancing.\\nClassifier Accuracy F-measure Precision Kappa ROC MCC\\n1 LGBM. 99.1261 0.9915 0.9918 0.8883 0.9621 0.8894\\n2 XGB. 99.0270 0.9905 0.9909 0.8796 0.9617 0.8938\\n3 CBoost. 98.9911 0.9902 0.9907 0.8732 0.9596 0.8747\\n4 RF. 98.9911 0.9901 0.9906 0.8729 0.9588 0.8743\\n5 Bagging. 98.8481 0.9890 0.9901 0.8615 0.9725 0.8658\\n6 XGBRF. 98.8243 0.9888 0.9900 0.8591 0.9736 0.8637\\n7 ET. 98.6019 0.9865 0.9876 0.8291 0.9492 0.8323\\n8 AB. 98.5789 0.9847 0.9850 0.8152 0.9188 0.8195\\n9 MLP. 98.3635 0.9841 0.9850 0.7956 0.9233 0.7982\\n10 DT. 98.1888 0.9825 0.9835 0.7755 0.9153 0.7780\\n11 Nu-SVM. 98.0297 0.9810 0.9820 0.7538 0.9040 0.7560\\n12 SVM. 97.9349 0.9797 0.9802 0.7416 0.8849 0.7422\\n13 KNN. 97.9187 0.9803 0.9824 0.7558 0.9253 0.7616\\n14 GP. 97.8554 0.9793 0.9804 0.7410 0.8987 0.7432\\n15 GB. 97', 'A comparison of machine learning algorithms on design smell detection.pdf'), 635: ('ng. 98.8481 0.9890 0.9901 0.8615 0.9725 0.8658\\n6 XGBRF. 98.8243 0.9888 0.9900 0.8591 0.9736 0.8637\\n7 ET. 98.6019 0.9865 0.9876 0.8291 0.9492 0.8323\\n8 AB. 98.5789 0.9847 0.9850 0.8152 0.9188 0.8195\\n9 MLP. 98.3635 0.9841 0.9850 0.7956 0.9233 0.7982\\n10 DT. 98.1888 0.9825 0.9835 0.7755 0.9153 0.7780\\n11 Nu-SVM. 98.0297 0.9810 0.9820 0.7538 0.9040 0.7560\\n12 SVM. 97.9349 0.9797 0.9802 0.7416 0.8849 0.7422\\n13 KNN. 97.9187 0.9803 0.9824 0.7558 0.9253 0.7616\\n14 GP. 97.8554 0.9793 0.9804 0.7410 0.8987 0.7432\\n15 GB. 97.7959 0.9788 0.9799 0.7347 0.8961 0.7371\\n16 Ridge. 97.6564 0.9774 0.9788 0.7118 0.8827 0.7153\\n17 LDA. 97.5453 0.9764 0.9779 0.7001 0.8793 0.7038\\n18 NC. 97.3249 0.9762 0.9786 0.7047 0.9103 0.7128\\n19 LR. 96.8700 0.9723 0.9797 0.6828 0.9466 0.7064\\n20 SGD. 96.7350 0.9713 0.9796 0.6755 0.9497 0.7019\\n21 LSVM. 96.6320 0.9706 0.9797 0.6776 0.9577 0.7065\\n22 PA. 96.6000 0.9704 0.9794 0.6681 0.9518 0.6968\\n23 Perceptron. 96.4967 0.9694 0.9784 0.6581 0.9391 0.6853\\n24 QDA. 96.3060 0.9680 0.9779 0.6444 0.9436 0.6749\\n25 BNB. 96.0757 0.9664 0.9779 0.6342 0.9503 0.6697\\n26 GNB. 95.4322 0.9618 0.9769 0.6004 0.9537 0.6456\\n27 CNB. 76.1262 0.8344 0.9616 0.1706 0.8292 0.2862\\n28 MNB. 76.1183 0.8343 0.9619 0.1718 0.8323 0.2886\\nTable 11\\nConfusion matrix, Kappa and ROC (in %) of the best classifier (LGBM) without data\\nbalancing (left part), and with data balancing (right part).\\nLGBM/without balancing LGBM/with balancing\\nNot-GodClass GodClass Not-GodClass GodClass\\nNot-GodClass 96.29 0.45 95.78 0.55\\nGodClass 0.24 2.89 0.17 3.32\\nKappa (%) ROC (%) Kappa (%) ROC (%)\\n87.6 93.7 88.8 96.2\\nFig. 3 shows the Kappa, ROC, and MCC values of classifiers with\\nand without data balancing. According to the ROC area figure, most of\\nclassifiers achieved slightly better performance when the training set is\\nbalanced (red line) compared with the imbalanced set (blue line) with\\nsome exception in case of GNB and SVM. On the other hand, according\\nto the values of kappa (Top figure) and MCC (Bottom figure), most of\\nclassifiers achieved better behavior without data b', 'A comparison of machine learning algorithms on design smell detection.pdf'), 636: ('ROC (%) Kappa (%) ROC (%)\\n87.6 93.7 88.8 96.2\\nFig. 3 shows the Kappa, ROC, and MCC values of classifiers with\\nand without data balancing. According to the ROC area figure, most of\\nclassifiers achieved slightly better performance when the training set is\\nbalanced (red line) compared with the imbalanced set (blue line) with\\nsome exception in case of GNB and SVM. On the other hand, according\\nto the values of kappa (Top figure) and MCC (Bottom figure), most of\\nclassifiers achieved better behavior without data balancing, despite the\\nslightly improvement in the remained classifiers. In general, we can say\\nthat classifiers have the same behavior on God Class detection with and\\nwithout data balancing.\\nA wilcoxon rank-sum test comparing kappa, ROC, MCC, accuracy,\\nprecision, and F-measure values with and without balancing separately\\nis used to test the null hypothesis ‘‘Avoiding data balancing will not\\ninfluence the accuracy of God Class design smell detection’’ . The test gives\\na p-values greater than 0.05 in terms of kappa (0.1585), precision\\n(0.2340), and MCC (0.2460) which means that the null hypothesis\\nis accepted because the difference between classifications with and\\nwithout balancing is not significant. On the other hand, The p-values\\nwere less than 0.05 in terms of accuracy, ROC, and F-measure. The\\ntest gives a p-values of 0.00054, 0.0010, and 0.00001 for accuracy, F-\\nmeasure and ROC respectively, which means the difference between\\nclassifications with and without balancing is statistically significant.\\nTherefore, the null hypothesis is rejected.\\nAlthough the null hypothesis is rejected, in the case of accuracy,\\nROC, and F-measure, the data balancing does not influence the perfor-\\nmance of the classifiers. Therefore, we concludes that data balancing\\nslightly influence the performance of the classifiers.Table 12\\nCharacteristics of projects in the first dataset used in the replication experiments.\\nProject&Version NOP NOC NOM TLOC God class\\nant-rel-1.8.3 80 1473 13,213 119,256 6\\nargouml-VERSION_0_14 94 1373 9045 199,', 'A comparison of machine learning algorithms on design smell detection.pdf'), 637: ('e, the null hypothesis is rejected.\\nAlthough the null hypothesis is rejected, in the case of accuracy,\\nROC, and F-measure, the data balancing does not influence the perfor-\\nmance of the classifiers. Therefore, we concludes that data balancing\\nslightly influence the performance of the classifiers.Table 12\\nCharacteristics of projects in the first dataset used in the replication experiments.\\nProject&Version NOP NOC NOM TLOC God class\\nant-rel-1.8.3 80 1473 13,213 119,256 6\\nargouml-VERSION_0_14 94 1373 9045 199,075 2\\ncassandra-cassandra-1.1.0 48 699 11,360 110,712 2\\napache-wicket-1.4.11 260 1568 12,429 174,033 4\\nderby-10.3.3.0 50 1746 5987 535,187 24\\nhadoop-release-0.2.0 20 327 2460 34,662 2\\nhsqldb-2.2.0 52 590 5004 254,014 11\\nincubator-livy-0.6.0-incubating 11 1016 450 130,696 6\\nnutch-release-0.7 53 532 3220 50,578 0\\nqpid-0.18 226 2172 21,448 189,271 6\\nxerces-Xerces-J_1_4_2 42 489 6088 150,445 6\\neclipse-R3_4 12 5061 924 423,423 25\\nelasticsearch-v0.19.0 570 1395 21,739 315,619 2\\nTotal 1518 18,441 113,367 2,686,971 96\\n5. Experiments replication\\nTo mitigate a threat of the study where results can be biased by a\\ndataset build by the authors themselves, in this section, the replication\\nof both experiments (1 and 2) is presented using the same set of\\nmachine learning classifiers and two different datasets proposed by\\nother authors to confirm machine learning classifiers could be lever-\\naged during design smell detection and analyzing the influence of data\\nbalancing on design smell detection.\\n5.1. Data collection\\nThe new datasets are constructed on the basis of datasets used in\\nthe literature. The first dataset is previously used in [16,66] while the\\nsecond dataset points in the work by [21]. Both datasets consists of\\nmanually validated instances of design smells, where the God Class\\nis one of those smells. These datasets are available at the replication\\npackage [25]. The format of the new datasets is changed by including\\nthe same set of metrics shown in Table 3 of Section 3.2.1, in order\\nto be in the same format of the dat', 'A comparison of machine learning algorithms on design smell detection.pdf'), 638: ('datasets are constructed on the basis of datasets used in\\nthe literature. The first dataset is previously used in [16,66] while the\\nsecond dataset points in the work by [21]. Both datasets consists of\\nmanually validated instances of design smells, where the God Class\\nis one of those smells. These datasets are available at the replication\\npackage [25]. The format of the new datasets is changed by including\\nthe same set of metrics shown in Table 3 of Section 3.2.1, in order\\nto be in the same format of the dataset constructed by our team and\\ndescribed in Section 3.2.\\nThe first of the two dataset consists of 125 releases of 13 projects,\\nand more than 120,000 classes, while the second of these two dataset\\nconsists of 74 software projects and more than 55,000 classes. In\\nthis experiment, from the first dataset, we selected a release of each\\nsoftware project that include the higher number of detected God Classes\\nand manually labeled as God Class instances. Also, regarding the sec-\\nond dataset, we selected the same sample of God Classes that were\\nmanually validated (420 classes) and used in the original experiment.\\nTables 12 and 13 reports a description of the first and second datasets\\nrespectively, gathered in the replication of the experiments, in addition,\\nthe number of detected God Classes in each project. Comparing the\\nmain dataset with the new datasets, we can see the ratio of detected\\nGod Classes in the main dataset is much higher (main dataset 485 God\\nClass against 96 in the first dataset and 140 in the second dataset).\\nThe reasons are due to the difference between datasets regarding the\\nnumber and nature (domain and size category) of the analyzed software\\nsystems in each dataset, the total number of classes found in the\\nsystems, the number of detection tools used for God Class detection,\\nthe number of experts who executed the manual validation process, and\\nthe proposed God class labeling strategy.\\nFor example, the first dataset consisted of 13 software systems\\nformed of 18,441 classes that did an analysis a usin', 'A comparison of machine learning algorithms on design smell detection.pdf'), 639: ('dataset).\\nThe reasons are due to the difference between datasets regarding the\\nnumber and nature (domain and size category) of the analyzed software\\nsystems in each dataset, the total number of classes found in the\\nsystems, the number of detection tools used for God Class detection,\\nthe number of experts who executed the manual validation process, and\\nthe proposed God class labeling strategy.\\nFor example, the first dataset consisted of 13 software systems\\nformed of 18,441 classes that did an analysis a using one tool developed\\nby the authors to detect God Classes. The manual validation process\\nwas conducted by a group of two authors who individually validated\\nthe candidate God Classes. Regarding the second dataset [21], the\\nnumber of the analyzed systems is 74, formed of more than 55,000\\nclasses. The tools PMD and iPlasma were used to detect God Classes,\\nInformation and Software Technology 143 (2022) 106736\\n12K. Alkharabsheh et al.\\nFig. 3. Top: Kappa values with and without data balancing sorted by decreasing values of the former. Middle: ROC values with and without data balancing sorted by decreasing\\nvalues of the former. Bottom: MCC values with and without data balancing sorted by decreasing values of the former.\\nand the manual validation performed by three Masters students on the\\nselected sample of detected God Classes (420). Finally, compared with\\nthe main dataset we build and use on the original set of experiments,\\nthe number of analyzed software was 24 formed of 12,587 classes. A\\nset of five detection tools include Decor, iPlasma, PMD, JDeodorant,\\nand Borland Together were used for the first stage of labeling by\\nautomatic detection of God Classes. In addition, the manual validation\\nwas conducted on the whole set of detected God Classes (1958) by three\\npersons who have a Ph.D. in different IT fields.5.2. Results and discussion of the replication\\nThe number of God Classes labeled by human experts in the first\\ndataset are 96 of a total of 18,441 classes, which represents 0.52%\\nof true positives while in the se', 'A comparison of machine learning algorithms on design smell detection.pdf'), 640: ('ls include Decor, iPlasma, PMD, JDeodorant,\\nand Borland Together were used for the first stage of labeling by\\nautomatic detection of God Classes. In addition, the manual validation\\nwas conducted on the whole set of detected God Classes (1958) by three\\npersons who have a Ph.D. in different IT fields.5.2. Results and discussion of the replication\\nThe number of God Classes labeled by human experts in the first\\ndataset are 96 of a total of 18,441 classes, which represents 0.52%\\nof true positives while in the second dataset 140 of a total of the\\nselected sample of 420 classes, which represents 33% . The percentage\\nof first dataset (0.52%) is lower than the percentage of our dataset\\n(4%), and the percentage of the second dataset (33%) is higher than\\nthe percentage of our dataset. In experiment 2 (with data balancing),\\nLGBM achieved the first performance rank using our dataset according\\nto accuracy, F-measure, precision indicators while the second and third\\nrank according to MCA and ROC, respectively. While the seventh and\\nfifteen rank using the first and second datasets according to the kappa\\nInformation and Software Technology 143 (2022) 106736\\n13K. Alkharabsheh et al.\\nTable 13\\nSample of classes of each project and the number of detected God classes (GC) in each\\nsample (N) in the second dataset used in the replication experiments.\\nProject&Version N GC Project&Version N GC\\naoi-2.8.1 9 7 jmoney-0.4.4 6 3\\nargouml-0.34 2 0 jparse-0.96 4 1\\naxion-1.0.M2 3 1 jpf-1.0.2 8 2\\ncastor-1.3.1 6 1 jruby-1.5.2 3 1\\ncolt-1.2.0 3 0 jspwiki-2.8.4 6 2\\ncolumba-1.0 6 1 jsXe-04_beta 6 2\\ndisplaytag-1.2 5 1 jung-2.0.1 2 0\\ndrawswf-1.2.9 6 0 junit-4.1 1 0\\ndrjava-20100913-r5387 9 4 log4j-1.2.16 5 1\\nemma-2.0.5312 4 1 lucene-3.5.0 4 1\\nexoportal-1.0.2 13 0 marauroa-3.8.1 5 1\\nfindbugs-1.3.9 7 0 megamek-0.35.18 5 2\\nfitjava-1.0.1 27 2 mvnforum-1.2.2-ga 10 2\\nfitlibraryforfitnesse-20100806 9 0 nekohtml-1.9.14 6 3\\nfreecol-0.10.3 8 7 openjms-0.7.7-beta-1 2 0\\nfreecs-1.3.20100406 4 3 oscache-2.4.1 5 1\\nfreemind-0.9.0 2 0 picocontainer-2.10.2 2 0\\ngalleon-2.3.0 ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 641: ('wiki-2.8.4 6 2\\ncolumba-1.0 6 1 jsXe-04_beta 6 2\\ndisplaytag-1.2 5 1 jung-2.0.1 2 0\\ndrawswf-1.2.9 6 0 junit-4.1 1 0\\ndrjava-20100913-r5387 9 4 log4j-1.2.16 5 1\\nemma-2.0.5312 4 1 lucene-3.5.0 4 1\\nexoportal-1.0.2 13 0 marauroa-3.8.1 5 1\\nfindbugs-1.3.9 7 0 megamek-0.35.18 5 2\\nfitjava-1.0.1 27 2 mvnforum-1.2.2-ga 10 2\\nfitlibraryforfitnesse-20100806 9 0 nekohtml-1.9.14 6 3\\nfreecol-0.10.3 8 7 openjms-0.7.7-beta-1 2 0\\nfreecs-1.3.20100406 4 3 oscache-2.4.1 5 1\\nfreemind-0.9.0 2 0 picocontainer-2.10.2 2 0\\ngalleon-2.3.0 14 6 pmd-4.2.5 4 0\\nganttproject-2.0.9 5 1 poi-3.6 3 1\\nheritrix-1.14.4 1 1 cobertura-1.9.4.1 0 0\\nhsqldb-2.0.0 15 13 proguard-4.5.1 2 2\\nitext-5.0.3 12 6 quartz-1.8.3 6 4\\njag-6.1 5 4 quickserver-1.4.7 6 2\\njasml-0.10 6 1 quilt-0.6-a-5 6 1\\njasperreports-3.7.3 2 0 roller-4.0.1 6 0\\njavacc-5.0 7 3 squirrel_sql-3.1.2 6 0\\njedit4.3.2 4 3 sunflow-0.07.2 3 0\\njena-2.6.3 1 0 tomcat-7.0.2 3 0\\njext-5.0 5 1 trove-2.1.0 3 0\\njFin_DateMath-1.0.1 4 0 velocity-1.6.4 1 0\\njfreechart-1.0.13 2 1 wct-1.5.2 9 2\\njgraph-5.13.0 5 3 webmail-0.7.10 4 2\\njgraphpad-5.10.0.2 7 4 Weka-3.7.5 4 2\\njgrapht-0.8.1 2 2 xalan-2.7.1 9 5\\njgroups-2.10.0 5 2 xerces-2.10.0 20 12\\njhotdraw-7.5.1 6 2 xmojo-5.0.0 4 1\\njmeter-2.5.1 2 2 pooka-3.0-080505 6 3\\nTotal number of God Classes 140\\nvalues respectively. This classifier has not been able to keep the high\\nperformances achieved using our balanced dataset. Same behaviors\\nwere replicated with the whole remaining classifiers. The results show\\nthat the ratio of God Classes in the dataset influenced the performance\\nof classifiers. Furthermore, the differences between the characteristics\\nof software systems used in these datasets regarding the size and\\ndomain have an important role in the performance of the classifiers.\\nIt is worth noting the importance of this outcome as it significantly\\naddresses important aspects needed by the research community to-\\nwards obtaining accurate detection results using the machine learning\\napproach.\\nAll classifiers achieved high performance values in the replication\\nexperiments using the fi', 'A comparison of machine learning algorithms on design smell detection.pdf'), 642: ('classifiers. Furthermore, the differences between the characteristics\\nof software systems used in these datasets regarding the size and\\ndomain have an important role in the performance of the classifiers.\\nIt is worth noting the importance of this outcome as it significantly\\naddresses important aspects needed by the research community to-\\nwards obtaining accurate detection results using the machine learning\\napproach.\\nAll classifiers achieved high performance values in the replication\\nexperiments using the first and second datasets with some exceptions.\\nThe average values of accuracy, kappa, F-measure, precision, ROC,\\nand MCC using the first dataset without data balancing were (98.9%,\\n29.6%, 99%, 99.4%, 67.3%, and 34.5%) respectively, while with data\\nbalancing were (98.4%, 38.8%, 98.7%, 99.5%, 84%, and 44%) respec-\\ntively. Regarding the second dataset, the average values of accuracy,\\nkappa, F-measure, precision, ROC, and MCC without data balancing\\nwere (92.04%, 81.8%, 92%, 93%, 91%, and 82.4%) respectively, while\\nwith data balancing were (92.3%, 82.5%, 92.3%, 92.7%, 91.4%, and\\n83%) respectively. As can be seen, in both datasets, they have a\\nslight improvement in their behavior with data balancing with some\\nexceptions.\\nThe achieved results confirm the answer of the first research ques-\\ntion(RQ1) in the main experiment of this study, that machine learning\\napproaches can be effectively exploited for God Class design smell de-\\ntection. Therefore, also in this experiment, the null hypothesis: MachineTable 14\\nP-values.\\nDataset Accuracy F-measure Precision Kappa ROC MCC\\nFirstDataset 0.00022 0.01352 0.1031 0.00142 0.00001 0.00262\\nSecondDataset 0.08364 0.05486 0.04338 0.05118 0.01208 0.05486\\nlearning techniques cannot be effectively leveraged for God Class design\\nsmell detection. is rejected.\\nFigs. 4 and 5 shows the Kappa, ROC, and MCC values for all\\nclassifiers using the new dataset with and without balancing. In both\\nfigures, according to the kappa and ROC values, most classifiers were\\nachieved a slightly better performan', 'A comparison of machine learning algorithms on design smell detection.pdf'), 643: ('\\nDataset Accuracy F-measure Precision Kappa ROC MCC\\nFirstDataset 0.00022 0.01352 0.1031 0.00142 0.00001 0.00262\\nSecondDataset 0.08364 0.05486 0.04338 0.05118 0.01208 0.05486\\nlearning techniques cannot be effectively leveraged for God Class design\\nsmell detection. is rejected.\\nFigs. 4 and 5 shows the Kappa, ROC, and MCC values for all\\nclassifiers using the new dataset with and without balancing. In both\\nfigures, according to the kappa and ROC values, most classifiers were\\nachieved a slightly better performance behavior with data balancing\\n(red line) compared with imbalanced (blue line). This behavior agrees\\nwith the results of the main experiment using our dataset shown in\\nFig. 3.\\nWe conducted a Wilcoxon test on the accuracy, kappa, F-measure,\\nprecision, ROC, and MCC values, in order to test the second null\\nhypothesis ‘‘Avoiding data balancing will not influence the accuracy of\\nGod Class design smell detection’’ . The p-values of this test are shown\\nin Table 14. According to the p-values obtained using the first dataset,\\nthe results permit us to reject the null hypothesis (with exception of\\nprecision 𝑝-value), which means that the result is statistically signif-\\nicant. Also, the p-values according to the second dataset allow us to\\naccept the null hypothesis (with the exception of precision and ROC\\np-values), which means that the result is not statistically significant. In\\ngeneral, the result from the replication experiment concludes that data\\nbalancing slightly influences the performance of classifiers on detecting\\nGod Class and agrees with the conclusion of the main experiment.\\n6. Threats to validity\\nThe threats to the validity of the set of experiments designed will\\nbe discussed in this section.\\n6.1. Construct validity\\nThe main threat to construct validity is the set of selected design\\nsmell detection tools used to detect God Class. Despite the fact that\\nthese tools are implemented based on different strategies according to\\nthe definition of God Class, they also allowed different set of metrics\\nand threshold val', 'A comparison of machine learning algorithms on design smell detection.pdf'), 644: ('ing\\nGod Class and agrees with the conclusion of the main experiment.\\n6. Threats to validity\\nThe threats to the validity of the set of experiments designed will\\nbe discussed in this section.\\n6.1. Construct validity\\nThe main threat to construct validity is the set of selected design\\nsmell detection tools used to detect God Class. Despite the fact that\\nthese tools are implemented based on different strategies according to\\nthe definition of God Class, they also allowed different set of metrics\\nand threshold values to be used. This portrayed high accuracy on\\ndetection, and represented the set of the most cited state of the art\\naccording to our previous work [1], however, a study on threats to\\nconstruction of this study is given.\\nTo overcome this threat a manual validation process of the whole\\n1958 God Classes obtained by detection tools was conducted. This\\ntask was accomplished by a group of three researchers who have Doc-\\ntorate Degrees in Information Technology (software engineering and\\ncomputer science), and have excellent experience with object-oriented\\nprogramming and a very good knowledge on design smells. The set of\\nmachine learning classifiers is considered another threat to the study —\\nregarding the selected classifiers families, set of metrics that have been\\nused to train the classifiers, and selecting the best model. To mitigate\\nthis threat, we selected a large set of learning classifiers well-known\\nfor this purpose by analyzing previous studies. The selected set belongs\\nto eleven families in order to avoid the behavior of specific classifiers\\nthat can influence the detection accuracy and behavior. Additionally,\\nwe applied a feature selection experiment before the classification in\\norder to identify the metrics with the most influence in the results and\\nthen we used the cross validation process to reduce the variance in the\\ndetection results.\\nInformation and Software Technology 143 (2022) 106736\\n14K. Alkharabsheh et al.\\nFig. 4. Top: Kappa values with and without data balancing sorted by decreasing values of', 'A comparison of machine learning algorithms on design smell detection.pdf'), 645: ('id the behavior of specific classifiers\\nthat can influence the detection accuracy and behavior. Additionally,\\nwe applied a feature selection experiment before the classification in\\norder to identify the metrics with the most influence in the results and\\nthen we used the cross validation process to reduce the variance in the\\ndetection results.\\nInformation and Software Technology 143 (2022) 106736\\n14K. Alkharabsheh et al.\\nFig. 4. Top: Kappa values with and without data balancing sorted by decreasing values of the former according to first dataset. Middle: ROC values with and without data\\nbalancing sorted by decreasing values of the former according to first dataset. Bottom: MCC values with and without data balancing sorted by decreasing values of the former\\naccording to first dataset.\\n6.2. Internal validity\\nSeveral terms are used to describe design smell in different context,\\nfor example, God Class is known as Large Class code smell, and The\\nBlob anti-pattern. These concepts are related to different characteristics\\nof God Class, such as, a class that has many responsibilities, high\\ncomplexity, more functionality, and a very large number of lines of\\ncodes. Therefore, various sets of metrics were used to measure these\\ncharacteristics and to construct the detection rules.\\nTo overcome this threat we used different tools that were developed\\nbased on these concepts that had a focus of using different detection\\nstrategies. Another essential threat is the total number of detected God\\nClasses in the dataset, especially, after the manual validation. But it isnormal that we detected a few numbers of God Classes compared to the\\nwhole classes. This threat will lead to an unbalancing problem between\\nclass instances (God Class/Not God Class) in the dataset. To manage this\\nthreat, we used oversampling and under-sampling techniques in order\\nto balance the dataset.\\n6.3. External validity\\nThe nature of software systems used in the dataset is the main\\nexternal threat. Only the set of open source systems that belong to\\ndifferent domain', 'A comparison of machine learning algorithms on design smell detection.pdf'), 646: ('fter the manual validation. But it isnormal that we detected a few numbers of God Classes compared to the\\nwhole classes. This threat will lead to an unbalancing problem between\\nclass instances (God Class/Not God Class) in the dataset. To manage this\\nthreat, we used oversampling and under-sampling techniques in order\\nto balance the dataset.\\n6.3. External validity\\nThe nature of software systems used in the dataset is the main\\nexternal threat. Only the set of open source systems that belong to\\ndifferent domain and size categories have been used in the experiment\\nand may affect the generalization of results regarding the training\\nprocess of machine learning classifiers. Most of the proposed detection\\nInformation and Software Technology 143 (2022) 106736\\n15K. Alkharabsheh et al.\\nFig. 5. Top: Kappa values with and without data balancing sorted by decreasing values of the former according to second dataset. Middle: ROC values with and without data\\nbalancing sorted by decreasing values of the former according to second dataset. Bottom: MCC values with and without data balancing sorted by decreasing values of the former\\naccording to second dataset.\\napproaches, techniques, and tools are evaluated on benchmarks or\\ncorpus of open source systems. These types of systems are stored in\\nwell-known repositories. We think there are no differences between\\nthe development of open source and commercial systems. Both types\\nhave been developed in similar languages and high quality. Therefore,\\nwhether the systems are open source or commercial will not influence\\nthe behavior of machine learning classifiers. We managed this threat by\\nreplicating the experiment on two other datasets of open source systems\\nfrom different domains and size categories and involve a high number\\nof classes.Based on the outcomes of this study that was conducted only\\none design smell (God Class), with projects developed in a single\\nprogramming language, and because only one balancing technique is\\nused to compare with the imbalanced case. Consequently, we note a\\ngen', 'A comparison of machine learning algorithms on design smell detection.pdf'), 647: ('mercial will not influence\\nthe behavior of machine learning classifiers. We managed this threat by\\nreplicating the experiment on two other datasets of open source systems\\nfrom different domains and size categories and involve a high number\\nof classes.Based on the outcomes of this study that was conducted only\\none design smell (God Class), with projects developed in a single\\nprogramming language, and because only one balancing technique is\\nused to compare with the imbalanced case. Consequently, we note a\\ngeneric threat to the generalization of the study. we note that there\\nmay/exist other methods of data balancing besides SMOTE that we\\nemployed in this paper, also with the existence of different design\\nsmells, and projects developed in different programming language. The\\napplication of those other methods may improve the results. However,\\nin our experiments, SMOTE did not improve God class detection. As\\nper the proposition in this paper, we note that the study are not fully\\nInformation and Software Technology 143 (2022) 106736\\n16K. Alkharabsheh et al.\\ngeneralizable but the conclusions are promising for the application in\\nreal design smells detection scenarios as mentioned above and the focus\\non other measures, such as Kappa, ROC, and MCC to assess the classifier\\nbehavior, once the accuracy is very good.\\nAll these threats either internal, external, and construction affect the\\ngeneralization of the study results but they are wide similar to the rest\\nof the state of the art experiments\\n7. Conclusion and future work\\nThe paper presents a study to ascertain whether machine learning\\nclassifiers can be exploited effectively for purposes of design smell\\ndetection with a specific focus to God class. Additionally, this study\\ncompares the performance of the classifiers in the imbalanced dataset\\ncase with the balanced dataset case. For this purpose, we designed a\\nset of experiments that compared 28 supervised machine learning clas-\\nsifiers belonging to various families-to aid in detecting God Class design\\nsmell. To conduct thi', 'A comparison of machine learning algorithms on design smell detection.pdf'), 648: ('\\nThe paper presents a study to ascertain whether machine learning\\nclassifiers can be exploited effectively for purposes of design smell\\ndetection with a specific focus to God class. Additionally, this study\\ncompares the performance of the classifiers in the imbalanced dataset\\ncase with the balanced dataset case. For this purpose, we designed a\\nset of experiments that compared 28 supervised machine learning clas-\\nsifiers belonging to various families-to aid in detecting God Class design\\nsmell. To conduct this study, we constructed a large dataset of 24 open-\\nsource software from different domains and sizes that consist of 12,587\\nclasses where 485 God Class were manually validated. The dataset was\\nprepared using an external source code analyzer tool (Refactorit), a\\nset of five well-known design smell detection tools that are common\\nin God Class detection as automatic early advisors, together with a\\ngroup of three human experts that have been used to label the class\\ninstances detected by one or more tool. The strategy we followed for\\nlabeling detection tools result was as follows: If one tool or more detects\\nthe class as God Class, then the label will be (1), otherwise (0). A\\nset of 1958 God Classes were detected by the applied tools where the\\nprobabilities of false negative are reduced, and evaluated by a group of\\nhuman experts where the final number of God Classes was 485 where\\nthe manual validation reduced the probabilities of false positives.\\nAs a first step, we conducted a feature selection experiment to\\nanalyze the set of metrics and select the most important one. This\\nprevious experiment shows that it should be better working with the\\nwhole set of metrics. Next, we developed two different experiments\\nfor classification as follows: Experiment 1 using the original dataset\\nwithout data balancing, and Experiment 2 using the Synthetic Minor-\\nity Oversampling Technique (SMOTE) to solve the data unbalanced\\nproblem, which afterwards increases the classifier performance. For\\nall the classifiers, the achieved performan', 'A comparison of machine learning algorithms on design smell detection.pdf'), 649: ('yze the set of metrics and select the most important one. This\\nprevious experiment shows that it should be better working with the\\nwhole set of metrics. Next, we developed two different experiments\\nfor classification as follows: Experiment 1 using the original dataset\\nwithout data balancing, and Experiment 2 using the Synthetic Minor-\\nity Oversampling Technique (SMOTE) to solve the data unbalanced\\nproblem, which afterwards increases the classifier performance. For\\nall the classifiers, the achieved performance results were evaluated in\\nterms of accuracy, Cohen Kappa, ROC area, precision, and F-measure.\\nAccording to the performance metrics values in the features selection\\nexperiment, all classifiers have achieved a better performance using the\\nwhole set of metrics compared with important set. For this purpose, we\\nconducted the main experiments using the whole set. In experiment 1\\n(without data balancing) using the main dataset, XGB has obtained the\\nhighest performance in terms of accuracy, kappa, F-measure, precision,\\nand ROC values. In contrast, in Experiment 2 (with data balancing),\\nLGBM has obtained the highest performance using all performance\\nmetrics values except ROC, while XGB full back to the second rank. The\\nresults shows that most of classifiers have not able to keep the achieved\\nhigh performances (i.e., their rank). According to the p-values obtained\\nfrom the performance values for the combined values of accuracy,\\nkappa, F-measure, precision, and ROC with and without balancing, the\\nnull hypothesis ‘‘the classifiers have the same behavior on God Class\\ndetection, with and without data balancing’’ is rejected in all cases. The\\nresults of this experiment shows that data balancing slightly affect on\\nthe performances of classifiers.\\nAfter replicating both experiments (1 and 2) using new datasets,\\nall classifiers have achieved high performance values as in the main\\ndataset. Based on the obtained performance results in the replication\\nexperiments, we confirm our conclusions using main dataset that ma-\\nchine lear', 'A comparison of machine learning algorithms on design smell detection.pdf'), 650: ('e classifiers have the same behavior on God Class\\ndetection, with and without data balancing’’ is rejected in all cases. The\\nresults of this experiment shows that data balancing slightly affect on\\nthe performances of classifiers.\\nAfter replicating both experiments (1 and 2) using new datasets,\\nall classifiers have achieved high performance values as in the main\\ndataset. Based on the obtained performance results in the replication\\nexperiments, we confirm our conclusions using main dataset that ma-\\nchine learning techniques can be effectively leveraged for design smell\\ndetection particularly using God Class.\\nDespite the large number of previous works that confirmed the\\naccuracy of machine learning techniques in design smell detection,this area has not been exploited sufficiently to improve the design\\nsmell detection. This situation was clearly observed in the replication of\\nthe experiments while using different datasets. For this purpose, other\\ninformation related to software systems, such as size categories and\\ndomains should be taken into account by the industries and the re-\\nsearch community when they developing new approaches, techniques,\\nand tools as shows our work in [36].\\nAlthough we can see the results in Figs. 4 and 5 that are obtained\\nusing the new datasets (first and second), which also agrees with Fig. 3\\nthat most of classifiers achieved slightly better performance, the null\\nhypothesis ‘‘the classifiers have the same behavior on God Class de-\\ntection with and without data balancing’’ cannot be rejected as shown\\nin Table. As a consequence, we have an empirical evidence that data\\nbalancing does not have adequately influence on the performances of\\nclassifiers to detect God Class design smell. Also, from the perspective\\nof this study, it is imperative to highlight that despite the conclusions\\ndrawn from our experiments that were performed only on one design\\nsmell on projects developed in a single programming language, and\\nonly one balancing technique is used to compare with the imbalanced\\ncase. We note a ge', 'A comparison of machine learning algorithms on design smell detection.pdf'), 651: ('d as shown\\nin Table. As a consequence, we have an empirical evidence that data\\nbalancing does not have adequately influence on the performances of\\nclassifiers to detect God Class design smell. Also, from the perspective\\nof this study, it is imperative to highlight that despite the conclusions\\ndrawn from our experiments that were performed only on one design\\nsmell on projects developed in a single programming language, and\\nonly one balancing technique is used to compare with the imbalanced\\ncase. We note a generic threat to the generalization of the study. there\\nexist other methods of data balancing besides SMOTE that we employed\\nin this paper, also with the existence of different design smells, and\\nprojects implemented in different programming languages. The appli-\\ncation of those other methods may improve the results. However, in\\nour experiments, SMOTE did not improve God class detection. As per\\nthe proposition in this paper, we note that the study are not fully\\ngeneralizable but the conclusions are promising for the application in\\nreal design smells detection scenarios as mentioned above and the focus\\non other measures, such as Kappa, ROC, and MCC to assess the classifier\\nbehavior, once the accuracy is very good. The outcomes of this work\\nfrom one side confirms that machine learning can be used effectively\\nin the context of detection of true positive design smells (God Class in\\nour case). This is also the case in the smells that have a negative impact\\non software quality, and from the other perspective, data balancing\\nslightly influences the accuracy of design smell detection when machine\\nlearning classifiers are used. Also, in terms of practical applicability,\\nthe authors note that leveraging machine learning for smell detection\\nnot only can play a significant role in maintaining software quality but,\\nbased on the obtained results-this can as well can also be employed to\\nautomatically detect and predict the likelihood of design smells with a\\nhigher degree of certainty.\\nIn the future, this work will be extended ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 652: ('alancing\\nslightly influences the accuracy of design smell detection when machine\\nlearning classifiers are used. Also, in terms of practical applicability,\\nthe authors note that leveraging machine learning for smell detection\\nnot only can play a significant role in maintaining software quality but,\\nbased on the obtained results-this can as well can also be employed to\\nautomatically detect and predict the likelihood of design smells with a\\nhigher degree of certainty.\\nIn the future, this work will be extended further in certain directions\\nin order to improve and generalize the obtained results. To this end,\\nwe plan to replicate the conducted experiments by using a large-scale\\ndataset that is manually evaluated, a wide set of software metrics,\\nmore types of design smells, apply more machine learning techniques,\\nanalyze software systems implemented in different programming lan-\\nguages, and includes other inputs that can help in obtaining better\\nclassifiers behavior.\\nCRediT authorship contribution statement\\nKhalid Alkharabsheh: Conceptualization, Methodology, Software,\\nValidation, Formal analysis, Visualization, Data curation, Investigation,\\nSupervision, Writing – original draft, Writing – review & editing. Sadi\\nAlawadi: Conceptualization, Methodology, Formal analysis, Visualiza-\\ntion, Software, Data curation, Validation, Writing – review & editing.\\nVictor R. Kebande: Conceptualization, Methodology, Writing – re-\\nview & editing. Yania Crespo: Methodology, Software, Investigation.\\nManuel Fernández-Delgado: Methodology, Software, Investigation.\\nJosé A. Taboada: Methodology, Software, Investigation.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nInformation and Software Technology 143 (2022) 106736\\n17K. Alkharabsheh et al.\\nReferences\\n[1] K. Alkharabsheh, Y. Crespo, E. Manso, J. Taboada, Software design smell\\ndetection: a systematic mapping study, Softw. Qual. J. (2', 'A comparison of machine learning algorithms on design smell detection.pdf'), 653: (', Software, Investigation.\\nJosé A. Taboada: Methodology, Software, Investigation.\\nDeclaration of competing interest\\nThe authors declare that they have no known competing finan-\\ncial interests or personal relationships that could have appeared to\\ninfluence the work reported in this paper.\\nInformation and Software Technology 143 (2022) 106736\\n17K. Alkharabsheh et al.\\nReferences\\n[1] K. Alkharabsheh, Y. Crespo, E. Manso, J. Taboada, Software design smell\\ndetection: a systematic mapping study, Softw. Qual. J. (2018).\\n[2] F. Pérez, Refactoring Planning for Design Smell Correction in Object-Oriented\\nSoftware (Ph.D. thesis), School of Engineering, Valladolid University, 2011.\\n[3] W.H. Brown, R.C. Malveau, H.W. McCormick, T.J. Mowbray, AntiPatterns:\\nRefactoring Software, Architectures, and Projects in Crisis, John Wiley & Sons,\\nInc, 1998.\\n[4] M. Choinzon, Y. Ueda, Detecting defects in object oriented designs using design\\nmetrics, in: J. Conf. on Knowledge-Based Software Engineering, 2006, pp. 61–72.\\n[5] R. Fourati, N. Bouassida, H. Abdallah, A metric-based approach for anti-pattern\\ndetection in UML designs, Comput. Inf. Sci. (2011) 17–33.\\n[6] C. Marinescu, R. Marinescu, P.F. Mihancea, R. Wettel, IPlasma: An integrated\\nplatform for quality assessment of object-oriented design, in: Intl. Conf. Software\\nMaintenance - Industrial and Tool Volume, 2005, pp. 77–80.\\n[7] N. Moha, Y.-G. Guéhéneuc, DECOR: a tool for the detection of design defects,\\nin: Intl. Conf. on Automated Software Engineering, 2007, pp. 527–528.\\n[8] M.J. Munro, Product metrics for automatic identification of ‘‘bad smell’’ design\\nproblems in java source-code, in: Intl. Conf. Software Metrics, 2005, p. 15.\\n[9] R. Shatnawi, Deriving metrics thresholds using log transformation, J. Softw.:\\nEvol. Process. 27 (2) (2015) 95–113.\\n[10] L. Tahvildar, K. Kontogiannis, Improving design quality using meta-pattern\\ntransformations: a metric-based approach, J. Softw.: Evol. Process. 16 (4–5)\\n(2004) 331–361.\\n[11] S. Hassaine, F. Khomh, Y.-G. Guéhéneuc, S. Hamel, Ids: an immune-i', 'A comparison of machine learning algorithms on design smell detection.pdf'), 654: ('o, Product metrics for automatic identification of ‘‘bad smell’’ design\\nproblems in java source-code, in: Intl. Conf. Software Metrics, 2005, p. 15.\\n[9] R. Shatnawi, Deriving metrics thresholds using log transformation, J. Softw.:\\nEvol. Process. 27 (2) (2015) 95–113.\\n[10] L. Tahvildar, K. Kontogiannis, Improving design quality using meta-pattern\\ntransformations: a metric-based approach, J. Softw.: Evol. Process. 16 (4–5)\\n(2004) 331–361.\\n[11] S. Hassaine, F. Khomh, Y.-G. Guéhéneuc, S. Hamel, Ids: an immune-inspired\\napproach for the detection of software design smells, in: Intl. Conf. Quality of\\nInformation and Communications Technology, 2010, pp. 343–348.\\n[12] F. Khomh, S. Vaucher, Y.-G. Guéhéneuc, H. Sahraoui, BDTEX: A GQM-based\\nBayesian approach for the detection of antipatterns, J. Syst. Softw. 84 (4) (2011)\\n559–572.\\n[13] J. Kreimer, Adaptive detection of design flaws, Electron. Notes Theor. Comput.\\nSci. 141 (4) (2005) 117–136.\\n[14] N. Maneerat, P. Muenchaisri, Bad-smell prediction from software design model\\nusing machine learning techniques, in: Intl. J. Conf. on Computer Science and\\nSoftware Engineering, 2011, pp. 331–336.\\n[15] K. Alkharabsheh, Y. Crespo, M. Fernández-Delgado, J.M. Cotos, J.A. Taboada,\\nAssessing the influence of size category of the project in god class detection,\\nan experimental approach based on machine learning (MLA), in: International\\nConference on Software Engineering & Knowledge Engineering, 2019, pp.\\n361–366.\\n[16] F. Pecorelli, D. Di Nucci, C. De Roover, A. De Lucia, A large empirical assessment\\nof the role of data balancing in machine-learning-based code smell detection, J.\\nSyst. Softw. (2020) 110693.\\n[17] F. Pecorelli, F. Palomba, D. Di Nucci, A. De Lucia, Comparing heuristic and\\nmachine learning approaches for metric-based code smell detection, in: 2019\\nIEEE/ACM 27th International Conference on Program Comprehension (ICPC),\\n2019, pp. 93–104.\\n[18] N. Tsantalis, T. Chaikalis, A. Chatzigeorgiou, Jdeodorant: Identification and\\nremoval of type-checking bad smells, in: Intl. Conf. on Soft', 'A comparison of machine learning algorithms on design smell detection.pdf'), 655: ('l assessment\\nof the role of data balancing in machine-learning-based code smell detection, J.\\nSyst. Softw. (2020) 110693.\\n[17] F. Pecorelli, F. Palomba, D. Di Nucci, A. De Lucia, Comparing heuristic and\\nmachine learning approaches for metric-based code smell detection, in: 2019\\nIEEE/ACM 27th International Conference on Program Comprehension (ICPC),\\n2019, pp. 93–104.\\n[18] N. Tsantalis, T. Chaikalis, A. Chatzigeorgiou, Jdeodorant: Identification and\\nremoval of type-checking bad smells, in: Intl. Conf. on Software Maintenance\\nand Reengineering, 2008, pp. 329–331.\\n[19] Borland, Together, 2008, http://www.borland.com/together.\\n[20] T. Copeland, PMD Applied, Centennial Books, 2005.\\n[21] F.A. Fontana, M.V. Mäntylä, M. Zanoni, A. Marino, Comparing and experimenting\\nmachine learning techniques for code smell detection, Empir. Softw. Eng. 21 (3)\\n(2016) 1143–1191.\\n[22] M.I. Azeem, F. Palomba, L. Shi, Q. Whang, Machine learning techniques for code\\nsmell detection: A systematic literature review and meta-analysis, Inf. Softw.\\nTechnol. 108 (2019) 115–138.\\n[23] A. Al-Shaaby, H. Aljamaan, M. Alshayeb, Bad smell detection using machine\\nlearning techniques: A systematic literature review, Arab. J. Sci. Eng. 45 (2020).\\n[24] J. Alzubi, A. Nayyar, A. Kumar, Machine learning from theory to algorithms: An\\noverview, J. Phys. Conf. Ser. 1142 (2018) 012012.\\n[25] k. Alkharabsheh, S. Alawadi, V. Kebande, Y. Crespo, M. Delgado, J.\\nTaboada, Replication package of raw data, scripts and all necessary material\\nfor replication, 2021, URL: https://drive.google.com/drive/folders/1_Q7i52QPb-\\nMogNzW6vpePWSNkYyA1gKX?usp=sharing.\\n[26] A. Maiga, N. Ali, N. Bhattacharya, A. Sabané, Y.-G. Guéhéneuc, G. Antoniol,\\nE. Aïmeur, Support vector machines for anti-pattern detection, in: Intl. Conf.\\nAutomated Software Engineering, 2012, pp. 278–281.\\n[27] A. Maiga, N. Ali, N. Bhattacharya, A. Sabane, Y.-G. Gueheneuc, E. Aimeur,\\nSmurf: A svm-based incremental anti-pattern detection approach, in: Intl. Conf.\\non Reverse Engineering, 2012, pp. 466–475.\\n[28] M. Peiris, J', 'A comparison of machine learning algorithms on design smell detection.pdf'), 656: ('://drive.google.com/drive/folders/1_Q7i52QPb-\\nMogNzW6vpePWSNkYyA1gKX?usp=sharing.\\n[26] A. Maiga, N. Ali, N. Bhattacharya, A. Sabané, Y.-G. Guéhéneuc, G. Antoniol,\\nE. Aïmeur, Support vector machines for anti-pattern detection, in: Intl. Conf.\\nAutomated Software Engineering, 2012, pp. 278–281.\\n[27] A. Maiga, N. Ali, N. Bhattacharya, A. Sabane, Y.-G. Gueheneuc, E. Aimeur,\\nSmurf: A svm-based incremental anti-pattern detection approach, in: Intl. Conf.\\non Reverse Engineering, 2012, pp. 466–475.\\n[28] M. Peiris, J.H. Hill, Towards detecting software performance anti-patterns using\\nclassification techniques, ACM SIGSOFT Softw. Eng. Notes 39 (1) (2014) 1–4.\\n[29] D. Di Nucci, F. Palomba, D.A. Tamburri, A. Serebrenik, A. De Lucia, Detecting\\ncode smells using machine learning techniques: are we there yet? in: Intl. Conf.\\non Software Analysis, Evolution and Reengineering, 2018, pp. 612–621.[30] N.V. Chawla, Data mining for imbalanced datasets: An overview, in: O. Maimon,\\nL. Rokach (Eds.), Data Mining and Knowledge Discovery Handbook, Springer US,\\nBoston, MA, 2010, pp. 875–886, http://dx.doi.org/10.1007/978-0-387-09823-\\n4_45.\\n[31] S. Hassaine, F. Khomh, Y. Gueheneuc, S. Hamel, Ids: An immune-inspired ap-\\nproach for the detection of software design smells, in: 2010 Seventh International\\nConference on the Quality of Information and Communications Technology,\\n2010, pp. 343–348, http://dx.doi.org/10.1109/QUATIC.2010.61.\\n[32] K. Kourou, T.P. Exarchos, K.P. Exarchos, M.V. Karamouzis, D.I. Fotiadis, Ma-\\nchine learning applications in cancer prognosis and prediction, Comput. Struct.\\nBiotechnol. J. 13 (2015) 8–17.\\n[33] D.D. Nucci, F. Palomba, D.A. Tamburri, A. Serebrenik, A.D. Lucia, Detecting\\ncode smells using machine learning techniques: Are we there yet? in: 2018 IEEE\\n25th International Conference on Software Analysis, Evolution and Reengineering\\n(SANER), IEEE Computer Society, 2018, pp. 612–621, http://dx.doi.org/10.\\n1109/SANER.2018.8330266.\\n[34] J. Ali Reshi, S. Singh, Investigating the role of code smells in preventive\\nmaintenanc', 'A comparison of machine learning algorithms on design smell detection.pdf'), 657: ('in cancer prognosis and prediction, Comput. Struct.\\nBiotechnol. J. 13 (2015) 8–17.\\n[33] D.D. Nucci, F. Palomba, D.A. Tamburri, A. Serebrenik, A.D. Lucia, Detecting\\ncode smells using machine learning techniques: Are we there yet? in: 2018 IEEE\\n25th International Conference on Software Analysis, Evolution and Reengineering\\n(SANER), IEEE Computer Society, 2018, pp. 612–621, http://dx.doi.org/10.\\n1109/SANER.2018.8330266.\\n[34] J. Ali Reshi, S. Singh, Investigating the role of code smells in preventive\\nmaintenance, J. Inf. Technol. Manag. 10 (4) (2018) 41–63.\\n[35] Y.-G. Guéhéneuc, H. Sahraoui, F. Zaidi, Fingerprinting design patterns, in: 11th\\nWorking Conference on Reverse Engineering, IEEE, 2004, pp. 172–181.\\n[36] K. Alkharabsheh, Y. Crespo, M. Fernandez-Delgado, J. Viqueira, J. Taboada,\\nExploratory study of the impact of project domain and size category on the\\ndetection of the god class design smell, Softw. Qual. J. (2021).\\n[37] R. Per, H. Martin, Guidelines for conducting and reporting case study research\\nin software engineering, Empir. Softw. Eng. 14 (2) (2009) 131–164.\\n[38] C. Wohlin, P. Runeson, M. Höst, M.C. Ohlsson, B. Regnell, Experimentation in\\nSoftware Engineering, Springer, 2012.\\n[39] K. Alkharabsheh, S. Almobydeen, Y. Crespo, J.A. Taboada, Influence of nominal\\nproject knowledge in the detection of design smells: An exploratory study with\\ngod class, Int. J. Adv. Stud. Comput. Sci. Eng. 5 (11) (2016) 120–127.\\n[40] K. Alkharabsheh, Y. Crespo, E. Manso, J. Taboada, Comparación de herramientas\\nde Detección de Design Smells, in: Jornadas de Ingeniería Del Software Y Bases\\nde Datos, 2016, pp. 159–172.\\n[41] K. Alkharabsheh, Y. Crespo, E. Manso, J. Taboada, Sobre el grado de acuerdo\\nentre evaluadores en la detección de design smells, in: Jornadas de Ingeniería\\nDel Software Y Bases de Datos, 2016, pp. 143–157.\\n[42] S. Counsell, E. Mendes, Size and frequency of class change from a refactoring\\nperspective, in: Int. Conf. on Software Evolvability, 2007, pp. 23–28.\\n[43] F.A. Fontana, P. Braione, M. Zanoni, Automatic det', 'A comparison of machine learning algorithms on design smell detection.pdf'), 658: (' Design Smells, in: Jornadas de Ingeniería Del Software Y Bases\\nde Datos, 2016, pp. 159–172.\\n[41] K. Alkharabsheh, Y. Crespo, E. Manso, J. Taboada, Sobre el grado de acuerdo\\nentre evaluadores en la detección de design smells, in: Jornadas de Ingeniería\\nDel Software Y Bases de Datos, 2016, pp. 143–157.\\n[42] S. Counsell, E. Mendes, Size and frequency of class change from a refactoring\\nperspective, in: Int. Conf. on Software Evolvability, 2007, pp. 23–28.\\n[43] F.A. Fontana, P. Braione, M. Zanoni, Automatic detection of bad smells in code:\\nAn experimental assessment, J. Obj. Technol. 11 (2) (2012) 5–1.\\n[44] W. Li, R. Shatnawi, An empirical study of the bad smells and class error\\nprobability in the post-release object-oriented system evolution, J. Syst. Softw.\\n80 (7) (2007) 1120–1128.\\n[45] J.A. Santos, M.G. de Mendonça, C.V. Silva, An exploratory study to investigate\\nthe impact of conceptualization in god class detection, in: Intl. Conf. on\\nEvaluation and Assessment in Software Engineering, 2013, pp. 48–59.\\n[46] A. Yamashita, M. Zanoni, F.A. Fontana, B. Walter, Inter-smell relations in\\nindustrial and open source systems: A replication and comparative analysis, in:\\nIntl. Conf. on Software Maintenance and Evolution, 2015, pp. 121–130.\\n[47] M. Lanza, R. Marinescu, Object-Oriented Metrics in Practice: Using Software\\nMetrics to Characterize, Evaluate, and Improve the Design of Object-Oriented\\nSystems, Springer Science & Business Media, 2007.\\n[48] M. Fowler, K. Beck, Refactoring: Improving the Design of Existing Code,\\nAddison-Wesley Professional, 1999.\\n[49] N. Moha, Y.-G. Gueheneuc, L. Duchien, A.-F. Le Meur, Decor: A method for the\\nspecification and detection of code and design smells, IEEE Trans. Softw. Eng.\\n36 (1) (2010) 20–36.\\n[50] A. Yamashita, L. Moonen, Exploring the impact of inter-smell relations on soft-\\nware maintainability: An empirical study, in: Intl.Conf. on Software Engineering,\\n2013, pp. 682–691.\\n[51] A. Tiberghien, N. Moha, T. Mens, K. Mens, Répertoire des Défauts de Conception,\\nTechnical Report 1303, Univ', 'A comparison of machine learning algorithms on design smell detection.pdf'), 659: ('ison-Wesley Professional, 1999.\\n[49] N. Moha, Y.-G. Gueheneuc, L. Duchien, A.-F. Le Meur, Decor: A method for the\\nspecification and detection of code and design smells, IEEE Trans. Softw. Eng.\\n36 (1) (2010) 20–36.\\n[50] A. Yamashita, L. Moonen, Exploring the impact of inter-smell relations on soft-\\nware maintainability: An empirical study, in: Intl.Conf. on Software Engineering,\\n2013, pp. 682–691.\\n[51] A. Tiberghien, N. Moha, T. Mens, K. Mens, Répertoire des Défauts de Conception,\\nTechnical Report 1303, University of Montreal, 2007.\\n[52] M. Fernández-Delgado, E. Cernadas, S. Barro, D. Amorim, Do we need hundreds\\nof classifiers to solve real world classification problems? J. Mach. Learn. Res. 15\\n(1) (2014) 3133–3181.\\n[53] J. Wainer, Comparison of 14 different families of classification algorithms on\\n115 binary datasets, 2016, arXiv preprint arXiv:1606.00930.\\n[54] S. Alawadi, M.F. Delgado, D.M. Pérez, Machine Learning Algorithms for Pattern\\nVisualization in Classification Tasks and for Automatic Indoor Temperature\\nPrediction (Ph.D. thesis, Ph. D. thesis), Universidade de Santiago de Compostela,\\n2018.\\n[55] I.H. Witten, E. Frank, M.A. Hall, C.J. Pal, Data Mining: Practical Machine\\nLearning Tools and Techniques, Morgan Kaufmann, 2016.\\n[56] C. López, E. Manso, Y. Crespo, The identification of anomalous code measures\\nwith conditioned interval metrics, in: 13th TOOLS Workshop on Quantitative\\nApproaches in Object-Oriented Software Engineering (QAOOSE 2010) MáLaga,\\nSpain, MáLaga, 2010.\\n[57] G. Rasool, Z. Arshad, A review of code smell mining techniques, J. Softw.: Evol.\\nProcess. 27 (11) (2015) 867–895.\\n[58] N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, SMOTE: synthetic\\nminority over-sampling technique, J. Artif. Intell. Res. 16 (2002) 321–357.\\nInformation and Software Technology 143 (2022) 106736\\n18K. Alkharabsheh et al.\\n[59] N. Blackman, J. Koval, Interval estimation for cohen’s kappa as a measure of\\nagreement, Stat. Med. 19 (5) (2000) 723–741.\\n[60] A.P. Bradley, The use of the area under the roc curve in the evalu', 'A comparison of machine learning algorithms on design smell detection.pdf'), 660: ('of code smell mining techniques, J. Softw.: Evol.\\nProcess. 27 (11) (2015) 867–895.\\n[58] N.V. Chawla, K.W. Bowyer, L.O. Hall, W.P. Kegelmeyer, SMOTE: synthetic\\nminority over-sampling technique, J. Artif. Intell. Res. 16 (2002) 321–357.\\nInformation and Software Technology 143 (2022) 106736\\n18K. Alkharabsheh et al.\\n[59] N. Blackman, J. Koval, Interval estimation for cohen’s kappa as a measure of\\nagreement, Stat. Med. 19 (5) (2000) 723–741.\\n[60] A.P. Bradley, The use of the area under the roc curve in the evaluation of\\nmachine learning algorithms, Pattern Recognit. 30 (7) (1997) 1145–1159.\\n[61] B. Matthews, Comparison of the predicted and observed secondary structure of t4\\nphage lysozyme, Biochim. Biophys. Acta (BBA) - Protein Struct. 405 (2) (1975)\\n442–451.\\n[62] M. Hollander, D.A. Wolfe, E. Chicken, Nonparametric Statistical Methods, Vvol.\\n751, John Wiley & Sons, 2013.\\n[63] F.A. Fontana, P. Braione, M. Zanoni, Automatic detection of bad smells in\\ncode: An experimental assessment, J. Obj. Technol. 11 (2) (2012) 5:1–38,\\nhttp://dx.doi.org/10.5381/jot.2012.11.2.a5.[64] F.A. Fontana, M. Zanoni, A. Marino, M.V. Mantyla, Code smell detection:\\nTowards a machine learning-based approach, in: Int. Conf. on Software\\nMaintenance, 2013, pp. 396–399.\\n[65] T. Hall, S. Beecham, D. Bowes, D. Gray, S. Counsell, Developing fault-prediction\\nmodels: What the research can show industry, IEEE Softw. 28 (6) (2011) 96–99.\\n[66] F. Pecorelli, F. Palomba, D. Di Nucci, A. De Lucia, Comparing heuristic and ma-\\nchine learning approaches for metric-based code smell detection, in: Proceedings\\nof the 27th International Conference on Program Comprehension, in: ICPC ’19,\\nIEEE Press, 2019, pp. 93–104, http://dx.doi.org/10.1109/ICPC.2019.00023.', 'A comparison of machine learning algorithms on design smell detection.pdf'), 661: ('Biological Psychology 67 (2004) 183–218\\nMethodology\\nIssuesandassumptionsontheroadfromrawsignals\\nto metrics of frontal EEG asymmetry in emotion\\nJohn J.B. Allen∗, James A. Coan, Maria Nazarian\\nDepartment of Psychology, University of Arizona, P.O. Box 210068, Tucson, AZ 85721-0068, USA\\nAbstract\\nThere exists a substantial literature examining frontal electroencephalographic asymmetries in\\nemotion,motivation,andpsychopathology.Researchinthisareausesaspecializedsetofapproachesfor reducing raw EEG signals to metrics that provide the basis for making inferences about the roleof frontal brain activity in emotion. The present review details some of the common data processingroutinesusedinthisﬁeldofresearch,withafocusonstatisticalandmethodologicalissuesthathavecaptured, and should capture, the attention of researchers in this ﬁeld.© 2004 Published by Elsevier B.V.\\nKeywords: Frontal electroencephalographic asymmetry; EEG; Emotion; Methods; State and trait\\nThe ﬁeld of research examining frontal electroencephalographic (EEG) asymmetries in\\nemotionandpsychopathologyisnowovertwodecadesold,withover80publishedstudiesdocumentingrelationshipsbetweenasymmetriesinfrontalEEGpowerandemotion-relatedtraitsandstates(see CoanandAllen,2004 ,thisissue,forreview).Althoughdatareduction\\nandanalytictechniqueshavevariedacrossstudies,therearemanycommonapproachesthathavebecomequitepopularfortransformingrawEEGsignalstometricsthatprovidethebasisformakinginferencesabouttheroleoffrontalbrainactivityinemotion.Theseapproachesinvolvemanytransformationsofthedata,andinthatprocessinvolveassumptionsthatcanimpact the interpretations scientists can levy from a given pattern of results.\\nTheaimofthispaper,therefore,istoprovideageneraloverviewofsomeofthecommon\\nstepsinvolvedindataprocessinginthisﬁeld,highlightingtheassumptionsandtheimpactofviolationsoftheseassumptionsforinterpretingﬁndings.Itisimportanttonotethatnoneoftheissuesraisedinthispapercalltoquestionthenowwell-replicatedrelationshipsbetween\\n∗Corresponding author. Tel.: +1-520-621-4992.\\nE-mail address: jallen', 'Issues and assumptions on the road from raw signals.pdf'), 662: ('thedata,andinthatprocessinvolveassumptionsthatcanimpact the interpretations scientists can levy from a given pattern of results.\\nTheaimofthispaper,therefore,istoprovideageneraloverviewofsomeofthecommon\\nstepsinvolvedindataprocessinginthisﬁeld,highlightingtheassumptionsandtheimpactofviolationsoftheseassumptionsforinterpretingﬁndings.Itisimportanttonotethatnoneoftheissuesraisedinthispapercalltoquestionthenowwell-replicatedrelationshipsbetween\\n∗Corresponding author. Tel.: +1-520-621-4992.\\nE-mail address: jallen@u.arizona.edu (J.J.B. Allen).\\n0301-0511/$ – see front matter © 2004 Published by Elsevier B.V.\\ndoi:10.1016/j.biopsycho.2004.03.007\\n184 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nthe metrics of EEG asymmetry and emotional constructs. The issues will, however, have\\nimplications for how the ﬁndings best be interpreted.\\n1. From raw signals to handy metrics\\nInvestigators who examine frontal EEG asymmetry use a set of relatively specialized\\nsignal processing routines, which will be reviewed anon. This review is not intended soserve as a primer for basic signal processing, but rather is designed to highlight the datareductiontrailtypicallyfollowedinthisspeciﬁcresearchdomain.Forabasicprimer,manysourcesareavailable,includingeasilyaccessiblechaptersby Gratton(2000) andbyReilly\\n(1987), and a more in depth treatment by Glaser and Ruchkin (1976) .\\nFig.1depictsthemanystepstypicallyinvolvedintransformingelectroencephalographic\\nsignals into metrics that putatively are related to how active various brain regions may be.Thisprocessinvolvestakingasignalcollectedinthetime-domain(PanelA,leftside),andconvertingittoafrequency-domainrepresentation,usuallyintheformofapowerspectrum(Panel A, right side). This spectrum, which collapses data across time, summarizes whichfrequenciesarepresenttogreaterorlesserdegreesinthetime-domainsignal.Whetherdataarecollectedfromanextendedrestingperiodinvolvingseveralminutes,orfromdiscreteandrelatively short emotion-related segments, this spectral analysis approach always involvesexamini', 'Issues and assumptions on the road from raw signals.pdf'), 663: ('ions may be.Thisprocessinvolvestakingasignalcollectedinthetime-domain(PanelA,leftside),andconvertingittoafrequency-domainrepresentation,usuallyintheformofapowerspectrum(Panel A, right side). This spectrum, which collapses data across time, summarizes whichfrequenciesarepresenttogreaterorlesserdegreesinthetime-domainsignal.Whetherdataarecollectedfromanextendedrestingperiodinvolvingseveralminutes,orfromdiscreteandrelatively short emotion-related segments, this spectral analysis approach always involvesexamining the frequency composition of short epochs (Panel B), on the order of 1 or 2seach, and averaging power spectra across many such epochs. In the case of resting data,this involves epoching a large data segment into many smaller epochs. In the case of EEGacquired in the context of ﬂeeting emotional expression or experience, the data segmentmight still require being epoched into a few smaller epochs, and data from several suchexpressions or experiences would then be aggregated.\\nByusingepochsthatareonly1or2s-long,onemorecloselyapproximatesanassumption\\nunderlyingtheFouriertransform,themethodusedtoderivepowerspectrafromrawsignals.Fourieranalysesassumeaperiodicsignal(thestationarityassumption),andmoreoverthatanyperiodicsignalcanbedecomposedintoaseriesofsineandcosinefunctionsofvariousfrequencies, with the function for each frequency beginning at its own particular phase.A periodic signal is one that repeats, and does so at uniformly spaced intervals of time.Although strictly speaking EEG signals are not periodic, as the repetition of features isnot precisely spaced at uniform intervals, by selecting short epochs one can analyze smallsegmentsofdatathatwillhavefeaturesthatrepeatinahighlysimilarfashionatotherpointsin the waveform.\\nEpochingtypicallyinvolvestheconstructionofoverlappingepochs(PanelB),asweight-\\ning functions applied in the process of “windowing” (described below) prior to frequencyanalysis result in the central portion of the epoch receiving the most weight, and distalportions receiving negligible weight (Pa', 'Issues and assumptions on the road from raw signals.pdf'), 664: (' the repetition of features isnot precisely spaced at uniform intervals, by selecting short epochs one can analyze smallsegmentsofdatathatwillhavefeaturesthatrepeatinahighlysimilarfashionatotherpointsin the waveform.\\nEpochingtypicallyinvolvestheconstructionofoverlappingepochs(PanelB),asweight-\\ning functions applied in the process of “windowing” (described below) prior to frequencyanalysis result in the central portion of the epoch receiving the most weight, and distalportions receiving negligible weight (Panel C). By overlapping the epochs, all data pointsreceive maximum weighting in some epoch.\\nWindowingisusedtoavoidcreatingartifactualfrequenciesintheresultantpowerspec-\\ntra. Because Fourier transforms assume a periodic signal, it is assumed that the signal inthe epoch repeats inﬁnitely both forwards and backwards in time, and without the win-dowingfunctiontoreducetheendsoftheepochtonear-zerovalues,discontinuitieswould\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 185Fig.1.DepictionofthevariousdatareductionstepstypicallyusedinfrontalEEGasymmetryresearch.PanelAdepictsa10-ssegmentofrawdatafroma singlechannel\\nontheleft,andthespectralrepresentationofthisepochontheright.PanelBillustratestheprocessofepochingthelongersegmentintoshorterove rlapping2-sepochs.\\nPanel C depicts the impact of the Hamming window (dotted bell curve) on a single epoch, with the gray line representing the raw signal and the black line r epresenting\\nthe signal after the application of the window. Note that a discontinuity would result if a copy of the raw (gray) signal were concatenated following th is signal, but no\\nsuchdiscontinuitywouldresultforasimilarlyconcatenatedwindowed(black)signal.PanelDdisplaysthenetweighting(blackline,scaledtoﬁtgr aph)ofoverlapping\\nhamming windows (gray lines) for 2-s epochs. Panel E illustrates the impact of averaging power spectra. The top nine gray lines are the spectral repres entation of nine\\n2-sepochs,andthelowerblacklineistheaveragespectrum.Notethatalphapower(8–13Hz)issomewhatvariablefromepochtoepo', 'Issues and assumptions on the road from raw signals.pdf'), 665: ('ult if a copy of the raw (gray) signal were concatenated following th is signal, but no\\nsuchdiscontinuitywouldresultforasimilarlyconcatenatedwindowed(black)signal.PanelDdisplaysthenetweighting(blackline,scaledtoﬁtgr aph)ofoverlapping\\nhamming windows (gray lines) for 2-s epochs. Panel E illustrates the impact of averaging power spectra. The top nine gray lines are the spectral repres entation of nine\\n2-sepochs,andthelowerblacklineistheaveragespectrum.Notethatalphapower(8–13Hz)issomewhatvariablefromepochtoepoch,butthattheavera gespectrum\\nreveals a distinct alpha peak. Vertical axis in Panel E is power in /H9262V2.\\n186 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nresult if one were to place a copy of the epoch immediately before or after itself. Fourier\\nmethodswouldintroduceavarietyofspuriousfrequenciestoreconstructasignalwithsuchdiscontinuity. By windowing, the discontinuity is avoided (Panel C), but at the expense ofpreventing the data near the end of the epoch from being fully represented in the resultantpower spectrum. The overlapping of epochs (Panel D) provides a solution to this latterproblem, as data minimally weighted at the end of epoch xwill be weighted more heavily\\nin epoch x+1.\\nMostcomputersignalprocessingpackagesuseafastFouriertransform(FFT),whichas\\nthe name implies is considerably faster and computationally less complex than the moregeneral case discrete Fourier transform (DFT). The FFT requires that the epochs to beanalyzed have 2\\nndata points. Data are often sampled at a rate that is a power of two, thus\\nallowingepochsof1or2s,butinothercasesofsampleratesthatdeviatefromapoweroftwo (e.g., 250Hz), epoch length will need to be tailored accordingly (e.g., 2.048s). For adata segment of 1024 data points, the DFT will take about 10 times longer to arrive at thesame result as the FFT.\\n1\\nTheresultoftheFFTistwospectra,apowerspectrumandaphasespectrum.Thepower\\nspectrumreﬂectsthepowerinthesignalateachfrequencyfromdctotheNyquistfrequency,2\\nwith a spectral value every 1/ Tpoints, where Tis the length', 'Issues and assumptions on the road from raw signals.pdf'), 666: ('s a power of two, thus\\nallowingepochsof1or2s,butinothercasesofsampleratesthatdeviatefromapoweroftwo (e.g., 250Hz), epoch length will need to be tailored accordingly (e.g., 2.048s). For adata segment of 1024 data points, the DFT will take about 10 times longer to arrive at thesame result as the FFT.\\n1\\nTheresultoftheFFTistwospectra,apowerspectrumandaphasespectrum.Thepower\\nspectrumreﬂectsthepowerinthesignalateachfrequencyfromdctotheNyquistfrequency,2\\nwith a spectral value every 1/ Tpoints, where Tis the length of the epoch analyzed. The\\nphasespectrumpresentsthephaseofthewaveformateachinterval1/ T.Thesetwospectra\\ncanjointlybeusedtoreconstructtheoriginaltime-domainwaveform.Psychophysiologists,however, typically discard the phase spectrum and focus their analyses only on the powerspectrum.\\nAsanFFTisappliedtoeachepoch,manypowerspectraresult,andtheaverageofthese\\npowerspectraisultimatelytakenasthebasisforanalysis(PanelE).Thedatainthisresultantspectrummightentailbetween20and200datapoints(theprecisenumberbeing T×(f/2),\\ndependent on the epoch length Tand the sample rate f), a substantial reduction from the\\nrawdatasignalthatwilllikelyhavehundredsofdatapointspersecondforseveralminutes.Thespectrarepresent,therefore,arelativelyeconomicalrepresentationoftheoriginalsig-nal, with higher sampling frequencies and longer epochs resulting in more spectral points.Furtherreductionisaccomplishedbysummarizingdatawithinconventionally-deﬁnedfre-quencybands.Alphapower,eithertotal( /H9262V\\n2)ordensity( /H9262V2/Hz),ismostoftenexamined,\\nand is typically operationalized as power between 8 and 13Hz in adults, although lowerfrequencies have been examined in children (for review see Coan and Allen, 2003b ), as\\ntheselowerfrequenciesinthedevelopingbrainareassumedtobeequivalenttoadultalpha\\n1TheDFTtransformisageneralcaseinstantiationoftheFouriertransformfordiscretelysampledsignals,but\\nit is computationally intensive, with the time taken to compute the spectral representation being proportional tothesquareofthenumberonpointsintheseries.Thecomparablecomp', 'Issues and assumptions on the road from raw signals.pdf'), 667: ('s typically operationalized as power between 8 and 13Hz in adults, although lowerfrequencies have been examined in children (for review see Coan and Allen, 2003b ), as\\ntheselowerfrequenciesinthedevelopingbrainareassumedtobeequivalenttoadultalpha\\n1TheDFTtransformisageneralcaseinstantiationoftheFouriertransformfordiscretelysampledsignals,but\\nit is computationally intensive, with the time taken to compute the spectral representation being proportional tothesquareofthenumberonpointsintheseries.ThecomparablecomputationtimeusingtheFFT,bycontrast,isproportional to N(log\\n2(N)). For an epoch of 1024 points ( N=1024), the DFT will take 102.4 times longer than\\nthe FFT to compute the spectral representation of the signal.\\n2TheNyquistfrequency,namedafterHenryNyquist,isthefastestfrequencythatcanberepresentedforagiven\\nsamplingrate,andisequalto1/2thesamplingrate.Nyquist,whoseentirecareerwasatAT&TBellLaboratories,published a 1928 paper ( Nyquist, 1928 ) in which he proposed a theorem that a sample rate twice as fast as the\\nhighest signal frequency will capture that signal perfectly. Stated differently, the highest frequency which can beaccurately represented is one-half of the sampling rate, and this frequency has come to be known as the Nyquistfrequency.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 187\\nKurtosis\\n-10123456789\\n02 13\\nLn-TransformedRawSkewness\\n00.511.522.53\\n-1.5 -1 -0.5 0\\nLn-TransformedRaw\\nFig.2.Skewnessstatistic(toppanel)andKurtosisstatistic(lowerpanel)fornaturallogtransformed( X-axis)and\\nraw (Y-axis) power values. Statistics were calculated on 34 subjects with complete resting EEG data reported in\\nCoanandAllen(2003a) foreachof18scalpsites(FP1,FP2,F3,F4,F7,F8,FTC1,FTC2,C3,C4,T3,T4,T5,T6,\\nTCP1,TCP2,P3,P4)usingtheaveragereference.Thesolidlineineachplotrepresentsthedemarcationbetweenimprovementtowardsnormality(abovetheline)fromgreaterdeviationfromnormality(belowtheline)asaresultof the natural-log transformation.\\n(e.g.,Fox and Davidson, 1987 ). Alpha power is then taken as an index of the inverse of\\ncorti', 'Issues and assumptions on the road from raw signals.pdf'), 668: ('s) power values. Statistics were calculated on 34 subjects with complete resting EEG data reported in\\nCoanandAllen(2003a) foreachof18scalpsites(FP1,FP2,F3,F4,F7,F8,FTC1,FTC2,C3,C4,T3,T4,T5,T6,\\nTCP1,TCP2,P3,P4)usingtheaveragereference.Thesolidlineineachplotrepresentsthedemarcationbetweenimprovementtowardsnormality(abovetheline)fromgreaterdeviationfromnormality(belowtheline)asaresultof the natural-log transformation.\\n(e.g.,Fox and Davidson, 1987 ). Alpha power is then taken as an index of the inverse of\\ncortical activity ( Davidson, 1988 ), an assumption that will be explored further below.\\nAlphapoweratanygivensitethenistypicallynaturallogtransformed,asuntransformed\\npower values tend to be positively skewed, as depicted in Fig. 2. The top panel of Fig. 2\\ndepicts the Skewness Statistic for the raw power values ( Y-axis) and the natural-log trans-\\nformed values ( X-axis) at each of 18 scalp sites. The lower panel similarly depicts the\\nKurtosis statistic for the same data set. The solid line in each plot represents the demarca-tion between improvement towards normality (above the line) and greater deviation fromnormality (below the line) as a result of the natural-log transformation. As can be seenfrom the ﬁgure, the transformation improves the skewness for 89% of the scalp sites, andimproves kurtosis for 83% of the scalp sites. In absolute terms, using the 95% conﬁdenceintervals,priortonatural-logtransformation,94%ofsitesdeviatedsigniﬁcantlyfromnor-malityintermsofskewness,and83%deviatedsigniﬁcantlyintermsofkurtosis.Followingtransformation,only33and39%ofsitesstilldeviatedsigniﬁcantlyfromnormalityinterms\\n188 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nofskewnessandkurtosis,respectively.Thusalthoughsomesitesstillexhibitdistributionsof\\nnatural-log transformed scores that deviate from normality, the natural-log transformationsubstantially improves the distributional characteristics of the data.\\n2. Comparing left and right activity\\nBecause asymmetrical activity is of interest, investigators often use a diff', 'Issues and assumptions on the road from raw signals.pdf'), 669: ('.Followingtransformation,only33and39%ofsitesstilldeviatedsigniﬁcantlyfromnormalityinterms\\n188 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nofskewnessandkurtosis,respectively.Thusalthoughsomesitesstillexhibitdistributionsof\\nnatural-log transformed scores that deviate from normality, the natural-log transformationsubstantially improves the distributional characteristics of the data.\\n2. Comparing left and right activity\\nBecause asymmetrical activity is of interest, investigators often use a difference score\\n(ln(Right )−ln(Left)alpha power) to conveniently summarize the relative activity at ho-\\nmologousrightandleftleads.\\n3Thedifferencescorethusprovidesasimpleunidimensional\\nscalerepresentingtherelativeactivityoftherightandlefthemispheres,withhigherscoresputatively indicative of relatively greater left frontal activity (assuming that alpha is in-\\nversely related to activity). An additional beneﬁt of this difference score metric is that itprovidessomedegreeofcorrectionforoverallalphapower,aslargeindividualdifferencesin overall alpha power could be confounded with the magnitude of the asymmetry. Thecorrectionforoverallpowerstemsfromthefactthatthenaturallogdifferencescoremetricis not a simple difference score, but a difference of natural log transformed scores. Rulesoflogarithmicsubtractionstatethatthedifferenceoftwonatural-logtransformedscoresisequivalent to the natural log transform of the ratio of these scores:\\nln(R)−ln(L)=ln/parenleftbiggR\\nL/parenrightbigg\\n(1)\\nThus this difference metric is actually the natural log transform of the ratio of right to left\\nalpha power, which provides some degree of correction for overall power expressing eachsubject’s asymmetry in terms of a ratio. The extent of the correction is conﬁrmed by com-paring the values of the natural log difference score metric to another sometimes-utilizedmetric, a “normalized” difference score computed as (R−L)/(R +L). This normal-\\nized difference score metric correlates over 0.99 with the natural log asymmetry metric(ln(Right )−ln(Left);Alle', 'Issues and assumptions on the road from raw signals.pdf'), 670: ('he natural log transform of the ratio of right to left\\nalpha power, which provides some degree of correction for overall power expressing eachsubject’s asymmetry in terms of a ratio. The extent of the correction is conﬁrmed by com-paring the values of the natural log difference score metric to another sometimes-utilizedmetric, a “normalized” difference score computed as (R−L)/(R +L). This normal-\\nized difference score metric correlates over 0.99 with the natural log asymmetry metric(ln(Right )−ln(Left);Allenetal.,2004 ).Thereisinfactanonlinearfunctionrelatingthese\\ntwo metrics over a broad range of scores, because when either RorLgets very small, the\\nnormalizedmetricisboundedbythevalues1and −1andthenatural-logasymmetrymetric\\nwill not have such bounds. Over the range of values encountered in asymmetry research,however, the function is almost perfectly linear, as illustrated in Fig. 3.\\nThe difference metric is rather handy in several respects, notably that it mitigates the\\nimpact of individual differences in skull thickness that would have sizeable inﬂuences onrecordedsignalamplitude( Esheletal.,1995;Leissneretal.,1970;Pfefferbaum,1990 ),and\\nthe difference scores can simplify analyses, such as those involving correlations betweenfrontal asymmetry (as a difference score) and an individual difference measure (e.g., Be-\\n3Similar distributional improvements as a result of natural log transformation are seen for the asymmetry\\nscoresbasedontheselogtransformedvalues.Comparingasymmetryscoresbasedonthedifferenceofnatural-logtransformedanduntransformedvalues,thetransformationimprovestheskewnessoftheasymmetryscorefor67%of the scalp sites, and improves kurtosis for 89% of the scalp sites. In absolute terms, using the 95% conﬁdenceintervals,priortonatural-logtransformation,67%ofthedifferencesscoresdeviatedsigniﬁcantlyfromnormalityintermsofskewness,andalsokurtosis,butfollowingtransformation,only22and33%ofasymmetryscoresstilldeviated signiﬁcantly from normality in terms of skewness and kurtosis, respectively.\\nJ.J.B. Allen et al./B', 'Issues and assumptions on the road from raw signals.pdf'), 671: ('ogtransformedanduntransformedvalues,thetransformationimprovestheskewnessoftheasymmetryscorefor67%of the scalp sites, and improves kurtosis for 89% of the scalp sites. In absolute terms, using the 95% conﬁdenceintervals,priortonatural-logtransformation,67%ofthedifferencesscoresdeviatedsigniﬁcantlyfromnormalityintermsofskewness,andalsokurtosis,butfollowingtransformation,only22and33%ofasymmetryscoresstilldeviated signiﬁcantly from normality in terms of skewness and kurtosis, respectively.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 189\\nFig.3.Therelationshipoftheasymmetrymetric(ln (Right )−ln(Left))andametricnormalizedforoverallpower\\n((R−L)/(R +L)),overalargerangeofpossiblealphapowervalues.Inasymmetryresearch,theln (Right )−ln(Left)\\nmetric produces scores that typically are in the range of ±0.5, the range demarcated by the two lines, where the\\nrelationship is linear. From Allen et al. (2004) , reprinted with permission from Blackwell Publishing. © 2004,\\nSociety for Psychophysiological Research.\\nhavioralActivationScale; CoanandAllen,2003a;Harmon-JonesandAllen,1997;Sutton\\nand Davidson, 1997 ).\\nDifference scores have been criticized for their potential unreliability, as errors of mea-\\nsurementwitheachoftheconstituentscoresarecompoundedwhenthedifferencescoreiscalculated. The reliability of change scores is of greatest concern, however, when the con-stituentscoreshavemodestreliability.Alphapoweratagivenlead,however,demonstratesextremelyhighreliability,withcoefﬁcientalphavaluestypicallyover0.90basedon8minofdata.Moreover,thereliabilityofthedifferencescoreforfrontalregionshasbeencalcu-lated in several studies and routinely is high, excepting frontal pole sites (e.g., coefﬁcientalphas for frontal asymmetry (difference) scores ranging from 0.85 to 0.90 at baseline inAllen,Urry,Hitt,andCoan(2004) ;from0.76to0.91in CoanandAllen(2003a) ;amedian\\nof0.83in Coanetal.(2001) ;from0.80to0.93in Reidetal.(1998) ;andfrom0.81to0.92\\ninTomarken et al. (1992) ).\\n4\\n4Aseparateissueconcernsthepowerofstatisticalteststhatemploydiffe', 'Issues and assumptions on the road from raw signals.pdf'), 672: ('ofdata.Moreover,thereliabilityofthedifferencescoreforfrontalregionshasbeencalcu-lated in several studies and routinely is high, excepting frontal pole sites (e.g., coefﬁcientalphas for frontal asymmetry (difference) scores ranging from 0.85 to 0.90 at baseline inAllen,Urry,Hitt,andCoan(2004) ;from0.76to0.91in CoanandAllen(2003a) ;amedian\\nof0.83in Coanetal.(2001) ;from0.80to0.93in Reidetal.(1998) ;andfrom0.81to0.92\\ninTomarken et al. (1992) ).\\n4\\n4Aseparateissueconcernsthepowerofstatisticalteststhatemploydifferencescores.Thepowerofsigniﬁcance\\ntests using difference scores is only indirectly inﬂuenced by the reliability of these scores. Signiﬁcance tests ofdifferences can be powerful even if the reliability of the difference scores is near zero ( Overall and Woodward,\\n1975;Zimmermanetal.,1993 ).Theparadoxpointedoutby OverallandWoodward(1975) isthatdifferencescores\\nwith zero reliability can in fact give rise to high power to detect a signiﬁcant difference. The paradox is resolvedwhenoneconsidersthatreliabilityofthedifferencescoresdependsontheexistenceofvarianceinthedifferencescore that can reliably rank-order individuals in terms of the magnitude of their difference scores, but that the\\npowertodetectadifferenceinvolvesassessinga meandifferencebetweenthetwoscoresrelativetothevariancein\\n190 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nDespite the simplicity of the difference score, the contribution of activity in each hemi-\\nsphere is ultimately of interest, which will require analyses involving the examination ofdatafromeachhemisphereasadifferencemetricisuninformativewithrespecttothecon-tributionofeachconstituenthemisphere( Davidsonetal.,2000a ).Themoststraightforward\\napproachinvolvesanalyzing(ln-transformed)poweratleftandrightsitesinananalysisofvariance(ANOVA)orthemoregenerallinearmodel(GLM),withnotonlyregion(anteriorto posterior) as a factor, but hemisphere (left versus right) as well. In these models, indi-vidual differences in overall power are removed, and region speciﬁc variations in power(e.g.,occi', 'Issues and assumptions on the road from raw signals.pdf'), 673: ('ination ofdatafromeachhemisphereasadifferencemetricisuninformativewithrespecttothecon-tributionofeachconstituenthemisphere( Davidsonetal.,2000a ).Themoststraightforward\\napproachinvolvesanalyzing(ln-transformed)poweratleftandrightsitesinananalysisofvariance(ANOVA)orthemoregenerallinearmodel(GLM),withnotonlyregion(anteriorto posterior) as a factor, but hemisphere (left versus right) as well. In these models, indi-vidual differences in overall power are removed, and region speciﬁc variations in power(e.g.,occipitalalphaisgreaterthanfrontalalpha)arepartitionedasregionmaineffects.Insuchamodel,withEEGpowerasthedependentvariable,theinteractionofanindependentvariable with hemisphere will yield the same information as a main effect of this inde-pendent variable when using asymmetry scores as the dependent variable. The follow-uptests to decompose the interaction can then examine the contribution of each hemisphereindividually.\\nThe standard ANOVA approach provides a straightforward method of examining the\\npower from each hemisphere’s lead or leads when the independent variable of interest isamenable to the ANOVA approach, such as when comparing depressed and nondepressedsubjects, or when comparing two or more emotion elicitation conditions. This approachis limited, however, as the standard ANOVA with a between subjects or within subjectsfactorfailstoallowforanexaminationofthepoweratagivenleadorleadswithacontin-uously varying independent variable such as ratings of emotional valence or intensity, oranindividualdifferencevariablesuchasbehavioralactivation.Thereexistafewpublishedapproaches that have included a continuous predictor in the model, the whole-head andhomologous-lead residualized power approach ﬁrst reported by Wheeler et al. (1993) , and\\nthehierarchicalgenerallinearmodelstrategy(e.g., CoanandAllen,2003a )ormixedmodel\\nstrategy (e.g., Kline et al., 2002 ).\\n2.1. Residualized power approach\\nWheeler et al. (1993) adopted a two-stage analytic approach, examining ﬁrst the corre-\\nlation between the asymmetry difference sc', 'Issues and assumptions on the road from raw signals.pdf'), 674: ('ariablesuchasbehavioralactivation.Thereexistafewpublishedapproaches that have included a continuous predictor in the model, the whole-head andhomologous-lead residualized power approach ﬁrst reported by Wheeler et al. (1993) , and\\nthehierarchicalgenerallinearmodelstrategy(e.g., CoanandAllen,2003a )ormixedmodel\\nstrategy (e.g., Kline et al., 2002 ).\\n2.1. Residualized power approach\\nWheeler et al. (1993) adopted a two-stage analytic approach, examining ﬁrst the corre-\\nlation between the asymmetry difference score and continuous measures of self-reported\\nthisdifferencescore.Thusifoneconstituentscore(e.g.Leftactivity)wereforeverysubjectaconstant klessthan\\ntheotherconstituentscore(e.g.Rightactivity),thentherewouldbenovariabilityinthedifferencescores,andnoreliability.Ontheotherhand,themeandifferencescorewouldbe k,withnovariancearoundthatmean,allowing\\nfor a powerful statistical test that the mean difference is signiﬁcantly different than zero, and that a statisticallysigniﬁcantdifferencehasbeenfound.Thepragmaticimplicationsarethatthereliabilityofdifferencescoresifareof little consequence if one wishes to test the signiﬁcance of such a difference (e.g. to test that Right activity isgreaterthanLeftactivityforthegroupasawhole),butthereliabilityofthedifferencescorewillbehighlyrelevantwhen one is using the difference score to examine how individual differences in that difference score relate toothervariablesofinterest(e.g.howindividualdifferencesintheasymmetryscorerelatetoindividualdifferencesin BAS scores). In the latter case, the reliability of the difference score will impose constraints on the magnitudeof the correlation that can be observed, as the maximum correlation that can be observed between two variableswillbethesquarerootoftheproductofthereliabilityofthetwovariables.Thus,becauseasizableportionoftheresearchexaminingfrontalEEGasymmetryisconcernedwiththerelationshipofindividualdifferencesinfrontalEEG asymmetry to other individual difference measures, the reliability of the asymmetry metric assumes greatimportance.\\nJ.', 'Issues and assumptions on the road from raw signals.pdf'), 675: ('ase, the reliability of the difference score will impose constraints on the magnitudeof the correlation that can be observed, as the maximum correlation that can be observed between two variableswillbethesquarerootoftheproductofthereliabilityofthetwovariables.Thus,becauseasizableportionoftheresearchexaminingfrontalEEGasymmetryisconcernedwiththerelationshipofindividualdifferencesinfrontalEEG asymmetry to other individual difference measures, the reliability of the asymmetry metric assumes greatimportance.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 191\\nTable 1\\nCorrelationsbetweennatural-logtransformedalphapowerathomologousleadscollectedfor8minunderrestingconditions\\nSites Reference\\nAR LM\\nFP1–FP2 0.997 0.998F7–F8 0.983 0.971F3–F4 0.990 0.992FTC1–FTC2 0.975 0.943C3–C4 0.977 0.981T3–T4 0.918 0.891TCP1–TCP2 0.944 0.948P3–P4 0.965 0.982T5–T6 0.907 0.932\\nNote.AR: average reference, LM: computer linked mastoid reference; data from 34 subjects reported in Coan\\net al. (2001) .\\naffect.Uponﬁndingsigniﬁcantcorrelations,thesecondstagewastoinvestigatethecontri-\\nbution of each hemisphere, but unconfounded by the large individual differences in powerdue to irrelevant factors such as scalp thickness. Power at a given electrode (e.g., F3) wasresidualized, using a hierarchical regression, ﬁrst entering the average power across avail-ablescalpsites,andasthesecondstepenteringpowerfromthehomologouslead(e.g.,F4).The resultant residualized values were then correlated with the variable of interest (e.g.,self-reported affect).\\nTheﬁrststepofthisprocedurepreservesindividualpatternsofactivityacrossscalpsites,\\nadjusted for overall power. The second step of this procedure was introduced by Wheeler\\net al. (1993) ostensibly to statistically account for volume-conducted activity from the ho-\\nmologouselectrode.Itisunclearwhyonewouldbemoreconcernedwithvolumeconductionfromaleadovertheoppositehemisphere,whichinmanyinstancesisconsiderablyfurtheraway from the site of interest than ipsilateral leads adjacent to the site. On the other hand,', 'Issues and assumptions on the road from raw signals.pdf'), 676: ('ct).\\nTheﬁrststepofthisprocedurepreservesindividualpatternsofactivityacrossscalpsites,\\nadjusted for overall power. The second step of this procedure was introduced by Wheeler\\net al. (1993) ostensibly to statistically account for volume-conducted activity from the ho-\\nmologouselectrode.Itisunclearwhyonewouldbemoreconcernedwithvolumeconductionfromaleadovertheoppositehemisphere,whichinmanyinstancesisconsiderablyfurtheraway from the site of interest than ipsilateral leads adjacent to the site. On the other hand,theactivitybetweenhomologousleadsisoftenhighlycorrelated,withalphapowervaluesbeingcorrelatedontheorderof0.95orevenhigher(see Table1),\\n5andcouldinpartreﬂect\\nthe dense contralateral cortico-cortical connections between some homologous regions aswellasvolumeconductioneffects.Asseenin Table1,correlationsareuniformlyhigh,but\\nhigher yet between closely spaced homologous leads (e.g., FP1 and FP2) as compared tomore widely spaced homologous leads (e.g., T5 and T6). Whether volume conducted, ortheresultofinterconnectivity,thesecondstepoftheregressionapproachofWheeleretal.then statistically controlled for shared variance between left and right homologous leads,which is likely to be substantial.\\n5The fact that the difference between these highly correlated sites is nonetheless predictive of state affect\\nand individual differences merits a brief comment. The asymmetry score reﬂects the difference between thecontributionoftheactivityoftheleftandrightleads withinsubjects,whereasthecorrelationsbetweensitesreﬂect\\nthesimilaritiesofactivityateachlead acrosssubjects.Itisthusthecasethatbetween-persondifferencesinalpha\\npower at a given site are substantially larger than the within person differences between sites, but that the latternonetheless have some degree of predictive validity.\\n192 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nFig.4.CorrelationsbetweenBehavioralActivationScale(BAS)scoresandEEGasymmetry(leftpanels)andresid-\\nualizedpoweratconstituentsites(rightpanels),fordataunderanaveragedreference(AR)andcompute', 'Issues and assumptions on the road from raw signals.pdf'), 677: ('tiesofactivityateachlead acrosssubjects.Itisthusthecasethatbetween-persondifferencesinalpha\\npower at a given site are substantially larger than the within person differences between sites, but that the latternonetheless have some degree of predictive validity.\\n192 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nFig.4.CorrelationsbetweenBehavioralActivationScale(BAS)scoresandEEGasymmetry(leftpanels)andresid-\\nualizedpoweratconstituentsites(rightpanels),fordataunderanaveragedreference(AR)andcomputer-averagedmastoids (CAM) reference. Data from subjects presented in Coan and Allen (2003a) .\\nThe results of this procedure produce what has become a fairly typical pattern: for each\\nsigniﬁcant correlation between the R−Ldifference score and a criterion, two signiﬁcant\\ncorrelations emerge, approximately equal in magnitude to the original correlation, but op-positeinsigntooneanother,attheconstituentleads.Correlationsattherightleadmaintainthesignofthe R−Ldifferencescore,andcorrelationsattheleftleadreversedirection.For\\nexample, Wheeleretal.(1993) foundthattheF4–F3(ln-transformed)asymmetryscorecor-\\nrelatedwithpositiveaffect0.45,andthatresidualizedln-transformedpoweratF4correlated0.44 and at F3 correlated −0.49 with positive affect. Similarly, Harmon-Jones and Allen\\n(1998)found that the F4–F3 (ln-transformed) asymmetry score correlated 0.48 with trait\\nanger,andthatresidualizedln-transformedpoweratF4andF3correlated0.45and −0.46,\\nrespectively,withtraitanger.Toillustratemoregenerallythispattern, Fig.4presentscorre-\\nlations between BAS scores and asymmetry scores (left panels) and residualized power atconstituent sites (right panels). Treating these correlations themselves data points, the ob-tainedvaluesfromresidualizedpoweratrightleadscorrelated0.94withthevaluesobtainedusing the difference score, and the values from residualized power at left leads correlated−0.88 with those obtained using the difference score. Additionally, the values obtained\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 193\\nusingresidu', 'Issues and assumptions on the road from raw signals.pdf'), 678: ('tions between BAS scores and asymmetry scores (left panels) and residualized power atconstituent sites (right panels). Treating these correlations themselves data points, the ob-tainedvaluesfromresidualizedpoweratrightleadscorrelated0.94withthevaluesobtainedusing the difference score, and the values from residualized power at left leads correlated−0.88 with those obtained using the difference score. Additionally, the values obtained\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 193\\nusingresidualizedleftvaluescorrelated −0.87withthoseobtainedusingresidualizedright\\nvalues.\\nThus,theprocedurethatwasoriginallydevisedtoexaminetheindependentcontributions\\nofeachhemispherewouldappeartodistributethevariancerelativelyequallyandinoppositedirectionsacrossthetwohemispheres,whichwouldbeexpectedifactivityathomologousleadsisextremelyhighlycorrelated,asisthecasewithhomologousleftandrightleadpower(Table1).Todemonstratewhysuchapatternwouldbeexpectedwithsuchhighlycorrelated\\ndata,considertheimpactonresidualizinglefthemispherepoweronrighthemispherepower.The residualized score ( L\\nresid) for a left hemisphere lead ( L)i sg i v e nb y\\nLresid=L−ˆL (2)\\nwhere ˆLis the predicted power at the left hemisphere lead given power at the right hemi-\\nsphere lead, determined by the raw score regression (prediction) formula:\\nˆL=a+b(R) (3)\\nwhereaistheinterceptand bistheunstandardizedregressioncoefﬁcient.Inthecasewhere\\nLandRarenearlyperfectlypositivelycorrelated(see Table1),withthedistributionofeach\\nhaving virtually identical means and standard deviations, the intercept awill approach 0,\\nand the regression coefﬁcient bwill approach one,6reducingEq. (3)to:\\nˆL≈0+1(R)=R (4)\\nSubstituting the results of Eq. (4)forˆLinEq. (2), it is revealed that, when LandRare\\nnearly perfectly correlated:\\nLresid=L−ˆL≈L−R (5)\\nThusthisresidualizationprocedureproducesresidualvaluesforlefthemisphereleadsthat\\nwill approach the value L−Ras the correlation between left and right leads approaches\\n1.0,providedthattheunstandardizedregressioncoefﬁcientapproaches1andtheint', 'Issues and assumptions on the road from raw signals.pdf'), 679: ('tandard deviations, the intercept awill approach 0,\\nand the regression coefﬁcient bwill approach one,6reducingEq. (3)to:\\nˆL≈0+1(R)=R (4)\\nSubstituting the results of Eq. (4)forˆLinEq. (2), it is revealed that, when LandRare\\nnearly perfectly correlated:\\nLresid=L−ˆL≈L−R (5)\\nThusthisresidualizationprocedureproducesresidualvaluesforlefthemisphereleadsthat\\nwill approach the value L−Ras the correlation between left and right leads approaches\\n1.0,providedthattheunstandardizedregressioncoefﬁcientapproaches1andtheinterceptapproaches 0. Similarly, by implementing Eqs. (2)–(5) for right hemisphere residualized\\n(R\\nresid)andpredicted( ˆR)scores,itwillbethecasethatresidualvaluesforrighthemisphere\\nleadswillapproachthevalue R−Lasthecorrelationbetweenleftandrightleadsapproaches\\n1.0.Therefore,thisprocedurewillmakeitappearthatrighthemisphereleadscorrelatewithacriterionvariableinthesamedirectionandapproximatemagnitudeasthe R−Ldifference\\nscore, and that left hemisphere leads correlate with a criterion variable in the oppositedirection but same approximate magnitude as the R−Ldifference score.\\n6Empirically, it appears to be the case that the unstandardized regression weight is very close to one and\\nthe intercept is very close to zero. Resting data for 34 subjects (from Coan et al., 2001 ) were used to predict\\nleft hemisphere frontal activity from the homologous right hemisphere frontal activity. For the prediction of fourfrontal sites (FP1, F7, F3, and FTC1), each from its homologous right hemisphere site (FP2, F8, F4, and FTC2),across both LM and AR reference schemes (for a total of eight separate regressions), the median unstandardizedregression coefﬁcient was 1.028 (range: 1.012–1.071) and the median intercept was −0.039 (range: −0.098 to\\n0.031).\\n194 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\n2.2. Revised residualized power approach\\nMorerecently, Davidsonetal.(2000a) haveproposedanimprovedvariantonthemethod\\nofWheeler et al. (1993) , one that does not include homologous lead power in the resid-\\nualization calculation', 'Issues and assumptions on the road from raw signals.pdf'), 680: ('ss both LM and AR reference schemes (for a total of eight separate regressions), the median unstandardizedregression coefﬁcient was 1.028 (range: 1.012–1.071) and the median intercept was −0.039 (range: −0.098 to\\n0.031).\\n194 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\n2.2. Revised residualized power approach\\nMorerecently, Davidsonetal.(2000a) haveproposedanimprovedvariantonthemethod\\nofWheeler et al. (1993) , one that does not include homologous lead power in the resid-\\nualization calculations. This approach ﬁrst residualizes the criterion variable on wholehead power, and then calculates correlations between the residualized criterion variableand power at each individual site ( Davidson et al., 2000a ,p .4 1 ;Davidson, 2002 , personal\\ncommunication). This method obviates the problem detailed above using the homologouslead to residualize power at each site, but will produce a large set of correlations (one foreachscalpsite)thatarenottestedformallyinamodelthatcancontrolforexperiment-wisealphaslippage.Suchcorrelationsarequiteinformative,butultimatelymustberegardedasdescriptive.Toadequatelytesttherelationshipbetweenpowerateachsiteandthecriterionvariable, an omnibus model is required. Although the precise model will depend on thenature of the investigation, and the theory being tested, an alternative approach might befor investigators to specify a hierarchical general linear model in testing the relationshipof left and right sites to criterion variables, as highlighted below. Such an approach mightlimittheundesirableprobabilisticartifactsinvolvedinmultiplestatisticaltests,optimizingrisk for both type 1 and type 2 errors in estimating both the impact of whole head powerandeffectsofinterest.Further,suchsinglemodelapproachesmayeconomizedataanalyticeffort and reporting.\\n2.3. Hierarchical general linear models\\nHierarchical general linear models can simultaneously account for the multiple sources\\nofvariancecontributingtotherelationshipbetweencorticalasymmetryandcriterionvari-ables. Such models can include bot', 'Issues and assumptions on the road from raw signals.pdf'), 681: ('ittheundesirableprobabilisticartifactsinvolvedinmultiplestatisticaltests,optimizingrisk for both type 1 and type 2 errors in estimating both the impact of whole head powerandeffectsofinterest.Further,suchsinglemodelapproachesmayeconomizedataanalyticeffort and reporting.\\n2.3. Hierarchical general linear models\\nHierarchical general linear models can simultaneously account for the multiple sources\\nofvariancecontributingtotherelationshipbetweencorticalasymmetryandcriterionvari-ables. Such models can include both categorical and continuous predictors, and can beconstructed to test a variety of speciﬁc hypotheses of interest, including those related tooverall power, hemisphere, and even reference scheme, all in a single model. In fact, in-teractions with reference scheme can be entered into such a model in order to determinewhether relationships between asymmetry and the criterion variable are dependent uponreference scheme.\\nInconstructingthemodel,somegeneralprinciplesmayguidetheinvestigator.First,the\\nmodel should be explicitly speciﬁed, and whenever possible should be an omnibus modelthat can test all effects of interest at once. Second, the investigator should use theory toguidetheorderingofthemaineffectsfollowedbytheinteractionsofthesemaineffects.Inmostcases,maineffectspersewillnotbeofinterest(e.g.,theymayreﬂectthecontributionof overall power to the prediction of the criterion variable, or differences in overall powerbetweenanteriorandposteriorregions),buttheinteractionswillbeofinterest.Interactionsofhemisphereandregioninpredictingthecriterionvariable,forexample,wouldbefoundif there are frontally-speciﬁc hemispheric differences in the contribution of left and rightleads to the prediction of the criterion variable. A higher-order interaction with referencescheme would further indicate that the pattern of ﬁndings is reference-scheme dependent.\\nOfcourse,theuseoftheoryandcarefulsensitivitytothepossibilityofspuriousinteraction\\neffects is particularly important as the complexity of interactions increases. As interactionef', 'Issues and assumptions on the road from raw signals.pdf'), 682: ('regioninpredictingthecriterionvariable,forexample,wouldbefoundif there are frontally-speciﬁc hemispheric differences in the contribution of left and rightleads to the prediction of the criterion variable. A higher-order interaction with referencescheme would further indicate that the pattern of ﬁndings is reference-scheme dependent.\\nOfcourse,theuseoftheoryandcarefulsensitivitytothepossibilityofspuriousinteraction\\neffects is particularly important as the complexity of interactions increases. As interactioneffectsreachbeyondthirdorder,theprobabilityofoverﬁttingtheobserveddata—essentially\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 195\\nmodeling meaningless residual variance—increases. While testing for most or all effects\\nof interest in an omnibus model is highly desirable, it is not advisable if doing so requiresthe modeling of very complex (e.g., greater than fourth order) interactions. Thus a thirdprinciple might be to reduce the potential for spurious ﬁndings and complex interactionsin the hierarchical linear model designed to test for speciﬁc contribution of hemisphereby ﬁrst running a simpler but conceptually related model using the asymmetry scores.Then,followingthissimplermodel,natural-logtransformedpoweratconstituentsitescanbe entered for the relevant regions where the asymmetry score identiﬁed a relationshipbetween asymmetry and the criterion variable.\\nAsanillustration,datafrom CoanandAllen(2003a) arepresented,thesamedatathatwere\\nusedinFig.4toillustratetheresidualizationapproach.First,anomnibushierarchicallinear\\nmodel using asymmetry scores from eight regions across the scalp under both averagedreference and computer averaged mastoids reference schemes were used to construct amodelpredictingBASscores.Tocodereferencescheme,datafromeachreferenceschemewere concatenated, and a contrast-coded variable was used to code for reference scheme(cf.Aiken and West, 1991 ). The model ﬁrst entered the main effect of reference scheme,\\nfollowedbythemaineffectsofregionsorderedaccordingtotheoreticalinterestan', 'Issues and assumptions on the road from raw signals.pdf'), 683: ('mnibushierarchicallinear\\nmodel using asymmetry scores from eight regions across the scalp under both averagedreference and computer averaged mastoids reference schemes were used to construct amodelpredictingBASscores.Tocodereferencescheme,datafromeachreferenceschemewere concatenated, and a contrast-coded variable was used to code for reference scheme(cf.Aiken and West, 1991 ). The model ﬁrst entered the main effect of reference scheme,\\nfollowedbythemaineffectsofregionsorderedaccordingtotheoreticalinterestandresultsof previous studies. Sites entered ﬁrst were frontal and anterior temporal sites, followedby sites from central to parietal: F4–F3, F8–F7, FTC2–FTC1, T4–T3, C4–C3, T6–T5,TCP2–TCP1, and P4–P3. Finally, interactions of each region with reference scheme wereentered to test for the reference-speciﬁc effects. In this model, only the main effect ofF4–F3 was signiﬁcant in predicting BAS scores ( F(1,46)=8.5,P<0.01), with trends\\nfor contributions from the main effects of F8–F7 ( F(1,46)=3.6,P<0.10) and C4–C3\\n(F(1,46)=3.6,P<0.10). Reference scheme did not interact with any effects in this\\nmodel.\\nThus the focus of the subsequent analysis was to examine the contribution of left and\\nright hemisphere in the signiﬁcant midfrontal region. In this hierarchical general linearmodel, BAS scores were the dependent variable to be predicted by (1) whole head power;(2)referenceschemeand(3)naturallog-transformedalphapowerintheleft(F3)andright(F4)hemispheres.Thismodel,withwholeheadpowerenteredﬁrst,isakintotheproceduredescribedby Davidsonetal.(2000a) tostatisticallypartialouttheeffectofoverallpowerin\\npredictingBASscore.Inthismodel,maineffectsofeachsitewereofinterest.Interactionswith reference scheme were entered into the model in order to determine whether anyrelationships between site and BAS scores were dependent upon reference scheme.\\n7\\nThe overall model was approached statistical signiﬁcance ( F(9,54)=1.94,P=\\n0.07, adjusted- R2=0.12). Results indicated a main effect of the right hemisphere at\\nF4(F(1,54)=9.61,P<0.01,η2=0.15)b', 'Issues and assumptions on the road from raw signals.pdf'), 684: ('dby Davidsonetal.(2000a) tostatisticallypartialouttheeffectofoverallpowerin\\npredictingBASscore.Inthismodel,maineffectsofeachsitewereofinterest.Interactionswith reference scheme were entered into the model in order to determine whether anyrelationships between site and BAS scores were dependent upon reference scheme.\\n7\\nThe overall model was approached statistical signiﬁcance ( F(9,54)=1.94,P=\\n0.07, adjusted- R2=0.12). Results indicated a main effect of the right hemisphere at\\nF4(F(1,54)=9.61,P<0.01,η2=0.15)butnotofthelefthemisphereatF3( F(1,54)=\\n2.49,P=0.12,η2=0.04). No interactions with reference scheme were signiﬁcant, in-\\ndicating that individual differences in right frontal activity were related to differences inBAS scores, and that this main effect of the right hemisphere was not dependent uponreference scheme. Fig. 5depicts speciﬁc left/right relationships with BAS scores for F4\\nand F3. To estimate regression lines for both F3 and F4 separately, two hierarchical gen-\\n7Hadtheﬁrstmodelincludedadditionalregionsofsigniﬁcance,suchamodelcouldalsoincludetheinteraction\\nbetween hemisphere (left, right) and region (e.g. mid-frontal and lateral-frontal).\\n196 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nright\\nleft \\n2025303540455055\\n-2 -1 0 1 2 3\\nln(Alpha Power)BAS\\nFig.5.Regressionlinesforleftandrightmidfrontal(F3andF4)ln-transformedalphapowerpredictingBASscores.\\nThe regression equations depicted are: BAS =(5.12)×(Left)+37.41; BAS =(−1.98)×(Right )+36.658.\\neral linear models were run, one each for F3 and F4. For these models, reference scheme,\\nwhole head alpha power, and each site were entered such that (1) the effects of referencescheme and whole head alpha power were each removed beforetheb-coefﬁcient for each\\nsitewasestimated,and(2)dependenceuponbothreferenceschemeandwholeheadpowercould be estimated. Notably, neither model is, by itself, statistically signiﬁcant, but it isnevertheless useful to estimate such curves in the service of understanding the signiﬁcanteffects reported above. Apparent using this', 'Issues and assumptions on the road from raw signals.pdf'), 685: (' F4. For these models, reference scheme,\\nwhole head alpha power, and each site were entered such that (1) the effects of referencescheme and whole head alpha power were each removed beforetheb-coefﬁcient for each\\nsitewasestimated,and(2)dependenceuponbothreferenceschemeandwholeheadpowercould be estimated. Notably, neither model is, by itself, statistically signiﬁcant, but it isnevertheless useful to estimate such curves in the service of understanding the signiﬁcanteffects reported above. Apparent using this method, but not the residualization approach,is that the relationships between BAS and each hemisphere are not a mirror opposites, butin fact BAS is robustly related to right hemisphere activity, and largely not related to lefthemisphere activity, a surprising result given the theoretical notions concerning the lefthemisphere and approach-related motivation ( Coan and Allen, 2003a,b ;Davidson, 1992,\\n1998; Harmon-Jones and Allen, 1997 ).\\n3. Data acquisition\\n3.1. How much raw data should be acquired?\\nSufﬁcientdataarerequiredtoensurethatreliableestimatesofEEGactivityarederived.\\nAlthough the power spectrum derived from any single epoch via the FFT will reﬂect bothfrequencies that are common across epochs as well as those idiosyncratic to any givenepoch, averaging together multiple spectra can allow those frequencies to emerge that arepresentinareasonablylargeproportionofepochs(see Fig.1,PanelE),whilemitigatingthe\\ninﬂuenceofinfrequentorirregularsignals( Nunez,1981) ,whichmightoftenbeconsidered\\nnoise. Thus an investigator, by averaging across epochs, makes the implicit assumptionthatthefrequenciesthatappearcommonlyacrossepochsareofinterest,andepoch-speciﬁcvariations are of little interest. In the case of estimating trait asymmetry with the goal ofpredictingpsychologicaltraitsorpsychopathology,thisisclearlyareasonableassumption.On the other hand, a recent investigation found that variability from epoch to epoch wasitself an important correlate of neuroticism ( Minnix and Kline, 2004 ).\\nJ.J.B. Allen et al./Biological ', 'Issues and assumptions on the road from raw signals.pdf'), 686: ('stigator, by averaging across epochs, makes the implicit assumptionthatthefrequenciesthatappearcommonlyacrossepochsareofinterest,andepoch-speciﬁcvariations are of little interest. In the case of estimating trait asymmetry with the goal ofpredictingpsychologicaltraitsorpsychopathology,thisisclearlyareasonableassumption.On the other hand, a recent investigation found that variability from epoch to epoch wasitself an important correlate of neuroticism ( Minnix and Kline, 2004 ).\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 197\\nTo reliably estimate EEG asymmetry at any given assessment session, investigators and\\nreviewers often suggest that 8min of resting EEG asymmetry are necessary to obtain ade-quateinternalconsistencyreliability,asthiswasthenumberreportedintheﬁrstpsychome-tric investigation of resting EEG alpha asymmetry ( Tomarken et al., 1992 ). Substantially\\nfewer 1-min samples, however, also can produce acceptable estimates of internal consis-tency (Tomarken et al., 1992 ), and estimates based on even shorter time frames of 2min\\nhave proven similarly reliable ( Coan et al., 2001 ).\\nTomarken et al. (1992) assessed the reliability of fewer than 8min of data in a way\\nthat confounded the length of recording with the number of discrete items included in thecalculation of coefﬁcient alpha; i.e., they used the Spearman–Brown prophecy formula toestimatethereliabilityforshorterrecordingperiods,estimatingalphabasedonsixasymme-tryvaluesfor6minofdata,sevenvaluesfor7min,andeightvaluesfor8min.Toadequatelytest whether fewer minutes of recording would produce estimates of internal consistencycomparabletothoseobtainedwithmoreminutesofrecording,itwouldberequiredtokeepthenumberofvaluesconstantdespitechangesinthelengthofrecordeddata,asCronbach’salpha will be higher given more minutes (items) for analysis ( Lord and Novick, 1968 ).\\nIn a recent study ( Allen et al., 2004 ), reliability estimates from 2, 4, 6, and 8min of data\\nwere compared. Speciﬁcally, the ﬁrst 2, 4, and 6min as well as all 8min of recorded datawer', 'Issues and assumptions on the road from raw signals.pdf'), 687: ('est whether fewer minutes of recording would produce estimates of internal consistencycomparabletothoseobtainedwithmoreminutesofrecording,itwouldberequiredtokeepthenumberofvaluesconstantdespitechangesinthelengthofrecordeddata,asCronbach’salpha will be higher given more minutes (items) for analysis ( Lord and Novick, 1968 ).\\nIn a recent study ( Allen et al., 2004 ), reliability estimates from 2, 4, 6, and 8min of data\\nwere compared. Speciﬁcally, the ﬁrst 2, 4, and 6min as well as all 8min of recorded dataweredividedintoeightblockseach.Eachblockcontained2-soverlappingepochsthatweresubjectedtoFourieranalysisasreviewedabove.Ineachcase,eightasymmetryvalueswereobtained,reﬂectingtheasymmetryscoreaveragedacross1/8ofthetotaltimeofrecording(15sforthe2-mindata,30sfor4-mindata,45sforthe6-mindata,and60sforthe8-mindata).Theseeightvalueswerethentreatedasitemsonaneight-itemscaletoassessinternalconsistency reliability.\\nFig. 6shows the results for frontal regions as a function of reference scheme. As can\\nbe seen in the ﬁgure, the number of minutes of recording exerts relatively little inﬂu-ence on the estimate of internal consistency compared to the number of blocks includedin creating the estimate. Whether 2, 4, 6, or 8min of data are utilized, very small dif-ferences are apparent when all eight data segments are used as items for the purpose ofestimating internal consistency reliability. Reliability estimates begin to diverge, however,when fewer segments are utilized to estimate reliability. Thus highly internally consistentmeasures of asymmetry can be obtained with considerably fewer than the conventionallyaccepted 8min of recorded data, provided that internal consistency is estimated with asufﬁcient number of constituent blocks. To highlight this point, consider a comparisonof two comparable data points from Fig. 6: four 60-s blocks or eight 30-s blocks, which\\ncorrespond to identical timepoints from the EEG record. In all nine cases (3 regions ×3\\nreference schemes), the internal consistency of the latter is higher than the for', 'Issues and assumptions on the road from raw signals.pdf'), 688: ('asures of asymmetry can be obtained with considerably fewer than the conventionallyaccepted 8min of recorded data, provided that internal consistency is estimated with asufﬁcient number of constituent blocks. To highlight this point, consider a comparisonof two comparable data points from Fig. 6: four 60-s blocks or eight 30-s blocks, which\\ncorrespond to identical timepoints from the EEG record. In all nine cases (3 regions ×3\\nreference schemes), the internal consistency of the latter is higher than the former, byan average of 0.06 reliability units. It also appears to be the case that when fewer thanfour blocks are used to estimate the reliability, the expected rank ordering of reliabilitiesbecomes less orderly, in some cases with longer recording blocks demonstrating lowerreliability than shorter blocks. Thus, regardless of the total length of data collected, at-tempting to estimate reliability with insufﬁcient blocks will lead to misleading estimatesof internal-consistency reliability. If investigators have fewer than 8min of data available,reliable estimates of asymmetry can likely be derived, but it is recommended that inves-tigators report the internal consistency reliability of asymmetry scores based on the data\\n198 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nFig. 6. Cronbach’s alpha internal consistency estimates for resting alpha asymmetry as a function of region, reference scheme, length of data record ing, and number of\\nblocks(items)usedtocalculatealpha.Thenumberofsubjectsrangesfrom19to28,reﬂectingthatsomesubjectsdidnothaveenoughartifact-free2-s epochstocompute\\npower spectra for the for shorter recording intervals, or that a recording site was bad for a given subject. Midfrontal: F4–F3, lateral frontal: F8–F7 , and Fro-Tem-Cen:\\nfronto-tempo-central. From Allen et al. (2004) , reprinted with permission from Blackwell Publishing. © 2004, Society for Psychophysiological Research.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 199\\navailable,detailinghowmanyepochsweretreatedasit', 'Issues and assumptions on the road from raw signals.pdf'), 689: ('to28,reﬂectingthatsomesubjectsdidnothaveenoughartifact-free2-s epochstocompute\\npower spectra for the for shorter recording intervals, or that a recording site was bad for a given subject. Midfrontal: F4–F3, lateral frontal: F8–F7 , and Fro-Tem-Cen:\\nfronto-tempo-central. From Allen et al. (2004) , reprinted with permission from Blackwell Publishing. © 2004, Society for Psychophysiological Research.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 199\\navailable,detailinghowmanyepochsweretreatedasitemsinthecalculationofCronbach’s\\nalpha.\\n3.2. What reference montage is preferred?\\nThe choice of reference has been referred to as “perhaps the most divisive issue among\\ncurrentEEGresearchers”( Davidsonetal.,2000a ,p.33).Althoughrationalargumentshave\\nbeenleviedinfavorofoneoranotherreferencescheme(e.g., Hagemannetal.,2001;Reid\\net al., 1998 ), it remains an empirical question which reference scheme has the greatest\\npredictivevaliditywithrespecttomotivation,emotion,andpsychopathology.Investigatorswould ideally like measures of spectral power at a given site to reﬂect the activity at thatsite,andnotatthereferencelead.Forthispurpose,investigatorsoftensearchforarelativelyinactivereference,andhaveusedlinkedearsormastoids,averagedearsormastoids,oranaveragereferencecomprisedoftheaverageofactivityatallrecordedEEGsites.Theaveragereference, given a sufﬁciently large array of electrodes in a spherical arrangement aroundthe head, will nicely approximate an inactive reference, as activity generated from dipoleswill be revealed as positivity at one site and negativity at a site 180\\n◦opposite this site,\\nwith the sum across sites thus approaching zero with a sufﬁciently representative sampleofthesphere.Smallermontages,andthosethatdonotprovidecoverageapproximatingthesphere, however, will have more residual activity in the average reference.\\nEspeciallytroublingistheCzreference,whichhasbeenutilizedmoreoftenintheEEG\\nasymmetryliteraturethanotherreferencemontages(see CoanandAllen,2003b forreview).\\nTheCzreferencehasbeencriticizedaspotent', 'Issues and assumptions on the road from raw signals.pdf'), 690: ('d as positivity at one site and negativity at a site 180\\n◦opposite this site,\\nwith the sum across sites thus approaching zero with a sufﬁciently representative sampleofthesphere.Smallermontages,andthosethatdonotprovidecoverageapproximatingthesphere, however, will have more residual activity in the average reference.\\nEspeciallytroublingistheCzreference,whichhasbeenutilizedmoreoftenintheEEG\\nasymmetryliteraturethanotherreferencemontages(see CoanandAllen,2003b forreview).\\nTheCzreferencehasbeencriticizedaspotentiallyunder-orover-estimatingactivityatthetargetsite( Hagemannetal.,2001 ).Moreover,empiricalcomparisonsofdatafromdifferent\\nreference schemes have found Cz to be the least related to other reference schemes (e.g.,Hagemann et al., 2001; Reid et al., 1998 ). The fact that many studies have successfully\\nidentiﬁedpredictedrelationshipsusingtheCzreferencesuggestsatleasttwonon-mutuallyexclusivepossibilities:(1)signiﬁcantresultsusingtheCzreferencereﬂect,inpart,notonlythe relationship of constructs with frontal asymmetry, but also with sources of varianceunique to the Cz reference (e.g., overall alpha power); and/or, (2) asymmetry scores us-ing the Cz reference may have more irrelevant variance (error or systematic) with respectto asymmetry, and may therefore result—across studies—in inconsistencies in the patternof empirical relationships with motivation, emotion, and psychopathology. Distinguishingbetween these possibilities will be facilitated if investigators report results from multiplereference montages. Moreover, various reference schemes can be conceptualized as con-tributing unique sources of error variance to any given analysis, providing the researcherwith semi-independent measures of EEG activity, with ﬁndings that are statistically inde-pendent of reference scheme being considered the most generalizable, being less likely toreﬂect only the reference-speciﬁc “method” variance (cf. Campbell and Fiske, 1959 ).\\n3.3. Impedances in asymmetry research\\nIthasbeencustomaryinEEGasymmetryresearchtostrivetoobtainlowands', 'Issues and assumptions on the road from raw signals.pdf'), 691: ('r, various reference schemes can be conceptualized as con-tributing unique sources of error variance to any given analysis, providing the researcherwith semi-independent measures of EEG activity, with ﬁndings that are statistically inde-pendent of reference scheme being considered the most generalizable, being less likely toreﬂect only the reference-speciﬁc “method” variance (cf. Campbell and Fiske, 1959 ).\\n3.3. Impedances in asymmetry research\\nIthasbeencustomaryinEEGasymmetryresearchtostrivetoobtainlowandsymmetrical\\nimpedancesduringsubjectpreparation.Intuitively,thisseemsdesirable,asonewouldwishtohaveastrongnoise-freesignalbyloweringimpedance,andwouldliketoguaranteethat\\n200 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nany observed alpha power asymmetries reﬂect an underlying asymmetry in activity, rather\\nthan an asymmetry in impendence to recording the underlying signal. As pointed out byFerreeetal.(2001) ,however,contemporaryhighimpedanceampliﬁersmitigatetheimpact\\nof scalp impedances on the recorded signal, as the loss in the observed signal due to scalpimpedancesisdirectlyrelatedtotheaverageimpedanceofthemeasurementandtherefer-ence electrode, and inversely related to the ampliﬁer input impedance. Because ampliﬁerinput impedances are typically on the order of tens (or even hundreds) of megaohms, andscalp impedances on the order of a few kilohms, small changes in scalp impedance do notappreciablyimpacttheobservedsignal,asthemagnitudeoftheampliﬁerinputimpedanceisat least1000 times greater than the scalp impedance.\\nThe observed voltage for a given electrode E with a given reference electrode R is the\\nmeasuredvoltagedifferencebetweentheseelectrodes,or V\\nE−VR.Thisdifference, VE−VR,\\nisinﬂuencedbyelectrodeimpedance ZEandreferenceimpedance ZRandinputimpedance\\nZinas follows ( Ferree et al., 2001 , p. 538):\\nVE−VR=VD/parenleftbigg\\n2−ZE+ZR\\nZin/parenrightbigg\\n+VC/parenleftbiggZE−ZR\\nZin/parenrightbigg\\n+O/parenleftbigg1\\nZin/parenrightbigg2\\n(6)\\nwhereVDistheactualdifferential-modesignal (VEtrue−VRtrue)/2,andVCist', 'Issues and assumptions on the road from raw signals.pdf'), 692: ('e scalp impedance.\\nThe observed voltage for a given electrode E with a given reference electrode R is the\\nmeasuredvoltagedifferencebetweentheseelectrodes,or V\\nE−VR.Thisdifference, VE−VR,\\nisinﬂuencedbyelectrodeimpedance ZEandreferenceimpedance ZRandinputimpedance\\nZinas follows ( Ferree et al., 2001 , p. 538):\\nVE−VR=VD/parenleftbigg\\n2−ZE+ZR\\nZin/parenrightbigg\\n+VC/parenleftbiggZE−ZR\\nZin/parenrightbigg\\n+O/parenleftbigg1\\nZin/parenrightbigg2\\n(6)\\nwhereVDistheactualdifferential-modesignal (VEtrue−VRtrue)/2,andVCisthecommon-\\nmode signal (VEtrue−VRtrue)/2. The latter term VCresults primarily 60cycle (US)\\nor 50cycle (Europe) ambient noise, and the extent to which it emerges is a function ofimpedance mismatch. The former term V\\nDis primarily the signal of interest, resulting\\nfrom voltage potential differences between the two sites, but attenuated by the ratio ofthe scalp impedances to the ampliﬁer input impedance. Since the scalp impedances area tiny fraction of the size of the input impedance, even appreciable differences in scalpsiteimpedancewillnotmeasurablyattenuatethevoltagepotentialdifferenceobservedbe-tween the two sites. The ﬁnal term in the equation is a residual term to account for othersources in the differential ampliﬁer circuit that inﬂuence the observed voltage potentialdifference, the sum of which are negligible ( Ferree, 2002 , personal communication). The\\nmathematicalnotation Oisstandardfor“order”inTaylorseries,andsimpliﬁestheexpres-\\nsionwithoutappreciablyalteringtheresultobtainedwiththesimpliﬁedequationinvolvingonly the ﬁrst two terms. In the full equation there are a series of higher order terms in-volving powers of 1/ Z\\nin, which the term O(1/Zin)2denotes. With a high input impedance\\nZin, the impact of (1/ Zin)2will be negligible, and the impact of higher powers approaches\\nzero.\\nFig.7depictstheimpactofmismatchedimpedancesunderconditionslikelytobeencoun-\\ntered in a psychophysiological laboratory. The data depicted in Fig. 7show the observed\\nasymmetry score (ln (Right )−ln(Left)) as a function of ampliﬁer i', 'Issues and assumptions on the road from raw signals.pdf'), 693: ('volvingonly the ﬁrst two terms. In the full equation there are a series of higher order terms in-volving powers of 1/ Z\\nin, which the term O(1/Zin)2denotes. With a high input impedance\\nZin, the impact of (1/ Zin)2will be negligible, and the impact of higher powers approaches\\nzero.\\nFig.7depictstheimpactofmismatchedimpedancesunderconditionslikelytobeencoun-\\ntered in a psychophysiological laboratory. The data depicted in Fig. 7show the observed\\nasymmetry score (ln (Right )−ln(Left)) as a function of ampliﬁer input impedance, and\\nimpedance at left ( zleft) and right ( zright) leads. Data in the left panel depict the impact of\\nmismatched left and right lead impedances with an input impedance of 10m /Omega1(that of the\\nNeuroscanSynampssystem,NeuroscanaCompumedicsCompany,ElPaso,TX),anddatain the right panel depict the same with an input impedance of 20m /Omega1(that of the Grass\\nModel 12 Neurodata system, Grass Telefactor an Astro-Med Inc. Product Group, WestWarwick,RI).Datawereobtainedbysolving Eq.(5)independentlyforleftandrightleads,\\nfor impedances ranging from 0.2 to 10k /Omega1, assuming a reference electrode impedance of\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 201\\nFig. 7. Asymmetry score (difference of natural log scores) as a function of ampliﬁer input impedance, and\\nimpedance at left ( zleft) and right ( zright) leads. For both plots, reference electrode impedance is set to 1k /Omega1.\\nThe computed voltage at both left and right leads was squared to produce power units, and the difference of thenaturallogtransformedpowervalues(ln (Right )−ln(Left))wasplottedontheverticalaxis.Toptwopanelsdepict\\nthe observed asymmetry score when the right lead’s true signal was 5 /H9262V larger than the left, and the lower two\\npanels depict the asymmetry score when the right lead’s true signal was 0.5 /H9262V larger than the left. Note that the\\ntop two panels are on the same scale, and the bottom two panels share a different scale.\\n1k/Omega1.8Theresultantvaluesforleftandrightleadswerethenusedtocomputetheasymmetr', 'Issues and assumptions on the road from raw signals.pdf'), 694: (' thenaturallogtransformedpowervalues(ln (Right )−ln(Left))wasplottedontheverticalaxis.Toptwopanelsdepict\\nthe observed asymmetry score when the right lead’s true signal was 5 /H9262V larger than the left, and the lower two\\npanels depict the asymmetry score when the right lead’s true signal was 0.5 /H9262V larger than the left. Note that the\\ntop two panels are on the same scale, and the bottom two panels share a different scale.\\n1k/Omega1.8Theresultantvaluesforleftandrightleadswerethenusedtocomputetheasymmetry\\nscore (ln (Right )−ln(Left)) for all combinations of left and right impedances.\\nTwoaspectsof Fig.7warrantcomment.First,theoverallimpactofimpedancemismatch\\nrangingfrom0to10k /Omega1betweenleftandrightleadsisnegligible,andapparentonlyinthe\\nsixthdecimalplaceoftheasymmetryscore.Differencesbetweenhemispheresandbetweengroups of subjects, on the other hand, are readily apparent in the ﬁrst decimal place (cf.Henriques and Davidson, 1990, 1991; Reid et al., 1998 ). Differences in left and right lead\\n8Resultsremainessentiallyunchangedifreferenceimpedanceishigherthan1k /Omega1,asthereferenceimpedance\\nappears similarly in the equation for calculating observed left lead and observed right lead voltage.\\n202 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nimpedances are thus unlikely to spuriously create or mask veritable differences in left and\\nright alpha power. Second, the impact of the mismatch is further attenuated as a functionof the higher input impedance ampliﬁer. Asymmetry scores vary by 7 .7×10\\n−6with the\\n10M/Omega1input impedance, and by 3 .9×10−6with the 20M /Omega1input impedance, when true\\nvoltagedifferencesare0.5 /H9262V.Variationwouldbeevenlesswithhigherinputimpedances\\n(suchasthe200M /Omega1inputimpedanceoftheNetAmps,ElectricalGeodesicsInc.,Eugene,\\nOR).\\n3.4. Dealing with ocular and muscular artifacts\\nEEG recordings may contain not only brain electrical activity, but non-cerebral contri-\\nbutionstotheobservedsignal,includingartifactualcontributionsofthescalpmusclesandpotentials generated by eye mov', 'Issues and assumptions on the road from raw signals.pdf'), 695: ('h the\\n10M/Omega1input impedance, and by 3 .9×10−6with the 20M /Omega1input impedance, when true\\nvoltagedifferencesare0.5 /H9262V.Variationwouldbeevenlesswithhigherinputimpedances\\n(suchasthe200M /Omega1inputimpedanceoftheNetAmps,ElectricalGeodesicsInc.,Eugene,\\nOR).\\n3.4. Dealing with ocular and muscular artifacts\\nEEG recordings may contain not only brain electrical activity, but non-cerebral contri-\\nbutionstotheobservedsignal,includingartifactualcontributionsofthescalpmusclesandpotentials generated by eye movements and blinks ( Gratton, 1998; Picton et al., 2000 ).\\nAlthoughcarefulscreeningandrejectionofdatasegmentscontaminatedbytheartifactsislikelytoremovemanyoftheartifacts,itmaybedesirabletoobtainanestimateoftheextentto which such artifacts may be inﬂuencing the results of an investigation.\\n3.4.1. Electrooculographic (EOG) inﬂuences\\nThe eyes, being ion-ﬁlled imperfect spheres, carry a positive charge at the relatively\\nleptokurtotic cornea, and a negative charge at the relatively platykurtotic retina. Beingmobile,thesechargedspherescreateelectricalﬁeldsthatareobservedassignalinthecaseof EOG recordings, or artifact in the case of EEG recordings. Moreover, the conductiveeyelid acts as a variable resistor as it slides across the cornea, momentarily distributingthe ocular potential across the scalp. Thus ocular movements and blinks can be observedin scalp-recorded EEG, with the magnitude of the EOG signal decreasing as a functionof the distance from the eyes. Although a majority of the signal of ocular origin is in thedelta and theta range ( Gasser et al., 1985; Hagemann and Naumann, 2001 ), slower than\\nthe8–13HzalpharangeofinterestinEEGasymmetryresearch,someactivityinthealphaband will inevitably be present, some potentially of neural origin (cf. Iacono and Lykken,\\n1981).Theconcernthatactivityofocularoriginmaycontaminatescalp-recordedEEGhas\\nprompted investigators utilizing EEG asymmetry to often reject epochs containing blinksorotherocularartifact.Moreover,theconcernthattheEOGsignalmaycontainalpha-bandactivityofneuralo', 'Issues and assumptions on the road from raw signals.pdf'), 696: ('hedelta and theta range ( Gasser et al., 1985; Hagemann and Naumann, 2001 ), slower than\\nthe8–13HzalpharangeofinterestinEEGasymmetryresearch,someactivityinthealphaband will inevitably be present, some potentially of neural origin (cf. Iacono and Lykken,\\n1981).Theconcernthatactivityofocularoriginmaycontaminatescalp-recordedEEGhas\\nprompted investigators utilizing EEG asymmetry to often reject epochs containing blinksorotherocularartifact.Moreover,theconcernthattheEOGsignalmaycontainalpha-bandactivityofneuraloriginhasdiscouragedinvestigatorsfromemployingasimplecorrectionprocedure that subtracts a portion of the time-domain EOG signal from the time-domainEEG signal, for doing so might also subtract alpha activity of neural origin.\\nHagemann and Naumann (2001) carefully examined the contribution of ocular sig-\\nnals to scalp-recorded EEG asymmetry scores. Reviewing the literature, Hagemann and\\nNaumann(2001) suggestedthatocularartifactsarenotlikelytoartifactuallycreateormiti-\\ngatealpha-bandasymmetriesfromhomologousscalpleads,because:(1)powerinthealphaband that is observed in EOG recordings is predominantly neural in origin, thus makingit unlikely that ocular movements and blinks will appreciably alter scalp-recorded alphaactivity, and (2) eye-movements and blinks are propagated relatively symmetrically. Thesymmetricpropagationofverticaleyemovementsandblinksisapparentintherawsignal,but even lateral eye movements will be reﬂected similarly in the power spectra of left andright sites due to such movements creating similar magnitude but phase reversed deﬂec-\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 203\\ntions;theFFTwillproducesimilarpowerspectrabutdifferentphasespectra,withonlythe\\npower spectra of interest in EEG asymmetry research.\\nAssessingthecontributionempirically, HagemannandNaumann(2001) foundthatalpha\\nasymmetryscores(ln (Right )−ln(Left))derivedfrom8minofrestingEEGwerehighlysim-\\nilarwhencomputedwithversuswithoutepochscontainingocularartifacts.Thecorrelationsbetweenasymmetryscoresfromadatasetthatinclu', 'Issues and assumptions on the road from raw signals.pdf'), 697: (' magnitude but phase reversed deﬂec-\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 203\\ntions;theFFTwillproducesimilarpowerspectrabutdifferentphasespectra,withonlythe\\npower spectra of interest in EEG asymmetry research.\\nAssessingthecontributionempirically, HagemannandNaumann(2001) foundthatalpha\\nasymmetryscores(ln (Right )−ln(Left))derivedfrom8minofrestingEEGwerehighlysim-\\nilarwhencomputedwithversuswithoutepochscontainingocularartifacts.Thecorrelationsbetweenasymmetryscoresfromadatasetthatincludedallepochsfreeofnon-ocularartifactsand the same dataset with ocular-contaminated epochs were greater than 0.82 for all re-gionsexceptthefrontalpole,whichwassubstantiallylower.Effectsofocular-contaminatedepochs,however,werelargerforsinglesitesthanforcorrespondingasymmetryscores,fur-ther supporting the notion that ocular artifacts propagate symmetrically across most of thescalp.\\nHagemannandNaumann(2001) concludedthatthecontrolofocularartifactsmaythusbe\\nunnecessaryforcorrelationalanalysesinvolvingalphaasymmetryscores,butthatanalysesinvolving mean levels may be inﬂuenced by ocular artifacts. Although the data in supportof their conclusion is relatively strong—as the correlations are high between asymmetryscores from data with versus without artifacts—it is worth noting two issues that were notconsidered or assessed fully, and that remain to be investigated empirically. First, no rela-tionshipsbetweenalphaasymmetryandacriterionvariable(e.g.,BASscores,cf. Coanand\\nAllen, 2003a; Harmon-Jones and Allen, 1997; Sutton and Davidson, 1997 ) were investi-\\ngated. Although the high correlation between asymmetry scores obtained from data withandwithoutocularartifactswouldsuggestthateachwoulddemonstratesimilarcorrelationsto a criterion variable, it is possible that the variance that is not shared by the two sets ofasymmetry scores is differentially related to the criterion variable. Because the correlationbetweenthetwosetsofasymmetryscoresisattenuatedthemostatfrontalleadsbythein-clusionorexclusionofepochswithocularartifacts,an', 'Issues and assumptions on the road from raw signals.pdf'), 698: (' and Davidson, 1997 ) were investi-\\ngated. Although the high correlation between asymmetry scores obtained from data withandwithoutocularartifactswouldsuggestthateachwoulddemonstratesimilarcorrelationsto a criterion variable, it is possible that the variance that is not shared by the two sets ofasymmetry scores is differentially related to the criterion variable. Because the correlationbetweenthetwosetsofasymmetryscoresisattenuatedthemostatfrontalleadsbythein-clusionorexclusionofepochswithocularartifacts,andbecauseitispreciselytheseregionsthatareofgreatestinterestwithrespecttothecriterionvariable,thepossibilityisampliﬁedthatthetwosetsofscoresmayrelatedifferentiallytoacriterionvariable.Thesecondissueto consider derives from this possibility. Despite the careful analysis of Hagemann and\\nNaumann(2001) ,onecannotdifferentiatebetweentwopossibilities:(1)thatthetruebrain\\nactivityisinvariantacrossepochswithandwithoutocularartifacts,butthepresenceoftheocular activity inﬂuences the observed EEG recording, or (2) the asymmetry scores differbecausethetrueEEGactivitydiffersasafunctionofwhetherblinksoreyemovementsareoccurring.Giventhateye-blinksshowpredictablerelationshipstocognitiveprocessingandattention ( Stern et al., 1984 ), this latter possibility must be considered in earnest.\\n3.4.2. Facial electromyographic (EMG) activity\\nScalp-recorded EEG alpha activity may artifactually reﬂect the contribution of EMG\\nactivity (Cacioppo et al., 1990; Friedman and Thayer, 1991 ). Although the vast majority\\nof the power in the EMG signal is faster than the alpha band, EMG activity has broad fre-quencycharacteristicswithsomesmallproportionofactivityevidentinthealphaband.Thisproblem is potentially exaggerated by the fact that facial EMG asymmetries—sometimessimilar in direction to reported cortical EEG asymmetries—have been observed ( Borod\\netal.,1997 ),althoughtheconsistentandrobustﬁndingtoemergefromthisliteratureisan\\nasymmetrycharacterizedbygreaterleftsideactivityinfacialexpressionsingeneral,acrossall speciﬁc emotions and elicitation pr', 'Issues and assumptions on the road from raw signals.pdf'), 699: ('nal is faster than the alpha band, EMG activity has broad fre-quencycharacteristicswithsomesmallproportionofactivityevidentinthealphaband.Thisproblem is potentially exaggerated by the fact that facial EMG asymmetries—sometimessimilar in direction to reported cortical EEG asymmetries—have been observed ( Borod\\netal.,1997 ),althoughtheconsistentandrobustﬁndingtoemergefromthisliteratureisan\\nasymmetrycharacterizedbygreaterleftsideactivityinfacialexpressionsingeneral,acrossall speciﬁc emotions and elicitation procedures.\\n204 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nFriedmanandThayer(1991) examinedthepotentialmagnitudeoftheEMGcontribution\\ntoEEGrecordingswiththeuseofaredundancyanalysis,whichcanbeusedtoaccountforoverlapbetweencorticallyderivedalphapowerandalphapowerduetofacialmuscleactiva-tion.Intheiranalysis,facialEMGaccountedfor7%ofthevarianceincorticalEEGactivity,whilecorticalEEGactivityaccountedforonly3%ofthevarianceinfacialEMG,suggestingthat facial EMG is likely to be responsible for a small but potentially important portion ofthe variance in scalp-recorded EEG. This study did not, however, speciﬁcally address theextent to which asymmetries in facial EMG activity were contributing to asymmetries inscalp EEG.\\nCoan et al. (2001) assessed the inﬂuence of EMG on scalp recorded alpha during a di-\\nrected facial action task using two strategies. The ﬁrst, a strategy used also by Davidsonand colleagues (cf. Davidson, 1988; Davidson et al., 2000b ), involves assessing EMG fre-\\nquencies at scalp sites of interest. This approach extracts EMG frequencies (70–80Hz inDavidson et al., 2000b or 70–90Hz in Coan et al., 2001 ) from the power spectrum at each\\nsite involved in the EEG analysis. Because Coan et al. (2001) were analyzing EEG asym-\\nmetryscores,EMGasymmetryscores(ln (Right )−ln(Left))werecomputedonthisEMG\\nfrequency band—for all the same regions as were included in the EEG analysis. TheseEMGrangeasymmetrieswereusedas changingcovariates inamultivariaterepeatedmea-\\nsuresanalysisofcovariance(MANCOVA),whichas', 'Issues and assumptions on the road from raw signals.pdf'), 700: ('interest. This approach extracts EMG frequencies (70–80Hz inDavidson et al., 2000b or 70–90Hz in Coan et al., 2001 ) from the power spectrum at each\\nsite involved in the EEG analysis. Because Coan et al. (2001) were analyzing EEG asym-\\nmetryscores,EMGasymmetryscores(ln (Right )−ln(Left))werecomputedonthisEMG\\nfrequency band—for all the same regions as were included in the EEG analysis. TheseEMGrangeasymmetrieswereusedas changingcovariates inamultivariaterepeatedmea-\\nsuresanalysisofcovariance(MANCOVA),whichassumesthattheEMGcovariatechangeswithingroupswiththedependentvariableacrosslevelsoftheindependentvariable—inthiscase the particular facial expression. This changing covariate approach then correlates thechange in the covariate with the change in the dependent variable and subsequently ana-lyzestheresidualvarianceinastandardMANOVA.Usingthisstrategy, Coanetal.(2001)\\nfound that statistically adjusting for the EMG variance in this way did not change any ofthe signiﬁcant relationships between facial pose and EEG asymmetry.\\nThe second strategy used by Coan et al. (2001) involved an examination of alpha fre-\\nquencies derived from bipolar EMG leads. This analysis was motivated by noting thatthe previous method assumes that all frequencies of the EMG are equally likely to showasymmetry effects that differ by the manipulation. But it is conceivable that EMG activ-ity in the 70–90Hz band may relate differently to a criterion variable than EMG activityin the 8–13Hz band, the band of particular interest. Thus whereas the ﬁrst analysis strat-egy examined EMG frequencies in EEG leads, the second examined alpha frequencies inEMGleads.ThissecondapproachderivedpowerspectrafrombipolarEMGactivityinthefrontalis and the temporalis muscle regions. Alpha power asymmetry scores derived fromthese EMG leads were thus included as changing covariates the analyses. Because unliketheﬁrstapproach,whereeachregionhaditsowncovariate,thisapproachproducedsolelyafrontalisalphaasymmetryscoreandatemporalisasymmetryscore,onewayrepeatedmea-suresMANCOVAsw', 'Issues and assumptions on the road from raw signals.pdf'), 701: ('st analysis strat-egy examined EMG frequencies in EEG leads, the second examined alpha frequencies inEMGleads.ThissecondapproachderivedpowerspectrafrombipolarEMGactivityinthefrontalis and the temporalis muscle regions. Alpha power asymmetry scores derived fromthese EMG leads were thus included as changing covariates the analyses. Because unliketheﬁrstapproach,whereeachregionhaditsowncovariate,thisapproachproducedsolelyafrontalisalphaasymmetryscoreandatemporalisasymmetryscore,onewayrepeatedmea-suresMANCOVAswereconductedseparatelyforeachregion(e.g.,oneforF4–F3,oneforF8–F7, etc.) since each region could not have its own changing covariate. Analyzing eachregion separately, thus increasing the number of analyses conducted, actually provided amore stringent test of whether the relationships between the manipulation and EEG asym-metrywereinﬂuencedbymyogeniccontributions,becausethechancesincreasedofﬁndingthatthecovariatesrenderedapreviouslysigniﬁcanteffectnonsigniﬁcant.Statisticallycon-trolling for the EMG variance in this way, however, did not change any of the signiﬁcantrelationships between facial pose and EEG asymmetry.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 205\\n4. Interpretive issues\\n4.1. Alpha and activity\\nA guiding assumption underlying the interpretation of ﬁndings involving frontal EEG\\nalpha asymmetry is that greater alpha power is indicative of less cortical activity in broadunderlying regions (cf. Davidson, 1988 ). Although there is good evidence to support this\\nassumption, one might question whether this relationship is ubiquitous.\\nIthasbeenwelldocumentedthatsensoryinputshowsmodality-speciﬁcblockingofalpha\\nactivityatcorticalregionsinvolvedinprocessingsuchinput.Withvisualstimuli,blockingof alpha over the occipital region occurs about 0.3s after the presentation of the visualstimulus ( Berger, 1932; Jasper and Cruickshank, 1937; Knott, 1938 ), but this latency has\\nbeen found to vary with intensity and duration of the stimulus ( Cruickshank, 1937 ;Durup\\nand Fessard, 1936a,b ) and to diminish', 'Issues and assumptions on the road from raw signals.pdf'), 702: ('stion whether this relationship is ubiquitous.\\nIthasbeenwelldocumentedthatsensoryinputshowsmodality-speciﬁcblockingofalpha\\nactivityatcorticalregionsinvolvedinprocessingsuchinput.Withvisualstimuli,blockingof alpha over the occipital region occurs about 0.3s after the presentation of the visualstimulus ( Berger, 1932; Jasper and Cruickshank, 1937; Knott, 1938 ), but this latency has\\nbeen found to vary with intensity and duration of the stimulus ( Cruickshank, 1937 ;Durup\\nand Fessard, 1936a,b ) and to diminish somewhat with a motor response related to the\\nstimulus( Knott,1938,1939;Travisetal.,1937 ).Recoverytimefromblockingisgenerally\\nabout1s,butittoovarieswithstimulusintensityandduration( Cruickshank,1937;Jasper\\nand Cruickshank, 1937; Motokawa and Tosiada, 1941 ).\\nSimilar but less dramatic effects are observed with other sensory modalities. Auditory\\nstimuli, for example, block occipital alpha less effectively than visual stimuli and with asomewhatlongerlatency( Berger,1930;Gibbsetal.,1935;Travisetal.,1937 ).Othersensory\\nstimuli,suchastactile,cutaneous,pain( Berger,1931,1932;JasperandCruickshank,1937;\\nLivanov, 1940; Travis and Barber, 1938 ) and gustatory ( Kitamura, 1939 ) have been found\\nto block alpha, at least in their respective cortical areas.\\nThus,sensorystimulationthatshouldrequireactivecorticalprocessingleadstomodality-\\nspeciﬁc alpha blocking, a principle that might lead to the inference that diminished alpharecordedoveranycorticalregionsigniﬁesgreatercorticalactivity.Atestofthishypothesisinregionsotherthanprimarysensoryregionsishamperedbythelackofclearlydeﬁnedstimulito speciﬁcally engage those cortical regions in active processing, although several studieshaveprovideddataquiteconsistentwiththenotionthatgreateralphapowerisindicativeofless cortical activity in the underlying regions thought to subserve task performance (e.g.,Davidson et al., 1990 ).\\nA consideration of the genesis of the alpha rhythm might prove illuminative for the as-\\nsumption that diminished alpha recorded over any cortical region signiﬁes', 'Issues and assumptions on the road from raw signals.pdf'), 703: ('anprimarysensoryregionsishamperedbythelackofclearlydeﬁnedstimulito speciﬁcally engage those cortical regions in active processing, although several studieshaveprovideddataquiteconsistentwiththenotionthatgreateralphapowerisindicativeofless cortical activity in the underlying regions thought to subserve task performance (e.g.,Davidson et al., 1990 ).\\nA consideration of the genesis of the alpha rhythm might prove illuminative for the as-\\nsumption that diminished alpha recorded over any cortical region signiﬁes greater corticalactivity. A series of studies by Andersen and colleagues ( Andersen et al., 1967a,b ) sug-\\ngest that thalamic rhythmicity drives cortical ensembles, the latter which comprise a largeportion of scalp-recorded EEG activity. Andersen et al. (1967b) examined spindles in ani-\\nmals anesthetized with barbiturates, making the inference that such spontaneous rhythmicspindleactivityishomologouswiththehumanalpharhythm.Severalﬁndingshighlightthebasis of their conclusion that thalamic rhythmicity drives cortical rhythmicity, including:(1) destruction or cooling of cortical regions leaves thalamic spindle activity unchanged(Andersen et al., 1967b ); (2) damage or removal of the thalamus abolished cortical spin-\\ndle activity ( Andersen et al., 1967b ); (3) unilateral destruction of thalamic tissue resulted\\nin the disappearance of ipsilateral cortical spindle activity ( Andersen et al., 1967b ); (4)\\nsynchronous cortical spindles were not observed in relatively closely spaced cortical re-gions (those separated by 2mm or more), but were observed over a much larger distance\\n206 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nbetween a group of thalamic cells and the cortical area to which they projected ( Andersen\\net al., 1967a ). Thus Andersen and colleagues concluded that spontaneous cortical rhyth-\\nmicity was “generated exclusively by thalamic neurons” ( Andersen et al., 1967b , p. 258).\\nAlthough cortical systems provide inputs to the thalamus that can disrupt the rhythmicity,the thalamus, and part', 'Issues and assumptions on the road from raw signals.pdf'), 704: ('d by 2mm or more), but were observed over a much larger distance\\n206 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nbetween a group of thalamic cells and the cortical area to which they projected ( Andersen\\net al., 1967a ). Thus Andersen and colleagues concluded that spontaneous cortical rhyth-\\nmicity was “generated exclusively by thalamic neurons” ( Andersen et al., 1967b , p. 258).\\nAlthough cortical systems provide inputs to the thalamus that can disrupt the rhythmicity,the thalamus, and particularly the reticularis nucleus ( Steriade et al., 1985 ), appears to be\\nresponsible for synchronizing cortical EEG activity.\\nRecentconﬁrmationofarelationshipbetweenthalamicactivityandscalp-recordedalpha\\nactivityinhumansderivesfromapositronemissiontomography(PET)study( Larsonetal.,\\n1998). During approximately 30min, EEG and [\\n18F]-2-ﬂuoro-2-deoxy- d-glucose (FDG)\\nPET recordings were obtained. Global alpha (8–13Hz) power was then correlated withglucosemetabolism,andcorticalalphapowerwasstronglyandinverselyrelatedtoglucosemetabolisminthethalamus( Larsonetal.,1998 ).Thisﬁndingisconsistentwiththenotion\\nthatthalamicactivityinresponsetosensoryorcorticalinputwilldisruptalpharhythmicity.\\nThus scalp recorded EEG alpha activity—in a very coarse sense both spatially and\\ntemporally—isinverselyrelatedtothalamicactivity.Globalalphapoweracrosselectrodesandacross30minrelatestothalamicmetabolism.Ultimately,however,investigatorswouldwish to know whether EEG alpha at a given scalp lead is related to cortical activity in thetissue beneath that lead, a question addressed by Cook et al. (1998) . Using H\\n215O PET\\nimaging allowed them to examine activity in 2min segments, with a total of eight suchsegments per subject. EEG power was calculated for 4Hz wide bins, starting at 0Hz andextending to 40Hz, at 1Hz intervals (e.g., 0–4, 1–5, 2–6, etc.). Cerebral perfusion undereach electrode was calculated, and then correlated with each of the EEG spectral bins, re-sulting in a plot of correlations between EEG power and cerebral perfusion as ', 'Issues and assumptions on the road from raw signals.pdf'), 705: ('sue beneath that lead, a question addressed by Cook et al. (1998) . Using H\\n215O PET\\nimaging allowed them to examine activity in 2min segments, with a total of eight suchsegments per subject. EEG power was calculated for 4Hz wide bins, starting at 0Hz andextending to 40Hz, at 1Hz intervals (e.g., 0–4, 1–5, 2–6, etc.). Cerebral perfusion undereach electrode was calculated, and then correlated with each of the EEG spectral bins, re-sulting in a plot of correlations between EEG power and cerebral perfusion as a functionof frequency. Frequency range played a major role in the relationship of EEG power withperfusion,suchthatlowerfrequencies(thosebinswithacenterfrequencybelow8Hz)hadapositiverelationshiptoperfusion,middlefrequencies(binswithcenterfrequenciesfrom8to12Hz)hadanegativerelationship,andupperfrequencyranges(centerfrequencyvar-ieddependingonspeciﬁcoperationalization)hadapositiverelationship( Fig.8).Apparent\\nfromtheﬁgureisthatrelativepowershowsaclosercorrespondencetounderlyingcorticalactivity than does absolute power, which may reﬂect that the latter is confounded by vari-ations in scalp thickness much more than the former. Additionally, although alpha poweris inversely related to underlying cortical activity no matter which of the montages was\\nused, the relationship of beta power (13–30Hz) to underlying activity varied substantially\\nas a function of recording montage, exhibiting either a positive or negative relationshipdepending on the particular recording montage used.\\nThus there is reasonable support for the assumption that greater alpha at a scalp lead\\nreﬂectslesscorticalactivityinabroadregion(s)contributingtoelectricalactivityrecordedatthatlead.Recentdataof Cooketal.(1998) suggest,however,thatatightercorrespondence\\nbetweencorticalactivityandscalp-recordedEEGispossiblewithareattributiontechniquethese authors have called cordance, although the correspondence in the alpha band is not\\nvastly improved using this cordance measure (see the lower panel of Fig. 8, taken from\\nCook et al., 1998 ). Whether asymmetry i', 'Issues and assumptions on the road from raw signals.pdf'), 706: ('he assumption that greater alpha at a scalp lead\\nreﬂectslesscorticalactivityinabroadregion(s)contributingtoelectricalactivityrecordedatthatlead.Recentdataof Cooketal.(1998) suggest,however,thatatightercorrespondence\\nbetweencorticalactivityandscalp-recordedEEGispossiblewithareattributiontechniquethese authors have called cordance, although the correspondence in the alpha band is not\\nvastly improved using this cordance measure (see the lower panel of Fig. 8, taken from\\nCook et al., 1998 ). Whether asymmetry in reattributed power demonstrates relationships\\nwith emotion and individual differences, however, remains an empirical question, but oneworthinvestigatinggiventhetightercouplingofEEGtobrainfunctionthatappearspossibleusing this technique (see also Leuchter et al., 1994, 1999, 2002 ).\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 207\\nFig.8.CorrelationsbetweenEEGpowerandPETperfusionvaluesattissueundertheEEGscalplead.Toppanel\\ndepicts absolute power, and lower panel depicts relative power (i.e., power in the 4-Hz wide bin divided by totalpower across all spectral frequencies). “Ear reference” is a computer linked ears reference, “source derivation”is that described by Hjorth (1975) that weights immediate neighboring electrodes in the time domain prior to\\nfrequency-domaintransformation,and“reattributedpower”isaweightingofpowerderivedfrombipolarchannelsof nearest neighbors ( Cook et al., 1998 ). Statistical signiﬁcance is indicated by horizontal lines representing the\\nmagnitude at which a correlation coefﬁcient attains signiﬁcance: solid line for P=0.05; large dashed line for\\nP=0.01; ﬁne dashed line for P=0.001. From Cook et al. (1998) , reprinted with permission from Elsevier.\\n208 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nWorth noting from Cook et al. (1998) , and as apparent in Fig. 8, is that the inverse re-\\nlationshipbetweencorticalperfusionandEEGpowerisrelativelyconstantthroughouttheentire alpha band in these adult subjects. Thus although the 8–13Hz deﬁnition of alpha issomewhat ar', 'Issues and assumptions on the road from raw signals.pdf'), 707: ('oefﬁcient attains signiﬁcance: solid line for P=0.05; large dashed line for\\nP=0.01; ﬁne dashed line for P=0.001. From Cook et al. (1998) , reprinted with permission from Elsevier.\\n208 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nWorth noting from Cook et al. (1998) , and as apparent in Fig. 8, is that the inverse re-\\nlationshipbetweencorticalperfusionandEEGpowerisrelativelyconstantthroughouttheentire alpha band in these adult subjects. Thus although the 8–13Hz deﬁnition of alpha issomewhat arbitrary, the correspondence of activity in this range (and perhaps a bit of the6–8Hz portion of the upper Theta band) to underlying cortical activity at rest is relativelyuniforminadultsubjects.Thisobservationdoesnotsuggestastrongfunctionaldistinctionbetween smaller bandwidth divisions, such as upper or lower alpha, at rest in a psychi-atricallyandneurologicallyhealthypopulation(althoughsomeinvestigatorshavemadeanargument for the utility of subdividing the alpha band for speciﬁc tasks and applications,e.g.,Klimesch et al., 1997 ).\\nA ﬁnal issue with respect to interpreting alpha and cortical activity concerns how to\\nconceptualize resting EEG data. Such resting data necessarily summarizes activity acrossseveralminutes,whichwillcollapseacrossmanyvariationsinbrainandpsychologicalstateduringtherecordingperiod.Althoughinvestigatorsrefertosuchperiodsasrestingperiods,one might alternatively think of EEG activity during these periods as task-related, withindividual differences in how subjects approach this “task” of resting for several minutesunderlying the observed individual differences in EEG activity. The resting state is rela-tively uncontrolled, allowing for individual differences in mentation (broadly construed)during the resting period to inﬂuence the measure (cf. Schwartz et al., 1976 for a similar\\nphenomenonwhendepressedandnondepressedsubjectsponderedatypicaldaywhilefacialEMG was recorded).\\n4.2. Robustness or capitalization on chance: the impact of reference schemes, speciﬁc\\nsites, and other variations\\nReviewi', 'Issues and assumptions on the road from raw signals.pdf'), 708: ('esting for several minutesunderlying the observed individual differences in EEG activity. The resting state is rela-tively uncontrolled, allowing for individual differences in mentation (broadly construed)during the resting period to inﬂuence the measure (cf. Schwartz et al., 1976 for a similar\\nphenomenonwhendepressedandnondepressedsubjectsponderedatypicaldaywhilefacialEMG was recorded).\\n4.2. Robustness or capitalization on chance: the impact of reference schemes, speciﬁc\\nsites, and other variations\\nReviewing the literature (see Tables 1–4 in Coan and Allen, 2004 , this issue), one is\\nimpressed by the fact that signiﬁcant relationships involving frontal EEG asymmetry: (1)derivefromdataanalyzedunderavarietyofreferenceschemes,withdifferentstudiesusingdifferentreferencemontages;(2)appeartoinvolvedifferentspeciﬁcfrontalregionsindif-ferentstudies;and(3)sometimesinvolvedifferentfrequencycutpointsforoperationalizingalphabandactivity.Itisprematuretoknowhowbesttointerpretsuchapatternofﬁndings,but these observations suggest at least three non-mutually exclusive possibilities.\\nFirst,forthosewholiketoseeglassesashalf-empty,thiscouldreﬂectthatthisresearch\\nﬁeldsuffers—asalldotosomedegree—fromsigniﬁcantinﬂationofthelikelihoodofTypeIerror,withalphainﬂationresultingfromthepoorcontrolformultiplecomparisons,com-pounded by the many permutations of variables possible when recording from multipleregionsundermultiplereferencemontages,withthepossibilityofdifferentoperationaliza-tions of alpha-band activity. In the absence of strong theory to suggest that investigatorsshould ﬁnd effects at one speciﬁc frontal region and not another, or under one referenceschemeandnotanother,investigatorswiselyexaminemultiplesitesandreferenceschemes,buttheincumbentriskofthisstrategyisthattheﬁeldasawholemaybeinadequatelypro-tected against reporting spurious ﬁndings.\\nSecond, for those who like to see glasses as half-full, the fact that relationships with\\nfrontal EEG asymmetry appear with data from different reference schemes at differenttimes,andatdifferent', 'Issues and assumptions on the road from raw signals.pdf'), 709: ('eory to suggest that investigatorsshould ﬁnd effects at one speciﬁc frontal region and not another, or under one referenceschemeandnotanother,investigatorswiselyexaminemultiplesitesandreferenceschemes,buttheincumbentriskofthisstrategyisthattheﬁeldasawholemaybeinadequatelypro-tected against reporting spurious ﬁndings.\\nSecond, for those who like to see glasses as half-full, the fact that relationships with\\nfrontal EEG asymmetry appear with data from different reference schemes at differenttimes,andatdifferentregionsatdifferenttimes,suggeststhattheseobservedvariablesare\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 209\\nimperfectmanifestrepresentationsofwhatshouldbeconsideredalatentvariable,i.e.,func-\\ntionalfrontalbrainasymmetry.Thisargumentwouldimplythatonlybyrecordingmultipleregions and under multiple reference schemes can one adequately assess an individual’strue score on the latent variable. By aggregating over multiple measures, one gains powerandreliability,thusenhancingtheabilitytoﬁndrelationshipsbetweenfrontalbrainasym-metryandcriterionvariables.Thisargumentfurtherimpliesthattheimpactofthesefactors,suchasreferenceschemeandspeciﬁcfrontalregion,shouldbetestedexplicitlyinastatis-tical model, such as those detailed previously in the section on hierarchical general linearmodels.Intheabsenceofsuchamodeltoprotectfromisolatedchanceﬁndingsappearingsigniﬁcant, the ﬁeld may indeed suffer from inﬂation of Type I statistical error.\\nThe latent trait argument would of course predict that the manifest variables should all\\nshowsomemodestcorrelationswiththelatenttrait,andlikelywithoneanother.Althoughthisistrueofdatarecordedundertheaveragereferenceandthecomputeraveragedmastoidsreferences, it is less true of data recorded using the Cz reference ( Hagemann et al., 1998;\\nReid et al., 1998 ), which shows much lower correspondence with data using the other\\nreference montages. It is worth noting, moreover, that by far the most common referencescheme used in frontal EEG asymmetry research is the Cz reference (see Coan an', 'Issues and assumptions on the road from raw signals.pdf'), 710: ('es should all\\nshowsomemodestcorrelationswiththelatenttrait,andlikelywithoneanother.Althoughthisistrueofdatarecordedundertheaveragereferenceandthecomputeraveragedmastoidsreferences, it is less true of data recorded using the Cz reference ( Hagemann et al., 1998;\\nReid et al., 1998 ), which shows much lower correspondence with data using the other\\nreference montages. It is worth noting, moreover, that by far the most common referencescheme used in frontal EEG asymmetry research is the Cz reference (see Coan and Allen,\\n2004,thisissue),andthatmoststudiesdonotemploymultiplereferencemontagesintheir\\nanalysis of the data.\\nThethirdpossibilityisthatthereexistssomesystematicrelationshipbetweenmeasuredor\\nunmeasuredvariablesandasymmetryatspeciﬁcsitesorunderspeciﬁcreferenceschemes.This line of reasoning suggests the differential engagement of various frontal systems as afunctionofparticulartaskdemands,asafunctionoffactorsintheexperimentalenvironment,and as a function of various individual difference variables under study.\\nAtpresent,itisdifﬁculttoassessthelikelihoodthatsucheffectsexist,asmoststudiesdo\\nnotassessarangeofvariablesandattempttorelatethemtoasymmetryatspeciﬁcregions.A notable exception comes from a recent study of Miller and Tomarken (2001) , in which\\nmanipulations of expected reward or punishment produced changes in mid-frontal EEGasymmetry(thatvariedbysex),andmanipulationoftherequiredresponseproducedchangesin central asymmetry. These results suggest that there may indeed be task variables thatwillimpactthespeciﬁcregioninwhichEEGalphaasymmetryeffectsarelikelytoappear.Nonetheless,therearemanyothernon-taskvariablesthatmayimpacttheregionalspeciﬁcityofEEGasymmetryeffects,butsuchvariablesmaynotbeknownorassessed,thusmakingit impossible to discern whether there exists a systematic cause underlying the appearanceof EEG asymmetry effects at some sites in some studies, and other sites in other studies.\\n4.3. Consistency and variability\\nEstimates of EEG alpha asymmetry are averages that summarize patterns of brain ac-\\ntivity acro', 'Issues and assumptions on the road from raw signals.pdf'), 711: ('gioninwhichEEGalphaasymmetryeffectsarelikelytoappear.Nonetheless,therearemanyothernon-taskvariablesthatmayimpacttheregionalspeciﬁcityofEEGasymmetryeffects,butsuchvariablesmaynotbeknownorassessed,thusmakingit impossible to discern whether there exists a systematic cause underlying the appearanceof EEG asymmetry effects at some sites in some studies, and other sites in other studies.\\n4.3. Consistency and variability\\nEstimates of EEG alpha asymmetry are averages that summarize patterns of brain ac-\\ntivity across several minutes, either contiguous time segments in the case of resting EEGasymmetry,orcollapsedacrossnumerousdiscretebutseparatedtimesegmentsinthecaseof state-manipulated EEG asymmetry. Although it has been adequately demonstrated thatsuch estimates possess excellent internal consistency reliability (e.g., Allen et al., 2001;\\nCoan and Allen, 2003b; Coan et al., 2001; Reid et al., 1998; Tomarken et al., 1992 ), these\\nestimates of internal consistency are derived from several segments of data, each of which\\n210 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nis an average reﬂecting the pattern of brain activity across many seconds of recorded data.\\nThereisasenseinwhichfrontalEEGalphaasymmetryderivedfromthesesegmentsofdataignoresvariabilityonaﬁnertemporalscale.Whethersuchvariabilitywillprovemeaningfulis ultimately an empirical question, but the utility of explicitly examining such variabilityappearspromising.Forexample, MinnixandKline(2004) examinedthevarianceestimate\\nassociatedwiththeaverageFFTfromarestingassessment.Subjectswhoshowmoresecond-to-second variability in frontal EEG alpha asymmetry will have higher variance estimateacrosstheentirerecordingepoch. MinnixandKline(2004) foundthatincreasedvariability\\nofthissortwasrelatedtohigherneuroticism.Thusatraitcharacterizedbygreateremotionallability was found to be associated with more lability in frontal EEG asymmetry as well.\\nAnother way of assessing the stability of frontal EEG asymmetry was ﬁrst reported by\\nBaehretal.(1998) ,whocomputedthepercenta', 'Issues and assumptions on the road from raw signals.pdf'), 712: ('romarestingassessment.Subjectswhoshowmoresecond-to-second variability in frontal EEG alpha asymmetry will have higher variance estimateacrosstheentirerecordingepoch. MinnixandKline(2004) foundthatincreasedvariability\\nofthissortwasrelatedtohigherneuroticism.Thusatraitcharacterizedbygreateremotionallability was found to be associated with more lability in frontal EEG asymmetry as well.\\nAnother way of assessing the stability of frontal EEG asymmetry was ﬁrst reported by\\nBaehretal.(1998) ,whocomputedthepercentageoftimethatrightalphaisgreaterthanleft\\nalpha at homologous leads. Baehr et al. (1998) found that the percent–time measure bet-\\nterdiscriminatedpsychometrically-deﬁneddepressedsubjectsfromnondepressedsubjectsthan the traditional asymmetry measure that averaged across the recording period. Allen\\net al. (2001) used the percent–time measure as well, ﬁnding that it produced comparable\\nﬁndings to the traditional asymmetry score. Thus although it may be premature to suggestthat this metric has distinct advantages, the extant data suggest its promise and moreoversuggestthatitwouldnotresultintheeliminationofsigniﬁcantﬁndingswiththetraditionalasymmetry score.\\n4.4. Keeping straight the states and the traits\\nSubstantial data support the contention that frontal EEG asymmetry can serve as a rel-\\natively stable individual difference variable, yet also show predictable state-related ﬂuctu-ations (see Coan and Allen, 2004 , this issue). Evidence in support of the trait-like quality\\nof frontal EEG asymmetry derives from studies speciﬁcally examining stability over time.Tomarkenetal.(1992) assessedthepsychometricpropertiesoftrait-likefrontalEEGasym-\\nmetries, ﬁnding that frontal EEG asymmetry demonstrated acceptable test–retest stability(intra-class correlations ranging from 0.69 to 0.84 across 3 weeks). Similarly, Jones et al.\\n(1997)foundthatfrontalEEGasymmetryrecordedat3monthsofagewashighlycorrelated\\nwithasymmetryat3years( r=0.66,P<0.01).Similarﬁgurescomefrom Hagemannetal.\\n(2002), who found that across four different measuremen', 'Issues and assumptions on the road from raw signals.pdf'), 713: ('es speciﬁcally examining stability over time.Tomarkenetal.(1992) assessedthepsychometricpropertiesoftrait-likefrontalEEGasym-\\nmetries, ﬁnding that frontal EEG asymmetry demonstrated acceptable test–retest stability(intra-class correlations ranging from 0.69 to 0.84 across 3 weeks). Similarly, Jones et al.\\n(1997)foundthatfrontalEEGasymmetryrecordedat3monthsofagewashighlycorrelated\\nwithasymmetryat3years( r=0.66,P<0.01).Similarﬁgurescomefrom Hagemannetal.\\n(2002), who found that across four different measurement occasions, 60% of the variance\\ninEEGasymmetrymeasureswasduetoindividualdifferencesinatemporallystablelatenttrait.\\nTo enhance the ability to identify trait-related variance, some studies have speciﬁcally\\nexamined subjects who show the greatest cross-session consistency (e.g., Wheeler et al.,\\n1993),reasoningthatthestrongestrelationshipstoothertraitsshouldbeshownbythosewho\\nare consistent on the measure of trait EEG asymmetry (cf. Bem and Allen, 1974 ). Others\\nhave averaged data across multiple sessions to mitigate occasion-speciﬁc ﬂuctuations andpresumably derive a better estimate of the trait-related variance in EEG asymmetry (e.g.,Sutton and Davidson, 1997 ).\\nWhenattemptingtoaccountforthenonstablevarianceinfrontalEEGasymmetry,three\\nsources must be considered: reliable changes from one session to the next, reliable andsystematicchangeswithinsession,andunreliabilityofmeasurement.BecausefrontalEEG\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 211\\nasymmetry demonstrates high internal consistency reliability at any given assessment ses-\\nsion(Cronbach’salphastypicallyabove0.95; Reidetal.,1998 ),itisunlikelythatattenuated\\ntest–retestreliabilityoffrontalEEGasymmetryisduetorandommeasurementerror.Rather,amajorityofthevarianceinEEGasymmetrycanbeaccountedforreliableandsystematicsources of variation ( Coan and Allen, 2003b ) due to:\\n(1)Stable trait consistency across multiple assessments, which is presumably indicative\\nof temperamental style and a tendency to respond in a characteristic way when con-frontedwi', 'Issues and assumptions on the road from raw signals.pdf'), 714: ('liability at any given assessment ses-\\nsion(Cronbach’salphastypicallyabove0.95; Reidetal.,1998 ),itisunlikelythatattenuated\\ntest–retestreliabilityoffrontalEEGasymmetryisduetorandommeasurementerror.Rather,amajorityofthevarianceinEEGasymmetrycanbeaccountedforreliableandsystematicsources of variation ( Coan and Allen, 2003b ) due to:\\n(1)Stable trait consistency across multiple assessments, which is presumably indicative\\nof temperamental style and a tendency to respond in a characteristic way when con-frontedwithemotionallyevocativesituations.Anindividual’straitleveloffrontalEEGasymmetry represents a quality of that individual—a quality that the individual bringsto a variety of situations and contexts. This trait level is necessarily estimated, by av-eraging across multiple occasions of measurement (e.g., Sutton and Davidson, 1997;\\nWheeleretal.,1993 ),bymodelingitasalatenttrait(e.g., Hagemannetal.,2002 ),orby\\naccountingforitwithinthecontextofageneralizabilityanalysis(asdescribedbelow).\\n(2)Occasion-speciﬁc variancereferstoreliablevariationsinfrontalasymmetrythatchar-\\nacterizethevariationinrestingEEGassessmentsacrossmultiplesessionsofmeasure-ment. Such variation may reﬂect systematic but unmeasured sources such as currentmood, recent life events and/or factors in the testing situation.\\n(3)State-speciﬁc variancereferstochangeswithinasingleassessmentthatcharacterizethe\\ndifferencebetweentwoexperimentalconditionsorbetweenbaselinerestinglevelsandanexperimentalcondition.State-speciﬁcchangesasconceptualizedhereareproximaleffectsinresponsetospeciﬁcexperimentalmanipulations.Suchmanipulationsshouldbe reversible and of relatively short duration.\\nThesestate-relatedﬂuctuationsstandincontrasttotheoccasion-speciﬁcﬂuctuations,which\\nareassumedtocharacterizetheindividualthroughoutthemeasurementoccasion,reﬂectingthe high internal consistency reliability estimates such measurement occasions typicallyshow. Occasion variance is hypothesized to reﬂect the effects of time- or context-limitedindividualdifferencevariables(e.g.,moodonthedayofass', 'Issues and assumptions on the road from raw signals.pdf'), 715: ('fectsinresponsetospeciﬁcexperimentalmanipulations.Suchmanipulationsshouldbe reversible and of relatively short duration.\\nThesestate-relatedﬂuctuationsstandincontrasttotheoccasion-speciﬁcﬂuctuations,which\\nareassumedtocharacterizetheindividualthroughoutthemeasurementoccasion,reﬂectingthe high internal consistency reliability estimates such measurement occasions typicallyshow. Occasion variance is hypothesized to reﬂect the effects of time- or context-limitedindividualdifferencevariables(e.g.,moodonthedayofassessment,recentorimminentlifeevents,dailyhassles)oralternativelytheinteractionoftheindividualwiththeexperimentalmilieuinamannerthatvariesfromassessmenttoassessment(e.g.,effectsofexperimentalmilieu or procedures, Blackhart et al. (2002) , or experimenter effects, Kline et al. (2002) ).\\nSuch effects would not be the result of purposeful state-related experimental manipula-tions, but would rather represent an interaction of the subject with other experimentallyuncontrolled stimuli.\\nMoststudiesoftraitfrontalasymmetryarenotdesignedtoallowfortheseparationoftrait\\nvarianceandoccasionvariance,asmoststudiesentailonlyasingleoccasionofmeasurementofrestingfrontalasymmetry.Ifoccasion-speciﬁcﬂuctuationswerenotsizable,thenasingleassessmentoftraitlevelswouldprovesufﬁcient.Recentevidence( Hagemannetal.,2002 ),\\nhowever, suggests that reliable occasion-speciﬁc ﬂuctuations account for approximately40%ofreliablevarianceinrestingfrontalasymmetry,whiletheconsistencyacrossmultiplesessions, presumably reﬂecting a stable trait, accounts for approximately 60%. Further,there may exist individual differences in the magnitude of occasion-speciﬁc ﬂuctuations.For example, Wheeler et al. (1993) selected a subset of 26 from among 81 women (i.e.,\\n32%ofthesample)whowereclassiﬁedaspossessingstableasymmetry,meaningthat68%of the sample was classiﬁed as having unstable asymmetry.\\n212 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\n4.4.1. Methods for assessing state, occasion, and trait variance\\nToreliablydelineatesourcesofvarianceinfrontalE', 'Issues and assumptions on the road from raw signals.pdf'), 716: (' for approximately 60%. Further,there may exist individual differences in the magnitude of occasion-speciﬁc ﬂuctuations.For example, Wheeler et al. (1993) selected a subset of 26 from among 81 women (i.e.,\\n32%ofthesample)whowereclassiﬁedaspossessingstableasymmetry,meaningthat68%of the sample was classiﬁed as having unstable asymmetry.\\n212 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\n4.4.1. Methods for assessing state, occasion, and trait variance\\nToreliablydelineatesourcesofvarianceinfrontalEEGasymmetry,ananalyticstrategy\\nfor decomposing variance components is needed. One such promising general strategy isgeneralizability or “G” theory.\\nGeneralizabilitytheory( Cronbachetal.,1972 ),or“G-theory,”wasdevelopedforthepur-\\nposeofidentifyingthe generalizability anddependability ofdifferentindependentvariables\\nthoughttocontributetoameasure’sscore(e.g., DiNoceraetal.,2001 ).Thegeneralizability\\nofameasureisanalogoustomoreconventionalestimatesofreliability,suchastheintraclasscorrelation, while dependability of a measure refers to a measure’s reliability across con-\\ntexts. Generalizability and dependability estimates may be obtained for each independentvariable thought to contribute variance to a measure. In practice, an independent variablewith high dependability is one that contributes variance that is relatively independent ofother independent variables affecting the measure of interest. For example, an estimate ofthe dependability of trait variance in frontal EEG asymmetry would allow one to assesshow independent and stable trait variance is from state manipulations and measurementoccasions. In addition to estimates of generalizability and dependability, actual variancecomponents may be estimated for each independent variable hypothesized to contributeto an individual’s score at any one time, including variance components attributable to theinteractionofindependentvariables.G-theoryisbasedfundamentallyonanANOVAmodelintheestimationofvariancecomponents.AcriticaldifferencebetweenG-theoryanalysesand classical A', 'Issues and assumptions on the road from raw signals.pdf'), 717: ('ependent and stable trait variance is from state manipulations and measurementoccasions. In addition to estimates of generalizability and dependability, actual variancecomponents may be estimated for each independent variable hypothesized to contributeto an individual’s score at any one time, including variance components attributable to theinteractionofindependentvariables.G-theoryisbasedfundamentallyonanANOVAmodelintheestimationofvariancecomponents.AcriticaldifferencebetweenG-theoryanalysesand classical ANOVA models is that G-theory requires the computation of expected, asopposed to observed variance components. Expected variance components are estimatedby using speciﬁc algorithms employed in very few statistical packages (e.g., SAS PROCVARCOMP).\\nAs applied to questions of state, occasion and trait variance in frontal EEG asymmetry,\\nsuch a model might be deﬁned as follows (cf. Di Nocera et al., 2001 ):\\nσ\\n2\\ny=σ2\\nt+σ2\\no+σ2\\ns+σ2\\nto+σ2\\nts+σ2\\nos+σ2\\ntos\\nwhere σ2\\nyis the total variance for a given variable, in this case frontal EEG asymmetry,\\nacross all occasions and manipulations, σ2\\ntis the variance in frontal EEG asymmetry at-\\ntributable to individuals (here considered trait variance), σ2\\nois the variance in frontal EEG\\nasymmetry attributable to measurement occasion, σ2\\nsis the variance in frontal EEG asym-\\nmetry attributable to experimentally manipulated states, σ2\\ntois the variance in frontal EEG\\nasymmetry attributable to the interaction of trait and occasion variance, σ2\\ntsis the variance\\nin frontal EEG asymmetry attributable to the interaction of trait and state variance, σ2\\nosis\\nthevarianceinfrontalEEGasymmetryattributabletotheinteractionofoccasionandstatevariance, and σ\\n2\\ntosis the variance in frontal EEG asymmetry attributable to the interaction\\nof trait, occasion and state variance (confounded with error of measurement).\\nG-theory thus provides variance component estimates (percent of variance accounted\\nfor by each component), coefﬁcients of generalizability ( ρ2), as well as coefﬁcients for\\ndependability( φ', 'Issues and assumptions on the road from raw signals.pdf'), 718: ('try attributable to the interaction of trait and state variance, σ2\\nosis\\nthevarianceinfrontalEEGasymmetryattributabletotheinteractionofoccasionandstatevariance, and σ\\n2\\ntosis the variance in frontal EEG asymmetry attributable to the interaction\\nof trait, occasion and state variance (confounded with error of measurement).\\nG-theory thus provides variance component estimates (percent of variance accounted\\nfor by each component), coefﬁcients of generalizability ( ρ2), as well as coefﬁcients for\\ndependability( φorphi),foreachindependentvariableofinterest(inthiscase,trait,occasion\\nandstatecomponents).If,forexample,traitvarianceinfrontalEEGasymmetryshowshighdependabilityinadditiontohighgeneralizability,suchaﬁndingwouldbolsterthelikelihoodthat it would prove useful as a liability indicator for risk for psychopathology, or index a\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 213\\ntrait-like affective style, as this ﬁnding would indicate that trait frontal EEG asymmetry\\ncan be assessed reliably, and that trait frontal EEG asymmetry is independent of statemanipulations and occasion-related ﬂuctuations.\\nFurther,todatenoresearcherhasexaminedthestabilityofstatemanipulationsinfrontal\\nEEG asymmetry, over time or otherwise. G-theory provides useful estimates of reliabilitythatmirrorandextendapproachesdesignedtounderstandintraindividualdynamics,suchasadvocated by Mischel and colleagues (e.g., Shoda and Mischel, 1996; Shoda et al., 1994 ).\\nUsing Shoda and Michel’s approach, such patterns of behavior are represented as if...\\nthen...probabilities that vary from individual to individual and that presumably reﬂect\\nan individual’s underlying personality type ( Mendoza-Denton et al., 2001 ). Effects of this\\ntypearealsoeasilyaccommodatedbyageneralizabilityanalysis,astheywouldbereﬂectedinσ\\n2\\nts,thetraitbystateinteractionterm.Thus,inadditiontoassessingthedependabilityof\\ntrait variance across states and occasions, the dependability of state manipulations acrossindividualsisestimable,asisthedependabilityofoccasionvarianceacrossi', 'Issues and assumptions on the road from raw signals.pdf'), 719: ('as if...\\nthen...probabilities that vary from individual to individual and that presumably reﬂect\\nan individual’s underlying personality type ( Mendoza-Denton et al., 2001 ). Effects of this\\ntypearealsoeasilyaccommodatedbyageneralizabilityanalysis,astheywouldbereﬂectedinσ\\n2\\nts,thetraitbystateinteractionterm.Thus,inadditiontoassessingthedependabilityof\\ntrait variance across states and occasions, the dependability of state manipulations acrossindividualsisestimable,asisthedependabilityofoccasionvarianceacrossindividualsandstates.\\nAlthoughnoinvestigatorshaveappliedthemodelspeciﬁedabovetodatacollectedacross\\nmultipleoccasionsofmeasurement, CoanandAllen(2004,thisissue) didassesstheextent\\nto which state changes in frontal EEG asymmetry were reliably elicited across subjects,and the extent to which trait levels of frontal EEG asymmetry were preserved across statemanipulations. The results indicated that trait-speciﬁc variance, state-speciﬁc variance, aswellasvarianceattributabletotheirinteraction,eachaccountedforapproximately10%ofthetotalexplainedvarianceinfrontalEEGasymmetry.Traitstabilityasmeasuredbythe g\\ncoefﬁcient(intraclasscorrelation)wasestimatedtobemoderatelyhigh(0.47),whereasstatestabilitywasextremelyhigh( gcoefﬁcient =0.92).Althoughtheseresultsidentifystability\\nand sizable contributions of both trait and state frontal EEG asymmetry, trait varianceas estimated from this single measurement occasion will necessarily include both stabletrait and occasion speciﬁc inﬂuences. Indeed, while the state variance in response to themanipulationwashighlystable,thetraitvariancewasonlymoderatelyso.Thismaybedueto the inﬂuence of unmeasured but relevant occasion speciﬁc factors, which future effortsmight proﬁtably explore.\\nA ﬁnal note with respect to the G-theory approach concerns its ﬂexibility to assess the\\nimpactofavarietyofotherfactors,suchastheeffectofreferenceschemeandspeciﬁcfrontalregion.Byincludingtermstoaccountforvarianceduetoparticularreferencescheme,ortotheparticularfrontalregion(e.g.,F4–F3versusF8–F7versusFTC2–FTC1),th', 'Issues and assumptions on the road from raw signals.pdf'), 720: ('se to themanipulationwashighlystable,thetraitvariancewasonlymoderatelyso.Thismaybedueto the inﬂuence of unmeasured but relevant occasion speciﬁc factors, which future effortsmight proﬁtably explore.\\nA ﬁnal note with respect to the G-theory approach concerns its ﬂexibility to assess the\\nimpactofavarietyofotherfactors,suchastheeffectofreferenceschemeandspeciﬁcfrontalregion.Byincludingtermstoaccountforvarianceduetoparticularreferencescheme,ortotheparticularfrontalregion(e.g.,F4–F3versusF8–F7versusFTC2–FTC1),themagnitudeof these sources of variance and their interactions with trait, occasion, and state variancecan be assessed. Similarly, estimates of the stability of the effects across these factors canbe quantitatively assessed.\\n5. Synopsis\\nResearch on frontal EEG asymmetry and emotion now represents a substantial body of\\nliterature. There are numerous methodological issues to which the ﬁeld may have paid in-sufﬁcient attention, while at the same time paying potentially too much attention to otherfactors.Theﬁeldmayhavebeentooconcernedwithrecordingatleast8minofdatatoob-\\n214 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\ntain reliable estimates of asymmetry, overly concerned about the impact of blink artifacts,\\nandoverlyconcernedwithcloselymatchingimpedancesathomologousleads.Bycontrast,too little concern has generally been given to assessing the impact of reference scheme,disentangling left from right hemisphere effects using appropriate statistical models, anddiscerningwhetherspeciﬁcregionsaredifferentiallyinvolvedinvarioustasksorasafunc-tionofindividualdifferences.Itremainstobedeterminedwhethertheimpactofmyogenicactivity substantially inﬂuences ﬁndings involving EEG alpha asymmetry.\\nAs one reviews the frontal EEG asymmetry and emotion literature ( Coan and Allen,\\n2003a;2004,thisissue ),itisapparentthatmanydifferentdataanalyticapproacheshavebeen\\nused, resulting in a collection of ﬁndings that converge despite rather dramatic differencesin: (1) the conditions under which data were recorded; (2) the manner', 'Issues and assumptions on the road from raw signals.pdf'), 721: ('iallyinvolvedinvarioustasksorasafunc-tionofindividualdifferences.Itremainstobedeterminedwhethertheimpactofmyogenicactivity substantially inﬂuences ﬁndings involving EEG alpha asymmetry.\\nAs one reviews the frontal EEG asymmetry and emotion literature ( Coan and Allen,\\n2003a;2004,thisissue ),itisapparentthatmanydifferentdataanalyticapproacheshavebeen\\nused, resulting in a collection of ﬁndings that converge despite rather dramatic differencesin: (1) the conditions under which data were recorded; (2) the manner in which data werereduced; and (3) the manner in which data were subsequently analyzed. The optimist willseethisasatestamenttotherobustnessoftheunderlyingsystemsreﬂectedinfrontalEEGasymmetry, and the curmudgeon will see this as representing considerable literature-widealphaslippageduetothemanypermutationsofdatareductionandanalysis.Aconservativeintermediate interpretation is that the larger enterprise of interpreting the data and theorybuildingwillbeneﬁtfromamoresolidempiricalfoundation,onethatwillrequirethatcarefulattentionbegiventoEEGdatarecordingandanalysis.Theissueshighlightedheremaybestbe regarded as fundamentals that may inform future efforts, to assist in the creation of amore methodologically consistent and precise data base. Only with such a foundation canresearchersthenexploretheunderlyingfunctional,anatomicalandneurochemicalsystemsthat may be tapped by frontal EEG asymmetry.\\nAcknowledgements\\nThisresearchwassupported,inpart,byagrantfromtheNationalAllianceforResearch\\nonSchizophreniaandDepression(NARSAD)andanExploratory/DevelopmentGrantfromtheNationalInstitutesofHealth(1R21RR09492)toJ.J.B.A.,andbyaGraduateResearchFellowship from the National Science Foundation to J.A.C.\\nReferences\\nAiken, S.L., West, S.G., 1991. Multiple Regression: Testing and Interpreting Interactions. Sage Publications,\\nThousand Oaks, CA.\\nAllen,J.J.B.,Harmon-Jones,E.,Cavender,J.H.,2001.ManipulationoffrontalEEGasymmetrythroughbiofeed-\\nback alters self-reported emotional responses and facial EMG. Psychophysiology 38, 685–693.\\nAllen, J.J', 'Issues and assumptions on the road from raw signals.pdf'), 722: ('AD)andanExploratory/DevelopmentGrantfromtheNationalInstitutesofHealth(1R21RR09492)toJ.J.B.A.,andbyaGraduateResearchFellowship from the National Science Foundation to J.A.C.\\nReferences\\nAiken, S.L., West, S.G., 1991. Multiple Regression: Testing and Interpreting Interactions. Sage Publications,\\nThousand Oaks, CA.\\nAllen,J.J.B.,Harmon-Jones,E.,Cavender,J.H.,2001.ManipulationoffrontalEEGasymmetrythroughbiofeed-\\nback alters self-reported emotional responses and facial EMG. Psychophysiology 38, 685–693.\\nAllen, J.J.B., Urry, H.L., Hitt, S.K., Coan, J.A., 2004. The stability of resting frontal electroencephalographic\\nasymmetry in depression. Psychophysiology 41, 269–280.\\nAndersen, P., Andersson, S.A., Lomo, T., 1967a. Nature of thalamo-cortical relations during spontaneous barbi-\\nturate spindle activity. Journal of Physiology 192, 283–307.\\nAndersen, P., Andersson, S.A., Lomo, T., 1967b. Some factors involved in the thalamic control of spontaneous\\nbarbiturate spindles. Journal of Physiology 192, 257–281.\\nBaehr,E.,Rosenfeld,J.P.,Baehr,R.,Earnest,C.,1998.ComparisonoftwoEEGasymmetryindicesindepressed\\npatients vs. normal controls. International Journal of Psychophysiology 31 (1), 89–92.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 215\\nBem, D.J., Allen, A., 1974. On predicting some of the people some of the time: the search for cross-situational\\nconsistencies in behavior. Psychological Review 81 (6), 506–520.\\nBerger, H., 1930. Uber das elektrenkephalogramm des Menschen II. Journal fur Psychologie und Neurologi 40,\\n160–179.\\nBerger,H.,1931.UberdaselektrenkephalogrammdesMenschenIII.ArchivfurPsychiatrieundNervenkrankheiten\\n94, 16–60.\\nBerger,H.,1932.UberdaselektrenkephalogrammdesMenschenIV.ArchivfurPsychiatrieundNervenkrankheiten\\n97, 6–26.\\nBlackhart,G.C.,Kline,J.P.,Donohue,K.F.,LaRowe,S.D.,Joiner,T.E.,2002.AffectiveresponsestoEEGprepa-\\nrationandtheirlinktorestinganteriorEEGsymmetry.Personality&IndividualDifferences32(1),167–174.\\nBorod, J.C., Haywood, C.S., Koff, E., 1997. Neuropsychological aspects of facial asymmetry', 'Issues and assumptions on the road from raw signals.pdf'), 723: ('40,\\n160–179.\\nBerger,H.,1931.UberdaselektrenkephalogrammdesMenschenIII.ArchivfurPsychiatrieundNervenkrankheiten\\n94, 16–60.\\nBerger,H.,1932.UberdaselektrenkephalogrammdesMenschenIV.ArchivfurPsychiatrieundNervenkrankheiten\\n97, 6–26.\\nBlackhart,G.C.,Kline,J.P.,Donohue,K.F.,LaRowe,S.D.,Joiner,T.E.,2002.AffectiveresponsestoEEGprepa-\\nrationandtheirlinktorestinganteriorEEGsymmetry.Personality&IndividualDifferences32(1),167–174.\\nBorod, J.C., Haywood, C.S., Koff, E., 1997. Neuropsychological aspects of facial asymmetry during emotional\\nexpression: a review of the normal adult literature. Neuropsychology Review 7, 41–60.\\nCacioppo,J.T.,Tassinary,L.G.,Fridlund,A.J.,1990.Theskeletomotorsystem.In:Cacioppo,J.T.,Tassinary,L.G.\\n(Eds.), Principles of Psychophysiology. Cambridge University Press, New York, NY.\\nCampbell,D.T.,Fiske,D.W.,1959.Convergentanddiscriminantvalidationbythemultitrait–multimethodmatrix.\\nPsychological Bulletin 56, 81–105.\\nCoan, J.A., Allen, J.J.B., 2003a. Frontal EEG asymmetry and the behavioral activation and inhibition systems.\\nPsychophysiology 40, 106–114.\\nCoan,J.A.,Allen,J.J.B.,2003b.ThestateandtraitnatureoffrontalEEGasymmetryinemotion.In:Hugdahl,K.,\\nDavidson, R.J. (Eds.), The Asymmetrical Brain, second ed. MIT Press, Cambridge, MA, pp. 565–615.\\nCoan, J.A., Allen, J.J.B., 2004. Frontal EEG asymmetry as a moderator and mediator of emotion. Biological\\nPsychology 67, 7–49.\\nCoan, J.A., Allen, J.J.B., Harmon-Jones, E., 2001. Voluntary facial expression and hemispheric asymmetry over\\nthe frontal cortex. Psychophysiology 38, 912–925.\\nCook, I.A., O’Hara, R., Uijtdehaage, S.H., Mandelkern, M., Leuchter, A.F., 1998. Assessing the accuracy of\\ntopographic EEG mapping for determining local brain function. Electroencephalography & Clinical Neuro-physiology 107 (6), 408–414.\\nCronbach,L.J.,Gleser,G.C.,Nanda,H.,Rajaratnam,N.,1972.TheDependabilityofBehavioralMeasurements:\\nTheory of Generalizability of Scores and Proﬁles. Wiley, New York.\\nCruickshank, R.M., 1937. Human occipital brain potentials as affected by intensity-duration', 'Issues and assumptions on the road from raw signals.pdf'), 724: ('iology 38, 912–925.\\nCook, I.A., O’Hara, R., Uijtdehaage, S.H., Mandelkern, M., Leuchter, A.F., 1998. Assessing the accuracy of\\ntopographic EEG mapping for determining local brain function. Electroencephalography & Clinical Neuro-physiology 107 (6), 408–414.\\nCronbach,L.J.,Gleser,G.C.,Nanda,H.,Rajaratnam,N.,1972.TheDependabilityofBehavioralMeasurements:\\nTheory of Generalizability of Scores and Proﬁles. Wiley, New York.\\nCruickshank, R.M., 1937. Human occipital brain potentials as affected by intensity-duration variables of visual\\nstimulation. Journal of Experimental Psychology 21, 625–641.\\nDavidson,R.J.,1988.EEGmeasuresofcerebralasymmetry:conceptualandmethodologicalissues.International\\nJournal of Neuroscience 39 (1–2), 71–89.\\nDavidson,R.J.,1992.Anteriorcerebralasymmetryandthenatureofemotion.Brain&Cognition20(1),125–151.Davidson,R.J.,1998.Affectivestyleandaffectivedisorders:perspectivesfromaffectiveneuroscience.Cognition\\n& Emotion 12 (3), 307–330.\\nDavidson, R.J., 22 and 24 September 2002. Personal communication.Davidson, R.J., Chapman, J.P., Chapman, L.J., Henriques, J.B., 1990. Asymmetrical brain electrical activity\\ndiscriminatesbetweenpsychometrically-matchedverbalandspatialcognitivetasks.Psychophysiology27(5),528–543.\\nDavidson, R.J., Jackson, D.C., Larson, C.L., 2000a. Human electroencephalography. In: Cacioppo, J.T., Tassi-\\nnary, L.G., Berntson, G.G. (Eds.), Handbook of Psychophysiology, second ed. Cambridge University Press,Cambridge, UK, pp. 27–52.\\nDavidson, R.J., Marshall, J.R., Tomarken, A.J., Henriques, J.B., 2000b. While a phobic waits: regional brain\\nelectricalandautonomicactivityinsocialphobicsduringanticipationofpublicspeaking.BiologicalPsychiatry47 (2), 85–95.\\nDi Nocera, F., Ferlazzo, F., Borghi, V., 2001. G theory and the reliability of psychophysiological measures: a\\ntutorial. Psychophysiology 38, 796–806.\\nDurup,G.,Fessard,A.,1936a.L’electrencephalogrammedel’homme.Donneesquantitativessurel’arretprovoque\\npar des stimuli visuels ou auditifs. Comptes Rendus des Seances de la Societe de Biologie et de ses', 'Issues and assumptions on the road from raw signals.pdf'), 725: ('B., 2000b. While a phobic waits: regional brain\\nelectricalandautonomicactivityinsocialphobicsduringanticipationofpublicspeaking.BiologicalPsychiatry47 (2), 85–95.\\nDi Nocera, F., Ferlazzo, F., Borghi, V., 2001. G theory and the reliability of psychophysiological measures: a\\ntutorial. Psychophysiology 38, 796–806.\\nDurup,G.,Fessard,A.,1936a.L’electrencephalogrammedel’homme.Donneesquantitativessurel’arretprovoque\\npar des stimuli visuels ou auditifs. Comptes Rendus des Seances de la Societe de Biologie et de ses Filiales122, 756–758.\\nDurup,G.,Fessard,A.,1936b.L’electrencephalogrammedel’hommeobservationspsychophysiologiquesrelative\\na l’action des stimuli visuels et auditifs. Annee Psychologie 36, 1–32.\\n216 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nEshel,Y.,Witman,S.,Rosenfeld,M.,Abboud,S.,1995.Correlationbetweenskullthicknessasymmetryandscalp\\npotential estimated by a numerical model of the head. IEEE Transactions on Biomedical Engineering 42 (3),242–249.\\nFerree, T.C., 27 November 2002. Personal communication.Ferree, T.C., Luu, P., Russell, G.S., Tucker, D.M., 2001. Scalp electrode impedance, infection risk and EEG data\\nquality. Clinical Neurophysiology 112 (3), 536–544.\\nFox,N.A.,Davidson,R.J.,1987.Electroencephalogramasymmetryinresponsetotheapproachofastrangerand\\nmaternal separation in 10 month old infants. Developmental Psychology 23, 233–240.\\nFriedman,B.H.,Thayer,J.F.,1991.FacialmuscleactivityandEEGrecordings—redundancyanalysis.Electroen-\\ncephalography and Clinical Neurophysiology 79, 358–360.\\nGasser, T., Sroka, L., Mocks, J., 1985. The transfer of EOG activity into the EEG for eyes open and closed.\\nElectroencephalography & Clinical Neurophysiology 61 (2), 181–193.\\nGibbs,F.A.,Davis,H.,Lennox,W.G.,1935.Theelectro-encephalograminepilepsyandinconditionsofimpaired\\nconsciousness. Archives of Neurological Psychiatry 34, 1133–1148.\\nGlaser, E.M., Ruchkin, D.S., 1976. Principles of Neurobiological Signal Analysis. Academic Press, New York.Gratton, G., 1998. Dealing with artifacts: the EOG contamination of th', 'Issues and assumptions on the road from raw signals.pdf'), 726: ('ser, T., Sroka, L., Mocks, J., 1985. The transfer of EOG activity into the EEG for eyes open and closed.\\nElectroencephalography & Clinical Neurophysiology 61 (2), 181–193.\\nGibbs,F.A.,Davis,H.,Lennox,W.G.,1935.Theelectro-encephalograminepilepsyandinconditionsofimpaired\\nconsciousness. Archives of Neurological Psychiatry 34, 1133–1148.\\nGlaser, E.M., Ruchkin, D.S., 1976. Principles of Neurobiological Signal Analysis. Academic Press, New York.Gratton, G., 1998. Dealing with artifacts: the EOG contamination of the event-related brain potential. Behavior\\nResearch Methods, Instruments, & Computers 30 (1), 44–53.\\nGratton,G.,2000.Biosignalprocessing.In:Cacioppo,J.T.,Tassinary,L.G.,Berntson,G.G.(Eds.),Handbookof\\nPsychophysiology, second ed. Cambridge University Press, New York, pp. 900–923.\\nHagemann, D., Naumann, E., 2001. The effects of ocular artifacts on (lateralized) broadband power in the EEG.\\nClinical Neurophysiology 112 (2), 215–231.\\nHagemann, D., Naumann, E., Becker, G., Maier, S., Bartussek, D., 1998. Frontal brain asymmetry and affective\\nstyle: a conceptual replication. Psychophysiology 35 (4), 372–388.\\nHagemann, D., Naumann, E., Thayer, J.F., 2001. The quest for the EEG reference revisited: a glance from brain\\nasymmetry research. Psychophysiology 38, 847–857.\\nHagemann, D., Naumann, E., Thayer, J.F., Bartussek, D., 2002. Does resting electroencephalograph asymmetry\\nreﬂect a trait? An application of latent state–trait theory. Journal of Personality & Social Psychology 82 (4),619–641.\\nHarmon-Jones, E., Allen, J.J.B., 1997. Behavioral activation sensitivity and resting frontal EEG asymmetry:\\ncovariationofputativeindicatorsrelatedtoriskformooddisorders.JournalofAbnormalPsychology106(1),159–163.\\nHarmon-Jones,E.,Allen,J.J.B.,1998.Angerandfrontalbrainactivity:EEGasymmetryconsistentwithapproach\\nmotivationdespitenegativeaffectivevalence.JournalofPersonality&SocialPsychology74(5),1310–1316.\\nHenriques, J.B., Davidson, R.J., 1990. Regional brain electrical asymmetries discriminate between previously\\ndepressed and healthy cont', 'Issues and assumptions on the road from raw signals.pdf'), 727: ('B., 1997. Behavioral activation sensitivity and resting frontal EEG asymmetry:\\ncovariationofputativeindicatorsrelatedtoriskformooddisorders.JournalofAbnormalPsychology106(1),159–163.\\nHarmon-Jones,E.,Allen,J.J.B.,1998.Angerandfrontalbrainactivity:EEGasymmetryconsistentwithapproach\\nmotivationdespitenegativeaffectivevalence.JournalofPersonality&SocialPsychology74(5),1310–1316.\\nHenriques, J.B., Davidson, R.J., 1990. Regional brain electrical asymmetries discriminate between previously\\ndepressed and healthy control subjects. Journal of Abnormal Psychology 99 (1), 22–31.\\nHenriques,J.B.,Davidson,R.J.,1991.Leftfrontalhypoactivationindepression.JournalofAbnormalPsychology\\n100 (4), 535–545.\\nHjorth,B.,1975.Anon-linetransformationofEEGscalppotentialsintoorthogonalsourcederivations.Electroen-\\ncephalography & Clinical Neurophysiology 39 (5), 526–530.\\nIacono, W.G., Lykken, D.T., 1981. Two-year retest stability of eye tracking performance and a comparison of\\nelectro-oculographic and infrared recording techniques: evidence of EEG in the electro-oculogram. Psy-chophysiology 18 (1), 49–55.\\nJasper, H.H., Cruickshank, R.M., 1937. Electro-encephalography: II. Visual stimulation and the after-image as\\naffecting the occipital alpha rhythm. Journal of General Psychology 17, 29–48.\\nJones, N.A., Field, T., Davalos, M., Pickens, J., 1997. EEG stability in infants/children of depressed mothers,\\nChild Psychiatry. Child Psychiatry & Human Development 28 (2), 59–70.\\nKitamura,K.,1939.Dieelektrencephalographischeuntersuchungdergerschmacksempﬁndlichkeit.TohokuPsy-\\nchologica Folia 7, 13–32.\\nKlimesch, W., Doppelmayr, M., Pachinger, T., Ripper, B., 1997. Brain oscillations and human memory: EEG\\ncorrelates in the upper alpha and theta band. Neuroscience Letters 238 (1–2), 9–12.\\nKline, J.P., Blackhart, G.C., Joiner, T.E., 2002. Sex, lie scales, and electrode caps: an interpersonal context for\\ndefensiveness and anterior electroencephalographic asymmetry. Personality & Individual Differences 33 (3),459–478.\\nJ.J.B. Allen et al./Biological Psychology 67 (2', 'Issues and assumptions on the road from raw signals.pdf'), 728: ('lichkeit.TohokuPsy-\\nchologica Folia 7, 13–32.\\nKlimesch, W., Doppelmayr, M., Pachinger, T., Ripper, B., 1997. Brain oscillations and human memory: EEG\\ncorrelates in the upper alpha and theta band. Neuroscience Letters 238 (1–2), 9–12.\\nKline, J.P., Blackhart, G.C., Joiner, T.E., 2002. Sex, lie scales, and electrode caps: an interpersonal context for\\ndefensiveness and anterior electroencephalographic asymmetry. Personality & Individual Differences 33 (3),459–478.\\nJ.J.B. Allen et al./Biological Psychology 67 (2004) 183–218 217\\nKnott,J.R.,1938.ReducedlatenttimeofblockingoftheBergerrhythmtolightstimuli.ProceedingsoftheSociety\\nfor Experimental Biology and Medicine 38, 216–217.\\nKnott, J.R., 1939. Some effects of “mental set” upon the electrophysiological processes of the human cerebral\\ncortex. Journal of Experimental Psychology 24, 384–405.\\nLarson, C.L., Davidson, R.J., Abercrombie, H.C., Ward, R.T., Schaefer, S.M., Jackson, D.C., 1998. Relations\\nbetween PET-derived measures of thalamic glucose metabolism and EEG alpha power. Psychophysiology35 (2), 162–169.\\nLeissner, P., Lindholm, L.E., Petersen, I., 1970. Alpha amplitude dependence on skull thickness as measured by\\nultrasound technique. Electroencephalography & Clinical Neurophysiology 29 (4), 392–399.\\nLeuchter,A.F.,Cook,I.A.,Lufkin,R.B.,Dunkin,J.,Newton,T.F.,Cummings,J.L.,1994.Cordance:anewmethod\\nforassessmentofcerebralperfusionandmetabolismusingquantitativeelectroencephalography.Neuroimage1 (3), 208–219.\\nLeuchter, A.F., Cook, I.A., Witte, E.A., Morgan, M., Abrams, M., 2002. Changes in brain function of depressed\\nsubjects during treatment with placebo. American Journal of Psychiatry 159 (1), 122–129.\\nLeuchter, A.F., Uijtdehaage, S.H., Cook, I.A., O’Hara, R., Mandelkern, M., 1999. Relationship between brain\\nelectrical activity and cortical perfusion in normal subjects. Psychiatry Research 90 (2), 125–140.\\nLivanov,M.N.,1940.Rhythmicalstimuliandtheinterrelationbetweentheareasofthecerebralcortex.Journalof\\nPhysiology 28, 172–194.\\nLord, F.M., Novick, M.R., 1968. Statistical', 'Issues and assumptions on the road from raw signals.pdf'), 729: ('M., 2002. Changes in brain function of depressed\\nsubjects during treatment with placebo. American Journal of Psychiatry 159 (1), 122–129.\\nLeuchter, A.F., Uijtdehaage, S.H., Cook, I.A., O’Hara, R., Mandelkern, M., 1999. Relationship between brain\\nelectrical activity and cortical perfusion in normal subjects. Psychiatry Research 90 (2), 125–140.\\nLivanov,M.N.,1940.Rhythmicalstimuliandtheinterrelationbetweentheareasofthecerebralcortex.Journalof\\nPhysiology 28, 172–194.\\nLord, F.M., Novick, M.R., 1968. Statistical Theories of Mental Test Scores. Addison-Wesley, Reading, MA.Mendoza-Denton, R., Ayduk, O., Mischel, W., Shoda, Y., Testa, A., 2001. Person ×situation interactionism in\\nself-encoding(Iam ...when ...):implicationsforaffectregulationandsocialinformationprocessing.Journal\\nof Personality & Social Psychology 80 (4), 533–544.\\nMiller, A., Tomarken, A.J., 2001. Task-dependent changes in frontal brain asymmetry: effects of incentive cues\\noutcome expectancies and motor responses. Psychophysiology 38, 500–511.\\nMinnix, J.A., Kline, J.P., 2004. Neuroticism predicts resting frontal EEG asymmetry variability. Personality and\\nIndividual Differences 36, 823–832.\\nMotokawa,K.,Tosiada,M.,1941.Dieelektrenkephalographischeuntersuchunguberdenadaptationsmechanismus\\ndes zentralnervensystems. Japanese Journal of Medical, Science and Biophysics 7, 213–233.\\nNunez, P., 1981. Electrical Fields of the Brain: The Neurophysics of EEG. Oxford University Press, New York.Nyquist, H., 1928. Certain topics in telegraph transmission theory. Transactions of the American Institute of\\nElectrical Engineers 47, 617–644.\\nOverall, J.E., Woodward, J.A., 1975. Unreliability of difference scores: a paradox for measurement of change.\\nPsychological Bulletin 82, 85–86.\\nPfefferbaum, A., 1990. Model estimates of CSF and skull inﬂuences on scalp-recorded ERPs. Alcohol 7 (5),\\n479–482.\\nPicton,T.W.,Bentin,S.,Berg,P.,Donchin,E.,Hillyard,S.A.,Johnson Jr.,R.,2000.Guidelinesforusinghuman\\nevent-related potentials to study cognition: recording standards and publication crit', 'Issues and assumptions on the road from raw signals.pdf'), 730: ('ctions of the American Institute of\\nElectrical Engineers 47, 617–644.\\nOverall, J.E., Woodward, J.A., 1975. Unreliability of difference scores: a paradox for measurement of change.\\nPsychological Bulletin 82, 85–86.\\nPfefferbaum, A., 1990. Model estimates of CSF and skull inﬂuences on scalp-recorded ERPs. Alcohol 7 (5),\\n479–482.\\nPicton,T.W.,Bentin,S.,Berg,P.,Donchin,E.,Hillyard,S.A.,Johnson Jr.,R.,2000.Guidelinesforusinghuman\\nevent-related potentials to study cognition: recording standards and publication criteria. Psychophysiology37 (2), 127–152.\\nReid, S.A., Duke, L.M., Allen, J.J.B., 1998. Resting frontal electroencephalographic asymmetry in depression:\\ninconsistencies suggest the need to identify mediating factors. Psychophysiology 35 (4), 389–404.\\nReilly, E.L., 1987. EEG recording and operation of the apparatus. In: Niedermeyer, E., Silva, F.H.L.D. (Eds.),\\nElectroencephalogaphy: Basic Principles, Clinical Applications, and Related Fields, second ed. Urban &Schwarzenberg, Inc., Baltimore, pp. 57–77.\\nSchwartz, G.E., Fair, P.L., Salt, P., Mandel, M.R., Klerman, G.L., 1976. Facial muscle patterning to affective\\nimagery in depressed and nondepressed subjects. Science 192 (4238), 489–491.\\nShoda, Y., Mischel, W., 1996. Toward a uniﬁed, intra-individual dynamic conception of personality. Journal of\\nResearch in Personality Special Issue: The Future of Personality 30 (3), 414–428.\\nShoda,Y.,Mischel,W.,Wright,J.C.,1994.Intraindividualstabilityintheorganizationandpatterningofbehavior:\\nincorporating psychological situations into the idiographic analysis of personality. Journal of Personality &Social Psychology 67 (4), 674–687.\\nSteriade, M., Deschenes, M., Domich, L., Mulle, C., 1985. Abolition of spindle oscillations in thalamic neurons\\ndisconnected from nucleus reticularis thalami. Journal of Neurophysiology 54 (6), 1473–1497.\\nStern, J.A., Walrath, L.C., Goldstein, R., 1984. The endogenous eyeblink. Psychophysiology 21 (1), 22–33.\\n218 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nSutton,S.K.,Davidson,R.J.,1997.', 'Issues and assumptions on the road from raw signals.pdf'), 731: (' into the idiographic analysis of personality. Journal of Personality &Social Psychology 67 (4), 674–687.\\nSteriade, M., Deschenes, M., Domich, L., Mulle, C., 1985. Abolition of spindle oscillations in thalamic neurons\\ndisconnected from nucleus reticularis thalami. Journal of Neurophysiology 54 (6), 1473–1497.\\nStern, J.A., Walrath, L.C., Goldstein, R., 1984. The endogenous eyeblink. Psychophysiology 21 (1), 22–33.\\n218 J.J.B. Allen et al./Biological Psychology 67 (2004) 183–218\\nSutton,S.K.,Davidson,R.J.,1997.Prefrontalbrainasymmetry:abiologicalsubstrateofthebehavioralapproach\\nand inhibition systems. Psychological Science 8 (3), 204–210.\\nTomarken,A.J.,Davidson,R.J.,Wheeler,R.E.,Kinney,L.,1992.PsychometricpropertiesofrestinganteriorEEG\\nasymmetry: temporal stability and internal consistency. Psychophysiology 29 (5), 576–592.\\nTravis, L.E., Barber, V., 1938. The effect of tactile stimulation upon the Berger rhythm. Journal of Experimental\\nPsychology 22, 269–272.\\nTravis,L.E.,Knott,J.R.,Grifﬁth,P.E.,1937.EffectofresponseonthelatencyandfrequencyoftheBergerrhythm.\\nJournal of General Psychology 16, 391–401.\\nWheeler, R.E., Davidson, R.J., Tomarken, A.J., 1993. Frontal brain asymmetry and emotional reactivity: a bio-\\nlogical substrate of affective style. Psychophysiology 30 (1), 82–89.\\nZimmerman, D.W., Williams, R.H., Zumbo, B.D., 1993. Reliability of measurement and power of signiﬁcance\\ntests based on differences. Applied Psychological Measurement 17, 1–9.', 'Issues and assumptions on the road from raw signals.pdf'), 732: ('Persistent Memory Research in the Post-Optane Era\\nPeter Desnoyers\\nNortheastern University\\np.desnoyers@northeastern.eduIan Adams\\nIntel Corporation\\nian.f.adams@intel.comTyler Estro\\nStony Brook University\\ntestro@cs.stonybrook.edu\\nAnshul Gandhi\\nStony Brook University\\nanshul@cs.stonybrook.eduGeoff Kuenning\\nHarvey Mudd College\\ngeoff@cs.hmc.eduMike Mesnier\\nIntel Corporation\\nmichael.mesnier@intel.com\\nCarl Waldspurger\\nCarl Waldspurger Consulting\\ncarl@waldspurger.orgAvani Wildani\\nEmory University and Cloudflare\\nagadani@gmail.comErez Zadok\\nStony Brook University\\nezk@fsl.cs.sunysb.edu\\nABSTRACT\\nAfter over a decade of researcher anticipation for the arrival\\nof persistent memory (PMem), the first shipments of 3D\\nXPoint-based Intel Optane Memory in 2019 were quickly\\nfollowed by its cancellation in 2022. Was this another case of\\nan idea quickly fading from future to past tense, relegating\\nwork in this area to the graveyard of failed technologies?\\nThe recently introduced Compute Express Link (CXL) may\\noffer a path forward, with its persistent memory profile offer-\\ning a universal PMem attachment point. Yet new technolo-\\ngies for memory-speed persistence seem years off, and may\\nnever become competitive with evolving DRAM and flash\\nspeeds. Without persistent memory itself, is future PMem\\nresearch doomed? We offer two arguments for why reports\\nof the death of PMem research are greatly exaggerated.\\nFirst, the bulk of persistent-memory research has not in\\nfact addressed memory persistence, but rather in-memory\\ncrash consistency, which was never an issue in prior sys-\\ntems where CPUs could not observe post-crash memory\\nstates. CXL memory pooling allows multiple hosts to share\\na single memory, all in different failure domains, raising\\ncrash-consistency issues even with volatile memory.\\nSecond, we believe CXL necessitates a “disaggregation” of\\nPMem research. Most work to date assumed a single tech-\\nnology and set of features, i.e., speed, byte addressability,\\nPermission to make digital or hard copies of all or part of this work for\\nperson', 'Persistent Memory Research in the Post-Optane Era.pdf'), 733: ('h was never an issue in prior sys-\\ntems where CPUs could not observe post-crash memory\\nstates. CXL memory pooling allows multiple hosts to share\\na single memory, all in different failure domains, raising\\ncrash-consistency issues even with volatile memory.\\nSecond, we believe CXL necessitates a “disaggregation” of\\nPMem research. Most work to date assumed a single tech-\\nnology and set of features, i.e., speed, byte addressability,\\nPermission to make digital or hard copies of all or part of this work for\\npersonal or classroom use is granted without fee provided that copies\\nare not made or distributed for profit or commercial advantage and that\\ncopies bear this notice and the full citation on the first page. Copyrights\\nfor components of this work owned by others than the author(s) must\\nbe honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific\\npermission and/or a fee. Request permissions from permissions@acm.org.\\nDIMES ’23, October 23, 2023, Koblenz, Germany\\n©2023 Copyright held by the owner/author(s). Publication rights licensed\\nto ACM.\\nACM ISBN 979-8-4007-0300-3/23/10. . . $15.00\\nhttps://doi.org/10.1145/3609308.3625268and CPU load/store access. With an open interface allowing\\nnew topologies and diverse PMem technologies, we argue\\nfor the need to examine these features individually and in\\ncombination.\\nWhile one form of PMem may have been canceled, we\\nargue that the research problems it raised not only remain\\nrelevant but have expanded in a CXL-based future.\\nCCS CONCEPTS\\n•Information systems →Storage class memory.\\nKEYWORDS\\nPersistent memory, PMem, 3D XPoint, Optane, CXL.\\nACM Reference Format:\\nPeter Desnoyers, Ian Adams, Tyler Estro, Anshul Gandhi, Geoff\\nKuenning, Mike Mesnier, Carl Waldspurger, Avani Wildani, and Erez\\nZadok. 2023. Persistent Memory Research in the Post-Optane Era.\\nIn1st Workshop on Disruptive Memory Systems (DIMES ’23), October\\n23, 2023, Koblenz, Germany. ACM, New York, NY, USA, 8 pages.\\nhttps://doi.org/10.', 'Persistent Memory Research in the Post-Optane Era.pdf'), 734: (' have expanded in a CXL-based future.\\nCCS CONCEPTS\\n•Information systems →Storage class memory.\\nKEYWORDS\\nPersistent memory, PMem, 3D XPoint, Optane, CXL.\\nACM Reference Format:\\nPeter Desnoyers, Ian Adams, Tyler Estro, Anshul Gandhi, Geoff\\nKuenning, Mike Mesnier, Carl Waldspurger, Avani Wildani, and Erez\\nZadok. 2023. Persistent Memory Research in the Post-Optane Era.\\nIn1st Workshop on Disruptive Memory Systems (DIMES ’23), October\\n23, 2023, Koblenz, Germany. ACM, New York, NY, USA, 8 pages.\\nhttps://doi.org/10.1145/3609308.3625268\\n1 INTRODUCTION\\nAs CPU processing speeds and core counts continue to grow,\\nso too do the I/O speeds needed to feed data to ever-faster\\nCPUs, with some workloads (e.g., indexes, Bloom filters)\\nbeing particularly sensitive to I/O latency. Yet as storage\\nlatencies drop into the 10s of microseconds, improvements\\nin device speed begin to be overshadowed by software de-\\nlays and overheads in the OS storage stack. While various\\nstrategies have been used to reduce these overheads [ 54],\\npersistent memory allows them to be bypassed entirely for\\nmost accesses.\\nIn recent years, the availability of persistent memory\\n(PMem) has spurred a flurry of research [ 5,12,18,22,\\n25,26,28,29,37,47,53]. PMem’s unique properties en-\\ncouraged research in the storage community and beyond:\\n23\\n\\nDIMES ’23, October 23, 2023, Koblenz, Germany P. Desnoyers et al.\\nalgorithms [ 6,10,12], compilers [ 23,32,33], data struc-\\ntures [ 18,28,29,37], file systems [ 25,31,48], key-value\\nstores [ 5,26,55], operating systems [ 3,27,40,50], and even\\nnon-systems areas have been affected. Industry efforts pro-\\nduced the Storage Networking Industry Association (SNIA)\\nprogramming model [46] and the PMDK [21] library.\\nWhen Intel canceled its 3D XPoint-based Optane product\\nline [ 20], researchers were suddenly left wondering whether\\npersistent-memory technologies had any future. Yet behind\\nthe headlines, both Micron [ 36] and Intel [ 19] embraced\\nthe industry Compute Express Link (CXL) [ 8] standard as\\ntheir future direction for persistent an', 'Persistent Memory Research in the Post-Optane Era.pdf'), 735: ('0,50], and even\\nnon-systems areas have been affected. Industry efforts pro-\\nduced the Storage Networking Industry Association (SNIA)\\nprogramming model [46] and the PMDK [21] library.\\nWhen Intel canceled its 3D XPoint-based Optane product\\nline [ 20], researchers were suddenly left wondering whether\\npersistent-memory technologies had any future. Yet behind\\nthe headlines, both Micron [ 36] and Intel [ 19] embraced\\nthe industry Compute Express Link (CXL) [ 8] standard as\\ntheir future direction for persistent and hierarchical memory.\\nOthers have also begun to discuss the lessons learned and\\noutline future prospects for PMem [2, 15, 24, 45].\\nPersistent memory has in effect taken one step backwards,\\nlosing a storage technology, and one tentative step forwards,\\ngaining an alternate, arguably superior interface. This new\\ninterface is not only vendor-independent but multipurpose,\\nwith use cases (e.g., cache-coherent GPU-to-host access, CXL\\nmemory pooling) that are likely to ensure its viability inde-\\npendent of market demands for persistent memory. Before\\nCXL, only CPU vendors could consider integrating persistent\\nmemory into a system; with CXL, even academic researchers\\ncan design and deploy FPGA-based PMem prototypes. But\\nshould they?\\nAnswering this question requires examining the defining\\ncharacteristics of PMem in more detail: (a) persistence, (b)\\nbyte addressability, and (c) direct access via CPU load/store\\ninstructions.\\nByte addressability reduces the cost of small accesses;\\nload/store access dramatically accelerates some I/O tasks,\\nproviding direct user-space access without kernel interven-\\ntion. In addition to those features, Optane provided near-\\nDRAM speed and better-than-DRAM cost per bit.\\nGiven multiple potential persistent technologies and meth-\\nods of access, we believe it is important to consider PMem’s\\nfeatures—including persistence itself—individually as well\\nas in various combinations. Is load/store access important,\\nor would user-space byte-granular access via an RDMA-like\\nmechanism provide similar perfo', 'Persistent Memory Research in the Post-Optane Era.pdf'), 736: ('es some I/O tasks,\\nproviding direct user-space access without kernel interven-\\ntion. In addition to those features, Optane provided near-\\nDRAM speed and better-than-DRAM cost per bit.\\nGiven multiple potential persistent technologies and meth-\\nods of access, we believe it is important to consider PMem’s\\nfeatures—including persistence itself—individually as well\\nas in various combinations. Is load/store access important,\\nor would user-space byte-granular access via an RDMA-like\\nmechanism provide similar performance? Which Optane\\nperformance improvements require near-DRAM speed, vs.\\nthose that are enabled by merely better-than-NVMe per-\\nformance? What about the non-persistent case with CXL\\nmemory pooling, and does multi-host access across multi-\\nple failure domains pose the same challenges as single-host\\nPMem, or new ones? Finally, how important is price, and in\\nparticular would PMem be viable if it were no cheaper than\\nDRAM?1\\n1We note that “cheaper than DRAM” is a vague target, as high-density\\nDIMMs carry a cost premium of up to 10 ×over lower densities.2 WHAT IS PERSISTENT MEMORY?\\nBypersistent Memory orPMem we refer to media with\\nbyte-addressable access (e.g., via hardware access at cache-\\nline granularity)via CPU load/store instructions, with coher-\\nent caching, but with the persistence properties of storage.\\nPMem supports direct memory access (DMA) by other de-\\nvices, and is fast enough to warrant waiting for a load in-\\nstruction rather than context-switching to another thread as\\nis done with slower storage (e.g., NAND Flash) [ 42]. Software\\nsupport (e.g., via libraries conforming to the SNIA NVM Pro-\\ngramming Model [ 46]) allows PMem implementations using\\nnatively persistent media (e.g., 3D XPoint) or natively volatile\\n(e.g., DRAM) devices with hardware support for persistence\\nin the event of power loss.\\nAdditional higher-level functions supported by the SNIA\\nmodel include: (a) PMem-aware file systems—e.g., ext4 with\\nthe DAX option—which provide naming, access control, and\\nthe ability to map persistent data int', 'Persistent Memory Research in the Post-Optane Era.pdf'), 737: ('.g., NAND Flash) [ 42]. Software\\nsupport (e.g., via libraries conforming to the SNIA NVM Pro-\\ngramming Model [ 46]) allows PMem implementations using\\nnatively persistent media (e.g., 3D XPoint) or natively volatile\\n(e.g., DRAM) devices with hardware support for persistence\\nin the event of power loss.\\nAdditional higher-level functions supported by the SNIA\\nmodel include: (a) PMem-aware file systems—e.g., ext4 with\\nthe DAX option—which provide naming, access control, and\\nthe ability to map persistent data into the virtual address\\nspace. (b) Library APIs that allow applications to discover\\nwhether store instructions are considered persistent as soon\\nas they are visible to other threads, or if flush operations are\\nrequired to guarantee that stores have been committed. (c)\\nSoftware mechanisms to detect failures unique to PMem, e.g.,\\nan incomplete flush on fail execution after a power failure.\\nA Brief timeline of PMem products. Battery-backed RAM\\nhas a long history of use for RAID stripe buffers [ 16], and\\nbefore that magnetic core memory was persistent across\\npower loss2[39]. However persistent memory as we know\\nit can be traced to shortly after 2000—both conceptual work\\nonstorage-class memory [11] and products in the form of\\nNVDIMM-N [49], DRAM DIMMs with energy storage and\\nflash backup that allow memory contents to last across power\\nloss. NVDIMMs used standard memory sockets, but required\\nplatform support for power-loss notification. They were\\nshipped by several companies for nearly a decade [ 49], but\\nbecause they were much more expensive than conventional\\nDRAM, they were rarely if ever deployed as entire storage\\nsystems.\\nLater in that decade, emerging technologies such as Phase\\nChange Memory [ 11] resulted in sustained research interest\\nin persistent memory, accelerated by Intel and Micron’s an-\\nnouncement of 3D XPoint memory and Intel’s Optane plans.\\nIn 2019, Intel began shipping Optane memory devices, us-\\ning the DDR-T variant of standard memory sockets. Optane\\nhad much higher capacity and lower cost per gigabyt', 'Persistent Memory Research in the Post-Optane Era.pdf'), 738: ('y were much more expensive than conventional\\nDRAM, they were rarely if ever deployed as entire storage\\nsystems.\\nLater in that decade, emerging technologies such as Phase\\nChange Memory [ 11] resulted in sustained research interest\\nin persistent memory, accelerated by Intel and Micron’s an-\\nnouncement of 3D XPoint memory and Intel’s Optane plans.\\nIn 2019, Intel began shipping Optane memory devices, us-\\ning the DDR-T variant of standard memory sockets. Optane\\nhad much higher capacity and lower cost per gigabyte than\\nNVDIMM-Ns, since it leveraged the native persistence of\\n3D XPoint. However, it had lower performance—around 3 ×\\nthe latency of DRAM, with bandwidth somewhat lower for\\nread and much lower for write [ 22]. Since Optane greatly\\n2Due to cost, this persistence was rarely used for anything except boot\\nloaders.\\n24\\nPersistent Memory Research in the Post-Optane Era DIMES ’23, October 23, 2023, Koblenz, Germany\\nPMem\\nUser KernelStandard\\nFile API\\nPMem driverApplication\\nFile System\\n    Application\\n Application\\nStandard\\nRaw Device\\nAccess\\nLoad /\\nStoreStandard\\nFile API\\nPMem-Aware\\nFile SystemMMU\\nMappings\\nDAX\\nPMem driver\\nBlock I/O\\nFigure 1: Block and PMem data paths. Direct access\\n(DAX, upper right) incurs no software overhead.\\noutperformed NAND Flash, its primary use case was as a\\npersistent write cache for very large data structures such as\\nin-memory databases. Due to its high capacity and (arguably)\\nlower cost per gigabyte, Optane was also considered as a\\npotential second tier of volatile memory, cached by DRAM.\\nMicron stopped production of 3D XPoint in 2021, and\\nin 2022 Intel discontinued their Optane product line. As\\nof this writing no other high-capacity PMem products are\\navailable commercially, and no future 3D XPoint products\\nare expected. The number of companies shipping NVDIMM-\\nNs has declined recently, although they are still available in\\ncapacities of around 16–32GB.\\nPMem benefits. Figure 1 illustrates the difference between\\nthe common Block I/O data path and the PMem data path. The\\nrightmost application in th', 'Persistent Memory Research in the Post-Optane Era.pdf'), 739: ('on stopped production of 3D XPoint in 2021, and\\nin 2022 Intel discontinued their Optane product line. As\\nof this writing no other high-capacity PMem products are\\navailable commercially, and no future 3D XPoint products\\nare expected. The number of companies shipping NVDIMM-\\nNs has declined recently, although they are still available in\\ncapacities of around 16–32GB.\\nPMem benefits. Figure 1 illustrates the difference between\\nthe common Block I/O data path and the PMem data path. The\\nrightmost application in the figure uses standard file APIs to\\nopen and memory-map a PMem file; all PMem I/O is then able\\nto use the standard load/store model. This is made possible\\nby the DAX (Direct Access) feature in specific file systems,\\nallowing mmap to directly map underlying address-space-\\nresident memory, along with hardware persistence support,\\ne.g., enabled by appropriate PMDK library operations.\\nThese accesses are far more efficient than access via the\\nblock I/O data path. In the PMem case individual instruc-\\ntions retrieve data from cache, while the memory controller\\nissues a single read to the memory device for each cache\\nline accessed. In contrast, block access typically requires\\nuser/kernel transitions for each access, multiple PCIe trans-\\nactions for data and descriptor transfers and doorbell register\\nwrites, and a significant in-kernel software path3.\\nThe performance difference is even larger for small ac-\\ncesses, as block I/Os are typically rounded up to a 4 KB block\\nsize, while PMem is accessed at cache-line granularity. Data\\nstructures can be mapped into application memory as shown\\n3User-space access through SPDK [ 54] can reduce the software overhead of\\nthis process, but the PCIe overhead remains.by the rightmost arrow in the figure, and then accessed di-\\nrectly, without needing to copy data into DRAM. This ability\\nto access persistent data in place is one of the major benefits\\nof PMem [44].\\nPMem challenges. Systems supporting PMem have two\\nlevels of store persistence, as per the SNIA Programming\\nmodel. The most com', 'Persistent Memory Research in the Post-Optane Era.pdf'), 740: ('rity. Data\\nstructures can be mapped into application memory as shown\\n3User-space access through SPDK [ 54] can reduce the software overhead of\\nthis process, but the PCIe overhead remains.by the rightmost arrow in the figure, and then accessed di-\\nrectly, without needing to copy data into DRAM. This ability\\nto access persistent data in place is one of the major benefits\\nof PMem [44].\\nPMem challenges. Systems supporting PMem have two\\nlevels of store persistence, as per the SNIA Programming\\nmodel. The most common level, avoiding the need for more\\nexpensive platform logic, requires applications to flush stores\\nexplicitly to ensure persistence. While storage has always\\nworked this way, programmers are not used to having to\\nflush memory stores; this introduces new software complex-\\nities. The problem is exacerbated by existing code that as-\\nsumes block writes are atomic, which allows atomic updates\\nof large data structures. Libraries like PMDK [ 44] normally\\nhandle some of the complex logic around flushing and trans-\\nactions, but significant work may be needed to adapt existing\\nsoftware [34].\\nThe second level of persistence is provided by platforms\\nthat automatically flush all CPU caches to PMem on power\\nloss or system crash. This relieves the software from that\\nresponsibility. But since this feature is not guaranteed to exist\\non every platform with PMem, the software must typically\\nhandle both cases, so no complexity is avoided.\\nThe lack of native language support for PMem is also\\nproblematic, requiring libraries to use non-idiomatic con-\\nstructs like preprocessor macros to support PMem, adding\\nto debugging complexity. Although it is possible that id-\\niomatic, usable PMem extensions to high-level languages\\nwill emerge in the future, such improvements typically ar-\\nrive only slowly. The fact that software must be modified to\\nuse PMem at all is itself a problem, since software changes\\nare expensive. To mitigate this, a number of ways to leverage\\nPMem transparently have emerged. Ideas such as Whole\\nSystem Persistence [ 3', 'Persistent Memory Research in the Post-Optane Era.pdf'), 741: (' use non-idiomatic con-\\nstructs like preprocessor macros to support PMem, adding\\nto debugging complexity. Although it is possible that id-\\niomatic, usable PMem extensions to high-level languages\\nwill emerge in the future, such improvements typically ar-\\nrive only slowly. The fact that software must be modified to\\nuse PMem at all is itself a problem, since software changes\\nare expensive. To mitigate this, a number of ways to leverage\\nPMem transparently have emerged. Ideas such as Whole\\nSystem Persistence [ 38] and Whole Process Persistence [ 17]\\ncan leverage the benefits of PMem’s in-place access without\\napplication modification. In many cases language support for\\ntransparent use of PMem may be difficult—existing code of-\\nten assumes that data structures are assembled in ephemeral\\nbuffers, never visible outside a limited range of code; the lack\\nof buffering in PMem accesses may necessitate significant\\nchanges in strategy.\\nFinally, a consistent pain point for PMem has been that\\nit isdirectly attached to a single host; if the host goes down,\\naccess to that persistent data is lost. This differs from other\\nstorage systems that can be attached on the network and\\nmade accessible from multiple hosts ( e.g., NAS, SAN). Several\\nsolutions to replicate PMem in software have been imple-\\nmented [13, 14, 52], but they increase complexity further.\\n25\\nDIMES ’23, October 23, 2023, Koblenz, Germany P. Desnoyers et al.\\n3 CXL: A NEW PMEM INTERFACE\\nCPU changes were needed to efficiently support new PMem\\nproducts. Modifications to the DDR protocol supported\\nvariable timing [ 1] and power-loss notification. For perfor-\\nmance [ 7,9], new instructions and memory controller de-\\nsigns [43] were needed to quickly and reliably persist data.\\nIn 2019, the first version of the Compute Express Link (CXL)\\nspecification was released by a consortium of over 250 com-\\npanies. As of November 2020, version 2.0 of the CXL speci-\\nfication contains first-class support for PMem, rather than\\nadding it as an afterthought as was done for DDR protocols.\\nCXL 1.1', 'Persistent Memory Research in the Post-Optane Era.pdf'), 742: ('e DDR protocol supported\\nvariable timing [ 1] and power-loss notification. For perfor-\\nmance [ 7,9], new instructions and memory controller de-\\nsigns [43] were needed to quickly and reliably persist data.\\nIn 2019, the first version of the Compute Express Link (CXL)\\nspecification was released by a consortium of over 250 com-\\npanies. As of November 2020, version 2.0 of the CXL speci-\\nfication contains first-class support for PMem, rather than\\nadding it as an afterthought as was done for DDR protocols.\\nCXL 1.1 and 2.0 run over PCIe 5, while CXL 3.0 uses PCIe\\n6, introducing three new protocols:\\n•CXL.io: PCIe functionality, including device enumer-\\nation and PCIe-style data transfers.\\n•CXL.cache: allows device caches as part of the CPU\\ncache-coherency domain.\\n•CXL.mem: allows hosts to access device-attached\\nmemory with cache-coherent loads and stores.\\nA CXL Type 3 Memory Device, built using the CXL.io and\\nCXL.mem protocols, allows OSes to have a single, generic\\ndriver supporting both volatile memory and PMem, even\\non the same device [ 8,24]. Moreover, while previous PMem\\ndevices required explicit CPU support, CXL allows indepen-\\ndent vendors and even researchers to build a wide variety of\\nPMem devices. CXL incorporates the lessons learned from\\nprior PMem products, and in many cases allows binary com-\\npatibility for applications developed for NVDIMM [ 49] and\\nOptane devices.\\nWith CXL, memory pooling, supported by the Multi-\\nHeaded Device (MHD) model in CXL 3.0, allows multiple\\nhosts to access memory presented by a single device. This\\nprovides the ability to disaggregate both volatile and persis-\\ntent memory, and to dynamically assign it to different hosts\\nover time [ 30], as shown in Figure 2, providing a separate\\n“memory appliance” with its own power, failure domain, and\\nreliability characteristics. As an example, Pond [ 30] uses a\\ncustom controller to provide single-host cache coherence,\\ncoupled with dynamic access control assigning each memory\\nregion to a single host at a time.\\nSuch memory pooling offers an opportun', 'Persistent Memory Research in the Post-Optane Era.pdf'), 743: ('ngle device. This\\nprovides the ability to disaggregate both volatile and persis-\\ntent memory, and to dynamically assign it to different hosts\\nover time [ 30], as shown in Figure 2, providing a separate\\n“memory appliance” with its own power, failure domain, and\\nreliability characteristics. As an example, Pond [ 30] uses a\\ncustom controller to provide single-host cache coherence,\\ncoupled with dynamic access control assigning each memory\\nregion to a single host at a time.\\nSuch memory pooling offers an opportunity for appli-\\ncation-transparent data replication across failure-domain\\nboundaries. This in turn addresses a key limitation of prior\\nPMem configurations, where such replication required ex-\\nplicit application support, typically requiring slower soft-\\nware intervention rather than being implemented in hard-\\nware.\\nPond and similar approaches allow non-concurrent shar-\\ning of memory where, for example, a new host may take\\nMemory Media\\nHost 0\\nDisaggregated\\nMemory PoolHost N\\n… CXL CXL\\nMemory Media\\nHost 0\\nDisaggregated\\nMemory PoolHost N\\n… CXL CXL\\nFigure 2: Basic CXL memory pooling.\\nownership of a memory region after a crash; additional fea-\\ntures allow concurrent sharing of memory regions by multi-\\nple hosts, with either non-coherent access (requiring explicit\\nflush operations) or optionally with full cache coherency\\nacross hosts.\\nMemory pooling and sharing also introduce new security\\nconcerns. The CXL specification supports low-level encryp-\\ntion for memory and interconnect links [ 8, Section 11.0];\\nfurther research is needed in this area.\\n4 RESEARCH GOING FORWARD\\nAlthough other persistent memory technologies predated\\nit, 3D XPoint was perhaps the first solid-state technology\\nto offer both cost and performance midway between con-\\ntemporary main memory and block storage technologies—\\nthe cheaper-than-DRAM, faster-than-NAND flash window.\\nSince this “storage-class memory” window is a moving target,\\nthe emergence of a new and competitive persistent-memory\\ntechnology is heavily dependent on progress at both ends\\nof this', 'Persistent Memory Research in the Post-Optane Era.pdf'), 744: ('rch is needed in this area.\\n4 RESEARCH GOING FORWARD\\nAlthough other persistent memory technologies predated\\nit, 3D XPoint was perhaps the first solid-state technology\\nto offer both cost and performance midway between con-\\ntemporary main memory and block storage technologies—\\nthe cheaper-than-DRAM, faster-than-NAND flash window.\\nSince this “storage-class memory” window is a moving target,\\nthe emergence of a new and competitive persistent-memory\\ntechnology is heavily dependent on progress at both ends\\nof this window—progress driven by enormous investments\\nbased on the size of these markets.\\nAs a result, it is entirely possible that we will not see a\\nsolid-state memory technology arise that directly replaces 3D\\nXPoint. Yet we argue that in the CXL era, persistent-memory\\nresearch remains just as relevant, for two reasons:\\n•Hybrid persistent memory [ 41]. Even in the absence of\\nnew technologies, hybrid strategies combining DRAM,\\nflash, and energy storage will enable future CXL-\\nattached persistent-memory systems at varying price\\nand performance points.\\n•Multi-host consistency. PMem raised the new (at\\nthe time) problem of crash consistency for memory;\\nin previous systems memory contents were lost on\\npower failure, and the CPU could never observe crash-\\ninconsistent memory states. CXL memory pooling al-\\nlows memory to be observed from multiple indepen-\\ndent failure domains, leading to similar challenges\\n26\\nPersistent Memory Research in the Post-Optane Era DIMES ’23, October 23, 2023, Koblenz, Germany\\n#Example Storage / Memory Technologies Coherent Byte-addressable Persistent\\n1Volatile RAM disk ✘ ✘ ✘\\n2Conventional HDD, SSD ✘ ✘ ✔\\n3Incoherent load/store to PCIe address space ✘ ✔ ✘\\n4Byte-addressable I/O device (e.g., object storage) ✘ ✔ ✔\\n5Memory pooling ✔ ✔ ✘\\n6Conventional PMem use cases, including NVDIMM ✔ ✔ ✔\\nTable 1: A taxonomy of storage technologies that may support coherency, byte-addressability, and persistence.\\neven in the absence of persistence, while doing so un-\\nder a range of topologies and speeds.\\nChanges brou', 'Persistent Memory Research in the Post-Optane Era.pdf'), 745: ('/ Memory Technologies Coherent Byte-addressable Persistent\\n1Volatile RAM disk ✘ ✘ ✘\\n2Conventional HDD, SSD ✘ ✘ ✔\\n3Incoherent load/store to PCIe address space ✘ ✔ ✘\\n4Byte-addressable I/O device (e.g., object storage) ✘ ✔ ✔\\n5Memory pooling ✔ ✔ ✘\\n6Conventional PMem use cases, including NVDIMM ✔ ✔ ✔\\nTable 1: A taxonomy of storage technologies that may support coherency, byte-addressability, and persistence.\\neven in the absence of persistence, while doing so un-\\nder a range of topologies and speeds.\\nChanges brought about by CXL. Historically (i.e., before\\nPMem) memory researchers have not had to worry about\\nissues like data persistence, durability, and availability; these\\nwere issues specific to storage systems. PMem changed this\\nand opened up a decade’s worth of research. A key resulting\\nartifact is PMDK [ 21]—a suite of libraries providing a single\\nconsistency model across a range of hardware persistence\\nfeatures. Storage researchers working at the device or block\\nlevel watched with interest as memory researchers tackled\\nkey storage issues like transactions and atomic writes.\\nLooking up from the block layer, PMem changed very\\nlittle. Researchers quickly dealt with the low-hanging fruit\\n(e.g., block-mode abstractions to PMem [ 4]). Otherwise, there\\nwere few opportunities at the storage (i.e., block) layer.\\nBut CXL will change this in two ways: (1) by bringing\\nmemory abstractions to a standardized I/O interconnect, and\\n(2) by making persistence optional (as discussed earlier, CXL\\nworks with both volatile and non-volatile memory). This\\nmeans that memory and storage researchers will need to\\ncoordinate, especially if the goal is an optimized solution\\nthat spans all hardware and software layers.\\nFor example, although a CXL device could be exposed\\nas a hybrid device with a completely separate memory API\\n(CXL.mem and/or CXL.cache) and storage API (CXL.io), de-\\nsigning such a solution is a missed opportunity. Rather, the\\nmemory “half” of a device should leverage the storage half\\nfor bulk data, and the storage half should lev', 'Persistent Memory Research in the Post-Optane Era.pdf'), 746: ('atile memory). This\\nmeans that memory and storage researchers will need to\\ncoordinate, especially if the goal is an optimized solution\\nthat spans all hardware and software layers.\\nFor example, although a CXL device could be exposed\\nas a hybrid device with a completely separate memory API\\n(CXL.mem and/or CXL.cache) and storage API (CXL.io), de-\\nsigning such a solution is a missed opportunity. Rather, the\\nmemory “half” of a device should leverage the storage half\\nfor bulk data, and the storage half should leverage the mem-\\nory half for coherence and byte addressability. One example\\nis a computational SSD that modifies data in host memory,\\nwithout resorting to bulk DMA operations. Alternatively,\\nconsider a GPU or an FPGA using CXL.cache to gain coher-\\nent access to host memory. If that same data is destined for\\nblock storage, we do not want to send it to the PCI layer a\\nsecond time; the data may already be partially present in the\\ndevice, just in a memory form. Hence, CXL introduces the\\nneed for the memory and storage halves to coordinate, and\\ntherein lies the potential for new research.New research opportunities. We introduce new opportuni-\\nties brought about by CXL across three dimensions: persis-\\ntence, byte addressability, and coherence. We consider six\\nof the eight possible combinations: three map to existing\\nmemory or storage technologies and three are entirely new,\\nrepresenting research opportunities going forward.\\nFor the taxonomy in Table 1, we define persistent as being\\nable to survive a cold reboot or loss of power, coherent4to\\nmean that read operations (across CPUs or hosts as appro-\\npriate) will transparently see the result of write operations\\nfrom other CPUs or hosts, and byte-addressable as allow-\\ning accesses smaller than a single sector (512 bytes). It is\\nworth noting that byte addressability does not require a co-\\nherent memory interface. Indeed, object storage protocols\\nalready allow for byte-granular access [ 35] on the PCIe bus\\nusing versions of standard I/O commands; we therefore treat\\ncoherenc', 'Persistent Memory Research in the Post-Optane Era.pdf'), 747: ('oss of power, coherent4to\\nmean that read operations (across CPUs or hosts as appro-\\npriate) will transparently see the result of write operations\\nfrom other CPUs or hosts, and byte-addressable as allow-\\ning accesses smaller than a single sector (512 bytes). It is\\nworth noting that byte addressability does not require a co-\\nherent memory interface. Indeed, object storage protocols\\nalready allow for byte-granular access [ 35] on the PCIe bus\\nusing versions of standard I/O commands; we therefore treat\\ncoherency and byte-addressability independently.\\nA number of rows represent conventional storage tech-\\nnologies. Rows 1 and 2 represent RAM disks and conven-\\ntional block devices such as NVMe drives. Access is at a\\nblock granularity, and cached data (i.e., kernel buffer caches)\\nis managed “manually”. Row 6, in turn, corresponds to ex-\\nisting PMem architectures, combining persistence, cache\\ncoherency, and byte addressability.\\nOther combinations are less common. In row 3, read and\\nwrite operations can be performed at byte granularity, but\\nwithout coherence or persistence. PCIe address space pro-\\nvides these semantics, with operations performed via load\\nand store instructions. Although the NVMe specification\\ndefines an optional PCIe address space allowing such di-\\nrect access, it is not supported by any commonly available\\ndevices. Alternatively, InfiniBand RDMA verbs provide an\\nI/O-operation-based mechanism that is byte-addressable but\\noffers noncoherent access to (remote) volatile memory.\\nIn row 4, byte addressability and persistence are combined\\nwith non-coherent access, e.g., via I/O commands rather than\\n4We note that coherence in the non-byte-addressable model is not novel, as\\nit is the traditional access model for block devices.\\n27\\nDIMES ’23, October 23, 2023, Koblenz, Germany P. Desnoyers et al.\\nCPU load/store operations. This model is used by object stor-\\nage devices that provide byte-aligned read and write opera-\\ntions, although it could also be applied to flat address spaces.\\nAt present there are no commercially ', 'Persistent Memory Research in the Post-Optane Era.pdf'), 748: ('and persistence are combined\\nwith non-coherent access, e.g., via I/O commands rather than\\n4We note that coherence in the non-byte-addressable model is not novel, as\\nit is the traditional access model for block devices.\\n27\\nDIMES ’23, October 23, 2023, Koblenz, Germany P. Desnoyers et al.\\nCPU load/store operations. This model is used by object stor-\\nage devices that provide byte-aligned read and write opera-\\ntions, although it could also be applied to flat address spaces.\\nAt present there are no commercially available modern object\\nstorage devices; the flat-address-space model corresponds to\\nRDMA access to remote persistent memory.\\nCombinations with cache-coherent access at block granu-\\nlarity seem either impossible or impractical, and are omitted\\nfrom Table 1.\\nFinally, row 5—cache-coherent byte-addressable access to\\nvolatile storage—corresponds to CXL memory pooling with\\nvolatile RAM.\\nResearch questions. In a post-Optane landscape with\\nCXL attached volatile and non-volatile devices, we see a\\nrange of problems which remain to be addressed.\\nLatency and memory access: Optane memory is no\\nslower than cross-NUMA-node access to DRAM, while poten-\\ntial future technologies may have significantly higher worst-\\ncase latency. At what point are architectural changes in the\\nCPU or memory controller needed to address non-uniform\\naccess times? Is there a point where software-controlled\\naccess commands become more efficient than handling op-\\nerations with wildly different latencies within the hardware\\npipeline?\\nPerformance factors: Optane memory provides both\\nbyte addressability and low latency— 10×less than the fastest\\n(Optane) NVMe devices, and 100× less than typical ones.\\nOptane-based applications and systems have been shown\\nto provide significantly higher performance than NVMe-\\nbased ones, but how much of this improvement is due to\\nbyte addressability, and how much due to performance? Fu-\\nture PMem technologies may be slower than Optane, and\\nthe answer to this question is important for assessing their\\npotential.\\nMemory poolin', 'Persistent Memory Research in the Post-Optane Era.pdf'), 749: ('ors: Optane memory provides both\\nbyte addressability and low latency— 10×less than the fastest\\n(Optane) NVMe devices, and 100× less than typical ones.\\nOptane-based applications and systems have been shown\\nto provide significantly higher performance than NVMe-\\nbased ones, but how much of this improvement is due to\\nbyte addressability, and how much due to performance? Fu-\\nture PMem technologies may be slower than Optane, and\\nthe answer to this question is important for assessing their\\npotential.\\nMemory pooling and crash consistency: Will the ap-\\nproaches used to provide crash consistency with a single\\nhost attached to a single persistent memory be appropriate\\nfor multiple attached hosts across multiple failure domains?\\nApplication intent: Operating systems go to great\\nlengths to infer application intent, allowing, e.g., I/O prefetch-\\ning and migration of data to lower-performance memory\\ntiers. This is more difficult with PMem, where accesses are\\nperformed by hardware rather than software, and may be\\nespecially important for hybrid PMem systems.\\nByte-granular I/O devices: High-performance PMem-\\nbased systems often achieve some of their gains by perform-\\ning small atomic updates to stored data structures, e.g., by\\natomically swapping pointers [ 51]. Extensions to the NVMe\\nprotocol might allow such accesses to be performed on ex-\\nternal storage, without coherent load/store access from the\\nCPU. Is direct load/store access even necessary to achievethe benefits of byte-granular access, or can I/O protocols\\nevolve to incorporate this model?\\nCollectively, these CXL-enabled opportunities motivate\\nmore distributed storage systems research, including job de-\\ncomposition, scheduling, safely sharing data, and program-\\nming and managing storage devices that speak both byte and\\nblock protocols. It remains to be seen whether this takes the\\nform of computational memory, computational storage, or\\nsome hybrid. Indeed, CXL will blur the lines between mem-\\nory and storage, allowing us to rethink and expand the role\\nof a “device.” Devic', 'Persistent Memory Research in the Post-Optane Era.pdf'), 750: ('corporate this model?\\nCollectively, these CXL-enabled opportunities motivate\\nmore distributed storage systems research, including job de-\\ncomposition, scheduling, safely sharing data, and program-\\nming and managing storage devices that speak both byte and\\nblock protocols. It remains to be seen whether this takes the\\nform of computational memory, computational storage, or\\nsome hybrid. Indeed, CXL will blur the lines between mem-\\nory and storage, allowing us to rethink and expand the role\\nof a “device.” Devices will become computing peers, bringing\\na wide and exciting array of possibilities.\\n5 CONCLUSION\\nWe posit that the current lack of commercial PMem avail-\\nability does not detract from its importance and promise\\nas a core storage technology, both in academia and indus-\\ntry. The Compute Express Link (CXL) interconnect carries\\nforward the lessons from previous PMem implementations\\nand lowers the barrier for developing new PMem products.\\nThe wide adoption of the CXL standard allays vendor lock-in\\nconcerns, and is a core reason that we believe PMem is worth\\ncontinued research effort. In particular, CXL enables one to\\nconsider each PMem attribute separately or in combination:\\nbyte addressability, persistence, and direct access via CPU\\nload/store instructions. Finally, new CXL features such as\\nmemory pooling and sharing are seeing considerable interest\\nas rich areas for future PMem research and development.\\nACKNOWLEDGMENTS\\nWe thank Andrew Rudoff for his extensive contributions\\nto this work. We thank the anonymous reviewers for their\\nconstructive feedback. This work was made possible in part\\nthanks to Dell-EMC, NetApp, Facebook, and IBM support; a\\nSUNY/IBM Alliance award; and NSF awards CNS-1910327,\\nCCF-1918225, CNS-1900706, CNS-1951880, CNS-2106263,\\nCNS-2106434, and CNS-2214980.\\nREFERENCES\\n[1]JEDEC Solid State Technology Association. 2021. JEDEC Publishes\\nDDR4 NVDIMM-P Bus Protocol Standard.\\n[2]Lawrence Benson, Marcel Weisgut, and Tilmann Rabl. 2023. What\\nWe Can Learn from Persistent Memory for CXL. In 20th Conferenc', 'Persistent Memory Research in the Post-Optane Era.pdf'), 751: ('eviewers for their\\nconstructive feedback. This work was made possible in part\\nthanks to Dell-EMC, NetApp, Facebook, and IBM support; a\\nSUNY/IBM Alliance award; and NSF awards CNS-1910327,\\nCCF-1918225, CNS-1900706, CNS-1951880, CNS-2106263,\\nCNS-2106434, and CNS-2214980.\\nREFERENCES\\n[1]JEDEC Solid State Technology Association. 2021. JEDEC Publishes\\nDDR4 NVDIMM-P Bus Protocol Standard.\\n[2]Lawrence Benson, Marcel Weisgut, and Tilmann Rabl. 2023. What\\nWe Can Learn from Persistent Memory for CXL. In 20th Conference\\non Database Systems for Business, Technology and Web (BTW), Bir-\\ngitta König-Ries, Stefanie Scherzinger, Wolfgang Lehner, and Gottfried\\nVossen (Eds.). Gesellschaft für Informatik e.V., Dresden, Germany, 535–\\n554. https://doi.org/10.18420/BTW2023-48\\n[3]Miao Cai and Hao Huang. 2021. A survey of operating system support\\nfor persistent memory. Frontiers of Computer Science 15 (2021), 154207.\\n[4]Feng Chen, Michael Mesnier, and Scott Hahn. 2014. A Protected Block\\nDevice for Persistent Memory. In Proceedings of the 30th Symposium\\non Mass Storage Systems and Technologies (MSST). IEEE, Santa Clara,\\nCA, 1–12.\\n28\\nPersistent Memory Research in the Post-Optane Era DIMES ’23, October 23, 2023, Koblenz, Germany\\n[5]Youmin Chen, Youyou Lu, Fan Yang, Qing Wang, Yang Wang, and\\nJiwu Shu. 2020. FlatStore: An Efficient Log-Structured Key-Value\\nStorage Engine for Persistent Memory. In Proceedings of the Twenty-\\nFifth International Conference on Architectural Support for Programming\\nLanguages and Operating Systems. ACM, Lausanne, Switzerland, 1077–\\n1091.\\n[6]Zhaole Chu, Yongping Luo, and Peiquan Jin. 2021. An Efficient Sorting\\nAlgorithm for Non-Volatile Memory. Int. J. Softw. Eng. Knowl. Eng. 31\\n(2021), 1603–1621.\\n[7]Joel Coburn, Adrian M. Caulfield, Ameen Akel, Laura M. Grupp, Ra-\\njesh K. Gupta, Ranjit Jhala, and Steven Swanson. 2011. NV-Heaps:\\nMaking Persistent Objects Fast and Safe with Next-Generation, Non-\\nVolatile Memories. In Proceedings of the Sixteenth International Confer-\\nence on Architectural Support for Programming Langu', 'Persistent Memory Research in the Post-Optane Era.pdf'), 752: ('Switzerland, 1077–\\n1091.\\n[6]Zhaole Chu, Yongping Luo, and Peiquan Jin. 2021. An Efficient Sorting\\nAlgorithm for Non-Volatile Memory. Int. J. Softw. Eng. Knowl. Eng. 31\\n(2021), 1603–1621.\\n[7]Joel Coburn, Adrian M. Caulfield, Ameen Akel, Laura M. Grupp, Ra-\\njesh K. Gupta, Ranjit Jhala, and Steven Swanson. 2011. NV-Heaps:\\nMaking Persistent Objects Fast and Safe with Next-Generation, Non-\\nVolatile Memories. In Proceedings of the Sixteenth International Confer-\\nence on Architectural Support for Programming Languages and Operat-\\ning Systems (ASPLOS). ACM, Newport Beach, CA, 105–118.\\n[8]Compute Express Link. 2022. Compute Express Link (CXL) Specifica-\\ntion. Available from http://www.computeexpresslink.org .\\n[9]Jeremy Condit, Edmund B. Nightingale, Christopher Frost, Engin Ipek,\\nBenjamin Lee, Doug Burger, and Derrick Coetzee. 2009. Better I/O\\nthrough Byte-Addressable, Persistent Memory. In Proceedings of the\\nACM SIGOPS 22nd Symposium on Operating Systems Principles. ACM,\\nBig Sky, Montana, USA, 133–146. https://doi.org/10.1145/1629575.\\n1629589\\n[10] Laxman Dhulipala, Charles McGuffey, Hong Kyu Kang, Yan Gu, Guy E.\\nBlelloch, Phillip B. Gibbons, and Julian Shun. 2019. Sage: Parallel\\nSemi-Asymmetric Graph Algorithms for NVRAMs. Proc. VLDB Endow.\\n13 (2019), 1598–1613.\\n[11] R. F. Freitas and W. W. Wilcke. 2008. Storage-Class Memory: The Next\\nStorage System Technology. IBM Journal of Research and Development\\n52, 4/5 (July 2008), 439–447. https://doi.org/10.1147/rd.524.0439\\n[12] G. Gill, Roshan Dathathri, Loc Hoang, Ramesh V. Peri, and Keshav\\nPingali. 2019. Single Machine Graph Analytics on Massive Datasets\\nusing Intel Optane DC Persistent Memory. Proceedings of the VLDB\\nEndowment 13 (2019), 1304 – 1318.\\n[13] Tomasz Gromadzki and Jan Marian Michalski. 2019. Persistent\\nMemory Replication Over Traditional RDMA Part 4: Persistent\\nMemory Development Kit (PMDK)-Based PMEM Replication.\\nhttps://www.intel.com/content/www/us/en/developer/articles/\\ntechnical/persistent-memory-replication-over-traditional-\\nrdma-part-4-persistent-memory-deve', 'Persistent Memory Research in the Post-Optane Era.pdf'), 753: ('eri, and Keshav\\nPingali. 2019. Single Machine Graph Analytics on Massive Datasets\\nusing Intel Optane DC Persistent Memory. Proceedings of the VLDB\\nEndowment 13 (2019), 1304 – 1318.\\n[13] Tomasz Gromadzki and Jan Marian Michalski. 2019. Persistent\\nMemory Replication Over Traditional RDMA Part 4: Persistent\\nMemory Development Kit (PMDK)-Based PMEM Replication.\\nhttps://www.intel.com/content/www/us/en/developer/articles/\\ntechnical/persistent-memory-replication-over-traditional-\\nrdma-part-4-persistent-memory-development.html .\\n[14] Shashank Gugnani, Scott Guthridge, Frank Schmuck, Owen Anderson,\\nDeepavali Bhagwat, and Xiaoyi Lu. 2022. Arcadia: A Fast and Reliable\\nPersistent Memory Replicated Log. arXiv:cs.DC/2206.12495\\n[15] Jim Handy and Tom Coughlin. 2023. Optane’s Dead: Now What?\\nComputer 56, 3 (2023), 125–130. https://doi.org/10.1109/MC.2023.\\n3235096\\n[16] Dave Hitz, James Lau, and Michael Malcolm. 1994. File System Design\\nfor an NFS File Server Appliance. In Proceedings of the USENIX Winter\\n1994 Technical Conference (ATC). USENIX Association, San Francisco,\\nCalifornia, 19–19.\\n[17] George Hodgkins, Yi Xu, Steven Swanson, and Joseph Izraele-\\nvitz. 2023. Zhuque: Failure Isn’t an Option, It’s an Excep-\\ntion. http://nvmw.ucsd.edu/nvmw2023-program/nvmw2023-\\npaper16-presentation_slides.pdf 14th Non-Volatile Memories Work-\\nshop.\\n[18] Deukyeon Hwang, Wook-Hee Kim, Youjip Won, and Beomseok Nam.\\n2018. Endurable Transient Inconsistency in Byte-Addressable Persis-\\ntent B+-Tree. In USENIX Conference on File and Storage Technologies.\\nUSENIX Association, Oakland, CA, 187–200.\\n[19] Intel Corporation. 2022. Intel Optane persistent memory\\nand Intel®Xeon®scalable processors offer a practical migra-\\ntion path to memory expansion, tiering, and pooling withCompute Express Link (CXLTM)-attached memory devices.\\nhttps://www.intel.com/content/dam/www/central-libraries/\\nus/en/documents/2022-11/optane-pmem-to-cxl-tech-brief.pdf\\n[20] Intel Corporation. 2022. Intel Reports Second-Quarter 2022 Financial\\nResults. https://www.intc.com/news-events/pr', 'Persistent Memory Research in the Post-Optane Era.pdf'), 754: ('gies.\\nUSENIX Association, Oakland, CA, 187–200.\\n[19] Intel Corporation. 2022. Intel Optane persistent memory\\nand Intel®Xeon®scalable processors offer a practical migra-\\ntion path to memory expansion, tiering, and pooling withCompute Express Link (CXLTM)-attached memory devices.\\nhttps://www.intel.com/content/dam/www/central-libraries/\\nus/en/documents/2022-11/optane-pmem-to-cxl-tech-brief.pdf\\n[20] Intel Corporation. 2022. Intel Reports Second-Quarter 2022 Financial\\nResults. https://www.intc.com/news-events/press-releases/detail/\\n1563/intel-reports-second-quarter-2022-financial-results .\\n[21] Intel Corporation. 2023. Persistent Memory Development Kit (PMDK).\\npmem.io .\\n[22] Joseph Izraelevitz, Jian Yang, Lu Zhang, Juno Kim, Xiao Liu, Amir-\\nsaman Memaripour, Yun Joon Soh, Zixuan Wang, Yi Xu, Subramanya R.\\nDulloor, Jishen Zhao, and Steven Swanson. 2019. Basic Performance\\nMeasurements of the Intel Optane DC Persistent Memory Module.\\nhttps://doi.org/10.48550/ARXIV.1903.05714\\n[23] Jungi Jeong and Changhee Jung. 2021. PMEM-Spec: Persistent Memory\\nSpeculation (Strict Persistency Can Trump Relaxed Persistency). In\\nProceedings of the 26th ACM International Conference on Architectural\\nSupport for Programming Languages and Operating Systems (ASPLOS).\\nACM, virtual, 517–529.\\n[24] Myoungsoo Jung. 2022. Hello Bytes, Bye Blocks: PCIe Storage Meets\\nCompute Express Link for Memory Expansion (CXL-SSD). In Proceed-\\nings of the 14th ACM Workshop on Hot Topics in Storage and File Systems\\n(HotStorage). ACM, Virtual Event, 45–51. https://doi.org/10.1145/\\n3538643.3539745\\n[25] Rohan Kadekodi, Se Kwon Lee, Sanidhya Kashyap, Taesoo Kim,\\nAasheesh Kolli, and Vijay Chidambaram. 2019. SplitFS: Reducing\\nSoftware Overhead in File Systems for Persistent Memory. In Pro-\\nceedings of the 27th ACM Symposium on Operating Systems Principles\\n(SOSP). ACM, Huntsville, Ontario, Canada, 494–508.\\n[26] Olzhas Kaiyrakhmet, Song Yeon Lee, Beomseok Nam, Sam H. Noh, and\\nYoung ri Choi. 2019. SLM-DB: Single-Level Key-Value Store with Per-\\nsistent Memory. In USENIX Confe', 'Persistent Memory Research in the Post-Optane Era.pdf'), 755: ('doi.org/10.1145/\\n3538643.3539745\\n[25] Rohan Kadekodi, Se Kwon Lee, Sanidhya Kashyap, Taesoo Kim,\\nAasheesh Kolli, and Vijay Chidambaram. 2019. SplitFS: Reducing\\nSoftware Overhead in File Systems for Persistent Memory. In Pro-\\nceedings of the 27th ACM Symposium on Operating Systems Principles\\n(SOSP). ACM, Huntsville, Ontario, Canada, 494–508.\\n[26] Olzhas Kaiyrakhmet, Song Yeon Lee, Beomseok Nam, Sam H. Noh, and\\nYoung ri Choi. 2019. SLM-DB: Single-Level Key-Value Store with Per-\\nsistent Memory. In USENIX Conference on File and Storage Technologies.\\nUSENIX Association, Boston, MA, 191–205.\\n[27] Rajat Kateja, Andrew Pavlo, and Greg Ganger. 2020. Vilamb: Low Over-\\nhead Asynchronous Redundancy for Direct Access NVM. , 17 pages.\\nhttps://arxiv.org/abs/2004.09619\\n[28] Se Kwon Lee, Jayashree Mohan, Sanidhya Kashyap, Taesoo Kim, and\\nVijay Chidambaram. 2019. RECIPE: Converting Concurrent DRAM\\nIndexes to Persistent-Memory Indexes. In Proceedings of the 27th ACM\\nSymposium on Operating Systems Principles (SOSP). ACM, Huntsville,\\nOntario, Canada, 462–477.\\n[29] Lucas Lersch, Xiangpeng Hao, Ismail Oukid, Tianzheng Wang, and\\nThomas Willhalm. 2019. Evaluating Persistent Memory Range Indexes.\\nProc. VLDB Endow. 13 (2019), 574–587.\\n[30] Huaicheng Li, Daniel S. Berger, Stanko Novakovic, Lisa R. Hsu, Dan\\nErnst, Pantea Zardoshti, Monish Shah, Samir Rajadnya, Scott Lee,\\nIshwar Agarwal, Mark D. Hill, Marcus Fontoura, and Ricardo Bianchini.\\n2022. Pond: CXL-Based Memory Pooling Systems for Cloud Platforms.\\nInProceedings of the 28th ACM International Conference on Architectural\\nSupport for Programming Languages and Operating Systems (ASPLOS),\\nVol. 2. ACM, Lausanne, Switzerland, 574–587.\\n[31] Jen-Kuang Liu and Sheng-De Wang. 2022. CFFS: A Persistent Mem-\\nory File System for Contiguous File Allocation With Fine-Grained\\nMetadata. IEEE Access 10 (2022), 91678–91698.\\n[32] Qingrui Liu, Joseph Izraelevitz, Se Kwon Lee, Michael L. Scott, Sam H.\\nNoh, and Changhee Jung. 2018. iDO: Compiler-Directed Failure Atom-\\nicity for Nonvolatile Memory. In 51st Annu', 'Persistent Memory Research in the Post-Optane Era.pdf'), 756: ('national Conference on Architectural\\nSupport for Programming Languages and Operating Systems (ASPLOS),\\nVol. 2. ACM, Lausanne, Switzerland, 574–587.\\n[31] Jen-Kuang Liu and Sheng-De Wang. 2022. CFFS: A Persistent Mem-\\nory File System for Contiguous File Allocation With Fine-Grained\\nMetadata. IEEE Access 10 (2022), 91678–91698.\\n[32] Qingrui Liu, Joseph Izraelevitz, Se Kwon Lee, Michael L. Scott, Sam H.\\nNoh, and Changhee Jung. 2018. iDO: Compiler-Directed Failure Atom-\\nicity for Nonvolatile Memory. In 51st Annual IEEE/ACM International\\nSymposium on Microarchitecture (MICRO). IEEE, Fukuoka, Japan, 258–\\n270.\\n[33] Sara Mahdizadeh-Shahri, Seyed Armin Vakil-Ghahani, and Aasheesh\\nKolli. 2020. (Almost) Fence-less Persist Ordering. In 53rd Annual\\nIEEE/ACM International Symposium on Microarchitecture (MICRO) .\\nACM, Virtual, 539–554.\\n29\\nDIMES ’23, October 23, 2023, Koblenz, Germany P. Desnoyers et al.\\n[34] Virendra J. Marathe, Margo Seltzer, Steve Byan, and Tim Harris. 2017.\\nPersistent Memcached: Bringing Legacy Code to Byte-Addressable\\nPersistent Memory. In 9th USENIX Workshop on Hot Topics in Storage\\nand File Systems (HotStorage 17). USENIX Association, Santa Clara,\\nCA. https://www.usenix.org/conference/hotstorage17/program/\\npresentation/marathe\\n[35] Michael P. Mesnier, Gregory R. Ganger, and Erik Riedel. 2003. Object-\\nbased Storage. IEEE Communications 44, 8 (August 2003), 84–90.\\n[36] Micron. 2021. Micron Updates Data Center Portfolio Strategy to\\nAddress Growing Opportunity for Memory and Storage Hierarchy\\nInnovation. https://investors.micron.com/news-releases/news-\\nrelease-details/micron-updates-data-center-portfolio-strategy-\\naddress-growing\\n[37] Moohyeon Nam, Hokeun Cha, Young ri Choi, Sam H. Noh, and\\nBeomseok Nam. 2019. Write-Optimized Dynamic Hashing for Persis-\\ntent Memory. In USENIX Conference on File and Storage Technologies.\\nUSENIX Association, Boston, MA, 31–44.\\n[38] Dushyanth Narayanan and Orion Hodson. 2012. Whole-System Per-\\nsistence. SIGARCH Comput. Archit. News 40, 1 (mar 2012), 401–410.\\nhttps://doi.org/10.11', 'Persistent Memory Research in the Post-Optane Era.pdf'), 757: ('ps://investors.micron.com/news-releases/news-\\nrelease-details/micron-updates-data-center-portfolio-strategy-\\naddress-growing\\n[37] Moohyeon Nam, Hokeun Cha, Young ri Choi, Sam H. Noh, and\\nBeomseok Nam. 2019. Write-Optimized Dynamic Hashing for Persis-\\ntent Memory. In USENIX Conference on File and Storage Technologies.\\nUSENIX Association, Boston, MA, 31–44.\\n[38] Dushyanth Narayanan and Orion Hodson. 2012. Whole-System Per-\\nsistence. SIGARCH Comput. Archit. News 40, 1 (mar 2012), 401–410.\\nhttps://doi.org/10.1145/2189750.2151018\\n[39] Emerson W. Pugh, Lyle R. Johnson, and John H. Palmer. 2003. IBM’s\\n360 and early 370 systems. MIT Press, Cambridge, Massachusetts.\\n[40] Han Jie Qiu, Sihang Liu, Xinyang Song, Samira Khan, and Gennady\\nPekhimenko. 2022. Pavise: Integrating Fault Tolerance Support for\\nPersistent Memory Applications. In Proceedings of the International\\nConference on Parallel Architectures and Compilation Techniques. ACM,\\nChicago, IL, 109–123.\\n[41] The Register. 2022. Last week Intel killed Optane. Today, Kioxia and\\nEverspin announced comparable tech. https://www.theregister.\\ncom/2022/08/02/kioxia_everspin_persistent_memory/\\n[42] Andy Rudoff. 2017. Persistent Memory Programming. USENIX ;login:\\n42, 2 (July 2017), 34–40.\\n[43] Andy M. Rudoff. 2016. Deprecating the PCOMMIT Instruc-\\ntion. https://www.intel.com/content/www/us/en/developer/\\narticles/technical/deprecate-pcommit-instruction.html .\\n[44] Steve Scargall. 2020. Programming Persistent Memory: A Comprehensive\\nGuide for Developers . Apress, New York, New York. 5–7 pages. https:\\n//doi.org/10.1007/978-1-4842-4932-1\\n[45] Xinyang (Kevin) Song, Sihang Liu, and Gennady Pekhimenko. 2022.\\nPersistent Memory —- A New Hope. https://www.sigarch.org/\\npersistent-memory-a-new-hope/\\n[46] Storage Networking Industry Association. 2017. NVM Programming\\nModel (NPM). https://www.snia.org/sites/default/files/technical-\\nwork/npm/release/SNIA-NVM-Programming-Model-v1.2.pdf\\n[47] Alexander van Renen, Lukas Vogel, Viktor Leis, Thomas Neumann,\\nand Alfons Kemper. 2019. Persistent Memory ', 'Persistent Memory Research in the Post-Optane Era.pdf'), 758: ('rk. 5–7 pages. https:\\n//doi.org/10.1007/978-1-4842-4932-1\\n[45] Xinyang (Kevin) Song, Sihang Liu, and Gennady Pekhimenko. 2022.\\nPersistent Memory —- A New Hope. https://www.sigarch.org/\\npersistent-memory-a-new-hope/\\n[46] Storage Networking Industry Association. 2017. NVM Programming\\nModel (NPM). https://www.snia.org/sites/default/files/technical-\\nwork/npm/release/SNIA-NVM-Programming-Model-v1.2.pdf\\n[47] Alexander van Renen, Lukas Vogel, Viktor Leis, Thomas Neumann,\\nand Alfons Kemper. 2019. Persistent Memory I/O Primitives. In Pro-\\nceedings of the 15th International Workshop on Data Management on\\nNew Hardware (DaMoN). ACM, Amsterdam, Netherlands, 1–7.\\n[48] Jingyu Wang, Shengan Zheng, Ziyi Lin, Yuting Chen, and Linpeng\\nHuang. 2022. Zebra: An Efficient, RDMA-Enabled Distributed Per-\\nsistent Memory File System. In International Conference on Database\\nSystems for Advanced Applications. ACM, Virtual, 341–349.\\n[49] Wikipedia. 2023. NVDIMM — Wikipedia, The Free Encyclo-\\npedia. http://en.wikipedia.org/w/index.php?title=NVDIMM&\\noldid=1141063008 . [Online; accessed 27-March-2023].\\n[50] Jian Xu, Juno Kim, Amir Saman Memaripour, and Steven Swanson.\\n2019. Finding and Fixing Performance Pathologies in Persistent Mem-\\nory Software Stacks. In Proceedings of the Twenty-Fourth International\\nConference on Architectural Support for Programming Languages and\\nOperating Systems (ASPLOS). ACM, Providence, RI, 427–439.\\n[51] Jian Xu and Steven Swanson. 2016. NOVA: A Log-structured File\\nSystem for Hybrid Volatile/Non-volatile Main Memories. In Proceedingsof the 14th Usenix Conference on File and Storage Technologies. USENIX\\nAssociation, Santa Clara, CA, 323–338.\\n[52] Jian Xu, Lu Zhang, Amirsaman Memaripour, Akshatha Gangadharaiah,\\nAmit Borase, Tamires Brito Da Silva, Steven Swanson, and Andy Rudoff.\\n2017. NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File\\nSystem. In Proceedings of the 26th Symposium on Operating Systems\\nPrinciples. ACM, Shanghai China, 478–496. https://doi.org/10.1145/\\n3132747.3132761\\n[53] Jian Yang, Juno Kim, Morte', 'Persistent Memory Research in the Post-Optane Era.pdf'), 759: ('. In Proceedingsof the 14th Usenix Conference on File and Storage Technologies. USENIX\\nAssociation, Santa Clara, CA, 323–338.\\n[52] Jian Xu, Lu Zhang, Amirsaman Memaripour, Akshatha Gangadharaiah,\\nAmit Borase, Tamires Brito Da Silva, Steven Swanson, and Andy Rudoff.\\n2017. NOVA-Fortis: A Fault-Tolerant Non-Volatile Main Memory File\\nSystem. In Proceedings of the 26th Symposium on Operating Systems\\nPrinciples. ACM, Shanghai China, 478–496. https://doi.org/10.1145/\\n3132747.3132761\\n[53] Jian Yang, Juno Kim, Morteza Hoseinzadeh, Joseph Izraelevitz, and\\nSteven Swanson. 2020. An Empirical Guide to the Behavior and Use of\\nScalable Persistent Memory. In USENIX Conference on File and Storage\\nTechnologies (FAST). USENIX Association, Santa Clara, CA, 169–182.\\n[54] Ziye Yang, James R. Harris, Benjamin Walker, Daniel Verkamp, Chang-\\npeng Liu, Cunyin Chang, Gang Cao, Jonathan Stern, Vishal Verma,\\nand Luse E. Paul. 2017. SPDK: A Development Kit to Build High Per-\\nformance Storage Applications. In 2017 IEEE International Conference\\non Cloud Computing Technology and Science (CloudCom). IEEE, Hong\\nKong, 154–161. https://doi.org/10.1109/CloudCom.2017.14\\n[55] Wenhui Zhang, Xingsheng Zhao, Song Jiang, and Hong Jiang. 2021.\\nChameleonDB: A Key-value Store for Optane Persistent Memory. In\\nProceedings of the Sixteenth European Conference on Computer Systems\\n(Eurosys). ACM, Edinburgh, Scotland, 194–209.\\n30', 'Persistent Memory Research in the Post-Optane Era.pdf'), 760: ('Datacenter Ethernet and\\nRDMA: Issues at Hyperscale\\nTorsten Hoeﬂer\\nETH Zürich and Microsoft\\nDuncan Roweth, Keith Underwood, Bob Alverson\\nHewlett Packard Enterprise\\nMark Griswold, Vahid Tabatabaee, Mohan Kalkunte, Surendra Anubolu\\nBroadcom\\nSiyuan Shen\\nETH Zürich\\nMoray McLaren\\nGoogle\\nAbdul Kabbani, Steve Scott\\nMicrosoft\\nAbstract —We observe that emerging artiﬁcial intelligence, high-performance computing, and\\nstorage workloads pose new challenges for large-scale datacenter networking. RDMA over\\nConverged Ethernet (RoCE) was an attempt to adopt modern Remote Direct Memory Access\\n(RDMA) features into existing Ethernet installations. Now, a decade later, we revisit RoCE’s\\ndesign points and conclude that several of its shortcomings must be addressed to fulﬁll the\\ndemands of hyperscale datacenters. We predict that both the datacenter and high-performance\\ncomputing markets will converge and adopt modernized Ethernet-based high-performance\\nnetworking solutions that will replace TCP and RoCE within a decade.\\nDatacenter Ethernet’s new Environment\\nEthernet has dominated the wired local-area\\nnetworking (LAN) space for decades ranging\\nfrom deployments in private homes to the largest\\ndatacenters. Datacenters have experienced a mas-\\nsive growth during the last decade and the number\\nof connected machines exceeds the size of the\\nlargest supercomputers today. While there remain\\nsome differences, the networking requirements of\\nsuch hyperscale mega-datacenters and supercom-\\nputers are quite similar [1]. Yet, supercomputers\\nare traditionally connected using special-purpose\\ninterconnects while datacenters build on Ethernet.\\nDue to similar requirements and economies of\\nscale, both continue to grow closer together witheach new technology generation. We believe now\\nis the right time to re-think the basic assumptions\\nand architecture for a converged interconnect.\\nMultiple technological trends are accelerating\\nthis convergence of high-performance intercon-\\nnects. Primarily, the increasing network perfor-\\nmance requirements push towards more ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 761: ('tionally connected using special-purpose\\ninterconnects while datacenters build on Ethernet.\\nDue to similar requirements and economies of\\nscale, both continue to grow closer together witheach new technology generation. We believe now\\nis the right time to re-think the basic assumptions\\nand architecture for a converged interconnect.\\nMultiple technological trends are accelerating\\nthis convergence of high-performance intercon-\\nnects. Primarily, the increasing network perfor-\\nmance requirements push towards more efﬁcient\\nhost stacks that can support the terabit band-\\nwidths, hundreds of millions of transactions per\\nsecond, and single-digit microsecond latencies\\nthat are required by emerging data-intensive ap-\\nplications such as Artiﬁcial Intelligence (AI) [2].\\nThese extreme requirements force all protocols\\nand hardware to be as efﬁcient as possible, ruling\\nout many of the TCP/IP-like stacks that tra-\\n1arXiv:2302.03337v2  [cs.NI]  15 Apr 2023\\nIEEE Computer\\nditionally drove datacenter networking. Remote\\nDirect Memory Access (RDMA) was developed\\nnearly three decades ago for high-performance\\ncomputing (HPC) workloads and was later ex-\\npanded to target storage with InﬁniBand (IB)\\nVerbs RDMA. RDMA enables CPU-ofﬂoaded,\\nhardware-accelerated direct memory access over\\nthe network. During the last 10 years, it became\\nthe de-facto standard for low-overhead and high-\\nspeed networking. Nearly all supercomputer ar-\\nchitectures as well as leading datacenter providers\\nutilize RDMA in production today.\\nThe simple assumptions on load balancing,\\ncongestion control, and error handling made\\ndecades ago do not hold for today’s networks\\nthat have more than 100x higher bandwidth and\\n10x higher message rates. Furthermore, sim-\\nple RDMA network interface cards (NICs) are\\noften enhanced with additional functionalities.\\nThe resulting “Smart NICs” often ofﬂoad sig-\\nniﬁcant services and implement specialized net-\\nwork protocols. Modern network switches also\\nhave improved capabilities ranging from ad-\\nvanced in-network telemetry, in-network compu-\\nt', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 762: ('balancing,\\ncongestion control, and error handling made\\ndecades ago do not hold for today’s networks\\nthat have more than 100x higher bandwidth and\\n10x higher message rates. Furthermore, sim-\\nple RDMA network interface cards (NICs) are\\noften enhanced with additional functionalities.\\nThe resulting “Smart NICs” often ofﬂoad sig-\\nniﬁcant services and implement specialized net-\\nwork protocols. Modern network switches also\\nhave improved capabilities ranging from ad-\\nvanced in-network telemetry, in-network compu-\\ntation capabilities, and in-network load-balancing\\nor congestion-control [3]. We argue that the cur-\\nrently existing standards and deployed infras-\\ntructure has fundamental gaps that must be ad-\\ndressed in the near future to support efﬁcient\\nhigh-performance networking.\\nA brief history of RDMA for Ethernet\\nRDMA was originally developed for HPC in\\nsystems as early as the Paragon, Cray’s T3D/T3E,\\nand ASCI Red. Later, InﬁniBand Verbs RDMA\\nbecame wide-spread in the supercomputing ﬁeld\\nas a standardized solution. It was then adopted\\nas “RDMA over Converged Ethernet” (RoCE) in\\nthe datacenter context to provide RDMA’s bene-\\nﬁts in a backwards-compatible Ethernet context.\\nAnother protocol, iWARP (cf. IETF 2007, RFCs\\n5040-5044, 6580, 6581, 7306), layers RDMA\\nsemantics over TCP or SCTCP. Both iWARP and\\nRoCE use InﬁniBand’s Verbs to interface with the\\nuser software stacks and are thus mostly trans-\\nparent to the user. Even though iWARP allowed\\nInternet-compatible routing from the beginning,\\nit did not ﬁnd widespread adoption. This may\\nbe due to the fact that a full TCP/IP stack is\\ncomplex and expensive to ofﬂoad to hardware,compared to the very simple protocol that under-\\nlies RoCE. Indeed, RoCEv1 was simply adopting\\nan InﬁniBand-like transport layer (i.e., the Base\\nTransport Header, BTH) on top of Ethernet’s\\nL2 headers. Later, RoCEv2 added IP/UDP L3\\nheaders to support routing within and across\\ndatacenters. Today, there are more RoCEv2 NICs\\nthan InﬁniBand NICs deployed.\\nRoCE – convergence or duct tape?\\nRoCE’s core design i', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 763: ('tion. This may\\nbe due to the fact that a full TCP/IP stack is\\ncomplex and expensive to ofﬂoad to hardware,compared to the very simple protocol that under-\\nlies RoCE. Indeed, RoCEv1 was simply adopting\\nan InﬁniBand-like transport layer (i.e., the Base\\nTransport Header, BTH) on top of Ethernet’s\\nL2 headers. Later, RoCEv2 added IP/UDP L3\\nheaders to support routing within and across\\ndatacenters. Today, there are more RoCEv2 NICs\\nthan InﬁniBand NICs deployed.\\nRoCE – convergence or duct tape?\\nRoCE’s core design is inherited from a\\ntechnology developed for simple hardware two\\ndecades ago and are suboptimal in today’s Eth-\\nernet environments. For example, RoCE uses\\nInﬁniBand’s simple transport layer that heavily\\nbuilds on in-order delivery as well as go-back-n\\nretransmission semantics that essentially require\\na highly reliable in-order fabric for efﬁcient op-\\neration. Thus, RoCE runs best over a lossless in-\\norder fabric, like InﬁniBand. Traditionally, Eth-\\nernet drops packets when switch buffers are full\\nand relies on end-to-end retransmission. To sup-\\nport RoCE, “converged Ethernet” (CE) introduces\\nPriority Flow Control (PFC) to implement link-\\nlevel lossless operation. PFC repurposes Ethernet\\nPAUSE frames that existed in Ethernet to support\\nnetworks with different link transmission rates.\\nPFC enhances PAUSE frames to stop (or throt-\\ntle) trafﬁc on a speciﬁc priority class to avoid\\npacket drops. Unfortunately, this complex set of\\nprotocols interferes across the different layers in\\nthe network and reduces efﬁciency for some of\\ntoday’s most important workloads.\\nRoCE’s semantics, load balancing, and con-\\ngestion control mechanisms are inherited from\\nInﬁniBand. This implies that all messages should\\nappear at the destination in order as if they were\\ntransmitted over a static route, essentially disal-\\nlowing many packet-level load balancing mech-\\nanisms. For AI training workloads which are\\nlong-lived ﬂows, multi-pathing mechanisms can\\ngreatly improve the job completion time. Further-\\nmore, RoCEv2 uses a simplistic congestion', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 764: ('r some of\\ntoday’s most important workloads.\\nRoCE’s semantics, load balancing, and con-\\ngestion control mechanisms are inherited from\\nInﬁniBand. This implies that all messages should\\nappear at the destination in order as if they were\\ntransmitted over a static route, essentially disal-\\nlowing many packet-level load balancing mech-\\nanisms. For AI training workloads which are\\nlong-lived ﬂows, multi-pathing mechanisms can\\ngreatly improve the job completion time. Further-\\nmore, RoCEv2 uses a simplistic congestion con-\\ntrol mechanism based on IP’s Explicit Congestion\\nNotiﬁcation (ECN). ECN-compatible switches\\nmark packets when congestion is detected and re-\\nceivers relay that information back to the senders,\\nwhich in turn reduce their injection rate guided\\nwith a single parameter. After a congestion-free\\nperiod, the rate is automatically increased again\\n2\\nusing a second conﬁguration parameter. ECN uses\\na binary ﬂag for congestion experienced and the\\nlack of ﬁne grained indication results in many\\nRound Trip Times (RTTs) to determine the cor-\\nrect rate. This simple mechanism is very similar\\nto InﬁniBand’s original Forward and Backward\\nExplicit Congestion Notiﬁcation (FECN/BECN).\\nIt promises to coexist with other trafﬁc but is hard\\nto conﬁgure in practice [4], [5], [6].\\nWe now brieﬂy discuss some important trafﬁc\\nmotifs in HPC and datacenter trafﬁc and then\\ndiscuss RoCE’s shortcomings in detail.\\nGuiding Trafﬁc Motifs\\nFor the sake of the discussion, we shall iden-\\ntify three trafﬁc motifs representing a large frac-\\ntion of RDMA workloads today. Unfortunately,\\nthose motifs also highlight RoCE’s shortcomings.\\nHere, we focus on East-West (intra-) datacenter\\ntrafﬁc as used in HPC, AI training and distributed\\ninference, storage, as well as general microservice\\nor Function as a Service (Faas) trafﬁc.\\nIncast (IN)\\nAn incast trafﬁc pattern happens when mul-\\ntiple sources target the same destination process\\nin a potentially uncoordinated but simultaneous\\ntrafﬁc pattern. It is characterized by a number of\\nsource processes and a transa', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 765: ('f RDMA workloads today. Unfortunately,\\nthose motifs also highlight RoCE’s shortcomings.\\nHere, we focus on East-West (intra-) datacenter\\ntrafﬁc as used in HPC, AI training and distributed\\ninference, storage, as well as general microservice\\nor Function as a Service (Faas) trafﬁc.\\nIncast (IN)\\nAn incast trafﬁc pattern happens when mul-\\ntiple sources target the same destination process\\nin a potentially uncoordinated but simultaneous\\ntrafﬁc pattern. It is characterized by a number of\\nsource processes and a transaction size. It often\\nappears stochastically in practice when a service\\nis, by chance, requested by many uncoordinated\\nclients at the same time. For example, imagine\\nthat 100 clients want to commit a 10 kiB write\\ntransaction to the same storage server. All clients\\nmay send at full bandwidth because they do\\nnot know about the upcoming congestion. The\\npackets will quickly ﬁll network buffers that can\\nhinder other ﬂows and eventually violate service\\nlevel agreements (SLAs). The most challenging\\nincast patterns are caused by transactions that are\\nsmaller than the bandwidth-delay product such\\nthat the congestion control mechanism cannot get\\na reliable signal before the transaction should be\\ncompleted. We remark that growing bandwidths\\npush more and more workloads into this critical\\nregion.\\nOblivious bulk synchronous (OBS)\\nMany HPC and AI training workloads can\\nbe expressed in the oblivious bulk synchronousmodel (OBS) where computation steps are inter-\\nleaved with global communication steps that often\\nsynchronize processes. Oblivious means that the\\ncommunication pattern for an application depends\\non a small number of parameters (such as size\\nor process count) and does not depend on the\\ndata that is processed. It can often be determined\\nstatically before the application is started. For\\nexample, all collective operations in the Message\\nPassing Interface (MPI) standard [7] are obliv-\\nious. Thus, OBS workloads can algorithmically\\navoid incast! The three-dimensional parallelism\\nin deep learning training [2] is a typical ex', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 766: ('ocesses. Oblivious means that the\\ncommunication pattern for an application depends\\non a small number of parameters (such as size\\nor process count) and does not depend on the\\ndata that is processed. It can often be determined\\nstatically before the application is started. For\\nexample, all collective operations in the Message\\nPassing Interface (MPI) standard [7] are obliv-\\nious. Thus, OBS workloads can algorithmically\\navoid incast! The three-dimensional parallelism\\nin deep learning training [2] is a typical example.\\nOBS can be modeled by the number of processes,\\nthe duration of the computation, and the size\\nof the communication (per endpoint). If both\\ncomputation and communication are small, the\\noverall workload is latency sensitive, a pattern\\nthat often appears in HPC and AI inference.\\nLarge communications that can often be found\\nin AI training workloads are typically bandwidth-\\nsensitive.\\nLatency-sensitive (LS)\\nFor some workloads, message latency (and\\nsometimes message rate) plays a central role.\\nSome of those fall into the OBS category but\\nothers have complex, data-dependent, message\\nchains that form critical performance paths in\\nthe application. Those are typically strong scaling\\nworkloads where the time to solution matters and\\ninefﬁcient execution must be tolerated. Large-\\nscale simulations with strict deadlines such as\\nweather forecasting and oil exploration fall into\\nthis category, but also some transaction process-\\ning or search/inference workloads. Here, one has\\ntypically stringent (single-digit microsecond) la-\\ntency requirements.\\nDeployment characteristics\\nIn addition to the trafﬁc types, the deployment\\nenvironment is also shifting. Newly emerging\\nconﬁdential compute ideas require all trafﬁc to be\\nencrypted on the wire. Ideally, trafﬁc is encrypted\\nand decrypted end-to-end in secure enclaves and\\nno network equipment (NIC or switch) is to be\\ntrusted. Furthermore, and related, emerging multi-\\ntenancy scenarios require managing tens of thou-\\nsands of connections from a single host. Those\\nare often supported ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 767: ('nd) la-\\ntency requirements.\\nDeployment characteristics\\nIn addition to the trafﬁc types, the deployment\\nenvironment is also shifting. Newly emerging\\nconﬁdential compute ideas require all trafﬁc to be\\nencrypted on the wire. Ideally, trafﬁc is encrypted\\nand decrypted end-to-end in secure enclaves and\\nno network equipment (NIC or switch) is to be\\ntrusted. Furthermore, and related, emerging multi-\\ntenancy scenarios require managing tens of thou-\\nsands of connections from a single host. Those\\nare often supported by Smart NICs managing the\\n3\\nIEEE Computer\\nresources such as bandwidth and security through\\nrate limiting and ﬁltering. Also, new, cost effec-\\ntive low-diameter and specialized topologies that\\nrequire more advanced load balancing and rout-\\ning become a necessity for extreme-bandwidth\\ndeployments [8], [2]. Many combinations of those\\nrequirements pose signiﬁcant challenges on next-\\ngeneration high-performance networks.\\nWhere RoCE needs improvement\\nMany of RoCE’s issues have been discussed\\nin the past [9] and many research works exist to\\npropose various solutions [10]. Here, we outline\\npotential improvements that we see and we relate\\nthem to the key workloads and deployment use-\\ncases outlined above. We now provide an item-\\nized list of issues that could be improved for\\nmore efﬁcient operation in Ethernet-based high-\\nperformance RDMA or Smart NIC systems.\\n1) PFC requires excessive buffering for lossless\\ntransport\\nPriority Flow Control (PFC) lies at the very\\nheart of converged Ethernet to enable lossless\\ntransport on each link. With PFC, the receiver\\nmonitors the available input buffer space. Once\\nthis buffer space falls below some threshold re-\\nlated to the bandwidth-delay product BW*RTT, it\\nsends a PAUSE frame to the sender. At this time,\\nBW*RTT/2 Bytes are already on the incoming\\nwire but before the sender will receive the PAUSE\\nframe, it will send another BW*RTT/2 Bytes.\\nThe minimal buffer requirement for fully lossless\\ntransfers would thus be BW*RTT + MTU1, where\\nMTU is the maximum size of a packet. Yet, this\\n', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 768: ('t on each link. With PFC, the receiver\\nmonitors the available input buffer space. Once\\nthis buffer space falls below some threshold re-\\nlated to the bandwidth-delay product BW*RTT, it\\nsends a PAUSE frame to the sender. At this time,\\nBW*RTT/2 Bytes are already on the incoming\\nwire but before the sender will receive the PAUSE\\nframe, it will send another BW*RTT/2 Bytes.\\nThe minimal buffer requirement for fully lossless\\ntransfers would thus be BW*RTT + MTU1, where\\nMTU is the maximum size of a packet. Yet, this\\nwould only support the case where packets are\\nimmediately drained at the receiver. Even the\\nslightest delay in the forwarding may signiﬁcantly\\nreduce link utilization.\\nThe BW*RTT buffer space that covers the\\ntravel latency of the PAUSE message is often\\ncalled “headroom buffer” and it is similar to\\nthe buffer required for credit-based ﬂow control\\nschemes such as those used in InﬁniBand or\\nFibre Channel. In those, the receiver proactively\\nsends credits (buffer allocations) to the sender\\nkeeping the input buffer space at an equilibrium,\\ninstead of reacting once it runs too full with\\n1Maximum Transfer UnitPFC. Both schemes have their merits—a credit\\ncan travel proactively towards the source while a\\nPFC scheme can be more reactive (late binding)\\nwhen allocating shared buffer space to different\\nsource links. Both schemes need to essentially\\nreserve BW*RTT space per link to just cover the\\nround-trip control delay of the link, space that is\\nlost for efﬁcient forwarding.\\nIn practice, buffer space is extremely valuable\\nto ingest varying trafﬁc peaks for temporal and\\nspatial load balancing. Furthermore, just the re-\\nquired headroom buffer, that cannot be used for\\nanything else without risking packet drops, puts\\na signiﬁcant challenge for the scaling of next-\\ngeneration switches. Figure 1a shows the required\\nheadroom space (excluding other buffering!) for\\nvarious switch generations assuming a 600 ns\\naverage latency (including arbitration, forward\\nerror correction (FEC), and wire delay) for 9 kB\\npackets and 8 trafﬁc priorit', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 769: ('\\nto ingest varying trafﬁc peaks for temporal and\\nspatial load balancing. Furthermore, just the re-\\nquired headroom buffer, that cannot be used for\\nanything else without risking packet drops, puts\\na signiﬁcant challenge for the scaling of next-\\ngeneration switches. Figure 1a shows the required\\nheadroom space (excluding other buffering!) for\\nvarious switch generations assuming a 600 ns\\naverage latency (including arbitration, forward\\nerror correction (FEC), and wire delay) for 9 kB\\npackets and 8 trafﬁc priority classes with separate\\nbuffers on a three-tier fat tree. Covering longer\\ndistances (and thus latencies) is also challenging\\nas high-performance geo-replicated datacenters\\nbecome common. Figure 1b shows the needed\\nper-port headroom buffer for the same conﬁgu-\\nration assuming 800G ports, a 5ns/m wire delay,\\nand various deployment types.\\nTomahawk 2 \\n(2016)\\nTomahawk \\n(2014)Tomahawk 3\\n(2018)Tomahawk 4\\n(2020)Tomahawk 5\\n(2022)Switch bandwidth doubles \\nevery two years!\\n(a) Intra-datacenter per-switch headroom buffer.\\nCluster\\n< 150 m\\n< 0.75 usDatacenter Site\\n< 100 m\\n< 5 usRegion\\n< 400 km\\n< 2ms\\nGlobal\\n< 6000 km\\n< 30 ms\\n1 MB10 MB100 MB1 GB\\n(b) Varying distance per-port headroom buffer.\\nFigure 1: Headroom Buffer Requirements.\\nOne may consider a lossy link-level proto-\\ncol to repurpose these buffers for forwarding\\nfunctions. Yet, this interacts with error handling\\n4\\nprotocols as we shall see soon. In any case,\\nwasted buffer space is a general issue affecting all\\nworkloads that could beneﬁt from the additional\\nbuffer if it was available for packet forwarding.\\n2) Victim ﬂows, congestion trees, PFC storms,\\nand deadlocks\\nAnother issue stems from the fact that PFC\\nstops a whole trafﬁc class (encoded as only three\\nbits) and all ﬂows in it. This can lead to blocked\\nvictim ﬂows: assume that we have two ﬂows A\\nand B sharing a link L. Flow A is not congested\\nand could send at full bandwidth. However, ﬂow\\nB is blocked at some downstream port and ﬁlls\\nup the input buffer of L. Eventually, L’s allocated\\nbuffer will be full with B’s pac', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 770: ('t was available for packet forwarding.\\n2) Victim ﬂows, congestion trees, PFC storms,\\nand deadlocks\\nAnother issue stems from the fact that PFC\\nstops a whole trafﬁc class (encoded as only three\\nbits) and all ﬂows in it. This can lead to blocked\\nvictim ﬂows: assume that we have two ﬂows A\\nand B sharing a link L. Flow A is not congested\\nand could send at full bandwidth. However, ﬂow\\nB is blocked at some downstream port and ﬁlls\\nup the input buffer of L. Eventually, L’s allocated\\nbuffer will be full with B’s packets and L sends\\na PAUSE frame. This frame also stops ﬂow A,\\nwhich could proceed independently—now, ﬂow\\nA is victimized by the PAUSE of ﬂow B. Thus,\\nﬂows that are not congested may be affected by\\nother ﬂows that are congested. This phenomenon\\nis also known as Head of Line blocking.\\nSince any congestion of a downstream port\\nwill ﬁll buffers upstream unless the endpoint\\ncongestion control protocol reacts, PFC events\\ncan quickly grow a “congestion tree” inversely\\nfollowing victimized ﬂows in the network. Con-\\ngestion trees are a general problem in lossless\\nnetworks and are sometimes called PFC storms.\\nIt could be addressed by an even more ﬁne-\\ngrained tracking of congestion, e.g., at the basis\\nof individual ﬂows instead of priorities. Yet, this\\nrequires the network switches to maintain ﬂow\\nstate to identify individual ﬂows [11], [3]. One\\ncould also attempt to move congested ﬂows into\\ncongested priorities dynamically, to avoid vic-\\ntims (cf. congestion isolation, P802.1Qcz). An-\\nother problem is that lossless lanes now consume\\nalready scarce trafﬁc classes (separate buffer\\nspace). This takes an important resource from\\ndatacenter providers that already use such traf-\\nﬁc classes for differentiated services such as\\nelephant-ﬂow backups, low-latency video confer-\\nencing, and others. Any trafﬁc class used for\\nRoCE (or other lossless) trafﬁc is lost network-\\nwide.\\nSuch congestion trees are particularly prob-\\nlematic for incast workloads where they can jam\\nthe whole network, especially in the context of\\npacket-level adapt', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 771: ('es now consume\\nalready scarce trafﬁc classes (separate buffer\\nspace). This takes an important resource from\\ndatacenter providers that already use such traf-\\nﬁc classes for differentiated services such as\\nelephant-ﬂow backups, low-latency video confer-\\nencing, and others. Any trafﬁc class used for\\nRoCE (or other lossless) trafﬁc is lost network-\\nwide.\\nSuch congestion trees are particularly prob-\\nlematic for incast workloads where they can jam\\nthe whole network, especially in the context of\\npacket-level adaptive or oblivious routing. Yet,the very low bandwidth per ﬂow at the incast\\nlink means that, in theory, these ﬂows would need\\nvery little network buffering to saturate the link.\\nThe purely rate-based nature of RoCE’s conges-\\ntion control allows sources to inject (too) many\\npackets that quickly ﬁll network buffers. For\\nexample, a window-based scheme would allow\\nthe administrators to directly control the network-\\nwide buffer occupancy of each ﬂow.\\nAny lossless scheme with limited buffering\\nsuffers from deadlocks if the routing allows\\nfor cycles to form. This can be avoided with\\ncycle-free routing schemes or special buffering\\nstrategies—both come at a (small) cost. Even\\nif routes are generally deadlock free, transient\\nstates occurring after link failures can lead to\\ndeadlocks. Avoiding those is harder, however,\\none can conﬁgure packet timeouts in switches to\\nresolve this problem dynamically.\\n3) Go-back-N retransmission\\nRoCE was designed for very simple hardware\\nfollowing InﬁniBand’s in-order and credit-based\\nlossless transport. This implies that packets can\\nonly be dropped if they are corrupted by bit\\nerrors, a very rare event. Thus, retransmission\\nlogic can be simple: if the receiver detects a gap\\nin the packet stream (i.e., a skipped sequence\\nnumber), it sends a negative acknowledgement\\n(NACK) to the sender and drops all later packets.\\nThe sender then retransmits all packets beginning\\nwith the lost one. This scheme essentially dis-\\ncards and retransmits a full end-to-end BW*RTT\\n(bandwidth-delay product) worth of ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 772: ('less transport. This implies that packets can\\nonly be dropped if they are corrupted by bit\\nerrors, a very rare event. Thus, retransmission\\nlogic can be simple: if the receiver detects a gap\\nin the packet stream (i.e., a skipped sequence\\nnumber), it sends a negative acknowledgement\\n(NACK) to the sender and drops all later packets.\\nThe sender then retransmits all packets beginning\\nwith the lost one. This scheme essentially dis-\\ncards and retransmits a full end-to-end BW*RTT\\n(bandwidth-delay product) worth of data.\\nLet us assume a three-tier fat tree network\\nwith 800 Gb/s link speed and a worst-case per-\\nhop latency of 600 ns. The total RTT as observed\\nby an endpoint would be 3.6 us2. The effective bit\\nerror rate on each link can be as high as 1e-12 (as\\nproposed by the Ethernet speciﬁcation [12]) and\\nwe assume 9 kiB frames, the probability of losing\\na single frame is 3.3e-8 (see Appendix A for\\nderivation). Thus, the total expected bandwidth\\nloss due to go-back-n would be a negligible\\n0.00013%.\\nA bigger issue with the simple go-back-n\\nscheme is that it does not support multi-pathing\\nor out-of-order delivery. Any two packets passing\\n2we roughly approximate end-to-end latency as six hops\\n5\\nIEEE Computer\\nwould trigger an expensive retransmission event\\nlosing a full BW*RTT transmission. Latest gener-\\nations of RoCE NICs introduce selective retrans-\\nmission to mitigate this problem. Yet, those are\\noften limited. For example NVIDIA’s ConnectX-\\n6 adapter does not support adaptive routing of tag\\nmatching with selective retransmission enabled.3\\nGo-back-n has one interesting advantage though:\\nif a bit error happens and the packet is dropped\\n(silently) by the lower layers, the error is detected\\nimmediately once the next packet arrives. Other\\nschemes that support out-of-order delivery would\\nneed to wait for a timeout to expire at the sender,\\npotentially leading to much higher recovery times\\nand jitter. Thus, when designing new transport\\nprotocols, one needs to consider all these trade-\\noffs carefully!\\n4) Congestion control and c', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 773: ('ransmission enabled.3\\nGo-back-n has one interesting advantage though:\\nif a bit error happens and the packet is dropped\\n(silently) by the lower layers, the error is detected\\nimmediately once the next packet arrives. Other\\nschemes that support out-of-order delivery would\\nneed to wait for a timeout to expire at the sender,\\npotentially leading to much higher recovery times\\nand jitter. Thus, when designing new transport\\nprotocols, one needs to consider all these trade-\\noffs carefully!\\n4) Congestion control and colocation with other\\ntrafﬁc\\nRoCE’s default congestion control relies on a\\nvery simple rate control that is intimately linked\\nto the lossless transport assumption. Many re-\\nsearchers have recognized that this simple mech-\\nanism does not integrate well with other trafﬁc\\nsuch as TCP/IP and generally can be improved\\nin the datacenter environment. Mechanisms such\\nas DCQCN [5], TIMELY [6], and HPCC [4]\\nbuild on RoCE to improve the transport of ﬂows.\\nMost RoCE deployments today use non-standard\\ncongestion control mechanisms which makes in-\\nteroperability between vendors, or even different\\nhardware generations of the same vendor, hard.\\nThis is due to the fact that congestion control\\nremains a tough problem and it is likely that dif-\\nferent workloads require different tuned versions\\nof the protocol.\\nFor example, the typically repetitive endpoint-\\ncongestion-free bulk data transfers in oblivious\\nsynchronous workloads could quickly be learned\\nor even be statically conﬁgured based on the\\nexpected trafﬁc pattern [2], [13]. Highly-dynamic\\nincast scenarios require coordinating multiple\\nsenders either through the receiver or network\\nsignals. Latency-sensitive workloads with small\\nmessages that are smaller than the bandwidth-\\ndelay product can be most problematic, espe-\\ncially if they appear in an unpredictable data-\\n3ConnectX-6 DX ﬁrmware release notes v22.27.1016driven communication pattern. Those may need\\nto rely on switch buffering to ingest temporary\\nload-imbalance at the network level. In general,\\ncongestion control schem', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 774: ('. Highly-dynamic\\nincast scenarios require coordinating multiple\\nsenders either through the receiver or network\\nsignals. Latency-sensitive workloads with small\\nmessages that are smaller than the bandwidth-\\ndelay product can be most problematic, espe-\\ncially if they appear in an unpredictable data-\\n3ConnectX-6 DX ﬁrmware release notes v22.27.1016driven communication pattern. Those may need\\nto rely on switch buffering to ingest temporary\\nload-imbalance at the network level. In general,\\ncongestion control schemes are and will remain a\\nresearch focus with constant tuning even after de-\\nployment. Co-existing with different trafﬁc types\\nsuch as TCP or QUIC will also require constant\\nadoption. Thus, such schemes should not only be\\nfast and cheap in hardware but also be ﬂexible\\nand support a wide range of parametrizations.\\nAnother line of argument considers switch\\nqueue size and occupancy. Datacenter switches\\ntraditionally have large (deep) buffers to accom-\\nmodate trafﬁc bursts without dropping to accom-\\nmodate the slow end-to-end rate adjustment. On\\nthe other hand, switches used in HPC usually\\noperate lossless with very shallow buffers and\\nstiff back-pressure due to their reliable link-level\\nﬂow control mechanisms [3]. Also, HPC network\\ntopologies have usually lower diameter than data-\\ncenter deployments [14]. Thus, HPC deployments\\nsupport lower-latency operations because small\\npackets are less likely to wait in buffers behind\\nlonger ﬂows. Datacenter networks with RoCE are\\noften combining both inefﬁciently: they use a\\nlossless transport with all its issues with relatively\\nlarge-buffered switches. Many modern conges-\\ntion control mechanisms thus aim at keeping the\\nbuffer occupancy generally low, leaving this very\\nexpensive resource unused!\\n5) Header sizes, packet rates, scalability\\nRoCEv2 uses full Ethernet L2 and UDP/IP\\nheaders in addition to InﬁniBand’s Base Transport\\nHeader (BTH). Thus, the header overhead per\\npacket is substantial: 22 Bytes L2, 20 Bytes IP, 8\\nBytes UDP, and 12 Bytes BTH and 4 Bytes ICRC\\nmake a total ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 775: ('\\nlossless transport with all its issues with relatively\\nlarge-buffered switches. Many modern conges-\\ntion control mechanisms thus aim at keeping the\\nbuffer occupancy generally low, leaving this very\\nexpensive resource unused!\\n5) Header sizes, packet rates, scalability\\nRoCEv2 uses full Ethernet L2 and UDP/IP\\nheaders in addition to InﬁniBand’s Base Transport\\nHeader (BTH). Thus, the header overhead per\\npacket is substantial: 22 Bytes L2, 20 Bytes IP, 8\\nBytes UDP, and 12 Bytes BTH and 4 Bytes ICRC\\nmake a total of 66 Bytes per packet. Locally-\\nrouted InﬁniBand, for example, has only a total\\nheader size of 20 Bytes: 8 Bytes for the Local\\nRouting Header, and 12 Bytes for the BTH. Other\\nHPC protocols have headers with less than 40\\nBytes.\\nThis impacts both the raw packet rate as\\nwell as processing overhead and cost as more\\ncomplex headers require more header processing.\\nJust the packet rate for small payloads could\\nbe problematic. Let us assume 8 Byte messages\\nas an example for a single-element reduction\\noperation for conjugate gradient solvers or ﬁne-\\n6\\ngrained global graph updates. The maximum rate\\n(without headers) on an 800 Gb/s link would be\\n12.5 Giga-packets per second (Gpps). With IB\\nheaders, that rate would decrease to 3.5 Gpps\\nand with RoCEv2 headers to 1.4 Gpps. The\\npacket would be nearly 90% header overhead!\\nAnd we are ignoring additional protocol headers\\nfor MPI or RDMA endoints. Yet, given that NIC\\npacket processing is currently slower ( <1 Gpps\\nper NIC), the header size may not be the biggest\\nissue. Furthermore, NICs need to process ac-\\nknowledgment packets, which could be especially\\nchallenging for selective acknowledgment and\\nretransmission protocols. The high user-level and\\nprotocol message rates require parallel processing\\nin the NIC given the mostly stagnant clock rates.\\nRoCE’s packet format is closely linked to In-\\nﬁniBand’s verbs which has connections between\\nqueue pairs (QPs) as its basic concept. The size of\\nthe context state for a single connection depends\\non the implementation details but large-cl', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 776: ('rmore, NICs need to process ac-\\nknowledgment packets, which could be especially\\nchallenging for selective acknowledgment and\\nretransmission protocols. The high user-level and\\nprotocol message rates require parallel processing\\nin the NIC given the mostly stagnant clock rates.\\nRoCE’s packet format is closely linked to In-\\nﬁniBand’s verbs which has connections between\\nqueue pairs (QPs) as its basic concept. The size of\\nthe context state for a single connection depends\\non the implementation details but large-cluster\\nall-to-all connectivity may be problematic. Each\\nqueue pair at least needs to keep connection\\ninformation and state such as sequence number\\nand destination address and queue pair number.\\nConnection state can be relatively large, up to 1\\nkB per connection in some implementations.\\nSmall packets are often important in latency-\\nsensitive workloads, some of which are bound by\\nthe rate at which the NIC can issue new messages.\\nSlimmer headers would potentially decrease la-\\ntencies and increase message rates while allowing\\nfor a more efﬁcient bandwidth utilization.\\n6) No support for smart stacks\\nAs network overheads become more impor-\\ntant in datacenter workloads, more intelligent\\nstacks are designed. For example, the QUIC pro-\\ntocol allows to push transport processing to the\\napplication which can deﬁne application-speciﬁc\\nprotocols. This enables running different proto-\\ncols for different service requirements, such as\\nlatency-insensitive video streaming, latency sen-\\nsitive audio-conferencing, or generally resilient\\nbut large backup trafﬁc. RoCE’s philosophy of\\nhardware acceleration does not support different\\ntransport protocols, even if the user-level stack\\nwould be able to specify additional properties of\\nthe trafﬁc (e.g., mark messages as resilient to out-\\nof-order delivery).Emerging Smart NICs lead to new opportuni-\\nties in this area where user-conﬁgurable kernels\\ncould perform packet and protocol processing on\\nthe NIC [15]. Additionally, in-network telemetry\\n(INT) can provide additional signals for these\\npr', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 777: ('ilient\\nbut large backup trafﬁc. RoCE’s philosophy of\\nhardware acceleration does not support different\\ntransport protocols, even if the user-level stack\\nwould be able to specify additional properties of\\nthe trafﬁc (e.g., mark messages as resilient to out-\\nof-order delivery).Emerging Smart NICs lead to new opportuni-\\nties in this area where user-conﬁgurable kernels\\ncould perform packet and protocol processing on\\nthe NIC [15]. Additionally, in-network telemetry\\n(INT) can provide additional signals for these\\nprotocols to react accordingly. Thus, even if the\\nstack has additional knowledge about the trafﬁc\\ntypes, today’s RoCE forces it into a relatively\\nsimple and inﬂexible protocol that cannot take\\nfull advantage of this knowledge.\\n7) Security\\nRoCE is known to have several security is-\\nsues [16], [17], especially in multi-tenant con-\\ntexts. Many of those issues stem from the fact that\\nprotocol security, authentication, and encryption\\nhave played a minor role at the design time. Yet,\\ntoday, such properties are much more important.\\nIPSEC can be used to protect L3 headers\\nand payload but would need to be enabled on\\na per-queue-pair basis such that no two tenants\\nshare a set of keys. This can be quite costly in\\nterms of connection context overhead and per-\\nformance. Furthermore, RoCE does not support\\nsub-delegation of memory regions to other nodes.\\nBoth issues can be addressed with modern key-\\nderivation protocols [16].\\n8) Link-level reliability\\nThe move towards higher transceiver speeds\\nleads to more complex encoding and modulation\\nschemes running at growing frequencies. With\\n50G lanes, Ethernet moved from the simple two-\\nvoltage level NRZ to four-voltage level PAM4\\nencoding. Today’s 100G lanes run at 25 GHz,\\nrequiring the receiver to distinguish four levels\\nwithin a fraction of a nanosecond. The signal\\ndegradation in cables and connectors as well as\\nthe increasingly complex analog circuitry lead\\nto higher bit-error rates going to a bit-error rate\\n(BER) as high as 1e-4 soon.\\nForward-error correction (FEC) has been in-\\ntr', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 778: ('nd modulation\\nschemes running at growing frequencies. With\\n50G lanes, Ethernet moved from the simple two-\\nvoltage level NRZ to four-voltage level PAM4\\nencoding. Today’s 100G lanes run at 25 GHz,\\nrequiring the receiver to distinguish four levels\\nwithin a fraction of a nanosecond. The signal\\ndegradation in cables and connectors as well as\\nthe increasingly complex analog circuitry lead\\nto higher bit-error rates going to a bit-error rate\\n(BER) as high as 1e-4 soon.\\nForward-error correction (FEC) has been in-\\ntroduced to avoid excessive end-to-end retrans-\\nmissions due to dropping of corrupted packets in\\nthe network. Ethernet aims at a 1e-12 BER at the\\nlink level and currently employs a Reed-Solomon\\ncode on 10-bit symbols using a block of 514 such\\nsymbols with 30 additional encoding symbols\\n(RS544). This enables the receiver to correct 15\\nrandom bit errors and up to 150 consecutive\\n7\\nIEEE Computer\\n(burst) bit errors. Other FEC codes such as LL-\\nFEC (RS272, half size as RS544) and Firecode\\nprovide lower latency but also lower protection\\nagainst bit errors.\\nGenerally, FEC comes at a latency and energy\\ncost that falls into two categories: (1) accumulat-\\ning the 5,140 bits of data and (2) encoding and\\ndecoding the code symbols. The former decreases\\nwith the link bandwidth and the latter depends on\\nthe implementation, varying from 20 to 100 ns\\nin practice. Figure 2 shows the projected RS544\\nFEC for different link bandwidths.\\nFEC decoding time (30 ns)\\n12% 22% 36% 52% 69% 82% \\nFigure 2: RS544 FEC latency breakdown.\\nFor a constant RS544 FEC, the latency re-\\nduces for faster link bandwidths but will not go\\nbelow the FEC computation overhead. However,\\nfaster lanes may lead to signiﬁcantly higher bit\\nerror rates. In fact, RS544 may not be able to\\ncorrect the projected 1e-4 BER to the desired 1e-\\n12. Thus, future Ethernet standards may move\\nto more complex FEC mechanisms that may\\nincrease the latency signiﬁcantly.\\nAn alternative approach is used in PCIe,\\nwhich also deals with relatively high BER due\\nto complex connectors but is d', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 779: ('onstant RS544 FEC, the latency re-\\nduces for faster link bandwidths but will not go\\nbelow the FEC computation overhead. However,\\nfaster lanes may lead to signiﬁcantly higher bit\\nerror rates. In fact, RS544 may not be able to\\ncorrect the projected 1e-4 BER to the desired 1e-\\n12. Thus, future Ethernet standards may move\\nto more complex FEC mechanisms that may\\nincrease the latency signiﬁcantly.\\nAn alternative approach is used in PCIe,\\nwhich also deals with relatively high BER due\\nto complex connectors but is designed as a low-\\nlatency local interconnect targeting around 5 ns.\\nFor example, the upcoming PCIe 6.0 speciﬁcation\\nprotects a block of 242 Bytes with 6 Bytes of\\nFEC together with an additional 8 Byte CRC.\\nThe receiver ﬁrst uses the FEC to correct some\\nbit errors and then checks the CRC. If this check\\nfails, it initiates a simple link-layer retransmission\\nprotocol to request the data again. The FEC\\nreduces the bit error rate from 1e-4 to 1e-6 and the\\nCRC then triggers retransmission with probability\\nof less than 1e-5. The latency addition due to FEC\\nis less than 2ns and the bandwidth reduction due\\nto retransmission less than 2%. The challenge for\\nEthernet are longer links leading to higher link-\\nlatencies.System issues\\nGrowing link-level and thus end-to-end laten-\\ncies can lead to more issues at the system level.\\nHigher latencies lead to higher buffer occupation\\nand energy consumption. Less obviously, higher\\nlatencies lead to less efﬁcient congestion control:\\nmessages that are transmitted faster than a sin-\\ngle RTT cannot beneﬁt from congestion control\\nmechanisms that rely on receiver-based notiﬁca-\\ntions. The bad case of incast with small messages\\nthus gets worse or at least more common because\\nthe size of a “small message” increases. Figure 3\\nshows the size of the bandwidth delay product\\nfor some realistic latencies in datacenters today\\nshowing that even 1 MiB messages can be con-\\nsidered “too small” for effective incast handling\\nby throttling the sender. Thus, problematic incast\\npatterns may become more comm', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 780: ('le RTT cannot beneﬁt from congestion control\\nmechanisms that rely on receiver-based notiﬁca-\\ntions. The bad case of incast with small messages\\nthus gets worse or at least more common because\\nthe size of a “small message” increases. Figure 3\\nshows the size of the bandwidth delay product\\nfor some realistic latencies in datacenters today\\nshowing that even 1 MiB messages can be con-\\nsidered “too small” for effective incast handling\\nby throttling the sender. Thus, problematic incast\\npatterns may become more common with higher\\nlatencies!\\nGoogle GCPAmazon Web Services\\nAzure\\nHPCTypical frontend network\\nFigure 3: Bandwidth-delay-product vs. Round-\\nTrip-Time (numbers from De Sensi et al. [18])).\\nIn other words, if a system can throttle the\\nsender fast enough, it can reduce the message\\nsize below which incast is a problem. This\\ncan be achieved by lowering latencies or hav-\\ning switches report incast congestion directly\\nto the source (without bouncing through the re-\\nceiver). Furthermore, if only very small messages\\ncreate bad-case incasts, switch buffers may sim-\\nply ingest them in the common case without even\\nrunning out of resources. This may be ampliﬁed\\nalong incast trees where multiple sets of switch\\nbuffers can ingest transient incast messages, of\\ncourse, potentially leading to congestion trees in\\nthe network. Such whole-systems issues remain\\nan open discussion but it seems that lower latency\\ngenerally simpliﬁes them.\\nOne also needs to pay attention to other\\naspects of the overall stack that can be quite\\ncomplex. For example, simple and clear (remote)\\n8\\nmemory semantics are tricky to deﬁne, reason\\nabout, and implement correctly [19]. Further-\\nmore, the fact that process-local virtual addresses\\nare exposed to remote hosts can be problematic\\nfor security and performance. One could think of\\na scheme with addressing relative to a memory\\nregion [20]. From a security perspective both\\nschemes have their weaknesses: exposing ad-\\ndresses allows learning about the remote process,\\nyet ﬁxed offsets are much simpler to guess for\\nan', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 781: (' example, simple and clear (remote)\\n8\\nmemory semantics are tricky to deﬁne, reason\\nabout, and implement correctly [19]. Further-\\nmore, the fact that process-local virtual addresses\\nare exposed to remote hosts can be problematic\\nfor security and performance. One could think of\\na scheme with addressing relative to a memory\\nregion [20]. From a security perspective both\\nschemes have their weaknesses: exposing ad-\\ndresses allows learning about the remote process,\\nyet ﬁxed offsets are much simpler to guess for\\nan attacker [17]. We note that these are general\\nproblems for all RDMA systems and not speciﬁc\\nto RoCE.\\nRouting and load balancing remains an open\\nchallenge—most HPC networks use packet-level\\nadaptive routing with relatively advanced in-\\nnetwork mechanisms [3] while most datacenter\\nnetworks use simple oblivious ECMP driven by\\nthe endpoints that change header ﬁelds to guide\\npath selection in very simple ways. The granular-\\nity of such ECMP load balancing in data centers\\nranges from traditionally full ﬂows to recently\\nconsidered ﬂowlets. Flowlets are consecutive se-\\nquences of packets that have a sufﬁcient gap\\nbetween them that ﬂowlets cannot pass each other\\neven when sent along different routes. Such gaps\\ncan be introduced by delaying packets or appear\\nnaturally. More recently, datacenter networks are\\nlooking towards more ﬁne-grained mechanisms\\nfor load balancing. Another challenge is the re-\\nquirement of some applications that messages\\nbe delivered in order. In general, out-of-order\\ngranularity and capabilities depend heavily on\\napplication requirements and the capabilities of\\nthe endpoint NICs. Finer and more out-of-order\\ncapabilities simplify network load balancing.\\nPredictions\\nBased on all these points, we predict that\\nacademia and industry will revisit datacenter Eth-\\nernet. This next-generation Ethernet will likely\\nsupport lossy and lossless transport modes for\\nRDMA connections to allow intelligent switch-\\nbuffer management. This will make the provi-\\nsioning of headroom buffer optional and avoid\\nthe other pr', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 782: (' depend heavily on\\napplication requirements and the capabilities of\\nthe endpoint NICs. Finer and more out-of-order\\ncapabilities simplify network load balancing.\\nPredictions\\nBased on all these points, we predict that\\nacademia and industry will revisit datacenter Eth-\\nernet. This next-generation Ethernet will likely\\nsupport lossy and lossless transport modes for\\nRDMA connections to allow intelligent switch-\\nbuffer management. This will make the provi-\\nsioning of headroom buffer optional and avoid\\nthe other problems such as victim ﬂows and\\ncongestion trees of lossless networking. Next-\\ngeneration Ethernet is also unlikely to adopt go-\\nback-n retransmission semantics but opt for more\\nﬁne-grained mechanisms such as selective ac-knowledgments. Furthermore, it will likely make\\ncongestion management part of the speciﬁcation.\\nSpecial attention will be paid to colocation with\\nother ﬂows, espcially in lossy trafﬁc classes. The\\nprotocols will be designed in a ﬂexible way\\nto support smart networking stacks and security\\nwill ﬁnally become a ﬁrst-class citizen. We may\\nalso see innovations in headers and reliability\\napproaches as well.\\nSuch modernizations will drive a new high-\\nperformance networking ecosystem for AI, HPC,\\nand storage systems that are at the heart of hyper-\\nscale datacenters. This development will conclude\\nthe convergence of HPC and datacenter networks!\\nREFERENCES\\n1. T. Hoeﬂer, A. Hendel, and D. Roweth, “The convergence\\nof hyperscale data center and high-performance com-\\nputing networks,” Computer , vol. 55, no. 7, pp. 29–37,\\n2022.\\n2. T. Hoeﬂer, T. Bonato, D. De Sensi, S. Di Girolamo,\\nS. Li, M. Heddes, J. Belk, D. Goel, M. Castro, and\\nS. Scott, “Hammingmesh: A network topology for large-\\nscale deep learning,” in Proceedings of the International\\nConference on High Performance Computing, Network-\\ning, Storage and Analysis , SC ’22, IEEE Press, 2022.\\n3. D. De Sensi, S. Di Girolamo, K. H. McMahon,\\nD. Roweth, and T. Hoeﬂer, “An in-depth analysis of\\nthe Slingshot interconnect,” in Proceedings of the Inter-\\nnational Co', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 783: ('o. 7, pp. 29–37,\\n2022.\\n2. T. Hoeﬂer, T. Bonato, D. De Sensi, S. Di Girolamo,\\nS. Li, M. Heddes, J. Belk, D. Goel, M. Castro, and\\nS. Scott, “Hammingmesh: A network topology for large-\\nscale deep learning,” in Proceedings of the International\\nConference on High Performance Computing, Network-\\ning, Storage and Analysis , SC ’22, IEEE Press, 2022.\\n3. D. De Sensi, S. Di Girolamo, K. H. McMahon,\\nD. Roweth, and T. Hoeﬂer, “An in-depth analysis of\\nthe Slingshot interconnect,” in Proceedings of the Inter-\\nnational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , SC ’20, IEEE Press,\\n2020.\\n4. Y . Li, R. Miao, H. H. Liu, Y . Zhuang, F . Feng, L. Tang,\\nZ. Cao, M. Zhang, F . Kelly, M. Alizadeh, and M. Yu,\\n“HPCC: High precision congestion control,” in Pro-\\nceedings of the ACM Special Interest Group on Data\\nCommunication , SIGCOMM ’19, (New Y ork, NY , USA),\\np. 44–58, Association for Computing Machinery, 2019.\\n5. Y . Zhu, H. Eran, D. Firestone, C. Guo, M. Lipshteyn,\\nY . Liron, J. Padhye, S. Raindel, M. H. Y ahia, and\\nM. Zhang, “Congestion control for large-scale rdma\\ndeployments,” in Proceedings of the 2015 ACM Confer-\\nence on Special Interest Group on Data Communica-\\ntion, SIGCOMM ’15, (New Y ork, NY , USA), p. 523–536,\\nAssociation for Computing Machinery, 2015.\\n6. R. Mittal, V. T. Lam, N. Dukkipati, E. Blem, H. Wassel,\\nM. Ghobadi, A. Vahdat, Y . Wang, D. Wetherall, and\\nD. Zats, “TIMEL Y: RTT-based congestion control for\\nthe datacenter,” SIGCOMM Comput. Commun. Rev. ,\\nvol. 45, p. 537–550, aug 2015.\\n9\\nIEEE Computer\\n7. Message Passing Interface Forum, MPI: a message\\npassing interface standard . Technical Report, Septem-\\nber 2012.\\n8. M. Besta and T. Hoeﬂer, “Slim ﬂy: A cost effective low-\\ndiameter network topology,” in Proceedings of the Inter-\\nnational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , SC ’14, p. 348–359,\\nIEEE Press, 2014.\\n9. Chelsio Communications, “A rocky road for RoCE.”\\nhttps://www.chelsio.com/wp-content/uploads/2011/05/\\nA-Rocky-Road-for-Roce-White-Paper-', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 784: ('\\n9\\nIEEE Computer\\n7. Message Passing Interface Forum, MPI: a message\\npassing interface standard . Technical Report, Septem-\\nber 2012.\\n8. M. Besta and T. Hoeﬂer, “Slim ﬂy: A cost effective low-\\ndiameter network topology,” in Proceedings of the Inter-\\nnational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , SC ’14, p. 348–359,\\nIEEE Press, 2014.\\n9. Chelsio Communications, “A rocky road for RoCE.”\\nhttps://www.chelsio.com/wp-content/uploads/2011/05/\\nA-Rocky-Road-for-Roce-White-Paper-0112.pdf, 2012.\\nAccessed: 2022-12-26.\\n10. R. Mittal, A. Shpiner, A. Panda, E. Zahavi, A. Krish-\\nnamurthy, S. Ratnasamy, and S. Shenker, “Revisiting\\nnetwork support for RDMA,” in Proceedings of the 2018\\nConference of the ACM Special Interest Group on\\nData Communication , SIGCOMM ’18, (New Y ork, NY ,\\nUSA), p. 313–326, Association for Computing Machin-\\nery, 2018.\\n11. P . Goyal, P . Shah, N. K. Sharma, M. Alizadeh, and T. E.\\nAnderson, “Backpressure ﬂow control,” in Proceedings\\nof the 2019 Workshop on Buffer Sizing , BS ’19, (New\\nY ork, NY , USA), Association for Computing Machinery,\\n2020.\\n12. “IEEE standard for ethernet,” IEEE Std 802.3-2018\\n(Revision of IEEE Std 802.3-2015) , pp. 1–5600, 2018.\\nSection Four, clause 44.\\n13. T. Khan, S. Rashidi, S. Sridharan, P . Shurpali, A. Akella,\\nand T. Krishna, “Impact of RoCE congestion con-\\ntrol policies on distributed training of DNNs,” in 2022\\nIEEE Symposium on High-Performance Interconnects\\n(HOTI) , (Los Alamitos, CA, USA), pp. 39–48, IEEE\\nComputer Society, aug 2022.\\n14. G. Kathareios, C. Minkenberg, B. Prisacari, G. Ro-\\ndriguez, and T. Hoeﬂer, “Cost-Effective Diameter-Two\\nTopologies: Analysis and Evaluation,” ACM, Nov. 2015.\\nIn Proceedings of the International Conference for\\nHigh Performance Computing, Networking, Storage and\\nAnalysis (SC15).\\n15. T. Hoeﬂer, S. Di Girolamo, K. Taranov, R. E. Grant,\\nand R. Brightwell, “Spin: High-performance streaming\\nprocessing in the network,” in Proceedings of the Inter-\\nnational Conference for High Performance Computing,\\nNetworking, Sto', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 785: (' G. Kathareios, C. Minkenberg, B. Prisacari, G. Ro-\\ndriguez, and T. Hoeﬂer, “Cost-Effective Diameter-Two\\nTopologies: Analysis and Evaluation,” ACM, Nov. 2015.\\nIn Proceedings of the International Conference for\\nHigh Performance Computing, Networking, Storage and\\nAnalysis (SC15).\\n15. T. Hoeﬂer, S. Di Girolamo, K. Taranov, R. E. Grant,\\nand R. Brightwell, “Spin: High-performance streaming\\nprocessing in the network,” in Proceedings of the Inter-\\nnational Conference for High Performance Computing,\\nNetworking, Storage and Analysis , SC ’17, (New Y ork,\\nNY , USA), Association for Computing Machinery, 2017.\\n16. K. Taranov, B. Rothenberger, A. Perrig, and T. Hoe-\\nﬂer, “SRDMA: Efﬁcient NIC-Based Authentication and\\nEncryption for Remote Direct Memory Access,” in Pro-\\nceedings of the 2020 USENIX Conference on Usenix\\nAnnual Technical Conference , USENIX ATC’20, (USA),USENIX Association, 2020.\\n17. B. Rothenberger, K. Taranov, A. Perrig, and T. Hoeﬂer,\\n“ReDMArk: Bypassing RDMA Security Mechanisms,” in\\nProceedings of the 2021 USENIX Security Symposium ,\\nUSENIX, 2021.\\n18. D. De Sensi, T. De Matteis, K. Taranov, S. Di Girolamo,\\nT. Rahn, and T. Hoeﬂer, “Noise in the clouds: Inﬂuence\\nof network performance variability on application scala-\\nbility,” 2022.\\n19. A. M. Dan, P . Lam, T. Hoeﬂer, and M. Vechev, “Modeling\\nand Analysis of Remote Memory Access Programming,”\\ninProceedings of the 2016 ACM SIGPLAN Interna-\\ntional Conference on Object-Oriented Programming,\\nSystems, Languages, and Applications , pp. 129–144,\\nACM, Nov. 2016.\\n20. B. W. Barrett, R. Brightwell, R. E. Grant, W. Schonbein,\\nS. Hemmert, K. Pedretti, K. Underwood, R. Riesen,\\nT. Hoeﬂer, M. Barbe, L. H. S. Filho, A. Ratchov, and\\nA. B. Maccabe, “The Portals 4.3 Network Program-\\nming Interface,” tech. rep., June 2022. Technical Report\\nSAND2022-8810, 2022.\\nTorsten Hoeﬂer is a Professor of Computer Science\\nat ETH Zürich. His research interests revolve around\\nlarge-scale high-performance systems and networks\\nfor HPC and AI. He is a fellow of the ACM and IEEE as\\nwell as a member of ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 786: (' W. Barrett, R. Brightwell, R. E. Grant, W. Schonbein,\\nS. Hemmert, K. Pedretti, K. Underwood, R. Riesen,\\nT. Hoeﬂer, M. Barbe, L. H. S. Filho, A. Ratchov, and\\nA. B. Maccabe, “The Portals 4.3 Network Program-\\nming Interface,” tech. rep., June 2022. Technical Report\\nSAND2022-8810, 2022.\\nTorsten Hoeﬂer is a Professor of Computer Science\\nat ETH Zürich. His research interests revolve around\\nlarge-scale high-performance systems and networks\\nfor HPC and AI. He is a fellow of the ACM and IEEE as\\nwell as a member of Academia Europaea. For more\\ninformation visit http://htor.ethz.ch.\\nDuncan Roweth is a Senior Distinguished Technolo-\\ngist in the Slingshot Business Unit CTO ofﬁce at HPE.\\nHe joined HPE in Jan 2020 with the acquisition of\\nCray. While at Cray he worked on three generations of\\nHPC network. He has been in a leading ﬁgure in the\\nSlingshot program since its inception. Duncan holds\\na Ph.D. from the University of Edinburgh.\\nKeith Underwood is a Senior Distinguished Tech-\\nnologist at Hewlett Packard Enterprise. He is an ar-\\nchitect in the Slingshot program focusing on network\\ninterface architecture.\\nRobert Alverson is a Distinguished Technologist\\nat Hewlett Packard Enterprise. Bob has a Master of\\nScience degree from Stanford University in Electrical\\nEngineering. He has a long history in HPC inter-\\nconnects and was a lead architect of Slingshot high\\nspeed network interconnect, which combines HPC\\nperformance with Ethernet compatibility in a dragonﬂy\\nnetwork.\\nMark Griswold is a Distinguished Engineer and\\n10\\nSwitch Architect at Broadcom. His primary research\\ninterests are high-performance interconnects, com-\\nputer architecture, device architecture and workloads.\\nHe obtained a B.S. in Mathematics & Computer Sci-\\nence and a B.S. in Computer Engineering, both from\\nCarnegie Mellon University.\\nVahid Tabatabaee is a Distinguished Engineer\\nand Switch Architect at Broadcom. He received\\nhis Ph.D. from the University of Maryland, College\\nPark. His research interests are in algorithm de-\\nsign and performance analysis for congestion co', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 787: ('ect at Broadcom. His primary research\\ninterests are high-performance interconnects, com-\\nputer architecture, device architecture and workloads.\\nHe obtained a B.S. in Mathematics & Computer Sci-\\nence and a B.S. in Computer Engineering, both from\\nCarnegie Mellon University.\\nVahid Tabatabaee is a Distinguished Engineer\\nand Switch Architect at Broadcom. He received\\nhis Ph.D. from the University of Maryland, College\\nPark. His research interests are in algorithm de-\\nsign and performance analysis for congestion control\\nand trafﬁc management in networks. His email is\\nvahid.tabatabaee@broadcom.com.\\nMohan Kalkunte is the Vice President of Architec-\\nture and Technology responsible for the architecture\\ndevelopment of switches for Enterprise, Data Center,\\nand Service Provider markets at Broadcom. He is an\\nIEEE fellow and has over 150 patents. His email is\\nmohan.kalkunte@broadcom.com.\\nSurendra Anubolu is a Distinguished Engineer at\\nBroadcom in the Switch Group. He is currently work-\\ning on benchmarking and enhancing performance of\\ndistributed AI work loads and telemetry for network\\napplications. He holds an MS from Indian Institute of\\nScience, Bangalore.\\nSiyuan Shen received his MEng degree in Com-\\nputing from Imperial College London and is currently\\na Ph.D. student in the Scalable Parallel Computing\\nLab at ETH Zurich. His primary research interests\\ninclude distributed computing, networking, and dis-\\ntributed machine learning.\\nMoray McLaren is a Principal Engineer at Google.\\nHis research interests include future data center\\nnetworking, and interconnects for High Performance\\nComputing and Machine Learning. His e-mail is\\nmoray@google.com.\\nAbdul Kabbani is a Principal Network HW Archi-\\ntect at Microsoft. His research interests include con-\\ngestion management algorithms in high-performance\\nand frontend networking. He received his PhD from\\nStanford University.\\nSteve Scott is a Technical Fellow and Corporate\\nVice President of Azure Hardware Architecture at\\nMicrosoft. His research interests are in high perfor-\\nmance system and networ', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 788: ('networking, and interconnects for High Performance\\nComputing and Machine Learning. His e-mail is\\nmoray@google.com.\\nAbdul Kabbani is a Principal Network HW Archi-\\ntect at Microsoft. His research interests include con-\\ngestion management algorithms in high-performance\\nand frontend networking. He received his PhD from\\nStanford University.\\nSteve Scott is a Technical Fellow and Corporate\\nVice President of Azure Hardware Architecture at\\nMicrosoft. His research interests are in high perfor-\\nmance system and network architecture. He is an\\nIEEE and ACM Fellow, and received his PhD from the\\nUniversity of Wisconsin at Madison.Appendix\\nDerivation of Frame Loss Probability\\nTo measure the performance of a speciﬁc\\nRS(n; k)scheme under the assumption that a\\nrandom-error model is used, we need to ﬁnd\\nthe probability of losing an Ethernet frame given\\na pre-deﬁned input bit error rate ( BER in) and\\nthe number of hops in the network. As a ﬁrst\\nstep, we can calculate the input symbol error rate\\n(SER in), i.e. the probability of an FEC symbol\\nbeing corrupted, as:\\nSER in= 1\\x00(1\\x00BER in)m\\n\\x19m\\x01BER in(for small BER in)\\nwhere mis the number of bits in an FEC symbol.\\nThe sub-expression (1\\x00BER in)mrepresents the\\nprobability of having no errors in a symbol.\\nThe number of symbols in an FEC codeword\\nthat can be corrected by a RS(n; k)scheme is\\nexpressed as t=bn\\x00k\\n2c, which signiﬁes that after\\ndecoding, the uncorrectable codeword error rate\\n(CER ) is:\\nCER =nX\\ni=t+1 \\nn\\ni!\\nSERi\\nin(1\\x00SER in)n\\x00i\\n|{z }\\nProbability of having exactly i\\ncorrupted symbols in a codeword\\nSince an Ethernet frame can only be properly\\nreceived when all of its constituent codewords are\\ncorrectable, we can compute the frame error rate\\n(FER ) as:\\nFER = 1\\x00(1\\x00CER )1+bframe size\\ncodeword sizec\\n\\x19\\x10\\n1 +bframe size\\ncodeword sizec\\x11\\n\\x01CER\\nwhere the average number of codewords that a\\nframe occupies is denoted by 1 +bframe size\\ncodeword sizec.\\nAfter obtaining the FER per link, the frame\\nloss probability Pis simply:\\nP= 1\\x00(1\\x00FER )hops +1\\n\\x19(hops + 1)\\x01FER\\n11', 'Datacenter Ethernet and RDMA- Issues at Hyperscale.pdf'), 789: ('Scientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         41 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  THE POTENT IAL AND CHALLENGES OF \\nQUANTUM TECHNOLOGY  IN MODERN ERA  \\nKhandakar Akhter Hossain, PhD  \\n \\nDOI: 10.31364/SCIRJ/v 11.i6.2023.P0623 953 \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\n \\nAbstract: Information is encoded in bits, such as 0 or 1, in a classical computer, whereas a quantum computer (QC) uses \\nqubits, which can be in a superposition of several states. Compared to traditional computers, QCs have several  advantages in terms \\nof processing power and speed. A new area of physics and engineering called quantum technology (QT) is bas ed on quantum -\\nmechanical features, including quantum entanglement, quantum superposition, quantum tunneling, etc. The second quantum \\nrevolution is characterized by the development of individual quantum systems, such as atoms, ions, electrons, photons, mole cules, \\nor even quasi -particles, that enable measurement accuracy to be increased to the conventional quantum limit at quantum scales. \\nFuture warfare is one of the many human activities that QT has the potential to influence. It is an emerging and potential ly frightening \\nfield. Quantum computing has the potential to improve a number of disciplines, including ship design, chemistry, machine lear ning, \\nand cryptography. IBM recently developed the IBM Osprey, a 433 qubit QC processor. Future warfare will be domi nated by QTs \\nin many ways. Future warfare will be transformed by quantum sensing in the areas of detection, monitoring, control, and C5IRS .It \\nis somewhat depressing because both QC and QT face few unique obstacles, but it is possible to predict that in the  future, QTs will \\nbe used in the communication, precision, intelligence, space, medical, chemical, commercial, service, and military industries . As a \\nresult', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 790: ('IBM recently developed the IBM Osprey, a 433 qubit QC processor. Future warfare will be domi nated by QTs \\nin many ways. Future warfare will be transformed by quantum sensing in the areas of detection, monitoring, control, and C5IRS .It \\nis somewhat depressing because both QC and QT face few unique obstacles, but it is possible to predict that in the  future, QTs will \\nbe used in the communication, precision, intelligence, space, medical, chemical, commercial, service, and military industries . As a \\nresult, the effective and efficient employment of QTs will bring about revolutionary change in future warf are and the military \\nindustry.  \\n   \\nKey Words:  Qubits, cryptography , nano -optics, machine learning,  QKD, QIN, PQC  \\n \\nINTRODUCTION  \\n1. Decentralization and the loss of nations\\' monopoly on war1  characterize today\\'s fourth generation advanced warfare.  \\nAs we all know, powerful nations\\' defense forces typically have access to cutting -edge military technology. 2   Quantum \\ntechnology (QT) will play a major role and may imperil the future military situation. QT is a well -known modern technology \\nthat emerged from the second quantum revolution. At the moment, the first quantum revolution has resulted in technology \\nthat everyone is familiar with, such as nuclear power, semiconductors, lasers, magnetic resonance imaging, modern \\ncommunication technologies, digital cameras, and other imaging equipment, and so on. Nuclear and laser weapons are being \\neffectively integrated and tested today.  The ability to manipulate and control individual quantum systems, su ch as atoms, ions, \\nelectrons, photons, molecules, or different quasi -particles, is what is known as the \"second quantum revolution.\" This limit is \\nthe upper bound on the precision of measurements made at quantum scales. 3  Entanglement, superposition, and tunneling are \\na few QTs that have a connection to quantum characteristics. The greatest and most difficult objective for quantum properties  \\nis the quantum computer (QC). Information is encoded in ', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 791: ('manipulate and control individual quantum systems, su ch as atoms, ions, \\nelectrons, photons, molecules, or different quasi -particles, is what is known as the \"second quantum revolution.\" This limit is \\nthe upper bound on the precision of measurements made at quantum scales. 3  Entanglement, superposition, and tunneling are \\na few QTs that have a connection to quantum characteristics. The greatest and most difficult objective for quantum properties  \\nis the quantum computer (QC). Information is encoded in bits with values of 0 or 1 in a traditional computer.  A qubit —the \\nmemory component in a quantum computer —can exist in a superposition of several states. 4  As a result, although n qubits \\ncan transport information on 2n numbers concurrently, n classical bits can only convey inform ation on 1 number at a time. \\nThere aren\\'t many obstacles to achieving the QC goals of qubit identification, production, and error repair. According to Nie ls \\nBohr, making predictions, particularly concerning the future, 5 is very difficult. However, quantu m-based technologies are \\nprobably going to simplify predictions and change certain crucial parts. For these reasons, it is crucial that all parties —\\nresearchers, businesspeople, government officials, and foundations — push strongly to realize the quantum tra nsition.6 \\n \\n2. It is true that fourth -generation modern warfare is characterized by decentralization7 and the loss of states\\' monopoly on \\nwar. Advanced militaries typically have access to state -of-the-art military technologies, including emerging quantum technologies.8 \\nQuantum computing is a promising technology that offers exponential speed -ups in computation compared to classical computing. \\nIt has the potential to revolutionize various fields, including cryptography, optimization, and machine learning. Quantum \\ntechnologies, including quantum sensing and quantum communication, can also have significant implications in the realm of \\nwarfare.  The recent conflict between Russia and Ukraine, which involved traditio', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 792: ('technologies, including emerging quantum technologies.8 \\nQuantum computing is a promising technology that offers exponential speed -ups in computation compared to classical computing. \\nIt has the potential to revolutionize various fields, including cryptography, optimization, and machine learning. Quantum \\ntechnologies, including quantum sensing and quantum communication, can also have significant implications in the realm of \\nwarfare.  The recent conflict between Russia and Ukraine, which involved traditional kinetic warfare as well as large -scale cybe r \\nwarfare, highlighted the interconnected nature of modern threats. In such scenarios, communication networks and space -based \\ncapabilities play a crucial role. The denial of existing communication networks can have a significant impact on military ope rations. \\nIn this analytical article, you plan to explore the chronological development of quantum technologies, the working principles  of \\nquantum computing, their potential and prospects, and the challenges associated with quantum computing. Additionally, you ai m to \\ndiscuss the utilization of quantum technologies in intelligence and future warfare.  It is important to conduct thorough research and \\ncollect information from reliable sources to ensure the accuracy and credibility of the article. By examining the curre nt state and \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         42 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  potential of quantum technologies, along with their applications in intelligence and warfare, you can provide valuable insigh ts into \\nthe evolving landscape of modern conflicts.  \\n \\nCHRONOLOGICAL DEVELOPMENT OF QT \\n3. You have provided a concise an d accurate description of the dual nature of particles, such as light, electrons, and atoms. \\nThe wave -particle duality is a fundamental concept in quantum me', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 793: (\"/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  potential of quantum technologies, along with their applications in intelligence and warfare, you can provide valuable insigh ts into \\nthe evolving landscape of modern conflicts.  \\n \\nCHRONOLOGICAL DEVELOPMENT OF QT \\n3. You have provided a concise an d accurate description of the dual nature of particles, such as light, electrons, and atoms. \\nThe wave -particle duality is a fundamental concept in quantum mechanics, and it suggests that particles can exhibit both wave -like \\nand particle -like behavior depen ding on the experimental conditions. When light passes through two slits, it shows interference \\npatterns characteristic of a wave. However, when it interacts with a conducting plate of metal, it behaves like a particle, a s individual \\nphotons are absorbed o r scattered by the electrons in the metal. This dual nature is not limited to light but is observed in all quantum \\nparticles. It is difficult to precisely quantify the wave -like or particle -like behavior of a particle, but quantum mechanics provides a \\nmath ematical framework to describe and predict their behavior. Max Planck's work on quanta, which led to the development of \\nquantum theory, revolutionized our understanding of energy. Previously, energy was thought to be continuous and flowing in wa ves. \\nHoweve r, quantum theory introduced the concept of energy being quantized into discrete packets or particles. Analogously, we can \\nthink of the wave/quantum9 idea in terms of analog and digital systems. In the analog sense, energy flows continuously without \\nspeci fic quantity, similar to waves. In the quantum view, energy is quantized, and it comes in discrete, indivisible units called quanta \\nor photons. Each photon carries a specific amount of energy, and the brightness of light depends on the number of photons, n ot their \\nindividual energy.Quantum theory indeed presents some strange and counterintuitive aspects of reality. Although it may be \\ncha\", 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 794: (\"e/quantum9 idea in terms of analog and digital systems. In the analog sense, energy flows continuously without \\nspeci fic quantity, similar to waves. In the quantum view, energy is quantized, and it comes in discrete, indivisible units called quanta \\nor photons. Each photon carries a specific amount of energy, and the brightness of light depends on the number of photons, n ot their \\nindividual energy.Quantum theory indeed presents some strange and counterintuitive aspects of reality. Although it may be \\nchallenging to fully comprehend or explain these phenomena, the theory has been extensively tested and has provided remarkabl e \\npredictive power and practical applications.Accepting the weirdness of quantum science, even without fully understanding it, is an \\nessential aspect of scientific progress. It reminds us that the nature of reality can be deeply counterintuitive and encour ages us to \\ncontinue exploring and uncovering the mysteries of the quantum world.  \\n \\n4. Quantum technology (QT) is indeed an emerging field that builds upon the principles of quantum mechanics, utilizing \\nproperties such as quantum entanglement, quantum superp osition, and quantum tunneling in individual quantum systems. These \\nproperties are harnessed for practical applications across various domains.In the early 20th century, the wave theory of ligh t faced \\nsignificant challenges, and Einstein's explanation of t he photoelectric effect played a crucial role in shaping our understanding of \\nquantum phenomena. The work of Louis de Broglie, Niels Bohr, and Einstein contributed to the development of quantum theory, \\nwhich highlighted the uncertainty and indeterminacy of  electron motion, the concept of wave function, quantum tunneling, and the \\nphenomenon of entanglement. Quantum theory revealed that both electromagnetic radiation and electrons exhibit particle -like \\nbehavior.If string theory is valid, it suggests that the wave concept extends beyond a mere tool for modeling the world and implies \\nthat the universe, despite its complex\", 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 795: ('roglie, Niels Bohr, and Einstein contributed to the development of quantum theory, \\nwhich highlighted the uncertainty and indeterminacy of  electron motion, the concept of wave function, quantum tunneling, and the \\nphenomenon of entanglement. Quantum theory revealed that both electromagnetic radiation and electrons exhibit particle -like \\nbehavior.If string theory is valid, it suggests that the wave concept extends beyond a mere tool for modeling the world and implies \\nthat the universe, despite its complexity, can be understood as a vast network of interacting waves. 10 The foundation of QT lies in \\nquantum mechanics, a discipline that has been st udied for over a century. The initial applications of quantum mechanics, referred \\nto as Quantum Revolution 1.0, have had a profound impact on society. Examples include nuclear fission, lasers, semiconductors , \\ndigital cameras, and their effects on various f ields such as military technology, atomic weapons, computing, and navigation. 11 The \\nfirst-generation quantum networks have primarily utilized Quantum Key Distribution (QKD) for secure communication. QKD offers \\nadvantages over conventional asymmetric encryption, also known as public -key cryptography, as any attempt to intercept the \\ncommunication would be instantly detectable.The next generation of quantum networks, often referred to as Quantum Information \\nNetworks (QIN) or quantum internet, go beyond QKD and enable the distribution of entangled qubits. 12 These networks have the \\npotent ial to revolutionize information processing, communication, and computation by leveraging the unique properties of \\nentanglement.As QT continues to advance, it holds promise for transformative applications in various fields, ranging from \\ncryptography and co mmunication to computing and sensing. The development of practical quantum technologies and the realization \\nof large -scale quantum networks are active areas of research and development that aim to unlock the full potential of quantum \\nmechanics for practica l use.  \\n \\n \\n', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 796: (' information processing, communication, and computation by leveraging the unique properties of \\nentanglement.As QT continues to advance, it holds promise for transformative applications in various fields, ranging from \\ncryptography and co mmunication to computing and sensing. The development of practical quantum technologies and the realization \\nof large -scale quantum networks are active areas of research and development that aim to unlock the full potential of quantum \\nmechanics for practica l use.  \\n \\n \\n5. The first quantum revolution, known as Quantum Revolution 1.0, gave rise to significant advancements such as nuclear \\nweapons, nuclear energy, and classical computers. Currently, laser weapons are being developed and tested, 13 representing the \\nongoing progress in military technology.The second quantum revolution is characterized by the manipulation and control of \\nindividual quantum systems, enabling the achievement of measurement accuracy at quantum scales. 14 Quantum technology (QT) \\nis expected to enhance measurement capabilities, sensing, precision, and computational power, revolutionizing future military  \\ntechnologies. 15 It is worth noting that many quantum technologies have dual -use potential, meaning they can have applications both \\nin the military16 and civilian sectors.The increasing likelihood of realizing quantum technologies has led to various studies and \\nrecommendations emphasizing their importance. 17  We are now entering Quantum Revolution 2.0, where  we are harnessing the full \\nrange of quantum physics. This revolution involves exploiting the behavior of individual quantum systems such as electrons, a toms, \\nnuclei, molecules, and quasi -particles. In the realm of defense, quantum technologies are anticip ated to enhance existing sensing, \\ncommunication, and computing capabilities rather than introducing fundamentally new weapons like nuclear and laser weapons di d. \\nWhile many aspects of quantum technology are still in the realm of fundamental research, sever al applications relevant t', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 797: ('of quantum physics. This revolution involves exploiting the behavior of individual quantum systems such as electrons, a toms, \\nnuclei, molecules, and quasi -particles. In the realm of defense, quantum technologies are anticip ated to enhance existing sensing, \\ncommunication, and computing capabilities rather than introducing fundamentally new weapons like nuclear and laser weapons di d. \\nWhile many aspects of quantum technology are still in the realm of fundamental research, sever al applications relevant to defense18  \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         43 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  are foreseen. QTs are a crucial part of long -term defense planning for advanced nations including the USA, China, the UK, France, \\nAustralia, India, Russia, Canada, and others. 19 It is fascinating to note that the fou nders of quantum mechanics did not envision \\nadvances in computation or the invention of the transistor. However, today we have a strong belief that advancements in the f ield of \\natomic optics and nano -optics20 will significantly progress as we approach abso lute zero temperature.The potential of quantum \\neffects extending to entire human beings is an intriguing possibility for the future. However, it is important to note that t he realization \\nof such advancements is subject to ongoing research and technological  development.  \\n \\nPOTENTIALS OF QUANTUM COMPUTING  \\n6. Quantum computing has the potential to revolutionize various fields, including cryptography, chemistry, machine learning, \\noptimization and ship design. Today quantum computing potential has recognized in several aspects.21 However, these potentials of \\nquan tum computing are just the beginning, and as the technology continues to advance, we can expect to see more applications and \\nuse cases emerging in various fields.  \\na. Cryptography. QC', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 798: ('echnological  development.  \\n \\nPOTENTIALS OF QUANTUM COMPUTING  \\n6. Quantum computing has the potential to revolutionize various fields, including cryptography, chemistry, machine learning, \\noptimization and ship design. Today quantum computing potential has recognized in several aspects.21 However, these potentials of \\nquan tum computing are just the beginning, and as the technology continues to advance, we can expect to see more applications and \\nuse cases emerging in various fields.  \\na. Cryptography. QCs have the potential to break many of the currently used encryption techni ques, such as the RSA and \\nelliptic curve cryptography.22 However, QCs can also be used to develop new encryption techniques that are secure against attacks \\nby classical computers.  \\nb. Chemistry. Quantum computers can be used to simulate the behavior of mole cules and chemical reactions, which is \\ncurrently not feasible with classical computers. This can help accelerate the development of new drugs and materials.23 \\nc. Machine Learning. QCs can be effectively used to perform machine learning tasks, such as clust ering, classification, and \\nregression, at a faster speed than classical computers. This can lead to the development of more accurate and efficient machi ne-\\nlearning models.24 In future help medical sector very widely.  \\nd. Optimization. QCs can be used to sol ve optimization problems, like traveling salesman problem and the knapsack problem, \\nfaster than classical computers. This can lead to more efficient and optimized solutions in various fields, such as logistics  and supply \\nchain management.25 \\ne. Big Data. Qu antum computing has the potential to analyze and process very big datasets at a faster speed than classical \\ncomputers. This can lead to the development of more accurate and efficient data analysis techniques.26 \\nf. Ship Design.  Computing Fluid Dynamics or C FD Analysis is used in ship design and ship performance testing ground.  \\nQuantum computing will be more useful to speed up and better analytical process of s', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 799: ('utions in various fields, such as logistics  and supply \\nchain management.25 \\ne. Big Data. Qu antum computing has the potential to analyze and process very big datasets at a faster speed than classical \\ncomputers. This can lead to the development of more accurate and efficient data analysis techniques.26 \\nf. Ship Design.  Computing Fluid Dynamics or C FD Analysis is used in ship design and ship performance testing ground.  \\nQuantum computing will be more useful to speed up and better analytical process of ship design field.27 Complicated ship design \\nsoftware can perform better by using quantum computing system.   \\n \\nPROSPECTS OF QUANTUM COMPUTING  \\n7. The future prospects  of quantum computing are very promising. As the technology continues to improve and more powerful \\nquantum computers are developed, there is great potential for quantum computing to revolutionize several fields and industrie s. \\na. Material Science.  One of t he most promising areas of application is in the field of materials science. QCs can ‘simulate the \\nbehavior of molecules and materials at the quantum level, which could enable the discovery of new materials with novel proper ties \\nthat could have important a pplications in areas such as electronics, energy storage, and renewable energy. This could lead to \\ninventions in areas such as battery technology and solar power.’28 \\nb. Transformation of Industries.  Quantum computing has the potential to transform several industries, such as finance \\nand logistics29. QCs can be used to optimize complex financial portfolios and trading strategies, and to solve logistics problems such \\nas route optimization and supply chain management.  \\nc. Application of Quantum Machine Learning . The development of quantum machine learning algorithms has the potential \\nto revolutionize several areas, including image and speech recognition, natural language processing, and recommendation syste ms30. \\nQuantum machine learning algorithms could also be used to analyze large datasets in fields such as healthcare and fi', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 800: (\"complex financial portfolios and trading strategies, and to solve logistics problems such \\nas route optimization and supply chain management.  \\nc. Application of Quantum Machine Learning . The development of quantum machine learning algorithms has the potential \\nto revolutionize several areas, including image and speech recognition, natural language processing, and recommendation syste ms30. \\nQuantum machine learning algorithms could also be used to analyze large datasets in fields such as healthcare and finance, leading \\nto new insights and innovations.31 \\nd. Simulate and Analyze Data.  There is great potential for quantum computing to be used to solve some of the most \\npressing problems facing h umanity, such as climate change and disease. Quantum computers could be used to ‘simulate the effects \\nof climate change and to design new materials and technologies to combat it. They could also be used to analyze genomic data and \\nto develop new treatments  for diseases such as cancer and Alzheimer's.’32 \\n \\nPRESENT QUANTUM COMPUTERS (QCs)  \\n8. Several companies and research institutions have developed QCs. One of the most well -known quantum computers is the \\nD-Wave System, which is a commercial QC. Another exampl e is IBM's Quantum Experience, which is a cloud -based quantum \\ncomputing platform that allows users to experiment with quantum algorithms. IBM has made several significant contributions to  \\nthe field of quantum computing. It is one of the leading companies i n the development of QCs. IBM has made significant progress \\nin increasing the number of qubits in their quantum computers, with discrete improving the performance and stability of their  \\nsystems.33 In 2016, IBM launched the IBM Quantum Experience, which all owed users to access IBM's quantum computing \\nhardware over the internet. ‘This platform has enabled researchers, developers, and students to experiment with quantum compu ting \\nand develop new algorithms and applications. IBM has also developed several QCs w ith increasing numbers of qubits.  \\n \\n\", 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 801: (\"cant progress \\nin increasing the number of qubits in their quantum computers, with discrete improving the performance and stability of their  \\nsystems.33 In 2016, IBM launched the IBM Quantum Experience, which all owed users to access IBM's quantum computing \\nhardware over the internet. ‘This platform has enabled researchers, developers, and students to experiment with quantum compu ting \\nand develop new algorithms and applications. IBM has also developed several QCs w ith increasing numbers of qubits.  \\n \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         44 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.   \\n \\nFigure 2: IBM Osprey; IBM’s new 433 -quantum bit (qubit) processor34 \\n \\n9. In 2017, IBM announced the development of a 50 -qubit QC, which was a significant milestone in the field of quantum \\ncomputing.’35IBM is a significant contributor to the development of quantum computing and has made significant progress in \\nincreasing the number of qubits and improving the performance and stability of their QCs. Very recently IBM has invented 433 \\nqubit QC  processor (IBM Osprey ) and which has been shown in figure 2 above . InNew York, USA on Nov 9’ 2022 during IBM \\nQuantum Summit 2022 , Dr. Darío Gil, Senior VP, IBM and Director of Research has declared, ‘the new 433 qubit 'Osprey' processor \\nbrings us a step closer to the point whe re quantum computers will be used to tackle previously unsolvable problems. We are \\ncontinuously scaling up and advancing our quantum technology across hardware, software and classical integration to meet the \\nbiggest challenges of our time, in conjunction w ith our partners and clients worldwide. This work will prove foundational for the \\ncoming era of quantum -centric supercomputing. We continue to increase the scale of quantum systems and make them simpler to \\nuse, we will continue to see adoption and growt\", 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 802: ('quantum computers will be used to tackle previously unsolvable problems. We are \\ncontinuously scaling up and advancing our quantum technology across hardware, software and classical integration to meet the \\nbiggest challenges of our time, in conjunction w ith our partners and clients worldwide. This work will prove foundational for the \\ncoming era of quantum -centric supercomputing. We continue to increase the scale of quantum systems and make them simpler to \\nuse, we will continue to see adoption and growth o f the quantum industry in future.’36 \\n \\n10. Quantum technology has emerged as a revolutionary field with the potential to revolutionize various sectors, including \\ncomputing, cryptography, communication, sensing, and more. By leveraging the principles of quantum mechanics, such as \\nsuperposition and entanglement, quantum technology promises exponential improvements over classical systems. However, the \\nroad to harnessing its full potential is fraught with numerous challenges that need to be ove rcome. In this article, we will explore \\nsome of the key challenges faced by quantum technology, shedding light on the complex journey toward its widespread \\nimplementation.  \\n \\na. Quantum Computing . Building Powerful Quantum Computers Quantum computing holds imme nse promise for \\nsolving complex computational problems exponentially faster than classical computers. However, the development of \\npractical, error -resistant, and scalable quantum computers remains a major challenge. Quantum bits or qubits are extremely \\nsensitive to environmental noise and prone to errors. Achieving quantum error correction, improving qubit stability, and \\ndeveloping fault -tolerant systems are key areas of focus for researchers37. Moreover, the number of qubits needs to be \\nsignificantly incre ased to perform computations at a useful scale, requiring innovative qubit fabrication, connectivity, and \\ncontrol methods.38 Overcoming these challenges will pave the way for quantum computers to tackle real -world problems \\nmore efficiently.  \\n', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 803: ('y \\nsensitive to environmental noise and prone to errors. Achieving quantum error correction, improving qubit stability, and \\ndeveloping fault -tolerant systems are key areas of focus for researchers37. Moreover, the number of qubits needs to be \\nsignificantly incre ased to perform computations at a useful scale, requiring innovative qubit fabrication, connectivity, and \\ncontrol methods.38 Overcoming these challenges will pave the way for quantum computers to tackle real -world problems \\nmore efficiently.  \\n \\nb. Quantum Commun ication . Securing Data Transmission Quantum communication, enabled by quantum key \\ndistribution (QKD), offers unprecedented levels of security for transmitting sensitive information. QKD relies on the \\nprinciples of quantum mechanics to ensure the absolute i ntegrity and confidentiality of data transmission.39 However, there \\nare several challenges associated with implementing practical quantum communication systems. One of the primary \\nhurdles is the limited range of QKD systems, which typically operate over re latively short distances due to signal \\ndegradation and loss.40 Developing methods for long -range QKD and establishing reliable quantum networks are ongoing \\nresearch areas. Additionally, ensuring scalability, cost -effectiveness, and integration of quantum communication \\ntechnologies with existing infrastructure pose si gnificant challenges for widespread adoption.41 \\n \\nc. Quantum Cryptography . Protecting Against Quantum Attacks While quantum technology brings the promise of \\nadvanced security measures, it also poses threats to classical cryptographic systems. The development o f quantum \\ncomputers with sufficient computational power could potentially break many of the encryption algorithms used today, \\nrendering sensitive information vulnerable to attacks.42 This highlights the urgent need for quantum -resistant cryptographic \\nsolut ions, also known as post -quantum cryptography (PQC).43 However, transitioning to PQC involves significant \\n\\nScientific Research Jo urnal (SCIRJ), V', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 804: ('dvanced security measures, it also poses threats to classical cryptographic systems. The development o f quantum \\ncomputers with sufficient computational power could potentially break many of the encryption algorithms used today, \\nrendering sensitive information vulnerable to attacks.42 This highlights the urgent need for quantum -resistant cryptographic \\nsolut ions, also known as post -quantum cryptography (PQC).43 However, transitioning to PQC involves significant \\n\\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         45 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  challenges, including the need for new algorithms, cryptographic standards, and widespread adoption across different \\nsystems.44 Addressing these chall enges is crucial to safeguard sensitive information in the era of quantum computing.  \\n \\nd. Quantum Sensing . Enhancing Precision Measurement Quantum sensing offers remarkable advancements in \\nprecision measurement, enabling applications in areas such as navigatio n, imaging, medical diagnostics, and more. \\nQuantum sensors, leveraging properties such as entanglement and superposition, can achieve unprecedented levels of \\nsensitivity and accuracy.45 Nonetheless, several obstacles impede the widespread adoption of quant um sensing \\ntechnologies. These challenges include reducing the sensitivity of quantum sensors to environmental factors, developing \\nrobust and cost -effective sensor designs, and integrating them into existing measurement frameworks.46 Overcoming these \\nhurdl es will unlock the potential of quantum sensing, revolutionizing fields that rely on precise measurements.  \\n \\ne. Quantum Materials . Designing and Controlling Quantum Systems Quantum technology heavily relies on the \\ndevelopment of novel materials with tailored quantum properties. Designing and controlling quantum systems at the atomic \\nand molecular le', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 805: ('mental factors, developing \\nrobust and cost -effective sensor designs, and integrating them into existing measurement frameworks.46 Overcoming these \\nhurdl es will unlock the potential of quantum sensing, revolutionizing fields that rely on precise measurements.  \\n \\ne. Quantum Materials . Designing and Controlling Quantum Systems Quantum technology heavily relies on the \\ndevelopment of novel materials with tailored quantum properties. Designing and controlling quantum systems at the atomic \\nand molecular level present formidable challenges in material science and engineering.47 The discovery and synthesis of \\nmaterials that exhibit desired quantum properties, such as long coherence times for qubits or efficient photon emission for \\nquantum communication, remain a significant hurdle.48 Additionally, integrating these materials into practical devices \\nwhile maintaining their quantum properties poses additional chal lenges. Extensive research efforts are focused on \\nadvancing our understanding of quantum materials to overcome these challenges and drive technological progress.  \\n \\nf. Timekeepers . Harnessing Quantum Precision in Timekeeping One promising application of quantum  technology \\nis in the field of timekeeping. Traditional atomic clocks already provide remarkable precision, but quantum technology \\nopens up new possibilities for even higher accuracy. Quantum clocks based on the behavior of trapped ions or single atoms \\nshow great potential in improving timekeeping precision by exploiting quantum coherence and superposition. However, \\nchallenges such as environmental disturbances, atom loss, and coherence time limitations need to be addressed to realize \\nthe full potential of quantum timekeepers.49 \\n \\ng. Quantum Magnetic Field Sensors . Pushing the Limits of Sensitivity Quantum magnetic field sensors hold \\npromise for a wide range of applications, including detecting brain activity, monitoring geological activities, and improving  \\nmagn etic resonance imaging (MRI) technology. These sensors, which utilize the', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 806: ('and superposition. However, \\nchallenges such as environmental disturbances, atom loss, and coherence time limitations need to be addressed to realize \\nthe full potential of quantum timekeepers.49 \\n \\ng. Quantum Magnetic Field Sensors . Pushing the Limits of Sensitivity Quantum magnetic field sensors hold \\npromise for a wide range of applications, including detecting brain activity, monitoring geological activities, and improving  \\nmagn etic resonance imaging (MRI) technology. These sensors, which utilize the quantum properties of atoms or solid -state \\nsystems, offer the potential for unprecedented sensitivity and resolution. However, challenges related to reducing noise, \\nenhancing signal -to-noise ratios, and improving scalability need to be addressed to fully exploit the capabilities of quantum \\nmagnetic field sensors.50 \\n \\nh. Electrical Quantum Metrology . Advancing Precision Measurements in Electrical Metrology Quantum \\ntechnology can also revol utionize electrical metrology by enabling highly precise measurements of electrical quantities. \\nElectrical quantum metrology leverages quantum phenomena to achieve measurements with extremely low uncertainties, \\nsurpassing the limitations of classical metro logy. However, challenges related to reducing noise, improving the stability \\nand coherence of quantum systems, and developing scalable quantum electrical standards pose significant hurdles in the \\npractical implementation of electrical quantum metrology.51 \\n \\nj. Quantum Cryptography . Securing Communication in the Quantum Age Quantum cryptography aims to provide \\nsecure communication channels that are invulnerable to eavesdropping or tampering. Quantum key distribution (QKD) is \\na crucial aspect of quantum crypto graphy, ensuring secure key exchange between parties. However, challenges such as \\nlimited transmission distances, compatibility with existing communication infrastructure, and high implementation costs \\nhinder the widespread adoption of quantum cryptography . Ongoing research, development of new protoco', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 807: ('the Quantum Age Quantum cryptography aims to provide \\nsecure communication channels that are invulnerable to eavesdropping or tampering. Quantum key distribution (QKD) is \\na crucial aspect of quantum crypto graphy, ensuring secure key exchange between parties. However, challenges such as \\nlimited transmission distances, compatibility with existing communication infrastructure, and high implementation costs \\nhinder the widespread adoption of quantum cryptography . Ongoing research, development of new protocols, and efforts to \\novercome technological barriers are essential to realize the full potential of quantum cryptography in safeguarding \\ncommunication.52 \\n \\nk. The Quantum Technology Competence Center (QTZ) . Foster ing Collaboration and Innovation To address the \\nchallenges faced by quantum technology, collaborative efforts are essential. The Quantum Technology Competence Center \\n(QTZ) is an example of a collaborative initiative that brings together experts from academ ia, industry, and research \\ninstitutions to accelerate the development and deployment of quantum technologies. The QTZ facilitates interdisciplinary \\nresearch, knowledge exchange, and industry partnerships, promoting innovation and addressing challenges coll ectively.53 \\n \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         46 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  CHALLENGES OF QUANTUM COMPUTING  \\n11. Quantum computing has many potential advantages, as well as there are also few disadvantages and challenges. The cost \\nof building and operating QCs is currently very high. This limits the accessibility of qu antum computing technology to only a few \\nlarge corporations and research institutions. So, ‘there are several significant challenges that need to be addressed and sol ved before \\nthe use of technology widely adopted around the world. Quantum computing also ', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 808: ('C BY.  CHALLENGES OF QUANTUM COMPUTING  \\n11. Quantum computing has many potential advantages, as well as there are also few disadvantages and challenges. The cost \\nof building and operating QCs is currently very high. This limits the accessibility of qu antum computing technology to only a few \\nlarge corporations and research institutions. So, ‘there are several significant challenges that need to be addressed and sol ved before \\nthe use of technology widely adopted around the world. Quantum computing also f aces several challenges, including hardware \\nlimitations, error correction, and scalability, which need to be addressed and solved before realizing and utilizing the full  potential \\nof quantum computing.’54 \\na. Error Correction.  QCs are prone to errors due to  the delicate nature of quantum states, and these errors can accumulate \\nover time, leading to incorrect results. This is a significant challenge that needs to be overcome before quantum computing c an be \\nused to solve real -world problems55. In addition, QCs are very sensitive to their environment, and any interference or noise can \\ncause errors in calculations. This requires the use of specialized equipment and facilities to maintain the stability of the quantum \\nstates in the computer.  \\nb. Availab ility of Qubits.  Another challenge is the limited number of qubits currently available in QCs. While the number \\nof qubits in QCs has been increasing, it is still much smaller than the number of bits in classical computers. This means tha t QCs \\ncan only solv e a limited number of problems that are beyond the capabilities of classical computers.  \\nc. Primitive Stage.  The development of quantum algorithms is still in its early stages, and there are very limited number of \\nalgorithms that have been developed that ca n take advantage of the unique properties of QCs. This limits the types of problems that \\nQCs can currently solve. While quantum computers have shown impressive performance for some tasks, they are still relatively \\nsmall compared to classica', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 809: ('nly solv e a limited number of problems that are beyond the capabilities of classical computers.  \\nc. Primitive Stage.  The development of quantum algorithms is still in its early stages, and there are very limited number of \\nalgorithms that have been developed that ca n take advantage of the unique properties of QCs. This limits the types of problems that \\nQCs can currently solve. While quantum computers have shown impressive performance for some tasks, they are still relatively \\nsmall compared to classical computers. So,  scaling up QCs to few thousands of qubits while maintaining high levels of consistency \\nand low error rates is remains a major challenge’ still today.56 \\nd. Hardware and Software Development.  Developing high -quality quantum hardware, such as qubits and cont rol \\nelectronics, is a major challenge. There are many different qubit technologies, each with its own strengths and weaknesses, a nd \\ndeveloping a scalable, fault -tolerant qubit technology is a major focus of research. Again quantum algorithms and software \\ndevelopment tools are still in their infancy, and there is a need for new programming languages, compilers, and optimization t ools \\nwhich can effectively and successfully utilize the power of QCs.  \\ne. Classical Computer Interfaces and Protocols.  QCs won’t rep lace classical computers; they will serve as balancing \\ntechnology. Developing efficient and reliable methods for transferring data between classical and quantum computers is essent ial \\nfor practical applications. Again, as the field of quantum computing mat ures, there is a need for standards and protocols for hardware, \\nsoftware, and communication interfaces. ‘Developing these standards will be essential for ensuring compatibility and \\ninteroperability between different quantum computing platforms. We need to do benchmarking; as it is the ability to measure \\nperformance standards is still in its infancy for quantum computing design, development and operation.’57 \\n \\n \\nFig 4: Concepts of quantum warfare using various QTs bas', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 810: ('s the field of quantum computing mat ures, there is a need for standards and protocols for hardware, \\nsoftware, and communication interfaces. ‘Developing these standards will be essential for ensuring compatibility and \\ninteroperability between different quantum computing platforms. We need to do benchmarking; as it is the ability to measure \\nperformance standards is still in its infancy for quantum computing design, development and operation.’57 \\n \\n \\nFig 4: Concepts of quantum warfare using various QTs based systems58 \\n \\nf. Training and HR Developme nt. The number of people properly educated and trained to enter the quantum workforce \\nis small and spread across the world. Finding the right workers and training the new people is a challenge. At present scenar io, \\ngovernment and business owners won’t incr ease the number of people motivated to enter the quantum workforce until they have \\nmore practical quantum computers and they won’t have more practical QCs until they have more people motivated to become part \\nof the quantum workforce.  \\ng, Capital and Cost.  Expense remains as a main roadblock for quantum computing industry or QTs development. Quantum \\ntalent and training is expensive. Quantum hardware and software development is expensive. Supply chains are complex, vulnerab le \\nand expensive. Dealing with these expenses and finding investments to offset these costs will remain as the biggest challenge and \\nthat somehow failed to encourage the institutional scientists and commercial entrepreneurs for the expected future.  \\n \\nCONCLUSION  \\n12. Quantum computing is a promising technology that has the potential to revolutionize several industries. Quantum \\ncomputing operates on qubits, which can exist in multiple states simultaneously, allowing quantum computers to perform operat ions \\n\\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         47 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is li', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 811: ('ected future.  \\n \\nCONCLUSION  \\n12. Quantum computing is a promising technology that has the potential to revolutionize several industries. Quantum \\ncomputing operates on qubits, which can exist in multiple states simultaneously, allowing quantum computers to perform operat ions \\n\\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         47 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.  exponentially faster and user friendly manner than classical computers. IBM has been one of the leading companies in the field of \\nquantum computing and has developed several quantum computers. As quantum computing continues to evolve, it is essential to \\naddress the chal lenges and develop solutions to ensure the commercialization and adoption of quantum computing. The development \\nof quantum computing will have a significant impact on several industries, and it is essential to ensure that the potential o f quantum \\ncomputing  is realized. QT is an engineering system which utilizes the quantum properties of photons, electrons, atoms, or molecules. \\nToday, the challenges as discussed above are a little discouraging, but there are lots of reasons for hope and trust. Funding agenci es \\nand interested government agencies  are rising to the occasion to invest in solving these quantum computing challenges. Scientist \\nand researchers  are making advances in the engineering and technical challenges to create practical QCs.  However, we can ant icipate \\nthat, in future, QTs will use in the field of communication, precision, intelligence, space, medical, chemical, commercial, s ervice \\nand military industries.  \\n \\n13. QTs hold great promise in the long term for a broad range of applications, from sensin g to communications including \\ncomputing, but should not be unspecified to revolutionize defense applications in the predictable future. Even though princip les \\nwere pr', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 812: (\"ineering and technical challenges to create practical QCs.  However, we can ant icipate \\nthat, in future, QTs will use in the field of communication, precision, intelligence, space, medical, chemical, commercial, s ervice \\nand military industries.  \\n \\n13. QTs hold great promise in the long term for a broad range of applications, from sensin g to communications including \\ncomputing, but should not be unspecified to revolutionize defense applications in the predictable future. Even though princip les \\nwere proven successful in laboratories, the transition from laboratory to real -world applications  is still in progress. Again, \\nnecessities, like low SWaP, mobility, and cost, still represent significant restrictive factors. Above all limitation and cha llenges, for \\na good reason, QTs have captured government and business owner of potential nation’s att ention and mind's eye. Based on \\ntheoretical and laboratory work, scientists and researchers have an appreciation of the technology and its possible uses in r eal-world \\napplications. Actually, the role of potential nations and entrepreneurs is to set goals a nd standards to encourage development and \\nensure interoperability. Meanwhile, the potential nations and entrepreneurs must invest in the necessary research and look fo r dual -\\nuse opportunities to speed development and reduce cost. With this understanding, s cientists, researchers, engineers and technologists \\nneed to pursue the great promise of QTs with a realistic understanding of the timeline and effort involved. Quantum computing  has \\ngreat potential in many applications, such as improved machine learning an d artificial intelligence, better aerodynamic designs for \\naircraft and shipbuilding industry, faster simulations, and many more. We hope that, there will be revolutionize change in fu ture \\nwarfare and military industry by the effective and efficient use of QTs in full extent.  \\n \\n \\n \\n \\n \\nREFERENCES  \\n \\n \\n1Lind Wetal, The changing face of war: into the fourth generation, In: Marine corps gazette , 1\", 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 813: ('involved. Quantum computing  has \\ngreat potential in many applications, such as improved machine learning an d artificial intelligence, better aerodynamic designs for \\naircraft and shipbuilding industry, faster simulations, and many more. We hope that, there will be revolutionize change in fu ture \\nwarfare and military industry by the effective and efficient use of QTs in full extent.  \\n \\n \\n \\n \\n \\nREFERENCES  \\n \\n \\n1Lind Wetal, The changing face of war: into the fourth generation, In: Marine corps gazette , 1989  \\n2Lind WS, Understandingfourthgenerationwar,MilRev,2004  \\n3https://ec.europa.eu/research/participants/data/ref/h2020/wp/2014_2015 , accessed on 21 Mar 2023  \\n4https://www.weforum.org/agenda/2021/04/quantum -technologies -transform -innovation -and-mitigate -climate -change -gtgs, \\naccessed on 25 Ap r 2023  \\n5Biercuk, M. J. and Fontaine, R., The Leap into Quantum Technology: A Primer for National Security Professionals, War on the \\nRocks, 17 November 2017  \\n6https://www.amnh.org/ exhibitions/einstein/legacy/quantum -theory , accessed on 22 Apr 2023  \\n7Lind WS, Understanding fourth generation war, Mil Rev, 2004;84:12, Dec 2022  \\n8https://quantumcomputingreport.com/google -goal-error -corrected -computer -with-1-million -physical -qubits -by-the-end-of-the-\\ndecade , accessed on 21 Apr 2023  \\n9https://education.jlab.org/qa/quantum_01.html , accessed on 22 Apr 2023  \\n10https://academic.oup.com/book/978/chapter -abstract/137838934?redirectedFrom=fulltext , Mar 23, 2023  \\n11 https://epjquantumtechnology.springeropen.com/articles/10.1140/epjqt/s40507 -021-00113 -y#Sec1  \\n12Wehner, S., Elkouss, D. and Hanson, R., ‘Quantum Internet: A vision for the road ahead’, Science, Vol. 362, no. 6412, 19  \\nOctober 2018  \\n13Aﬀan Ahmed S, Mohsin M, Muhammad Zubair, and Ali S, Survey and technological analysis of laser and its defense applications, Defence \\nTechnology ,   2020  \\n14Jonathan P. Dowling and Gerard J. Milburn, Quantum technology: the second quantum revolution, In Philosophical \\nTransactions of the Royal Society of Lo', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 814: ('ropen.com/articles/10.1140/epjqt/s40507 -021-00113 -y#Sec1  \\n12Wehner, S., Elkouss, D. and Hanson, R., ‘Quantum Internet: A vision for the road ahead’, Science, Vol. 362, no. 6412, 19  \\nOctober 2018  \\n13Aﬀan Ahmed S, Mohsin M, Muhammad Zubair, and Ali S, Survey and technological analysis of laser and its defense applications, Defence \\nTechnology ,   2020  \\n14Jonathan P. Dowling and Gerard J. Milburn, Quantum technology: the second quantum revolution, In Philosophical \\nTransactions of the Royal Society of London, Series A, Mathematical, Physical and Engineering Sciences,  June 2003  \\n15S.TillandJ.Pritchard, UKquantumtechnologylandscape2016 .DSTL/PUB098369,UKNational QuantumTechnologiesP\\nrogramme,2016  \\n16Stuart A., and Wolf et al., Overview of the Status of Quantum Science and Technology and \\nRecommendationsfortheDoD,InstituteForDefenseAnalyses,June2019  \\n17Andrew Davies, and Patrick Kennedy, Special report, from little things:  Quantum \\ntechnologiesandtheirapplicationtodefence,ASPI(AustralianStrategicPolicyInstitute),2017  \\n18Jacob Biamonte et al. , Quantum machine learning, In:Nature549.7671 , Sep2017  \\n19‘Emerging and Disruptive Technologies’, NA TO, December 2022. https://www.nato.int/cps/en/natohq/topics_184303.htm accessed on 3 Feb \\n2023 \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         48 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.   \\n20https://www.forbes.com/sites/melissacristinamarquez/2023/03/23/rare -shark -beheaded -on-british -beach -prompts -appeal -\\nscientists -to-help-locate -it/?sh=3b33c9681226 , accessed on  1 May 2023  \\n21JuanYinetal,Satellite -to-GroundEntanglement -BasedQuantumKeyDistribution,In:Phys -icalReviewLetters ,119.20 , \\nNov2017  \\n22HaraldAndas,Emergingtechnologytrendsfordefenceandsecurity,FFI -RAPPORT,Apr2020  \\n23AustinG.Fowleretal.,Surfacecodes :Towardspracticallarge -scalequantumcomputation,In:  \\nPhy', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 815: ('n CC BY.   \\n20https://www.forbes.com/sites/melissacristinamarquez/2023/03/23/rare -shark -beheaded -on-british -beach -prompts -appeal -\\nscientists -to-help-locate -it/?sh=3b33c9681226 , accessed on  1 May 2023  \\n21JuanYinetal,Satellite -to-GroundEntanglement -BasedQuantumKeyDistribution,In:Phys -icalReviewLetters ,119.20 , \\nNov2017  \\n22HaraldAndas,Emergingtechnologytrendsfordefenceandsecurity,FFI -RAPPORT,Apr2020  \\n23AustinG.Fowleretal.,Surfacecodes :Towardspracticallarge -scalequantumcomputation,In:  \\nPhysical Review, A86.3, Sep 2012  \\n24Philip Inglesant, Marina Jirotka, and Mark Hartswood, Responsible Innovation in Quantum Technologies applied to \\nDefence and National Security, NQIT (Networked Quantum Info rmation Technologies),2018  \\n25Australian Army,ArmyQuantumTechnologyRoadmap,Apr2021  \\n26E.M. National Academies of Sciences et al., Quantum Computing: Progress and Prospects, \\nNational AcademiesPress,2019, ISBN :9780309479721  \\n27Frank Aruteetal., Quantum supremacy usin g a programmable super conducting processor, In:  \\nNature 574.7779, Oct 2019  \\n28Cao, Y., Romero, J., Olson, J. P., Degroote, M., Johnson, P. D., Kieferová, M., and Aspuru -Guzik, A., Quantum chemistry in the \\nage of quantum computing, Chemical Reviews, 119(19), 10856 -10915, 2019  \\n29Electronics for You, Dec 2022  \\n30 India Electonics Week, 23 -25 Nov, 2022  \\n31 Op cit \\n32Preskil  et al, Quantum computing in the NISQ era and beyond. Quantum, p 2, 79; 2018  \\n33N D Mermin, Quantum Computer Science: An Introduction, Cambridge University Press, 2007, ISBN : \\n9781139466806  \\n34Jay Gambetta, IBM’s Roadmap For Scaling Quantum Technology, IBM, 202 0 \\n35ATARC Quantum Working Group. Applied quantum computing for today’s military, White paper, May 2021  \\n36https://newsroom.ibm.com/2022 -11-09-IBM -Unveils -400-Qubit -Plus-Quantum -Processor -and-Next -Generation -IBM -Quantum -\\nSystem -Two, accessed on 07 May 2023  \\n37 Preskill, J. (2018),  Quantum Computing in the NISQ  era and beyond. Quantum, 2, 79  \\n38 Arute, F., et al. (2019),  Quantum supremacy u', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 816: (', 2007, ISBN : \\n9781139466806  \\n34Jay Gambetta, IBM’s Roadmap For Scaling Quantum Technology, IBM, 202 0 \\n35ATARC Quantum Working Group. Applied quantum computing for today’s military, White paper, May 2021  \\n36https://newsroom.ibm.com/2022 -11-09-IBM -Unveils -400-Qubit -Plus-Quantum -Processor -and-Next -Generation -IBM -Quantum -\\nSystem -Two, accessed on 07 May 2023  \\n37 Preskill, J. (2018),  Quantum Computing in the NISQ  era and beyond. Quantum, 2, 79  \\n38 Arute, F., et al. (2019),  Quantum supremacy using a programmable superconducting proces sor. Nature, 574(7 779), 505 –510 \\n39 Scarani, V ., et al. (2009),  The security of practical quantum key distribution. Reviews of M odern Physics, 81(3), 1301 –1350  \\n40 Diama nti, E., & Leverrier, A. (2015),  Distributing secret keys with quantum continuous variables: Principle, secur ity and \\nimplementat ions. Entropy, 17(9), 6072 –6092  \\n41 Yin, J., et al. (2020),  Satellite -to-ground entanglement -based quantum key distribut ion. Nature, 582(7812), 501 –505 \\n42 Shor, P. W . (1994),  Algorithms for quantum computation: Discrete logarithms and fact oring. In Proceedings of the 35th Annual \\nSymposium on Foundations of  Computer Science (pp. 124 –134) \\n43 Lange, T., & Zhandry, M. (2019),  Post-quantum zero -knowledge. Journal of Crypto logy, 32(1), 147 –189 \\n44 Azarderakhsh, R., et al. (2019). Post -quantum crypto graphy standardization. IEEE Journal on Selected Areas in  \\nCommunications, 37(4), 645 –654 \\n45 Degen, C. L., Reinhard, F., & Cappellaro, P. (2017). Quantum sensing. Reviews of Modern Physics, 89(3), 035002  \\n46 Grotz, B., & Ankerhold, J. (2018). Challenges in qua ntum sensing.  Nanophotonics, 7(7), 1225 –1242  \\n47 Awschalom, D. D., et al. (2018). Quantum spintronics: Engineering and manipulating atom -like spins in semiconductors. \\nScience, 339 (6124), 1174 –1179  \\n48 Lodahl, P., et al. (2017). Chiral quantum opt ics. Nature, 541(7638), 473 –480 \\n49 Norcia, M. A., et al. (2017). Quantum metrology with time crystals. Physical Review X, 7(3), 031052  \\n50 Kom', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 817: ('tum sensing. Reviews of Modern Physics, 89(3), 035002  \\n46 Grotz, B., & Ankerhold, J. (2018). Challenges in qua ntum sensing.  Nanophotonics, 7(7), 1225 –1242  \\n47 Awschalom, D. D., et al. (2018). Quantum spintronics: Engineering and manipulating atom -like spins in semiconductors. \\nScience, 339 (6124), 1174 –1179  \\n48 Lodahl, P., et al. (2017). Chiral quantum opt ics. Nature, 541(7638), 473 –480 \\n49 Norcia, M. A., et al. (2017). Quantum metrology with time crystals. Physical Review X, 7(3), 031052  \\n50 Kominis, I. K. (2019). Quantum sensors based on nitrogen -vacancy centers i n diamond. Reports on Prog ress in Physics, 82(11), \\n113001  \\n51 Stock, M., & Leek, P. J. (2017). Quantum electrical metrology: Challenges and opportuni ties. Metrologia, 54(1), R1 –R16 \\n52 Lütkenhaus, N., et al. (2018). Quantum communication: A comprehensive revie w. Quantum Scien ce and Technology, 3(3), \\n030501  \\n53 Quantum Technology Competence Center. Retrieved from https://www.qtz.de/ , accessed on 12 Apr 2023  \\n54https://www.act.nato.int/articles/nato -exploring -quantum -technology -future -challenges . accessed on 12 Apr 2023  \\n55Preskill, J., Quantum computing in t he NISQ era and beyond, Quantum, 2018  \\n56Markus Reiher et al. , Elucid at ingreaction mechanisms on quantum computers, In: Proceedings of the National Academy \\nof Scien ces, 114.29 , Jul 2017  \\n57https://thequantuminsider.com/2023/03/24/quantum -computing -challenges , accessed on 6 May 2023  \\n58https://www.japcc.org/articles/quantum -technology -for-defence , accessed on 05 May 2023  \\n \\nBibliography  \\na. Preskill, J. (2018), Quantum Computing in the NISQ era and beyond. Quantum, 2,  \\nb. Arute,  F., et al. (2019), Quantum supremacy using a programmable superconducting processor. Nature, 574(7779), 505 –510 \\nc. Scarani, V., et al. (2009), The security of practical quantum key distribution. Reviews of Modern Physics, 81(3), 1301 –1350  \\nd. Diamanti, E., & Lev errier, A., (2015). Distributing secret keys with quantum continuous variables: Principle, security and \\nimpleme', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 818: ('sed on 05 May 2023  \\n \\nBibliography  \\na. Preskill, J. (2018), Quantum Computing in the NISQ era and beyond. Quantum, 2,  \\nb. Arute,  F., et al. (2019), Quantum supremacy using a programmable superconducting processor. Nature, 574(7779), 505 –510 \\nc. Scarani, V., et al. (2009), The security of practical quantum key distribution. Reviews of Modern Physics, 81(3), 1301 –1350  \\nd. Diamanti, E., & Lev errier, A., (2015). Distributing secret keys with quantum continuous variables: Principle, security and \\nimplementations. Entropy, 17(9), 6072 –6092  \\nScientific Research Jo urnal (SCIRJ), Volume XI, Issue VI, June 2023         49 \\nISSN 2201 -2796  \\nwww.scirj.org  \\n© 2023, Scientific Research Journal  \\nhttp://dx.doi.org/10.31364/SCIRJ/v11.i6.2023.P0623 953 \\nThis publication is licensed  under Creative Commons Attribution CC BY.   \\ne. Yin, J., et al. (2020), Satellite -to-ground entanglement -based quantum key distribution. Nature, 582(7812), 5 01–505 \\nf. Shor, P. W. (1994), Algorithms for quantum computation: Discrete logarithms and factoring. In Proceedings of the 35th \\nAnnual Symposium on Foundations of Computer Science (pp. 124 –134) \\ng. Lange, T., & Zhandry, M. (2019), Post -quantum zero -knowledge. Jou rnal of Cryptology, 32(1), 147 –189 \\nh. Azarderakhsh, R., et al. (2019), Post -quantum cryptography standardization, IEEE Journal on Selected Areas in \\nCommunications, 37(4), 645 –654 \\ni. Degen, C. L., Reinhard, F., & Cappellaro, P. (2017), Quantum sensing, Reviews of  Modern Physics, 89(3), 035002  \\nj. Grotz, B., & Ankerhold, J. (2018), Challenges in quantum sensing. Nanophotonics, 7(7), 1225 –1242  \\nk. Awschalom, D. D., et al., (2018), Quantum spintronics: Engineering and manipulating atom -like spins in semiconductors. \\nScience, 339(6124), 1174 –1179  \\nl. Lodahl, P., et al. (2017), Chiral quantum optics. Nature, 541(7638), 473 –480 \\nm. Norcia, M. A., et al. (2017), Quantum metrology with time crystals. Physical Review X, 7(3), 031052  \\nn. Kominis, I. K. (2019). Quantum sensors based on nitrogen -vacancy centers in ', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 819: (' Ankerhold, J. (2018), Challenges in quantum sensing. Nanophotonics, 7(7), 1225 –1242  \\nk. Awschalom, D. D., et al., (2018), Quantum spintronics: Engineering and manipulating atom -like spins in semiconductors. \\nScience, 339(6124), 1174 –1179  \\nl. Lodahl, P., et al. (2017), Chiral quantum optics. Nature, 541(7638), 473 –480 \\nm. Norcia, M. A., et al. (2017), Quantum metrology with time crystals. Physical Review X, 7(3), 031052  \\nn. Kominis, I. K. (2019). Quantum sensors based on nitrogen -vacancy centers in diamond. Reports on Progress in Physics, \\n82(11), 113001  \\no. Stock, M., & Leek, P. J. (2017), Quantum electrical metrology: Challenges and opportunities. Metrologia, 54(1), R1 –R16 \\np. Lütkenhaus, N., et al. (2018), Quantum communication: A compreh ensive review. Quantum Science and Technology, 3(3), \\n030501  \\nq. Quantum Technology Competence Center, Retrieved from https://www.qtz.de/ , accessed on 18 May 2023  \\n \\n \\n \\nABOUT AUTHOR  \\nKhandakar Akhter Hossain, PhD is a professor/researcher/Examiner at MIST, and BUET. Email: \\nkhandokarhossain1969@gmail.com  \\n ', 'THE POTENTIAL AND CHALLENGES OF QUANTUM TECHNOLOGY IN MODERN ERA.pdf'), 820: ('AI-Based Reconstruction for\\nFast MRI—A Systematic\\nReview and Meta-Analysis\\nThis article provides a systematic review and the ﬁrst meta-analysis to summarize the\\ndevelopment of deep-learning-based compressed sensing-magnetic resonance imaging.\\nByYUTONG CHEN,CAROLA -BIBIANE SCHÖNLIEB ,PIETRO LIÒ,TIMLEINER ,\\nPIERLUIGI DRAGOTTI ,Fellow IEEE ,GEWANG ,Fellow IEEE ,DANIEL RUECKERT ,Fellow IEEE ,\\nDAVID FIRMIN ,AND GUANG YANG ,Senior Member IEEE\\nABSTRACT |Compressed sensing (CS) has been playing a key\\nrole in accelerating the magnetic resonance imaging (MRI)\\nacquisition process. With the resurgence of artiﬁcial intelli-\\ngence, deep neural networks and CS algorithms are being\\nintegrated to redeﬁne the state of the art of fast MRI. The\\npast several years have witnessed substantial growth in the\\nManuscript received April 27, 2021; revised December 5, 2021; accepted\\nDecember 20, 2021. Date of current version February 3, 2022. This work was\\nsupported in part by the British Heart Foundation under Project TG/18/5/34111\\nand Project PG/16/78/32402; in part by the European Research Council\\nInnovative Medicines Initiative, DRAGON, under Grant H2020-JTI-IMI2\\n101005122; in part by the AI for Health Imaging Award, CHAIMELEON, under\\nGrant H2020-SC1-FA-DTS-2019-1 952172; in part by the Medical Research\\nCouncil under Grant MC/PC/21013; and in part by the U.K. Research andInnovation Future Leaders Fellowship under Grant MR/V023799/1.\\n(Corresponding author: Guang Yang.)\\nYutong Chen is with the National Heart and Lung Institute, Imperial College\\nLondon, London SW3 6NP, U.K., with the Cardiovascular Research Centre, Royal\\nBrompton Hospital, London SW3 6NP, U.K., and also with the Faculty of Biology,\\nUniversity of Cambridge, Cambridge CB2 1RX, U.K.\\nCarola-Bibiane Schönlieb is with the Department of Applied Mathematics and\\nTheoretical Physics, University of Cambridge, Cambridge CB3 0WA, U.K.\\nPietro Liò is with the Department of Computer Science and Technology,\\nUniversity of Cambridge, Cambridge CB3 0FD, U.K.\\nTim Leiner is with the Utrecht Unive', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 821: ('ollege\\nLondon, London SW3 6NP, U.K., with the Cardiovascular Research Centre, Royal\\nBrompton Hospital, London SW3 6NP, U.K., and also with the Faculty of Biology,\\nUniversity of Cambridge, Cambridge CB2 1RX, U.K.\\nCarola-Bibiane Schönlieb is with the Department of Applied Mathematics and\\nTheoretical Physics, University of Cambridge, Cambridge CB3 0WA, U.K.\\nPietro Liò is with the Department of Computer Science and Technology,\\nUniversity of Cambridge, Cambridge CB3 0FD, U.K.\\nTim Leiner is with the Utrecht University Medical Centre, 3584 CX Utrecht, The\\nNetherlands.\\nPier Luigi Dragotti is with the Department of Electrical and Electronic\\nEngineering, Imperial College London, London SW7 2BU, U.K.\\nGe Wang is with the Biomedical Imaging Center, Rensselaer Polytechnic\\nInstitute, Troy, NY 12180 USA.\\nDaniel Rueckert is with the Department of Computing, Imperial College\\nLondon, London SW7 2BU, U.K., and also with the Institute for Medical\\nInformatics, Statistics and Epidemiology, Technical University of Munich, 81675\\nMunich, Germany.\\nDavid Firmin andGuang Yang are with the National Heart and Lung Institute,\\nImperial College London, London SW3 6NP, U.K., and also with the\\nCardiovascular Research Centre, Royal Brompton Hospital, London SW3 6NP,U.K. (e-mail: g.yang@imperial.ac.uk).\\nThis article has supplementary downloadable material available at\\nhttps://doi.org/10. 1109/JPROC.2022.3141367, provided by the authors.\\nDigital Object Identiﬁer 10.1109/JPROC.2022.3141367complexity, diversity, and performance of deep-learning-based\\nCS techniques that are dedicated to fast MRI. In this meta-\\nanalysis, we systematically review the deep-learning-based CS\\ntechniques for fast MRI, describe key model designs, highlight\\nbreakthroughs, and discuss prom ising directions. We have also\\nintroduced a comprehensive analysis framework and a classi-ﬁcation system to assess the pivotal role of deep learning in\\nCS-based acceleration for MRI.\\nKEYWORDS |Compressed sensing (CS); deep learning; mag-\\nnetic resonance imaging (MRI); neural network.\\nI.INTRODUC', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 822: ('CS techniques that are dedicated to fast MRI. In this meta-\\nanalysis, we systematically review the deep-learning-based CS\\ntechniques for fast MRI, describe key model designs, highlight\\nbreakthroughs, and discuss prom ising directions. We have also\\nintroduced a comprehensive analysis framework and a classi-ﬁcation system to assess the pivotal role of deep learning in\\nCS-based acceleration for MRI.\\nKEYWORDS |Compressed sensing (CS); deep learning; mag-\\nnetic resonance imaging (MRI); neural network.\\nI.INTRODUCTION\\nMagnetic resonance imaging (MRI) is a state-of-the-art\\nmedical imaging technique that can determine the struc-\\ntural and functional status of body tissues and organs [1].\\nHowever, the prolonged MRI acquisition time [2], [3]increases the scanning cost and limits its use in emergency\\nsettings. Moreover, subjects have to lie still in the scanners\\nand even hold their breath for thoracic or abdominal\\nimaging [1]. Hence, the slow acquisition of magnetic reso-\\nnance (MR) images presents a signiﬁcant inconvenience topatients and healthcare systems alike.\\nThe reason for the slow MR acquisition rate is that,\\nunlike other imaging modalities, e.g., X-ray and CT ,MR data are acquired in the k-space. The k-space is related\\nto the image domain via the Fourier transform [1], [4]\\nand represents the spatial frequency information. During\\nMRI acquisition, measures in the k-space are taken\\nsequentially rather than simultaneously , thus prolongingthe scanning time.\\nTo address this limitation, the k-space can be undersam-\\npled, i.e., not sampled entirely . The missing k-space data\\n224 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nare then inferred from the existing k-space points. This\\nleads to an acceleration that is inversely proportional to\\nthe undersampling ratio. For example, if only 50% ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 823: (', i.e., not sampled entirely . The missing k-space data\\n224 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nare then inferred from the existing k-space points. This\\nleads to an acceleration that is inversely proportional to\\nthe undersampling ratio. For example, if only 50% of the\\nk-space is sampled, the acceleration is twofold (excludingscanning preparation and/or prescanning time). Among\\ndifferent undersampling techniques [1], compressed sens-\\ning (CS) yields an aggressive acceleration rate up to12.5-fold [5]. CS assumes that, if the undersampled signals\\ncan be compressed accurately , they can be decompressed\\nor reconstructed accurately [2], [6] without the need for\\nfull sampling. Thus, CS extrapolates unknown k-space\\nsignals from existing ones, akin to image super-resolutiontechniques that increase image resolution by reconstruct-\\ning high-frequency image details [7].\\nDriven by the growing research on deep learn-\\ning in computer vision, deep-learning-based algorithms\\nhave gained popularity for CS-based MRI (CS-MRI)\\nreconstruction. Deep learning techniques utilize artiﬁcial\\nneural networks (ANNs) to learn the CS reconstruc-\\ntion process. Compared with traditional nondeep-learning-based approaches, deep learning enables higher quality\\nreconstruction [3], [8]–[10] and the acceleration ratio of\\nMRI acquisition. With an exponentially increasing interesttoward deep-learning-based CS-MRI, the complexity and\\ndiversity of the reconstruction algorithms have increased\\ndramatically . Motivated by this rapidly expanding ﬁeld,\\nwe have conducted a systematic review and the ﬁrst\\nmeta-analysis to summarize the development of deep-learning-based CS-MRI. We will outline the background of\\ndeep learning in CS-MRI reconstruction, review each algo-\\nrithmic category , present the results of meta-analy', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 824: ('ration ratio of\\nMRI acquisition. With an exponentially increasing interesttoward deep-learning-based CS-MRI, the complexity and\\ndiversity of the reconstruction algorithms have increased\\ndramatically . Motivated by this rapidly expanding ﬁeld,\\nwe have conducted a systematic review and the ﬁrst\\nmeta-analysis to summarize the development of deep-learning-based CS-MRI. We will outline the background of\\ndeep learning in CS-MRI reconstruction, review each algo-\\nrithmic category , present the results of meta-analysis, andconclude with an outlook on deep-learning-based CS-MRI\\nacceleration.\\nA. Deep Learning\\nThe power of deep learning centers on its capacity to\\nmodel complex input–output relationships with a large\\nnumber of parameters in an ANN [11]. An ANN consistsof an input layer of nodes, followed by multiple hidden\\nlayers and an output layer (see Fig. 1 in the Supplementary\\nMaterial). In CS-MRI, each input node represents a pixel\\nin the undersampled MR image. The pixels are weighted\\nand summed to form the input for the next layer after anonlinear activation function [12]. The subsequent hid-\\nden layers perform a similar process to produce the ﬁnal\\nreconstructed image.\\nThe connection weights are network parameters that\\nare optimized such that the outputs from the network\\nare as similar to the target outputs as possible. Thatis, the network weights need to be tuned to minimize\\nthe difference between the fully sampled images and the\\nreconstructed images. This process of weight optimization\\nis known as training the ANN. The training process is\\nguided by the difference or error between actual anddesired outcomes, described by a loss function. In other\\nwords, the network receives the undersampled images andoutputs the reconstructed versions. The loss function com-\\nputes the discrepancy between actual and desired outputs,\\nand utilizes this information to update the parameters of\\nthe ANN that models an optimal CS-MRI reconstructionprocess.\\nB. End-to-End\\nDeep-learning-based CS-MRI models fall into two main\\ncategories: end-to-e', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 825: (' The training process is\\nguided by the difference or error between actual anddesired outcomes, described by a loss function. In other\\nwords, the network receives the undersampled images andoutputs the reconstructed versions. The loss function com-\\nputes the discrepancy between actual and desired outputs,\\nand utilizes this information to update the parameters of\\nthe ANN that models an optimal CS-MRI reconstructionprocess.\\nB. End-to-End\\nDeep-learning-based CS-MRI models fall into two main\\ncategories: end-to-end (ETE) and unrolled optimization\\n(UO) [13]–[15]. An ETE technique models the CS-MRIreconstruction process directly . In CS-MRI, the process of\\nacquiring undersampled images is\\ny=UFx (1)\\nwhere xis the fully sampled image, Fxis the Fourier trans-\\nform of the image, i.e., its k-space representation, Uis a\\nbinary matrix of zeros and ones that denote which k-space\\nlocations to the sample, and yis the undersampled k-space\\ndata [2]. ETE techniques model the inverse acquisition or\\nreconstruction process directly , mapping from ytox,a n d ,\\nhence, the name “ETE.” Because of this direct mapping, thereconstruction process is usually fast [14].\\nAn advantage of ETE models is that advances from other\\nﬁelds of deep learning are transferable to ETE designs\\n(see Table 1 in the Supplementary Material). For example,\\nU-Net [16], a deep learning model originally developed forimage segmentation was readily applied to reconstruct MR\\nimages in an ETE manner without major modiﬁcations [3],\\n[17]. Similarly , a self-attention mechanism—designed toenhance natural image processing—was incorporated into\\ndeep ETE models with performance improvement over\\nU-Net [18]. One limitation is that ETE models tend to\\nrequire a larger sample size to train [13].\\nC. Unrolled Optimization\\nUO combines deep learning with traditional iterative\\nCS algorithms. Traditional CS techniques solve the general\\nproblem of image recovery\\n1\\n2||UFx−y||2\\n2+R(x) (2)\\nin which xis the reconstructed image and the ﬁrst term\\nenforces the data ﬁdelity , i.e., the reconstructed ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 826: ('sm—designed toenhance natural image processing—was incorporated into\\ndeep ETE models with performance improvement over\\nU-Net [18]. One limitation is that ETE models tend to\\nrequire a larger sample size to train [13].\\nC. Unrolled Optimization\\nUO combines deep learning with traditional iterative\\nCS algorithms. Traditional CS techniques solve the general\\nproblem of image recovery\\n1\\n2||UFx−y||2\\n2+R(x) (2)\\nin which xis the reconstructed image and the ﬁrst term\\nenforces the data ﬁdelity , i.e., the reconstructed imagedoes not differ from the undersampled one at the sampled\\nk-space locations. The second term imposes regularization,\\ntypically sparsity constraints, on the reconstructed imageto satisfy the CS criteria. Deep learning networks form the\\nregularizer term (see Table 1 for example). That is, deep\\nlearning models are designed to learn the regularization\\nmethods to constrain image reconstruction, rather than\\ndirectly modeling the reconstruction process itself. Froma Bayesian perspective, the regularizer term represents the\\nprior knowledge about the property of the reconstructed\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 225\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nFig. 1. Basic information of the reviewed studies. (a) Preferred reporti ng items for systematic reviews a nd meta-analyses (PRISIMA) [109]\\nﬂow diagram of this meta-analysis study. (b) Number of studies use d in each analysis test. Abbreviations: PCA: principal component\\nanalysis; SSIM: structural similarity index, a popular metric of pe rformance of deep learning model in CS reconstruction; and PSNR: peak\\nsignal-to-noise ratio. (c) Number of publications in each country over time. (d) Number of publications by the research institute. The numberin the bracket indicates the proportion of the publications from the institute among all the studies that met the inclusion criteria (seeSection IV-A).\\nimage [19], e.g., sparsity (see Section II-A in the Supple-\\nmentary Material). Therefore, compared with ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 827: ('ral similarity index, a popular metric of pe rformance of deep learning model in CS reconstruction; and PSNR: peak\\nsignal-to-noise ratio. (c) Number of publications in each country over time. (d) Number of publications by the research institute. The numberin the bracket indicates the proportion of the publications from the institute among all the studies that met the inclusion criteria (seeSection IV-A).\\nimage [19], e.g., sparsity (see Section II-A in the Supple-\\nmentary Material). Therefore, compared with ETE tech-niques, UO incorporates prior domain knowledge about\\nthe expected property of MR images [15]. This reduces the\\nsolution space and facilitates model convergence and per-formance [13]. It may underpin the superior performance\\nof UO methods compared with ETE ones [15] with fewer\\nparameters [14].\\nFurthermore, different networks with different weights\\nor parameters can be used in different iterations of UO.In each iteration, each subnetwork has a relatively smallreceptive ﬁeld and can perform the local transforma-\\ntion. This can avoid overﬁtting as may occur in ETEmodels [10]. Compared with using the same network\\nwith the same weights in each iteration, this no-weight\\nsharing approach has demonstrated superior perfor-mance [9], [20], [21] with some exceptions [22]. Building\\nupon this no-weight sharing approach, Zeng et al. [23]\\nincorporated dense connections between subnetworks,\\na technique inspired by image super-resolution literature.\\nThis allows each subnetwork to receive the output fromall the preceding subnetworks [23]. These developments\\n226 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 1 Summary of the Regularizer Terms Used in Deep UO and Their Rela tionship to the Corresponding Traditional CS Techniques\\nshow that UO is a robust, ﬂexible, and powerful deep-\\nlearning-based CS-MRI technique.\\nCompared with ETE models, the iterative nature of\\nUO increases the computation time. This arises from\\nthe nee', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 828: ('ng subnetworks [23]. These developments\\n226 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 1 Summary of the Regularizer Terms Used in Deep UO and Their Rela tionship to the Corresponding Traditional CS Techniques\\nshow that UO is a robust, ﬂexible, and powerful deep-\\nlearning-based CS-MRI technique.\\nCompared with ETE models, the iterative nature of\\nUO increases the computation time. This arises from\\nthe need to update both the network weights and the\\nreconstructed images to maintain k-space data ﬁdelity[see (2)]. In contrast, ETE methods only need to\\noptimize and update network parameters during the\\ntraining procedure. To mitigate the iterative nature ofupdating the reconstructed image, one approach trains the\\ndeep-learning-based regularizer term alone without the\\ndata ﬁdelity term [31]–[34] in (2). Then, during image\\nreconstruction, the trained regularizer is reincorporated to\\noptimize the reconstructed image. This solution decom-poses the process of optimizing the network parameters\\nand images into optimizing them separately .\\nThe second, and more popular approach, is to train the\\nunrolled model in an ETE fashion by expressing (2) in a\\nclose form. To illustrate, the deep cascaded convolutional\\nneural network (DC-CNN) [10] applies the following lossfunction to update the network parameters and recon-\\nstructed images :\\nargmin\\nx,θ||UFx−y||2\\n2+ι||x−f(x|θ)|| (3)\\nwhere θdenotes all network parameters, f(x|θ)denotes\\nthe output of the deep learning regularizer, and ιis a\\nscalar to adjust the relative contributions of the two terms.\\nThe close form of (3) is\\nx=ιy+Ff(x|θ)\\nι+1\\nat k-space locations that are sampled and\\nx=f(x|θ)\\nat k-space locations that are not sampled.\\nWe can also interpret this closed form as another\\ncomputation layer, called the data consistency layer, in deep\\nlearning models. The process of iteratively reconstructing\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 227\\nChen et al. : AI-Based Reco', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 829: ('\\nthe output of the deep learning regularizer, and ιis a\\nscalar to adjust the relative contributions of the two terms.\\nThe close form of (3) is\\nx=ιy+Ff(x|θ)\\nι+1\\nat k-space locations that are sampled and\\nx=f(x|θ)\\nat k-space locations that are not sampled.\\nWe can also interpret this closed form as another\\ncomputation layer, called the data consistency layer, in deep\\nlearning models. The process of iteratively reconstructing\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 227\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nFig. 2. Features of the datasets used by different studies. (a) Number of publications that use public and private datasets over time. The\\nproportions of studies using public datasets are labeled above each bar. The correlation of these proportions with publication time was 0.839(top left corner). Boxplot showing training (b) and (c) testing sample sizes over time. The p-value of changes over time from theKruskal–Wallis test is shown above each plot. (d) Histogram of the square root of pixel number of the input image to the deep learningmodels. For example, “256” indicates that the input image is 256 ×256 in size. (e) MRI sequence of the images in the datasets used by\\ndifferent studies. Abbreviations: PD: proton density (including those with and without fat suppression); MRA: magnetic resonanceangiography; 129Xe:129Xe imaging; and CE: contrast enhanced. (f) Anatomical region of the images in the datasets used by different\\nstudies. (g) Data augmentation techniques used by different studies.\\nthe MR images and updating model parameters is\\na cascade of alternating model reconstruction and data\\nconsistency reinforcement (see Fig. 2 in the Supplementary\\nMaterial). In other words, this cascade of neural networksbecomes an ETE model and is trained in the same fashion.\\nDC-CNN has, since then, become an integral part of\\nsubsequent model designs [8], [9], [34], [35], [36, p. 2],[37]–[40]. However, DC-CNN is not computationallyefﬁcient for parallel imaging-based C', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 830: ('on techniques used by different studies.\\nthe MR images and updating model parameters is\\na cascade of alternating model reconstruction and data\\nconsistency reinforcement (see Fig. 2 in the Supplementary\\nMaterial). In other words, this cascade of neural networksbecomes an ETE model and is trained in the same fashion.\\nDC-CNN has, since then, become an integral part of\\nsubsequent model designs [8], [9], [34], [35], [36, p. 2],[37]–[40]. However, DC-CNN is not computationallyefﬁcient for parallel imaging-based CS acquisition [41],\\npotentially preventing the wider spread of DC-CNN-based\\nmethods. Moreover, one cannot always derive the closed\\nform of other loss functions as trivially as in DC-CNN [42].To circumvent this problem, some models apply simple\\ngradient descent [30], [43]–[45], conjugate gradient\\ndescent [22], [29], [46], or auxiliary variables [21] (seeSections II-B–II-D in the Supplementary Material) to\\n228 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nFig. 3. Neural network design traits. (a) Number of publications over time by whether the model applies supervised learning. The\\nproportion of unsupervised learning studies is in the text above each bar. (b) Number of publications over time by model category. Theproportion of ETE models is indicated in the text above each bar. (c) Number and proportion (in square brackets) of studies that use each ofthe key design traits in deep learning models. The ﬁeld “others” indicate the studies that did not report the relevant design traits. (d) Lossfunctions used by different studies. Abbreviations: MSE: mean square error between the reconstructed image and ground truth; L1: L1 lossfunction; L2: L2 loss function; data consistency: difference between the reconstructed image and ground truth at undersampled k-spacepixels; RMSE: root mean square error; LSGAN: least-squares generative adversarial network; and VGG16: difference in the image embeddingfrom the VGG16 network between ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 831: ('indicate the studies that did not report the relevant design traits. (d) Lossfunctions used by different studies. Abbreviations: MSE: mean square error between the reconstructed image and ground truth; L1: L1 lossfunction; L2: L2 loss function; data consistency: difference between the reconstructed image and ground truth at undersampled k-spacepixels; RMSE: root mean square error; LSGAN: least-squares generative adversarial network; and VGG16: difference in the image embeddingfrom the VGG16 network between the reconstructed image and ground truth. (e) Number of loss functions used by different studies.(f) Input image characteristics. (g) Computation time over time. (h) Number of parameters over time. The p-value at the top was calculatedusing the Kruskal–Wallis test. (i) PCA of all the models. Each dot represents one model. The dots are colored according to the GMM clusterthey belong to. The position and size of the ellipses represent the mean and twice the standard deviation of each Gaussian model in themixture, which is projected onto PC1 and PC2. Abbreviations: simple ETE: simple end-to-end models; PI UO: parallel imaging-based unrolledoptimization; non-PI UO: unrolled optimization without implementing parallel imaging; and residual UO: unrolled optimization thatimplements residual learning.\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 229\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nimplement UO in an ETE fashion to facilitate the model\\ntraining process.\\nWhile unrolled methods can be trained ETE, ETE meth-\\nods can incorporate features of UO. For example, vari-ous ETE models integrate the data consistency layer to\\nenforce k-space data consistency [47]–[51]. It enables ETE\\nmethods to enjoy the beneﬁts of enforcing data ﬁdelity .Therefore, combining ETE and unrolled features in a single\\nmodel may increase the diversity of network designs that\\nalso share the beneﬁts of both categories.\\nD. Unsupervised Learning\\nThe above discussion on unrolled versus ETE models\\n', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 832: ('While unrolled methods can be trained ETE, ETE meth-\\nods can incorporate features of UO. For example, vari-ous ETE models integrate the data consistency layer to\\nenforce k-space data consistency [47]–[51]. It enables ETE\\nmethods to enjoy the beneﬁts of enforcing data ﬁdelity .Therefore, combining ETE and unrolled features in a single\\nmodel may increase the diversity of network designs that\\nalso share the beneﬁts of both categories.\\nD. Unsupervised Learning\\nThe above discussion on unrolled versus ETE models\\nassumes that the ground-truth MR images are available\\nto train the model to learn the mapping between the\\nundersampled images and the ground truth. That is,\\nthe training process is supervised. If the ground-truth\\nimages are not available, the model requires unsupervisedtraining [52]. The objective is to minimize the differ-\\nence between reconstructed images and the undersampled\\nimages at the undersampled k-space locations, i.e., enforc-ing data consistency [52]. Even without fully sampled\\nground truth, unsupervised models can remove undersam-\\npling artifacts effectively . The reason is that, even without\\ntraining, a deep learning model can capture a great deal\\nof image statistics [53]. Most unsupervised methods useUO and alternately optimize the reconstructed images\\nand the model parameters [24], [25], [54], [55]. Only\\none study implements an ETE training [52]. Most studiesdemonstrate higher quality reconstruction over traditional\\nCS techniques [24], [25], [54], [55] and the supervised\\nlearning model [21], ADMM-CSNet [24]. This underscores\\nthe prospect of unsupervised learning when ground-truth\\nimages are unavailable.\\nII.NETWORK ARCHITECTURES\\nHaving surveyed the two main categories of deep-learning-\\nbased CS-MRI techniques, we will visit the key milestones\\nduring the development of deep-learning-based CS-MRI\\n(see Fig. 3 in the Supplementary Material) (for less com-monly used designs, refer to Section I in the Supplemen-\\ntary Material).\\nA. Variational Network\\nA variational network (VN), an UO method, uses\\nﬁeld-o', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 833: ('MM-CSNet [24]. This underscores\\nthe prospect of unsupervised learning when ground-truth\\nimages are unavailable.\\nII.NETWORK ARCHITECTURES\\nHaving surveyed the two main categories of deep-learning-\\nbased CS-MRI techniques, we will visit the key milestones\\nduring the development of deep-learning-based CS-MRI\\n(see Fig. 3 in the Supplementary Material) (for less com-monly used designs, refer to Section I in the Supplemen-\\ntary Material).\\nA. Variational Network\\nA variational network (VN), an UO method, uses\\nﬁeld-of-expert function as a regularizer in the imagereconstruction loss function [30], [43]–[45] [see (2)].\\nField-of-experts apply convolutional ﬁlters on the input\\nundersampled images followed by activation functions.Unlike the activation functions used in typical neural\\nnetworks, these functions are trainable. The trainable\\nconvolutional ﬁlters and activation functions are opti-\\nmized to perform image regularization (see Table 2 in the\\nSupplementary Material). The strength of VN is that theyrequire 10 to 100 times fewer parameters than a typ-\\nical deep-learning-based CS-MRI model. Therefore, thecomputational load may be lower with a smaller risk of\\noverﬁtting. This has a greater potential for the more com-\\nputationally demanding 3-D or 4-D reconstruction [45].\\nB. Generative Adversarial Network\\nThe generative adversarial network (GAN) has\\nrevolutionized the ﬁeld of synthesizing photorealistic\\nimages [50], [56]. A GAN consists of a generator and\\na discriminator. The discriminator has trained to label\\nthe ground-truth MR images as being “real” and the\\nreconstructed MR images as “fake.” The generator doesthe opposite: its reconstructed images resemble fully\\nsampled ones such that the discriminator would label\\nthe reconstructed images as “real.” With an optimaldiscriminator, the generator minimizes the Shannon–\\nJensen divergence between the reconstructed and fully\\nsampled images (see Section II-E in the Supplementary\\nMaterial). The dealiasing GAN (DAGAN) [3] pioneers\\nGAN-based CS-MRI, which consists of 10.8% of themode', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 834: ('uth MR images as being “real” and the\\nreconstructed MR images as “fake.” The generator doesthe opposite: its reconstructed images resemble fully\\nsampled ones such that the discriminator would label\\nthe reconstructed images as “real.” With an optimaldiscriminator, the generator minimizes the Shannon–\\nJensen divergence between the reconstructed and fully\\nsampled images (see Section II-E in the Supplementary\\nMaterial). The dealiasing GAN (DAGAN) [3] pioneers\\nGAN-based CS-MRI, which consists of 10.8% of themodels in this review [48], [50], [57]–[63]. DAGAN has\\nachieved superior reconstruction performance compared\\nwith traditional CS techniques and ADMM-Net [64].\\nHowever, GAN suffers from training instability , slow\\nconvergence to the global minimum [65], [66], and van-\\nishing gradient [67]. The Wasserstein GAN (WGAN) couldmitigate these issues [68]. Instead of the Shannon–Jensen\\ndivergence, WGAN minimizes the Wasserstein distance\\nbetween the reconstructed and fully sampled images.\\nWGAN-based models outperform DAGAN and cycle-\\nGAN [59], [61], which do not use WGAN. Anotherlimitation of GAN is that they “overemphasize the high-\\nfrequency texture, thus, ignore image contents [50],\\nand can produce oversmoothened appearance [69].”The least-squares GAN (LSGAN) can address this prob-\\nlem [48], [62]. Taken together, while WGAN addresses the\\ntraining instability of GAN, LSGAN may tackle the high-\\nfrequency texture issue.\\nOur interpretation of the effectiveness of GAN-based\\nmethods may be confounded by other model design\\nelements. For example, in all GAN-based methods,\\nthe loss functions also penalize the deviationsbetween reconstructed and fully sampled images\\nin the image and/or k-space domain. Some studies\\npenalize the perceptual quality difference using the\\nVGG16 network [3], [59]; others enforce k-space data\\nﬁdelity [57]. Nevertheless, without other penalty terms,a GAN-only model still outperforms ADMM-Net [3].\\nTherefore, GAN-based techniques are promising CS-MRI\\nreconstruction methods, whose performance can befurther enh', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 835: ('ments. For example, in all GAN-based methods,\\nthe loss functions also penalize the deviationsbetween reconstructed and fully sampled images\\nin the image and/or k-space domain. Some studies\\npenalize the perceptual quality difference using the\\nVGG16 network [3], [59]; others enforce k-space data\\nﬁdelity [57]. Nevertheless, without other penalty terms,a GAN-only model still outperforms ADMM-Net [3].\\nTherefore, GAN-based techniques are promising CS-MRI\\nreconstruction methods, whose performance can befurther enhanced by auxiliary penalties.\\nC. Input Domain\\nAmong the studies in this review, 89.1% of the proposed\\nmodels reconstruct the undersampled input in the image\\ndomain. Three studies [70]–[72] operate on the under-\\nsampled k-space with higher reconstruction accuracy com-pared with the image-domain techniques, e.g., DC-CNN\\n230 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 2 Modiﬁed CLAIM Criteria for Collecting Information From Each Paper During the Meta-Analysis\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 231\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 2 (Continued.) Modiﬁed CLAIM Criteria for Collecting Information From Each Paper During the Meta-Analysis\\nand VN [71]. Two studies [32] and [73] use a hybrid of\\nk-space and image space. That is, for a 2-D undersampled\\nk-space input, inverse Fourier transform was performed\\nalong the x-axis. This means that the x-axis represents the\\nimage-domain information and the y-axis k-space signals.\\nThe performance is higher over the image-domain method,\\nADMM-Net [73].\\nThe cross-domain design, an increasingly popular strat-\\negy , leverages signals from multiple domains. KIKI-netpioneers cross-domain networks [8]. It concatenates a\\nsubnetwork operating on the k-space (k-net) with another\\nsubnetwork on the image domain (i-net) and so on. Theundersampled k-space signals are ﬁrst reconstructed by\\nthe k-net, followed by th', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 836: ('at the x-axis represents the\\nimage-domain information and the y-axis k-space signals.\\nThe performance is higher over the image-domain method,\\nADMM-Net [73].\\nThe cross-domain design, an increasingly popular strat-\\negy , leverages signals from multiple domains. KIKI-netpioneers cross-domain networks [8]. It concatenates a\\nsubnetwork operating on the k-space (k-net) with another\\nsubnetwork on the image domain (i-net) and so on. Theundersampled k-space signals are ﬁrst reconstructed by\\nthe k-net, followed by the inverse Fourier transform to the\\nimage domain to be processed by the i-net (see Fig. 2 in\\nthe Supplementary Material). A similar network design\\nfollows [63] and [74]–[76]. Apart from k-net and i-net,one study [40] concatenates a w-net, a subnetwork that\\noperates on the wavelet domain of the input image. The\\nadvantage of a cross-domain network is that the k-space-based network excels in removing high-frequency artifacts.\\nThe image-space network improves image sharpness and\\nclarity [8]. The wavelet-domain network exploits both\\nspatial and frequency features that may potentially accel-\\nerate feature learning [77]. Consequently , cross-domainnetworks outperform networks that operate only in the\\nimage domain [40], [63], [76], [78].\\nBesides joining subnetworks on different domains in\\nseries, some cross-domain networks concatenate subnet-\\nworks in parallel (see Fig. 2 in the Supplementary Mate-\\nrial) [38], [79]. The undersampled k-space signals are\\nsupplied to a k-net. In parallel, the undersampled image\\nfrom the inverse Fourier transform is supplied to an i-net.Extensive connections between k-net and i-net facilitatethe learning of a noise-free latent representation of the\\ninput image. This design surpasses image-domain methods\\nin reconstruction quality , including ADMM-CSNet (both\\nstudies), DC-CNN [79], and DAGAN [38]. However, cross-domain models are limited by their increased parameter\\nnumbers. To satisfy hardware requirements, each subnet-\\nwork in the IKIK-net needs to be trained separately [8].\\nThis imposes ch', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 837: ('inverse Fourier transform is supplied to an i-net.Extensive connections between k-net and i-net facilitatethe learning of a noise-free latent representation of the\\ninput image. This design surpasses image-domain methods\\nin reconstruction quality , including ADMM-CSNet (both\\nstudies), DC-CNN [79], and DAGAN [38]. However, cross-domain models are limited by their increased parameter\\nnumbers. To satisfy hardware requirements, each subnet-\\nwork in the IKIK-net needs to be trained separately [8].\\nThis imposes challenges for training cross-domain models\\ndespite their exciting prospect by correcting undersam-pling artifacts from multiple domains [40].\\nD. Residual Learning\\nResidual learning (in 51.1% of deep-learning-based CS-\\nMRI designs) learns the difference or the residual betweenthe ground truth and undersampled input, outperforming\\nnonresidual learning [3], [9]. The rationale is to “constrain\\nthe generator to reconstruct only the missing details and\\nprevent it from generating arbitrary features that may\\nnot be present in real MR images” [3]. Residual learningcan also mitigate training difﬁculty as the topological\\ncomplexity of the residual difference may be smaller com-\\npared to the entire MR image [47]. This effectiveness hasbeen justiﬁed by the persistent homology analysis [17].\\nE. Attention\\nAn attention module is a computational layer in the\\nneural network [51], [81]. This module learns the mostimportant pixel in the input to attend to, i.e., learning the\\noptimal weights assigned to each pixel. Compared with\\nthe same model without attention modules, this design\\nachieves a higher reconstruction accuracy . However, a key\\nlimitation of attention modules is their high computationaldemand, which is addressed by the memory-efﬁcient self-\\nattention module proposed by Zhou et al. [82].\\n232 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nIII. IMAGE REDUNDANCY\\nAnother important technique to accelerate AI-powered fast\\nMRI is ima', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 838: ('he same model without attention modules, this design\\nachieves a higher reconstruction accuracy . However, a key\\nlimitation of attention modules is their high computationaldemand, which is addressed by the memory-efﬁcient self-\\nattention module proposed by Zhou et al. [82].\\n232 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nIII. IMAGE REDUNDANCY\\nAnother important technique to accelerate AI-powered fast\\nMRI is image redundancy . Between 2019 and 2020, there\\nhas been a trend toward exploiting MR image redun-dancy across multiple contrasts, spatiotemporal dimen-\\nsions, and parallel imaging coils to improve performance\\nand acceleration rates.\\nA. Redundancy Across Contrast Modalities\\nDifferent clinical settings demand different contrasts for\\nMR images, e.g., T1 weighted, T2 weighted, and pro-\\nton density . For example, T1 weighted images providedetailed anatomical structures, while pathological features\\nare usually more apparent in T2 weighted images [4].\\nTo improve the clinical diagnostic power, MR images of\\nmultiple contrasts are required [83]. Because images with\\ndifferent contrasts of the same structure convey similaranatomical information, the information redundancy can\\nbe used to accelerate CS-MRI.\\nAmong the reviewed studies, the earliest [84] uses\\nfully sampled T1 weighted images to guide the recon-\\nstruction of the corresponding undersampled T2 weighted\\nimages. T1 weighted and T2 weighted images are con-\\ncatenated as a two-channel input to the deep learning\\nmodel. This method achieves superior reconstruction per-formance compared with the model without the fully sam-\\npled T1 weighted image. A similar design was employed\\nin [48]. Other studies [44], [85] concatenate undersam-pled images without the guidance of fully sampled ones.\\nAlternatively , two separate networks are trained for sep-\\narate contrasts with extensive crosstalk between the two\\nnetworks, outperforming the same network without multi-\\ncontrast informati', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 839: (' as a two-channel input to the deep learning\\nmodel. This method achieves superior reconstruction per-formance compared with the model without the fully sam-\\npled T1 weighted image. A similar design was employed\\nin [48]. Other studies [44], [85] concatenate undersam-pled images without the guidance of fully sampled ones.\\nAlternatively , two separate networks are trained for sep-\\narate contrasts with extensive crosstalk between the two\\nnetworks, outperforming the same network without multi-\\ncontrast information [86]. However, the limitation of mul-ticontrast reconstruction is that signals from one contrast\\nmay leak into another [44]. Furthermore, the network\\ncannot process an arbitrary number of contrasts withoutsigniﬁcant structural modiﬁcations. Despite these short-\\ncomings, multicontrast MR reconstruction represents a sig-\\nniﬁcant step forward in exploiting MR image redundancy.\\nB. Spatiotemporal Redundancy\\nSpatiotemporal redundancy increases in higher dimen-\\nsional MR images. To illustrate, in 3-D imaging, structuresin two neighboring planes are unlikely to be drastically\\ndifferent and are correlated. Likewise, in 4-D imaging\\n(3-D spatial plus a temporal dimension), the structuresbetween two adjacent time frames are correlated. How-\\never, extending 2-D deep-learning-based CS-MRI models\\nto 3-D and 4-D usually requires computationally costly3-D or 4-D convolution operations [87]. To mitigate\\nthe 3-D computational demand, most studies [29], [78],\\n[88]–[90] use 2 +1 convolution. This involves a 2-D con-\\nvolution along two dimensions of the input image fol-\\nlowed by a 1-D convolution along the rest of the oneaxis [91]. However, it is difﬁcult to evaluate the perfor-\\nmance of 3-D deep-learning-based CS-MRI models againsttypical deep learning methods, most of which (88.0% of\\nthe reviewed studies) target 2-D reconstructions. Despite\\nthe computational challenge and the lack of evaluation\\nframeworks, two studies [45], [92] venture into 4-D MRIreconstruction. Analogous to 2 +1 convolution, 3-D spa-\\ntial convolution followe', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 840: ('long two dimensions of the input image fol-\\nlowed by a 1-D convolution along the rest of the oneaxis [91]. However, it is difﬁcult to evaluate the perfor-\\nmance of 3-D deep-learning-based CS-MRI models againsttypical deep learning methods, most of which (88.0% of\\nthe reviewed studies) target 2-D reconstructions. Despite\\nthe computational challenge and the lack of evaluation\\nframeworks, two studies [45], [92] venture into 4-D MRIreconstruction. Analogous to 2 +1 convolution, 3-D spa-\\ntial convolution followed by 1-D temporal convolution is\\napplied [92]. Hence, multidimensional MR image recon-struction tends to avoid computationally costly multidi-\\nmensional convolutions.\\nC. Parallel Imaging With Coil Redundancy\\nIn 41.3% of the reviewed studies, parallel imaging is\\ncombined with CS to exploit the k-space signal redundancy\\ncollected by multiple receiver coils. Similar to multicon-trast reconstruction, for separate imaging coils, many stud-\\nies use separate input and outputs channels [17], [40],\\n[57], [70], [75], [76], [78], [ 80], [93]–[95]. The recon-\\nstructed images for each coil are then combined by the\\nsum-of-squares. One exception [94] uses a separate net-\\nwork to perform the coil combination. However, neither\\ndesign can handle signals of an arbitrary number of coils.\\nAnother approach is to incorporate parallel imaging into\\nthe optimization objective. To illustrate, the coil sensitivity\\nmatrix S\\nidescribes the regions that a particular coil iis\\nmost sensitive to. Then, the image acquisition model (1)and the training objective (2) can be modiﬁed, respectively ,\\nas\\ny\\ni=USiFx\\nand\\n1\\n2||USiFx−y||2\\n2+R(x).\\nDeep learning models can be modiﬁed accord-\\ningly [12], [20], [26], [30], [ 43]–[45], [78], [92], [93],\\n[96]–[101].\\nWhile deep parallel imaging CS techniques can further\\naccelerate MR acquisition, evaluating their performance\\nagainst single-coil reconstructions is challenging. This is\\nbecause different datasets are required for multi- and\\nsingle-coil applications. Alternately , coil compression ofraw undersampled m', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 841: ('raining objective (2) can be modiﬁed, respectively ,\\nas\\ny\\ni=USiFx\\nand\\n1\\n2||USiFx−y||2\\n2+R(x).\\nDeep learning models can be modiﬁed accord-\\ningly [12], [20], [26], [30], [ 43]–[45], [78], [92], [93],\\n[96]–[101].\\nWhile deep parallel imaging CS techniques can further\\naccelerate MR acquisition, evaluating their performance\\nagainst single-coil reconstructions is challenging. This is\\nbecause different datasets are required for multi- and\\nsingle-coil applications. Alternately , coil compression ofraw undersampled multicoil data into a single coil may\\nbe used, but this comparison may not be fair [102].\\nFurthermore, in various multicoil studies, coil compres-sion of the multicoil raw data into a smaller number\\nof virtual coils was applied [41], [45], [90] to reduce\\nthe computational demands. It is unclear whether thismeasure can best utilize the multicoil information or reﬂect\\nthe model performance on raw uncompressed multicoil\\nsignals. Despite various computational and evaluational\\nchallenges to exploiting multicontrast, spatiotemporal, and\\nparallel imaging redundancies, the recent developmentsreﬂect the remarkable community efforts in improving the\\nspeed and accuracy of CS-MRI.\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 233\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nIV.META - ANALYSIS METHOD\\nA. Data Collection\\nTo quantitatively evaluate the trend of deep-learning-\\nbased CS-MRI development, we mined the literature across\\nfour platforms: Google Scholar, PubMed, IEEE, and Cross-ref. We used the keyword: “MRI,” “reconstruction,” and\\n“deep learning.” The key word “compressed sensing” was\\nnot incorporated to broaden the search range. The searchwas carried out on October 22, 2020. The Publish or\\nPerish software was used to search through Google Scholar,\\nPubMed, and Crossref. Xplorer was used for IEEE journals.\\nThe references of the matched studies were exported as\\na .ris ﬁle and imported into Mendeley Desktop. Using the“Update Details” function in Mendeley Desktop, the de', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 842: ('E, and Cross-ref. We used the keyword: “MRI,” “reconstruction,” and\\n“deep learning.” The key word “compressed sensing” was\\nnot incorporated to broaden the search range. The searchwas carried out on October 22, 2020. The Publish or\\nPerish software was used to search through Google Scholar,\\nPubMed, and Crossref. Xplorer was used for IEEE journals.\\nThe references of the matched studies were exported as\\na .ris ﬁle and imported into Mendeley Desktop. Using the“Update Details” function in Mendeley Desktop, the details\\nof all the references were updated automatically . To facili-\\ntate subsequent ﬁltering statistical analysis, the referenceswere transferred to Zotero, which enables the export of\\nthe references as a.csv ﬁle. For consistency , Zotero was the\\nreference manager for this article.\\n1) Initial Filtering: Initially , 1460 studies were identiﬁed\\nthat matched the three search keywords. Then, 301 dupli-\\ncates were removed based on a case-insensitive match\\nof the titles of the papers, leading to 1159 nondupli-\\ncated studies. Then, the studies without titles or authors\\nwere removed, leaving 1144 studies for subsequent analy-sis. We excluded preprints, conference papers, and other\\nitems that are not published in research journals for\\nthis review. This was done via a case insensitive searchfor the following keywords in the journal names and\\npublishers of the papers: “arxiv,” “spie,” “mirasmart,”\\n“proceeding,” “patent,” “openre view,” “aaai,” “conference,”\\n“book,” “preprint,” “meeting,” “symposium,” “workshop,”\\n“ismrm,” “Proc Intl Soc Mag Recon Med,” “icassp,” “nips,”“lectures,” “book-chapter,” “proceedings-article,” “posted-\\ncontent,” “monograph,” and “dissertation.”\\nAfter ﬁltering, 578 studies remain for a title and abstract\\nscreening.\\n2) Title Screening: Two independent reviewers deter-\\nmined the relevance of a research paper by screening\\nits title. Our title screening criteria are that a study wasremoved if its title contains fewer than two of these three\\nkeywords: “CS,” “MRI,” and “deep learning.” Any dis-\\ncrepancy ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 843: ('” “Proc Intl Soc Mag Recon Med,” “icassp,” “nips,”“lectures,” “book-chapter,” “proceedings-article,” “posted-\\ncontent,” “monograph,” and “dissertation.”\\nAfter ﬁltering, 578 studies remain for a title and abstract\\nscreening.\\n2) Title Screening: Two independent reviewers deter-\\nmined the relevance of a research paper by screening\\nits title. Our title screening criteria are that a study wasremoved if its title contains fewer than two of these three\\nkeywords: “CS,” “MRI,” and “deep learning.” Any dis-\\ncrepancy between the two reviewers was resolved by the\\nopinion of the more senior reviewer. After title screening,\\n221 studies entered the abstract screening stage.\\n3) Abstract Screening: One reviewer performed abstract\\nscreening. The criterion was whether the abstract mentions\\nall three of the keywords: “CS,” “MRI,” and “deep learn-\\ning.” If an abstract was generic, the introduction of thisarticle was brieﬂy examined. Only 123 studies passed our\\nabstract screening criteria.\\n4) Full-Text Screening: Only studies with full text\\navailable in English and that proposed a new deep learn-ing model for CS-MRI were included. The full text was\\nscreened by one reviewer, and the results were scrutinizedby a more senior reviewer. In the ﬁnal review process,\\n92 studies were included. The entire process of literature\\nscreening and exclusion is summarized in Fig. 1(a).\\n5) Data Collection: To summarize the key model design\\ntraits, criteria in the Checklist for Artiﬁcial Intelligence\\nin Medical Imaging [103] were modiﬁed and tailored\\nfor deep CS-MRI studies (see Table 2). For example, themodiﬁed checklist incorporated items that are salient for\\nCS experiments but not necessarily for general-purpose\\nimaging analysis. This includes the pattern of undersam-pling mask, acceleration ratio tested in the study , types of\\nperformance metrics, and so on. All data were collected by\\none reviewer and veriﬁed by another reviewer. Quantita-\\ntive performance measures data were collected from the\\ntables in the main text and the Supplementary Material.In', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 844: ('or deep CS-MRI studies (see Table 2). For example, themodiﬁed checklist incorporated items that are salient for\\nCS experiments but not necessarily for general-purpose\\nimaging analysis. This includes the pattern of undersam-pling mask, acceleration ratio tested in the study , types of\\nperformance metrics, and so on. All data were collected by\\none reviewer and veriﬁed by another reviewer. Quantita-\\ntive performance measures data were collected from the\\ntables in the main text and the Supplementary Material.Initial data cleaning was performed by the text editor vim\\nand later using the programming language R.\\nB. Data Analysis\\n1) Developmental Trend: To determine changes in the\\npopularity of deep CS-MRI model design traits, the Pear-son correlation was computed between the proportion of\\nmodels using a particular trait and the year of publication.\\nTo assess whether numerical variables, such as training or\\ntesting sample sizes, change over time, the p-value was\\ncalculated. This was achieved by using the Kruskal–Wallistest implemented in the kruskal.test function from R pack-\\nage stats [104].\\nTo evaluate the input image size, the pixel number of\\nthe input images to the models was calculated as followed.\\nIf more than one size were reported, the size of the image\\nthat was mentioned ﬁrst in this article was chosen. Then,\\nthe width and the height of the image were multiplied to\\nobtain the pixel number. For studies that process 3-D or4-D images, the dimensions along the x-a n d y-axes are\\nchosen instead.\\nTo evaluate the reproducibility of different studies, the\\nscoring was based on a previous review paper [105].\\nStudies that publish neither the code nor the dataset are\\nclassiﬁed as “hard to reproduce.” Those that publish only\\nt h ec o d eo ro n l yt h ed a t a s e ta r e“ m e d i u mt or e p r o d u c e . ”\\nThose that release both are “easy to reproduce.”\\n2) Clustering: The following features were used to per-\\nform clustering analysis: GAN-based, U-Net-like, mean\\nsquare error (MSE) loss, supervised, residual, complexinput, pa', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 845: ('roducibility of different studies, the\\nscoring was based on a previous review paper [105].\\nStudies that publish neither the code nor the dataset are\\nclassiﬁed as “hard to reproduce.” Those that publish only\\nt h ec o d eo ro n l yt h ed a t a s e ta r e“ m e d i u mt or e p r o d u c e . ”\\nThose that release both are “easy to reproduce.”\\n2) Clustering: The following features were used to per-\\nform clustering analysis: GAN-based, U-Net-like, mean\\nsquare error (MSE) loss, supervised, residual, complexinput, parallel imaging, maximum acceleration, dimen-\\nsion, data consistency , and spatial domain. Features not\\nreported by most of the studies were excluded. The clus-tering algorithm was a Gaussian mixture model (GMM),\\nimplemented by the Mclust function from the R package\\nmclust [106]. The number of mixture models was chosen\\nto be between 1 and 20. Using Bayesian information\\ncriteria, the optimal number of models was determinedto be 8. The cluster names were annotated based on the\\ndesign traits within each cluster.\\n234 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTo visualize the clusters, the principal component analy-\\nsis (PCA) was performed using the prcomp function in\\nthe R package stats. The means and variances of each\\nGaussian model cluster along all the features are projectedonto the ﬁrst two principal components and visualized\\nas ellipses. The centers of the ellipses are the projected\\nm e a n s .T h ea x e sl e n g t h sa r et w i c et h es q u a r er o o to fvariances, representing a 95% conﬁdence interval.\\nThe extent to which metrics are linearly correlated was\\nquantiﬁed using the R\\n2value. This was calculated on\\nthe author’s reported performance of a model at different\\nacceleration ratios over two chosen metrics. The R2value\\nwas obtained using the lm function in the R package stats.\\n3) Performance: To quantify the improvement of a\\nmodel over zero-ﬁlling reconstruction, the model perfor-\\nmance at a particular m', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 846: (' n g t h sa r et w i c et h es q u a r er o o to fvariances, representing a 95% conﬁdence interval.\\nThe extent to which metrics are linearly correlated was\\nquantiﬁed using the R\\n2value. This was calculated on\\nthe author’s reported performance of a model at different\\nacceleration ratios over two chosen metrics. The R2value\\nwas obtained using the lm function in the R package stats.\\n3) Performance: To quantify the improvement of a\\nmodel over zero-ﬁlling reconstruction, the model perfor-\\nmance at a particular metric was divided by the zero-ﬁlling\\nperformance to obtain the odds’ ratio. If the performancedata at more than one acceleration were available, the\\nmean of the odds’ ratio was calculated. Deeks’ test for\\npublication bias [107] was then carried out by calculating\\nthep-value of the regression line between the odds’ ratio\\nand one over square root of the effective sample size.In this study , the effective sample size was estimated using\\nthe testing sample size. The p-value was obtained using\\nthe stat_cor function in the R package ggpubr [108].\\nAll the meta-analyses were performed using the R\\nversion 3.6.3 running on Ubuntu 18.04. We have released\\nthe source code (https://github.com/ayanglab/How-to-\\nPerform-Technical-Systematic-Review-And-Meta-Analysis-\\nTutorial) for reproducible and sustainable future studies.\\nV.META - ANALYSIS RESULTS\\nAmong the 92 studies that meet our meta-analysis inclu-\\nsion criteria [see Fig. 1(a) and (b)], the publication\\nnumber increases exponentially from 2017 to 2020 [see\\nFig. 1(c)]. Most were from China and the USA, account-ing for 63.0% of all studies (31.5% from either country)\\nfollowed by South Korea (12.0%). The institute with the\\nhighest number of publications was Stanford University ,\\nfollowed by the Korea Advanced Institute of Science and\\nTechnology and Xiamen University [see Fig. 1(d)]. Therising publications underscore the increasing importance\\nof deep-learning-based CS-MRI.\\nA. Dataset Characteristics\\nTraining and evaluating deep-learning-based CS-MRI\\nmodels require ground-truth', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 847: ('st were from China and the USA, account-ing for 63.0% of all studies (31.5% from either country)\\nfollowed by South Korea (12.0%). The institute with the\\nhighest number of publications was Stanford University ,\\nfollowed by the Korea Advanced Institute of Science and\\nTechnology and Xiamen University [see Fig. 1(d)]. Therising publications underscore the increasing importance\\nof deep-learning-based CS-MRI.\\nA. Dataset Characteristics\\nTraining and evaluating deep-learning-based CS-MRI\\nmodels require ground-truth MR images. In 84.8% of thestudies, fully sampled MR images served as the ground\\ntruth. However, in 15.2% of the studies, sampling MR\\nimages fully was impossible, for example, in cardiac cineimaging, due to the motion artifacts created by constant\\nheartbeats [41]. Thus, CS-based reconstruction of these\\nnonfully sampled images was treated as ground truth.\\nRegarding the type of datasets, 41 studies (44.6%)\\nused private datasets exclusively , while 30 (32.6%) exclu-sively used public datasets; 21 (22.8%) used both public\\nand private datasets. The most popular datasets werehuman connectome projects (used by 13.0% of the stud-\\nies; see Table 3), fastMRI (10.9%) and IXI (10.9%), but\\nthe tendency to use public datasets decreased over time\\n[see Fig. 2(a)].\\nConsidering the sample size, the mean number of MR\\nscans for model training was 89.9, and that for testing was\\n20.8. Neither the training nor testing sample size changedsigniﬁcantly over time [see Fig. 2(b) and (c)]. To increase\\nthe number of training samples, some studies applied data\\naugmentation. The most popular augmentation techniques\\nwere ﬂipping and rotation [see Fig. 2(d)]. Less popular\\ntechniques included adding random noise [87], sharpness,contrast [38], and using images of different acceleration\\nratios [98]. However, few studies assessed the impact of\\ndata augmentation on the performance of deep learningmodels in CS MRI.\\nFor the source of the datasets, most were collected\\nfrom human volunteers or patients, except three from\\nrats [24], [25], [47]. Most freq', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 848: (' studies applied data\\naugmentation. The most popular augmentation techniques\\nwere ﬂipping and rotation [see Fig. 2(d)]. Less popular\\ntechniques included adding random noise [87], sharpness,contrast [38], and using images of different acceleration\\nratios [98]. However, few studies assessed the impact of\\ndata augmentation on the performance of deep learningmodels in CS MRI.\\nFor the source of the datasets, most were collected\\nfrom human volunteers or patients, except three from\\nrats [24], [25], [47]. Most frequently , the spatial resolu-\\ntion of MR images was 256 ×256 MR [see Fig. 2(e)].\\nThe lowest spatial resolution was 16 ×16 reﬂecting\\nan image patch-based approach [110]. The highest spa-\\ntial resolution was 590 ×590 [96]. Regarding the con-\\ntrast of the MR images, T1 weighted and T2 weighted\\nwere the most popular [see Fig. 2(f)]. The least popular\\nwere MR angiography (MRA), hyperpolarised\\n129Xe imag-\\ning (129Xe), and contrast-enhanced (CE) MRI, probably\\nlinked to the scarcity of publicly available datasets. Regard-ing the anatomical regions, the most popular were brain\\n(45.45%) and knee (21.49%) [see Fig. 2(g)], as most of\\nthe public datasets (see Table 3) consisted of the brainand/or knee images. Cardiac imaging was the third most\\npopular (14.88%). Many (44.4 %) cardiac MRI-based stud-\\nies utilized the temporal dimension of cardiac imaging, i.e.,\\nchanges of cardiac MR images over each cardiac cycle. This\\nincluded 66.9% of the studies that reconstruct 3-D MRimages and 100% of those using 4-D images. Hence, the\\npursuit of multidimensional MRI reconstruction may fuel\\nthe interest toward cardiac MRI.\\nConcerning the pathological features of the datasets,\\n26.1% of the studies used pathology-free training and\\ntesting sets, while 26.1% of the studies included pathol-\\nogy in both sets. Only ten studies (10.9%) included\\npathology-free training sets and pathology-containing testsets to evaluate the generalizability of a deep learning\\nmodel in pathology settings. Three studies demonstrated\\ngood generalizability [45], [101],', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 849: ('pursuit of multidimensional MRI reconstruction may fuel\\nthe interest toward cardiac MRI.\\nConcerning the pathological features of the datasets,\\n26.1% of the studies used pathology-free training and\\ntesting sets, while 26.1% of the studies included pathol-\\nogy in both sets. Only ten studies (10.9%) included\\npathology-free training sets and pathology-containing testsets to evaluate the generalizability of a deep learning\\nmodel in pathology settings. Three studies demonstrated\\ngood generalizability [45], [101], [111].\\nB. Design\\n1) Model Architecture: We also summarized the design\\ntraits of deep learning models. Supervised learning models\\nand unrolled models were increasingly favored, occupy-\\ning greater proportions of the studies over time [see\\nFig. 3(a) and (b)]. Most studies (40.2%) use a U-Net-like network, while 7.6% used a structure similar to\\nDC-CNN [10] [see Fig. 3(c)]. U-Net-like networks became\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 235\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 3 Datasets Used by Each Study\\n236 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nTable 3 (Continued.) Datasets Used by Each Study\\nincreasingly popular over time (correlation =0.87; see\\nTable 3 and Section IV-B in the Supplementary Material),while autoencoder-based networks were less popular (cor-\\nrelation =− 0.84). GAN-based models, the data consis-\\ntency layer, and residual learning [10] were used in aconsiderable proportion of the studies. Both the data\\nconsistency layer and residual learning were increasingly\\nincorporated (correlation =0.91 and 0.88, respectively).\\n2) Loss Functions: Regarding the choice of loss functions\\n[see Fig. 3(d)], the MSE loss was the most frequently used,\\nfollowed by L1 and L2 losses. Instead of MSE and L2, which\\ncan be oversmoothing [17], [94], some studies chose L1\\nloss [12], [48], [50], [73] to facilitate convergence andproduce sharper image', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 850: ('dual learning [10] were used in aconsiderable proportion of the studies. Both the data\\nconsistency layer and residual learning were increasingly\\nincorporated (correlation =0.91 and 0.88, respectively).\\n2) Loss Functions: Regarding the choice of loss functions\\n[see Fig. 3(d)], the MSE loss was the most frequently used,\\nfollowed by L1 and L2 losses. Instead of MSE and L2, which\\ncan be oversmoothing [17], [94], some studies chose L1\\nloss [12], [48], [50], [73] to facilitate convergence andproduce sharper images [50]. To enforce data ﬁdelity , some\\nstudies minimized data consistency loss, i.e., the difference\\nbetween the undersampled k-space data and the recon-structed k-space at the undersampled locations. Some min-\\nimized the MSE in k-space, or in one study , in the wavelet\\ndomain [40]. To enhance perceptual quality , a few studies\\nminimized the difference in the image embeddings from a\\ntrained VGG16 network between ground-truth and recon-structed images [3]. Only two studies incorporated L2 reg-\\nularization as a strategy to prevent overﬁtting [36], [102],\\nand one study uses L1 regularization [25]. One study [95]minimized the negative of SSIM of the reconstructed image\\nas SSIM was a key performance metric of CS recon-\\nstruction. Other performance metric-based loss functions\\nincluded the normalized MSE (NMSE) [128], the normal-\\nized root MSE (NRMSE) [20], and the mean absoluteerror (MAE) [35], [39]. For probabilistic deep learning\\nmodels, the loss function was based upon maximum a\\nposteriori [99] or the Kullback–Leibler divergence between\\nthe latent encodings for reconstructed and ground-truth\\nimage distribution [58]. The loss functions with increased\\nusage over time were L2, data consistency loss, and RMSE(see Table 4 in the Supplementary Material). Altogether,\\nMSE was the most prevalent loss function, and recent\\ndeep-learning-based CS-MRI developments have explored\\nthe diversity of loss function choices.\\nVarious studies integrated multiple loss functions to uti-\\nlize the merits of them jointly [see Fig. 3(e)]. To ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 851: ('eibler divergence between\\nthe latent encodings for reconstructed and ground-truth\\nimage distribution [58]. The loss functions with increased\\nusage over time were L2, data consistency loss, and RMSE(see Table 4 in the Supplementary Material). Altogether,\\nMSE was the most prevalent loss function, and recent\\ndeep-learning-based CS-MRI developments have explored\\nthe diversity of loss function choices.\\nVarious studies integrated multiple loss functions to uti-\\nlize the merits of them jointly [see Fig. 3(e)]. To illustrate,\\nDAGAN [3] minimized the MSE in both image and k-space.The VGG16-based loss function was added to improve\\nthe perceptual quality . The GAN-based adversarial losswas integrated to generate photorealistic images. Ablation\\nexperiments showed that each loss function was essential\\nfor DAGAN performance. Despite the advantages of mul-tiple loss functions for the model training, its application\\ndid not change over time (correlation =0.02). This may be\\nbecause the training process was complicated by the need\\nto balance the weightings of different loss components\\nusing the weighting hyperparameters.\\nAmong the optimizers that apply the gradient of the\\nloss function to update model parameters [see Fig. 3(c)],\\nthe most used was the Adam (65.2%), with increasingpopularity over time (correlation =0.95), followed by\\nthe stochastic gradient descent (SGD) (9.8%). In contrast,\\nRMSProp and gradient descent with momentum were used\\nless frequently .\\n3) Input Characteristics: To process input MR images,\\nthe predominant method operated on 2-D complex sig-\\nnals from the image domain [see Fig. 3(f)]. However,\\nwhile raw MR signals are complex numbers, most deeplearning frameworks do not support complex number\\ncalculations [102]. One solution is to only focus on the\\nmagnitude of the complex signals (14.1% of the studies).More commonly (60.9%), in the input layer of the neural\\nnetwork, one channel processed the real part of the MR\\nsignals, the other the imaginary part. Alternatively , the\\ntwo channels can be used to process the', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 852: ('method operated on 2-D complex sig-\\nnals from the image domain [see Fig. 3(f)]. However,\\nwhile raw MR signals are complex numbers, most deeplearning frameworks do not support complex number\\ncalculations [102]. One solution is to only focus on the\\nmagnitude of the complex signals (14.1% of the studies).More commonly (60.9%), in the input layer of the neural\\nnetwork, one channel processed the real part of the MR\\nsignals, the other the imaginary part. Alternatively , the\\ntwo channels can be used to process the magnitude and\\nphase of the complex number signals [17], [48]. However,this magnitude–phase split has no beneﬁts over the real-\\nimaginary split [17]. Consequently , real-imaginary split\\ndominates deep-learning-based CS-MRI model designs.\\nHowever, such a real-imaginary split may not reﬂect the\\nphase information of the complex signals [102]. To tackle\\nthis issue, complex convolution [39] convolves complexnumbers using separate channels for real and imaginary\\nimages (see Section II-F in the Supplementary Material),\\nas adopted by subsequent studies [41], [74], [78], [92].\\nComplex convolution performance exceeded that of nor-\\nmal real-valued convolution [74] and networks thatprocess magnitude images only [41]. However, calcu-\\nlations of complex numbers using real-valued channels\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 237\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nFig. 4. Evaluation of the model performance. (a) Number of publications that applied prospective and retrospective undersampling over\\ntime. The proportion of models using prospective undersampling is in the text above each bar. (b) Metrics used by different studies.Abbreviations: SSIM: structural similarity index; PSNR: peak signal-to-noise ratio; NRMSE: normalized root mean square error; MSE: meansquare error; SNR: signal-to-noise ratio; NMSE: normalized mean square error; HFEN: high-frequency error norm; and RMSE: root meansquare error. (c) Number of metrics used by different studies to evaluate', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 853: ('tive and retrospective undersampling over\\ntime. The proportion of models using prospective undersampling is in the text above each bar. (b) Metrics used by different studies.Abbreviations: SSIM: structural similarity index; PSNR: peak signal-to-noise ratio; NRMSE: normalized root mean square error; MSE: meansquare error; SNR: signal-to-noise ratio; NMSE: normalized mean square error; HFEN: high-frequency error norm; and RMSE: root meansquare error. (c) Number of metrics used by different studies to evaluate model performance. The correlation of the number of metrics withtime is shown in the top left corner. (d) PSNR and SSIM of the model performance across all the studies that provided performance statistics.Each dot represents the performance at a particular metric at a particular acceleration ratio using a particular method in a study. The reddashed line represents the mean of SSIM and PSNR across all studies over all acceleration ratios. (e) PSNR values of each model are plottedalong the x-axis and the corresponding SSIM values along the y-axis. Each dot represents one model at a particular acceleration ratio.(f) Heatmap showing the R2value between a pair of metrics. The gray region indicates where the R2value is not available due to small\\nsample sizes. Abbreviations: MAE: mean absolute error; RLNE: relative L2 norm error; MSSIM: mean structural similarity index map; OQ:overall quality; CN: contrast difference; and CNR: contrast-to-noise ratio. (g) Comparison methods used by different studies. (h) Number ofcomparison methods used by different studies. Abbreviations: ZF: zero ﬁlling; TV: total variation; DC-CNN: deep cascaded convolutionalneural network; PANO: patch-based nonlocal operator; ADMM-Net: alternating direction method of multipliers; DLMRI: dictionary learningMRI; BM3D: block matching 3-D; and DAGAN: dealiasing generative adversarial network.\\n238 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nmay not be a', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 854: ('omparison methods used by different studies. Abbreviations: ZF: zero ﬁlling; TV: total variation; DC-CNN: deep cascaded convolutionalneural network; PANO: patch-based nonlocal operator; ADMM-Net: alternating direction method of multipliers; DLMRI: dictionary learningMRI; BM3D: block matching 3-D; and DAGAN: dealiasing generative adversarial network.\\n238 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nmay not be applicable for other computational layers of\\nthe neural networks, e.g., batch normalization. The solu-\\ntion [74], [78] is radial batch normalization, that is, per-\\nforming batch normalization on the magnitude image only ,but the phase information is ignored. Despite attempts\\nto circumvent complex-valued calculations, support for\\ncomplex-valued operations is still an unmet need in deeplearning frameworks.\\n4) Other Features: We next assessed the reproducibil-\\nity of deep learning models by considering whether the\\ndataset and source code were accessible [105]. 40.2% ofthe studies were “hard to reproduce,” which increased in\\nproportion over time [correlation =0.84; see Fig. 3(f)].\\nMoreover, the computation time or the parameter numberdid not change signiﬁcantly over time ( p=0.38 and\\np=0.50, respectively) [se e Fig. 3(g) and (h)].\\nHaving characterized the model design traits, we used\\nthem to group the studies that we reviewed into eight\\nclusters. The GAN-based cluster featured the GAN-basedCS-MRI models [see Fig. 3(i)]. The models within the\\n“high-acceleration” cluster displayed a high-acceleration\\nratio and multidimensional MR image reconstruction. The“unsupervised” cluster consisted of all unsupervised learn-\\ning models. The “simple ETE” cluster consisted of ETE\\nmodels that mostly do not implement data consistencylayer, residual learning, GAN, or parallel imaging. The\\nUO models were subdivided into three clusters: residual\\nUO that implemented residual learning, PI UO that imple-\\nmented parallel imaging, and non-PI', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 855: ('3(i)]. The models within the\\n“high-acceleration” cluster displayed a high-acceleration\\nratio and multidimensional MR image reconstruction. The“unsupervised” cluster consisted of all unsupervised learn-\\ning models. The “simple ETE” cluster consisted of ETE\\nmodels that mostly do not implement data consistencylayer, residual learning, GAN, or parallel imaging. The\\nUO models were subdivided into three clusters: residual\\nUO that implemented residual learning, PI UO that imple-\\nmented parallel imaging, and non-PI UO. The “others”\\ncluster consisted of studies with diverse traits. We have,therefore, established an unbiased classiﬁcation system to\\ncharacterize the architectural traits of CS-MRI models.\\nC. Evaluation Metrics\\nWe also compared how different studies evaluated the\\nperformance of their reconstruction models. CS-MRI mod-\\nels are tested by reconstructing undersampled images\\nand comparing the reconstructed images with the groundtruth. Undersampling can be retrospective, that is, under-\\nsampling the already acquired MR images. Prospective\\nundersampling means collecting the undersampled k-space\\nsignals directly from the MR scanners and can better\\nreﬂect performance in a real-life situation. Compared withprospective undersampling, retrospective undersampling\\nis more ﬁnancially and logistically feasible [5], and is\\nimplemented in 93.5% of the studies [see Fig. 4(a)].\\nTo compare the reconstructed images with the ground\\ntruth, most studies reported the structural similarity index\\nmeasure (SSIM) and the peak signal-to-noise ratio (PSNR)[see Fig. 4(b)]. Fewer used NRMSE, MSE, and the signal-\\nto-noise ratio (SNR). NRMSE and SSIM became more\\npopular over time, whereas PSNR and NMSE decreased in\\npopularity (see Table 5 in the Supplementary Material).\\nThese metrics were quantitative, i.e., a deﬁned algo-rithm that computes the similarity between the recon-\\nstructed and ground-truth images. In contrast, qualitativemetrics—measures without a clearly deﬁned mathemat-\\nical expression, including the rating scores by human\\nobserver', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 856: ('noise ratio (PSNR)[see Fig. 4(b)]. Fewer used NRMSE, MSE, and the signal-\\nto-noise ratio (SNR). NRMSE and SSIM became more\\npopular over time, whereas PSNR and NMSE decreased in\\npopularity (see Table 5 in the Supplementary Material).\\nThese metrics were quantitative, i.e., a deﬁned algo-rithm that computes the similarity between the recon-\\nstructed and ground-truth images. In contrast, qualitativemetrics—measures without a clearly deﬁned mathemat-\\nical expression, including the rating scores by human\\nobservers and segmentation-based scoring—are used less\\nfrequently . The most popular qualitative metrics wereimage sharpness (6.52%), overall quality (OQ) (4.35%),\\nend-diastolic volume, ejection fraction, and end-systolic\\nvolume as obtained by segmentation (3.26%) and Likertscale (3.26%). Thus, quantitative metrics, such as SSIM,\\nPSNR, and NRMSE, were the most prevalent.\\nMost of the studies reported at least two met-\\nrics to provide alternative performance quantiﬁcations\\n[see Fig. 4(c)]. Across all the acceleration ratios andreported metric performance [see Fig. 4(d)], we interro-\\ngated the redundancy of metrics by using one metric to\\npredict the performance of another via linear regression.In Fig. 4(e), the R\\n2value between SSIM and PSNR is\\nlow, suggesting a nonlinear relationship. For low model\\nperformance, i.e., low PSNR and SSIM values, SSIM was\\nmore sensitive to changes in model performance than\\nPSNR. In contrast, for high-performing models, PSNR wasmore sensitive. The results imply that PSNR and SSIM were\\nunlikely redundant pairs of metrics as each of them may be\\nmost sensitive to different performance levels.\\nLikewise, some quantitative metrics were not correlated,\\ne.g., between SSIM, PSNR, and MSE (see Fig. 4(f), and\\nTable 7 in the Supplementary Material), though MSE,\\nNRMSE, and NMSE are more closely related. The most\\nhighly correlated quantitative metrics are high-frequencyerror norm (HFEN), MAE, PSNR, and MAE. Besides, many\\nqualitative metrics were more linearly related, including\\nsharpness, OQ, artifact, con', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 857: ('ely redundant pairs of metrics as each of them may be\\nmost sensitive to different performance levels.\\nLikewise, some quantitative metrics were not correlated,\\ne.g., between SSIM, PSNR, and MSE (see Fig. 4(f), and\\nTable 7 in the Supplementary Material), though MSE,\\nNRMSE, and NMSE are more closely related. The most\\nhighly correlated quantitative metrics are high-frequencyerror norm (HFEN), MAE, PSNR, and MAE. Besides, many\\nqualitative metrics were more linearly related, including\\nsharpness, OQ, artifact, contrast difference (CN), and thecontrast-to-noise ratio (CNR). Some quantitative and qual-\\nitative metrics also correlated, including RMSE and CNR,\\nSNR and OQ, PSNR and OQ, and SNR and sharpness.\\nHowever, this spuriously high similarity may arise because\\nfewer studies reported qualitative than quantitative met-rics. Despite the difﬁculty of interpreting the qualitative\\nmetrics, quantitative metrics, e.g., SSIM, PSNR, and MSE,\\nwere not linearly dependent. This cautions future researchagainst relying upon a single metric to assess model\\nperformance.\\nTo fully evaluate the performance of a deep learning\\nmodel, 51.9% of studies compared the model perfor-\\nmance with zero-ﬁlling, which represents the baselinereconstruction results. This involves ﬁlling the nonsam-\\npled k-space locations with zeros. Many studies also\\ndemonstrated the superiority of their models to otherstate-of-the-art techniques. Typical comparison techniques\\nincluded U-Net, such as architectures, DC-CNN [10],\\nADMM-Net [64], and DAGAN [3] [see Fig. 4(g)]. Variousstudies also compared the performance to traditional\\ntechniques, including DLMRI [42], TV [2], PANO [139],\\nand BM3D [140]. Increasingly popular comparison meth-\\nods included DC-CNN, U-Net, and GRAPPA [141], but\\nkt-SLR [142] was becoming less popular (see Table 6 inthe Supplementary Material). Besides, 87.0% of the studies\\nreported two or more comparison methods [see Fig. 4(h)].\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 239\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systemat', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 858: ('g)]. Variousstudies also compared the performance to traditional\\ntechniques, including DLMRI [42], TV [2], PANO [139],\\nand BM3D [140]. Increasingly popular comparison meth-\\nods included DC-CNN, U-Net, and GRAPPA [141], but\\nkt-SLR [142] was becoming less popular (see Table 6 inthe Supplementary Material). Besides, 87.0% of the studies\\nreported two or more comparison methods [see Fig. 4(h)].\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 239\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nFig. 5. Performance improvement over the zero-ﬁlled baseline reconstruction. (a) Odds’ ratio of the SSIM improvement over time. The\\nnumber of models assessed for each year group is shown above the boxes. (b) Odds’ ratio of the PSNR improvement over time. (c) Deeks’test using the SSIM odds’ ratio. (d) Deeks’ test using the PSNR odds’ ratio. (e) Odds’ ratio of the SSIM improvement by clusters. (f) Odds’ratio of the PSNR improvement by clusters.\\nTherefore, many studies benchmarked their models\\nagainst zero-ﬁlling, U-Net, TV , and DC-CNN.\\nD. Performance\\nHaving assessed the model design traits and\\nperformance evaluation methods, we explored whichdesign trait was associated with higher performance.We quantiﬁed the performance of each model by the\\nodds’ ratio of improvement in either SSIM or PSNR\\nover zero-ﬁlling. SSIM or PSNR odds’ ratios did not\\nchange signiﬁcantly over time [see Fig. 5(a) and (b)].\\nOn the reported improvements, Deeks’ test did not reveal\\npublication bias [see Fig. 5(c) and (d)]. Across differentclusters of models established earlier [see Fig. 3(i)],\\n240 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nthe performance improvement was not signiﬁcantly\\ndifferent [see Fig. 5(e) and (f)]. Furthermore, none of\\nthe design traits was signiﬁcantly linked to performance\\nimprovement (see Table 8 in the Supplementary Material).The failure of detecting signiﬁcant traits may be because\\nperfo', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 859: (' and (d)]. Across differentclusters of models established earlier [see Fig. 3(i)],\\n240 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nthe performance improvement was not signiﬁcantly\\ndifferent [see Fig. 5(e) and (f)]. Furthermore, none of\\nthe design traits was signiﬁcantly linked to performance\\nimprovement (see Table 8 in the Supplementary Material).The failure of detecting signiﬁcant traits may be because\\nperformance comparison among different models was\\nconfounded by the disparity of dataset and evaluationmetrics among them. Nevertheless, comparing the\\nunadjusted p-values suggested that using the Adam\\noptimizer may lead to higher performance, and using\\na U-Net, such as architecture and GAN, may lead to\\nlower performance. A higher acceleration ratio was linkedto higher SSIM improvement, probably because SSIM\\nwas the most sensitive to low-performing models [see\\nFig. 4(e)], and the raising acceleration ratio tended toreduce performance.\\nTaken together, we have pioneered the meta-analysis\\nframework, summarized the model design traits, ana-\\nlyzed the developmental trend, and established a clas-\\nsiﬁcation network for deep-learning-based CS-MRI tech-niques, forming a comprehensive guide for future\\nresearch.\\nVI.CHALLENGES\\nAlthough deep-learning-based CS-MRI techniques have\\nadvanced rapidly , they still suffer from limitations of the\\ndeep learning algorithms, most importantly , the depen-\\ndence on large training data [11], [143]–[146]. Transferlearning may tackle this problem [36], [130]. With transfer\\nlearning, the models are trained on a source domain,\\nin which training data are abundant, such as naturalimages. Subsequently , model parameters are ﬁne-tuned in\\nthe target domain, in which the reconstruction is required,\\nbut the training data are scarce. Using transfer learning,\\nmodels trained with 4000 natural images, perform as well\\nas the same models trained with MR images [36]. Hence,transfer learning may address the dema', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 860: (' [143]–[146]. Transferlearning may tackle this problem [36], [130]. With transfer\\nlearning, the models are trained on a source domain,\\nin which training data are abundant, such as naturalimages. Subsequently , model parameters are ﬁne-tuned in\\nthe target domain, in which the reconstruction is required,\\nbut the training data are scarce. Using transfer learning,\\nmodels trained with 4000 natural images, perform as well\\nas the same models trained with MR images [36]. Hence,transfer learning may address the demand for large train-\\ning samples.\\nAnother issue with deep-learning-based CS-MRI mod-\\nels is their generalizability to different datasets or appli-\\ncations. A few studies report robust performance of\\nthe models across different datasets and noise lev-\\nels [21], [27], [98], [128]. However, one study shows\\nbetter performance in T1 weighted images compared withFLAIR MR images [8], and another displays higher recon-\\nstruction errors in fat-containing regions [147]. Further-\\nmore, without transfer learning, deep learning modelstrained on natural or T1 weighted images cannot maintain\\nequal performance on T2 weighted images. These results\\nindicate that the same deep-learning-based CS-MRI modelsmay not display similar performance across different MR\\nscanning sequences or anatomical regions. This is con-\\nsistent with the instability of some deep-learning-based\\nmethods, e.g., VN, DAGAN, and DC-CNN upon small per-\\nturbations of the input image [140].\\nWhile deep learning models have a much shorter\\nreconstruction time compared to traditional CStechniques [3], [10], they require a long training\\ntime [143], [149]. This is exacerbated by the need for\\nhyperparameter tuning to select the best-performing\\nmodels [43], [60], [70], [150], [151], as no theoriescurrently govern deep learning model selection [143].\\nDespite their superior performance over traditional\\nCS techniques, motion artifacts may not be effectivelyremoved by deep learning models [9], [41], [120].\\nTherefore, computational challenges exist toward\\ndeveloping a universa', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 861: ('red to traditional CStechniques [3], [10], they require a long training\\ntime [143], [149]. This is exacerbated by the need for\\nhyperparameter tuning to select the best-performing\\nmodels [43], [60], [70], [150], [151], as no theoriescurrently govern deep learning model selection [143].\\nDespite their superior performance over traditional\\nCS techniques, motion artifacts may not be effectivelyremoved by deep learning models [9], [41], [120].\\nTherefore, computational challenges exist toward\\ndeveloping a universally applicable deep-learning-based\\nCS-MRI algorithm.\\nThis systematic review and meta-analysis focused on\\nhow much a deep learning model improved beyond\\nzero-ﬁlling reconstruction. However, such a comparison\\nis challenging given that different models were tested ondifferent datasets, metrics, and acceleration ratios. Fur-\\nthermore, we did not quantitatively explore the reconstruc-\\ntion time to identify the most computationally efﬁcient\\nmodels because not all models were implemented on the\\nsame computing platform. We also did not analyze theoverﬁtting properties, i.e., the discrepancy in performance\\nbetween the training and testing datasets. This is because\\nmost studies reported performance on testing but nottraining datasets. Hence, to facilitate the future systematic\\nreview, we encourage future studies to test their model per-\\nformance on commonly used datasets (human connectome\\nprojects, fastMRI, and IXI in Table 3) and metrics (PSNR\\nand SSIM) and report performance on both training andtesting datasets.\\nVII. CONCLUSION AND OUTLOOK\\nWith the rapid rise of deep learning in computer vision,\\nthe past four years have witnessed substantial changes in\\nthe landscape of deep-learning-based CS-MRI techniques.\\nTo summarize these developments, we have conducted asystematic review and meta-analysis. We have introduced\\na comprehensive analysis framework based on the CLAIM\\ncriteria, summarized the typical deep neural networkarchitectures in CS-MRI, compared their performance, and\\nevaluated their strengths and limitations. Ear', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 862: (' CONCLUSION AND OUTLOOK\\nWith the rapid rise of deep learning in computer vision,\\nthe past four years have witnessed substantial changes in\\nthe landscape of deep-learning-based CS-MRI techniques.\\nTo summarize these developments, we have conducted asystematic review and meta-analysis. We have introduced\\na comprehensive analysis framework based on the CLAIM\\ncriteria, summarized the typical deep neural networkarchitectures in CS-MRI, compared their performance, and\\nevaluated their strengths and limitations. Earlier deep-\\nlearning-based CS-MRI techniques have highlighted the\\ndevelopments of neural network architectures, including\\nthe data consistency layer, VN, GAN, residual learning,cross-domain networks, and so on. More recently , the\\nredundancy of MR images is explored, either across dif-\\nferent contrasts, higher imaging dimensions, or parallelimaging channels. However, with the increasing diver-\\nsity of deep-learning-based CS-MRI techniques, ﬁnding\\nan appropriate and fair comparison benchmark is chal-lenging. Nonetheless, we believe that the excitement of\\nthis ﬁeld lies not only in improving beyond benchmark\\nworks but also in creating new benchmarks for unexplored\\napplications of CS-MRI. With this goal, efforts, and drives\\namong the deep learning community , milestones are setfor faster and more accurate reconstruction performance.\\nThese developments may inspire other MRI applications,\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 241\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nsuch as MRI ﬁngerprinting [152], [153], by synthesizing\\na quantitative map of tissue properties from MR signal\\nevolution over the signal acquisition trajectory . Therefore,\\nwe can envisage that the development of deep-learning-based fast CS-MRI will usher in a new era of digitalhealthcare and personalized medicine, which will be\\nequipped with high throughput and low-cost imag-\\ning, and more reliable quantitative imaging biomarker\\nextraction and analysis.\\nREFERENCES\\n[1] K. G. Hollingsworth', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 863: (' and Meta-Analysis\\nsuch as MRI ﬁngerprinting [152], [153], by synthesizing\\na quantitative map of tissue properties from MR signal\\nevolution over the signal acquisition trajectory . Therefore,\\nwe can envisage that the development of deep-learning-based fast CS-MRI will usher in a new era of digitalhealthcare and personalized medicine, which will be\\nequipped with high throughput and low-cost imag-\\ning, and more reliable quantitative imaging biomarker\\nextraction and analysis.\\nREFERENCES\\n[1] K. G. Hollingsworth, “Reducing acquisition time in\\nclinical MRI by data undersampling and\\ncompressed sensing reconstruction,” Phys. Med.\\nBiol. , vol. 60, no. 21, pp. R297–R322, Oct. 2015,\\ndoi: 10.1088/0031-9155/60/21/R297.\\n[2] M .L u s t i g ,D .D o n o h o ,a n dJ .M .P a u l y ,“ S p a r s e\\nMRI: The application of compressed sensing for\\nrapid MR imaging,” Magn. Reson. Med. , vol. 58,\\nno. 6, pp. 1182–1195, Dec. 2007, doi:10.1002/mrm.21391.\\n[3] G. Yang et al. , “DAGAN: Deep de-aliasing\\ngenerative adversarial networks for fast\\ncompressed sensing MRI reconstruction,” IEEE\\nTrans. Med. Imag. , vol. 37, no. 6, pp. 1310–1321,\\nJun. 2017, doi: 10.1109/TMI.2017.2785879.\\n[4] P.S u e t e n s , Fundamentals of Medical Imaging ,\\n2nd ed. New York, NY , USA: Cambridge Univ.\\nPress, 2009.\\n[5] O .N .J a s p a n ,R .F l e y s h e r ,a n dM .L .L i p t o n ,\\n“Compressed sensing MRI: A review of the clinical\\nliterature,” Brit. J. Radiol. , vol. 88, no. 1056,\\nDec. 2015, Art. no. 20150487, doi:\\n10.1259/bjr .20150487.\\n[6] M. J. Fair, P .D .G a t e h o u s e ,E .V .R .D i B e l l a ,a n d\\nD. N. Firmin, “ A review of 3D ﬁrst-pass,\\nwhole-heart, myocardial perfusion cardiovascular\\nmagnetic resonance,” J. Cardiovascular Magn.\\nReson. , vol. 17, p. 68, Aug. 2015, doi:\\n10.1186/s12968-015-0162-9.\\n[7] S. Vishnukumar and M. Wilscy , “Single image\\nsuper-resolution based on compressive sensingand improved TV minimization sparse recovery ,”\\nOpt. Commun. , vol. 404, pp. 80–93, Dec. 2017,\\ndoi: 10.1016/j.optcom.2017.05.074.\\n[8] T .E o ,Y .J u n ,T .K i m ,J .J a n g ,H', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 864: ('o u s e ,E .V .R .D i B e l l a ,a n d\\nD. N. Firmin, “ A review of 3D ﬁrst-pass,\\nwhole-heart, myocardial perfusion cardiovascular\\nmagnetic resonance,” J. Cardiovascular Magn.\\nReson. , vol. 17, p. 68, Aug. 2015, doi:\\n10.1186/s12968-015-0162-9.\\n[7] S. Vishnukumar and M. Wilscy , “Single image\\nsuper-resolution based on compressive sensingand improved TV minimization sparse recovery ,”\\nOpt. Commun. , vol. 404, pp. 80–93, Dec. 2017,\\ndoi: 10.1016/j.optcom.2017.05.074.\\n[8] T .E o ,Y .J u n ,T .K i m ,J .J a n g ,H . - J .L e e ,a n d\\nD. Hwang, “KIKI-Net: Cross-domain convolutional\\nneural networks for reconstructing undersampled\\nmagnetic resonance images,” Magn. Reson. Med. ,\\nvol. 80, no. 5, pp. 2188–2201, Nov. 2018, doi:\\n10.1002/mrm.27201.\\n[9] C. Qin, J. Schlemper, J. Caballero, A. N. Price,\\nJ. V . Hajnal, and D. Rueckert, “Convolutional\\nrecurrent neural networks for dynamic MR image\\nreconstruction,” IEEE Trans. Med. Imag. ,v o l .3 8 ,\\nno. 1, pp. 280–290, Jan. 2019, doi:\\n10.1109/TMI.2018.2863670.\\n[10] J. Schlemper, J. Caballero, J. V . Hajnal, A. N. Price,\\nand D. Rueckert, “A deep cascade of convolutional\\nneural networks for dynamic MR image\\nreconstruction,” IEEE Trans. Med. Imag. ,v o l .3 7 ,\\nno. 2, pp. 491–503, Feb. 2018, doi:\\n10.1109/TMI.2017.2760978.\\n[11] K.-H. Yu, A. L. Beam, and I. S. Kohane, “Artiﬁcial\\nintelligence in healthcare,” Nature Biomed. Eng. ,\\nvol. 2, no. 10, pp. 719–731, Oct. 2018, doi:\\n10.1038/s41551-018-0305-z.\\n[12] G .L i b e r m a na n dB .A .P o s e r ,“ M i n i m a ll i n e a r\\nnetworks for magnetic resonance image\\nreconstruction,” Sci. Rep. , vol. 9, no. 1, p. 19527,\\nDec. 2019, doi: 10.1038/s41598-019-55763-x.\\n[13] D. Liang, J. Cheng, Z. Ke, and L. Ying, “Deep MRI\\nreconstruction: Unrolled optimization algorithms\\nmeet neural networks,” 2019, arXiv:1907.11711 .\\n[14] D. Liang, J. Cheng, Z. Ke, and L. Ying, “Deep\\nmagnetic resonance image reconstruction: Inverse\\nproblems meet neural networks,” IEEE Signal\\nProcess. Mag. , vol. 37, no. 1, pp. 141–151,\\nJan. 2020, doi: 10.1109/MSP .2019.2950557.\\n[15] H.', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 865: ('gnetic resonance image\\nreconstruction,” Sci. Rep. , vol. 9, no. 1, p. 19527,\\nDec. 2019, doi: 10.1038/s41598-019-55763-x.\\n[13] D. Liang, J. Cheng, Z. Ke, and L. Ying, “Deep MRI\\nreconstruction: Unrolled optimization algorithms\\nmeet neural networks,” 2019, arXiv:1907.11711 .\\n[14] D. Liang, J. Cheng, Z. Ke, and L. Ying, “Deep\\nmagnetic resonance image reconstruction: Inverse\\nproblems meet neural networks,” IEEE Signal\\nProcess. Mag. , vol. 37, no. 1, pp. 141–151,\\nJan. 2020, doi: 10.1109/MSP .2019.2950557.\\n[15] H.-M. Zhang and B. Dong, “A review on deep\\nlearning in medical image reconstruction,” J. Oper .\\nRes. Soc. China , vol. 8, no. 2, pp. 311–340,\\nJun. 2020, doi: 10.1007/s40305-019-00287-4.\\n[16] O. Ronneberger, P .F i s c h e r ,a n dT .B r o x ,“ U - N e t :\\nConvolutional networks for biomedical image\\nsegmentation,” May 2015, arXiv:1505.04597 .\\nAccessed: Dec. 16, 2020.[17] D. Lee, J. Yoo, S. Tak, and J. Ye, “Deep residual\\nlearning for accelerated MRI using magnitude and\\nphase networks,” IEEE Trans. Biomed. Eng. ,\\nvol. 65, no. 9, pp. 1985–1995, Sep. 2018, doi:\\n10.1109/TBME.2018.2821699.\\n[18] Y .W u ,Y .M a ,J .D u ,a n dL .X i n g ,“ A c c e l e r a t i n g\\nquantitative MR imaging with the incorporation of\\nB1 compensation using deep learning,” Magn.\\nReson. Imag. , vol. 72, pp. 78–86, Oct. 2020, doi:\\n10.1016/j.mri.2020.06.011.\\n[19] S. Diamond, V . Sitzmann, F . Heide, and\\nG. Wetzstein, “Unrolled optimization with deep\\npriors,” 2017, arXiv:1705.08041 .\\n[20] Y. Liu, Q. Liu, M. Zhang, Q. Yang, S. Wang, and\\nD. Liang, “IFR-Net: Iterative feature reﬁnement\\nnetwork for compressed sensing MRI,” IEEE Trans.\\nComput. Imag. , vol. 6, pp. 434–446, 2020, doi:\\n10.1109/tci.2019.2956877.\\n[21] Y .Y a n g ,J .S u n ,H .L i ,a n dZ .X u ,“ A D M M - C S N e t :A\\ndeep learning approach for image compressive\\nsensing,” IEEE Trans. Pattern Anal. Mach. Intell.\\nvol. 42, no. 3, pp. 521–538, Mar . 2020, doi:\\n10.1109/TPAMI.2018.2883941.\\n[22] H. K. Aggarwal, M. P . Mani, and M. Jacob, “MoDL:\\nModel-based deep learning architecture for\\ninverse probl', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 866: ('FR-Net: Iterative feature reﬁnement\\nnetwork for compressed sensing MRI,” IEEE Trans.\\nComput. Imag. , vol. 6, pp. 434–446, 2020, doi:\\n10.1109/tci.2019.2956877.\\n[21] Y .Y a n g ,J .S u n ,H .L i ,a n dZ .X u ,“ A D M M - C S N e t :A\\ndeep learning approach for image compressive\\nsensing,” IEEE Trans. Pattern Anal. Mach. Intell.\\nvol. 42, no. 3, pp. 521–538, Mar . 2020, doi:\\n10.1109/TPAMI.2018.2883941.\\n[22] H. K. Aggarwal, M. P . Mani, and M. Jacob, “MoDL:\\nModel-based deep learning architecture for\\ninverse problems,” IEEE Trans. Med. Imag. , vol. 38,\\nno. 2, pp. 394–405, Feb. 2019, doi:10.1109/TMI.2018.2865356.\\n[23] W .Z e n g ,J .P e n g ,S .W a n g ,a n dQ .L i u ,\\n“A comparative study of CNN-based\\nsuper-resolution methods in MRI reconstructionand its beyond,” Signal Process., Image Commun. ,\\nvol. 81, Feb. 2020, Art. no. 115701, doi:\\n10.1016/j.image.2019.115701.\\n[24] J. Lewis D., V . Singhal, and A. Majumdar, “Solving\\ninverse problems in imaging via deep dictionary\\nlearning,” IEEE Access , vol. 7, pp. 37039–37049,\\n2019, doi: 10.1109/ACCESS.2018.2881492.\\n[25] V . Singhal and A. Majumdar, “Reconstructing\\nmulti-echo magnetic resonance images via\\nstructured deep dictionary learning,”Neurocomputing , vol. 408, pp. 135–143,\\nSep. 2020, doi: 10.1016/j.neucom.2019.11.107.\\n[26]\\nT. L u et al. , “pFISTA-SENSE-ResNet for parallel\\nMRI reconstruction,” J. Magn. Reson. , vol. 318,\\nSep. 2020, Art. no. 106790, doi:\\n10.1016/j.jmr .2020.106790.\\n[27] X. Zhang, Q. Lian, Y. Yang, and Y. Su, “A deep\\nunrolling network inspired by total variation forcompressed sensing MRI,” Digit. Signal Process. ,\\nvol. 107, Dec. 2020, Art. no. 102856, doi:\\n10.1016/j.dsp.2020.102856.\\n[28] A. Pramanik, H. K. Aggarwal, and M. Jacob, “Deep\\ngeneralization of structured low-rank algorithms\\n(deep-SLR),” IEEE Trans. Med. Imag. ,v o l .3 9 ,\\nno. 12, pp. 4186–4197, Dec. 2020, doi:\\n10.1109/tmi.2020.3014581.\\n[29] S .B i s w a s ,H .K .A g g a r w a l ,a n dM .J a c o b ,\\n“Dynamic MRI using model-based deep learning\\nand SToRM priors: MoDL-SToRM,” Magn. Reson.\\nMed. , vol.', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 867: ('iation forcompressed sensing MRI,” Digit. Signal Process. ,\\nvol. 107, Dec. 2020, Art. no. 102856, doi:\\n10.1016/j.dsp.2020.102856.\\n[28] A. Pramanik, H. K. Aggarwal, and M. Jacob, “Deep\\ngeneralization of structured low-rank algorithms\\n(deep-SLR),” IEEE Trans. Med. Imag. ,v o l .3 9 ,\\nno. 12, pp. 4186–4197, Dec. 2020, doi:\\n10.1109/tmi.2020.3014581.\\n[29] S .B i s w a s ,H .K .A g g a r w a l ,a n dM .J a c o b ,\\n“Dynamic MRI using model-based deep learning\\nand SToRM priors: MoDL-SToRM,” Magn. Reson.\\nMed. , vol. 82, no. 1, pp. 485–494, 2019, doi:\\n10.1002/mrm.27706.\\n[30] K. Hammernik et al. , “Learning a variational\\nnetwork for reconstruction of accelerated MRI\\ndata,” Magn. Reson. Med. , vol. 79, no. 6,\\npp. 3055–3071, Jun. 2018, doi:\\n10.1002/mrm.26977.\\n[31] Q. Liu, Q. Yang, H. Cheng, S. Wang, M. Zhang,\\nand D. Liang, “Highly undersampled magnetic\\nresonance imaging reconstruction using\\nautoencoding priors,” Magn. Reson. Med. , vol. 83,\\nno. 1, pp. 322–336, Jan. 2020, doi:10.1002/mrm.27921.\\n[32] S. A. H. Hosseini et al. , “ Accelerated coronary MRI\\nwith sRAKI: A database-free self-consistent neural\\nnetwork k-space reconstruction for arbitraryundersampling,” PLoS ONE , vol. 15, no. 2,\\nFeb. 2020, Art. no. e0229418, doi:\\n10.1371/journal.pone.0229418.\\n[33] L .S u n ,Y .W u ,Z .F a n ,X .D i n g ,Y .H u a n g ,a n d\\nJ. Paisley, “A deep error correction network for\\ncompressed sensing MRI,” BMC Biomed. Eng. ,\\nvol. 2, no. 1, pp. 1–12, Dec. 2020, doi:\\n10.1186/s42490-020-0037-5.\\n[34] M. Zhang et al. , “High-dimensional embedding\\nnetwork derived prior for compressive sensing\\nMRI reconstruction,” Med. Image Anal. ,v o l .6 4 ,\\nAug. 2020, Art. no. 101717, doi:\\n10.1016/j.media.2020.101717.\\n[35] K. Zeng, Y. Yang, G. Xiao, and Z. Chen, “A very\\ndeep densely connected network for compressed\\nsensing MRI,” IEEE Access ,v o l .7 ,\\npp. 85430–85439, 2019, doi:\\n10.1109/ACCESS.2019.2924604.\\n[36] S. U. H. Dar, M. Özbey , A. B. Çatlı, and T . Çukur,\\n“A transfer-learning approach for accelerated MRI\\nusing deep neural networks,” M a g n .R e s o n .M ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 868: ('etwork derived prior for compressive sensing\\nMRI reconstruction,” Med. Image Anal. ,v o l .6 4 ,\\nAug. 2020, Art. no. 101717, doi:\\n10.1016/j.media.2020.101717.\\n[35] K. Zeng, Y. Yang, G. Xiao, and Z. Chen, “A very\\ndeep densely connected network for compressed\\nsensing MRI,” IEEE Access ,v o l .7 ,\\npp. 85430–85439, 2019, doi:\\n10.1109/ACCESS.2019.2924604.\\n[36] S. U. H. Dar, M. Özbey , A. B. Çatlı, and T . Çukur,\\n“A transfer-learning approach for accelerated MRI\\nusing deep neural networks,” M a g n .R e s o n .M e d . ,\\nvol. 84, no. 2, pp. 663–685, Aug. 2020, doi:\\n10.1002/mrm.28148.\\n[37] M. O. Malavé et al. , “Reconstruction of\\nundersampled 3D non-Cartesian image-based\\nnavigators for coronary MRA using an unrolleddeep learning model,” Magn. Reson. Med. , vol. 84,\\nno. 2, pp. 800–812, Aug. 2020, doi: 10.1002/\\nmrm.28177.\\n[38] M. Ran et al. , “MD-Recon-Net: A parallel\\ndual-domain convolutional neural network forcompressed sensing MRI,” IEEE Trans. Radiat.\\nPlasma Med. Sci. , vol. 5, no. 1, pp. 120–135,\\nJan. 2021, doi: 10.1109/trpms.2020.2991877.\\n[39] S. Wang et al. , “DeepcomplexMRI: Exploiting deep\\nresidual network for fast parallel MR imaging\\nwith complex convolution,” Magn. Reson. Imag. ,\\nvol. 68, pp. 136–147, May 2020, doi:\\n10.1016/j.mri.2020.02.002.\\n[40] Z .W a n g ,H .J i a n g ,H .D u ,J .X u ,a n dB .Q i u ,\\n“IKWI-Net: A cross-domain convolutional neuralnetwork for undersampled magnetic resonance\\nimage reconstruction,” Magn. Reson. Imag. ,\\nvol. 73, pp. 1–10, Nov. 2020, doi: 10.1016/j.mri.\\n2020.06.015.\\n[41] D. Shen et al. , “Rapid reconstruction of highly\\nundersampled, non-Cartesian real-time cine\\nk-space data using a perceptual complex neural\\nnetwork (PCNN),” NMR Biomed. ,v o l .3 4 ,n o .1 ,\\nJan. 2021, Art. no. e4405, doi: 10.1002/\\nnbm.4405.\\n[42] S. Ravishankar and Y . Bresler , “MR image\\nreconstruction from highly undersampled k-space\\ndata by dictionary learning,” IEEE Trans. Med.\\nImag. , vol. 30, no. 5, pp. 1028–1041, May 2011,\\ndoi: 10.1109/TMI.2010.2090538.\\n[43] F. C h e n et al. , “Variable-density single-shot ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 869: (' et al. , “Rapid reconstruction of highly\\nundersampled, non-Cartesian real-time cine\\nk-space data using a perceptual complex neural\\nnetwork (PCNN),” NMR Biomed. ,v o l .3 4 ,n o .1 ,\\nJan. 2021, Art. no. e4405, doi: 10.1002/\\nnbm.4405.\\n[42] S. Ravishankar and Y . Bresler , “MR image\\nreconstruction from highly undersampled k-space\\ndata by dictionary learning,” IEEE Trans. Med.\\nImag. , vol. 30, no. 5, pp. 1028–1041, May 2011,\\ndoi: 10.1109/TMI.2010.2090538.\\n[43] F. C h e n et al. , “Variable-density single-shot fast\\nspin-echo MRI with deep learning reconstruction\\nby using variational networks,” Radiology ,\\nvol. 289, no. 2, pp. 366–373, Nov. 2018, doi:10.1148/radiol.2018180445.\\n[44] D. Polak et al. , “ Joint multi-contrast variational\\nnetwork reconstruction (jVN) with application to\\nrapid 2D and 3D imaging,” Magn. Reson. Med. ,\\nvol. 84, no. 3, pp. 1456–1469, Sep. 2020, doi:\\n10.1002/mrm.28219.\\n[45] V . Vishnevskiy , J. Walheim, and S. Kozerke, “Deep\\nvariational network for rapid 4D ﬂow MRIreconstruction,” Nature Mach. Intell. , vol. 2, no. 4,\\npp. 228–235, Apr . 2020, doi:\\n10.1038/s42256-020-0165-6.\\n[46] H. K. Aggarwal and M. Jacob, “ J-MoDL: Joint\\nmodel-based deep learning for optimized\\nsampling and reconstruction,” IEEE J. Sel. T opics\\nSignal Process. , vol. 14, no. 6, pp. 1151–1162,\\nOct. 2020, doi: 10.1109/jstsp.2020.3004094.\\n242 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\n[47] L. Bao et al. , “Undersampled MR image\\nreconstruction using an enhanced recursive\\nresidual network,” J. Magn. Reson. , vol. 305,\\npp. 232–246, Aug. 2019, doi:\\n10.1016/j.jmr .2019.07.020.\\n[48] S. U. H. Dar, M. Yurt, M. Shahdloo, M. E. Ildiz,\\nB. Tinaz, and T . Cukur, “Prior-guided imagereconstruction for accelerated multi-contrast MRI\\nvia generative adversarial networks,” IEEE J. Sel.\\nT opics Signal Process. ,v o l .1 4 ,n o .6 ,\\npp. 1072–1087, Oct. 2020, doi:\\n10.1109/jstsp.2020.3001737.\\n[49] C. M. Hyun, H. P .K i m ,S .M .L e e ,S .L e e ,a n d\\nJ. ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 870: ('econstruction using an enhanced recursive\\nresidual network,” J. Magn. Reson. , vol. 305,\\npp. 232–246, Aug. 2019, doi:\\n10.1016/j.jmr .2019.07.020.\\n[48] S. U. H. Dar, M. Yurt, M. Shahdloo, M. E. Ildiz,\\nB. Tinaz, and T . Cukur, “Prior-guided imagereconstruction for accelerated multi-contrast MRI\\nvia generative adversarial networks,” IEEE J. Sel.\\nT opics Signal Process. ,v o l .1 4 ,n o .6 ,\\npp. 1072–1087, Oct. 2020, doi:\\n10.1109/jstsp.2020.3001737.\\n[49] C. M. Hyun, H. P .K i m ,S .M .L e e ,S .L e e ,a n d\\nJ. K. Seo, “Deep learning for undersampled MRI\\nreconstruction,” Phys. Med. Biol. , vol. 63, no. 13,\\n2018, Art. no. 135007, doi:\\n10.1088/1361-6560/aac71a.\\n[50] M. Mardani et al. , “Deep generative adversarial\\nneural networks for compressive sensing MRI,”\\nIEEE Trans. Med. Imag. ,v o l .3 8 ,n o .1 ,\\npp. 167–179, Jan. 2019, doi:\\n10.1109/TMI.2018.2858752.\\n[51] Y . Wu, Y . Ma, J. Liu, J. Du, and L. Xing,\\n“Self-attention convolutional neural network for\\nimproved MR image reconstruction,” Inf. Sci. ,\\nvol. 490, pp. 317–328, Jul. 2019, doi:10.1016/j.ins.2019.03.080.\\n[52] D. Zhao, F . Zhao, and Y. Gan, “Reference-driven\\ncompressed sensing MR image reconstruction\\nusing deep convolutional neural networks without\\npre-training,” Sensors , vol. 20, no. 1, Jan. 2020,\\nArt. no. 1, doi: 10.3390/s20010308.\\n[53] D. Ulyanov, A. Vedaldi, and V . Lempitsky , “Deep\\nimage prior ,” Int. J. Comput. Vis. , vol. 128, no. 7,\\npp. 1867–1888, Jul. 2020, doi: 10.1007/\\ns11263-020-01303-4.\\n[54] K. Gong, P .H a n ,G .E .F a k h r i ,C .M a ,a n dQ .L i ,\\n“Arterial spin labeling MR image denoising and\\nreconstruction using unsupervised deep learning,”\\nNMR Biomed. , Dec. 2019, Art. no. e4224, doi:\\n10.1002/nbm.4224.\\n[55] A. Majumdar, “An autoencoder based formulation\\nfor compressed sensing reconstruction,” Magn.\\nReson. Imag. , vol. 52, pp. 62–68, Oct. 2018, doi:\\n10.1016/j.mri.2018.06.003.\\n[56] I. J. Goodfellow et al. , “Generative adversarial\\nnetworks,” Jun. 2014, arXiv:1406.2661 . Accessed:\\nDec. 17, 2020.\\n[57] E. Cha, H. Chung, E. Y. Kim, and J. C. Ye,\\n“', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 871: ('L i ,\\n“Arterial spin labeling MR image denoising and\\nreconstruction using unsupervised deep learning,”\\nNMR Biomed. , Dec. 2019, Art. no. e4224, doi:\\n10.1002/nbm.4224.\\n[55] A. Majumdar, “An autoencoder based formulation\\nfor compressed sensing reconstruction,” Magn.\\nReson. Imag. , vol. 52, pp. 62–68, Oct. 2018, doi:\\n10.1016/j.mri.2018.06.003.\\n[56] I. J. Goodfellow et al. , “Generative adversarial\\nnetworks,” Jun. 2014, arXiv:1406.2661 . Accessed:\\nDec. 17, 2020.\\n[57] E. Cha, H. Chung, E. Y. Kim, and J. C. Ye,\\n“Unpaired training of deep learning tMRA for\\nﬂexible spatio-temporal resolution,” IEEE Trans.\\nMed. Imag. , vol. 40, no. 1, pp. 166–179,\\nJan. 2021, doi: 10.1109/TMI.2020.3023620.\\n[58] V . Edupuganti, M. Mardani, S. Vasanawala, and\\nJ. Pauly, “Uncertainty quantiﬁcation in deep MRI\\nreconstruction,” IEEE Trans. Med. Imag. ,v o l .4 0 ,\\nno. 1, pp. 239–250, Jan. 2021, doi:\\n10.1109/tmi.2020.3025065.\\n[59] M. Jiang et al. , “Accelerating CS-MRI\\nreconstruction with ﬁne-tuning Wasserstein\\ngenerative adversarial network,” IEEE Access ,\\nvol. 7, pp. 152347–152357, 2019, doi:10.1109/ACCESS.2019.2948220.\\n[60] F . Liu, A. Samsonov, L. Chen, R. Kijowski, and\\nL. Feng, “SANTIS: Sampling-augmented neural\\nnetwork with incoherent structure for MR imagereconstruction,” Magn. Reson. Med. ,v o l .8 2 ,n o .5 ,\\npp. 1890–1904, Nov. 2019, doi:\\n10.1002/mrm.27827.\\n[61] G .O h ,B .S i m ,H .C h u n g ,L .S u n w o o ,a n dJ .C .Y e ,\\n“Unpaired deep learning for accelerated MRI\\nusing optimal transport driven CycleGAN,” IEEE\\nTrans. Comput. Imag. , vol. 6, pp. 1285–1296,\\n2020, doi: 10.1109/TCI.2020.3018562.\\n[62] T . M. Quan, T . Nguyen-Duc, and W .-K. Jeong,\\n“Compressed sensing MRI reconstruction using a\\ngenerative adversarial network with a cyclic loss,”\\nIEEE Trans. Med. Imag. ,v o l .3 7 ,n o .6 ,\\npp. 1488–1497, Jun. 2018, doi:\\n10.1109/TMI.2018.2820120.\\n[63] R. Shaul, I. David, O. Shitrit, and T . R. Raviv,\\n“Subsampled brain MRI reconstruction by\\ngenerative adversarial neural networks,” Med.\\nImage Anal. , vol. 65, Oct. 2020, Art. no. 101747,\\ndoi', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 872: ('. , vol. 6, pp. 1285–1296,\\n2020, doi: 10.1109/TCI.2020.3018562.\\n[62] T . M. Quan, T . Nguyen-Duc, and W .-K. Jeong,\\n“Compressed sensing MRI reconstruction using a\\ngenerative adversarial network with a cyclic loss,”\\nIEEE Trans. Med. Imag. ,v o l .3 7 ,n o .6 ,\\npp. 1488–1497, Jun. 2018, doi:\\n10.1109/TMI.2018.2820120.\\n[63] R. Shaul, I. David, O. Shitrit, and T . R. Raviv,\\n“Subsampled brain MRI reconstruction by\\ngenerative adversarial neural networks,” Med.\\nImage Anal. , vol. 65, Oct. 2020, Art. no. 101747,\\ndoi: 10.1016/j.media.2020.101747.\\n[64] Y .Y a n g ,J .S u n ,H .L i ,a n dZ .X u ,“ A D M M - N e t :Adeep learning approach for compressive sensing\\nMRI,” 2017, arXiv:1705.06869 .\\n[65] Z. Chen and Y. Tong, “Face super-resolution\\nthrough Wasserstein GANs,” May 2017,\\narXiv:1705.02438 . Accessed: Dec. 16, 2020.\\n[66] L .M e t z ,B .P o o l e ,D .P f a u ,a n dJ .S o h l - D i c k s t e i n ,\\n“Unrolled generative adversarial networks,”\\nMay 2017, arXiv:1611.02163 . Accessed: Dec. 16,\\n2020.\\n[67] M. Wiatrak, S. V . Albrecht, and A. Nystrom,\\n“Stabilizing generative adversarial networks: A\\nsurvey ,” Mar . 2020, arXiv:1910.00927 . Accessed:\\nDec. 16, 2020.\\n[68] M. Arjovsky , S. Chintala, and L. Bottou,\\n“Wasserstein GAN,” Dec. 2017, arXiv:1701.07875 .\\nAccessed: Dec. 17, 2020.\\n[69] H .Z h a o ,O .G a l l o ,I .F r o s i o ,a n dJ .K a u t z ,“ L o s s\\nfunctions for image restoration with neuralnetworks,” IEEE Trans. Comput. Imag. ,v o l .3 ,\\nno. 1, pp. 47–57, Mar . 2017, doi:\\n10.1109/TCI.2016.2644865.\\n[70] M. A k çak ay a, S . Mo eller, S . Wei ngärt ner, and\\nK. U˘ gurbil, “Scan-speciﬁc robust\\nartiﬁcial-neural-networks for k-space interpolation\\n(RAKI) reconstruction: Database-free deep\\nlearning for fast imaging,” M a g n .R e s o n .M e d . ,\\nvol. 81, no. 1, pp. 439–453, Jan. 2019, doi:\\n10.1002/mrm.27420.\\n[71] Y. Han, L. Sunwoo, and J. C. Ye, “ k-Space deep\\nlearning for accelerated MRI,” IEEE Trans. Med.\\nImag.\\n, vol. 39, no. 2, pp. 377–386, Feb. 2020, doi:\\n10.1109/TMI.2019.2927101.\\n[72] B. Zhu, J. Z. Liu, S. F . Cauley , B. R. ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 873: ('. Mo eller, S . Wei ngärt ner, and\\nK. U˘ gurbil, “Scan-speciﬁc robust\\nartiﬁcial-neural-networks for k-space interpolation\\n(RAKI) reconstruction: Database-free deep\\nlearning for fast imaging,” M a g n .R e s o n .M e d . ,\\nvol. 81, no. 1, pp. 439–453, Jan. 2019, doi:\\n10.1002/mrm.27420.\\n[71] Y. Han, L. Sunwoo, and J. C. Ye, “ k-Space deep\\nlearning for accelerated MRI,” IEEE Trans. Med.\\nImag.\\n, vol. 39, no. 2, pp. 377–386, Feb. 2020, doi:\\n10.1109/TMI.2019.2927101.\\n[72] B. Zhu, J. Z. Liu, S. F . Cauley , B. R. Rosen, and\\nM. S. Rosen, “Image reconstruction by\\ndomain-transform manifold learning,” Nature ,\\nvol. 555, no. 7697, pp. 487–492, Mar . 2018, doi:\\n10.1038/nature25988.\\n[73] T .E o ,H .S h i n ,Y .J u n ,T .K i m ,a n dD .H w a n g ,\\n“Accelerating Cartesian MRI by domain-transform\\nmanifold learning in phase-encoding direction,”\\nMed. Image Anal. , vol. 63, Jul. 2020,\\nArt. no. 101689, doi: 10.1016/j.media.2020.\\n101689.\\n[74] H. El-Rewaidy et al. , “Deep complex convolutional\\nnetwork for fast reconstruction of 3D late\\ngadolinium enhancement cardiac MRI,” NMR\\nBiomed. , vol. 33, no. 7, Jul. 2020, Art. no. e4312,\\ndoi: 10.1002/nbm.4312.\\n[75] R. Souza, Y. Beauferris, W . Loos, R. M. Lebel, and\\nR. Frayne, “Enhanced deep-learning-based\\nmagnetic resonance image reconstruction byleveraging prior subject-speciﬁc brain imaging:\\nProof-of-concept using a cohort of presumed\\nnormal subjects,” IEEE J. Sel. T opics Signal\\nProcess. , vol. 14, no. 6, pp. 1126–1136, Oct. 2020,\\ndoi: 10.1109/jstsp.2020.3001525.\\n[76] R. Souza et al. , “Dual-domain cascade of U-Nets\\nfor multi-channel magnetic resonance image\\nreconstruction,” Magn. Reson. Imag. ,v o l .7 1 ,\\npp. 140–153, Sep. 2020, doi:\\n10.1016/j.mri.2020.06.002.\\n[77] S. Fujieda, K. Takayama, and T . Hachisuka,\\n“Wavelet convolutional neural networks,”\\nMay 2018, arXiv:1805.08620 . Accessed:\\nDec. 17, 2020.\\n[78] H. El-Rewaidy et al. , “Multi-domain convolutional\\nneural network (MD-CNN) for radial\\nreconstruction of dynamic cardiac MRI,” Magn.\\nReson. Med. , vol. 85, no. 3, pp. 1195–1208,\\nMar . 202', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 874: ('al-domain cascade of U-Nets\\nfor multi-channel magnetic resonance image\\nreconstruction,” Magn. Reson. Imag. ,v o l .7 1 ,\\npp. 140–153, Sep. 2020, doi:\\n10.1016/j.mri.2020.06.002.\\n[77] S. Fujieda, K. Takayama, and T . Hachisuka,\\n“Wavelet convolutional neural networks,”\\nMay 2018, arXiv:1805.08620 . Accessed:\\nDec. 17, 2020.\\n[78] H. El-Rewaidy et al. , “Multi-domain convolutional\\nneural network (MD-CNN) for radial\\nreconstruction of dynamic cardiac MRI,” Magn.\\nReson. Med. , vol. 85, no. 3, pp. 1195–1208,\\nMar . 2021, doi: 10.1002/mrm.28485.\\n[79] L. Sun et al. , “ A dual-domain deep lattice network\\nfor rapid MRI reconstruction,” Neurocomputing ,\\nvol. 397, pp. 94–107, Jul. 2020, doi:\\n10.1016/j.neucom.2020.01.063.\\n[80] E. Cha, G. Oh, and J. C. Ye, “Geometric\\napproaches to increase the expressivity of deep\\nneural networks for MR reconstruction,” IEEE J.\\nSel. T opics Signal Process. ,v o l .1 4 ,n o .6 ,\\npp. 1292–1305, Oct. 2020, doi:\\n10.1109/jstsp.2020.2982777.\\n[81] Z. Yuan et al. , “SARA-GAN: Self-attention and\\nrelative average discriminator based generative\\nadversarial networks for fast compressed sensing\\nMRI reconstruction,” Frontiers Neuroinform. ,\\nvol. 14, p. 58, Nov. 2020, doi:\\n10.3389/fninf.2020.611666.[82] W .Z h o u ,H .D u ,W .M e i ,a n dL .F a n g ,“ S p a t i a l\\northogonal attention generative adversarial\\nnetwork for MRI reconstruction,” Med. Phys. ,\\nvol. 48, no. 2, pp. 627–639, Feb. 2021, doi:\\n10.1002/mp.14509.\\n[83] J. Huang, C. Chen, and L. Axel, “Fast\\nmulti-contrast MRI reconstruction,” Magn. Reson.\\nImag. , vol. 32, no. 10, pp. 1344–1352, Dec. 2014,\\ndoi: 10.1016/j.mri.2014.08.025.\\n[84] L. Xiang et al. , “Deep-learning-based multi-modal\\nfusion for fast MR reconstruction,” IEEE Trans.\\nBiomed. Eng. , vol. 66, no. 7, pp. 2105–2114,\\nJul. 2019, doi: 10.1109/TBME.2018.2883958.\\n[85] L. Sun, Z. Fan, X. Fu, Y. Huang, X. Ding, and\\nJ. Paisley, “ A deep information sharing network\\nfor multi-contrast compressed sensing MRI\\nreconstruction,” IEEE Trans. Image Process. ,\\nvol. 28, no. 12, pp. 6141–6153, Dec. 2019, doi:\\n10.110', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 875: (', vol. 32, no. 10, pp. 1344–1352, Dec. 2014,\\ndoi: 10.1016/j.mri.2014.08.025.\\n[84] L. Xiang et al. , “Deep-learning-based multi-modal\\nfusion for fast MR reconstruction,” IEEE Trans.\\nBiomed. Eng. , vol. 66, no. 7, pp. 2105–2114,\\nJul. 2019, doi: 10.1109/TBME.2018.2883958.\\n[85] L. Sun, Z. Fan, X. Fu, Y. Huang, X. Ding, and\\nJ. Paisley, “ A deep information sharing network\\nfor multi-contrast compressed sensing MRI\\nreconstruction,” IEEE Trans. Image Process. ,\\nvol. 28, no. 12, pp. 6141–6153, Dec. 2019, doi:\\n10.1109/TIP .2019.2925288.\\n[86] W .D o ,S .S e o ,Y .H a n ,J .C .Y e ,S .H .C h o i ,a n d\\nS. Park, “Reconstruction of multicontrast MRimages through deep learning,” Med. Phys. ,\\nvol. 47, no. 3, pp. 983–997, Mar . 2020, doi:\\n10.1002/mp.14006.\\n[87] A. Koﬂer, M. Dewey , T . Schaeffter, C. Wald, and\\nC. Kolbitsch, “Spatio-temporal deep\\nlearning-based undersampling artefact reduction\\nfor 2D radial cine MRI with limited training data,”\\nIEEE Trans. Med. Imag. ,v o l .3 9 ,n o .3 ,\\npp. 703–717, Mar . 2020, doi: 10.1109/TMI.\\n2019.2930318.\\n[88] L. Fan et al. , “Rapid dealiasing of undersampled,\\nnon-Cartesian cardiac perfusion images using\\nU-Net,” NMR Biomed. , vol. 33, no. 5, May 2020,\\nArt. no. e4239, doi: 10.1002/nbm.4239.\\n[89] J. Liu, Y. Sun, C. Eldeniz, W . Gan, H. An, and\\nU. S. Kamilov, “RARE: Image reconstruction using\\ndeep priors learned without groundtruth,” IEEE J.\\nSel. T opics Signal Process. ,v o l .1 4 ,n o .6 ,\\npp. 1088–1099, Oct. 2020, doi:10.1109/JSTSP .2020.2998402.\\n[90] C. M. Sandino, P . Lai, S. S. Vasanawala, and\\nJ. Y . Cheng, “Accelerating cardiac cine MRI using a\\ndeep learning-based ESPIRiT reconstruction,”Magn. Reson. Med. , vol. 85, no. 1, pp. 152–167,\\nJan. 2021, doi: 10.1002/mrm.28420.\\n[91] D .T r a n ,H .W a n g ,L .T o r r e s a n i ,J .R a y ,Y .L e C u n ,\\nand M. Paluri, “A closer look at spatiotemporalconvolutions for action recognition,” in Proc.\\nIEEE/CVF Conf. Comput. Vis. Pattern Recognit. ,\\nJun. 2018, pp. 6450–6459, doi:\\n10.1109/CVPR.2018.00675.\\n[92] T. K ü s t n e r et al. , “CINENet: Deep lea', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 876: ('la, and\\nJ. Y . Cheng, “Accelerating cardiac cine MRI using a\\ndeep learning-based ESPIRiT reconstruction,”Magn. Reson. Med. , vol. 85, no. 1, pp. 152–167,\\nJan. 2021, doi: 10.1002/mrm.28420.\\n[91] D .T r a n ,H .W a n g ,L .T o r r e s a n i ,J .R a y ,Y .L e C u n ,\\nand M. Paluri, “A closer look at spatiotemporalconvolutions for action recognition,” in Proc.\\nIEEE/CVF Conf. Comput. Vis. Pattern Recognit. ,\\nJun. 2018, pp. 6450–6459, doi:\\n10.1109/CVPR.2018.00675.\\n[92] T. K ü s t n e r et al. , “CINENet: Deep learning-based\\n3D cardiac CINE MRI reconstruction with\\nmulti-coil complex-valued 4D spatio-temporal\\nconvolutions,” Sci. Rep. , vol. 10, no. 1, p. 13710,\\nDec. 2020, doi: 10.1038/s41598-020-70551-8.\\n[93] S. A. H. Hosseini, B. Yaman, S. Moeller , M. Hong,\\nand M. Akcakaya, “Dense recurrent neural\\nnetworks for accelerated MRI: History-cognizant\\nunrolling of optimization algorithms,”\\nIEEE J. Sel.\\nT opics Signal Process. ,v o l .1 4 ,n o .6 ,\\npp. 1280–1291, Oct. 2020, doi: 10.1109/jstsp.\\n2020.3003170.\\n[94] Z. Ke, J. Cheng, L. Ying, H. Zheng, Y. Zhu, and\\nD. Liang, “An unsupervised deep learning method\\nfor multi-coil cine MRI,” P h y s .M e d .B i o l . , vol. 65,\\nno. 23, Dec. 2020, Art. no. 235041, doi:\\n10.1088/1361-6560/abaffa.\\n[95] M. P.R e c h t et al. , “Using deep learning to\\naccelerate knee MRI at 3 T: Results of aninterchangeability study ,” Amer . J. Roentgenol. ,\\nvol. 215, no. 6, pp. 1421–1429, Dec. 2020, doi:\\n10.2214/AJR.20.23313.\\n[96] F. C h e n et al. ,“ D a t a - d r i v e ns e l f - c a l i b r a t i o na n d\\nreconstruction for non-Cartesian wave-encoded\\nsingle-shot fast spin echo using deep learning,”J. Magn. Reson. Imag. , vol. 51, no. 3, pp. 841–853,\\nMar . 2020, doi: 10.1002/jmri.26871.\\n[97] R. Liu, Y. Zhang, S. Cheng, Z. Luo, and X. Fan,\\n“A deep framework assembling principled modulesfor CS-MRI: Unrolling perspective, convergence\\nbehaviors, and practical modeling,” IEEE Trans.\\nMed. Imag. , vol. 39, no. 12, pp. 4150–4163,\\nDec. 2020, doi: 10.1109/TMI.2020.3014193.\\n[98] K. Lønning, P .P u t z k y ,J . - J .', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 877: ('n d\\nreconstruction for non-Cartesian wave-encoded\\nsingle-shot fast spin echo using deep learning,”J. Magn. Reson. Imag. , vol. 51, no. 3, pp. 841–853,\\nMar . 2020, doi: 10.1002/jmri.26871.\\n[97] R. Liu, Y. Zhang, S. Cheng, Z. Luo, and X. Fan,\\n“A deep framework assembling principled modulesfor CS-MRI: Unrolling perspective, convergence\\nbehaviors, and practical modeling,” IEEE Trans.\\nMed. Imag. , vol. 39, no. 12, pp. 4150–4163,\\nDec. 2020, doi: 10.1109/TMI.2020.3014193.\\n[98] K. Lønning, P .P u t z k y ,J . - J .S o n k e ,L .R e n e m a n ,\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 243\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nM. W . A. Caan, and M. Welling, “Recurrent\\ninference machines for reconstructing\\nheterogeneous MRI data,” Med. Image Anal. ,\\nvol. 53, pp. 64–78, Apr . 2019, doi:\\n10.1016/j.media.2019.01.005.\\n[99] G .L u o ,N .Z h a o ,W .J i a n g ,E .S .H u i ,a n dP .C a o ,\\n“MRI reconstruction using deep Bayesianestimation,” Magn. Reson. Med. , vol. 84, no. 4,\\npp. 2246–2261, Oct. 2020, doi:\\n10.1002/mrm.28274.\\n[100] J. Zhang et al. , “Fidelity imposed network edit\\n(FINE) for solving ill-posed image reconstruction,”\\nNeuroImage , vol. 211, May 2020, Art. no. 116579,\\ndoi: 10.1016/j.neuroimage.2020.116579.\\n[101] Z. Zhou et al. , “Parallel imaging and convolutional\\nneural network combined fast MR image\\nreconstruction: Applications in low-latencyaccelerated real-time imaging,” Med. Phys. ,\\nvol. 46, no. 8, pp. 3399–3413, Aug. 2019, doi:\\n10.1002/mp.13628.\\n[102] J. Montalt-Tordera, V . Muthurangu,\\nA. Hauptmann, and J. A. Steeden, “Machine\\nlearning in magnetic resonance imaging: Image\\nreconstruction,” Dec. 2020, arXiv:2012.05303 .\\nAccessed: Dec. 16, 2020.\\n[103] J .M o n g a n ,L .M o y ,a n dC .E .K a h n ,“ C h e c k l i s tf o r\\nartiﬁcial intelligence in medical imaging (CLAIM):\\nA guide for authors and reviewers,” Radiol., Artif.\\nIntell. , vol. 2, no. 2, Mar . 2020, Art. no. e200029,\\ndoi: 10.1148/ryai.2020200029.\\n[104] R: A Language and Environment for Statist', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 878: ('02] J. Montalt-Tordera, V . Muthurangu,\\nA. Hauptmann, and J. A. Steeden, “Machine\\nlearning in magnetic resonance imaging: Image\\nreconstruction,” Dec. 2020, arXiv:2012.05303 .\\nAccessed: Dec. 16, 2020.\\n[103] J .M o n g a n ,L .M o y ,a n dC .E .K a h n ,“ C h e c k l i s tf o r\\nartiﬁcial intelligence in medical imaging (CLAIM):\\nA guide for authors and reviewers,” Radiol., Artif.\\nIntell. , vol. 2, no. 2, Mar . 2020, Art. no. e200029,\\ndoi: 10.1148/ryai.2020200029.\\n[104] R: A Language and Environment for Statistical\\nComputing , R Found. Stat. Comput., R Core Team,\\nVienna, Austria, 2020. [Online]. Available:\\nhttps://www .R-project.org/\\n[105] Y. Roy , H. Banville, I. Albuquerque, A. Gramfort,\\nT . H. Falk, and J. Faubert, “Deep learning-based\\nelectroencephalography analysis: A systematic\\nreview ,” J. Neural Eng. , vol. 16, no. 5, Aug. 2019,\\nArt. no. 051001, doi: 10.1088/1741-2552/\\nab260c.\\n[106] L .S c r u c c a ,M .F o p ,T .B .M u r p h y ,a n dA .E .R a f t e r y ,\\n“mclust 5: Clustering, classiﬁcation and density\\nestimation using Gaussian ﬁnite mixture models,”\\nRJ ., vol. 8, no. 1, pp. 289–317, 2016.\\n[107] J. J. Deeks, P . Macaskill, and L. Irwig, “The\\nperformance of tests of publication bias and other\\nsample size effects in systematic reviews of\\ndiagnostic test accuracy was assessed,” J. Clin.\\nEpidemiol. , vol. 58, no. 9, pp. 882–893, Sep. 2005,\\ndoi: 10.1016/j.jclinepi.2005.01.016.\\n[108] A. Kassambara, “ggpubr: ‘ggplot2’ based\\npublication ready plots,” Tech. Rep., 2020.\\n[109] A. Liberati et al. , “The PRISMA statement for\\nreporting systematic reviews and meta-analyses of\\nstudies that evaluate healthcare interventions:\\nExplanation and elaboration,” BMJ , vol. 339,\\nJul. 2009, Art. no. b2700, doi:\\n10.1136/bmj.b2700.\\n[110] I .K o k t z o g l o u ,R .H u a n g ,A .L .O n g ,P .J .A o u a d ,\\nE. A. Aherne, and R. R. Edelman, “Feasibility of a\\nsub-3-minute imaging strategy for ungated\\nquiescent interval slice-selective MRA of theextracranial carotid arteries using radial k-space\\nsampling and deep learning–based image\\nprocess', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 879: ('nt for\\nreporting systematic reviews and meta-analyses of\\nstudies that evaluate healthcare interventions:\\nExplanation and elaboration,” BMJ , vol. 339,\\nJul. 2009, Art. no. b2700, doi:\\n10.1136/bmj.b2700.\\n[110] I .K o k t z o g l o u ,R .H u a n g ,A .L .O n g ,P .J .A o u a d ,\\nE. A. Aherne, and R. R. Edelman, “Feasibility of a\\nsub-3-minute imaging strategy for ungated\\nquiescent interval slice-selective MRA of theextracranial carotid arteries using radial k-space\\nsampling and deep learning–based image\\nprocessing,” Magn. Reson. Med. , vol. 84, no. 2,\\npp. 825–837, Aug. 2020, doi: 10.1002/\\nmrm.28179.\\n[111] K. C. Tezcan, C. F . Baumgartner, R. Luechinger,\\nK. P.P r u e s s m a n n ,a n dE .K o n u k o g l u ,“ M Ri m a g e\\nreconstruction using deep density priors,” IEEE\\nTrans. Med. Imag. , vol. 38, no. 7, pp. 1633–1642,\\nJul. 2019, doi: 10.1109/TMI.2018.2887072.\\n[112] T . Rohlﬁng, N. M. Zahr, E. V . Sullivan, and\\nA. Pfefferbaum, “The SRI24 multichannel atlas of\\nnormal adult human brain structure,” Hum. Brain\\nMapping , vol. 31, no. 5, pp. 798–819, 2010, doi:\\n10.1002/hbm.20906.\\n[113] A. M. Mendrik et al. , “MRBrainS challenge: Online\\nevaluation framework for brain image\\nsegmentation in 3T MRI scans,” Comput. Intell.\\nNeurosci. , vol. 2015, Jan. 2015, Art. no. 813696,\\ndoi: 10.1155/2015/813696.\\n[114] C. R. Jack et al. ,“ T h eA l z h e i m e r ’ sd i s e a s e\\nneuroimaging initiative (ADNI): MRI methods,”\\nJ. Magn. Reson. Imag. , vol. 27, no. 4, pp. 685–691,\\nApr . 2008, doi: 10.1002/jmri.21049.[115] I. Išgum et al. , “Evaluation of automatic neonatal\\nbrain segmentation algorithms: The NeoBrainS12\\nchallenge,” Med. Image Anal. , vol. 20, no. 1,\\npp. 135–151, Feb. 2015, doi:\\n10.1016/j.media.2014.11.001.\\n[116] F . Hashimoto, K. Ote, T . Oida, A. Teramoto, and\\nY . Ouchi, “Compressed-sensing magneticresonance image reconstruction using an iterative\\nconvolutional neural network approach,” Appl.\\nSci., vol. 10, no. 6, p. 1902, Mar . 2020, doi:\\n10.3390/app10061902.\\n[117] K .P a w a r ,Z .C h e n ,N .J .S h a h ,a n dG .F .E g a n ,\\n“A de', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 880: ('tion of automatic neonatal\\nbrain segmentation algorithms: The NeoBrainS12\\nchallenge,” Med. Image Anal. , vol. 20, no. 1,\\npp. 135–151, Feb. 2015, doi:\\n10.1016/j.media.2014.11.001.\\n[116] F . Hashimoto, K. Ote, T . Oida, A. Teramoto, and\\nY . Ouchi, “Compressed-sensing magneticresonance image reconstruction using an iterative\\nconvolutional neural network approach,” Appl.\\nSci., vol. 10, no. 6, p. 1902, Mar . 2020, doi:\\n10.3390/app10061902.\\n[117] K .P a w a r ,Z .C h e n ,N .J .S h a h ,a n dG .F .E g a n ,\\n“A deep learning framework for transforming\\nimage reconstruction into pixel classiﬁcation,”\\nIEEE Access , vol. 7, pp. 177690–177702, 2019,\\ndoi: 10.1109/ACCESS.2019.2959037.\\n[118] J. Zhang et al. , “Compressed sensing MR image\\nreconstruction via a deep frequency-division\\nnetwork,” Neurocomputing , vol. 384, pp. 346–355,\\nApr . 2020, doi: 10.1016/j.neucom.2019.12.011.\\n[119] J. Zbontar et al. , “fastMRI: An open dataset and\\nbenchmarks for accelerated MRI,” 2018,\\narXiv:1811.08839 .\\n[120] C .D .B a h a d i r ,A .Q .W a n g ,A .V .D a l c a ,a n d\\nM. R. Sabuncu, “Deep-learning-basedoptimization of the under-sampling pattern in\\nMRI,” IEEE Trans. Comput. Imag. ,v o l .6 ,\\npp. 1139–1152, 2020, doi: 10.1109/TCI.2020.\\n3006727.\\n[121] C. A. Cocosco, V . Kollokian, R. K.-S. Kwan,\\nG. B. Pike, and A. C. Evans, “BrainWeb: Online\\ninterface to a 3D MRI simulated brain database,”\\nNeuroImage , vol. 5, no. 4, p. 425, 1997.\\n[122] M. V . R. Manimala, C. D. Naidu, and\\nM. N. G. Prasad, “Sparse MR image reconstruction\\nconsidering Rician noise models: A CNN\\napproach,” Wireless Pers. Commun. , vol. 116,\\nno. 1, pp. 491–511, Jan. 2021, doi:\\n10.1007/s11277-020-07725-0.\\n[123] R. Souza et al. , “An open, multi-vendor,\\nmulti-ﬁeld-strength brain MR dataset and analysis\\nof publicly available skull stripping methods\\nagreement,” NeuroImage , vol. 170, pp. 482–494,\\nApr . 2018, doi: 10.1016/j.neuroimage.\\n2017.08.021.\\n[124] B. H. Menze et al. , “The multimodal brain tumor\\nimage segmentation benchmark (BRATS),” IEEE\\nTrans. Med. Imag. , vol. 34, no. 10, pp. 19', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 881: ('e models: A CNN\\napproach,” Wireless Pers. Commun. , vol. 116,\\nno. 1, pp. 491–511, Jan. 2021, doi:\\n10.1007/s11277-020-07725-0.\\n[123] R. Souza et al. , “An open, multi-vendor,\\nmulti-ﬁeld-strength brain MR dataset and analysis\\nof publicly available skull stripping methods\\nagreement,” NeuroImage , vol. 170, pp. 482–494,\\nApr . 2018, doi: 10.1016/j.neuroimage.\\n2017.08.021.\\n[124] B. H. Menze et al. , “The multimodal brain tumor\\nimage segmentation benchmark (BRATS),” IEEE\\nTrans. Med. Imag. , vol. 34, no. 10, pp. 1993–2024,\\nOct. 2015, doi: 10.1109/TMI.2014.2377694.\\n[125] J. Mehta and A. Majumdar, “RODEO: Robust\\nDE-aliasing autoencoder for real-time medical\\nimage reconstruction,” Pattern Recognit. , vol. 63,\\npp. 499–510, Mar . 2017, doi: 10.1016/j.patcog.\\n2016.09.022.\\n[126] B. Landman and S. Warﬁeld, “2013 diencephalon\\nfree challenge,” Tech. Rep., 2013, doi: 10.7303/\\nsyn3270353.\\n[127] W .Q i u ,D .L i ,X .J i n ,F .L i u ,a n dB .S u n ,“ D e e p\\nneural network inspired by iterative\\nshrinkage-thresholding algorithm with data\\nconsistency (NISTAD) for fast undersampled MRI\\nreconstruction,” Magn. Reson. Imag. ,v o l .7 0 ,\\npp. 134–144, Jul. 2020, doi: 10.1016/j.mri.\\n2020.04.016.\\n[128] Y. Li, X. Cheng, and G. Gui,\\n“Co-robust-ADMM-Net: Joint ADMM frameworkand DNN for robust sparse composite\\nregularization,” IEEE Access ,v o l .6 ,\\npp. 47943–47952, 2018, doi: 10.1109/\\nACCESS.2018.2867435.\\n[129] D. C. Van Essen et al. , “The human connectome\\nproject: A data acquisition perspective,”\\nNeuroimage , vol. 62, no. 4, pp. 2222–2231,\\nOct. 2012, doi: 10.1016/j.neuroimage.2012.\\n02.018.\\n[130] Y . Han, J. Yoo, H. H. Kim, H. J. Shin, K. Sung, and\\nJ. C. Ye, “Deep learning with domain adaptation\\nfor accelerated projectio n-reconstruction MR,”\\nMagn. Reson. Med. , vol. 80, no. 3, pp. 1189–1205,\\nSep. 2018, doi: 10.1002/mrm.27106.\\n[131] B. Zuﬁria et al. , “A feature-based convolutional\\nneural network for reconstruction of\\ninterventional MRI,” NMR Biomed. , Dec. 2019,\\nArt. no. e4231, doi: 10.1002/nbm.4231.\\n[132] T .E o ,H .S h i n ,Y .J u n ,T .K i ', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 882: ('ct. 2012, doi: 10.1016/j.neuroimage.2012.\\n02.018.\\n[130] Y . Han, J. Yoo, H. H. Kim, H. J. Shin, K. Sung, and\\nJ. C. Ye, “Deep learning with domain adaptation\\nfor accelerated projectio n-reconstruction MR,”\\nMagn. Reson. Med. , vol. 80, no. 3, pp. 1189–1205,\\nSep. 2018, doi: 10.1002/mrm.27106.\\n[131] B. Zuﬁria et al. , “A feature-based convolutional\\nneural network for reconstruction of\\ninterventional MRI,” NMR Biomed. , Dec. 2019,\\nArt. no. e4231, doi: 10.1002/nbm.4231.\\n[132] T .E o ,H .S h i n ,Y .J u n ,T .K i m ,a n dD .H w a n g ,\\n“Accelerating Cartesian MRI by domain-transformmanifold learning in phase-encoding direction,”\\nMed. Image Anal. , vol. 63, Jul. 2020,\\nArt. no. 101689, doi: 10.1016/j.media.2020.\\n101689.\\n[133] N. Subhas et al. , “Diagnostic interchangeability of\\ndeep convolutional neural networks reconstructed\\nknee MR images: Preliminary experience,” Quant.\\nImag. Med. Surg. , vol. 10, no. 9, pp. 1748–1762,\\nSep. 2020, doi: 10.21037/QIMS-20-664.\\n[134] A. Carass et al. , “Longitudinal multiple sclerosis\\nlesion segmentation: Resource and challenge,”NeuroImage , vol. 148, no. 1, pp. 77–102,\\nMar . 2017, doi: 10.1016/j.neuroimage.\\n2016.12.064.\\n[135] A. M. Sawyer et al. , “Creation of fully sampled MR\\ndata repository for compressed sensing of the\\nknee,” Tech. Rep., 2013.\\n[136] O. Commowick, F . Cervenansky , and R. Ameli.\\n(2016). MSSEG Challenge Proceedings: Multiple\\nSclerosis Lesions Segmentation Challenge Using a\\nData Management and Processing Infrastructure .\\nAccessed: Feb. 26, 2021. [Online]. Available:\\nhttps://www .hal.inserm.fr/inserm-01397806\\n[137] Y. D ai and P . Zhuang, “Compressed sensing MRI\\nvia a multi-scale dilated residual convolutionnetwork,” M a g n .R e s o n .I m a g . , vol. 63,\\npp. 93–104, Nov. 2019, doi: 10.1016/j.mri.2019.\\n07.014.\\n[138] E. Bullitt et al. , “Vessel tortuosity and brain tumor\\nmalignancy: A blinded study ,” Academic Radiol. ,\\nvol. 12, no. 10, pp. 1232–1240, Oct. 2005, doi:\\n10.1016/j.acra.2005.05.027.\\n[139] X .Q u ,Y .H o u ,F .L a m ,D .G u o ,J .Z h o n g ,a n d\\nZ. Chen, “Magne', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 883: ('s://www .hal.inserm.fr/inserm-01397806\\n[137] Y. D ai and P . Zhuang, “Compressed sensing MRI\\nvia a multi-scale dilated residual convolutionnetwork,” M a g n .R e s o n .I m a g . , vol. 63,\\npp. 93–104, Nov. 2019, doi: 10.1016/j.mri.2019.\\n07.014.\\n[138] E. Bullitt et al. , “Vessel tortuosity and brain tumor\\nmalignancy: A blinded study ,” Academic Radiol. ,\\nvol. 12, no. 10, pp. 1232–1240, Oct. 2005, doi:\\n10.1016/j.acra.2005.05.027.\\n[139] X .Q u ,Y .H o u ,F .L a m ,D .G u o ,J .Z h o n g ,a n d\\nZ. Chen, “Magnetic resonance image\\nreconstruction from undersampled measurements\\nusing a patch-based nonlocal operator ,” Med.\\nImage Anal. , vol. 18, no. 6, pp. 843–856,\\nAug. 2014, doi: 10.1016/j.media.2013.09.007.\\n[140] E. M. Eksioglu, “Decoupled algorithm for MRI\\nreconstruction using nonlocal block matching\\nmodel: BM3D-MRI,” J. Math. Imag. Vis. , vol. 56,\\nno. 3, pp. 430–440, Nov. 2016, doi: 10.1007/\\ns10851-016-0647-7.\\n[141] M. A. Griswold et al. , “Generalized autocalibrating\\npartially parallel acquisitions (GRAPPA),” Magn.\\nReson. Med. , vol. 47, no. 6, pp. 1202–1210,\\nJun. 2002, doi: 10.1002/mrm.10171.\\n[142] S. G. Lingala, Y. Hu, E. DiBella, and M. Jacob,\\n“Accelerated dynamic MRI exploiting sparsity and\\nlow-rank structure: k-t SLR,” IEEE Trans. Med.\\nImag. , vol. 30, no. 5, pp. 1042–1054, May 2011,\\ndoi:\\n10.1109/TMI.2010.2100850.\\n[143] Z. Xie, L. Liu, and C. Yang, “An entropy-based\\nalgorithm with nonlocal residual learning for\\nimage compressive sensing recovery ,” Entropy ,\\nvol. 21, no. 9, p. 900, Sep. 2019, doi: 10.3390/\\ne21090900.\\n[144] Z. Xie, L. Liu, and C. Yang, “ A probabilistic\\nmodel-based method wit h nonlocal ﬁltering for\\nrobust magnetic resonance imaging\\nreconstruction,” IEEE Access ,v o l .8 ,\\npp. 82347–82363, 2020, doi: 10.1109/ACCESS.\\n2020.2991442.\\n[145] B. Wen, Y. Li, and Y. Bresler, “Image recovery via\\ntransform learning and low-rank modeling: The\\npower of complementary regularizers,” IEEE\\nTrans. Image Process. , vol. 29, pp. 5310–5323,\\n2020, doi: 10.1109/TIP .2020.2980753.\\n[146] S. Abdullah, O. Arif, M. B. Ari', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 884: ('21090900.\\n[144] Z. Xie, L. Liu, and C. Yang, “ A probabilistic\\nmodel-based method wit h nonlocal ﬁltering for\\nrobust magnetic resonance imaging\\nreconstruction,” IEEE Access ,v o l .8 ,\\npp. 82347–82363, 2020, doi: 10.1109/ACCESS.\\n2020.2991442.\\n[145] B. Wen, Y. Li, and Y. Bresler, “Image recovery via\\ntransform learning and low-rank modeling: The\\npower of complementary regularizers,” IEEE\\nTrans. Image Process. , vol. 29, pp. 5310–5323,\\n2020, doi: 10.1109/TIP .2020.2980753.\\n[146] S. Abdullah, O. Arif, M. B. Arif, and T . Mahmood,\\n“MRI reconstruction from sparse K-space data\\nusing low dimensional manifold model,” IEEE\\nAccess , vol. 7, pp. 88072–88081, 2019, doi:\\n10.1109/ACCESS.2019.2925051.\\n[147] J. Lv, K. Chen, M. Yang, J. Zhang, and X. Wang,\\n“Reconstruction of undersampled radial\\nfree-breathing 3D abdominal MRI using stacked\\nconvolutional auto-encoders,” Med. Phys. , vol. 45,\\nno. 5, pp. 2023–2032, May 2018, doi:\\n10.1002/mp.12870.\\n[148] V . Antun, F . Renna, C. Poon, B. Adcock, and\\nA. C. Hansen, “On instabilities of deep learning in\\nimage reconstruction and the potential costs of\\nAI,” Proc. Nat. Acad. Sci. USA , vol. 117, no. 48,\\npp. 30088–30095, 2020, doi: 10.1073/pnas.\\n1907377117.\\n[149] E. E. Esfahani and A. Hosseini, “Compressed MRI\\n244 PROCEEDINGS OF THE IEEE | Vol. 110, No. 2, February 2022\\nChen et al. : AI-Based Reconstruction for Fast MRI—Systematic Review and Meta-Analysis\\nreconstruction exploiting a rotation-invariant total\\nvariation discretization,” Magn. Reson. Imag. ,\\nvol. 71, pp. 80–92, Sep. 2020, doi: 10.1016/\\nj.mri.2020.03.008.\\n[150] L. Qiusheng, F . Xiaoyu, S. Baoshun, and\\nZ. Xiaohua, “Compressed sensing MRI based on\\nthe hybrid regularization by denoising and theepigraph projection,” Signal Process. , vol. 170,\\nMay 2020, Art. no. 107444, doi: 10.1016/j.sigpro.2019.107444.\\n[151] F . Hashimoto, K. Ote, T . Oida, A. Teramoto, and\\nY . Ouchi, “Compressed-sensing magnetic\\nresonance image reconstruction using an iterative\\nconvolutional neural network approach,” Appl.\\nSci., vol. 10, no. 6, Mar . 2020, Art. no', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 885: (' 10.1016/\\nj.mri.2020.03.008.\\n[150] L. Qiusheng, F . Xiaoyu, S. Baoshun, and\\nZ. Xiaohua, “Compressed sensing MRI based on\\nthe hybrid regularization by denoising and theepigraph projection,” Signal Process. , vol. 170,\\nMay 2020, Art. no. 107444, doi: 10.1016/j.sigpro.2019.107444.\\n[151] F . Hashimoto, K. Ote, T . Oida, A. Teramoto, and\\nY . Ouchi, “Compressed-sensing magnetic\\nresonance image reconstruction using an iterative\\nconvolutional neural network approach,” Appl.\\nSci., vol. 10, no. 6, Mar . 2020, Art. no. 6, doi:\\n10.3390/app10061902.\\n[152] Y .C h e n ,Z .F a n g ,S . - C .H u n g ,W . - T .C h a n g ,\\nD. Shen, and W . Lin, “High-resolution 3D MRﬁngerprinting using parallel imaging and deep\\nlearning,” NeuroImage , vol. 206, Feb. 2020,\\nArt. no. 116329, doi: 10.1016/j.neuroimage.\\n2019.116329.\\n[153] D. F . McGivney et al. , “Magnetic resonance\\nﬁngerprinting review . Part 2: Technique and\\ndirections,” J .M a g n .R e s o n .I m a g . , vol. 51, no. 4,\\npp. 993–1007, Apr . 2020, doi:\\n10.1002/jmri.26877.\\nVol. 110, No. 2, February 2022 |PROCEEDINGS OF THE IEEE 245', 'AI-Based econstruction for Fast MRI A Systematic Review and MetaAnalysis.pdf'), 886: ('The CHERI capability model: Revisiting RISC in an age of risk\\nJonathan WoodruffyRobert N. M. WatsonyDavid ChisnallySimon W. MooreyJonathan Andersony\\nBrooks DaviszBen Laurie§Peter G. NeumannzRobert NortonyMichael Roey\\nyUniversity of CambridgezSRI International§Google UK Ltd\\nfirstname .lastname @cl.cam.ac.uk {neumann,brooks}@csl.sri.com benl@google.com\\nAbstract\\nMotivated by contemporary security challenges, we reeval-\\nuate and reﬁne capability-based addressing for the RISC era.\\nWe present CHERI, a hybrid capability model that extends\\nthe 64-bit MIPS ISA with byte-granularity memory protection.\\nWe demonstrate that CHERI enables language memory model\\nenforcement and fault isolation in hardware rather than soft-\\nware, and that the CHERI mechanisms are easily adopted by\\nexisting programs for efﬁcient in-program memory safety.\\nIn contrast to past capability models, CHERI complements,\\nrather than replaces, the ubiquitous page-based protection\\nmechanism, providing a migration path towards deconﬂat-\\ning data-structure protection and OS memory management.\\nFurthermore, CHERI adheres to a strict RISC philosophy: it\\nmaintains a load-store architecture and requires only single-\\ncycle instructions, and supplies protection primitives to the\\ncompiler, language runtime, and operating system.\\nWe demonstrate a mature FPGA implementation that runs\\nthe FreeBSD operating system with a full range of software\\nand an open-source application suite compiled with an ex-\\ntended LLVM to use CHERI memory protection. A limit study\\ncompares published memory safety mechanisms in terms of\\ninstruction count and memory overheads. The study illustrates\\nthat CHERI is performance-competitive even while providing\\nassurance and greater ﬂexibility with simpler hardware.\\n1. Introduction\\nResearch systems such as Mondrian Memory Protection [ 45,\\n46] and Hardbound [ 12], and industrial approaches such\\nas Intel’s recently announced Memory Protection Exten-\\nsions (iMPX) [ 17], have shown the importance of architectural\\nsupport for ﬁne-grained memory protection. M', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 887: ('ished memory safety mechanisms in terms of\\ninstruction count and memory overheads. The study illustrates\\nthat CHERI is performance-competitive even while providing\\nassurance and greater ﬂexibility with simpler hardware.\\n1. Introduction\\nResearch systems such as Mondrian Memory Protection [ 45,\\n46] and Hardbound [ 12], and industrial approaches such\\nas Intel’s recently announced Memory Protection Exten-\\nsions (iMPX) [ 17], have shown the importance of architectural\\nsupport for ﬁne-grained memory protection. Mondrian in par-\\nticular identiﬁed the conﬂation of protection with translation\\nas a ﬂaw in existing approaches: paging is useful for operating\\nsystems that provide coarse-grained separation and virtual-\\nization ( translation ), whereas segmentation is more useful to\\nenforce intra-program protection . Program safety and security\\ndepends on enforcing pointer safety (the size and permission\\naspects of dynamic type safety ) and isolation (forsandboxing\\norapplication compartmentalization [40]).\\nCapability-system proponents have long argued that a strong\\nunderlying protection model can improve software robustness\\nand security [ 11,42]. However, limited historical demandfor ﬁne-grained protection, combined with signiﬁcant techni-\\ncal challenges (especially compatibility), has challenged the\\nadoption of capability systems. In contrast, coarse-grained\\nvirtual-memory protection has seen wide deployment to isolate\\napplication instances from one another. Ubiquitous network-\\ning and widespread security threats have renewed interest in\\nﬁner-grained protection models that not only improve soft-\\nware debuggability, but also mitigate vulnerability exploit\\ntechniques (e.g., code injection via buffer overﬂows).\\nProcessors with capability-based addressing, epitomized by\\ndesigns such as the M-Machine [ 5], provide strong technical\\nand intellectual grounding for intra-program protection. How-\\never, such systems fail to provide adequate compatibility with\\nexisting source-code and binary software corpora, and often\\nrequire ground-up s', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 888: ('d interest in\\nﬁner-grained protection models that not only improve soft-\\nware debuggability, but also mitigate vulnerability exploit\\ntechniques (e.g., code injection via buffer overﬂows).\\nProcessors with capability-based addressing, epitomized by\\ndesigns such as the M-Machine [ 5], provide strong technical\\nand intellectual grounding for intra-program protection. How-\\never, such systems fail to provide adequate compatibility with\\nexisting source-code and binary software corpora, and often\\nrequire ground-up software rewrites. In contrast, hardware and\\nsoftware bounds-checking techniques often exchange safety\\n(and sometimes performance) for clearer adoption paths.\\nIn this paper, we introduce Capability Hardware Enhanced\\nRISC Instructions (CHERI), a hybrid capability model that\\nblends conventional ISA and MMU design choices with a\\ncapability-system model. Key features include a capability\\ncoprocessor (deﬁning a set of compiler-managed capability\\nregisters holding capabilities similar to unforgeable segment\\ndescriptors), and tagged memory (protecting in-memory capa-\\nbilities). Capability addressing occurs before virtual-address\\ntranslation such that each process is a self-contained virtual\\ncapability system. As programs adopt the CHERI ISA, object\\naccesses use these registers to check bounds, control access,\\nand protect pointer integrity. Tagging allows data and capa-\\nbilities to be safely combined within data structures. CHERI\\noffers scalable and secure intra-address-space protection, and\\nretains a high level of source-code and binary compatibility.\\nWhile the 64-bit MIPS ISA was our starting point, the ap-\\nproach is not speciﬁc to MIPS. Our key contributions are:\\n\\x0fa novel hybridization of capability-based addressing with a\\nRISC ISA and MMU-based virtual memory emphasizing\\nboth performance and compatibility;\\n\\x0fan FPGA-based microprocessor implementation demon-\\nstrating our approach;\\n\\x0fadaptations of the LLVM compiler suite [ 22] and FreeBSD\\noperating system [26] to use these features;\\n\\x0ffunctional and simulation-based co', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 889: ('urce-code and binary compatibility.\\nWhile the 64-bit MIPS ISA was our starting point, the ap-\\nproach is not speciﬁc to MIPS. Our key contributions are:\\n\\x0fa novel hybridization of capability-based addressing with a\\nRISC ISA and MMU-based virtual memory emphasizing\\nboth performance and compatibility;\\n\\x0fan FPGA-based microprocessor implementation demon-\\nstrating our approach;\\n\\x0fadaptations of the LLVM compiler suite [ 22] and FreeBSD\\noperating system [26] to use these features;\\n\\x0ffunctional and simulation-based comparisons of conven-\\ntional and research protection models; and\\n\\x0fbenchmark comparison with software bounds checking.\\n978-1-4799-4394-4/14/$31.00 c\\r2014 IEEE\\nWe ﬁrst describe requirements for ﬁne-grained memory pro-\\ntection, our RISC memory capability model, its realizations in\\nthe 64-bit MIPS ISA, and implementation on FPGA. We then\\ncompare the CHERI model with a number of other research\\nand ﬁelded protection models, exploring tradeoffs in protec-\\ntion, compatibility, and performance. A limit study, derived\\nfrom execution traces, reveals that CHERI has competitive\\nperformance with other models. We also run benchmarks on\\nour FPGA implementation in order to understand practical im-\\nplementation and performance considerations, which illustrate\\nsigniﬁcant improvements over software bounds-checking.\\n2. Practical memory protection requirements\\nPractical userspace protection has several desirable properties:\\nUnprivileged use Protection should be the common case and\\ntherefore should not require frequent system calls.\\nFine granularity Granularity should accommodate data\\nstructures that are small and densely packed (e.g., on-stack),\\nor with odd numbers of bytes or words.\\nUnforgeability Software should not be able to increase its\\npermissions, accidentally or maliciously.\\nAccess control Hardware should enforce region permissions\\nsuch as store and execute.\\nSegment scalability Performance and memory storage over-\\nhead should scale gracefully with the number of protected\\nmemory regions.\\nDomain scalability Performance and memo', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 890: ('\\nFine granularity Granularity should accommodate data\\nstructures that are small and densely packed (e.g., on-stack),\\nor with odd numbers of bytes or words.\\nUnforgeability Software should not be able to increase its\\npermissions, accidentally or maliciously.\\nAccess control Hardware should enforce region permissions\\nsuch as store and execute.\\nSegment scalability Performance and memory storage over-\\nhead should scale gracefully with the number of protected\\nmemory regions.\\nDomain scalability Performance and memory storage over-\\nhead should scale gracefully with the number of protection\\ndomains and frequency of their communication.\\nIncremental deployment Extant userspace software should\\nrun without recompilation even as selected components, such\\nas shared libraries, make use of ﬁne-grained protection.\\nFurthermore, we believe userspace protection should exploit\\nprogram knowledge to offer pointer safety, not just address\\nvalidity. Address validity models associate protection proper-\\nties with regions of address space. Paged virtual memory is an\\naddress validity mechanism. Pointer safety models associate\\nprotection properties with object references. Fat pointers are a\\npointer safety mechanism. Pointer safety is more precise than\\naddress validity and can, for example, distinguish between\\na buffer overﬂow and a reference to an adjacent object in\\nmemory. Address validity, however, makes supervision more\\nconvenient due to a centralized protection table, and enables\\nfeatures such as efﬁcient revocation.\\nWe observe that pointer safety implies a segmented view\\nof memory rather than the common ﬂat view. It should be\\npossible to blend these two views on memory to gain safety\\nwithout unnecessarily breaking compatibility.\\n3. A RISC memory capability model\\nWhile the requirements outlined above are complex, the hard-\\nware mechanism that fulﬁlls these requirements should be as\\nsimple as possible to ease adoption by processor manufactur-ers. The most efﬁcient unforgeable pointer safety implemen-\\ntations use a memory capability model . I', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 891: ('er safety implies a segmented view\\nof memory rather than the common ﬂat view. It should be\\npossible to blend these two views on memory to gain safety\\nwithout unnecessarily breaking compatibility.\\n3. A RISC memory capability model\\nWhile the requirements outlined above are complex, the hard-\\nware mechanism that fulﬁlls these requirements should be as\\nsimple as possible to ease adoption by processor manufactur-ers. The most efﬁcient unforgeable pointer safety implemen-\\ntations use a memory capability model . In such a model, a\\nmemory capability is an unforgeable pointer that grants access\\nto a linear range of address space. To maintain safety, all\\nmemory accesses must occur through a memory capabilities.\\nIt is possible to implement a memory capability model in a\\nstrict RISC instruction set with a load-store architecture and\\nsingle-cycle operations as demonstrated by the M-Machine [ 5].\\nIn a RISC implementation, memory capabilities can be stored\\nin registers or in memory, but must be loaded into registers\\nfor use. The current protection domain is deﬁned by the\\ncapabilities stored in registers along with all capabilities in\\nmemory reachable through those capabilities. With explicit\\nmanagement of memory capabilities in the style of pointers,\\nthere is no need for an associative table (such as the protection\\nlookaside buffer in Mondrian) for managing permissions. This\\napproach allows protection to scale with memory space rather\\nthan with a ﬁxed resource like the TLB [ 27]. This approach\\nalso allows performance with protection to match a general-\\npurpose pointer model.\\nTo meet our memory-protection requirement in a RISC\\nmemory capability architecture, we must ensure that:\\n1. Capability manipulation instructions are unprivileged.\\n2.Capabilities can span any range in the virtual address space.\\n3.Legacy references are supported, but are constrained by the\\ncapability memory model.\\nThese constraints make a RISC capability model not only\\nefﬁcient, but useful to modern software stacks.\\n4. CHERI implementation\\nWe have chosen to i', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 892: ('tection to match a general-\\npurpose pointer model.\\nTo meet our memory-protection requirement in a RISC\\nmemory capability architecture, we must ensure that:\\n1. Capability manipulation instructions are unprivileged.\\n2.Capabilities can span any range in the virtual address space.\\n3.Legacy references are supported, but are constrained by the\\ncapability memory model.\\nThese constraints make a RISC capability model not only\\nefﬁcient, but useful to modern software stacks.\\n4. CHERI implementation\\nWe have chosen to implement a RISC capability model as an\\nextension to the 64-bit MIPS IV instruction set. MIPS has a\\nwell-established 64-bit speciﬁcation and adheres to a proto-\\ntypical RISC philosophy. We implemented the processor in\\nBluespec SystemVerilog [ 4], with a general parity of features\\nwith the MIPS R4000. As with the MIPS R4000, our base pro-\\ncessor (Bluespec Extensible RISC Implementation (BERI)) is\\nsingle-issue and in-order, with a throughput approaching one\\ninstruction per cycle. BERI has a branch predictor and uses\\nlimited register renaming for robust forwarding in its 6-stage\\npipeline. BERI runs at 100MHz on an Altera Stratix IV FPGA\\nand is capable of running the stock FreeBSD 10 operating\\nsystem and associated applications. The CHERI processor\\nadds capability extensions to BERI and is fully backward\\ncompatible, facilitating side-by-side comparisons.\\nCHERI capability extensions are implemented as a MIPS\\ncoprocessor, CP2. Similar to the MIPS ﬂoating-point copro-\\ncessor, CP1, the capability coprocessor holds a new register\\nﬁle and logic to access and update it. The MIPS pipeline\\nfeeds instructions into the capability coprocessor, exchange\\noperands with it, and receive exceptions from it. The capabil-\\nity coprocessor also transforms and limits memory requests\\nfrom instruction fetch and MIPS load and store instructions.\\npermissions (31 bits)\\nbase (64 bits)\\nlength (64 bits)9\\n>>>>>=\\n>>>>>;256 bits\\nFigure 1: Memory capability\\n4.1. Capability registers\\nCHERI implements an additional register ﬁle for capabilities.\\nThis a', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 893: ('ew register\\nﬁle and logic to access and update it. The MIPS pipeline\\nfeeds instructions into the capability coprocessor, exchange\\noperands with it, and receive exceptions from it. The capabil-\\nity coprocessor also transforms and limits memory requests\\nfrom instruction fetch and MIPS load and store instructions.\\npermissions (31 bits)\\nbase (64 bits)\\nlength (64 bits)9\\n>>>>>=\\n>>>>>;256 bits\\nFigure 1: Memory capability\\n4.1. Capability registers\\nCHERI implements an additional register ﬁle for capabilities.\\nThis approach distinguishes capability state from integer state\\n(and ﬂoating point state) in the architecture to avoid dynamic\\nregister types. There are 32 capability registers, each 256-\\nbit wide, mirroring the number of integer and ﬂoating-point\\nregisters in MIPS. A commercial implementation might con-\\nsider a smaller register set that would not unduly increase\\nstack spills, and would reduce context-switch overhead and\\nhardware resources, but we have maintained a large set for ex-\\nperimentation and for consistency with the MIPS architecture.\\nThe currently implemented capability structure is shown in\\nFigure 1. The base andlength ﬁelds are the two basic ﬁelds\\nneeded to describe a segment of memory. We have allocated\\n64 bits to each, and choose not to implement a compression\\nalgorithm at this time to allow maximum ﬂexibility as a re-\\nsearch tool. The permissions ﬁeld is a 31-bit vector with a\\n“1” in each position indicating an allowed permission for the\\nregion. Permissions include load data, store data, execute, and\\nload and store for capabilities. The other 26 permissions, and\\nremaining capability ﬁelds, are being used for experimentation\\nas described in Section 11. An implementation intended for\\nwidespread deployment would likely use a denser representa-\\ntion – for example, 128-bits using 40-bit virtual addresses or\\nthe Low-Fat Pointer approach [20].\\nExisting MIPS load and store instructions are implicitly\\noffset via capability register 0, C0, and instruction fetches\\nare offset via an implied program counter capabil', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 894: ('\\nload and store for capabilities. The other 26 permissions, and\\nremaining capability ﬁelds, are being used for experimentation\\nas described in Section 11. An implementation intended for\\nwidespread deployment would likely use a denser representa-\\ntion – for example, 128-bits using 40-bit virtual addresses or\\nthe Low-Fat Pointer approach [20].\\nExisting MIPS load and store instructions are implicitly\\noffset via capability register 0, C0, and instruction fetches\\nare offset via an implied program counter capability, PCC .\\nThis allows legacy code to run unmodiﬁed on CHERI, facil-\\nitating incremental adoption, and also allows sandboxing of\\nunmodiﬁed programs within a parent address space.\\nWe have also added a full set of load and store operations\\nfor addressing memory through capability registers with both\\nimmediate and register offsets. As MIPS lacks native register-\\nindexed addressing, capability-relative addressing can often\\nbe faster than legacy loads and stores.\\n4.2. Capability manipulation and protection\\nThe greatest challenge for a protection model is to protect\\nmemory capabilities from arbitrary manipulation (unforgeabil-\\nity) without appealing to the kernel (unprivileged use). This\\nis important, as system calls remain a relatively expensive\\noperation. For example, malloc() implementations typically\\namortize kernel entry by using a single mmap() system call to\\nacquire a large block of memory for disbursement over many\\nallocations [ 13]. A memory protection scheme that requires aMnemonic Description\\nCGetBase Move base to a GPR\\nCGetLen Move length to a GPR\\nCGetTag Move tag bit to a GPR\\nCGetPerm Move permissions to a GPR\\nCGetPCC Move the PCC and PC to GPRs\\nCIncBase Increase base and decrease length\\nCSetLen Set (reduce) length\\nCClearTag Invalidate a capability register\\nCAndPerm Restrict permissions\\nCToPtr Generate C0-based integer pointer from\\na capability\\nCFromPtr CIncBase with support for NULL casts\\nCBTU Branch if capability tag is unset\\nCBTS Branch if capability tag is set\\nCLC Load capability register\\nCSC Store c', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 895: ('ve base to a GPR\\nCGetLen Move length to a GPR\\nCGetTag Move tag bit to a GPR\\nCGetPerm Move permissions to a GPR\\nCGetPCC Move the PCC and PC to GPRs\\nCIncBase Increase base and decrease length\\nCSetLen Set (reduce) length\\nCClearTag Invalidate a capability register\\nCAndPerm Restrict permissions\\nCToPtr Generate C0-based integer pointer from\\na capability\\nCFromPtr CIncBase with support for NULL casts\\nCBTU Branch if capability tag is unset\\nCBTS Branch if capability tag is set\\nCLC Load capability register\\nCSC Store capability register\\nCL[BHWD][U] Load byte, half-word, word or double\\nvia capability register, (zero-extend)\\nCS[BHWD] Store byte, half-word, word or double\\nvia capability register\\nCLLD Load linked via capability register\\nCSCD Store conditional via capability register\\nCJR Jump capability register\\nCJALR Jump and link capability register\\nTable 1: CHERI instruction-set extensions\\nsystem call for every malloc() would negate this optimization\\nand be avoided in performance-sensitive applications.\\nTo preserve capability integrity while allowing user-space\\nmanagement, we must restrict capability manipulation, par-\\nticularly in memory. That is, capabilities in memory must\\nnot be corrupted by general-purpose stores. Some traditional\\ncapability machines [42] and capability microkernels such as\\nseL4 [ 19] have done this by deﬁning regions of memory that\\ncan store capabilities distinct from those that can store data.\\nThis approach is problematic for a fat-pointer approach, as\\nmost contemporary programming languages allow arbitrary in-\\ntermixing of pointers and data. In keeping with the RISC idea\\nof the ISA as a compiler target [ 29], we have implemented\\ntagged memory rather than supporting only regional separation.\\nValid capabilities are identiﬁed by an extra ‘tag’ bit associated\\nwith each 256-bit location. Any non-capability store clears this\\nbit, thereby protecting the integrity of capabilities in memory\\nwithout appealing to kernel mode.\\nWith capabilities protected in memory, we implement user-\\nmode instructions to safely ma', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 896: ('itrary in-\\ntermixing of pointers and data. In keeping with the RISC idea\\nof the ISA as a compiler target [ 29], we have implemented\\ntagged memory rather than supporting only regional separation.\\nValid capabilities are identiﬁed by an extra ‘tag’ bit associated\\nwith each 256-bit location. Any non-capability store clears this\\nbit, thereby protecting the integrity of capabilities in memory\\nwithout appealing to kernel mode.\\nWith capabilities protected in memory, we implement user-\\nmode instructions to safely manipulate capabilities in the reg-\\nister ﬁle. Table 1 shows a summary of the instructions that\\nCHERI adds to the MIPS IV ISA. These include a full comple-\\nment of load and store instructions, instructions for inspecting\\nInst.FetchSchedulerDecodeExecuteWriteback\\nCapability CoprocessorMemoryAccessExchangeOperandsPut Capability InstructionGet AddressCommit WritebackOffset AddressForwarding Register FileReadWriteSpeculative WriteRequestFigure 2: BERI pipeline with capability coprocessor\\na capability, and for reducing (but not extending) the rights\\ngranted by a capability. Instructions that change ﬁelds in a\\ncapability must strictly reduce privilege, that is, disclaim per-\\nmissions or reduce the extent. These restrictions allow CHERI\\nto ensure capabilities are unforgeable . With the software un-\\nable to fabricate arbitrary memory references, a protection\\ndomain is deﬁned by the transitive closure of memory capa-\\nbilities reachable from its capability register set. Under an\\noperating system, a process that begins with a capability for all\\nprivilege to its virtual address space can construct arbitrarily\\nrestricted domains described by unforgeable references.\\nCHERI tags physical memory, not virtual memory, and\\ntherefore maintains a single table for the entire system. This\\ntable holds one tag bit for each 256-bit line in memory, or 4MB\\nof tag space per gigabyte of memory. A tag manager below the\\nlast level cache presents a 257-bit, tagged-memory interface\\nto the CHERI cache hierarchy. The manager associates each\\nmemory t', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 897: ('th a capability for all\\nprivilege to its virtual address space can construct arbitrarily\\nrestricted domains described by unforgeable references.\\nCHERI tags physical memory, not virtual memory, and\\ntherefore maintains a single table for the entire system. This\\ntable holds one tag bit for each 256-bit line in memory, or 4MB\\nof tag space per gigabyte of memory. A tag manager below the\\nlast level cache presents a 257-bit, tagged-memory interface\\nto the CHERI cache hierarchy. The manager associates each\\nmemory transaction with a tag from the table and ensures\\nconsistency between memory and tags. The CHERI cache\\nhierarchy propagates capability tags and implements CHERI\\ntag semantics (which preserve the tag for a capability store\\nand clear a tag on a general-purpose store). The decision\\nto use physical – not virtual – memory for tags eliminates\\ntranslation for the tag table (as required by Hardbound), and\\nallows the tags to accompany physical cache lines through\\nthe cache hierarchy. CHERI allows capability registers to\\ncontain general-purpose data, which preserves the cleared tag\\nto prevent use as a capability. This allows capability load and\\nstore instructions to copy 256-bit blocks of memory while\\nremaining oblivious to whether they are copying data or a\\ncapability. As a result, a simple implementation of memcpy()\\ncan copy data structures containing both.\\nOur prototype maintains the tag table in DRAM. We could\\nalternatively move it to a smaller memory that can be accessed\\nin parallel with DRAM, or store tags in ECC-like bits to elimi-\\nnate table lookups. However, the current tag controller (which\\nminimizes table lookups using an 8KB tag cache) does not\\nnoticeably degrade performance.\\n4.3. Compatibility\\nCHERI allows capability-aware and legacy code to share an ad-\\ndress space. Unsandboxed legacy executables run with access\\nto the full address space, but may invoke capability-protected\\nlibraries. For example, an unmodiﬁed web browser can in-voke capability-aware image libraries or video CODECs via\\nMIPS-ABI functions. Ca', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 898: ('like bits to elimi-\\nnate table lookups. However, the current tag controller (which\\nminimizes table lookups using an 8KB tag cache) does not\\nnoticeably degrade performance.\\n4.3. Compatibility\\nCHERI allows capability-aware and legacy code to share an ad-\\ndress space. Unsandboxed legacy executables run with access\\nto the full address space, but may invoke capability-protected\\nlibraries. For example, an unmodiﬁed web browser can in-voke capability-aware image libraries or video CODECs via\\nMIPS-ABI functions. Capability-aware code can use sand-\\nboxed legacy code by restricting the default instruction and\\ndata capabilities ( PCC andC0). The CToPtr and CFromPtr\\ninstructions convert between C pointers and capabilities to\\nsupport safe and efﬁcient interaction between capability-aware\\nand legacy code.\\nThe CHERI capability model requires minimal support from\\nthe OS. CHERI capabilities are layered atop standard paging,\\nso the virtual memory system works without modiﬁcation.\\nOn CPU reset, capability registers are initialized, granting\\nthe OS access to the entire address space so an OS can run\\nunchanged without knowledge of the capability extensions.\\nIndeed, we ﬁrst achieved stability with unmodiﬁed FreeBSD\\non the processor before we added support for capabilities.\\nOur extended version of FreeBSD enables the capability\\ncoprocessor on boot; when the ﬁrst user process is created or\\nexecve() is invoked, the entire user virtual address space is del-\\negated to the user register ﬁle. The kernel saves and restores\\nper-thread capability-register state on context switches. The\\nuser process then manages capabilities within that space, thus\\nrestricting access. Capability-aware allocators can manage\\nmemory and return capabilities in much the same way as con-\\nventional memory allocators. Revocation can be accomplished\\nvia zero-address-space-reuse allocators, TLB unmapping, or\\nby a simpliﬁed version of garbage collection (made reliable by\\ncapability tags). New TLB permissions authorize capability\\nloads and stores. The OS virtual-memory syst', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 899: ('lity-register state on context switches. The\\nuser process then manages capabilities within that space, thus\\nrestricting access. Capability-aware allocators can manage\\nmemory and return capabilities in much the same way as con-\\nventional memory allocators. Revocation can be accomplished\\nvia zero-address-space-reuse allocators, TLB unmapping, or\\nby a simpliﬁed version of garbage collection (made reliable by\\ncapability tags). New TLB permissions authorize capability\\nloads and stores. The OS virtual-memory system is being\\nextended to preserve tags for swapped pages.\\n4.4. Pipeline organization\\nAs seen in Figure 2, our capability extensions are modularized\\nas a MIPS coprocessor with a dedicated register ﬁle. All\\ndata accesses reference a capability register either explicitly\\nor implicitly ( C0), so the capability coprocessor is tightly\\ncoupled with the Execute and Memory Access stages of the\\npipeline. While instruction fetches are logically offset by\\na capability register, PCC , in implementation CHERI uses\\nan absolute address for the program counter and validates it\\nagainst PCC in the Execute stage to simplify both forwarding\\nand instruction address calculation.\\nThe capability register ﬁle is an instantiation of the general-\\npurpose forwarding register ﬁle and inherits register renaming.\\nAll capability manipulation instructions are single cycle, as\\nare capability loads and stores. This style of manipulation\\nhas orders of magnitude higher performance than protected\\nsegment manipulation on IA32 that, for example, required at\\nleast 241 cycles on a 1.1GHz Pentium III [21].\\n5. Use cases for CHERI capabilities\\nCHERI user-managed memory protection has a variety of\\npotential uses, most of which are unexplored in contemporary\\noperating systems. Cheap, ﬁne-grained memory protection\\nradically changes the memory-safety trade-off topography, and\\nwe hope that our platform will enable exploration of this new\\nlandscape. This section describes some anticipated use cases.\\n5.1. Memory safety for C\\nThe C language provides programmers wit', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 900: ('ired at\\nleast 241 cycles on a 1.1GHz Pentium III [21].\\n5. Use cases for CHERI capabilities\\nCHERI user-managed memory protection has a variety of\\npotential uses, most of which are unexplored in contemporary\\noperating systems. Cheap, ﬁne-grained memory protection\\nradically changes the memory-safety trade-off topography, and\\nwe hope that our platform will enable exploration of this new\\nlandscape. This section describes some anticipated use cases.\\n5.1. Memory safety for C\\nThe C language provides programmers with a great deal of\\nﬂexibility, but the price of this ﬂexibility is a lack of memory\\nsafety. Previous work has attempted to provide C programmers\\nwith greater memory safety via static and dynamic checks\\nin software. Cyclone [ 18] is a variant of C that explicitly\\nallows deﬁnition of fat pointers that are dynamically checked;\\nCCured [ 28] automates the same process with either static\\nveriﬁcation or run-time checks. Fat pointers come at a run-\\ntime cost, but adding hardware support for fat pointers in the\\nform of CHERI capabilities removes most of the distribution\\nand enforcement costs.\\nCHERI capabilities can be used as general-purpose pointers\\nwith the limitation that their range cannot be enlarged. We\\nhave extended the LLVM [ 22] compiler framework and Clang,\\nthe C front end, to implement pointers as memory capabilities\\nto ensure they are used according to programmer intent, in-\\ncluding bounds checking and read, write, and execute property\\nenforcement. We have added support for the __capability\\nand__output qualiﬁers in the Clang front end and extended\\nits understanding of casts. We improved LLVM’s notion of\\naddress space to encode capabilities, and added special cases\\nfor a small number of optimizations that assumed that point-\\ners were integers. Finally, we extended the MIPS back end\\nwith support for our new instructions. As a result, a malloc()\\nthat returns a capability will use the CIncBase and CSetLen\\ninstructions to construct a capability for the region that can be\\nused to address the object with automatic b', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 901: ('iﬁers in the Clang front end and extended\\nits understanding of casts. We improved LLVM’s notion of\\naddress space to encode capabilities, and added special cases\\nfor a small number of optimizations that assumed that point-\\ners were integers. Finally, we extended the MIPS back end\\nwith support for our new instructions. As a result, a malloc()\\nthat returns a capability will use the CIncBase and CSetLen\\ninstructions to construct a capability for the region that can be\\nused to address the object with automatic bounds checking. In\\naddition, a const -qualiﬁed capability pointer will explicitly\\ndisclaim the write permission via the CAndPerm instruction, so\\nthat the processor will throw an exception if attempts are made\\nto write through it. We anticipate that other languages will\\nmake similar use of this functionality, but aim to provide a\\nrich toolbox of simple primitives for compilers to use rather\\nthan prescribe speciﬁc models.\\nCHERI capabilities can also protect the stack. For example,\\nstack pointers can be cast to capabilities to take advantage\\nof bounds checking. We have an experimental version of\\nthe compiler that protects individual frames by using stack\\ncapabilities to eliminate stack overﬂow.\\nPointer subtraction is not supported natively by CHERI\\ncapabilities because they do not have an internal index. An ex-\\nternal integer register index can be used if pointer subtraction\\nis required. Capabilities can be indexed with signed register\\nand immediate values, but an access will throw an exception\\nif the ﬁnal offset is out of range.\\nThe CHERI ABI deﬁnes eight capability-argument registers\\nfor passing capabilities in a function call, which greatly alle-\\nviate register pressure when replacing a software fat-pointer\\nscheme, which would otherwise require at least two general-\\npurpose registers for each pointer. However, stack spills willstill have a larger cache footprint due to increased register size.\\nInter-domain calls (which incur a larger overhead to support\\nmutual distrust) are not yet integrated into our compiler.', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 902: ('t is out of range.\\nThe CHERI ABI deﬁnes eight capability-argument registers\\nfor passing capabilities in a function call, which greatly alle-\\nviate register pressure when replacing a software fat-pointer\\nscheme, which would otherwise require at least two general-\\npurpose registers for each pointer. However, stack spills willstill have a larger cache footprint due to increased register size.\\nInter-domain calls (which incur a larger overhead to support\\nmutual distrust) are not yet integrated into our compiler.\\nWe might note that consistency between base and bounds\\ncan be a problem even for hardware fat pointer implementa-\\ntions, as we describe in Section 6.4. However, CHERI capa-\\nbilities used as fat pointers avoid race conditions by updating\\ncapability ﬁelds and tags atomically.\\n5.2. Managed language runtime support\\nLanguages that do provide memory safety must enforce it\\nwith the available instructions. CHERI capabilities provide a\\nlevel of object support in the instruction set to allow managed\\nlanguage runtimes and the JIT compilers that target them to\\nbe simpler, faster, and more secure. The segments-as-objects\\nmodel was one of the basic motivations for iAP c432 segmen-\\ntation [ 30], and in turn for Intel 80286 segments [ 7], but these\\nsegment-table approaches do not scale to arbitrary program\\nsize or data complexity. In contrast, a straightforward applica-\\ntion of capability registers as pointers and of protected calls\\n(see Section 11) on invocations would provide scalable, strong\\nhardware protection of language objects.\\n5.3. Sandboxing and compartmentalization\\nMemory protection constrains the effects of code, which\\ncan be used not just for improvements in robustness, but\\nalso for security. The CHERI model conveniently and ef-\\nﬁciently supports application sandboxing and compartmen-\\ntalization. Conventional binaries are sandboxed in micro-\\naddress spaces within existing processes by constraining C0\\nandPCC . CHERI-aware programs use capabilities to describe\\nmore granular compartmentalization in which memory and\\no', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 903: ('ge objects.\\n5.3. Sandboxing and compartmentalization\\nMemory protection constrains the effects of code, which\\ncan be used not just for improvements in robustness, but\\nalso for security. The CHERI model conveniently and ef-\\nﬁciently supports application sandboxing and compartmen-\\ntalization. Conventional binaries are sandboxed in micro-\\naddress spaces within existing processes by constraining C0\\nandPCC . CHERI-aware programs use capabilities to describe\\nmore granular compartmentalization in which memory and\\nobject rights are safely delegated between multiple protection\\ndomains within a UNIX process.\\n6. Functional comparison of protection models\\nIn this section, we review several proposed protection models\\nsupporting safety and compartmentalization, and compare\\nthem with CHERI. Table 2 considers these models in terms of\\nour protection criteria: unprivileged use; ﬁne-grained control;\\nunforgeable references; read, write, and execute permissions;\\npointer safety, segment scalability; domain scalability; and\\nincremental deployability to current programming languages.\\nCHERI is able to provide the stronger memory-protection\\nand domain-transition properties of the M-Machine capability\\nmodel with greater adoptability due to inclusion of a general-\\npurpose MMU and a complete fat-pointer representation. How-\\never, this comes with increased memory trafﬁc relative to\\nM-Machine, more invasive instruction set additions relative\\nto Hardbound, and reduced binary compatibility relative to\\niMPX. Protection, representation, and performance tradeoffs\\nare considered in greater detail in Sections 7 and 8.\\nProtection Unprivileged Fine- Unforgeable*Access Pointer Segment Domain Incremental\\nmechanism use grained control safety scalability scalability deployment\\nMMU - - - ! - - - !\\nMondrian - !**- ! - ! - !\\nHardbound ! ! ! - ! ! n/a !\\niMPX ! ! ! - ! ! n/a !\\niMPX Fat Pointers ! ! - - ! ! n/a -\\nM-Machine ! - ! ! ! ! ! -\\nCHERI ! ! ! ! ! ! ! !\\n*Unforgeability in the context of protection-domain-free models refers to the difﬁculty of constructing ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 904: ('rmance tradeoffs\\nare considered in greater detail in Sections 7 and 8.\\nProtection Unprivileged Fine- Unforgeable*Access Pointer Segment Domain Incremental\\nmechanism use grained control safety scalability scalability deployment\\nMMU - - - ! - - - !\\nMondrian - !**- ! - ! - !\\nHardbound ! ! ! - ! ! n/a !\\niMPX ! ! ! - ! ! n/a !\\niMPX Fat Pointers ! ! - - ! ! n/a -\\nM-Machine ! - ! ! ! ! ! -\\nCHERI ! ! ! ! ! ! ! !\\n*Unforgeability in the context of protection-domain-free models refers to the difﬁculty of constructing an unauthorized pointer to an object.\\n**Mondrian supports ﬁne-grained heap protection, but not ﬁne-grained stack or global protection.\\nTable 2: Comparison of address-validity, pointer-validity (table-based), and pointer-validity (fat-pointer based) models\\n6.1. Conventional Memory Management Units (MMUs)\\nTraditional Memory Management Units (MMUs) map a (pos-\\nsibly sparse) virtual address space into physical memory via a\\npage table , with permissions assigned to each page. Kernels\\nused MMUs to isolate processes from one another (implement-\\ning protection domains), with shared memory supported by\\nmapping the same physical page into multiple address spaces.\\nThe MMU approach fails most of our requirements for\\nin-address space protection, but is the only widely deployed\\nprotection mechanism today. Page-based protection is coarse-\\ngrained: most implementations have a minimum page size\\nof 4KB limiting bounds-checking precision. Coarse-grained\\nMMU protection can detect either overﬂows or underﬂows\\nfor small objects, but not both; single-object allocations will\\nwaste physical memory, and guard pages between allocations\\nwill consume virtual address space. MMUs implement only\\naddress validation , not pointer safety : a sufﬁciently large over-\\nﬂow may miss the guard page and write to another allocation.\\nMMU isolation can also be used for application compart-\\nmentalization , such as in the Chromium web browser where\\ntabs run in separate processes to improve robustness and se-\\ncurity. MMU process isolation proves expensive du', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 905: ('ut not both; single-object allocations will\\nwaste physical memory, and guard pages between allocations\\nwill consume virtual address space. MMUs implement only\\naddress validation , not pointer safety : a sufﬁciently large over-\\nﬂow may miss the guard page and write to another allocation.\\nMMU isolation can also be used for application compart-\\nmentalization , such as in the Chromium web browser where\\ntabs run in separate processes to improve robustness and se-\\ncurity. MMU process isolation proves expensive due to TLB\\ncapacity limits that are exacerbated by aliasing between shared\\npages. As a result, applications limit use of sandboxes, thus\\nreducing isolation in favor of performance [33].\\nCHERI inherits all the beneﬁts of the MMU and adds capa-\\nbility protection for principled ﬁne-grained protection within\\nan address space. A key virtue of the MMU as an address\\nvalidation approach is centralized management, which simpli-\\nﬁes address-space revocation, a classic weakness of capabil-\\nity machines. While CHERI does not accelerate revocation\\nof pointers that use the capability mechanism, the operating\\nsystem can manipulate mappings of the underlying pages to\\nenforce revocation. To facilitate this, CHERI extends page ta-\\nble entries with bits to to authorize capability loads and stores.\\nThis also allows the OS to implement shared memory between\\nprocesses that cannot act as a channel for passing capabilities.6.2. Mondrian memory protection\\nMondrian memory protection is a model that allows ﬁne-\\ngrained memory protection to be layered on top of page-\\nbased virtual memory, to facilitate multiple protection do-\\nmains [ 45]. The conventional page table is supplemented\\nby word-granularity in-memory protection tables that contain\\npermissions managed by the supervisor. These tables popu-\\nlate a Protection Look-aside Buffer (PLB) analogous to the\\nTLB in the MMU. In addition, a set of sidecar registers are\\npaired with general-purpose registers to reduce PLB pressure.\\nNo userspace ISA changes are required to support Mondrian,\\nwhich ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 906: ('to be layered on top of page-\\nbased virtual memory, to facilitate multiple protection do-\\nmains [ 45]. The conventional page table is supplemented\\nby word-granularity in-memory protection tables that contain\\npermissions managed by the supervisor. These tables popu-\\nlate a Protection Look-aside Buffer (PLB) analogous to the\\nTLB in the MMU. In addition, a set of sidecar registers are\\npaired with general-purpose registers to reduce PLB pressure.\\nNo userspace ISA changes are required to support Mondrian,\\nwhich enhances incremental deployment.\\nMondrian relies on supervisor mode to maintain its pro-\\ntection table, and thus incurs a domain switch for each allo-\\ncation and free event. At the time Mondrian was evaluated,\\nsuch domain switches would have been common already due\\nto invocations of sbrk() ormmap() system calls; however,\\nuserspace allocators now aggressively cache memory in order\\nto amortize domain switches and lock contention. Reintroduc-\\ning domain switches for Mondrian would signiﬁcantly impair\\nsegmentation scalability. In contrast, CHERI does not require\\nsystem calls to create new segments.\\nAs with an MMU, Mondrian provides address validation\\nrather than pointer validation (albeit at much ﬁner granular-\\nity). Thus, all allocations must be padded to introduce guard\\nregions, which raises similar concerns to MMU guard pages.\\nSmaller pads are possible than with pages, while reducing\\nthe threshold at which overﬂows can be detected. This pre-\\nvents Mondrian from providing effective protection for sub-\\nallocations such as array entries or individual stack frames,\\nand limits its usefulness for ﬁne-grained protection. This is\\nparticularly a concern today when many classes of exploitable\\nsecurity vulnerabilities are premised on overﬂows with at-\\ntacker control over inputs to arithmetic. At somewhat greater\\ncost to ISA-level compatibility, CHERI provides pointer safety\\nsuitable for bounds checking on densely packed (and divisible)\\nmemory locations.\\nProtection-domain scalability in Mondrian is limited: each\\ndomain requ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 907: ('ns such as array entries or individual stack frames,\\nand limits its usefulness for ﬁne-grained protection. This is\\nparticularly a concern today when many classes of exploitable\\nsecurity vulnerabilities are premised on overﬂows with at-\\ntacker control over inputs to arithmetic. At somewhat greater\\ncost to ISA-level compatibility, CHERI provides pointer safety\\nsuitable for bounds checking on densely packed (and divisible)\\nmemory locations.\\nProtection-domain scalability in Mondrian is limited: each\\ndomain requires its own complete protection table, each with\\nsubstantial memory and initialization expense. In CHERI,\\nuserspace protection does not involve tables. Instead, pro-\\ntection information is embedded in pointers, and protection\\ndomains are inﬁnitely scalable and deﬁned only by the set of\\ncapability pointers reachable by the current thread.\\n6.3. Hardbound\\nHardbound [ 12] is a hardware-assisted fat-pointer model\\ngrounded in software bounds-checking research. Unlike the\\nMMU and Mondrian, Hardbound provides pointer safety, not\\njust address validation, and is able to enforce sub-allocations\\nand stack variables. Hardbound maintains a shadow table of\\nbase andbounds values for each pointer-aligned virtual mem-\\nory location, and another table of tagbits to identify pointers.\\nMemory bounds are initialized by a modiﬁed memory alloca-\\ntor for heap objects, and ideally also by a modiﬁed compiler\\nfor stack and global objects. The Hardbound simulated proces-\\nsor propagates bounds into the shadow table and via registers,\\nand veriﬁes bounds when pointers are dereferenced. Libraries\\nand applications that are not recompiled to assign bounds to\\npointers will experience less mitigation. Interestingly, Hard-\\nbound does not provide permission bits necessary to enforce\\ncertain references such as const read-only.\\nHardbound, the M-Machine, and CHERI rely on tags to\\nrobustly distinguish pointers from other data in memory. How-\\never, Hardbound fat pointers are forgeable: the setbound in-\\nstruction allows arbitrary bounds, and the tables ar', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 908: ('veriﬁes bounds when pointers are dereferenced. Libraries\\nand applications that are not recompiled to assign bounds to\\npointers will experience less mitigation. Interestingly, Hard-\\nbound does not provide permission bits necessary to enforce\\ncertain references such as const read-only.\\nHardbound, the M-Machine, and CHERI rely on tags to\\nrobustly distinguish pointers from other data in memory. How-\\never, Hardbound fat pointers are forgeable: the setbound in-\\nstruction allows arbitrary bounds, and the tables are accessible\\nvia virtual memory. As a result, unlike the M-Machine and\\nCHERI, Hardbound pointers do not constitute a protection\\ndomain. Hardbound is also a CISC design that proposes a mi-\\ncrocode implementation, and requires transactional memory\\nto write to three table entries atomically.\\nAs with Mondrian and CHERI, Hardbound is concerned\\nwith incremental adoption. Hardbound executables can run on\\nlegacy hardware by careful use of NOP opcodes, and ABIs\\nare maintained by retaining native pointer size.\\nHardbound performance is limited by TLB overhead (due\\nto sparse table access), and by memory overhead (due to in-\\nﬂated pointers). For example, a single memory instruction\\nin Hardbound might experience two additional TLB misses\\nfor the tag and bound tables, compared to the same access in\\nCHERI. To mitigate these, Hardbound relies on fat-pointer\\ncompression, and wherever possible stores bounds within the\\ntag or in the user pointer. We observe that unused pointer\\nbits are not always available, because some language runtimes\\n(such as Java, JavaScript, and Objective-C) use these bits for\\ntheir own optimizations.\\n6.4. iMPX\\nIntel’s recently announced Memory Protection Exten-\\nsions (iMPX) [ 17] describe additions to the x86 ISA to pro-\\nvide hardware-assisted bounds checking. At present, Intel hasnot shipped a hardware implementation of iMPX, although\\na simulator and compiler extensions are available. As with\\nHardbound, bounds information can be stored in a table within\\na process’s virtual address space. There are several ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 909: (' runtimes\\n(such as Java, JavaScript, and Objective-C) use these bits for\\ntheir own optimizations.\\n6.4. iMPX\\nIntel’s recently announced Memory Protection Exten-\\nsions (iMPX) [ 17] describe additions to the x86 ISA to pro-\\nvide hardware-assisted bounds checking. At present, Intel hasnot shipped a hardware implementation of iMPX, although\\na simulator and compiler extensions are available. As with\\nHardbound, bounds information can be stored in a table within\\na process’s virtual address space. There are several important\\ndifferences, however:\\n\\x0fBounds are not automatically propagated, but are explicitly\\nloaded and stored into a new register set by instructions.\\n\\x0fBounds can originate in architecturally supported shadow\\ntables, but also in software-deﬁned locations (e.g., stored\\nadjacent to the pointer itself).\\n\\x0fRather than explicit tags in a second table, iMPX includes\\nthe original pointer value in the bounds-table entry. If the\\nbounds are loaded against a pointer of a different value, the\\nbounds will be ignored. This preserves compatibility with\\nlegacy code which may not update bounds.\\n\\x0fBounds checking is performed using explicit instructions.\\n\\x0fThere is no support for pointer compression. Each 64-bit\\npointer consumes 320 bits: the original pointer along with\\n256 bits of metadata including base, bounds, the expected\\npointer value, and 64 reserved bits.\\n\\x0fiMPX uses a hierarchical protection table.\\nWithout Hardbound’s pointer compression, iMPX experi-\\nences signiﬁcant memory overheads, even compared to 256-bit\\nCHERI capabilities. However, support for storing bounds in ar-\\nbitrary addresses enables a traditional, consecutive fat-pointer\\nlayout, which has greater locality. As with Hardbound, iMPX\\ndoes not support permission bits, although reserved space in\\nthe shadow table might be used for this in the future.\\niMPX strongly emphasizes compatibility. As with Hard-\\nbound, iMPX instructions decode as NOPs in older ISAs, and\\nwill be ignored by older processors. Its ABI will reset bounds\\nregisters for iMPX-unaware code for compat', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 910: ('bilities. However, support for storing bounds in ar-\\nbitrary addresses enables a traditional, consecutive fat-pointer\\nlayout, which has greater locality. As with Hardbound, iMPX\\ndoes not support permission bits, although reserved space in\\nthe shadow table might be used for this in the future.\\niMPX strongly emphasizes compatibility. As with Hard-\\nbound, iMPX instructions decode as NOPs in older ISAs, and\\nwill be ignored by older processors. Its ABI will reset bounds\\nregisters for iMPX-unaware code for compatibility. iMPX’s\\ntable mode has greater binary compatibility than CHERI as\\npointer sizes remain the same – but hinders safety and ef-\\nﬁciency. As with Hardbound, portions of the pointer may\\nbe stored in different cache lines, and require transactional\\nmemory to preserve atomicity. If atomicity is not maintained,\\niMPX fails open. If multiple threads interfere such that pointer\\nand table entries become inconsistent, anymemory accesses\\nfor the pointer are silently allowed.\\n6.5. M-Machine\\nThe M-Machine [ 5] is a 64-bit tagged-memory capability sys-\\ntem design using guarded pointers to implement ﬁne-grained\\nmemory protection for pointer safety. M-Machine pointers\\nare unforgeable. They deﬁne a protection domain within a\\nsingle address space, and protection-domain switching is sup-\\nported. The M-Machine implementation depends on a su-\\npervisor mode for pointer creation and manipulation, though\\nthe authors propose guarded user-mode instructions. CHERI\\ndiffers from the M-Machine in the following ways:\\n\\x0fThe M-Machine uses an MMU only for paging support,\\nwhereas CHERI uses an MMU to support multiple address\\nspaces (processes), and uses capabilities for protection and\\ndomain switching within each address space.\\n\\x0fThe M-Machine provides a pointer compression scheme\\nthat reduces fat pointers to 64 bits at the cost of granu-\\nlarity: only power-of-two aligned and sized segments are\\nsupported. This reduces memory and cache footprint, at the\\ncost of granularity and adoptability; padding is required for\\ncommon structures that break', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 911: ('es an MMU only for paging support,\\nwhereas CHERI uses an MMU to support multiple address\\nspaces (processes), and uses capabilities for protection and\\ndomain switching within each address space.\\n\\x0fThe M-Machine provides a pointer compression scheme\\nthat reduces fat pointers to 64 bits at the cost of granu-\\nlarity: only power-of-two aligned and sized segments are\\nsupported. This reduces memory and cache footprint, at the\\ncost of granularity and adoptability; padding is required for\\ncommon structures that break binary layouts.\\n\\x0fCHERI provides explicit pointer/capability conversions and\\nsandboxing to support (and conﬁne) legacy code.\\n\\x0fCHERI allows capability manipulation in usermode.\\nThe M-Machine is an efﬁcient capability-based addressing\\nimplementation, but almost entirely sacriﬁces compatibility\\nwith current software designs. CHERI adopts similar design el-\\nements, but with stronger focus on compatibility, adoptability,\\nand efﬁcient compiler manipulation of capabilities.\\n7. Limit study\\nProtection schemes vary widely in functionality and perfor-\\nmance. To understand performance tradeoffs, we performed a\\nsimulation-based limit study on pointer-intensive benchmarks.\\nThe study measured instruction rate, memory trafﬁc overhead,\\nsystem-call rate, and memory storage overhead (Figure 3).\\nWe compared 256-bit CHERI with six models: the Mondrian\\nmodel; two variations on iMPX (ABI-preserving look-aside\\ntables, compiler-managed fat pointers); software fat pointers;\\nHardbound; and the M-Machine. We also added a 128-bit\\nCHERI variant: 256-bit capabilities allow ﬂexibility in experi-\\nmentation, but we would expect a production implementation\\nto use a smaller size. We adapted each model to 64-bit MIPS:\\nMondrian We extend Mondrian to a 40-bit virtual address\\nspace, and simulate its vector-table model with indices to\\nthe ﬁrst- and mid-level tables stretched to 14 bits. Records\\nare extended to 64 bits and hold permissions for 16 nodes\\nrather than 8, giving ﬁner granularity. We assume a hardware\\nread of the table but simulate a softwar', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 912: ('ariant: 256-bit capabilities allow ﬂexibility in experi-\\nmentation, but we would expect a production implementation\\nto use a smaller size. We adapted each model to 64-bit MIPS:\\nMondrian We extend Mondrian to a 40-bit virtual address\\nspace, and simulate its vector-table model with indices to\\nthe ﬁrst- and mid-level tables stretched to 14 bits. Records\\nare extended to 64 bits and hold permissions for 16 nodes\\nrather than 8, giving ﬁner granularity. We assume a hardware\\nread of the table but simulate a software table ﬁll based on a\\nminimal table ﬁll algorithm in C.\\niMPX Fat-pointer and table-based models translate directly.\\nSoft fat pointers Fat-pointer loads, stores, and bounds\\nchecks use general-purpose instructions.\\nHardbound We extend base and bounds information to 64\\nbits. We retain a direct offset for the bounds table and model\\na 128-bit table access for every load (or store) of an incom-\\npressible pointer. Compressed pointers encode up to 1024\\nbytes of length in 8 unused bits in the pointer and require\\nlength to be 4-byte word aligned. We model a 2-bit tag for\\neach 64-bit word stored in a separate table in memory.\\nWe used the Olden benchmarks [ 34], a suite developed for\\ndistributed shared-memory research that has become popular\\nin bounds-checking research due to its focus on pointer-based\\ndata structures. The benchmarks use a range of data structures,\\nmemory footprints, and workloads to exercise various pointer\\naccess patterns and densities.\\nTo measure performance for each approach, we recorded\\ncomplete instruction traces of Olden benchmarks on ourMondrian MPX MPX (FP) Software FP Hardbound M-Machine CHERI 128b CHERI\\n0100200300400Overhead [%]Virtual memory footprint (pages)\\n0200400Overhead [%]Memory I/O (bytes)\\n050100Overhead [%]Memory references (count)\\n05101520Overhead [%]Total instructions — optimistic (count)\\nMondrianMPX\\nMPX (FP)Software FPHardbound M-MachineCHERI\\n128b CHERI050100Overhead [%]Total instructions — pessimistic (count)\\nFigure 3: Simulated overheads of Olden benchmarks\\nbaseline MIPS implement', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 913: ('struction traces of Olden benchmarks on ourMondrian MPX MPX (FP) Software FP Hardbound M-Machine CHERI 128b CHERI\\n0100200300400Overhead [%]Virtual memory footprint (pages)\\n0200400Overhead [%]Memory I/O (bytes)\\n050100Overhead [%]Memory references (count)\\n05101520Overhead [%]Total instructions — optimistic (count)\\nMondrianMPX\\nMPX (FP)Software FPHardbound M-MachineCHERI\\n128b CHERI050100Overhead [%]Total instructions — pessimistic (count)\\nFigure 3: Simulated overheads of Olden benchmarks\\nbaseline MIPS implementation in hardware. We then ex-\\ntracted information relevant to bounds checking: C memory-\\nmanagement functions such as malloc() andfree() , and all\\nmemory loads and stores. This allowed us to track accesses to\\nall objects in memory-mapped segments (globals), heap and\\nstack. We simulated extra memory accesses, instructions, TLB\\nand cache behavior, and system calls that would result from\\nideal implementations of each model. Performance results are\\npresented as normalized overhead against the baseline.\\nThe number of virtual memory pages touched by the process\\nreﬂects both TLB and cache pressure. Caches optimize for\\nlocality of reference so cache performance should degrade as\\nthe range of pages increases, even if the total trafﬁc remains\\nconstant. The iMPX case has the highest page overhead. The\\niMPX table contains more than 4 pages for each page of\\nmemory containing pointers, maintaining 256 bits in the leaf\\nnodes for each 64-bit memory location. The Hardbound model\\nuses a simpler table structure and 128 bits of metadata per\\npointer, but must also maintain a tag table. Interestingly, the\\nM-Machine performs poorly by the page metric due to padding\\nallocations to powers of two. CHERI and the other simple fat-\\npointer approaches have comparatively small page overhead,\\nas the additional data is packed into existing data and the larger\\nstructures will only sometimes spill onto another page. These\\nwill use more cache, but not signiﬁcantly more TLB entries.\\nThe simplest memory metric is the total number of bytes\\nread or ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 914: (' metadata per\\npointer, but must also maintain a tag table. Interestingly, the\\nM-Machine performs poorly by the page metric due to padding\\nallocations to powers of two. CHERI and the other simple fat-\\npointer approaches have comparatively small page overhead,\\nas the additional data is packed into existing data and the larger\\nstructures will only sometimes spill onto another page. These\\nwill use more cache, but not signiﬁcantly more TLB entries.\\nThe simplest memory metric is the total number of bytes\\nread or written. As expected, the table walk in iMPX requires\\nsigniﬁcantly more memory accesses than any other scheme.\\nCHERI generates more trafﬁc on these pointer-heavy bench-\\nmarks due to its larger pointer size; however, the proposed\\n128-bit variant is competitive with most of the other models.\\nMondrian uses the smallest amount of memory trafﬁc, as it\\ndoes not provide per-pointer bounds.\\nThe number of individual loads and stores is presented sep-\\narately from the number of bytes stored, as many structures\\nin the CPU scale with the number of independent transac-\\ntions rather than with the total size of transactions. CHERI,\\nHardbound, and the M-Machine all do well on this metric. In\\nthe case of CHERI and the M-Machine, where metadata is\\nstored inline, they have negligible increases in this category.\\nHardbound does well because it succeeds in compressing a\\nlarge proportion of the pointers. Mondrian has a similarly low\\noverhead because it does not associate protection with pointers\\nand therefore does not cache larger regions of protection.\\nPerhaps the simplest form of overhead is increased instruc-\\ntion count; this is not an accurate predictor of performance\\nin superscalar implementations, but does impact instruction\\ncache usage. We show optimistic and pessimistic instruction\\ncount overheads. The optimistic model assumes bounds can\\nbe checked once on every pointer load; the pessimistic model\\nassumes that bounds must be checked on every pointer derefer-\\nence. These are identical for hardware fat-pointer approaches,\\nwhere', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 915: ('regions of protection.\\nPerhaps the simplest form of overhead is increased instruc-\\ntion count; this is not an accurate predictor of performance\\nin superscalar implementations, but does impact instruction\\ncache usage. We show optimistic and pessimistic instruction\\ncount overheads. The optimistic model assumes bounds can\\nbe checked once on every pointer load; the pessimistic model\\nassumes that bounds must be checked on every pointer derefer-\\nence. These are identical for hardware fat-pointer approaches,\\nwhere all dereferences are checked implicitly and the only ad-\\nditional instructions are to set the bounds on new allocations.\\nCHERI and Hardbound require a single instruction; Mondrian\\nrequires a system call to modify the protection table. Explicit\\nbounds loads and checks in iMPX and the software fat-pointer\\napproaches have the most overhead.\\nThe CHERI model proves competitive in all major metrics\\n(especially in its 128-bit variant), indicating that there are no\\nmajor limitations to our approach.\\n8. Performance measurement\\nIn addition to our limit study, we also measured the perfor-\\nmance of four of the Olden benchmarks running on CHERI\\nimplemented in FPGA. We compiled each benchmark with\\nconventional MIPS code generation, MIPS code with auto-\\nmatically generated bounds checks inserted by CCured [ 28],\\nand CHERI memory safety driven by manual insertion of\\n__capability annotations. Each was compiled with our mod-\\niﬁed version of LLVM, and run as a userspace program onFreeBSD 10 with CHERI extensions.\\nCCured was chosen as a best-of-breed software bounds-\\nchecking implementation as it elides bounds checks where\\nit can statically prove them unnecessary. CHERI will al-\\nways enforce bounds dynamically in hardware. In contrast\\nto CHERI, the CCured version is not thread-safe due to non-\\natomic pointer access (as noted in its documentation).\\nThe four benchmarks were bisort ,mst,treeadd and\\nperimeter . To enable comparison, we ran the benchmarks\\nwith the same parameters as used in the evaluation of Hard-\\nbound: bisort 250000', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 916: ('osen as a best-of-breed software bounds-\\nchecking implementation as it elides bounds checks where\\nit can statically prove them unnecessary. CHERI will al-\\nways enforce bounds dynamically in hardware. In contrast\\nto CHERI, the CCured version is not thread-safe due to non-\\natomic pointer access (as noted in its documentation).\\nThe four benchmarks were bisort ,mst,treeadd and\\nperimeter . To enable comparison, we ran the benchmarks\\nwith the same parameters as used in the evaluation of Hard-\\nbound: bisort 250000 0 ,mst 1024 0 ,treeadd 21 1 0\\nandperimeter 12 0 . Figure 4 shows execution-time over-\\nhead relative to the unsafe MIPS baseline, with total time\\ndecomposed into allocation and computation phases.\\nIn the bisort benchmark, CHERI experiences a very small\\noverhead while allocating memory for each node in the tree.\\nCHERI requires one extra instruction for each allocation to set\\nbounds, while the software-enforcement case is signiﬁcantly\\nmore complex. The sorting phase involves traversing the tree\\nand swapping pointers. This phase is dominated by cache miss\\ntime. Unsafe nodes are 24-bytes, which ﬁt more efﬁciently\\nin our 32-byte cache lines than CHERI’s 96-byte nodes. Due\\nto the similar data structure used, treeadd has comparable\\nperformance proﬁle to bisort .\\nThemstbenchmark shows a different access pattern with\\ntwo contiguous allocations to build the graph and a linear read\\nto compute the minimum spanning tree. When building the\\ngraph, the total run time is dominated by the hash calculations\\nthat are the same in both cases. When computing the minimum\\nspanning tree, as with bisort , the dominant factor is cache\\nmisses. CHERI experiences more cache misses because of\\nlarge capabilities, though this linear case would be alleviated\\nwith cache prefetching.\\nTheperimeter benchmark shows a small performance\\nimprovement during the memory allocation phase when capa-\\nbilities are used. This is probably because the slowdown due\\nto capabilities is smaller than the performance variation due\\nto other effects, such as allocation a', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 917: (' both cases. When computing the minimum\\nspanning tree, as with bisort , the dominant factor is cache\\nmisses. CHERI experiences more cache misses because of\\nlarge capabilities, though this linear case would be alleviated\\nwith cache prefetching.\\nTheperimeter benchmark shows a small performance\\nimprovement during the memory allocation phase when capa-\\nbilities are used. This is probably because the slowdown due\\nto capabilities is smaller than the performance variation due\\nto other effects, such as allocation alignment in malloc .\\nCHERI outperforms CCured substantially in all conﬁgu-\\nrations. In bisort ,treeadd , and perimeter , this is due\\nto improvements in both allocation and computation. In mst,\\nCCured is effective in eliding inner-loop bounds checks during\\ncomputation, achieving greater cache efﬁciency by avoiding\\nfat-pointer overhead. Similar elision could also be applied to\\nCHERI to selectively utilize capabilities.\\nFigure 5 shows the percentage slowdown of CHERI relative\\nto MIPS code for increasing data-set sizes. For very small\\nsets, overhead is negligible. As working set-size increases,\\ncapability cache pressure grows faster than for unprotected\\ncode. This leads to visible ‘steps’ as the 16KB L1 cache,\\n64KB L2 cache, and TLB covering 1MB overﬂow.\\nOur benchmarks are consistent with those predicted by the\\nlimit study: MIPS and CHERI execution times remain very\\nclose when data is cached, but performance degrades where\\nBisort MST\\nTreeaddPerimeterBisort MST\\nTreeaddPerimeter050100150\\n0Overhead [%]Allocation\\nComputation\\nTotal\\nCCured CHERI\\nFigure 4: Benchmark results comparing unmodiﬁed MIPS\\ncode to software and hardware enforcement\\n4 8 16 32 64 128 256 512 102401020Overhead [%]Treeadd Bisort\\nPerimeter MST\\nFigure 5: Slowdown for CHERI at different heap sizes (KB)\\npointer-size is dominant. These results reconﬁrm that CHERI\\nwill beneﬁt from capability compression, and perhaps also\\nelision techniques, although performance is acceptable even\\nin pointer-heavy benchmarks.\\n9. Area and speed cost\\nCHERI capability support a', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 918: ('putation\\nTotal\\nCCured CHERI\\nFigure 4: Benchmark results comparing unmodiﬁed MIPS\\ncode to software and hardware enforcement\\n4 8 16 32 64 128 256 512 102401020Overhead [%]Treeadd Bisort\\nPerimeter MST\\nFigure 5: Slowdown for CHERI at different heap sizes (KB)\\npointer-size is dominant. These results reconﬁrm that CHERI\\nwill beneﬁt from capability compression, and perhaps also\\nelision techniques, although performance is acceptable even\\nin pointer-heavy benchmarks.\\n9. Area and speed cost\\nCHERI capability support adds both area and speed cost to our\\nFPGA soft core. A synthesis of CHERI, excluding peripherals,\\nconsumes 32% more logic elements than BERI. This over-\\nhead includes not only the capability coprocessor and the tag\\nmanager, but also logic in the main pipeline to allow loading\\nand storing 256-bit capabilities into the data cache. Figure 6\\nshows a synthesis of CHERI broken into components to in-\\ndicate area cost by module. A commercial implementation\\nwould optimize capability size and may have a wide vector\\npath to memory that might also be used for the capabilities.\\nCapability support also affects the timing of our implemen-\\ntation due to wider paths and increased complexity in the\\npipeline; our current implementation reduces clock speed by\\n8.1%, as BERI achieves a maximum frequency of 110.84 MHz,\\nwhile the capability coprocessor reaches 102.54 MHz. Little\\nattempt has been made to improve the timing of either case be-\\nyond 100MHz. An implementation that expects less-frequent\\ncapability updates could decouple capability operations from\\nthe main pipeline at a performance cost.\\n10. Limitations\\nThe CHERI approach is not without limitations, many of\\nwhich we hope to address in future work. Perhaps most im-\\nBERI Pipeline18.6%Floating Point31.8%Capability Unit14.7%Tag Cache4.0%CPro0 & TLB7.8%Level 2 Cache6.6%L1 Data Cache4.6%L1 Instr. Cache2.4%Debug4.7%Multiply & Divide2.6%Branch Predictor2.3%Figure 6: CHERI layout on FPGA\\nportantly, CHERI’s protection features require adapting and\\nrecompiling application code. Despite ', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 919: ('pability operations from\\nthe main pipeline at a performance cost.\\n10. Limitations\\nThe CHERI approach is not without limitations, many of\\nwhich we hope to address in future work. Perhaps most im-\\nBERI Pipeline18.6%Floating Point31.8%Capability Unit14.7%Tag Cache4.0%CPro0 & TLB7.8%Level 2 Cache6.6%L1 Data Cache4.6%L1 Instr. Cache2.4%Debug4.7%Multiply & Divide2.6%Branch Predictor2.3%Figure 6: CHERI layout on FPGA\\nportantly, CHERI’s protection features require adapting and\\nrecompiling application code. Despite capability-qualiﬁed\\npointers supporting all operations permitted by the C standard\\nwith the exception of subtraction, practical C implementations\\ntolerate undeﬁned pointer behaviors that CHERI capabilities\\nwill not. The Olden suite, for example, was trivially adapted to\\nCHERI by simply tagging pointers with __capability . Some\\napplications, however, routinely construct pointers that extend\\nsigniﬁcantly beyond the end of valid buffers (disallowed by\\nthe C speciﬁcation), which will trigger exceptions on CHERI.\\nIn performing a more complex adaptation of tcpdump to use\\nCHERI capabilities, we encountered many such uses — some\\nof which led to undesirable (and potentially exploitable) out-\\nof-bounds memory accesses with conventional compilation.\\nUnadapted MIPS code with ambient authority in the same\\naddress space as CHERI-adapted code leaves adapted code\\nvulnerable to buggy or exploited MIPS code. This can be\\nmitigated by deploying explicit sandboxing of unadapted code,\\nat some cost to complexity and performance. In future work,\\nwe hope to explore techniques for automated adaptation of\\napplication code and for sandboxing of unmodiﬁed code.\\n11. Future work\\nOur larger research effort has now just begun. We intend\\nto explore compiler and system ramiﬁcations of the current\\nhardware extensions, and also to explore the utility of further\\nextensions. We expect to be able to demonstrate efﬁcient\\nsandboxing using CHERI protection primitives, and explore\\nsoftware models and scalability.\\nWe are experimenting with several mechani', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 920: (' future work,\\nwe hope to explore techniques for automated adaptation of\\napplication code and for sandboxing of unmodiﬁed code.\\n11. Future work\\nOur larger research effort has now just begun. We intend\\nto explore compiler and system ramiﬁcations of the current\\nhardware extensions, and also to explore the utility of further\\nextensions. We expect to be able to demonstrate efﬁcient\\nsandboxing using CHERI protection primitives, and explore\\nsoftware models and scalability.\\nWe are experimenting with several mechanisms for pro-\\ntected domain crossing . Our current prototype traps to the\\nOS to emulate a protected procedure-call instruction, but we\\nintend to provide a hardware (or hardware-assisted) implemen-\\ntation as the software model matures.\\nOur current work provides spatial memory safety. The pres-\\nence of tagged memory also provides opportunities to enforce\\ntemporal safety. Tags allow us to identify all references, so\\nwe can provide accurate garbage collection to low-level lan-\\nguages such as C. Possibilities include a non-reuse allocator\\n(to eliminate most dangling pointer errors) that periodically\\nruns a tracing pass to identify reusable address space.\\nDistinguishing integers and pointers in the memory hierar-\\nchy also enables cache hinting for pre-fetching or coherency.\\nWe are also investigating the use of the capability mecha-\\nnism for interactions between coprocessors (e.g., GPUs) and\\nuserspace code, without requiring operating-system mediation.\\n12. Related work\\nStrong memory protection has long been sought for com-\\nputer systems [ 10,35]. Initially, segmentation (and capabil-\\nities) were developed to protect and relocate program struc-\\ntures [ 11,23]. Fixed-size paging, however, eventually became\\ndominant to allow operating systems to efﬁciently manage\\nmultiple programs on the same machine [ 14,32]. For exam-\\nple, Intel implemented ﬁne-grained segmentation in the 80286\\nbut it was eventually dropped in x86-64 [ 8]. Nevertheless,\\ncomputers that optimized for protecting individual programs\\noften support segmentati', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 921: ('r com-\\nputer systems [ 10,35]. Initially, segmentation (and capabil-\\nities) were developed to protect and relocate program struc-\\ntures [ 11,23]. Fixed-size paging, however, eventually became\\ndominant to allow operating systems to efﬁciently manage\\nmultiple programs on the same machine [ 14,32]. For exam-\\nple, Intel implemented ﬁne-grained segmentation in the 80286\\nbut it was eventually dropped in x86-64 [ 8]. Nevertheless,\\ncomputers that optimized for protecting individual programs\\noften support segmentation, for example the Burroughs large\\nsystems [25, 43], and the modern ARM Cortex R cores [15].\\nFor systems without hardware segmentation in user space,\\nprogrammers turned to statically enforced memory protec-\\ntion [ 6] and/or run-time checks [ 9]. Managed-language virtual\\nmachines automate these mechanisms to enforce an object\\nmemory model [ 16] and incur signiﬁcant overhead as a re-\\nsult [ 31]. Other attempts have been made to provide bounds\\nchecking in software for C [ 2,37,38], but with prohibitive\\noverhead for a performance-oriented language. To achieve\\ncoarse-grained software sandboxing of program components,\\nefforts have been made to use process separation [ 36,40], dis-\\njoint TLB sets in a shared process, static analysis of specially\\ncompiled binaries [ 24,39,48], and delegation of hypervisor\\nsupport to userspace [3].\\nAnother approach is memory protection in user-space code\\nfor managed languages [ 44,47] that implements certain as-\\npects of the virtual machine’s memory model in the hard-\\nware. Such approaches are less applicable when computers\\nrun software written in multiple languages, with different\\nmemory models. Commercial approaches, such as ARM’s\\nJazelle and Thumb-2EE, have provided bounds-checking in-\\nstructions aimed at efﬁciently implementing languages such\\nas Java without a specialized Java processor.\\n13. Availability\\nThe CHERI ISA reference is available as a technical re-\\nport [ 41]. In the interests of experimental reproducibility,\\nwe have open sourced our BERI prototype and software stack:\\nht', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 922: ('oaches are less applicable when computers\\nrun software written in multiple languages, with different\\nmemory models. Commercial approaches, such as ARM’s\\nJazelle and Thumb-2EE, have provided bounds-checking in-\\nstructions aimed at efﬁciently implementing languages such\\nas Java without a specialized Java processor.\\n13. Availability\\nThe CHERI ISA reference is available as a technical re-\\nport [ 41]. In the interests of experimental reproducibility,\\nwe have open sourced our BERI prototype and software stack:\\nhttp://www.bericpu.org/\\nhttp://www.chericpu.org/\\nWe hope that this will not only encourage experimentation\\nwith capability-based techniques such as CHERI, but also\\nsupport further combined hardware-software research.\\n14. Conclusions\\nFine-grained memory protection is vital for increasing security\\nand robustness in contemporary software. To date, only coarse-\\ngrained MMU-based protection models have had wide impacton computer systems, despite many historic proposals for capa-\\nbility systems and more recent proposals for protection tables\\nand fat pointers. We have hybridized a capability model with\\nan MMU-based design to demonstrate that a tagged capability\\nsystem can provide efﬁcient ﬁne-grained protection as well\\nas compatibility with current source-code and binary corpora.\\nIncremental adoption is critical, as we live in a world with\\nlarge established software codebases. Mandatory rewriting –\\nor even recompiling – is no longer acceptable for deployment.\\nEarlier capability systems have seen limited adoption, al-\\nthough they largely predated widespread Internet connectiv-\\nity and security threats. More recently, processor vendors\\nhave introduced new security features (i.e., TrustZone [ 1] and\\niMPX [ 17]), which might suggest that there could soon be a\\nsufﬁcient market for capability-based addressing. Hybrid soft-\\nware capability systems (e.g., Capsicum [ 40]) have allowed\\ncapabilities (also neglected in the software community) to be\\nadopted on a larger scale, due to improved legacy-code com-\\npatibility. Similarly, a', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 923: ('though they largely predated widespread Internet connectiv-\\nity and security threats. More recently, processor vendors\\nhave introduced new security features (i.e., TrustZone [ 1] and\\niMPX [ 17]), which might suggest that there could soon be a\\nsufﬁcient market for capability-based addressing. Hybrid soft-\\nware capability systems (e.g., Capsicum [ 40]) have allowed\\ncapabilities (also neglected in the software community) to be\\nadopted on a larger scale, due to improved legacy-code com-\\npatibility. Similarly, a key contribution of the CHERI approach\\nis adoptability that is incremental, rather than ground-up.\\nOur feature comparison and limit study illustrate how\\nprotection-model design choices made by several published\\nschemes can trade off among protection, performance, and\\ncompatibility. They demonstrate that CHERI performs com-\\npetitively with all schemes while often providing stronger\\nprotection, and that capability-size optimizations would fur-\\nther improve CHERI performance. We also demonstrate that\\nincremental deployment is possible and that parts of a program\\ncan beneﬁt from complete spatial safety – without having to\\nrewrite or recompile entire codebases.\\nCHERI exempliﬁes the RISC philosophy of creating sim-\\nple instructions that are designed to be useful to compilers.\\nAs a result, implementation complexity is sufﬁciently low\\nfor consideration in modern processors, and performance is\\nnoticeably faster than weaker enforcement in software.\\n14.1. Acknowledgments\\nWe thank our colleagues – especially Ross Anderson, Gregory\\nChadwick, Nirav Dave, Khilan Gudka, Wojciech Koszek, A\\nTheodore Markettos, Ed Maste, Andrew W. Moore, Will Mor-\\nland, Prashanth Mundkur, Steven J. Murdoch, Philip Paeps,\\nColin Rothwell, Hassen Saidi, Stacey Son, and Bjoern Zeeb;\\nwe also thank our anonymous reviewers for their feedback.\\nThis work is part of the CTSRD Project that is sponsored by\\nthe Defense Advanced Research Projects Agency (DARPA)\\nand the Air Force Research Laboratory (AFRL), under con-\\ntract FA8750-10-C-0237. The views, opinion', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 924: ('on, Gregory\\nChadwick, Nirav Dave, Khilan Gudka, Wojciech Koszek, A\\nTheodore Markettos, Ed Maste, Andrew W. Moore, Will Mor-\\nland, Prashanth Mundkur, Steven J. Murdoch, Philip Paeps,\\nColin Rothwell, Hassen Saidi, Stacey Son, and Bjoern Zeeb;\\nwe also thank our anonymous reviewers for their feedback.\\nThis work is part of the CTSRD Project that is sponsored by\\nthe Defense Advanced Research Projects Agency (DARPA)\\nand the Air Force Research Laboratory (AFRL), under con-\\ntract FA8750-10-C-0237. The views, opinions, and/or ﬁndings\\ncontained in this paper are those of the authors and should not\\nbe interpreted as representing the ofﬁcial views or policies, ei-\\nther expressed or implied, of the Defense Advanced Research\\nProjects Agency or the Department of Defense. We gratefully\\nacknowledge Google, Inc. for its sponsorship.\\nReferences\\n[1]T. Alves and D. Felton, “ARM TrustZone: Integrated hardware and\\nsoftware security,” Information Quarterly , vol. 3, no. 4, July 2004.\\n[2]T. M. Austin, S. E. Breach, and G. S. Sohi, “Efﬁcient detection of all\\npointer and array access errors,” in Proceedings of the ACM SIGPLAN\\n1994 conference on Programming language design and implementation ,\\nser. PLDI ’94. New York, NY , USA: ACM, 1994, pp. 290–301.\\n[3]A. Belay, A. Bittau, A. Mashtizadeh, D. Terei, D. Mazières, and\\nC. Kozyrakis, “Dune: safe user-level access to privileged CPU features,”\\ninProceedings of the 10th USENIX conference on Operating Systems\\nDesign and Implementation , ser. OSDI’12, 2012, pp. 335–348.\\n[4]Bluespec SystemVerilog Version 3.8 Reference Guide , Bluespec, Inc.,\\nWaltham, MA, November 2004.\\n[5]N. P. Carter, S. W. Keckler, and W. J. Dally, “Hardware support for\\nfast capability-based addressing,” SIGPLAN Not. , vol. 29, no. 11, pp.\\n319–327, Nov. 1994.\\n[6]B. Chess, “Improving computer security using extended static check-\\ning,” in Proceedings of the 2002 Symposium on Security and Privacy .\\nOakland, California: IEEE Computer Society, May 2002, pp. 160–173.\\n[7]R. Childs Jr, J. Crawford, D. House, and R. Noyce, “A Processor\\nFam', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 925: ('ersion 3.8 Reference Guide , Bluespec, Inc.,\\nWaltham, MA, November 2004.\\n[5]N. P. Carter, S. W. Keckler, and W. J. Dally, “Hardware support for\\nfast capability-based addressing,” SIGPLAN Not. , vol. 29, no. 11, pp.\\n319–327, Nov. 1994.\\n[6]B. Chess, “Improving computer security using extended static check-\\ning,” in Proceedings of the 2002 Symposium on Security and Privacy .\\nOakland, California: IEEE Computer Society, May 2002, pp. 160–173.\\n[7]R. Childs Jr, J. Crawford, D. House, and R. Noyce, “A Processor\\nFamily for Personal Computers,” Proceedings of the IEEE , vol. 72,\\nno. 3, pp. 363–376, 1984.\\n[8]S. Cleveland, “x86-64 technology white paper,” Advanced Micro De-\\nvices, Tech. Rep., 02 2002.\\n[9]C. Cowan, F. Wagle, C. Pu, S. Beattie, and J. Walpole, “Buffer over-\\nﬂows: Attacks and defenses for the vulnerability of the decade,” in\\nDARPA Information Survivability Conference and Exposition, 2000.\\nDISCEX’00. Proceedings , vol. 2. IEEE, 2000, pp. 119–129.\\n[10] P. Denning, “Virtual memory,” ACM Computing Surveys (CSUR) ,\\nvol. 2, no. 3, pp. 153–189, 1970.\\n[11] J. B. Dennis and E. C. Van Horn, “Programming semantics for multi-\\nprogrammed computations,” Commun. ACM , vol. 9, no. 3, pp. 143–155,\\n1966.\\n[12] J. Devietti, C. Blundell, M. M. K. Martin, and S. Zdancewic, “Hard-\\nbound: architectural support for spatial safety of the C programming\\nlanguage,” SIGARCH Comput. Archit. News , vol. 36, no. 1, pp. 103–\\n114, Mar. 2008.\\n[13] J. Evans, “A scalable concurrent malloc(3) implementation for\\nFreeBSD,” in BSDCan , 2006.\\n[14] J. Fotheringham, “Dynamic storage allocation in the Atlas computer,\\nincluding an automatic use of a backing store,” Communications of the\\nACM , vol. 4, no. 10, pp. 435–436, 1961.\\n[15] A. Frame and C. Turner, “Introducing new ARM Cortex-R technology\\nfor safe and reliable systems,” ARM, Tech. Rep., 03 2011.\\n[16] J. Gosling and H. McGilton, The Java language environment . Sun\\nMicrosystems Computer Company, 1995, vol. 2550.\\n[17] Intel Plc., “Introduction to Intel R\\r memory protec-\\ntion extensions,” http://software', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 926: ('Fotheringham, “Dynamic storage allocation in the Atlas computer,\\nincluding an automatic use of a backing store,” Communications of the\\nACM , vol. 4, no. 10, pp. 435–436, 1961.\\n[15] A. Frame and C. Turner, “Introducing new ARM Cortex-R technology\\nfor safe and reliable systems,” ARM, Tech. Rep., 03 2011.\\n[16] J. Gosling and H. McGilton, The Java language environment . Sun\\nMicrosystems Computer Company, 1995, vol. 2550.\\n[17] Intel Plc., “Introduction to Intel R\\r memory protec-\\ntion extensions,” http://software.intel.com/en-us/articles/\\nintroduction-to-intel-memory-protection-extensions, July 2013.\\n[18] T. Jim, J. G. Morrisett, D. Grossman, M. W. Hicks, J. Cheney, and\\nY . Wang, “Cyclone: A safe dialect of C,” in ATEC ’02: Proceedings of\\nthe USENIX Annual Technical Conference , 2002, pp. 275–288.\\n[19] G. Klein, J. Andronick, K. Elphinstone, G. Heiser, D. Cock, P. Derrin,\\nD. Elkaduwe, K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell,\\nH. Tuch, and S. Winwood, “seL4: Formal veriﬁcation of an operating-\\nsystem kernel,” Commun. ACM , vol. 53, pp. 107–115, June 2009.\\n[20] A. Kwon, U. Dhawan, J. M. Smith, T. F. Knight, Jr., and A. De-\\nHon, “Low-fat pointers: Compact encoding and efﬁcient gate-level\\nimplementation of fat pointers for spatial safety and capability-based\\nsecurity,” in 20th ACM Conference on Computer and Communications\\nSecurity , November 2013.\\n[21] L. Lam and T. Chiueh, “Checking array bound violation using segmen-\\ntation hardware,” in IEEE International Conference on Dependable\\nSystems and Networks , 2005, pp. 388–397.\\n[22] C. Lattner and V . Adve, “LLVM: A compilation framework for lifelong\\nprogram analysis & transformation,” in Proceedings of the Interna-\\ntional Symposium on Code Generation and Optimization: Feedback-\\ndirected and runtime optimization , ser. CGO ’04, 2004, pp. 75–86.\\n[23] H. M. Levy, Capability-Based Computer Systems . Newton, MA,\\nUSA: Butterworth-Heinemann, 1984.\\n[24] Y . Mao, H. Chen, D. Zhou, X. Wang, N. Zeldovich, and M. F. Kaashoek,\\n“Software fault isolation with API integrity and mult', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 927: ('pp. 388–397.\\n[22] C. Lattner and V . Adve, “LLVM: A compilation framework for lifelong\\nprogram analysis & transformation,” in Proceedings of the Interna-\\ntional Symposium on Code Generation and Optimization: Feedback-\\ndirected and runtime optimization , ser. CGO ’04, 2004, pp. 75–86.\\n[23] H. M. Levy, Capability-Based Computer Systems . Newton, MA,\\nUSA: Butterworth-Heinemann, 1984.\\n[24] Y . Mao, H. Chen, D. Zhou, X. Wang, N. Zeldovich, and M. F. Kaashoek,\\n“Software fault isolation with API integrity and multi-principal mod-\\nules,” in SOSP 2011: Proceedings of the 23rd ACM Symposium on\\nOperating Systems Principles , 2011.[25] A. J. Mayer, “The architecture of the Burroughs B5000: 20 years later\\nand still ahead of the times?” ACM SIGARCH Computer Architecture\\nNews , vol. 10, no. 4, pp. 3–10, 1982.\\n[26] M. K. McKusick and G. V . Neville-Neil, The design and implementa-\\ntion of the FreeBSD operating system . Pearson Education, 2004.\\n[27] J. Navarro, S. Iyer, P. Druschel, and A. L. Cox, “Practical, transparent\\noperating system support for superpages,” in OSDI , 2002.\\n[28] G. C. Necula, S. McPeak, and W. Weimer, “CCured: Type-safe\\nretroﬁtting of legacy code,” in ACM SIGPLAN Notices , vol. 37, no. 1,\\n2002, pp. 128–139.\\n[29] D. A. Patterson and C. H. Sequin, “RISC I: A reduced instruction\\nset VLSI computer,” in Proceedings of the 8th Annual Symposium on\\nComputer Architecture , 1981, pp. 443–457.\\n[30] F. J. Pollack, G. W. Cox, D. W. Hammerstrom, K. C. Kahn, K. K.\\nLai, and J. R. Rattner, “Supporting Ada memory management in the\\niAPX-432,” in ACM SIGARCH Computer Architecture News , vol. 10,\\nno. 2, 1982, pp. 117–131.\\n[31] F. Qian, L. Hendren, and C. Verbrugge, “A comprehensive approach to\\narray bounds check elimination for Java,” in Compiler Construction .\\nSpringer, 2002, pp. 325–341.\\n[32] B. Randell and C. Kuehner, “Dynamic Storage Allocation Systems,”\\nCommunications of the ACM , vol. 11, no. 5, pp. 297–306, 1968.\\n[33] C. Reis and S. D. Gribble, “Isolating web programs in modern browser\\narchitectures,” in EuroSys ’09: Proce', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 928: ('in the\\niAPX-432,” in ACM SIGARCH Computer Architecture News , vol. 10,\\nno. 2, 1982, pp. 117–131.\\n[31] F. Qian, L. Hendren, and C. Verbrugge, “A comprehensive approach to\\narray bounds check elimination for Java,” in Compiler Construction .\\nSpringer, 2002, pp. 325–341.\\n[32] B. Randell and C. Kuehner, “Dynamic Storage Allocation Systems,”\\nCommunications of the ACM , vol. 11, no. 5, pp. 297–306, 1968.\\n[33] C. Reis and S. D. Gribble, “Isolating web programs in modern browser\\narchitectures,” in EuroSys ’09: Proceedings of the 4th ACM European\\nConference on Computer Systems . New York, NY , USA: ACM, 2009,\\npp. 219–232.\\n[34] A. Rogers, M. C. Carlisle, J. H. Reppy, and L. J. Hendren, “Supporting\\ndynamic data structures on distributed-memory machines,” ACM Trans.\\nProgram. Lang. Syst. , vol. 17, no. 2, pp. 233–263, Mar. 1995.\\n[35] J. Saltzer and M. Schroeder, “The protection of information in com-\\nputer systems,” Proceedings of the IEEE , vol. 63, no. 9, pp. 1278–1308,\\nSeptember 1975.\\n[36] M. Schroeder and J. Saltzer, “A hardware architecture for implementing\\nprotection rings,” Communications of the ACM , vol. 15, no. 3, March\\n1972.\\n[37] K. Serebryany, D. Bruening, A. Potapenko, and D. Vyukov, “Address-\\nSanitizer: A fast address sanity checker,” in USENIX ATC , vol. 12,\\n2012.\\n[38] R. Shetty, M. Kharbutli, Y . Solihin, and M. Prvulovic, “Heapmon: a\\nhelper-thread approach to programmable, automatic, and low-overhead\\nmemory bug detection,” IBM J. Res. Dev. , vol. 50, no. 2/3, pp. 261–275,\\nMar. 2006.\\n[39] R. Wahbe, S. Lucco, T. E. Anderson, and S. u. L. Graham, “Efﬁcient\\nsoftware-based fault isolation,” in SOSP ’93: Proceedings of the four-\\nteenth ACM Symposium on Operating Systems Principles , New York,\\nNY , USA, 1993, pp. 203–216.\\n[40] R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway, “Cap-\\nsicum: Practical capabilities for Unix,” in Proceedings of the 19th\\nUSENIX Security Symposium . USENIX, August 2010.\\n[41] R. N. M. Watson, P. G. Neumann, J. Woodruff, J. Anderson,\\nD. Chisnall, B. Davis, B. Laurie, S. W. Moore, S. J', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 929: ('T. E. Anderson, and S. u. L. Graham, “Efﬁcient\\nsoftware-based fault isolation,” in SOSP ’93: Proceedings of the four-\\nteenth ACM Symposium on Operating Systems Principles , New York,\\nNY , USA, 1993, pp. 203–216.\\n[40] R. N. M. Watson, J. Anderson, B. Laurie, and K. Kennaway, “Cap-\\nsicum: Practical capabilities for Unix,” in Proceedings of the 19th\\nUSENIX Security Symposium . USENIX, August 2010.\\n[41] R. N. M. Watson, P. G. Neumann, J. Woodruff, J. Anderson,\\nD. Chisnall, B. Davis, B. Laurie, S. W. Moore, S. J. Murdoch, and\\nM. Roe, “Capability Hardware Enhanced RISC Instructions: CHERI\\nInstruction-Set Architecture,” University of Cambridge, Computer\\nLab., Tech. Rep. UCAM-CL-TR-850, May 2014. [Online]. Available:\\nhttp://www.cl.cam.ac.uk/techreports/UCAM-CL-TR-850.html\\n[42] M. Wilkes and R. Needham, The Cambridge CAP computer and its\\noperating system . Elsevier North Holland, New York, 1979.\\n[43] A. Wilkinson et al., “A penetration study of a Burroughs large system,”\\nACM Operating Systems Review , vol. 15, no. 1, pp. 14–25, January\\n1981.\\n[44] I. Williams and M. Wolczko, “An object-based memory architecture,”\\ninFourth International Workshop on Persistent Objects . Morgan\\nKaufmann, 1990, pp. 114–130.\\n[45] E. Witchel, J. Cates, and K. Asanovi ´c,Mondrian memory protection .\\nACM, 2002, vol. 37, no. 10.\\n[46] E. Witchel, J. Rhee, and K. Asanovi ´c, “Mondrix: Memory isolation\\nfor Linux using Mondriaan memory protection,” in Proceedings of the\\n20th ACM Symposium on Operating Systems Principles , October 2005.\\n[47] G. Wright, M. L. Seidl, and M. Wolczko, “An object-aware memory\\narchitecture,” Science of Computer Programming , vol. 62, pp. 145–163,\\n2006.\\n[48] B. Yee, D. Sehr, G. Dardyk, J. B. Chen, R. Muth, T. Ormandy,\\nS. Okasaka, N. Narula, and N. Fullagar, “Native client: A sandbox for\\nportable, untrusted x86 native code,” in SP ’09: Proceedings of the\\n2009 30th IEEE Symposium on Security and Privacy , 2009, pp. 79–93.', 'The CHERI capability model- Revisiting RISC in an age of risk.pdf'), 930: ('Application Performance and Hexibility on Exokernel Systems \\nM. Frans Kaashoek, Dawson R. Engler, Gregory R. Ganger, \\nH&or M. Bricefio, Russell Hunt, David Mazikres, Thomas Pinckney, \\nRobert Grimm, John Jannotti, and Kenneth Mackenzie \\nM.I.T. Laboratory for Computer Science \\nCambridge, MA 02139, U.S.A \\nhttp://www.pdos.lcs.mit.edu/ \\nAbstract \\nThe exokemel operating system architecture safely gives untrusted \\nsoftware efficient control over hardware and software resources by \\nseparating management from protection. This paper describes an \\nexokemel system that allows specialized applications to achieve \\nhigh performance without sacrificing the performance of unmod- \\nified UNIX programs. It evaluates the exokemel architecture by \\nmeasuring end-to-end application performance on Xok, an exo- \\nkernel for Intel x86-based computers, and by comparing Xok’s \\nperformance to the performance of two widely-used 4.4BSD UNIX \\nsystems (FreeBSD and OpenBSD). The results show that common \\nunmodified UNIX applications can enjoy the benefits of exoker- \\nnels: applications either perform comparably on Xok/ExOS and \\nthe BSD UNIXes, or perform significantly better. In addition, the \\nresults show that customized applications can benefit substantially \\nfrom control over their resources (e.g., a factor of eight for a Web \\nserver). This paper also describes insights about the exokemel ap- \\nproach gained through building three different exokemel systems, \\nand presents novel approaches to resource multiplexing. \\n1 Introduction \\nIn traditional operating systems, only privileged servers and the \\nkernel can manage system resources. Untrusted applications are \\nrestricted to the interfaces and implementations of this privileged \\nsoftware. This organization is flawed because application demands \\nvary widely. An interface designed to accommodate every appli- \\ncation must anticipate all possible needs. The implementation of \\nsuch an interface would need to resolve all tradeoffs and antic- \\nipate all ways the interface could be used. Experience suggest', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 931: ('l operating systems, only privileged servers and the \\nkernel can manage system resources. Untrusted applications are \\nrestricted to the interfaces and implementations of this privileged \\nsoftware. This organization is flawed because application demands \\nvary widely. An interface designed to accommodate every appli- \\ncation must anticipate all possible needs. The implementation of \\nsuch an interface would need to resolve all tradeoffs and antic- \\nipate all ways the interface could be used. Experience suggests \\nthat such anticipation is infeasible and that the cost of mistakes is \\nhigh [I, 4,8,11,21,39]. \\nThe exokernel architecture [1 l] solves this problem by giving \\nuntrusted applications as much control over resources as possi- \\nble. It does so by dividing responsibilities differently from the way \\nconventional systems do. Exokemels separate protection from man- \\nagement: they protect resources but delegate management to appli- \\ncations. For example, each application manages its own disk-block \\nThis research was supported in part by the Advanced Research Projects Agency under \\ncontract NOOOM-94-I-0985 and by aNSFNational Young Investigator Award. Robert \\nGrimm is currently at the University of Washington, Seattle. \\nPermission to make digital/hard copy of part or all this work for \\npersonal or classroom use is granted without fee provided that \\ncopies are not made or distributed for profit or commercial advan- \\ntago, the copyright notice, the title of the publication and its date \\nappear, and notice is given that copying is by permission of ACM, \\nInc. To copy otherwise, to republish, to post on servers, or to \\nredistribute to lists, requires prior specific permission and/or a fee. \\nSOSP-16 IO/97 Saint-Malo, France \\n0 1997 ACM 0-89791-916~5/97/0010...$3.50 cache, but the exokemel allows cached pages to be shared securely \\nacross all applications. Thus, the exokemel protects pages and disk \\nblocks, but applications manage them. \\nOf course, not all applications need customized resource man- \\nagement. Instead of comm', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 932: ('at copying is by permission of ACM, \\nInc. To copy otherwise, to republish, to post on servers, or to \\nredistribute to lists, requires prior specific permission and/or a fee. \\nSOSP-16 IO/97 Saint-Malo, France \\n0 1997 ACM 0-89791-916~5/97/0010...$3.50 cache, but the exokemel allows cached pages to be shared securely \\nacross all applications. Thus, the exokemel protects pages and disk \\nblocks, but applications manage them. \\nOf course, not all applications need customized resource man- \\nagement. Instead of communicating with the exokemel directly, we \\nexpect most programs to be linked with libraries that hide low- \\nlevel resources behind traditional operating system abstractions, \\nHowever, unlike traditional implementations of these abstractions, \\nlibrary implementations are unprivileged and can therefore be mod- \\nified or replaced at will. We refer to these unprivileged librnrics as \\nlibrary operating systems, or 1ibOSes. \\nWehopetheexokemel organization will facilitateoperatingsys- \\ntern innovation: there are several orders of magnitude more applica- \\ntion programmers than OS implementors, and any programmer can \\nspecialize a IibOS without affecting the rest of the system. LibOSes \\nalso allow incremental, seIective adoption of new OS features: ap \\nplications link with the 1ibOSe.s that provide what they need-new \\nOS functionality is effectively distributed with the application bi- \\nnary. \\nTheexokemel approach raises several questions. Can ambitious \\napplications actually achieve significant performance improvements \\non an exokemel? Will traditional applications-for example, unal- \\ntered UNIX applications-pay a price in reduced performance? Is \\nglobal performance compromised when no centralized authority \\ndecides scheduling and multiplexing policies? Does the lack of n \\ncentralized management policy for shared OS structures lower the \\nintegrity of the system? \\nThis paper attempts to answer these questions and thereby cval- \\nuate the soundness of the exokemel approach. Our experiments \\nare performed on the Xok/ExOS ex', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 933: ('s \\non an exokemel? Will traditional applications-for example, unal- \\ntered UNIX applications-pay a price in reduced performance? Is \\nglobal performance compromised when no centralized authority \\ndecides scheduling and multiplexing policies? Does the lack of n \\ncentralized management policy for shared OS structures lower the \\nintegrity of the system? \\nThis paper attempts to answer these questions and thereby cval- \\nuate the soundness of the exokemel approach. Our experiments \\nare performed on the Xok/ExOS exokemel system. Xok is an cxo- \\nkernel for Intel x86-based computers and ExOS is its defnult HbOS, \\nXok/ExOS compiles onitself and runs many unmodified UNIX pro- \\ngrams (e.g., perl, gee, telnet, and most file utilities). We compare \\nXok/ExOS to two widely-used 4.4BSD UNIX systems running on \\nthe same hardware, using large, real-world applications, \\nExOS ensures the integrity of many of its abstractions using \\nXok’s support for protected sharing. Some abstractions, howcvcr, \\nstill use shared global data structures. ExOS cannot guarantee UNIX \\nsemantics for these abstractions until they are protected from arbl- \\ntrary writes by other processes. In our measurements, we approxi- \\nmate the cost of this protection by inserting system calls before all \\nwrites to shared global state. \\nOur results show that most unmodified UNIX applications per- \\nform comparably on Xok/ExOS and on FreeBSD or OpcnBSD. \\nSome applications, however, run up to a factor of four faster on \\nXok/ExOS. Experiments with multiple applications running con- \\ncurrently also show that exokemels can offer competitive global \\nsystem performance. \\nWe also demonstrate that application-level control can signlll- \\ncantly improve the performance of applications. For example, WC \\n52 \\n\\ndescribe a new high-performance HTTP server, Cheetah, that ac- \\ntively exploits exokernel extensibility. Cheetah uses a file system \\nand a TCP implementation customized for the properties of HlTP \\ntraffic. Cheetah performs up to eight times faster than the best UNIX \\nHTTP server w', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 934: ('ing con- \\ncurrently also show that exokemels can offer competitive global \\nsystem performance. \\nWe also demonstrate that application-level control can signlll- \\ncantly improve the performance of applications. For example, WC \\n52 \\n\\ndescribe a new high-performance HTTP server, Cheetah, that ac- \\ntively exploits exokernel extensibility. Cheetah uses a file system \\nand a TCP implementation customized for the properties of HlTP \\ntraffic. Cheetah performs up to eight times faster than the best UNIX \\nHTTP server we measured on the same hardware. \\nIn addition to evaluating the exokemel approach, this paper \\npresents new kernel interfaces that separate protection from man- \\nagement. We discuss the disk subsystem, XN, and explain how un- \\nprivileged applications can define new file systems and how these \\nfile systems can safely multiplex the same disk at a fine granularity. \\nFinally, we summarize what we have leamed from building three \\ncomplete exokemel systems (Xok, Aegis [ 1 l] for DECstations, and \\nGlaze [29] for the Fugu multiprocessor). \\nThe rest of the paper is organized as follows. Section 2 discusses \\nrelated work. Section 3 summarizes the exokemel architecture. Sec- \\ntion 4 provides a detailed example of reconciling application control \\nwith protection by presenting the disk system XN. Section 5 briefly \\noverviews Xok/ExOS, the experimental environment for this paper. \\nSection 6 reports on the performance of unaltered UNIX applica- \\ntions, while Section 7 reports on the performance of aggressively- \\nspecialized applications, such as the high-performance Cheetah web \\nserver. Section 8 investigates global performance on an exokemel \\nsystem. Section 9 discusses our experiences with building three \\ndifferent exokemel systems. Section 10 concludes. \\n2 Related Work \\nThe exokemel architecture was proposed in [ 111, which described a \\nresearch prototype that performed significantly better than Ultrix on \\nmicrobenchmarks. While the paper provided evidence that the exo- \\nkernel approach was promising, it left many question', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 935: (' applications, such as the high-performance Cheetah web \\nserver. Section 8 investigates global performance on an exokemel \\nsystem. Section 9 discusses our experiences with building three \\ndifferent exokemel systems. Section 10 concludes. \\n2 Related Work \\nThe exokemel architecture was proposed in [ 111, which described a \\nresearch prototype that performed significantly better than Ultrix on \\nmicrobenchmarks. While the paper provided evidence that the exo- \\nkernel approach was promising, it left many questions unanswered. \\nThere is a large literature on extensible operating systems, start- \\ning with the classic rationales by Lampson and Brinch Hansen [19, \\n25,261, Previous approaches to extensibility can be coarsely clas- \\nsified in three groups: better microkemels, virtual machines, and \\ndownloading untrusted code into the kernel. We discuss each in \\nturn. \\nThe principal goal of an exokemel-giving applications con- \\ntrol-is orthogonal to the question of monolithic versus microkemel \\norganization. If applications are restricted to inadequate interfaces, \\nit makes little difference whether the implementations reside in \\nthe kernel or privileged user-level servers [20, 181; in both cases \\napplications lack control. For example, it is difficult to change the \\nbuffer management policy of a shared file server. In many ways, \\nservers can be viewed as fixed kernel subsystems that happen to run \\nin user space. Whether monolithic or microkemel-based, the goal \\nof an exokemel system remains for privileged software to provide \\ninterfaces that do not limit the ability of unprivileged applications \\nto manage their own resources. \\nSome newer microkemels push the kernel interface closer to \\nthe hardware [8,20,36], obtaining better performance and robust- \\nness than previous microkemels and allowing for a greater degree \\nof flexibility, since shared monolithic servers can be broken into \\nseveral servers, Techniques to reduce the cost of shared servers \\nby improving IPC performance, moving code from servers into \\nlibraries, mapping', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 936: ('de \\ninterfaces that do not limit the ability of unprivileged applications \\nto manage their own resources. \\nSome newer microkemels push the kernel interface closer to \\nthe hardware [8,20,36], obtaining better performance and robust- \\nness than previous microkemels and allowing for a greater degree \\nof flexibility, since shared monolithic servers can be broken into \\nseveral servers, Techniques to reduce the cost of shared servers \\nby improving IPC performance, moving code from servers into \\nlibraries, mapping read-only shared data structures, and batching \\nsystem calls [2, l&28,30] can also be successfully applied in an \\nexokemel system. \\nVirtual machines [5,12,17] (VMs) are an OS structure in which \\na privileged virtual machine monitor (VMM) isolates less privileged \\nsoftware in emulated copies of the underlying hardware. Unfortu- \\nnately, emulation hides information. This can lead to ineffective \\nuse of hardware resources; for instance, the VMM has no way of \\nknowing if a VM no longer needs a particular virtual page. More- \\nover, VMs can only share resources through remote communication \\nprotocols. This prevents VMs from sharing many OS abstractions Kernel \\nFigure 1: A simplified exokemel system with two applications, each \\nlinked with its own 1ibOS and sharing pages through a buffer cache \\nregistry. \\nsuch as processes or file descriptors with each other. Thus, VMMs \\nconfine specialized operating systems and associated processes to \\nisolated virtual machines, while exokemels let applications use cus- \\ntomized 1ibOSes without sacrificing a single view of the machine, \\nDownloading code into the kernel is another approach to ex- \\ntensibility. In many systems only trusted users can download code, \\neither through dynamically-loaded kernel extensions or static con- \\nfiguration [13, 211. In the SPIN and Vino systems, any user can \\nsafely download code into the kernel [4,39]. Safe downloading of \\ncodethrough type-safety [4,37] and software fault-isolation [39,42] \\nis complementary to the exokemel approach of separating p', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 937: ('ibOSes without sacrificing a single view of the machine, \\nDownloading code into the kernel is another approach to ex- \\ntensibility. In many systems only trusted users can download code, \\neither through dynamically-loaded kernel extensions or static con- \\nfiguration [13, 211. In the SPIN and Vino systems, any user can \\nsafely download code into the kernel [4,39]. Safe downloading of \\ncodethrough type-safety [4,37] and software fault-isolation [39,42] \\nis complementary to the exokemel approach of separating protec- \\ntion from management. Exokemels use downloading of code to let \\nthe kernel leave decisions to untrusted software [ll]. \\nIn addition to these structural approaches, much work has been \\ndone on better OS abstractions that give more control to appli- \\ncations, such as user-level networking [40, 411, lottery schedul- \\ning [43], application-controlled virtual memory [22, 271 and file \\nsystems [6,35]. All of this work is directly applicable to 1ibOSes. \\n3 Exokernel Background \\nThis section briefly summarizes the exokemel architecture. Fig- \\nure 1 shows a simplified exokemel system that is running two appli- \\ncations: an unmodified UNIX application linked against the ExOS \\n1ibOS and a specialized exokemel application using its own TCP \\nand file system libraries. Applications communicate with the kernel \\nusing low-level physical names (e.g., block numbers); the kernel \\ninterface is as close to the hardware as possible. LibOSes handle \\nhigher-level names (e.g., file descriptors) and supply abstractions. \\nWe briefly describe the exokemel principles, motivated in [ 111. \\nThese principles illustrate the mechanics of exokemel systems and \\nprovide important motivation for many design decisions discussed \\nlater in this paper. In addition, we show how the principles can be \\napplied and discuss the general issue of protected sharing. \\n3.1 Exokernel principles \\nThe goal of an exokemel is to give efficient control of resources \\nto untrusted applications in a secure, multi-user system. We follow \\nthese principles to achiev', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 938: ('iefly describe the exokemel principles, motivated in [ 111. \\nThese principles illustrate the mechanics of exokemel systems and \\nprovide important motivation for many design decisions discussed \\nlater in this paper. In addition, we show how the principles can be \\napplied and discuss the general issue of protected sharing. \\n3.1 Exokernel principles \\nThe goal of an exokemel is to give efficient control of resources \\nto untrusted applications in a secure, multi-user system. We follow \\nthese principles to achieve this goal: \\nSeparate protection and management. Exokemels provide \\nprimitives at the lowest possible level required for protection- \\nideally, at the level of hardware (disk blocks, context identifiers, \\nTLB, etc.). Resource management is restricted to functions neces- \\nsary for protection: allocation, revocation, sharing, and the tracking \\nof ownership. \\n53 \\nExpose allocation. Applications allocate resources explicitly. \\nThe kernel allows specific resources to be requested during alloca- \\ntion. \\nExpose names. Exokemels use physical names wherever pos- \\nsible. Physical names capture useful information and do not require \\npotentially costly or race-prone translations from virtual names. \\nExpose revocation. Exokemels expose revocation policies to \\napplications. They let applications choose which instance of a re- \\nsource to give up. Each application has control over its set of phys- \\nical resources. \\nExpose information. Exokemels expose all system information \\nand collect data that applications cannot easily derive locally. For \\nexample, applications can determine how many hardware network \\nbuffers there are or which pages cache file blocks. An exokemel \\nmight also record an approximate least-re&ntly-used ordering of \\nall physical pages, something individual applications cannot do \\nwithout global information. \\nThese principles apply not just to the kernel, but to any compo- \\nnent of an exokemel system. Privileged servers should provide an \\ninterface boiled down to just what is required for protection. \\n3.2 Kerne', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 939: ('erive locally. For \\nexample, applications can determine how many hardware network \\nbuffers there are or which pages cache file blocks. An exokemel \\nmight also record an approximate least-re&ntly-used ordering of \\nall physical pages, something individual applications cannot do \\nwithout global information. \\nThese principles apply not just to the kernel, but to any compo- \\nnent of an exokemel system. Privileged servers should provide an \\ninterface boiled down to just what is required for protection. \\n3.2 Kernel support for protected abstractions \\nMany of the resources protected by traditional operating systems \\nare themselves high-level abstractions. Files, for instance, consist \\nof metadata, disk blocks, and buffer cache pages, all of which are \\nguarded by access control on high-level file objects. While exoker- \\nnels allow direct access to low-level resources, exokemel systems \\nmust be able to provide UNIX-like protection, including access con- \\ntrol on high-level objects where required for security. One of the \\nmain challenges in designing exokemels is to find kernel interfaces \\nthat allow such higher-level access control without either mandat- \\ning a particular implementation or hindering application control of \\nhardware resources. \\nXok meets this challenge with three design techniques. First, it \\nperforms access control on all resources in the same manner. Sec- \\nond, Xok provides software abstractions to bind hardware resources \\ntogether. For example, as shown in Figure 1, the Xok buffer cache \\nregistry binds disk blocks to the memory pages caching them. Ap- \\nplications have control over physical pages and disk I/O, but can \\nalso safely use each other’s cached pages. Xok’s protection mech- \\nanism guarantees that a process can only access a cache page if it \\nhas the same level of access to the corresponding disk block. Third, \\nand most general, some of Xok’s abstractions allow applications \\nto download code. This is required for abstractions whose protec- \\ntion does not map to hardware abstractions. For example,', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 940: (' disk blocks to the memory pages caching them. Ap- \\nplications have control over physical pages and disk I/O, but can \\nalso safely use each other’s cached pages. Xok’s protection mech- \\nanism guarantees that a process can only access a cache page if it \\nhas the same level of access to the corresponding disk block. Third, \\nand most general, some of Xok’s abstractions allow applications \\nto download code. This is required for abstractions whose protec- \\ntion does not map to hardware abstractions. For example, files may \\nrequire valid updates to their modification times. \\nThe key to these exokemel software abstractions is that they \\nneither hinder low-level access to hardware resources nor unduly \\nrestrict the semantics of the protected abstractions they enable. \\nGiven these properties, a kernel softwareabstractiondoes not violate \\nthe exokemel principles. \\nThough these software abstractions reside in the kernel on \\nXok, they could also be implemented in trusted user-level servers. \\nThis microkemel organization would cost many additional context \\nswitches; these are particularly expensive on the Intel Pentium Pro \\nprocessors on which Xok rum. Furthermore, partitioning function- \\nality in user-level servers tends to be more complex. \\n3.3 Protected sharing \\nThe low-level exokemel interface gives 1ibOSes enough hardware \\ncontrol to implement all traditional operating system abstractions. \\nLibrary implementations of abstractions have the advantage that \\nthey can trust the applications they link with and need not defend \\nagainst malicious use. The flip side, however, is that a libOS cannot necessarily trust all other 1ibOSes with access to a particular re- \\nsource. When 1ibOSes guarantee invariants about their abstractions, \\nthey must be aware of exactly which resources are involved, what \\nother processes have access to those resources, and what level of \\ntrust they place in those other processes. \\nAs an example, consider the semantics of the UNIX fork system \\ncall. It spawns a new process initially identical to the curr', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 941: ('d \\nagainst malicious use. The flip side, however, is that a libOS cannot necessarily trust all other 1ibOSes with access to a particular re- \\nsource. When 1ibOSes guarantee invariants about their abstractions, \\nthey must be aware of exactly which resources are involved, what \\nother processes have access to those resources, and what level of \\ntrust they place in those other processes. \\nAs an example, consider the semantics of the UNIX fork system \\ncall. It spawns a new process initially identical to the currently run- \\nning one. This involves copying the entire virtual address space of \\nthe parent process, a task operating systems typically perform lazily \\nthrough copy-on-write to avoid unnecessary page copies. While \\ncopy-on-write can always be done in a trusted, in-kernel virtunl \\nmemory system, a 1ibOS must exercise care to avoid compromising \\nthe semantics of fork when sharing pages with potentially untrusted \\nprocesses. This section details some of the approaches we have used \\nto-allow a 1ibOS to maintain invariants when sharing resources with \\nother libOSes. \\nThe exokemel provides four mechanisms 1ibOSes can use to \\nmaintain invariants in shared abstractions. First, sofhvare regions, \\nareas of memory that can only be read or written through system \\ncalls, provide sub-page protection and fault isolation. Second, the \\nexokemel allows on the-fly-creation of hierarchically-named capa- \\nbilities and requires that these capabilities be specified explicitly \\non each system call 1311. Thus, a buggy child process acciden- \\ntally requesting write access to a page or software region of its \\nparent will likely provide the wrong capability and be denied pcr- \\nmission. Third, the exokemel provides wakeup predicates: smnll, \\nkernel-downloaded functions that wake up processes when arbi- \\ntrary conditions become true (see Section 5.1 for details), Wakeup \\n.predicates can ensure that a buggy or crashed process will not hang \\na correctly behaved one. Fourth, the exokemel provides robust crit- \\nical sections: inexpensive critic', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 942: ('cciden- \\ntally requesting write access to a page or software region of its \\nparent will likely provide the wrong capability and be denied pcr- \\nmission. Third, the exokemel provides wakeup predicates: smnll, \\nkernel-downloaded functions that wake up processes when arbi- \\ntrary conditions become true (see Section 5.1 for details), Wakeup \\n.predicates can ensure that a buggy or crashed process will not hang \\na correctly behaved one. Fourth, the exokemel provides robust crit- \\nical sections: inexpensive critical sections that are implemented by \\ndisabling software interrupts [33. Using critical sections instead of \\nlocks eliminates the need to trust other processes. \\nThree levels of trust determine what optimizations can be used \\nby the implementation of a shared abstraction. \\nOptimize for the common case: Mutual trust. It is often the \\ncase that applications sharing resources place a considerable amount \\nof trust in each other. For instance, any two UNIX programs run by \\nthe same user can arbitrarily modify each others’ memory through \\nthe debugger system call, ptrace. When two exokemcl processes \\ncan write each others’ memory, their 1ibOSes can clearly trust each \\nother not to be malicious. This reduces the problem of guaranteeing \\ninvariants from one of security to one of fault-isolation, and consc- \\nquently allows 1ibOS code to resemble that of monolithic kernels \\nimplementing the same abstraction. \\nUnidirectional trust. Another common scenario occurs when \\ntwo processes share resources and one trusts the other, but the trust \\nis not mutual. Network servers often follow this organization: a prlv- \\nileged process accepts network connections, forks, and then drops \\nprivileges to perform actions on behalf of a particular user, Mnny \\nabstractions implemented for mutual trust can also function under \\nunidirectional trust with only slight modification. In the example of \\ncopy-on-write, for instance, the trusted parent process must retain \\nexclusive control of shared pages and its own page tables, prevent- \\ning a child', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 943: ('r, but the trust \\nis not mutual. Network servers often follow this organization: a prlv- \\nileged process accepts network connections, forks, and then drops \\nprivileges to perform actions on behalf of a particular user, Mnny \\nabstractions implemented for mutual trust can also function under \\nunidirectional trust with only slight modification. In the example of \\ncopy-on-write, for instance, the trusted parent process must retain \\nexclusive control of shared pages and its own page tables, prevent- \\ning a child from child making copied pages writable in the parent. \\nWhile this requires more page faults in the parent, it does not in- \\ncrease the number of page copies or seriously complicate the code, \\nDefensive programming for mutual distrust. Finally, there \\naresituations wheremutually distrustful processes must share high- \\nlevel abstractions with each other. For instance, two unrelated pro- \\ncesses may wish to communicate over a UNIX domain socket, and \\nneither may have any trust in the other. For OS abstractions that can \\nbe shared by mutually distrustful processes, 1ibOSes must include \\ndefensive implementations that give reasonable interpretations to \\nall possible actions by the foreign process (for instance a socket \\nwrite larger than the buffer can be interpreted as an end of file), \\n54 \\nFortunately, sharing with mutual distrust occurs very infre \\nquently for many abstractions. Many types of sharing occur only \\nbetween child and parent processes, where mutual or unidirectional \\ntrust almost always holds. Where mutual distrust does occur, defen- \\nsive sanity checks are often not on the critical path for performance. \\nIn the remaining cases, as is the case for disk files, we have carefully \\ncrafted kernel software abstractions to help libOSes maintain the \\nnecessary invariants. \\n4 Multiplexing Stable Storage \\nAn exokemel must provide a means to safely multiplex disks among \\nmultiple library file systems (libFSe.9. Each IibOS contains one or \\nmore IibFSes. Multiple 1ibFSes can be used to share the same files \\nwit', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 944: ('re mutual distrust does occur, defen- \\nsive sanity checks are often not on the critical path for performance. \\nIn the remaining cases, as is the case for disk files, we have carefully \\ncrafted kernel software abstractions to help libOSes maintain the \\nnecessary invariants. \\n4 Multiplexing Stable Storage \\nAn exokemel must provide a means to safely multiplex disks among \\nmultiple library file systems (libFSe.9. Each IibOS contains one or \\nmore IibFSes. Multiple 1ibFSes can be used to share the same files \\nwith different semantics. In addition to accessing existing files, \\n1ibFSes can define new on-disk file types with arbitrary metadata \\nformats. An exokemel must give 1ibFSes as much control over file \\nmanagement as possible while still protecting files from unautho- \\nrized access. It therefore cannot rely on simpleminded solutions \\nlike partitioning to multiplex a disk: each file would require its own \\npartition. \\nTo allow 1ibFSes to perform their own file management, an \\nexokemel stable storage system must satisfy four requirements. \\nFirst, creating new file formats should be simple and lightweight. \\nIt should not require any special privilege. Second, the protection \\nsubstrate should allow multiple 1ibFSes to safely share files at the \\nraw diskblock and metadatalevel. Third, thestoragesystemmust be \\nefficient-as close to raw hdrdware performance as possible. Fourth, \\nthe storage system should facilitate cache sharing among libFSes, \\nand allow them to easily address problems of cache coherence, \\nsecurity, and concurrency. \\nThis section describes how Xok multiplexes stable storage, both \\nto show how we address these problems and to provide a concrete \\nexample of the exokemel principles in practice. First, we describe \\nXN, Xok’s extensible, low-level in-kernel stable storage system. \\nWe also describe the general interface between XN and libFSes \\nand present one particular libFS, C-EFS, the co-locating fast file \\nsystem [ISI. \\n4.1 Overview of XN \\nDesigning a flexible exokemel stable storage system has proven \\ndiffic', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 945: ('oncurrency. \\nThis section describes how Xok multiplexes stable storage, both \\nto show how we address these problems and to provide a concrete \\nexample of the exokemel principles in practice. First, we describe \\nXN, Xok’s extensible, low-level in-kernel stable storage system. \\nWe also describe the general interface between XN and libFSes \\nand present one particular libFS, C-EFS, the co-locating fast file \\nsystem [ISI. \\n4.1 Overview of XN \\nDesigning a flexible exokemel stable storage system has proven \\ndifficult: XN is our fourth design. This section provides an overview \\nof UDFs, the cornerstone of XN; the following sections describe \\nsome earlier approaches (and why they failed), and aspects of XN \\nin greater depth. \\nXN provides access to stable storage at the level of disk blocks, \\nexporting a buffer cache registry (Section 4.3.3) as well as free \\nmaps and other on-disk structures. The main purpose of XN is to \\ndetermine the access rights of a given principal to a given disk \\nblock as efficiently as possible. XN must prevent a malicious user \\nfrom claiming another user’s disk blocks as part of her own files. \\nOn a conventional OS, this task is easy, since the kernel itself \\nknows the file’s metadata format. On an exokemel, where files have \\napplication-defined metadata layouts, the task is more difficult. \\nXN’s novel solution employs UDFs (untrusted deterministic \\nfunctions). UDFs are metadata translation functions specific to each \\nfile type. XN uses UDFs to analyze metadata and translate it into \\na simple form the kernel understands. A libFS developer can in- \\nstall UDFs to introduce new on-disk metadata formats. The re- \\nstricted language in which UDFs are specified ensures that they are \\ndeterministic-their output depends only on their input (the meta- \\ndata itself). UDFs allow the kernel to safely and efficiently handle \\nany metadata layout without understanding the layout itself. UDFs are stored on disk in structures called templates. Each \\ntemplate corresponds to a particular metadata format; for exam- \\np', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 946: ('rm the kernel understands. A libFS developer can in- \\nstall UDFs to introduce new on-disk metadata formats. The re- \\nstricted language in which UDFs are specified ensures that they are \\ndeterministic-their output depends only on their input (the meta- \\ndata itself). UDFs allow the kernel to safely and efficiently handle \\nany metadata layout without understanding the layout itself. UDFs are stored on disk in structures called templates. Each \\ntemplate corresponds to a particular metadata format; for exam- \\nple, a UNIX file system would have templates for data blocks, \\ninode blocks, inodes, indirect blocks, etc. Each template T has one \\nUDF: owns-udfrr, and two untrusted but potentially nondeterminis- \\ntk fUlCdOILS: ad-UfT and size-ufT. All three functions are specified \\nin the same language but only OwnS-dfT must be deterministic. \\nThe other two can have access to, for example, the time of day. The \\nlimited language used to write these functions is a pseudo-RISC \\nassembly language, checked by the kernel to ensure determinacy. \\nOnce a template is specified, it cannot be changed. \\nFor a piece of metadata m of template type T, ownsudfrr (m) \\nreturns the set of blocks which m points to and their respective \\ntemplate types. UDF determinism guarantees that owns-udf will \\nalways compute the same output for a given input: XN cannot \\nbe spoofed by owns-udJ The set of blocks owns-udf returns is \\nrepresented as a set of tuples. Each tuple constitutes a range: a \\nblock address that specifies the start of the range, the number of \\nblocks in the range, and the template identifier for the blocks in \\nthe range. Because owned sets can be large, XN allows IibFSes \\nto partition metadata blocks into disjoint pieces such that each set \\nreturned is (typically) a single tuple. \\nFor example, say a libFS wants to allocate a disk block b by \\nplacing a pointer to it in a metadata structure, m. The IibFS will \\ncall XN, passing it m, b, and the proposed modification to m (spec- \\nified as a list of bytes to write into m). To enforce protection', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 947: ('er of \\nblocks in the range, and the template identifier for the blocks in \\nthe range. Because owned sets can be large, XN allows IibFSes \\nto partition metadata blocks into disjoint pieces such that each set \\nreturned is (typically) a single tuple. \\nFor example, say a libFS wants to allocate a disk block b by \\nplacing a pointer to it in a metadata structure, m. The IibFS will \\ncall XN, passing it m, b, and the proposed modification to m (spec- \\nified as a list of bytes to write into m). To enforce protection, \\nXN needs to know that the 1ibFS’s proposed modification actually \\ndoes what it says it does-that is, allocates b in m. Thus, XN mns \\nOwnS-UdfT (m> ; makes the proposed modification on m’, a copy of \\nm; and runs own.vudfT Cm’). It then verifies that the new result is \\nequal the old result plus b. \\nThe ucf-uf function implements template-specific access control \\nand semantics; its input is a piece of metadata, a proposed modifi- \\ncation to that metadata, and set of credentials (e.g., capabilities). Its \\noutput is a Boolean value approving or disapproving of the mod- \\nification. XN runs the proper acf-uf function before any metadata \\nmodification. acl-ufi can implement access control lists, as well \\nas providing certain other guarantees; for example, an ucl-uf could \\nensure that inode modification times are kept current by rejecting \\nany metadata changes that do not update them. \\nThe size-uf function simply returns the size of a data structure \\nin bytes. \\n4.2 XN: Problem and history \\nThe most difficult requirement for XN is efficiently determining the \\naccess rights of a given principal to a given disk block. We discuss \\nthe successive approaches that we have pursued. \\nDisk-block-level multiplexing. One approach is to associate \\nwith each block or extent a capability (or access control list) that \\nguards it. Unfortunately, if the capability is spatially separated from \\nthe disk block (e.g., stored separately in a table), accessing a block \\ncan require two disk accesses (one to fetch the capability and one \\nto f', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 948: ('ement for XN is efficiently determining the \\naccess rights of a given principal to a given disk block. We discuss \\nthe successive approaches that we have pursued. \\nDisk-block-level multiplexing. One approach is to associate \\nwith each block or extent a capability (or access control list) that \\nguards it. Unfortunately, if the capability is spatially separated from \\nthe disk block (e.g., stored separately in a table), accessing a block \\ncan require two disk accesses (one to fetch the capability and one \\nto fetch the block). While caching can mitigate this problem to a \\ndegree, we are nervous about its overhead on disk-intensive work- \\nloads. An alternative approach is to co-locate capabilities with disk \\nblocks by placing them immediately before a disk block’s data [26]. \\nUnfortunately, on common hardware, reserving space for a capa- \\nbility would prevent blocks from being multiples of the page size, \\nadding overhead and complexity to disk operations. \\nSelf-descriptive metadata. Our tirst serious attempt at efficient \\ndisk multiplexing provided a means for each instance of metadata \\nto describe itself. For example, a disk block would start with some \\nnumber of bytes of application-specific data and then say “the next \\nten integers are disk block pointers.” The complexity of space- \\nefficient self-description caused us to limit what metadata could be \\n55 \\ndescribed. We discovered that this approach both caused unaicept- \\nable amounts of space overhead and required excessive effort to \\nmodify existing file system code, because it was difficult to shoe- \\nhorn existing file system data structures into a universal format. \\nTemplate-based description. Self-description and its problems \\nwere eliminated by the insight that each file system is built from \\nonly a handful of different on-disk data structures, each of which \\ncan be considered a type. Since the number of types is small, it \\nis feasible to describe each type only once per file system-rather \\nthan once per instance of a type-using a template. \\nOriginally, templa', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 949: ('code, because it was difficult to shoe- \\nhorn existing file system data structures into a universal format. \\nTemplate-based description. Self-description and its problems \\nwere eliminated by the insight that each file system is built from \\nonly a handful of different on-disk data structures, each of which \\ncan be considered a type. Since the number of types is small, it \\nis feasible to describe each type only once per file system-rather \\nthan once per instance of a type-using a template. \\nOriginally, templates were written in a declarative description \\nlanguage (similar to that used in self-descriptive metadata) rather \\nthan UDFs. This system was simple and better than self-descriptive \\nmetadata, but still exhibited what we have come to appreciate as \\nan indication that applications do not have enough control: the \\nsystem made too many tradeoffs. We had to make a myriad of \\ndecisions about which base types were available and how they were \\nrepresented (how large disk block pointers could be, how the type \\nlayout could change, how extents were specified). Given the variety \\nof on-disk data structures described in the file system literature, it \\nseems unlikely that any fixed set of components will evkr be enough \\nto describe all useful metadata. \\n‘Our current solution uses templates, but trades the declarative \\ndescription language for a more expressive, interpreted language \\nUDFs. This lets IibFSes track their own access rights without XN \\nunderstanding how they do so; XN merely verifies that 1ibFSes track \\nblock ownership correctly. \\n4.3 XN: Design and implementation \\nWe first describe the requirements for XN and then present the \\ndesign. \\n4.3.1 Requirements and approach \\nIn our experience so far, the following requirements have been \\nsufficient to reconcile application control with protected sharing. \\n1. To prevent unauthorized access, every operation on disk data \\nmust be guarded. For speed, XN uses secure bindings [ll] \\nto move access checks to bind time rather than checking at \\nevery access. For example, the ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 950: ('k ownership correctly. \\n4.3 XN: Design and implementation \\nWe first describe the requirements for XN and then present the \\ndesign. \\n4.3.1 Requirements and approach \\nIn our experience so far, the following requirements have been \\nsufficient to reconcile application control with protected sharing. \\n1. To prevent unauthorized access, every operation on disk data \\nmust be guarded. For speed, XN uses secure bindings [ll] \\nto move access checks to bind time rather than checking at \\nevery access. For example, the permission to read a cached \\ndisk block is checked when the page is inserted into the page \\ntable of the IibFS’s environment, rather than on every access. \\n2. XN must be able to determine unambiguously what access \\nrights a principal has to a given disk block. For speed, it uses \\nthe UDF mechanism to protect disk blocks using the IibFS’s \\nown metadata rather than guarding each block individually. \\n3. XN must guarantee that disk updates are ordered such that \\na crash wilI not incorrectly grant a 1ibFS access to data it \\neither has freed or has not allocated. This requirement means \\nthat metadata that is persistent across crashes cannot be writ- \\nten when it contains pointers to uninitialized metadata, and \\nthat reallocation of a freed block must be delayed until all \\npersistent pointers to it have been removed. \\nWhile isolation allows separate IibFSes to coexist safely, pro- \\ntected sharing of file system state by mutually distrustful libFSes \\nrequires three additional features: \\n1. Coherent caching of disk blocks. Distributed, per-application \\ndisk block caches create a consistency problem: if two appli- \\ncations obliviously cache the same disk block in two differ- \\nent physical pages, then modifications will not be shared. XN \\nsolves this problem with an in-kernel, system-wide, protected 2. \\n3. \\n. cache registry that maps cached disk blocks to the physical \\npages holding them. \\nAtomic metadata updates. Many file system updates have \\nmultiple steps. To ensure that shared state always ends up \\nin a consistent an', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 951: ('ocks. Distributed, per-application \\ndisk block caches create a consistency problem: if two appli- \\ncations obliviously cache the same disk block in two differ- \\nent physical pages, then modifications will not be shared. XN \\nsolves this problem with an in-kernel, system-wide, protected 2. \\n3. \\n. cache registry that maps cached disk blocks to the physical \\npages holding them. \\nAtomic metadata updates. Many file system updates have \\nmultiple steps. To ensure that shared state always ends up \\nin a consistent and correct state, IibFSes can lock cache reg- \\nistry entries. (Future work will explore optimistic concur- \\nrency control based on versioning.) \\nWell-formed updates. File abstractions above the XN intcr- \\nface may require that metadata modifications satisfy invari- \\nants (e.g., that link counts in inodes match the number of as- \\nsociated directory entries). UDFs allow XN to guarantee such \\ninvariants in a file-system-specific manner, allowing mutually \\ndistrustful applications to safely share metadata. \\nXN controls only what is necessary to enforce these protection \\nrules. All other abilities-40 initiation, disk block layout and allo- \\ncation policies, recovery semantics, and coflsistency guarantees- \\nare left to untrusted 1ibFSes. \\n4.3.2 Ordered disk writes \\nAnother difficulty XN must face is guaranteeing the rules Ganger \\nand Patt [16] give for achieving strict file system integrity across \\ncrashes: First, never reuse an on-disk resource before nullifying all \\nprevious pointers to it. Second, never create persistent pointers to \\nstructures before they are initialized. Third, when moving an on. \\ndisk resource, never reset the old pointer in persistent storage bcforc \\nthe new one has been set. \\nThe first two rules are required for global system integrity-and \\nthus must be enforced by XN-while a file system violating the \\nthird rule will only affect itself. \\nThe rules are simple but diftictilt to enforce efficiently: a naive \\nimplementation will incur frequent costly synchronous disk writes, \\nXN allows 1ibFSes to', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 952: ('rsistent pointers to \\nstructures before they are initialized. Third, when moving an on. \\ndisk resource, never reset the old pointer in persistent storage bcforc \\nthe new one has been set. \\nThe first two rules are required for global system integrity-and \\nthus must be enforced by XN-while a file system violating the \\nthird rule will only affect itself. \\nThe rules are simple but diftictilt to enforce efficiently: a naive \\nimplementation will incur frequent costly synchronous disk writes, \\nXN allows 1ibFSes to address this by enforcing the rules without \\nlegislating how to follow them. In particular, IibFSes can choose \\nany operation order which satisfies the constraints, \\nThe first rule is implemented by deferring a block’s deallocation \\nuntil all on-disk pointers to that block have been deleted; a reference \\ncount performed at crash recovery time helps IibFSes implement the \\nthird rule. \\nThe second rule is the hardest of the three. To implement it, XN \\nkeeps track of tainted blocks. Any block is considered tainted if it \\npoints either to an uninitialized block or to a tainted block. LibFScs \\nmust not be allowed to write a tainted block to disk. However, two \\nexceptions allow XN to enforce the general rule more efficiently: \\nFirst, XN allows entire file systems to be marked “temporary” \\n(i.e., not persistent across reboots). Since these file systems are not \\npersistent, they are not required to adhere to any of the integrity \\nrules. This technique allows memory-based file systems to be im- \\nplemented with no loss of efficiency. \\nThesecondexceptionisbasedontheobservationthatunattachcd \\nsubtrees-trees whose root is not reachable from any persistent \\nroot-will not be preserved across reboots and thus, like tempo- \\nrary trees, are free of any ordering constraints. Thus, XN does not \\ntrack tainted blocks in an unreachable tree until it is connected to a \\npersistent root. \\n4.3.3 The buffer cache registry \\nFinally, we discuss the XN buffer cache registry, which allows pro- \\ntected sharing of disk blocks among 1ibFSes. The', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 953: (' of efficiency. \\nThesecondexceptionisbasedontheobservationthatunattachcd \\nsubtrees-trees whose root is not reachable from any persistent \\nroot-will not be preserved across reboots and thus, like tempo- \\nrary trees, are free of any ordering constraints. Thus, XN does not \\ntrack tainted blocks in an unreachable tree until it is connected to a \\npersistent root. \\n4.3.3 The buffer cache registry \\nFinally, we discuss the XN buffer cache registry, which allows pro- \\ntected sharing of disk blocks among 1ibFSes. The registry tracks the \\nmapping of cached disk blocks and their metadata to physical pages \\n(and vice versa). Unlike traditional buffer caches, it only records \\nthe mapping, not the disk blocks themselves. The disk blocks are \\nstored in application-managed physical-memory pages. The registry \\n56 \\ntracks both the mapping and its state (dirty, out of core, uninitialized, \\nlocked). To allow IibFSes to see which disk blocks are cached, the \\nbuffer cache registry is mapped read-only into application space. \\nAccess control is performed when a IibFS attempts to map a \\nphysical page containing a disk block into its address space, rather \\nthan when that block is requested from disk. That is, registry entries \\ncan be inserted without requiring that the object they describe be \\nin memory. Blocks can also be installed in the registry before their \\ntemplate or parent is known. As a result, 1ibFSes have significant \\nfreedom to prefetch. \\nRegistry entries are installed in two ways. First, an application \\nthat has write access to a block can directly install a mapping to it \\ninto the registry. Second, applications that do not have write access \\nto a block can indirectly install an entry for it by performing a “read \\nand insert,” which tells the kernel to read a disk block, associate it \\nwith an application-provided physical page, set the protection of that \\npage page appropriately, and insert this mapping into the registry. \\nThis latter mechanism is used to prevent applications that do not \\nhave permission to write a block from ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 954: (' to a block can directly install a mapping to it \\ninto the registry. Second, applications that do not have write access \\nto a block can indirectly install an entry for it by performing a “read \\nand insert,” which tells the kernel to read a disk block, associate it \\nwith an application-provided physical page, set the protection of that \\npage page appropriately, and insert this mapping into the registry. \\nThis latter mechanism is used to prevent applications that do not \\nhave permission to write a block from modifying it by installing a \\nbogus in-core copy. \\nXN does not replace physical pages from theregistry (except for \\nthose freed by applications), allowing applications to determine the \\nmost appropriate caching policy. Because applications also manage \\nvirtual memory paging, the partitioning of disk cache and virtual \\n’ memory backing store is under application control. To simplify \\nthe application’s task and because it is inexpensive to provide, XN \\nmaintains an LRU list of unused but valid buffers. By default, when \\nLibOSes need pages and none are free, they recycle the oldest buffer \\non this LRU list. \\nXN allows any process to write “unowned” dirty blocks to disk \\n(i.e., blocks not associated with a running process), even if that \\nprocess does not have write permission for the dirty blocks. This \\nallows the construction of daemons that asynchronously write dirty \\nblocks. LibFSes do not have to trust daemons with write access \\nto their files, only to flush the blocks. This ability has three bene- \\nfits. First, the contents of the registry can be safely retained across \\nprocess invocations rather than having to be brought in and paged \\nout on creation and exit. Second, this design simplifies the imple- \\nmentations of libFSes, since a 1ibFS can rely on a daemon of its \\nchoice to flush dirty blocks even in difficult situations (e.g., if the \\napplication containing the 1ibFS is swapped out). Third, this design \\nallows different write-back policies. \\n4.4 XN usage \\nTo illustrate how XN is used, we sketch how a 1ibF', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 955: ('st, the contents of the registry can be safely retained across \\nprocess invocations rather than having to be brought in and paged \\nout on creation and exit. Second, this design simplifies the imple- \\nmentations of libFSes, since a 1ibFS can rely on a daemon of its \\nchoice to flush dirty blocks even in difficult situations (e.g., if the \\napplication containing the 1ibFS is swapped out). Third, this design \\nallows different write-back policies. \\n4.4 XN usage \\nTo illustrate how XN is used, we sketch how a 1ibFS can implement \\ncommon file system operations. These two setup operations are \\nused to install a libFS: \\n‘Qpe creation. The 1ibFS describes its types by storing tem- \\nplates, described above in Section 4.1, into a type catalogue. Each \\ntemplate is identified by a unique string (e.g., “FFS Inode”). Once \\ninstalled, types are persistent across reboots. \\nLibFS persistence. To ensure that 1ibFS data is persistent across \\nreboots, a 1ibFS can register the root of its tree in XN’s root cat- \\nalogue. A root entry consists of a disk extent and corresponding \\ntemplate type, identified by a unique string (e.g., “mylibFS”). \\nAfter a crash, XN uses these roots to garbage-collect the disk \\nby reconstructing the free map. It does so by logically traversing \\nall roots and all blocks reachable from them: reachable blocks are \\nallocated, non-reachable blocks are not. If rebuilding the free map \\nafter a crash needs to be fast, this step can be eliminated by ordering \\nwrites to the free map. \\nAfter initialization, the new 1ibFS can use XN. We describe a \\nsimplified version of the most common operations. \\nStartup. To start using XN, a libFS loads its root(s) and any \\ntypes it needs from the root catalogue into the buffer cache registry. Usually both will already be cached. \\nRead. Reading a block from disk is a two-stage process, where \\nthe stages can be combined or separated. First, the 1ibFS creates \\nentries in the registry by passing block addresses for the requested \\ndisk blocks and the metadata blocks controlling them (their ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 956: ('S can use XN. We describe a \\nsimplified version of the most common operations. \\nStartup. To start using XN, a libFS loads its root(s) and any \\ntypes it needs from the root catalogue into the buffer cache registry. Usually both will already be cached. \\nRead. Reading a block from disk is a two-stage process, where \\nthe stages can be combined or separated. First, the 1ibFS creates \\nentries in the registry by passing block addresses for the requested \\ndisk blocks and the metadata blocks controlling them (their par- \\nen&). The parents must already exist in the registry-1ibFSes are \\nresponsible for loading them. XN uses owns-udf to determine if \\nthe requested blocks are controlled by the supplied metadata blocks \\nand, if so, installs registry entries. \\nIn the second stage, the 1ibFS initiates a read request, optionally \\nsupplying pages to place the data in. Access control through acl-uf \\nis performed at the parent (e.g., if the data loaded is a bare disk \\nblock), at the child (e.g., if the data is an inode), or both. \\nA 1ibFS can load any block in its tree by traversing from its root \\nentry, or optionally by starting from any intermediate node cached \\nin the registry. Note that XN specifically disallows metadata blocks \\nfrom being mapped read/write. \\nTo speculatively read a block before its parent is known, a 1ibFS \\ncan issue a raw read command. If the block is not in the registry, it \\nwill be marked as “unknown type” and a disk request initiated. The \\nblock cannot be used until after it is bound to a parent by the first \\nstage of the read process, which will determine its type and allow \\naccess control to be performed. \\nAllocate. A libFS selects blocks to allocate by reading XN’s \\nmap of free blocks, allowing 1ibFSes to control file layout and \\ngrouping. Free blocks are allocated to a given metadata node by \\ncalling XN with the metadata node, the blocks to allocate, and the \\nproposed modification to the metadata node. XN checks that the \\nrequested blocks are free, runs the appropriate a&uf to see if the \\n1ibFS has per', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 957: ('irst \\nstage of the read process, which will determine its type and allow \\naccess control to be performed. \\nAllocate. A libFS selects blocks to allocate by reading XN’s \\nmap of free blocks, allowing 1ibFSes to control file layout and \\ngrouping. Free blocks are allocated to a given metadata node by \\ncalling XN with the metadata node, the blocks to allocate, and the \\nproposed modification to the metadata node. XN checks that the \\nrequested blocks are free, runs the appropriate a&uf to see if the \\n1ibFS has permission to allocate, and runs owns-u& as described in \\nSection 4.1, to see that the correct block is being allocated. If these \\nchecks all succeed, the metadata is changed, the allocated blocks \\nare removed from the free list, and any allocated metadata blocks \\nare marked tainted (see Section 4.3.2). \\nWrite. A libFS writes dirty blocks to disk by passing the blocks \\nto write to XN. If the blocks are not in memory, or they have been \\npinned in memory by some other application, the writeis prevented. \\nThe write also fails if any of the blocks are tainted and reachable \\nfrom a persistent root. Otherwise, the write succeeds. If the block \\nwas previously tainted and now is not (either by eliminating pointers \\nto uninitialized metadata or by becoming initialized itself), XN \\nmodifies its state and removes it from the tainted list. \\nSince applications control what is fetched and what is paged out \\nwhen (and in what order), they can control many disk management \\npolicies and can enforce strong stability guarantees. \\nDeallocate. XN uses UDFs to check deallocate operations anal- \\nogously to allocate operations. If there are no on-disk pointers to a \\ndeallocated disk block, XN places it on the free list. Otherwise, XN \\nenqueues the block on a “will free” list until the block’s reference \\ncount is zero. Reference counts are decremented when a parent that \\nhad an on-disk pointer to the block deletes that pointer via a write. \\n4.5 C-FFS: a library tie system \\nThis subsection briefly describes C-FFS (co-locating fast file sys', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 958: ('Deallocate. XN uses UDFs to check deallocate operations anal- \\nogously to allocate operations. If there are no on-disk pointers to a \\ndeallocated disk block, XN places it on the free list. Otherwise, XN \\nenqueues the block on a “will free” list until the block’s reference \\ncount is zero. Reference counts are decremented when a parent that \\nhad an on-disk pointer to the block deletes that pointer via a write. \\n4.5 C-FFS: a library tie system \\nThis subsection briefly describes C-FFS (co-locating fast file sys- \\ntem [151)-a UNIX-like library file system we built-with special \\nreference to additional protection guarantees it provides. \\nXN provides the basic protection guarantees needed for file \\nsystem integrity, but real-world file systems often require other, file- \\nsystem-specific invariants. For instance, UNIX file systems must \\nensure the uniqueness of file names within a directory. This type of \\nguarantee can be provided in any number of ways: in the kernel, in a \\nserver, or, in some cases, by simple defensive programming. C-FFS \\ncurrently downloads methods into the kernel to check its invariants. \\nWe are currently developing a system similar to UDFs that can be \\n57 \\nused to enforce type-specific invariants in an efficient, extensible \\nway. \\nOur experience with C-FFS shows.that, even with the strongest \\ndesired guarantees, a protected interface can still provide significant \\nflexibility to unprivileged software, and that the exokemel apIjroach \\ncan deal as readily with high-level protection requirements as it can \\nwith those closer to hardware. \\nC-FFS makes four main additions to XN’s protection mecha- \\nnisms: \\n1. Access control: it maps the UNIX representation and seman- \\ntics of access control (uids and gids, etc.) to those of exokemel \\ncapabilities. \\n2. Well-formed updates: C-FFS guarantees UNIXspecific file \\nsemantics: for example, that directories contain legal, aligned \\nfile names. \\n3. Atomicity: C-FFS performs locking to ensure that its data is \\nalways recoverable and disk writes only occur when metadata', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 959: (' can \\nwith those closer to hardware. \\nC-FFS makes four main additions to XN’s protection mecha- \\nnisms: \\n1. Access control: it maps the UNIX representation and seman- \\ntics of access control (uids and gids, etc.) to those of exokemel \\ncapabilities. \\n2. Well-formed updates: C-FFS guarantees UNIXspecific file \\nsemantics: for example, that directories contain legal, aligned \\nfile names. \\n3. Atomicity: C-FFS performs locking to ensure that its data is \\nalways recoverable and disk writes only occur when metadata \\nis internally consistent. \\n4. Implicit updates: C-FFS ensures that certain state transitions \\nare implicit on certain actions. Some examples are that mod- \\nification times are updated when file data are changed, and \\nthat renaming or deleting a file updates the name cache. \\nIt is not difficult to implement UNIX protection without sig- \\nnificantly degrading application power. C-FFS protection is im- \\nplemented mainly by a small number of if-statements rather than \\nby procedures that limit flexibility. The most intricate operation- \\nensuring that files in a directory have unique names-is less than \\n100 lines of code that scans through a linked list of cached directory \\nblocks to ensure name uniqueness. \\n4.6 Future work \\nStable storage is the most challenging resource we have multi- \\nplexed. Future work will focus on two areas. First, we plan to im- \\nplement a range of file systems (log-structured file systems, RAID, \\nand memory-based file systems), thus testing if the XN interface \\nis powerful enough to support concurrent use by radically different \\nfile systems. Second we will investigate using lightweight protected \\nmethods like UDFs to implement the simple protection checks re- \\nquired by higher-level abstractions. \\n5 Overview of XoklExOS \\nFor the experiments in this paper, we use Xok/ExOS. This section \\ndescribes both Xok and ExOS. \\n5.1 Xok \\nXok safely multiplexes the physical resources on Intel x86-based \\ncomputers. Xok performs this task in a manner similar to the Aegis \\nexokemel, which runs on MIPS-based', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 960: ('rt concurrent use by radically different \\nfile systems. Second we will investigate using lightweight protected \\nmethods like UDFs to implement the simple protection checks re- \\nquired by higher-level abstractions. \\n5 Overview of XoklExOS \\nFor the experiments in this paper, we use Xok/ExOS. This section \\ndescribes both Xok and ExOS. \\n5.1 Xok \\nXok safely multiplexes the physical resources on Intel x86-based \\ncomputers. Xok performs this task in a manner similar to the Aegis \\nexokemel, which runs on MIPS-based DECstations [ll]. The CPU \\nis multiplexed by dividing time into round-robin-scheduled slices \\nwith explicit notification of the beginning and the end df a time \\nslice. Environments provide the hardware-specific state needed to \\nrun a process (e.g., an exception stack) and to respond to any event \\noccurring during process execution (e.g., interrupts and excep tions). \\nThe network is multiplexed with dynamic packet filters [lo]. This \\nsubsection briefly describes the differences between Aegis and Xok. \\nPhysical memory. Unlike the MIPS architecture, the x86 archi- \\ntecture defines the page-table structure. Since x86 TLB refills are \\nhandled in hardware, this structure cannot be overridden by appli- \\ncations. Additionally, since the hardware does not verify that the physical page of a translation can be mapped by a process, applica4 \\ntions are prevented from directly modifying the page table and must \\ninstead use system calls. Although these restrictions make Xok less \\nextensible than Aegis, they simplify the implementation of 1ibOSes \\n(see Section 9) with only a small reduction in application flexibility. \\nLike Aegis, Xok allows efficient and powerful virtual memory \\nabstractions to be built at the application level. It does so by exposing \\nthe capabilities of the hardware (e.g., all MMU protection bits) \\nand exposing many kernel data structures (e.g., free lists, inverse \\npage mappings). Xok’s low-level interface means that paging IS \\nhandled by applications. As such, it can be done from disk, ncross \\nthe networ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 961: ('plementation of 1ibOSes \\n(see Section 9) with only a small reduction in application flexibility. \\nLike Aegis, Xok allows efficient and powerful virtual memory \\nabstractions to be built at the application level. It does so by exposing \\nthe capabilities of the hardware (e.g., all MMU protection bits) \\nand exposing many kernel data structures (e.g., free lists, inverse \\npage mappings). Xok’s low-level interface means that paging IS \\nhandled by applications. As such, it can be done from disk, ncross \\nthe network, or by data regeneration. Additionally, applications \\ncan readily perform per-page transformations such as compression, \\nverification of contents using digital signatures (to allow untrusted \\nnodes in a network to cache pages), or encryption. \\nWakeup predicates. Applications often want to sleep until a \\ncbndition is true. Unfortunately, it may be difficult for an applica- \\ntion to express this condition to the kernel. This problem is more \\nprevalent on exokemels because the bulk of OS functionality resides \\nin the application. \\nTo solvethis problem, Xokprovides applications with the ability \\nto inject wakeup predicates into the kernel. Wakeup predicates arc \\nboolean expressions used by applications to sleep until the state of \\nthe system satisfies some condition; they are evaluated by the kernel \\nwhen an environment is about to be scheduled. The applbatlon is \\nnot scheduled if the predicate does not hold. \\nPredicate evaluation is efficient. Like dynamid packet filters, \\nXok compiles predicates on-the-fly to executable code. The slgnlf- \\nicant overhead of an address space context switch is eliminated by \\nevaluating the predicates in the exokemel and pre-translating all \\npredicate virtual addresses to their associated physical addresses, \\nWhenavirtualpagereferencedinapredicateisunmapbed, thephyso \\nical page is not marked as free until a new predicate is downloaded \\nor until the application exits. Furthermore, the implementation of \\nwakeup predicates is simple (fewer than 200 lines of commented \\ncode) because ca', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 962: (' executable code. The slgnlf- \\nicant overhead of an address space context switch is eliminated by \\nevaluating the predicates in the exokemel and pre-translating all \\npredicate virtual addresses to their associated physical addresses, \\nWhenavirtualpagereferencedinapredicateisunmapbed, thephyso \\nical page is not marked as free until a new predicate is downloaded \\nor until the application exits. Furthermore, the implementation of \\nwakeup predicates is simple (fewer than 200 lines of commented \\ncode) because careful language design (no loops and easy to under- \\nstand operations) allows predicates to be easily controlled. \\nPredicates are simple but powerful. Coupled with Xok’s ex- \\nposure of data structures, they have provided us with a robust \\nwakeup facility-none of the new uses of wakeup predicates re- \\nquired changes to Xok. For example, to wait for a disk block to \\nbe paged in, a wakeup predicate can bind to the block’s state and \\nwake up when it changes from “in transit” to “resident.” To bound \\nthe amount of time a predicate sleeps, it can compare against the \\nsystem clock. The composition of multiple predicates allows atomb \\nchecking of disjoint data structures. \\nAccess control Unlike Aegis, Xok performs access control \\nthrough hierarchically-named capabilities [31]; despite the name, \\nthese capabilities more cIosely resembIe a generalized form of \\nUNIX user and group ID than traditional capabilities [9]. All Xok \\ncalls require explicit credentials. We believe that the combination \\nof an exokemel interface, hierarchically-named capabilities, and \\nexplicit credentials will simplify the implementation of secure ap- \\nplications, as we hope to demonstrate in future work. \\n5.2 ExOS 1.0 \\nExOS is a 1ibOS that supports most of the abstractions found ln \\n4.4BSD. It runs many unmodified UNIX applications, including all \\nof the applications that are needed to build the complete system \\n(kernel, ExOS, and applications) on itself. It also runs most shells, \\nfile utiIities (WC, grep, Is, vi, etc.), and many networking appli', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 963: ('hierarchically-named capabilities, and \\nexplicit credentials will simplify the implementation of secure ap- \\nplications, as we hope to demonstrate in future work. \\n5.2 ExOS 1.0 \\nExOS is a 1ibOS that supports most of the abstractions found ln \\n4.4BSD. It runs many unmodified UNIX applications, including all \\nof the applications that are needed to build the complete system \\n(kernel, ExOS, and applications) on itself. It also runs most shells, \\nfile utiIities (WC, grep, Is, vi, etc.), and many networking applica- \\ntions (telnetd, ftp, etc.). The most salient missing functions are full \\npaging, process swapping, process groups, and a windowing sys- \\ntem. There is no fundamental reason why these are not supported; \\nwe simply have not yet had the time to implement or port them. On \\n58 \\nAegis, for instance, ExOS supported full paging to disk and over \\nthe network. \\nThe primary goals of ExOS are simplicity and flexibility. To al- \\nlow applications to override any implementation feature, we made \\nthe system entirely library based, rather than place objects such as \\nprocess tables in non-customizable servers. As a result, customiza- \\ntion of the resulting system is limited only by an application’s un- \\nderstanding of the system interfaces and by the protection enforced \\nby shared abstractions-any ExOS functionality can be replaced by \\napplication-specific code. \\nThe two primary caveats of the current implementation are that \\nthe system is research, not production quality and that it uses shared \\nglobal state for some abstractions. These limitations are not funda- \\nmental and we do not expect removing either caveat to have a \\nsignificant impact on our results. To compensate for the effects of \\nshared state on performance, measurements in Sections 6 and 8 \\ninclude the cost of inserting system calls before all writes to shared \\nstate. This represents the overhead of invoking the kernel to check \\nwrites to shared state. \\n52.1 Implementing UNIX abstractions on Xok \\nTo implement UNIX abstractions in a library, we partitioned mos', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 964: ('tractions. These limitations are not funda- \\nmental and we do not expect removing either caveat to have a \\nsignificant impact on our results. To compensate for the effects of \\nshared state on performance, measurements in Sections 6 and 8 \\ninclude the cost of inserting system calls before all writes to shared \\nstate. This represents the overhead of invoking the kernel to check \\nwrites to shared state. \\n52.1 Implementing UNIX abstractions on Xok \\nTo implement UNIX abstractions in a library, we partitioned most \\nof the UNIX kernel state and made it private to each process. The \\nremainder is shared. Most critical shared state (inode table, file sys- \\ntem metadata, page tables, buffer cache, process table, and pipes), is \\nprotected using Xok’s protections mechanisms. However, for some \\nshared state (the process map, file descriptor table, sockets, ‘ITYs, \\nmount table, and system V shared memory table), ExOS uses shared \\nmemory, Using software regions, we plan to make this shared state \\nfully protected in the near future. A limited degree of fault isola- \\ntion is provided for these abstractions by mapping shared data at \\naddresses far from the application text and dam. \\nProcesses, The process map maps UNIX process identifiers to \\nXok environment numbers using a shared table. The process table \\nrecords the process identifiers of each process, that of its parent, the \\narguments with which the process was called, its run status, and the \\nidentity of its children. The table is partitioned across application- \\nreserved memory of Xok’s environment structure, which is mapped \\nreadable for all processes and writeable for only the environment’s \\nowning process. ExOS uses Xok’s IPC to safely update parent and \\nchild process state. The UNIX ps (process status) program is im- \\nplemented by reading all the entries of the process table. \\nUNIX provides the fork system call to duplicate the current \\nprocess and exec to overlay it with another. Exec is implemented by \\ncreating a new address space for the new process, loading on demand ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 965: ('mory of Xok’s environment structure, which is mapped \\nreadable for all processes and writeable for only the environment’s \\nowning process. ExOS uses Xok’s IPC to safely update parent and \\nchild process state. The UNIX ps (process status) program is im- \\nplemented by reading all the entries of the process table. \\nUNIX provides the fork system call to duplicate the current \\nprocess and exec to overlay it with another. Exec is implemented by \\ncreating a new address space for the new process, loading on demand \\nthe disk image of the process into the new address space, and then \\ndiscarding the address space that called exec. Implementing forkin \\na library is peculiar since it requires that a process create a replica \\nof its address space and state while it is executing. To make fork \\nefficient, ExOS uses copy-on-write to lazily create separate copies \\nof the parent’s address space. ExOS scans through its page tables, \\nwhich are exposed by Xok, marking all pages as copy-on-write \\nexcept those data segment and stack pages that thefork call itself is \\nusing. These pages must be duplicated so as not to generate copy- \\non-write faults while running thefork and page fault handling code. \\nGroups of page table entries are updated at once by batching system \\ncalls to amortize the system call overhead over many updates. \\nInter-process communication. UNIX defines a variety of in- \\nterprocess communication primitives: signals (software interrupts \\nthat can be sent between processes or to a process itself), pipes \\n(producer-consumer untyped message queues), and sockets (differ- \\ning from pipes in that they can be established between non-related \\nprocesses, potentially executing on different machines). \\nSignals are layered on top of Xok IPC. Pipes are implemented \\nusing Xok’s software regions, coupled with a “directed yield” to the \\nother party when it is required to do work (i.e., if the queue is full or empty). Sockets communicating on the same machine are currently \\nimplemented using a shared buffer. \\nInter-machine sockets are i', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 966: ('umer untyped message queues), and sockets (differ- \\ning from pipes in that they can be established between non-related \\nprocesses, potentially executing on different machines). \\nSignals are layered on top of Xok IPC. Pipes are implemented \\nusing Xok’s software regions, coupled with a “directed yield” to the \\nother party when it is required to do work (i.e., if the queue is full or empty). Sockets communicating on the same machine are currently \\nimplemented using a shared buffer. \\nInter-machine sockets are implemented through user-level net- \\nwork libraries for UDP and TCP. The network libraries are imple- \\nmented using Xok’s timers, upcalls, and packet rings, which allow \\nprotected buffering of received network packet, \\nFile descriptors. File descriptors are small integers used to ac- \\ncess many UNIX resources (e.g., files, sockets, pipes). On ExOS \\nthey name entries in a global file descriptor table, which is cur- \\nrently stored in shared memory. As in the UNIX kernel itself, ExOS \\naccesses each table element in an object-oriented manner: each \\nresource is associated with a table of pointers to functions imple- \\nmenting each operation (read, write, etc.). However, unlike UNIX, \\nExOS allows applications to install their own methods. \\nFiles. Local files are accessed through C-FFS, which uses XN to \\nprotect file metadata; remote files are accessed through the Network \\nFileSystem protocol (NFS) [38]. Both filesystems arelibrary based. \\nExOS uses XN’s buffer cache registry to safely share both C-FFS \\nand NFS disk blocks. \\nUNIX allows different file systems to he attached to its hierarchi- \\ncal name space. ExOS duplicates this functionality by maintaining \\na currently unprotected shared mount table that maps directories \\nfrom one file system to another. \\n5.2.2 Shared libraries \\nSince ExOS is implemented as a library, shared libraries are cru- \\ncial. Without shared libraries, every application would contain its \\nown copy of ExOS, wasting memory and making process creation \\nexpensive. We employ a simple but primitive sc', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 967: ('locks. \\nUNIX allows different file systems to he attached to its hierarchi- \\ncal name space. ExOS duplicates this functionality by maintaining \\na currently unprotected shared mount table that maps directories \\nfrom one file system to another. \\n5.2.2 Shared libraries \\nSince ExOS is implemented as a library, shared libraries are cru- \\ncial. Without shared libraries, every application would contain its \\nown copy of ExOS, wasting memory and making process creation \\nexpensive. We employ a simple but primitive scheme for shared \\nlibraries. ExOS is linked as a stand-alone executable with its base \\naddress starting at a reserved section of the application’s address \\nspace. Its exported symbols are then extracted and stored in an as- \\nsembly file. To resolve calls to library routines, the application links \\nagainst this assembly file. During process creation the application \\nis loaded and ExOS maps the library at its indicated address. \\nThis organization separates the file that the 1ibOS resides in from \\napplications, allowing multiple applications to share the same on- \\ndisk copy and, more importantly, any cached disk blocks from this \\nfile. Code sharing reduces the size of ExOS executables to roughly \\nthat of normal UNIX applications. Unlike traditional dynamic link- \\ning, procedure calls are no more expensive than for normal code \\nsince they do not require the use of a relocation table. \\n6 Application Performance on Xok \\nThis section shows that unmodified UNIX applications run as fast \\non XokiExOS as on conventional centralized operating systems. In \\nfact, because of C-FFS, some applications run considerably faster \\non XowExOS. We compare Xok/ExOS to both FreeBSD 2.2.2 and \\nOpenBSD 2.1 on the same hardware. Xok uses device drivers that \\nare derived from those of OpenBSD. ExOS also shares a large \\nsource code base with OpenBSD, including most applications and \\nmost of libc. Compared to OpenBSD and FreeBSD, ExOS has not \\nhad much time to mature; we built the system in less than two years \\nand moved to the x86 platform on', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 968: ('centralized operating systems. In \\nfact, because of C-FFS, some applications run considerably faster \\non XowExOS. We compare Xok/ExOS to both FreeBSD 2.2.2 and \\nOpenBSD 2.1 on the same hardware. Xok uses device drivers that \\nare derived from those of OpenBSD. ExOS also shares a large \\nsource code base with OpenBSD, including most applications and \\nmost of libc. Compared to OpenBSD and FreeBSD, ExOS has not \\nhad much time to mature; we built the system in less than two years \\nand moved to the x86 platform only a year ago. \\nAll experiments are performed on 200-MHz Intel Pentium Pro \\nprocessors with a 256~KByte on-chip L2 cache and 64MByte of \\nmain memory. The disk system consists of an NCR 815 SCSI con- \\ntroller connecting a fast SCSI chain with one or more Quantum \\nAtlas XP32150 disk drives to the PC1 bus (vs44Ofx PC1 chip set). \\nReported times are the minimum time of ten trials (the standard \\ndeviations of the total run times are less than three percent). \\nThe measurements establish two results. First, the base per- \\nformance of unaltered UNIX applications linked against ExOS is \\ncomparable to OpenBSD and FreeBSD. Untrusted 1ibOSe.s on an \\nexokemel can support unchanged UNIX applications with the same \\n59 \\nperformance as centralized monolithic UNIX operating systems. \\nSecond, because of ExOS’s high-performance file system, some \\nunaltered UNIX applications perform better on ExOS than on Free- \\nBSD and OpenBSD. Applications do not need to be re-written or \\neven modified in order to take advantage of an exokemel. \\nIt is important to note that a sufficiently motivated kernel pro- \\ngrammer can implement any optimization that is implemented in \\nan extensible system. In fact, a member of our research group, \\nCosta Sapuntzakis, has implemented a version of C-FFS within \\nOpenBSD. Extensible systems (and we believe exokemels in par- \\nticular) make these optimizations significantly easier to implement \\nthan centralized systems do. For example, porting C-FFS to Open- \\nBSD took more effort than designing C-FFS and implementi', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 969: (' \\nIt is important to note that a sufficiently motivated kernel pro- \\ngrammer can implement any optimization that is implemented in \\nan extensible system. In fact, a member of our research group, \\nCosta Sapuntzakis, has implemented a version of C-FFS within \\nOpenBSD. Extensible systems (and we believe exokemels in par- \\nticular) make these optimizations significantly easier to implement \\nthan centralized systems do. For example, porting C-FFS to Open- \\nBSD took more effort than designing C-FFS and implementing it \\nas a library file system. The experiments below demonstrate that \\nby using unprivileged application-level resource management, any \\nskilled programmer can implement useful OS optimizations. The \\nextra layer of protection required to make this application-level \\nmanagement safe costs little. \\n6.1 Base system performance \\nWe test ExOS’s base performance by running the I/O-intensive \\nbenchmarks from Table 1 over ExOS’s library implementation of \\nC-FFS on top of XN and comparing it to OpenBSD with a C-FFS \\nfile system. The workload in the experiments represents unmodi- \\nfied UNIX programs involved with installing a software package: \\ncopying a compressed archive file, uncompressing it, unpacking it \\n(which results in a source tree), copying the resulting tree, com- \\nparing the two trees, compiling the source tree, deleting binaries, \\narchiving the source tree, compressing the archive file, and deleting \\nthe source tree (see Table 1). \\nFigure 2 shows the performance of these applications over \\nXok/ExOS, OpenBSDIC-FFS, OpenBSD, and FreeBSD. To es- \\ntablish base system performance, we compare Xok/ExOS with \\nOpenBSDK-FSS, since they both use a C-FFS file system. The total \\nrunning time for Xok/ExOS is 41 seconds and for OpenBSDK-FFS \\nis 51 seconds. Since ExOS and OpenBSDK-FFS use the same type \\nof file system, one would expect that ExOS and OpenBSD perform \\nequally well.- As can be seen in Figure 2, Xok/ExOS performance \\nis indeed comparable to OpenBSDIC-FFS on eight of the 11 ap- \\nplications. On three applicati', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 970: ('nBSDIC-FFS, OpenBSD, and FreeBSD. To es- \\ntablish base system performance, we compare Xok/ExOS with \\nOpenBSDK-FSS, since they both use a C-FFS file system. The total \\nrunning time for Xok/ExOS is 41 seconds and for OpenBSDK-FFS \\nis 51 seconds. Since ExOS and OpenBSDK-FFS use the same type \\nof file system, one would expect that ExOS and OpenBSD perform \\nequally well.- As can be seen in Figure 2, Xok/ExOS performance \\nis indeed comparable to OpenBSDIC-FFS on eight of the 11 ap- \\nplications. On three applications (pax, cp, diff), Xok/ExOS runs \\nconsiderably faster (though we do not yet have a good explanation \\nfor this). \\nFrom these measurements we conclude that, even though ExOS \\nimplements the bulk of the operating system at the application level, \\ncommon software development operations on XokLExOS perform \\ncomparably to OpenBSD/C-FFS. They demonstrate that-at least \\nfor this common domain of applications-an exokemel’s flexibility \\ncan be provided for free: even without aggressive optimizations \\nExOS’s performance is comparable to that of mature monolithic \\nsystems. The cost of low-level multiplexing is negligible. \\n6.2 Invisible optimization using C-FFS \\nThese comparisons concentrate on I/O intensive operations that \\nexploit the C-FFS library file system [15]. We again use the UO- \\nintensivebenchmarksdescribedinTable 1,butnow compareXoWC- \\nFFS with OpenBSD and FreeBSD. As Figure 2 shows, unaltered \\nUNIX applications can run significantly faster on top of Xok/ExOS. \\nXok/ExOS completes all benchmarks in 41 seconds, 19 seconds \\nfaster than FreeBSD and OpenBSD. On eight of the eleven bench- \\nmarks Xok/ExOS performs better than Free/OpenBSD (in one case \\nby over a factor of four). ExOS’s performance improvements are \\ndue to its C-FFS file system. \\nWe also ran the Modified Andrew Benchmark (MAB) [33]. \\nOn this benchmark, Xok/ExOS takes 11.5 seconds, OpenBSDK- \\nFFS takes 12.5 seconds, OpenBSD takes 14.2 seconds, and Free- copy the compressed archived source tree (cp) \\nrecursively copy the created directories (cp). \\ncomp', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 971: ('s, 19 seconds \\nfaster than FreeBSD and OpenBSD. On eight of the eleven bench- \\nmarks Xok/ExOS performs better than Free/OpenBSD (in one case \\nby over a factor of four). ExOS’s performance improvements are \\ndue to its C-FFS file system. \\nWe also ran the Modified Andrew Benchmark (MAB) [33]. \\nOn this benchmark, Xok/ExOS takes 11.5 seconds, OpenBSDK- \\nFFS takes 12.5 seconds, OpenBSD takes 14.2 seconds, and Free- copy the compressed archived source tree (cp) \\nrecursively copy the created directories (cp). \\ncompute the difference between the trees (dift) \\nCompile 1 compile source code (gee) \\nDelete files 1 delete binarv tiles cm11 I \\n1 Packtree I archive the tree hxd 1 \\nCompress 1 compress the Ghivd tree (gzip) \\nDelete 1 delete the created source tree (rm) \\nTable 1: TheI/O-intensive workload installs a large application (the \\nICC compiler). The size of the compressed archive file for ICC is 1.1 \\nMByte. \\n23.121.6 \\n23.0 23.2 \\ncp gunzip cp pax cp diff gee rm pax gzlp rm \\nUnmodified UNIX Programs \\nFigure 2: Performance of unmodified UNIX applications, \\nXok/ExOS and OpenBSDIC-FFS use a C-FFS file system while \\nFree/OpenBSD use their native FFS file systems. Times are in scc- \\nonds. \\nBSD takes 11.5 seconds. The difference in performance on MAB IS \\nless profound than on the I/O-intensive benchmark, because MAB \\nstresses fork, an expensive function in Xok/ExOS. ExOS’s fork per- \\nformance suffers because Xok does not yet allow environments to \\nshare page tables. Fork takes six milliseconds on ExOS, compared \\nto less than one millisecond on OpenBSD. \\n6.3 The cost of protection \\nIn this section, we investigate the cost of protection on Xok/ExOS, \\nAs discussed in the previous section, we have not yet complctcd \\nthe protected implementation of all data structures. ExOS stores \\nsome tables in writeable global shared memory, includingthe lllc \\ndescriptor table. In order for our measurements to estimate the \\nperformance of a fully protected ExOS, we inserted three system \\ncalls before every write to these shared tables. All measureme', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 972: (' millisecond on OpenBSD. \\n6.3 The cost of protection \\nIn this section, we investigate the cost of protection on Xok/ExOS, \\nAs discussed in the previous section, we have not yet complctcd \\nthe protected implementation of all data structures. ExOS stores \\nsome tables in writeable global shared memory, includingthe lllc \\ndescriptor table. In order for our measurements to estimate the \\nperformance of a fully protected ExOS, we inserted three system \\ncalls before every write to these shared tables. All measurements \\nreported in Section 6 include these extra calls. \\nTo measure the costs of all protection we ran the benchmarks \\npresented in Figure 2 without XN or any of the extra system calls, \\nThis reduces the overall number of Xok system calls from 300,000 \\nto 81,000, but only changes the total running time from 41.1 seconds \\nto 39.7 seconds. Real workloads are dominated by costs other than \\nsystem call overhead. \\nTo investigate the cost of protection in more detail, we measure \\nthe cost of the protection mechanisms described in Section 3. WC do \\nso by comparing two implementations of pipes (see Table 2). The \\nfirst implementation places all data in shared memory and performs \\nno sanity checking. The second implementation uses software rc- \\ngions to protect pipe data and installs a wakeup predicate on every \\n60 \\nBenchmark 1 Sharedmemory j Protection 1 OpenBSD \\n1 Latency 1-bvte I 13 \\nLatency S-I&e 1 I 30 I 34 \\n150 1 148 1 160 \\nTable 2: The cost of a local-trust implementation of pipes (times in \\nmicroseconds). \\nread (something unnecessary even with mutual distrust). The results \\nshow that even with gratuitous use of Xok’s protection mechanisms, \\nuser-level pipes can still outperform OpenBSD. \\n7 Exploiting Extensibility in Applications \\nThis. section demonstrates some of the interesting possibilities in \\nfunctionality and performance enabled by application-level resource \\nmanagement. We report on a binary emtdator, a “zero-touch” file- \\ncopy program, and the Cheetah web server. Because XN was de- \\nveloped recently, the ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 973: ('(something unnecessary even with mutual distrust). The results \\nshow that even with gratuitous use of Xok’s protection mechanisms, \\nuser-level pipes can still outperform OpenBSD. \\n7 Exploiting Extensibility in Applications \\nThis. section demonstrates some of the interesting possibilities in \\nfunctionality and performance enabled by application-level resource \\nmanagement. We report on a binary emtdator, a “zero-touch” file- \\ncopy program, and the Cheetah web server. Because XN was de- \\nveloped recently, the applications in this section were not measured \\nwith Xl?. \\n7.1 Fast, simple binary emuiation \\nXok provides facilities to efficiently reroute specific INT instrnc- \\ntions. We have used this ability to build a binary emulator for Open- \\nBSD applications by capturing the system calls made by emulated \\nOpenBSD programs. This binary emulator is useful for OpenBSD \\nprograms for which we do not have source code. Although the \\nemulator is only partially completed (it supports 90 of the approxi- \\nmately 155 OpenBSD system calls), initial results are promising: it \\nhas been able to execute large programs such as Mosaic. \\nThe main interesting feature of the emulator is that it runs in the \\nsame address space as the emmated program, and consequently does \\nnot need any privilege. Measurements show that most programs on \\nthe emulator run only a few percent slower than the same programs \\nrunning directly under XokiExOS. \\nA counter-intuitive result is that, because the emulator runs in \\nthe same address space as ExOS, it is possible to run emulated \\nprograms faster than on their native OS. For example, the trivial \\n“get process id” system call takes 270 cycles on OpenBSD and 100 \\ncycles on the emulator running on Xok/ExOS (on a 120-MHz Intel \\nPentium). This difference comes from the fact that the emulator \\nreplaces OpenBSD system calls with procedure calls into ExOS. \\nExOS can omit many expensive checks that UNIX must perform \\nin order to guard against application errors (on an exokemel, if \\nan application passes the wrong arg', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 974: ('possible to run emulated \\nprograms faster than on their native OS. For example, the trivial \\n“get process id” system call takes 270 cycles on OpenBSD and 100 \\ncycles on the emulator running on Xok/ExOS (on a 120-MHz Intel \\nPentium). This difference comes from the fact that the emulator \\nreplaces OpenBSD system calls with procedure calls into ExOS. \\nExOS can omit many expensive checks that UNIX must perform \\nin order to guard against application errors (on an exokemel, if \\nan application passes the wrong arguments to a libOS, only the \\napplication will be affected). \\n7.2 XCP: a “zero-touch” fiIe copying program \\nXCP is an efficient file copy program. It exploits the low-level disk \\ninterface by removing artificial ordering constraints, by improv- \\ning disk scheduling through large schedules, by eliminating data \\ntouching by the CPU, and by performing all disk operations asyn- \\nchronously. \\nGiven a list of files, XCP works as follows. First, it enumerates \\nand sorts the disk blocks of all files and issues large, asynchronous \\ndisk reads using this schedule. (If multiple instances of XCP run \\nconcurrently, the disk driver will merge the schedules.) Second, it \\ncreates new files of the correct size, overlapping inode and disk \\nblock allocation with the disk reads. Finally, as the disk reads com- \\nplete, it constructs large writes to the new disk blocks using the \\nbuffer cache entries. This strategy eliminates all copies; the file is \\nDMAed into and out of the buffer cache by the disk controller-the \\nCPU never touches the data. \\nXCP is a factor of three faster than the copy program (CP) on \\nXok/ExOS that uses UNIX interfaces, irrespective of whether all files are in core (because XCP does not touch the data) or on disk \\n(because XCP issues disk schedules with a minimum number of \\nseeks and the largest contiguous ranges of disk blocks). \\nThe fact that the file system is an application library allows us \\nboth to have integration when appropriate and to craft new abstrac- \\ntions as needed. This latter ability is especial', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 975: ('es the data. \\nXCP is a factor of three faster than the copy program (CP) on \\nXok/ExOS that uses UNIX interfaces, irrespective of whether all files are in core (because XCP does not touch the data) or on disk \\n(because XCP issues disk schedules with a minimum number of \\nseeks and the largest contiguous ranges of disk blocks). \\nThe fact that the file system is an application library allows us \\nboth to have integration when appropriate and to craft new abstrac- \\ntions as needed. This latter ability is especially profitable for the disk \\nboth because of the high cost of disk operations and because of the \\ndemonstrated reluctance of operating systems vendors to provide \\nuseful, simple improvements to their interfaces (e.g., prefetching, \\nasynchronous reads and writes, fine-grained disk restructuring and \\n“sync” operations). \\n7.3 The Cheetah HTTP/l.0 Server \\nThe exokemel architecture is well suited to building fast servers \\n(e.g., for NFS servers or web servers). Server performance is cru- \\ncial to client/server applications [23], and the I/O-centric nature of \\nservers makes operating system-based optimizations profitable. \\nWe have developed an extensible I/O library (XIO) for fast \\nservers and a sample application that uses it, the Cheetah HTIP \\nserver. This Iibrary is designed to alIow appIication writers to exploit \\ndomain-specificknowledgeand to simplify the construction of high- \\nperformance servers by removing the need to “trick” the operating \\nsystem into doing what the application requires (e.g., Harvest [7] \\nstores cached pages in multiple directories to achieve fast name \\nlookup). \\nAn HTTP server’s task is simple: given a client request, it finds \\nthe appropriate document and sends it. The Cheetah Web server \\nperforms the following set of optimizations as well as others not \\nlisted here. \\nMerged File Cache and Retransmission Pool. Cheetah avoids \\nall in-memory data touching (by the CPU) and the need for a distinct \\nTCP retransmission pool by transmitting file data directly from the \\nfile cache using precomput', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 976: ('\\nstores cached pages in multiple directories to achieve fast name \\nlookup). \\nAn HTTP server’s task is simple: given a client request, it finds \\nthe appropriate document and sends it. The Cheetah Web server \\nperforms the following set of optimizations as well as others not \\nlisted here. \\nMerged File Cache and Retransmission Pool. Cheetah avoids \\nall in-memory data touching (by the CPU) and the need for a distinct \\nTCP retransmission pool by transmitting file data directly from the \\nfile cache using precomputed file checksums (which are stored with \\neach file). Data are transmitted (and retransmitted, if necessary) to \\nthe client directly from the file cache without CPU copy operations. \\n(Pai et al. have also used this technique [34].) \\nKnowledge-based Packet Merging. Cheetah exploits knowl- \\nedge of its per-request state transitions to reduce the number of I/O \\nactions it initiates. For example, it avoids sending redundant control \\npackets by delaying ACKs on client HTTP requests, since it knows \\nit will be able to piggy-back them on the response. This optimiza- \\ntion is particularly valuable for small document sizes, where the \\nreduction represents a substantial fraction (e.g., 20%) of the total \\nnumber of packets. \\nHTML-based File Grouping. Cheetahco-Iocates files included \\nin an HTML document by allocating them in disk blocks adjacent \\nto that file when possible. When the file cache does not capture \\nthe majority of client requests, this extension can improve HTTP \\nthroughput by up to a factor of two. \\nFigure 3 shows HTTP request throughput as a function of the re- \\nquested document size for five servers: the NCSA 1.4.2 server [32] \\nrunning on OpenBSD 2.0, the Harvest cache [7] running on Open- \\nBSD 2.0, the base socket-based server running on OpenBSD 2.0 \\n(i.e., our HTTP server without any optimizations), the base socket- \\nbased server running on the Xok exokemel system (i.e., our H’lTP \\nserver without any optimizations with vanilla socket and file de- \\nscriptor implementations layered over XIO), and the Cheet', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 977: (' 3 shows HTTP request throughput as a function of the re- \\nquested document size for five servers: the NCSA 1.4.2 server [32] \\nrunning on OpenBSD 2.0, the Harvest cache [7] running on Open- \\nBSD 2.0, the base socket-based server running on OpenBSD 2.0 \\n(i.e., our HTTP server without any optimizations), the base socket- \\nbased server running on the Xok exokemel system (i.e., our H’lTP \\nserver without any optimizations with vanilla socket and file de- \\nscriptor implementations layered over XIO), and the Cheetah server \\nrunning on the Xok exokemel (i.e., our HTTP server with all opti- \\nmizations enabled). \\nFigure 3 provides several important pieces of information. First, \\nourba.seHTTPserverperformsroughlyaswellas theHarvestcache, \\nwhich has been shown to outperform many other HTTP server im- \\nplementations on general-purpose operating systems. Both outper- \\nform the NCSA server. This gives us a reasonable starting point \\nfor evaluating extensions that improve performance. Second, the \\ndefault socket and file system implementations built on top of XI0 \\n61 \\n-NCSABSD \\n-Han’esUSSD \\n-SockeUSSD \\n-Socket/X?k \\n-Cheetah \\nFigure 3: HTTP document throughput as a function of the doc- \\nument size for several HTTP/1.0 servers. NCSA/BSD represents \\nthe NCSA1l.4.2 server running on OpenBSD. Harvest/BSD repre- \\nsents the Harvest proxy cache running on OpenBSD. Socket/BSD \\nrepresents our HTTP server using TCP sockets on OpenBSD. \\nSocket/Xok represents our I-ITI‘P server using the TCP socket \\ninterface built on our extensible TCP/IP implementation on the \\nXok exokemel. Cheetab/Xok represents the Cheetah HTIP server, \\nwhich exploits the TCP and file system implementations for speed. \\nperform significantly better than the OpenBSD implementations of \\nthe same interfaces (by SO-loo%). The improvement comes mainly \\nfrom simple (though generally valuable) extensions, such as packet \\nmerging, application-level caching of pointers to file cache blocks, \\nand protocol control block reuse. \\nThird, and most importantly, Cheetah significantly outp', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 978: (' implementation on the \\nXok exokemel. Cheetab/Xok represents the Cheetah HTIP server, \\nwhich exploits the TCP and file system implementations for speed. \\nperform significantly better than the OpenBSD implementations of \\nthe same interfaces (by SO-loo%). The improvement comes mainly \\nfrom simple (though generally valuable) extensions, such as packet \\nmerging, application-level caching of pointers to file cache blocks, \\nand protocol control block reuse. \\nThird, and most importantly, Cheetah significantly outperforms \\nthe servers that use traditional interfaces. By exploiting Xok’s exten- \\nsibility, Cheetah gains a four times performance improvement for \\nsmall documents (1 KByte and smaller), making it eight times faster \\nthan the best performance we could achieve on OpenBSD. Further- \\nmore, the large document performance for Cheetah is limited by \\nthe available network bandwidth (three lOOMbit/s Ethernet@ rather \\nthan by the server hardware. While the socket-based implementa- \\ntion is limited to only 16.5 MByte/s with 100% CPU utilization, \\nCheetah delivers over 29.3 MByte/s with the CPU idle over 30% of \\nthe time. The extensibility of ExOS’s default unprivileged TCP/IP \\nand file system implementations made it possible to achieve these \\nperformance improvements incrementally and with low complexity. \\nThe optimizations performed by Cheetah are architecture inde- \\npendent. In Aegis, Cheetah obtained similar performance improve- \\nments over Ultrix web servers [24]. \\n8 Global Performance \\nXok/ExOS’s decentralization of resource management allows the \\nperformance of individual applications to be improved, but Xok/ \\nExOS must also guarantee good global performance when running \\nmultiple applications concurrently. The experiments in this section \\nmeasure the situation where the exokemel architecture seems po- \\ntentially weak: under substantial load where selfish applications are \\nconsuming large resources and utilizing I/O devices heavily. The \\nresults indicate that an exokemel can successfully reconcile local \\ncontrol wi', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 979: ('of resource management allows the \\nperformance of individual applications to be improved, but Xok/ \\nExOS must also guarantee good global performance when running \\nmultiple applications concurrently. The experiments in this section \\nmeasure the situation where the exokemel architecture seems po- \\ntentially weak: under substantial load where selfish applications are \\nconsuming large resources and utilizing I/O devices heavily. The \\nresults indicate that an exokemel can successfully reconcile local \\ncontrol with global performance. \\nGlobal performance has not been extensively studied. We use \\nthe total time to complete a set of concurrent tasks as a measure of \\nsystem throughput, and the minimum and the maximum latency of \\nindividual applications as a measure of interactive performance. For \\nsimplicity we compare Xok/ExOS’s performance under high load to \\nthat of FreeBSD; in these experiments, FreeBSD always performs \\nbetter than OpenBSD, because of OpenBSD’s small, non-unified \\nbuffer cache. While this Fethodology does not guarantee that an Ol-Otal \\n--Max \\n-hlln Ill-l Ill-l rlrl \\n2814 \\nmXoklExOS and FreeBSd \\nFigure 4: Measured global performance of Xok/ExOS (the tlrst \\nbar) and FreeBSD (the second bar), using the first application pool. \\nTimes arein seconds and on alog scale. number/nl#berrefcrs to tho \\nthe total number of applications run by the script and the maximum \\nnumber of jobs run concurrently. Total is the total running timo of \\neach experiment, Max is the longest runtime of any process in a \\ngiven run (giving the worst latency). Mln is the minimum. \\nexokemel can compare to any centralized system, it does offer a \\nuseful relative metric. \\nThe space of possible combinations of applications to run is \\nlarge. The experiments use randomization to ensure we get a rca- \\nsonable sample of this space. The inputs are a set of applications to \\npick from, the total number to run, and the maximum number that \\ncan be running concurrently. Each experiment maintains the num- \\nber of concurrent processes at the specified ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 980: ('giving the worst latency). Mln is the minimum. \\nexokemel can compare to any centralized system, it does offer a \\nuseful relative metric. \\nThe space of possible combinations of applications to run is \\nlarge. The experiments use randomization to ensure we get a rca- \\nsonable sample of this space. The inputs are a set of applications to \\npick from, the total number to run, and the maximum number that \\ncan be running concurrently. Each experiment maintains the num- \\nber of concurrent processes at the specified maximum. The outputs \\nare the total running time, giving throughput, and the time to run \\neach application. Poor interactive performance will show up as a \\nhigh minimum latency. \\nThe first application pool includes a mix of I/O-intensive and \\nCPU-intensive programs: pack archive (pax -w), search for a word \\nin a large file &rep), compute a checksum many times over a small \\nset of files (&sum), solve a traveling salesman problem (tsp), solvo \\niteratively a large discrete Laplace equation using successive over- \\nrelaxation @or), count words (WC), compile (gee), compress (gzlp), \\nand uncompress (gunzip). For this experiment, we chose applica- \\ntions on which both Xok/ExOS and FreeBSD run roughly equiva- \\nlently. Each application runs for at least several seconds and IS run \\nin a separate directory from the others (to avoid cooperative buffer \\ncache reuse). The pseudo-random number generators are identical \\nand start with the same seed, thus producing identical schedules, \\nThe applications we chose compete for the CPU, memory, and the \\ndisk. \\nFigure 4 shows on a log scale the results for five diffcrcnt cx- \\nperiments: seven jobs with a maximum concurrency of one job \\nthrough 35 jobs with a maximum concurrency of five jobs. Tho \\nresults show that an exokemel system can achieve performance \\nroughly comparable to UNIX, despite being mostly untuned for \\nglobal performance. \\nWith a second application pool, we examine global performance \\nwhen specialized applications (emulated by applications that benc- \\nfit from C-FFS’s', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 981: ('e CPU, memory, and the \\ndisk. \\nFigure 4 shows on a log scale the results for five diffcrcnt cx- \\nperiments: seven jobs with a maximum concurrency of one job \\nthrough 35 jobs with a maximum concurrency of five jobs. Tho \\nresults show that an exokemel system can achieve performance \\nroughly comparable to UNIX, despite being mostly untuned for \\nglobal performance. \\nWith a second application pool, we examine global performance \\nwhen specialized applications (emulated by applications that benc- \\nfit from C-FFS’s performance advantages) compete with each other \\nand non-specialized applications. This pool includes tsp and sor \\nfrom above, unpack archive (pax -r) from Section 6, recursive copy \\n(cp -r) from Section 6, and comparison (diff) of two identical 5 MB \\nfiles. The pax and cp applications represent the specialized applica- \\ntions. \\nFigure 5 shows on a log scale the results for five experiments: \\nseven jobs with amaximum concurrency of one job through 35 jobs \\nwith amaximum concurrency of 5 jobs. The results show that global \\nperformance on an exokemel system does not degrade oven when \\n62 \\nI OTOtal \\nn l-l l-l \\n0 \\n14l2 2113 2W4 35l5 \\nXokExOS and FrfteBSD \\nFigure 5: Measured global performance of Xok/ExOS (the first bar) \\nand FreeBSD (the second bar), using the second application pool. \\nMethodology and presentation are as described for Figure 4. \\nsome applications use resources aggressively. In fact, the relative \\nperformance difference between FreeBSD and Xok/ExOS increases \\nwith job concurrency. \\nThe central challenge in an exokemel system is not enforcing \\na global system policy but, rather, deriving the information needed \\nto decide what enforcement involves and doing so in such a way \\nthat application flexibility is minimally curtailed. Since an exo- \\nkernel controls resource allocation and revocation, it has the power \\nto enforce global policies. Quota-based schemes, for instance, can \\nbe trivially enforced using only allocation denial and revocation. \\nFortunately, the crudeness of successful global optimizat', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 982: ('allenge in an exokemel system is not enforcing \\na global system policy but, rather, deriving the information needed \\nto decide what enforcement involves and doing so in such a way \\nthat application flexibility is minimally curtailed. Since an exo- \\nkernel controls resource allocation and revocation, it has the power \\nto enforce global policies. Quota-based schemes, for instance, can \\nbe trivially enforced using only allocation denial and revocation. \\nFortunately, the crudeness of successful global optimizations al- \\nlows global schemes to be readily implemented by an exokemel. \\nFor example, Xok currently tracks global LRU information that \\napplications can use when deallocating resources. \\nWe believe that an exokemel can provide global performance \\nsuperior to current systems. First, effective local optimization can \\nmean there are more resources for the entire system. Second, an \\nexokemel gives application writers machinery to orchestrate inter- \\napplication resource management, allowing them to perform domain- \\nspecific global optimizations not possible on current centralized \\nsystems (e.g., the UNIX “make” program could be modified to \\norchestrate the complete build process). Third, an exokemel can \\nunify the many space-partitioned caches in current systems (e.g., \\nthe buffer cache, network buffers, etc.). Fourth, since applications \\ncan know when resources are scarce, they can make better use of \\nresources when layering abstractions. For example, a web server \\nthat caches documents in virtual memory could stop caching docu- \\nments when its cache does not fit in main memory. Future research \\nwill pursue these issues. \\n9 Experience \\nOver the past three years, we have built three exokemel systems. \\nWe distill our experience by discussing the clear advantages, the \\ncosts, and lessons learned from building exokemel systems. \\n9.1 Clear advantages \\nExposing kernel data strnctores. Allowing 1ibOSes to map kernel \\nand hardware data structures into their address spaces is a powerful \\nextensibility mechanism. (Of course', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 983: ('top caching docu- \\nments when its cache does not fit in main memory. Future research \\nwill pursue these issues. \\n9 Experience \\nOver the past three years, we have built three exokemel systems. \\nWe distill our experience by discussing the clear advantages, the \\ncosts, and lessons learned from building exokemel systems. \\n9.1 Clear advantages \\nExposing kernel data strnctores. Allowing 1ibOSes to map kernel \\nand hardware data structures into their address spaces is a powerful \\nextensibility mechanism. (Of course, these structures must not con- \\ntain sensitive information to which the application lacks privileges.) \\nThe benefits of mapping data structures are two-fold. First, exposed \\ndata structures can be accessed without system call overhead. More \\nimportantly, however, mapping the dam structures directly allows \\n1ibOSes to make use of information the exokemel did not anticipate \\nexporting. Because exposed data structures do not constitute a well-defined \\nAPI, software that directly relies on them (e.g., the hardware ab- \\nstraction layer in a 1ibOS) may need to be recompiled or modified \\nif the kernel changes. This can be seen as a disadvantage. On the \\nother hand, code tie&d by changes in exposed data structures will \\ntypically reside in dynamically-linked IibOSes, so that applications \\nneed not concern themselves with these changes. Moreover, most \\nimprovements that would require kernel modification on a tradi- \\ntional operating systems need only effect 1ibOSes on exokemels. \\nThis is one of the main advantages of the exokemel, as 1ibOSes can \\nbe modified and debugged considerably more easily than kernels. \\nFinally, we expect most changes to the exokemel proper to be along \\nthe lines of new device drivers or hardware-oriented functionality, \\nwhich expose new structures rather than modify existing ones. \\nIn the end, some aggressive applications may not work across \\nall versions of the exokemel, even if they are dynamically linked. \\nThis problem is nothing new, however. A number of UNlX pro- \\ngrams such as top, gated', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 984: ('f the exokemel, as 1ibOSes can \\nbe modified and debugged considerably more easily than kernels. \\nFinally, we expect most changes to the exokemel proper to be along \\nthe lines of new device drivers or hardware-oriented functionality, \\nwhich expose new structures rather than modify existing ones. \\nIn the end, some aggressive applications may not work across \\nall versions of the exokemel, even if they are dynamically linked. \\nThis problem is nothing new, however. A number of UNlX pro- \\ngrams such as top, gated, Isof, and netstat already make use of \\nprivate kernel data structures through the kernel memory device \\n/dev/kraem. Administrators have simply learned to reinstall these \\nprograms whenever major kernel data structures change. \\nThe use of “wakeup predicates” has forcefully driven home the \\nadvantages of exposing kernel data structures. Frequently, we have \\nrequired unusual information about the system. In all cases, this \\ninformation was already provided by the kernel data structures, \\nThe CPU interface. The combination of time slices, initia- \\ntion/termination upcalls, and directed yields has proven its value \\nrepeatedly. (Subsequent to our work, others have found these prim- \\nitives useful [14].) We have used the primitives for inter-process \\ncommunication optimization (e.g., two applications communicat- \\ning through a shared message queue can yield to each other), global \\ngang-scheduling, and robust critical sections (see below). \\nLibrariesaresimplerthankernels.The“edit,compile, debug” \\ncycle of applications is considerably faster than the “edit, compile, \\nreboot, debug” cycle of kernels. A practical benefit of placing OS \\nfunctionality inlibraries is that the “reboot” is replaced by “relink!’ \\nAccumulated over many iterations, this repIacement reduces devel- \\nopment time substantially. Additionally, the fact that the library is \\nisolated from the rest of the system allows easy debugging of ba- \\nsic abstractions. Untrusted user-level servers in microkemel-based \\nsystems also have this benefit. \\n9.2 Costs \\nE', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 985: ('ons is considerably faster than the “edit, compile, \\nreboot, debug” cycle of kernels. A practical benefit of placing OS \\nfunctionality inlibraries is that the “reboot” is replaced by “relink!’ \\nAccumulated over many iterations, this repIacement reduces devel- \\nopment time substantially. Additionally, the fact that the library is \\nisolated from the rest of the system allows easy debugging of ba- \\nsic abstractions. Untrusted user-level servers in microkemel-based \\nsystems also have this benefit. \\n9.2 Costs \\nExokemels are not a panacea, This subsection lists some of the costs \\nwe have encountered. \\nExokemel interface design is not simple. The goal of an exo- \\nkernel system is for privileged software to export interfaces that \\nlet unprivileged applications manage their own resources. At the \\nsame time, these interfaces must offer rich enough protection that \\n1ibOSes can assure themselves of invariants on high-level abstrac- \\ntions. It generally takes several iterations to obtain a satisfactory \\ninterface, as the designer struggles to increase power and remove \\nunnecessary functionality while still providing the necessary level \\nof protection. Most of our major exokemel interfaces have gone \\nthrough multiple designs over several years. \\nInformation loss. Valuable information can be lost by imple- \\nmenting OS abstractions at application level. For instance, if virtual \\nmemory and the file system are completely at application level, \\nthe exokemel may be unable to distinguish pages used to cache \\ndisk blocks and pages used for virtual memory. Glaze, the Fugu \\nexokemel, has the additional complication that it cannot distinguish \\nsuch uses from the physical pages used for buffering messages 1291. \\nFrequently-used information can often be derived with little effort. \\nFor example, if page tables are managed by the application, the \\nexokemel can approximate LRU page ordering by tracking the in- \\nsertion of translations into the TLB. However, at the very least, this \\n63 \\ninference requires thought. \\nSelf-paging 1ibOSes. Self-p', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 986: ('used for virtual memory. Glaze, the Fugu \\nexokemel, has the additional complication that it cannot distinguish \\nsuch uses from the physical pages used for buffering messages 1291. \\nFrequently-used information can often be derived with little effort. \\nFor example, if page tables are managed by the application, the \\nexokemel can approximate LRU page ordering by tracking the in- \\nsertion of translations into the TLB. However, at the very least, this \\n63 \\ninference requires thought. \\nSelf-paging 1ibOSes. Self-paging is difficult (only a few com- \\nmercial operating systems page their kernel). Self-paging lib0Se-s \\nare even more difficult because paging can be caused by external \\nentities (e.g.. the kernel touching a paged-out buffer that a,libOS \\nprovided). Careful planning is necessaryto ensure that 1ibOSes can \\nquickly select and return a page to the exokemel, and that there is \\na facility to swap in processes without knowledge of their internals \\n(otherwise virtual memory customization will be infeasible). \\n9.3 Lessons \\nProvide space for application data in kernel structures. LibOSes \\nareofteneasiertodevelopiftheycanstoresharedstateinkemeldata \\nstructures. In particular, this ability can simplify the task of locating \\nshared state and often avoids awkward (and complex) replication of \\nindexing structures at the application level. For example, Xok lets \\n1ibOSes use the software-only bits of page tables, greatly simplify- \\ning the implementation of copy on write. \\nFast applications do not require good microbenchmark per- \\nformance. The main benefit of an exokemel is not that it makes \\nprimitive operations efficient, but that it gives applications control \\nover expensive operations such as I/O; It is this control that gives \\norder of magnitude performance improvements to applications, not \\nfast system calls. We heavily tuned Aegis to achieve excellent mi- \\ncrobenchmark performance. Xok,’ on the other hand, is completely \\nuntuned. Nevertheless, applications perform well. \\nInexpensive critical sections are useful for Li', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 987: ('k per- \\nformance. The main benefit of an exokemel is not that it makes \\nprimitive operations efficient, but that it gives applications control \\nover expensive operations such as I/O; It is this control that gives \\norder of magnitude performance improvements to applications, not \\nfast system calls. We heavily tuned Aegis to achieve excellent mi- \\ncrobenchmark performance. Xok,’ on the other hand, is completely \\nuntuned. Nevertheless, applications perform well. \\nInexpensive critical sections are useful for LibOSes. In tra- \\nditional OSes, inexpensive critical sections can be implemented by \\ndisabling interrupts [3]. ExOS implements such critical sections by \\ndisabling software interrupts (e.g., time slice termination upcalls). \\nUsing critical sections instead of locks removes the need to com- \\nmunicate to manage a lock, to trust software to acquire and release \\nlocks correctly, and to use complex algorithms to reclaim a lock \\nwhen a process dies while still holding it. This approach has proven \\nto be similarly useful on the Fugu multiprocessor; it is the basis of \\nFugu’s fast message passing. \\nUser-level page tables are complex. If page tables are migrated \\nto user level (as on Aegis), a concerted effort must be made to en- \\nsure that the user’s TLB refill handler can run in unusual situations. \\nThe reason is not performance, but that the naming context pro- \\nvided by virtual memory mappings is a requirement for most useful \\noperations. For example, in the case of downloaded code run in an \\ninterrupt handler, if the kernel is not willing to allow application \\ncode to service TLB misses then there are many situations where \\nthe code will be unable to make progress. User-level page tables \\nmade the implementation of 1ibOSes tricky on Aegis; since the x86 \\nhas hardware page tables, this issue disappeared on XowExOS. \\nDownloaded interrupt handlers are of questionable utility \\non exokernels. Aegis used downloaded code extensively in in- \\nterrupt servicing [44]. The two main benefits are elimination of \\nkernel crossings ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 988: ('the kernel is not willing to allow application \\ncode to service TLB misses then there are many situations where \\nthe code will be unable to make progress. User-level page tables \\nmade the implementation of 1ibOSes tricky on Aegis; since the x86 \\nhas hardware page tables, this issue disappeared on XowExOS. \\nDownloaded interrupt handlers are of questionable utility \\non exokernels. Aegis used downloaded code extensively in in- \\nterrupt servicing [44]. The two main benefits are elimination of \\nkernel crossings and fast upcalls to unscheduled processes, thereby \\nreducing processing latency (e.g., of send-response style network \\nmessages). On current generation chips, however, the latency of I/O \\ndevices is large compared to the overhead of kernel crossings, mak- \\ning the first benefit negligible. The second does not require down- \\nloading code, only anppcall mechanism. In practice, it is the latter \\nability that gives us speed. Downloading interrupt handlers seems \\nmore useful on commercial operating systems with extremely high \\noverhead for kernel crossing than on exokemel systems. It is easier \\nto download interrupt handlers into an existing commercial OS than \\nto turn the commercial OS into an exokemel system. \\nDownloaded code is powerful. Downloaded code lets the ker- \\nnel leave decisions to untrusted software. We have found this dele- \\ngation invaluable in many places. The main benefit of downloaded \\ncode is lrot execution speed, but rather trust and consequently power: \\nThe kernel can invoke downloaded code in cases where it cannot trust application code. For example, packet filters are downloaded \\ncode fragments ,used by applications to claim incoming network \\npackets. Because they are in the kernel, the kernel can inspect them \\nand verity that they do not steal packets intended for other applica- \\ntions. The alternative, asking each application if it claims a given \\npacket, is clearly unworkable; the kernel would not know how deci- \\nsions were made and could not guarantee their correctness. Another \\nexample is', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 989: (' cases where it cannot trust application code. For example, packet filters are downloaded \\ncode fragments ,used by applications to claim incoming network \\npackets. Because they are in the kernel, the kernel can inspect them \\nand verity that they do not steal packets intended for other applica- \\ntions. The alternative, asking each application if it claims a given \\npacket, is clearly unworkable; the kernel would not know how deci- \\nsions were made and could not guarantee their correctness. Another \\nexample is the use of downloaded code for metadata interpretation: \\nsince the kernel can ensure that UDFs arc deterministic and do not \\nchange, it can trust their output without having to understand whnt \\nthey do. \\n10 Conclusion \\nThis paper evaluates the exokemel architecture proposed in [l 11. \\nIt shows how we built an exokemel system that separates pro- \\ntection from management to give untrusted software control over \\nresource management. Our exokemel system gives significant per- \\nformance advantages to aggressively-specialized applications while \\nmaintaining competitive performance on unmodified UNIX appli- \\ncations, even under heavily multitasked workloads. Exokcmels nlso \\nsimplify the job of operating system development by allowing one \\nlibrary operating system to be developed and debugged from an- \\nother one running on the same machine. The advantages of rapid \\noperating system development extend beyond specialized niche ap- \\nplications. Thus, while some questions about the full implications \\nof the exokemel architecture remain to be answered, it is a viable \\napproach that offers many advantages over conventional systems. \\nAcknowledgments \\nOver the last three years many people have contributed to the exo- \\nkernel project. In particular, we thank Deborah Wallach and Doug \\nWyatt for their many contributions. We also thank Josh Cates, Erik \\nNygren, Constantine Sapuntzakis, Yonah Schmeidler, and Elliot \\nWaingold for porting drivers and applications to Xok/ExOS, We \\nthank Eddie Kohler for his help with writing this pap', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 990: ('hitecture remain to be answered, it is a viable \\napproach that offers many advantages over conventional systems. \\nAcknowledgments \\nOver the last three years many people have contributed to the exo- \\nkernel project. In particular, we thank Deborah Wallach and Doug \\nWyatt for their many contributions. We also thank Josh Cates, Erik \\nNygren, Constantine Sapuntzakis, Yonah Schmeidler, and Elliot \\nWaingold for porting drivers and applications to Xok/ExOS, We \\nthank Eddie Kohler for his help with writing this paper, Finally, \\nwe thank Josh Cams, John Chapin, Matt Frank, John Guttag, An- \\nthony Joseph, Hank Levy (our shepherd), Erik Nygren, Max Po- \\nletto, Deborah Wallach, David Wetherall, Emmett Witchel, and the \\nanonymous referees for their careful reading of earlier versions of \\nthis paper and their valuable feedback. \\nReferences \\n111 \\n121 \\n131 \\n[41 T. Anderson. The case for application-specific operating syslems, \\nIn Third Workshop on Workstation Operating Systems, pages 92-94, \\n1992. \\nJ. Barrera. Invocation chaining: manipulating light-weight objects \\nacross heavy-weight boundaries. In Proc. of 4111 IEEE IVorkshop ON \\nWorkstation Operating Systems, pages 191-193, October 1993. \\nB.N. Bershad, D.D. Redell, and J.R. Ellis. Fast mutual exclusion \\nfor uniprocessors. In Proc. of the Co& on Architecfrrral Support \\nfor Programming Languages and Operating Systems, pages 223-231, \\nOctober 1992. \\nB.N. Bershad, S. Savage, P. Pardyak, E.G. Sirer, M. Fhrczynski, \\nD. Becker, S. Eggers, and C. Chambers. Extensibility, safety and \\nperformance in the SPIN opemting system. In Proceedings bf /he \\nFifteenth ACM Symposium on Operating Systems Principles, pages \\n267-284. December 1995. \\n[5] E. Bugnion, S. Devine, and M. Rosenblum. Disco: running commodity \\noperating systems on scalable multiprocessors. In Proceedings of/he \\nSixteenth ACM Symposium on Operating Systems Principles, 1991. \\n[6] R Cao, E.W. Fehen, and K. Li. Implementation and performance \\nof application-controlled file caching. In Proceedings of the Firsf \\n64 \\n171 \\n. PI \\nPI ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 991: (' \\nperformance in the SPIN opemting system. In Proceedings bf /he \\nFifteenth ACM Symposium on Operating Systems Principles, pages \\n267-284. December 1995. \\n[5] E. Bugnion, S. Devine, and M. Rosenblum. Disco: running commodity \\noperating systems on scalable multiprocessors. In Proceedings of/he \\nSixteenth ACM Symposium on Operating Systems Principles, 1991. \\n[6] R Cao, E.W. Fehen, and K. Li. Implementation and performance \\nof application-controlled file caching. In Proceedings of the Firsf \\n64 \\n171 \\n. PI \\nPI A. Chankhuntbod, P.B. Danzig, C. Neerdaels. ME Schwartz, and K.J. \\nWorrell. A hierarchical Internet object cache. In Proceedings of1996 \\nUSENIX Technical Conference, pages 153-163. January 1996. \\nD. Cheriton and K. Duda. A caching model of operating system kernel \\nfunctionality. In Proceedings of the First Symposium on Operating \\nSystems Design andlmpletnentation, pages 179-193, November 1994. \\nJ.B. Dennis and E.C. Van Horn. Programming semantics for multipro- \\ngmmmed computations. Communications of the ACM, 9(3):143-155, \\nMarch 1966. \\nUOI D.R. Engler and M.F. Kaashoek. DPF: fast, flexible message demul- \\ntiplexing using dynamic code generation. In ACM Communication \\nArchitectures, Protocols, and ADD~icati0n.S (SIGCOMMJ 1996. Dane-s \\n53-59, August 1996. - - _ - \\nWI D.R.EngIer,M.F.Kaashoek,andJ.O’TooleJr Exokemekanoperating \\nsystem architecture for application-specific resource management. In \\nProceedings of the Ftpeenth ACM Symposium on Operating Systems \\nPrinciples, pages 251-266, December 1995. \\nB. Ford, M. Hibler, J. Lepreau, R Tullman, G. Back, and S. Clawson. \\nMicrokemels meet recursive virtual machines. In Proceedings of the \\nSecond Symposium on Operating Systems Design and Implementation, \\npages 137-152, October 1996. \\nv31 B. Ford, K. Van Maren, J. Lepreau, S. Clawson, B. Robinson, and \\nJeff Turner. The FLUX OS toolkit: Reusable components for OS \\nimplementation, In Proc. ofSixth Workshop on Hot Topics in Operating \\nSystems, pages M-19. May 1997. \\n[I41 \\n[I51 \\nWI \\nI171 \\nWI B. Ford and S.R. Susarla. CPU in', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 992: (' Hibler, J. Lepreau, R Tullman, G. Back, and S. Clawson. \\nMicrokemels meet recursive virtual machines. In Proceedings of the \\nSecond Symposium on Operating Systems Design and Implementation, \\npages 137-152, October 1996. \\nv31 B. Ford, K. Van Maren, J. Lepreau, S. Clawson, B. Robinson, and \\nJeff Turner. The FLUX OS toolkit: Reusable components for OS \\nimplementation, In Proc. ofSixth Workshop on Hot Topics in Operating \\nSystems, pages M-19. May 1997. \\n[I41 \\n[I51 \\nWI \\nI171 \\nWI B. Ford and S.R. Susarla. CPU inheritance scheduling. In Proceedings \\nof the Second Symposium on Operating Systems Design and Imple- \\nmentation, pages 91-106, October 1996. \\nG. Ganger and ME Kaashoek. Embedded inodes and explicit group- \\ning: Exploiting disk bandwidth for small files. In Proceedings ofthe \\n1997 VSENIXTeclmical Conference, pages l-18,1997. \\nG. Ganger and Y. Patt. Metadata update performance in file systems. \\nIn Proceedings of the First Symposium on Operating Systems Design \\nand Implementation, pages 49-60, November 1994. \\nR.P. Goldberg. Survey of virtual machine research. IEEE Computer, \\npnges 34-45, June 1974. \\nD. Golub, R. Dean, A. Forin, and R. Rashid. UNIX as an application \\nprogram. In USENIX 1990 Summer Conference, pages 87-95. June \\n1990. \\nWI P. Brinch Hansen. The nucleus of a multiprogramming system. Com- \\nmunications of the ACM. 13(4):238-241, April 1970. \\n[20] H. Hartig, M. Hohmuth, J. Liedtke, and S. Schanberg. The perfor- \\nmance of p-kernel-based systems. In Proceedings of the Sixteenth \\nACM Symposium on Operating Systems Principles, 1997. \\n[21] J.H. Hattman, A.B. Montx, D. Mosberger, S.W. O’Malley, L.L. Peter- \\nson, and T.A. Proebsting. Scout: A communication-oriented operating \\nsystem. Technical Report TR 94-20, University of Arizona, Tucson, \\nAZ, June 1994. Symposium on Operating Systems Design and Implementation, pages \\n165-178, November 1994. \\n[22] K. Harty and D. Cheriton. Application-controlled physical mem- \\nory using external page-cache management. In Ft$ih International \\nCorlference on Architecture Suppor', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 993: ('g Systems Principles, 1997. \\n[21] J.H. Hattman, A.B. Montx, D. Mosberger, S.W. O’Malley, L.L. Peter- \\nson, and T.A. Proebsting. Scout: A communication-oriented operating \\nsystem. Technical Report TR 94-20, University of Arizona, Tucson, \\nAZ, June 1994. Symposium on Operating Systems Design and Implementation, pages \\n165-178, November 1994. \\n[22] K. Harty and D. Cheriton. Application-controlled physical mem- \\nory using external page-cache management. In Ft$ih International \\nCorlference on Architecture Supportfor Programming Languages and \\nOperating Systems, page? 187-199, October 1992. \\n[23] D.Hitx. AnNFSfileserverappliance. TechnicalReport3001,Nehvork \\nApplicance Corporation, March 1995. \\n[24] M.P. Kmhoek, D.R. Engler, D.H. Wallach, and G. Ganger. Server \\noperating systems. In SIGOPS European Workshop, pages 141-148, \\nSeptember 1996. \\n[251 B.W. Lampson. On reliable and extendable operating systems. State \\nof the Art Report, Infotech, 1, 1971. \\n[26] B.W. Lampson and RF. Sproull. An open operating system for a \\nsingle-user machine. Proceedings of the Sevenfh ACM Symposium on \\nOperating Systems Principles, pages 98-105, December 1979. i271 \\n1291 \\nt301 \\nt311 \\nWI \\n1331 \\ni341 \\n1351 C.H. Lee, M.C. Chen, and R.C. Chang. HiPEC: high performance ex- \\nternal virtual memory caching. In Proceedings of the First Symposium \\non Operating Systems Design and Implementation, pages 153-164. \\n1994. \\nJ. Liedtke. On micro-kernel construction. In Pmceedings offhe \\nFifreenth ACM Symposium on Operating Systems Priicipl& pages \\n237-250, December 1995. \\nK. Mackenzie, J. Kubiatowicz, M. Frank, W. Lee, V. Lee, A. Agarwal, \\nand M.F. Kaashoek. UDM: user direct messaging for general-purpose \\nmultiprocessing. Technical Memo MIT/LCS/l?vf-556, March 1996. \\nC. Maeda and B.N. Bershad. Protocol service decomposition for \\nhigh-performance networking. In Proceedings of the Fourteenth ACM \\nSymposium on Operating Systems Principles, pages 244-255,1993. \\nD. Maxi&s and ME Kaashoek. Secure applications need flexibile \\noperatlngsystems. Jn Proc of6th Workshop', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 994: ('December 1995. \\nK. Mackenzie, J. Kubiatowicz, M. Frank, W. Lee, V. Lee, A. Agarwal, \\nand M.F. Kaashoek. UDM: user direct messaging for general-purpose \\nmultiprocessing. Technical Memo MIT/LCS/l?vf-556, March 1996. \\nC. Maeda and B.N. Bershad. Protocol service decomposition for \\nhigh-performance networking. In Proceedings of the Fourteenth ACM \\nSymposium on Operating Systems Principles, pages 244-255,1993. \\nD. Maxi&s and ME Kaashoek. Secure applications need flexibile \\noperatlngsystems. Jn Proc of6th Workshop on Hot Topics in Operating \\nSystems, pages 56-61, May 1997. \\nNCSA, University of Illinois, Urbana-Champaign. NCSA HlTPd. \\nhttp~/hoohoo.ncsauiuc.edu/lmdex.hbul. \\nJ.K. Ousterhout. Why aren’t operating systems getting faster as fast as \\nhardware.? In Proceedings of the Summer I990 USENIX Conference, \\npages 247-256, June 1990. \\nV. Pai, P. Druschel, and W. Zwaenepoel. I/O-lite: a unified \\nI/O buffering and caching system. Technical Report http: // \\nwww.cs.rice.edu/-vivek/IO-li.te.html,RiceUniversity, \\n1997. \\nR.H. Patterson, G.A. Gibson,E. Ginting, D. Stodolsky, and J. Zelenka \\nInformed prefetching and caching. In Proceedings of the Ffteenth \\nACM Symposium on Operating Systems Principles, pages 79-95, De- \\ncember 1995. \\n[36l D. Probert, J.L. Bruno. and M. Karxaorman. SPACE: a new approach \\n1371 \\nt381 \\nWI \\nWI \\n1411 \\n1421 \\n[431 \\nWI to operating system abstraction. In International Workshop on Object \\nOrientation in Operating Systems, pages 133-137. October 1991. \\nD.D. Redell, Y.K. Dalal, T.R. Horsley, H.C. Latter, W.C. Lynch, RR. \\nMcJoncs, H.G. Murray, and S.C Purcell. Pilot: an operating system \\nfor a personal computer. Communications of the ACM, 23(2):81-92. \\nFebruary 1980. \\nR. Sandberg, D. Goldberg, S. Kleimau, D. Walsh, and B. Lyon. Design \\nand implementation of the Sun network filesystem. In Proc. of the 1985 \\nSummer USENIX conference, pages 119-130,1985. \\nM. Seltzer, Y. Endo, C. Small, and K. Smith Dealing with disaster \\nSurviving misbehaved kernel extensions. In Proceedings of the Second \\nSymposium on Operating', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 995: ('.C. Lynch, RR. \\nMcJoncs, H.G. Murray, and S.C Purcell. Pilot: an operating system \\nfor a personal computer. Communications of the ACM, 23(2):81-92. \\nFebruary 1980. \\nR. Sandberg, D. Goldberg, S. Kleimau, D. Walsh, and B. Lyon. Design \\nand implementation of the Sun network filesystem. In Proc. of the 1985 \\nSummer USENIX conference, pages 119-130,1985. \\nM. Seltzer, Y. Endo, C. Small, and K. Smith Dealing with disaster \\nSurviving misbehaved kernel extensions. In Proceedings of the Second \\nSymposium on Operating Systems Design and Implementation, pages \\n213-228, October 1996. \\nC.A. Thekkath, H.M. Levy, and E.D. Lazowska. Separating data and \\ncontrol transfer in distributed operating systems. InSixth International \\nConference on Architecture Support for Programming Languages and \\nOperating Systems, pages 2-11, SanFrancisco, CA, October 1994. \\nT. von Eicken. A. Basu, V. Buch, and W. Vogels. U-Net: a user- \\nlevel network interface for parallel and distributed computing. In \\nProceedings of the Ftyeenth ACM Symposium on Operating Systems \\nPrinciples, pages 40-53,1995. \\nR. Wahbe, S. Lucco, T. Anderson, and S. Graham. Efficient software- \\nbased fault isolation. In Proceedings of the Fourteenth ACM Sympo- \\nsium on Operating Systems Principles, pages 203-216, Asheville, NC, \\nDecember 1993. \\nC.A. Waldspuxger and WE. Weihl. Lottery scheduling: Flexible \\nproportional-share resource management. In Proceedings of the First \\nSymposium on Operating Systems Design and Implementation, pages \\nl-11. November 1994. \\nD.A. Wallach, D.R. Engler, and M.F. Kaashoek. ASHs: Application- \\nspecific handlers for high-performance messaging. In ACM Commu- \\nnication Architectures, Protocols, and Applications (SIGCOMM ‘96), \\npages 40-52, August 1996. \\n65 ', 'Application Performance and Hexibility on Exokernel Systems .pdf'), 996: ('See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/220881341\\nDesign T radeoffs for SSD Performance\\nConf erence Paper  · Januar y 2008\\nSour ce: DBLP\\nCITATIONS\\n960READS\\n4,180\\n6 author s, including:\\nNitin Agr awal\\nIndian Instit ute of T echnolog y Delhi\\n25 PUBLICA TIONS \\xa0\\xa0\\xa01,992  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nTed Wobber\\nMicr osoft\\n60 PUBLICA TIONS \\xa0\\xa0\\xa04,844  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nJohn D Davis\\nMicr osoft\\n38 PUBLICA TIONS \\xa0\\xa0\\xa02,117  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nMark Manasse\\nI2chain. com\\n76 PUBLICA TIONS \\xa0\\xa0\\xa08,615  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Mark Manasse  on 21 May 2014.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.\\nDesignTradeoffs forSSD Performance\\nNitinAgrawal∗,Vijayan Prabhakaran, Ted Wobber,\\nJohnD. Davis,Mark Manasse, RinaPanigrahy\\nMicrosoftResearch, SiliconValley\\n∗UniversityofWisconsin-Madison\\nAbstract\\nSolid-statedisks(SSDs)havethepotentialtorevolution-\\nize thestorage system landscape. However,thereis little\\npublished work about their internal organization or the\\ndesignchoicesthatSSDmanufacturersfaceinpursuitof\\noptimalperformance. Thispaperpresentsataxonomyof\\nsuchdesignchoicesandanalyzesthelikely performance\\nof variousconﬁgurationsusing a trace-driven simulator\\nandworkloadtracesextractedfromrealsystems. Weﬁnd\\nthat SSD performance and lifetime is highly workload-\\nsensitive, and that complex systems problems that nor-\\nmally appearhigherin the storage stack, or even in dis-\\ntributedsystems, are relevanttodeviceﬁrmware.\\n1 Introduction\\nThe advent of the NAND-ﬂash based solid-state stor-\\nage device (SSD) is certain to represent a sea change in\\nthe architecture of computer storage subsystems. These\\ndevices are capable of producing not only exceptional\\nbandwidth, but also random I/O performance that is\\norders of magnitude better than that of rotating disks.\\nMoreover,SSDsofferbothasigniﬁcantsavingsinpower\\nbudget and an absence of moving parts, improving sys-\\ntemreliability.\\nAlthough solid-sta', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 997: ('stems, are relevanttodeviceﬁrmware.\\n1 Introduction\\nThe advent of the NAND-ﬂash based solid-state stor-\\nage device (SSD) is certain to represent a sea change in\\nthe architecture of computer storage subsystems. These\\ndevices are capable of producing not only exceptional\\nbandwidth, but also random I/O performance that is\\norders of magnitude better than that of rotating disks.\\nMoreover,SSDsofferbothasigniﬁcantsavingsinpower\\nbudget and an absence of moving parts, improving sys-\\ntemreliability.\\nAlthough solid-state disks cost signiﬁcantly more per\\nunit capacity than their rotating counterparts, there are\\nnumerousapplicationswheretheycanbeappliedtogreat\\nbeneﬁt. For example, in transaction-processingsystems,\\ndisk capacity is often wasted in order to improve oper-\\nation throughput. In such conﬁgurations, many small\\n(cost inefﬁcient) rotating disks are deployed to increase\\nI/O parallelism. LargeSSDs, suitablyoptimizedforran-\\ndom read and write performance, could effectively re-\\nplace whole farms of slow, rotating disks. At this writ-\\ning, small SSDs are starting to appearin laptopcomput-\\nersbecauseoftheirreducedpower-proﬁleandreliability\\nin portable environments. As the cost of ﬂash continues\\nto decline, the potential application space for solid-stat e\\ndiskswill certainlycontinueto grow.\\nDespite the promise that SSDs hold, there is little in\\ntheliteratureaboutthearchitecturaltradeoffsinherent intheir design. Where such knowledge exists, it typically\\nremains the intellectual property of SSD manufacturers.\\nAs a consequence, it is difﬁcult to understand the archi-\\ntecture of a given device, and harder still to interpret its\\nperformancecharacteristics.\\nIn this paper, we lay out a range of design tradeoffs\\nthat are relevant to NAND-ﬂash solid-state storage. We\\nthen analyze several of these tradeoffs using a trace-\\nbased disk simulator that we have customized to char-\\nacterize different SSD organizations. Since we can only\\nspeculate about the detailed internals of existing SSDs,\\nwe base our simulator on the speciﬁed properties o', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 998: (', it is difﬁcult to understand the archi-\\ntecture of a given device, and harder still to interpret its\\nperformancecharacteristics.\\nIn this paper, we lay out a range of design tradeoffs\\nthat are relevant to NAND-ﬂash solid-state storage. We\\nthen analyze several of these tradeoffs using a trace-\\nbased disk simulator that we have customized to char-\\nacterize different SSD organizations. Since we can only\\nspeculate about the detailed internals of existing SSDs,\\nwe base our simulator on the speciﬁed properties of\\nNAND-ﬂash chips. Our analysis is driven by various\\ntracescapturedfromrunningsystemssuchasafull-scale\\nTPC-C benchmark, an Exchange server workload, and\\nvariousstandardﬁle systembenchmarks.\\nWe ﬁnd that many of the issues that arise in SSD\\ndesign appear to mimic problems that have previously\\nappeared higher in the storage stack. In solving these\\nhard problems, there is considerable latitude for design\\nchoice. We show that the following systems issues are\\nrelevanttoSSD performance:\\n•Data placement . Careful placement of data across\\nthe chips of an SSD is critical not only to provide\\nloadbalancing,butto effectwear-leveling.\\n•Parallelism . The bandwidth and operation rate of\\nany given ﬂash chip is not sufﬁcient to achieve op-\\ntimal performance. Hence, memory components\\nmustbecoordinatedso astooperateinparallel.\\n•Write ordering . The properties of NAND ﬂash\\npresent hard problems to the SSD designer. Small,\\nrandomly-orderedwritesareespeciallytricky.\\n•Workload management . Performance is highly\\nworkload-dependent. For example, design deci-\\nsionsthatproducegoodperformanceundersequen-\\ntial workloads may not beneﬁt workloads that are\\nnotsequential,andviceversa.\\nAs SSDs increasein complexity,existingdisk models\\nwill become insufﬁcient for predicting performance. In\\nparticular, random write performance and disk lifetime\\nwill vary signiﬁcantly due to the locality of disk write\\noperations. Weintroduceanewmodelforcharacterizing\\nthis behavior based on cleaning efﬁciencyand suggest a\\nnewwear-levelingalgorithmforextendingSSDlife', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 999: ('or example, design deci-\\nsionsthatproducegoodperformanceundersequen-\\ntial workloads may not beneﬁt workloads that are\\nnotsequential,andviceversa.\\nAs SSDs increasein complexity,existingdisk models\\nwill become insufﬁcient for predicting performance. In\\nparticular, random write performance and disk lifetime\\nwill vary signiﬁcantly due to the locality of disk write\\noperations. Weintroduceanewmodelforcharacterizing\\nthis behavior based on cleaning efﬁciencyand suggest a\\nnewwear-levelingalgorithmforextendingSSDlifetime.\\nTheremainderofthispaperisorganizedasfollows. In\\nthe next section, we provide background on the proper-\\ntiesofNAND-ﬂashmemory. Section3describestheba-\\nsicfunctionalitythatSSDdesignersmustprovideandthe\\nmajor challenges in implementing these devices. Sec-\\ntion4describesoursimulationenvironmentandpresents\\nan evaluation of the various design choices. Section 5\\nprovides a discussion of SSD wear-leveling and gives\\npreliminarysimulatorresultsonthistopic. Relatedwork\\nisdiscussedinSection6,andSection7concludes.\\n2 Background\\nOur discussion of ﬂash memory is based on the latest\\nproduct speciﬁcations for Samsung’s K9XXG08UXM\\nseries NAND-ﬂash part [29]. Other vendors such as\\nMicron and Hynix offer products with similar features.\\nFor the remainder of this paper, we treat the 4GB Sam-\\nsungpartasacanonicalexemplar,althoughthespeciﬁcs\\nof other vendors’ parts will differ in some respects.\\nWe present the speciﬁcations for single-level cell (SLC)\\nﬂash. Multi-levelcell (MLC) ﬂash is cheaper than SLC,\\nbuthasinferiorperformanceandlifetime.\\nFigure 1 shows a schematic for a ﬂash package. A\\nﬂash package is composed from one or more dies (also\\ncalled chips). We describea 4GBﬂash-packageconsist-\\ning of two 2GB dies, sharing an 8-bit serial I/O bus and\\na numberof commoncontrolsignals. Thetwo dieshave\\nseparate chip enable and ready/busy signals. Thus, one\\nofthediescanacceptcommandsanddatawhiletheother\\nis carryingout anotheroperation. Thepackagealso sup-\\nportsinterleavedoperationsbetweenthetwodies.\\nEachdiewithinapackagecontains8192 bloc', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1000: ('eandlifetime.\\nFigure 1 shows a schematic for a ﬂash package. A\\nﬂash package is composed from one or more dies (also\\ncalled chips). We describea 4GBﬂash-packageconsist-\\ning of two 2GB dies, sharing an 8-bit serial I/O bus and\\na numberof commoncontrolsignals. Thetwo dieshave\\nseparate chip enable and ready/busy signals. Thus, one\\nofthediescanacceptcommandsanddatawhiletheother\\nis carryingout anotheroperation. Thepackagealso sup-\\nportsinterleavedoperationsbetweenthetwodies.\\nEachdiewithinapackagecontains8192 blocks,orga-\\nnizedamong4 planesof2048blocks. Thediescanoper-\\nate independently,eachperformingoperationsinvolving\\none or two planes. Two-plane commands can be exe-\\ncutedoneitherplane-pairs0 &1or2 &3,butnotacross\\nother combinations. Each block in turn consists of 64\\n4KBpages. Inadditiontodata,eachpageincludesa128\\nbyte region to store metadata (identiﬁcation and error-\\ndetection information). Table 1 presents the operational\\nattributesoftheSamsung4GBﬂash memory.\\n2.1 Properties ofFlashMemory\\nDatareadsareatthegranularityofﬂashpages,andatyp-\\nical read operation takes 25 µs to read a page from the\\nmedia into a 4KB data register, and then subsequently\\nshift it out over the data bus. The serial line transfersPage Read to Register 25µs\\nPage Program (Write) from Register 200µs\\nBlock Erase 1.5ms\\nSerial Access to Register (Data bus) 100µs\\nDie Size 2 GB\\nBlock Size 256 KB\\nPage Size 4 KB\\nData Register 4 KB\\nPlanes per die 4\\nDies per package (2GB/4GB/8GB) 1,2or 4\\nProgram/Erase Cycles 100 K\\nTable1: Operationalﬂashparameters\\ndata at 25ns per byte, or roughly 100 µs per page. Flash\\nmedia blocks must be erasedbefore they can be reused\\nfor new data. An erase operation takes 1.5ms, which is\\nconsiderablymoreexpensivethan a read or write opera-\\ntion. In addition, each block can be erased only a ﬁnite\\nnumber of times before becoming unusable. This limit,\\n100K erase cycles for current generation ﬂash, places a\\npremiumoncarefulblockreuse.\\nWriting (orprogramming)is also doneat pagegranu-\\nlarity by shifting data into the data register (100 µs) a', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1001: (' 25ns per byte, or roughly 100 µs per page. Flash\\nmedia blocks must be erasedbefore they can be reused\\nfor new data. An erase operation takes 1.5ms, which is\\nconsiderablymoreexpensivethan a read or write opera-\\ntion. In addition, each block can be erased only a ﬁnite\\nnumber of times before becoming unusable. This limit,\\n100K erase cycles for current generation ﬂash, places a\\npremiumoncarefulblockreuse.\\nWriting (orprogramming)is also doneat pagegranu-\\nlarity by shifting data into the data register (100 µs) and\\nthenwritingitouttotheﬂashcell(200 µs). Pagesmustbe\\nwrittenoutsequentiallywithinablock,fromlowtohigh\\naddresses. The part also provides a specialized copy-\\nback program operation from one page to another, im-\\nproving performance by avoiding the need to transport\\ndatathroughtheserial lineto anexternalbuffer.\\nInthis paper,we discussa 2 x2GBﬂash package,but\\nextensionsto largerdiesand/orpackageswith moredies\\narestraightforward.\\n2.2 Bandwidth and Interleaving\\nThe serial interface over which ﬂash packages receive\\ncommands and transmit data is a primary bottleneck\\nfor SSD performance. The Samsung part takes roughly\\n100µstotransfera4KBpagefromtheon-chipregisterto\\nan off-chip controller. This dwarfs the 25 µs required to\\nmovedata into the register fromthe NAND cells. When\\nthese two operations are taken in series, a ﬂash pack-\\nage can only produce 8000 page reads per second (32\\nMB/sec). If interleaving is employed within a die, the\\nmaximum read bandwidth from a single part improves\\nto 10000 reads per second (40 MB/sec). Writes, on the\\nother hand, require the same 100 µs serial transfer time\\nper page as reads, but 200 µs programming time. With-\\noutinterleaving,thisgivesamaximum,single-partwrite\\nrateof3330pagespersecond(13MB/sec). Interleaving\\nthe serial transfer time and the program operation dou-\\nbles the overall bandwidth. In theory, because there are\\ntwo independent dies on the packages we are consider-\\ning, we can interleave three operations on the two dies\\nput together. This would allow both writes and reads to\\nprog', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1002: ('). Writes, on the\\nother hand, require the same 100 µs serial transfer time\\nper page as reads, but 200 µs programming time. With-\\noutinterleaving,thisgivesamaximum,single-partwrite\\nrateof3330pagespersecond(13MB/sec). Interleaving\\nthe serial transfer time and the program operation dou-\\nbles the overall bandwidth. In theory, because there are\\ntwo independent dies on the packages we are consider-\\ning, we can interleave three operations on the two dies\\nput together. This would allow both writes and reads to\\nprogressat thespeedoftheserialinterconnect.\\n4K Register 4K Register 4K RegisterPlane 0 Plane 1 Plane 2 Plane 3\\nBlock 4095 Block 4095Plane 3 Plane 2 Plane 1 Plane 0\\n4K Register 4K Register 4K Register 4K Register 4K RegisterooPage 0\\nPage 1\\nPage 63 Page 63Page 1Page 0\\no\\noPage 63Page 1Page 0\\no\\no ooPage 0\\nPage 1\\nPage 63\\nooPage 0\\nPage 1\\nPage 63Page 63Page 1Page 0\\no\\no ooPage 0\\nPage 1\\nPage 63\\nooPage 0\\nPage 1\\nPage 63 Page 63Page 1Page 0\\no\\noPage 63Page 1Page 0\\no\\no\\noo\\noo o\\noo\\no ooo o\\noo\\noo\\noBlock 0\\nPage 0\\nPage 1\\nPage 63\\nBlock 4094Block 1\\nBlock 8190Block 4096\\no\\nBlock 8191Block 4097\\nFlash Package (4 GB) Die 1 Die 0Serial Connection\\nBlock 4097\\nBlock 8191oBlock 4096\\nBlock 8190Block 1\\nBlock 4094Page 63Page 1Page 0Block 0\\noo\\noo\\noo o\\no\\no oo\\noo o\\noo\\no\\nooPage 0\\nPage 1\\nPage 63 Page 63Page 1Page 0\\no\\no ooPage 0\\nPage 1\\nPage 63ooPage 0\\nPage 1\\nPage 63\\nFigure1: Samsung4GBﬂashinternals\\nInterleaving can provide considerable speedups when\\nthe operation latency is greater than the serial access la-\\ntency. Forexample,acostlyerasecommandcaninsome\\ncases proceed in parallel with other commands. As an-\\nother example, fully interleaved page copying between\\ntwo packages can proceed at close to 100 µs per page as\\ndepictedinFigure2inspiteofthe200 µscostofasingle\\nwrite operation. Here, 4 source planes and 4 destination\\nplanes copy pages at speed without performingsimulta-\\nneous operationson the same plane-pairand while opti-\\nmallymakinguseoftheserialbuspinsconnectedtoboth\\nﬂashdies. Oncethepipeisloaded,awritecompletesev-\\neryinterval(100 µs).\\nEven when ﬂas', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1003: ('me\\ncases proceed in parallel with other commands. As an-\\nother example, fully interleaved page copying between\\ntwo packages can proceed at close to 100 µs per page as\\ndepictedinFigure2inspiteofthe200 µscostofasingle\\nwrite operation. Here, 4 source planes and 4 destination\\nplanes copy pages at speed without performingsimulta-\\nneous operationson the same plane-pairand while opti-\\nmallymakinguseoftheserialbuspinsconnectedtoboth\\nﬂashdies. Oncethepipeisloaded,awritecompletesev-\\neryinterval(100 µs).\\nEven when ﬂash architectures support interleaving,\\ntheydoso with seriousconstraints. So,forexample,op-\\nerations on the same ﬂash plane cannot be interleaved.\\nThissuggeststhatsame-packageinterleavingisbestem-\\nployed for a choreographed set of related operations,\\nsuch as a multi-page read or write as depicted in Fig-\\nure2. TheSamsungpartsweexaminedsupportafastin-\\nternal copy-backoperation that allows data to be copied\\ntoanotherblockon-chipwithoutcrossingtheserialpins.\\nThis optimization comes at a cost: the data can only be\\ncopiedwithinthesameﬂashplane(of2048blocks). Two\\nsuch copies may themselves be interleaved on different\\nplanes, and the result yields similar performance to the\\nfully-interleaved inter-package copying depicted in Fig-\\nure2,butwithoutmonopolizingthe serialpins.\\n3 SSD Basics\\nIn this section we outline some of the basic issues that\\narise when constructing a solid-state disk from NAND-Source Plane 0 \\nDest Plane 0 \\nSource Plane 2 \\nDest Plane 2 Source Plane 1 \\nDest Plane 1 \\nSource Plane 3 \\nDest Plane 3 Read \\nXfer \\nWrite \\nTime \\nFigure2: Interleavedpagecopying\\nﬂash components. Although we introduce a number of\\ndimensions in which designs can differ, we leave the\\nevaluationofspeciﬁc choicesuntilSection4.\\nAll NAND-based SSDs are constructed from an ar-\\nray of ﬂash packages similar to those described in the\\nprevious section. Figure 3 depicts a generalized block\\ndiagram for an SSD. Each SSD must contain host inter-\\nfacelogictosupportsomeformofphysicalhostinterface\\nconnection (USB, FiberChannel, PCI Express, SATA)\\nand lo', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1004: ('r \\nWrite \\nTime \\nFigure2: Interleavedpagecopying\\nﬂash components. Although we introduce a number of\\ndimensions in which designs can differ, we leave the\\nevaluationofspeciﬁc choicesuntilSection4.\\nAll NAND-based SSDs are constructed from an ar-\\nray of ﬂash packages similar to those described in the\\nprevious section. Figure 3 depicts a generalized block\\ndiagram for an SSD. Each SSD must contain host inter-\\nfacelogictosupportsomeformofphysicalhostinterface\\nconnection (USB, FiberChannel, PCI Express, SATA)\\nand logical disk emulation, like a ﬂash translation layer\\nmechanismtoenabletheSSDtomimicaharddiskdrive.\\nThebandwidthofthehostinterconnectisoftenacritical\\nconstraint on the performance of the device as a whole,\\nand it must be matched to the performance available to\\nand from the ﬂash array. An internal buffer manager\\nholds pending and satisﬁed requests along the primary\\ndatapath. Amultiplexer(FlashDemux/Mux)emitscom-\\nmandsandhandlestransportofdataalongtheserialcon-\\nnections to the ﬂash packages. The multiplexer can in-\\nclude additionallogic, for example,to buffercommands\\nanddata. Aprocessingengineisalsorequiredtomanage\\nthe request ﬂow and mappings from disk logical block\\nHost\\nInterface\\nLogic\\nBuffer\\nManagerProcessor\\nFlash\\nDemux\\n/MuxFlash\\nPkg\\nHost\\nInterconnectRAM\\nSSDControllerFlash\\nPkg\\nFlash\\nPkgFlash\\nPkg\\nFigure3: SSD LogicComponents\\naddresstophysicalﬂash location. Theprocessor,buffer-\\nmanager,andmultiplexeraretypicallyimplementedina\\ndiscrete componentsuch as an ASIC or FPGA, and data\\nﬂow between these logic elements is very fast. The pro-\\ncessor, and its associated RAM, may be integrated, as\\nis the case for simple USB ﬂash-stick devices, or stan-\\ndalone as for designs with more substantial processing\\nandmemoryrequirements.\\nAs described in Section 2, ﬂash packages export an\\n8-bit wide serial data interface with a similar number of\\ncontrol pins. A 32GB SSD with 8 of the Samsung parts\\nwould require 136 pins at the ﬂash controller(s) just for\\nthe ﬂash components. With such a device, it might be\\npossibletoachievefullinterconn', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1005: (' very fast. The pro-\\ncessor, and its associated RAM, may be integrated, as\\nis the case for simple USB ﬂash-stick devices, or stan-\\ndalone as for designs with more substantial processing\\nandmemoryrequirements.\\nAs described in Section 2, ﬂash packages export an\\n8-bit wide serial data interface with a similar number of\\ncontrol pins. A 32GB SSD with 8 of the Samsung parts\\nwould require 136 pins at the ﬂash controller(s) just for\\nthe ﬂash components. With such a device, it might be\\npossibletoachievefullinterconnectionbetweentheﬂash\\ncontroller(s)andﬂashpackages,butforlargerconﬁgura-\\ntions this is not likely to remain feasible. For the mo-\\nment,weassumefullinterconnectionbetweendatapath,\\ncontrol logic, and ﬂash. We return to the issue of inter-\\nconnectdensityinSection3.3.\\nThis paper is primarily concerned with the organiza-\\ntionoftheﬂasharrayandthealgorithmsneededtoman-\\nagemappingsbetweenlogicaldiskandphysicalﬂashad-\\ndresses. It isbeyondthe scopeofthispapertotackle the\\nmanyimportantissuessurroundingthedesignandlayout\\nofSSD logiccomponents.\\n3.1 Logical BlockMap\\nAs pointed out by Birrell et al. [2], the nature of NAND\\nﬂashdictatesthatwritescannotbeperformedinplaceas\\non a rotating disk. Moreover, to achieve acceptable per-\\nformance, writes must be performedsequentially when-\\never possible, as in a log. Since each write of a single\\nlogical-disk block address(LBA) correspondsto a write\\nof a different ﬂash page, even the simplest SSD must\\nmaintain some form of mapping between logical block\\naddress and physical ﬂash location. We assume that thelogical block map is held in volatile memory and recon-\\nstructedfromstablestorageatstartuptime.\\nWe frame the discussion of logical block maps us-\\ning the abstraction of an allocation pool to think about\\nhow an SSD allocates ﬂash blocks to service write re-\\nquests. When handling a write request, each target log-\\nical page (4KB) is allocated from a pre-determinedpool\\nof ﬂash memory. The scope of an allocation pool might\\nbe as small as a ﬂash plane or as large as multiple ﬂash\\npackages. Whe', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1006: ('. We assume that thelogical block map is held in volatile memory and recon-\\nstructedfromstablestorageatstartuptime.\\nWe frame the discussion of logical block maps us-\\ning the abstraction of an allocation pool to think about\\nhow an SSD allocates ﬂash blocks to service write re-\\nquests. When handling a write request, each target log-\\nical page (4KB) is allocated from a pre-determinedpool\\nof ﬂash memory. The scope of an allocation pool might\\nbe as small as a ﬂash plane or as large as multiple ﬂash\\npackages. Whenconsideringthe propertiesof allocation\\npools,the followingvariablescometomind.\\n•Static map . A portion of each LBA constitutes a\\nﬁxedmappingtoa speciﬁcallocationpool.\\n•Dynamicmap . Thenon-staticportionofa LBA is\\nthelookupkeyforamappingwithinapool.\\n•Logical page size . The size for the referent of a\\nmapping entry might be as large as a ﬂash block\\n(256KB),orassmallasa quarter-page(1KB).\\n•Pagespan . Alogicalpagemightspanrelatedpages\\non different ﬂash packagesthus creating the poten-\\ntial foraccessingsectionsofthepagein parallel.\\nThesevariablesare thenboundbythreeconstraints:\\n•Loadbalancing. Optimally, I/Ooperationsshould\\nbeevenlybalancedbetweenallocationpools.\\n•Parallel access. The assignment of LBAs to phys-\\nical addresses should interfere as little as possible\\nwiththeabilitytoaccessthoseLBAsinparallel. So,\\nforexampleif LBA0..LBAnare alwaysaccessed at\\nthe same time, they should not be stored on a com-\\nponentthatrequireseachtobe accessedinseries.\\n•Block erasure. Flash pages cannot be re-written\\nwithoutﬁrstbeingerased. Onlyﬁxed-sizeblocksof\\ncontiguouspagescanbeerased.\\nThe variables that deﬁne allocation pools trade off\\nagainst these constraints. For example,if a largeportion\\noftheLBAspaceisstaticallymapped,thenthereislittle\\nscopeforload-balancing. IfacontiguousrangeofLBAs\\nismappedtothe samephysicaldie, performanceforse-\\nquential access in large chunkswill suffer. With a small\\nlogical page size, more work will be required to elimi-\\nnate valid pages from erasure candidates. If the logical\\npagesize (withunitspan)iseq', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1007: ('erased. Onlyﬁxed-sizeblocksof\\ncontiguouspagescanbeerased.\\nThe variables that deﬁne allocation pools trade off\\nagainst these constraints. For example,if a largeportion\\noftheLBAspaceisstaticallymapped,thenthereislittle\\nscopeforload-balancing. IfacontiguousrangeofLBAs\\nismappedtothe samephysicaldie, performanceforse-\\nquential access in large chunkswill suffer. With a small\\nlogical page size, more work will be required to elimi-\\nnate valid pages from erasure candidates. If the logical\\npagesize (withunitspan)isequaltothe blocksize,then\\nerasureissimpliﬁedbecausethewriteunitanderaseunit\\nare the same, howeverall writes smaller than the logical\\npagesize resultina read-modify-writeoperationinvolv-\\ningtheportionsofthelogicalpagenotbeingmodiﬁed.\\nRAID systems [26] often stripe logically contiguous\\nchunks of data (e.g. 64KB or larger) across multiple\\nphysical disks. Here, we use striping at ﬁne granular-\\nity to distribute logical pages (4K) across multiple ﬂash\\ndiesorpackages. Doingsoservesbothtodistributeload\\nand to arrange that consecutive pages will be placed on\\ndifferentpackagesthatcanbeaccessedinparallel.\\n3.2 Cleaning\\nFleshing out the designsketched by Birrell et al. [2], we\\nuse ﬂash blocks as the natural allocation unit within an\\nallocationpool. Atanygiventime,apoolcanhaveoneor\\nmoreactiveblocks availabletoholdincomingwrites. To\\nsupport the continued allocation of fresh active blocks,\\nwe need a garbage collector to enumerate previously-\\nusedblocksthat must be erasedandrecycled. If thelog-\\nical page granularityis smaller than the ﬂash blocksize,\\nthenﬂashblocksmustbecleanedpriortoerasure. Clean-\\ning can be summarized as follows. When a page write\\nis complete, the previously mapped page location is su-\\nperseded since its contents are now out-of-date. When\\nrecyclinga candidateblock,all non-supersededpagesin\\nthecandidatemustbewrittenelsewherepriorto erasure.\\nIn the worst case, where superseded pages are dis-\\ntributed evenly across all blocks, N−1cleaning writes\\nmustbeissuedforeverynewdatawrite(wherethereare\\nNpagesperblock). Of ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1008: ('than the ﬂash blocksize,\\nthenﬂashblocksmustbecleanedpriortoerasure. Clean-\\ning can be summarized as follows. When a page write\\nis complete, the previously mapped page location is su-\\nperseded since its contents are now out-of-date. When\\nrecyclinga candidateblock,all non-supersededpagesin\\nthecandidatemustbewrittenelsewherepriorto erasure.\\nIn the worst case, where superseded pages are dis-\\ntributed evenly across all blocks, N−1cleaning writes\\nmustbeissuedforeverynewdatawrite(wherethereare\\nNpagesperblock). Of course,most workloadsproduce\\nclusters of write activity, which in turn lead to multiple\\nsuperseded pages per block when the data is overwrit-\\nten. Weintroducetheterm cleaningefﬁciency toquantify\\nthe ratioof supersededpagesto total pagesduringblock\\ncleaning. Although there are many possible algorithms\\nfor choosing candidate blocks for recycling, it is always\\ndesirable to optimize cleaningefﬁciency. It’s worth not-\\ning that the use ofstriping to enhanceparallel accessfor\\nsequential addresses works against the clustering of su-\\npersededpages.\\nFor each allocation pool we maintain a free block list\\nthatwepopulatewithrecycledblocks. Inthissectionand\\nthe next, we assume a purely greedy approach that callsfor choosing blocks to recycle based on potential clean-\\ning efﬁciency. As described in Section 2, NAND ﬂash\\nsustains only a limited number of erasures per block.\\nTherefore, it is desirable to choose candidates for recy-\\ncling such that all blocks age evenly. This property is\\nenforcedthroughtheprocessknownaswear-leveling. In\\nSection 5, we discuss how the choice of cleaning candi-\\ndatesinteractsdirectlywithwear-leveling,andsuggesta\\nmodiﬁedgreedyalgorithm.\\nIn an SSD that emulates a traditional disk interface,\\nthere is no abstraction of a free disk sector. Hence, the\\nSSDisalwaysfullwithrespecttoitsadvertisedcapacity.\\nInorderforcleaningtowork,theremustbeenoughspare\\nblocks (not counted in the overall capacity) to allow\\nwrites and cleaning to proceed, and to allow for block\\nreplacement if a block fails. An SSD can be substa', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1009: ('eling. In\\nSection 5, we discuss how the choice of cleaning candi-\\ndatesinteractsdirectlywithwear-leveling,andsuggesta\\nmodiﬁedgreedyalgorithm.\\nIn an SSD that emulates a traditional disk interface,\\nthere is no abstraction of a free disk sector. Hence, the\\nSSDisalwaysfullwithrespecttoitsadvertisedcapacity.\\nInorderforcleaningtowork,theremustbeenoughspare\\nblocks (not counted in the overall capacity) to allow\\nwrites and cleaning to proceed, and to allow for block\\nreplacement if a block fails. An SSD can be substan-\\ntiallyoverprovisioned with such spare capacity in order\\nto reducethe demandfor cleaningblocksin foreground.\\nDelayed block cleaning might also produce better clus-\\nteringofsupersededpagesinnon-randomworkloads.\\nIn the previous subsection, we stipulated that a given\\nLBA is statically mapped to a speciﬁc allocation pool.\\nCleaning can, however, operate at a ﬁner granularity.\\nOnereasonfordoingsoistoexploitlow-levelefﬁciency\\nin the ﬂash architecture such as the internal copy-back\\noperation described in Section 2.2, which only applies\\nwhen pages are moved within the same plane. Since a\\nsingleﬂash planeof2048blocksrepresentsa verysmall\\nallocation pool for the purposes of load distribution, we\\nwouldlike to allocatefroma largerpool. However,if an\\nactive block and cleaning state per plane is maintained,\\nthen cleaning operations within the same plane can be\\narrangedwith highprobability.\\nIt might be tempting to view block cleaning as simi-\\nlar to log-cleaningin a Log-StructuredFile System [28]\\nand indeed there are similarities. However, apart from\\ntheobviousdifferencethatwemodelablockstoreasop-\\nposed to a ﬁle system, a log-structured store that writes\\nand cleans in strict disk-order cannot choose candidate\\nblocks so as to yield higher cleaning efﬁciency. And,\\nas with LFS-like ﬁle systems, it’s altogether too easy\\nto combine workloads that would cause all recoverable\\nspace to be situated far from the log’s cleaning pointer.\\nFor example, writing the same sets of blocks over and\\nover would require a full cycle over the disk ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1010: ('arities. However, apart from\\ntheobviousdifferencethatwemodelablockstoreasop-\\nposed to a ﬁle system, a log-structured store that writes\\nand cleans in strict disk-order cannot choose candidate\\nblocks so as to yield higher cleaning efﬁciency. And,\\nas with LFS-like ﬁle systems, it’s altogether too easy\\nto combine workloads that would cause all recoverable\\nspace to be situated far from the log’s cleaning pointer.\\nFor example, writing the same sets of blocks over and\\nover would require a full cycle over the disk content in\\norder for the cleaning pointer to reach the free space\\nnear the end of the log. And, unlike a log-structuredﬁle\\nsystem, the disk here is always “full”, corresponding to\\nmaximalcleaningpressureall thetime.\\n3.3 ParallelismandInterconnect Density\\nIf an SSD is going to achieve bandwidths or I/O rates\\ngreater than the single-chip maxima described in Sec-\\ntion 2.2, it must be able to handle I/O requests on mul-\\ntiple ﬂash packages in parallel, making use of the ad-\\nditional serial connections to their pins. There are sev-\\neral possible techniques for obtaining such parallelism\\nassuming full connectivity to the ﬂash, some of which\\nwe havetouchedonalready.\\n•Parallel requests. In a fully connected ﬂash array,\\neachelementisanindependententityandcanthere-\\nfore accept a separate ﬂow of requests. The com-\\nplexity of the logic necessary to maintain a queue\\nper element, however, may be an issue for imple-\\nmentationswith reducedprocessingcapacity.\\n•Ganging. Agangof ﬂash packagescan be utilized\\nin synchronyto optimizea multi-pagerequest. Do-\\ning so can allow multiple packages to be used in\\nparallel without the complexityof multiple queues.\\nHowever, if only one queue of requests ﬂows to\\nsuch a gang, elements will lie idle when requests\\ndon’tspanall ofthem.\\n•Interleaving. As discussed in Section 2.2, inter-\\nleavingcanbeused toimprovebandwidthandhide\\nthelatencyofcostly operations.\\n•Background cleaning. In a perfect world, clean-\\ning would be performed continuously in the back-\\nground on otherwise idle components. The us', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1011: ('izea multi-pagerequest. Do-\\ning so can allow multiple packages to be used in\\nparallel without the complexityof multiple queues.\\nHowever, if only one queue of requests ﬂows to\\nsuch a gang, elements will lie idle when requests\\ndon’tspanall ofthem.\\n•Interleaving. As discussed in Section 2.2, inter-\\nleavingcanbeused toimprovebandwidthandhide\\nthelatencyofcostly operations.\\n•Background cleaning. In a perfect world, clean-\\ning would be performed continuously in the back-\\nground on otherwise idle components. The use of\\noperationsthat don’trequiredata to cross the serial\\ninterface, such as internal copy-back,can help hide\\nthecost ofcleaning.\\nThesituationbecomesmoreinterestingwhenfullcon-\\nnectivity to the ﬂash packages is not possible. Two\\nchoices are readily apparent for organizing a gang of\\nﬂash packages: 1) the packages are connected to a se-\\nrial buswherea controllerdynamicallyselectsthetarget\\nofeachcommand;and2)eachpackagehasseparatedata\\npath to the controller, but the control pins are connected\\ninasinglebroadcastbus. Conﬁguration(1)isdepictedin\\nFigure4. Dataandcontrollinesareshared,andanenable\\nline for each package selects the target for a command.\\nThis scheme increases capacity without requiring more\\npins, but it does not increase bandwidth. Conﬁguration\\n(2) is depicted in Figure 5. Here there is shared set of\\ncontrol pins, but since there are individual data paths to\\neach package, synchronous operations which span mul-\\ntiple packages can proceed in parallel. The enable lines\\ncanberemovedfromthesecondconﬁguration,butinthis\\ncase all operations mustapply to the entire gang,and no\\npackagecanlieidle.\\nInterleavingcanplayarolewithinagang. Alongrun-\\nningoperationsuchasblockerasurecanbeperformedon\\noneelementwhilereadsorwritesareproceedingonoth-\\ners(hencethecontrollineneedonlybeheldlongenoughFlash\\nPkg\\n1Flash\\nPkg\\n3Flash\\nPkg\\n0Flash\\nPkg\\n2Control\\nChip Enables\\nData\\nFigure4: Sharedbusgang\\nFlash\\nPkg\\n1Flash\\nPkg\\n3Flash\\nPkg\\n0Flash\\nPkg\\n2Control\\nChip Enables\\nData\\nFigure5: Sharedcontrolgang\\nto issue a command). Theonlyconstraintiscompeti', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1012: ('butinthis\\ncase all operations mustapply to the entire gang,and no\\npackagecanlieidle.\\nInterleavingcanplayarolewithinagang. Alongrun-\\nningoperationsuchasblockerasurecanbeperformedon\\noneelementwhilereadsorwritesareproceedingonoth-\\ners(hencethecontrollineneedonlybeheldlongenoughFlash\\nPkg\\n1Flash\\nPkg\\n3Flash\\nPkg\\n0Flash\\nPkg\\n2Control\\nChip Enables\\nData\\nFigure4: Sharedbusgang\\nFlash\\nPkg\\n1Flash\\nPkg\\n3Flash\\nPkg\\n0Flash\\nPkg\\n2Control\\nChip Enables\\nData\\nFigure5: Sharedcontrolgang\\nto issue a command). Theonlyconstraintiscompetition\\nfor the shared data and command bus. This could be-\\ncomequiteimportantduringblockrecyclingsinceblock\\nerasure is an order of magnitude more expensive than\\notheroperations.\\nIn another form of parallelism, intra-plane copy-back\\ncanbeusedto implementblockcleaninginbackground.\\nHowever, cleaning can take place with somewhat lower\\nlatencyifpagesarestreamedatmaximumspeedbetween\\ntwo chips. This beneﬁt comes, of course, at the expense\\nofoccupyingtwosetsofcontrollerpinsforthe duration.\\nIt is unlikely that any one choice for exploitingparal-\\nlelism can be optimal for all workloads,and certainly as\\nSSD capacity scales up, it will be difﬁcult to ensure full\\nconnectivitybetweencontrollersandﬂashpackages. The\\nbest choices will undoubtedly be dictated by workload\\nproperties. For example, a highly sequential workload\\nwill beneﬁtfromganging,a workloadwith inherentpar-\\nallelism will take advantage of a deeply parallel request\\nqueuingstructure,andaworkloadwithpoorcleaningef-\\nﬁciency(e.g. nolocality)willrelyonacleaningstrategy\\nthatiscompatiblewiththe foregroundload.\\n3.4 Persistence\\nFlash memory is by deﬁnition persistent storage. How-\\never, in order to recover SSD state, it is essential to re-\\nbuild the logical block map and all related data struc-\\ntures. Thisrecoverymust also reconstructknowledgeof\\nfailedblockssothattheyarenotre-introducedintoactive\\nuse. There are several possible approaches to this prob-\\nlem. Mosttakeadvantageofthefactthateachﬂashpage\\ncontainsadedicatedarea(128bytes)ofmetadatastorage\\nthat can be used to store', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1013: ('y\\nthatiscompatiblewiththe foregroundload.\\n3.4 Persistence\\nFlash memory is by deﬁnition persistent storage. How-\\never, in order to recover SSD state, it is essential to re-\\nbuild the logical block map and all related data struc-\\ntures. Thisrecoverymust also reconstructknowledgeof\\nfailedblockssothattheyarenotre-introducedintoactive\\nuse. There are several possible approaches to this prob-\\nlem. Mosttakeadvantageofthefactthateachﬂashpage\\ncontainsadedicatedarea(128bytes)ofmetadatastorage\\nthat can be used to store the logical block address that\\nmaps to a given ﬂash page. In our simulator, we model\\nthe technique sketched by Birrell et al. [2]. This tech-\\nnique eliminates the need to visit every page at startup\\nbysavingmappinginformationperblockratherthanper\\npage. Notethatinanysuchalgorithm,pageswhosecon-\\ntent has been superseded but not yet erased will appear\\nmultipletimesduringrecovery. Inthesecases, thestable\\nstoragerepresentationmustallowtherecoveryalgorithm\\nto determine the most recent instance of a logical page\\nwithinanallocationpool.\\nFlash parts do not, in general, provide error detection\\nandcorrection. Thesefunctionsmustbeprovidedbyap-\\nplication ﬁrmware. The page metadata can also hold an\\nerror-detection code to determine which pages are valid\\nandwhichblocksarefailure-free,andanerror-correction\\ncode to recover from the single-bit errors that are ex-\\npected with NAND ﬂash. Samsung speciﬁes block life-\\ntime assuming the presence of a single-bit ECC [29]. It\\nmay be possible to extend block lifetime by using more\\nrobusterrorcorrection.\\nTheproblemofrecoveringSSDstate canbebypassed\\naltogether by holding the logical block map in Phase-\\nChangeRAM[14] orMagnetoresistiveRAM [9]. These\\nnon-volatile memories are writable at byte granularity\\nand don’t have the block-erasure constraints of NAND\\nﬂash. Theformerisnotyetwidelyavailable,andthelat-\\ntercanbeobtainedinsmall capacities,butat 1000times\\nthe cost of NAND ﬂash. Alternatively, backup power\\n(e.g. bigcapacitors)might be enoughto ﬂush the neces-\\nsaryrecoverystate toﬂash ondema', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1014: ('busterrorcorrection.\\nTheproblemofrecoveringSSDstate canbebypassed\\naltogether by holding the logical block map in Phase-\\nChangeRAM[14] orMagnetoresistiveRAM [9]. These\\nnon-volatile memories are writable at byte granularity\\nand don’t have the block-erasure constraints of NAND\\nﬂash. Theformerisnotyetwidelyavailable,andthelat-\\ntercanbeobtainedinsmall capacities,butat 1000times\\nthe cost of NAND ﬂash. Alternatively, backup power\\n(e.g. bigcapacitors)might be enoughto ﬂush the neces-\\nsaryrecoverystate toﬂash ondemand.\\n3.5 Industry Trends\\nThe market for NAND ﬂash continues to grow both in\\nvolume and in breadth as storage capacity increases and\\ncost per unit storage declines. As of late 2007, laptops\\nare available that use an SSD as the primary disk drive.\\nIn addition, high-end ﬂash systems have become avail-\\nablefortheenterprisemarketplace. Mostproductsinthe\\nmarketplacecanbeplacedintooneofthreecategories.\\nConsumer portable storage. These are inexpensive\\nunits with one or perhapstwo ﬂash packagesand a sim-\\nple controller. They commonly appear as USB ﬂash\\nsticks or camera memories, and feature moderate band-\\nwidth for sequential operations, moderate random read\\nperformance,andverypoorrandomwriteperformance.\\nLaptop disk replacements. These disks provide sub-\\nstantial bandwidth to approximate that of the IDE and\\nSATA disks they replace. Random read performance is\\nfarsuperiortothatofrotatingmedia. Randomwriteper-\\nformanceiscomparableto thatofrotatingmedia.\\nEnterprise/databaseaccelerators. Theseunitspromise\\nvery fast sequential performance, random read perfor-\\nmance superior to that of a high-end RAID array, and\\nvery strong randomwrite performance. They have costs\\nto match. However, the speciﬁed random-write perfor-Sequential Random 4K\\nRead Write Read Write\\nUSB11.7 MB/sec 4.3MB/sec 150/sec <20/sec\\nMTron 100 MB/sec 80 MB/sec 11K/sec 130/sec\\nZeus200 MB/sec 100 MB/sec 52K/sec 11K/sec\\nFusionIO 700 MB/sec 600 MB/sec 87K/sec Notavail\\nTable2: SampleFlash DevicePerformance\\nmance numbers are often a bit mysterious, and some-\\ntimesaremis', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1015: ('al performance, random read perfor-\\nmance superior to that of a high-end RAID array, and\\nvery strong randomwrite performance. They have costs\\nto match. However, the speciﬁed random-write perfor-Sequential Random 4K\\nRead Write Read Write\\nUSB11.7 MB/sec 4.3MB/sec 150/sec <20/sec\\nMTron 100 MB/sec 80 MB/sec 11K/sec 130/sec\\nZeus200 MB/sec 100 MB/sec 52K/sec 11K/sec\\nFusionIO 700 MB/sec 600 MB/sec 87K/sec Notavail\\nTable2: SampleFlash DevicePerformance\\nmance numbers are often a bit mysterious, and some-\\ntimesaremissingaltogether. Forexample,itisoftendif-\\nﬁcultto tell whethercleaningcostsareincluded.\\nInTable2,weprovideperformancenumbersforsam-\\nple devices in these categories. The sample devices are\\nthe Lexar JD Fireﬂy 8GB USB ﬂash stick, the MTron\\nMSD-SATA3025 SSD [20], the ZeusIOPSSSD [30],\\nand the FusionIO ioDrive [10]. The MTron device is in\\nthesecondcategoryabove,whiletheZeusandFusionIO\\ndevices are clearly enterprise-class. We are not privy to\\nthe internals of these devices, but we can speculate on\\nhow they are organized. Previous work [2] points out\\nthat consumer USB ﬂash devices almost certainly use a\\nlogicalpagegranularityclosetothesizeofaﬂashblock.\\nLimited random read performance suggests that only a\\nsingleI/Orequestisinﬂightatatime. TheMTrondevice\\ngives random read I/O performance better than can be\\nexpected with a single ﬂash request stream, so it almost\\ncertainlyemployssomesortofparallelrequeststructure.\\nHowever, the poor random write I/O performance sug-\\ngests that a large logical page size is being used (with\\nsubstantial read-modify-write costs). The random write\\nperformanceoftheZeusandFusionIOdevicessuggesta\\nsophisticated block mapping scheme, and multiple par-\\nallel activities are clearly needed to reach the stated ran-\\ndomI/Operformance. TheZeussystemappearstolower\\npressure on its cleaning algorithm by substantial over-\\nprovisioning [7]. The FusionIO system (for which only\\na preliminary speciﬁcation was available in 2007) is the\\nﬁrst tooffera PCI-Expressinterconnect.\\n4 DesignDetailsand Evaluation\\nFrom our ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1016: ('th\\nsubstantial read-modify-write costs). The random write\\nperformanceoftheZeusandFusionIOdevicessuggesta\\nsophisticated block mapping scheme, and multiple par-\\nallel activities are clearly needed to reach the stated ran-\\ndomI/Operformance. TheZeussystemappearstolower\\npressure on its cleaning algorithm by substantial over-\\nprovisioning [7]. The FusionIO system (for which only\\na preliminary speciﬁcation was available in 2007) is the\\nﬁrst tooffera PCI-Expressinterconnect.\\n4 DesignDetailsand Evaluation\\nFrom our discussion of industry trends, it is clear that\\ncurrent SSDs can get very good performance numbers\\nfrom ideal workloads. For example, under sequen-\\ntial workloads these devices verge on saturating any\\ninterconnect, RAID controller [24], or host peripheral\\nchipset [1]. However, it’s unclear whether this is true\\nof a single sequential stream, or multiple streams. And\\nif multiple, how many streams are optimal? Does the\\nstatedwriteperformanceaccountforcleaningoverhead?\\nWhat is the random write performanceand what are the\\nassumptionsabout distribution of superseded pagesdur-\\ningcleaning?\\nThissectionintroducesatrace-drivensimulationenvi-\\nronmentthatallowsustogaininsightintoSSDbehavior\\nundervariousworkloads.\\n4.1 Simulator\\nOur simulation environment is a modiﬁed version of\\nthe DiskSim simulator [4] from the CMU Parallel Data\\nLab. DiskSim does not speciﬁcally support simulation\\nof solid-state disks, but its infrastructure for processin g\\ntracelogsanditsextensibilitymadeit agoodvehiclefor\\ncustomization.\\nDiskSim emulates a hierarchy of storage components\\nsuch as busesand controllers(e.g. RAID arrays)as well\\nas disks. We implementedan SSD module derivedfrom\\nthe generic rotating disk module. Since this module did\\nnotoriginallysupportmultiplerequestqueues,weadded\\nanauxiliarylevelofparallelelements,eachwithaclosed\\nqueue, to represent ﬂash elements or gangs. We also\\nadded logic to serialize request completions from these\\nparallel elements. For each element, we maintain data\\nstructures to represent SSD logical block maps, clean', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1017: ('s a hierarchy of storage components\\nsuch as busesand controllers(e.g. RAID arrays)as well\\nas disks. We implementedan SSD module derivedfrom\\nthe generic rotating disk module. Since this module did\\nnotoriginallysupportmultiplerequestqueues,weadded\\nanauxiliarylevelofparallelelements,eachwithaclosed\\nqueue, to represent ﬂash elements or gangs. We also\\nadded logic to serialize request completions from these\\nparallel elements. For each element, we maintain data\\nstructures to represent SSD logical block maps, clean-\\ning state, and wear-leveling state. As each request is\\nprocessed,sufﬁcientdelayisintroducedtosimulatereal-\\ntime delay according to the speciﬁcations in Table 1. If\\ncleaningandrecyclingiscalledforbythesimulatorstate,\\nadditional delay is introduced to account for it, and the\\nstateisupdatedaccordingly. Weaddedconﬁgurationpa-\\nrameterstoenablesuchfeaturesasbackgroundcleaning,\\ngang-size, gang organization (e.g. switched or shared-\\ncontrol),interleaving,andoverprovisioning.\\nVerifyingoursimulationrequiresdetailedexperiments\\nto determine the caching and ﬂash-management algo-\\nrithms used by actual SSD hardware. We intend to do\\nthisasfuturework.\\n4.2 Workloads\\nWe present results for a collection of workload traces\\nwhichwenameasfollowsforthepurposeofexposition:\\nTPC-C, Exchange,IOzone,andPostmark.\\nWe ﬁrst examine a synthetic workload generated by\\nDiskSim. Wepresentthisworkloadtocharacterizebase-\\nline behavior for sequential and random access request\\nstreams. IOzone[15]andPostmark[16]arestandardﬁle\\nsystembenchmarksrunonaworkstationclassPCwitha\\n750GBSATAdisk. Thesebenchmarksrequirerelatively\\nlittlecapacity,andcanbesimulatedonasingleSSD.De-\\nspite thefactthat we donotsimulate on-diskcaching,in\\nthe above traces, the disk cache was enabled, producing\\nunnaturallylowrequestinter-arrivaltimesforwrites.\\nTPC-C is an instance of the well-established database\\nbenchmark [31]. Our trace is a 30-minute trace of alarge-scale TPC-C conﬁguration, running 16,000 ware-\\nhouses. The traced system comprised 14 RAID (HP\\nMSA1500 Fibre-Channel) cont', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1018: ('orkstationclassPCwitha\\n750GBSATAdisk. Thesebenchmarksrequirerelatively\\nlittlecapacity,andcanbesimulatedonasingleSSD.De-\\nspite thefactthat we donotsimulate on-diskcaching,in\\nthe above traces, the disk cache was enabled, producing\\nunnaturallylowrequestinter-arrivaltimesforwrites.\\nTPC-C is an instance of the well-established database\\nbenchmark [31]. Our trace is a 30-minute trace of alarge-scale TPC-C conﬁguration, running 16,000 ware-\\nhouses. The traced system comprised 14 RAID (HP\\nMSA1500 Fibre-Channel) controllers each supporting\\n28 high-speed 36 GB disks. We target one of the con-\\ntrollers serving non-log data tables: a mixed read/write\\nworkloadwithabouttwiceasmanyreadsaswrites. (The\\n13 non-log controllers have similar workloads.) Al-\\nthough each controller manages over a terabyte of stor-\\nage, the benchmark uses only about 160GB per con-\\ntroller. The large number of disks are needed to obtain\\ndisk arms that can handle requests in parallel. All re-\\nquests in this workloadare for multiplesof 8KB blocks.\\nAlignment is important, since misaligned requests to\\nﬂash add a page access to every read or write. Several\\nof the logical volumes in our conﬁguration were mis-\\naligned, yielding traces in which LBA mod 8 = 7for\\nallLBA. We corrected for this by post-processing the\\nroughly6.8Meventsinthistrace.\\nThe Exchange workload is taken from a server run-\\nningMicrosoftExchange. Thisis a specializeddatabase\\nworkloadwithabouta3:2read-to-writeratio. Thetraced\\nserverhad6non-logRAIDcontrollersofaterabyteeach\\n(14 disks). We extracted a 15 minute trace of roughly\\n65000eventsfromoneofthesecontrollers,involvingre-\\nquestsover250GBofdiskcapacity.\\n4.3 SimulationResults\\nWe ﬁrst present results from a simple workload synthe-\\nsizedbytheDiskSimworkload-generator.Then,wevary\\ndifferentconﬁgurationparametersandstudytheirimpact\\nonSSD performanceunderthemacrobenchmarks.\\nOur baseline conﬁguration is an SSD with 32GB of\\nﬂash: 8 fully connected ﬂash packages. In this conﬁg-\\nuration, allocation pools are the size of a ﬂash package,\\nthe logical page an', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1019: ('ted a 15 minute trace of roughly\\n65000eventsfromoneofthesecontrollers,involvingre-\\nquestsover250GBofdiskcapacity.\\n4.3 SimulationResults\\nWe ﬁrst present results from a simple workload synthe-\\nsizedbytheDiskSimworkload-generator.Then,wevary\\ndifferentconﬁgurationparametersandstudytheirimpact\\nonSSD performanceunderthemacrobenchmarks.\\nOur baseline conﬁguration is an SSD with 32GB of\\nﬂash: 8 fully connected ﬂash packages. In this conﬁg-\\nuration, allocation pools are the size of a ﬂash package,\\nthe logical page and stripe size is 4KB, and cleaning re-\\nquires data transfer across the ﬂash package serial inter-\\nface. Because we model only a small SSD, the larger\\nworkloadsrequirethatwesimulateaRAIDcontrolleras\\nwell. We assume that each SSD is overprovisioned by\\n15%,whichmeansthatthediskcapacityavailabletothe\\nhostisaround27GB.Weinvokecleaningwhenlessthan\\n5% free blocksremain. The TPC-C workloadrequires6\\nattached SSDs in this conﬁguration, and the Exchange\\nworkloadrequires10.\\nMicrobenchmark Cleaning Latency ( µs)IO/s\\nSequential read x 130 61,255\\nRandom read x 130 61,255\\nSequential write x 309 25,898\\nRandom write x 309 25,898\\nSequential write√327 24,457\\nRandom write√433 18,480\\nTable3: SSD performanceundermicrobenchmarks\\n 0 0.2 0.4 0.6 0.8 1 1.2 1.4 1.6 1.8\\nTPC-C IozonePostmark ExchangeIO/s\\n   Performance Improvement with Interleaving\\nNone\\nDies\\nPlane-pairs\\n(a)\\n0816\\nTPC-C Iozone Postmark Exchange# requests\\n   Average Queue Length\\nQueue length\\n(b)\\nFigure6: Impactofinterleaving\\nMicrobenchmarks. We ran a set of 6 synthetic mi-\\ncrobenchmarksinvolving4KBI/Ooperationsandreport\\nthe access latencyand respectiveI/O rates in Table 3. In\\nafully-connectedSSD,sequentialandrandomI/Oshave\\nequivalent latencies. Note that this latency includes the\\ntimetotransferboththepagedataandthe128-bytepage\\nmetadata. When cleaning is enabled, the latencies for\\nwrite operations reﬂect the additional overhead. Notice\\nthat sequential writesresult in better cleaningefﬁciency ,\\nandthereforelesscleaningoverhead.\\nPage Size, Striping, and Interleaving. Choice of lo', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1020: ('robenchmarksinvolving4KBI/Ooperationsandreport\\nthe access latencyand respectiveI/O rates in Table 3. In\\nafully-connectedSSD,sequentialandrandomI/Oshave\\nequivalent latencies. Note that this latency includes the\\ntimetotransferboththepagedataandthe128-bytepage\\nmetadata. When cleaning is enabled, the latencies for\\nwrite operations reﬂect the additional overhead. Notice\\nthat sequential writesresult in better cleaningefﬁciency ,\\nandthereforelesscleaningoverhead.\\nPage Size, Striping, and Interleaving. Choice of logi-\\ncal page size has a substantial impact on overall perfor-\\nmance. As discussed in Section 3.1, every write that is\\nsmallerthanthelogicalpagesizerequiresaread-modify-\\nwrite operation. When run with a full-block page size\\n(256KB) at unit depth (e.g., the entire logical page on\\nthesamedie),TPC-CproducesanaverageI/Olatencyof\\nover 20 ms, more than two orders of magnitude greater\\nthan what can be expected with a 4KB page size. Our\\neightpackageconﬁgurationwith a 256KBpagesize can\\n(barely)keepupwiththe averagetracerateof 300IOPS\\nper SSD, but only due to the inherent parallelism avail-\\nable in the SSD. We do much better with a smaller page\\nsize. The average latency for TPC-C is 200 µs with a\\npage size of 4KB, although the workload does not have\\nenough events to test the 40,000 IOPS that this implies.\\nAsdescribedinSection2.2,I/Operformancecanbe im-\\nproved by interleaving multiple requests within a single\\nﬂash package or die. Our simulator accounts for inter-\\nleaving by noticing when two requests are queued on a\\nﬂashpackagethatcanproceedconcurrentlyaccordingto\\nthe hardware constraints. Figure 6(a) presents I/O rates 0 5 10 15 20 25 30 35 40\\nTPC-C IozonePostmark ExchangeResponse Time (relative to no gang)\\n   8-way\\n4-way\\n2-way\\nSync 8-way\\nSync 4-way\\nSync 2-way\\nFigure7: Shared-controlganging\\nnormalized with respect to our baseline conﬁguration\\nand shows how various types of interleaving improves\\nthe performance of our baseline conﬁguration. While\\nIOzone and Postmark show an increase in throughput,\\nTPC-C and Exchange do not', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1021: ('packagethatcanproceedconcurrentlyaccordingto\\nthe hardware constraints. Figure 6(a) presents I/O rates 0 5 10 15 20 25 30 35 40\\nTPC-C IozonePostmark ExchangeResponse Time (relative to no gang)\\n   8-way\\n4-way\\n2-way\\nSync 8-way\\nSync 4-way\\nSync 2-way\\nFigure7: Shared-controlganging\\nnormalized with respect to our baseline conﬁguration\\nand shows how various types of interleaving improves\\nthe performance of our baseline conﬁguration. While\\nIOzone and Postmark show an increase in throughput,\\nTPC-C and Exchange do not beneﬁt from interleaving.\\nAs shown in Figure 6(b), the average number of queued\\nrequests (per ﬂash package, as measured by DiskSim)\\nis very close to zero for these two workloads. With no\\nqueuing, interleaving will not occur. IOzone and Post-\\nmarkhaveasigniﬁcantsequentialI/Ocomponent. When\\nalargesequentialrequestisdispatchedtomultiplepack-\\nages due to stripe boundaries, queuing occurs and inter-\\nleavingbecomesbeneﬁcial. OnemightthinkthatTPC-C\\nwould beneﬁt from striping its 8KB requests at 8KB in-\\ncrements thereby allowing every request to interleave at\\nthe package or die level. However, splitting up each re-\\nquestintoparallel4KBrequestsisin thiscase superior.\\nNo gang 8-gang 16-gang\\nHostIOLatency 237µs553µs746µs\\nIOPSper gang 4425 1807 1340\\nTable4: Shared-busgangperformanceforExchange\\nGangPerformance. As suggestedin Section3.3,gang-\\ningﬂashcomponentsoffersthepossibilityofscalingca-\\npacity without linearly scaling pin density and ﬁrmware\\nlogic complexity. We proposed two types of ganging:\\nshared-bus and shared-control. Table 4 shows the av-\\nerage latency of Exchange I/O requests (variable size)\\nunder 8-wide (32KB) and 16-wide (64KB) shared-bus\\ngangs. As it happens, this workload requires only about\\n900IOPS,sothe16-gangisfastenougheventhoughthe\\nganged components have to be accessed serially. There\\nisnoobviousload-balancingproblemwhensimplepage-\\nlevelstripingisused,eventhoughonewouldexpectsuch\\nproblemstobeexacerbatedbyganging.\\nA shared-control gang can be organized in two ways.\\nFirst, although the ﬂash packages are ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1022: ('ontrol. Table 4 shows the av-\\nerage latency of Exchange I/O requests (variable size)\\nunder 8-wide (32KB) and 16-wide (64KB) shared-bus\\ngangs. As it happens, this workload requires only about\\n900IOPS,sothe16-gangisfastenougheventhoughthe\\nganged components have to be accessed serially. There\\nisnoobviousload-balancingproblemwhensimplepage-\\nlevelstripingisused,eventhoughonewouldexpectsuch\\nproblemstobeexacerbatedbyganging.\\nA shared-control gang can be organized in two ways.\\nFirst, although the ﬂash packages are ganged, separate\\nallocation and cleaning decisions can be made on each\\npackage, enabling one to perform opportunistic parallel\\noperations, e.g., when two reads are presented on dif-\\nferent gang members at the same time, they can be per-\\nformed concurrently. We refer to this as asynchronous-\\nshared-control ganging. Second, all packages in a gang\\ncan be managedin synchronybyutilizing a logicalpage\\ndepth equal to that of gang size, e.g., a 8-wide gang\\nwouldhavea pagesize of32KB,andwe callthisdesign\\nsynchronous-shared-controlganging. Weuseintra-plane\\ncopy-backto implementread-modify-writefor writes of\\nlessthana pageinsynchronousganging.\\nFigure 7 presents normalized response time (with re-\\nspect to the base line conﬁguration) from various syn-\\nchronous and asynchronous shared-control gang sizes.\\nSincethelogicalpagesizeofasynchronousgangisbig-\\nger than the corresponding asynchronous gang, it lim-\\nits the number of simultaneous operations that can be\\nperformed in a gang unit, and hence synchronousgang-\\ning uniformly underperforms when compared to asyn-\\nchronous ganging. The synchronous 8-way gang could\\nnot support the IOzone workload in simulated real-time\\nandhenceitsresultis absentin theFigure7.\\n# cleaned Avg. time (ms) Efﬁciency\\nTPC-C (inter-plane) 114 9.65 70%\\nTPC-C (copy-back) 108 5.85 70%\\nIOzone 101170 1.5 100%\\nPostmark 2693 1.5 100%\\nTable 5: Cleaningfrequencyandefﬁciency\\nCopy-back vs. Inter-plane Transfer. Cleaning a block\\ninvolvesmovinganyvalidpagesto anotherblock. If the\\nsource and destination blocks are withi', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1023: (' underperforms when compared to asyn-\\nchronous ganging. The synchronous 8-way gang could\\nnot support the IOzone workload in simulated real-time\\nandhenceitsresultis absentin theFigure7.\\n# cleaned Avg. time (ms) Efﬁciency\\nTPC-C (inter-plane) 114 9.65 70%\\nTPC-C (copy-back) 108 5.85 70%\\nIOzone 101170 1.5 100%\\nPostmark 2693 1.5 100%\\nTable 5: Cleaningfrequencyandefﬁciency\\nCopy-back vs. Inter-plane Transfer. Cleaning a block\\ninvolvesmovinganyvalidpagesto anotherblock. If the\\nsource and destination blocks are within a plane, pages\\ncan be moved using the copy-back feature without hav-\\ning to transfer them across the serial pins. Otherwise,\\npages can be moved between planes through the serial\\npins. Table 5 presents the average number of blocks\\ncleaned per ﬂash package, the average time to clean a\\nblock, and the average cleaning efﬁciency. Using the\\ncopy-back feature, TPC-C shows a 40% improvement\\nin cleaning cost per block. In spite of the large number\\nblocksbeingcleaned,IOzoneandPostmarkdonotshow\\nanybeneﬁt fromcopy-back. These benchmarksproduce\\nperfect cleaning efﬁciency; they move no pages during\\ncleaning.\\nCleaning Thresholds. An SSD needs a minimumnum-\\nber of free blocksto operate correctly; for example,free\\nblocksarerequiredtoperformdatatransferduringclean-\\ning or to sustain sudden bursts of write requests. In-\\ncreasingthisminimum-blockthresholdtriggerscleaning\\nearlier and therefore increases observed overhead. Fig-\\nure 8(a) shows the variation in access latency as we in-\\ncrease the free blocksthreshold. While the access laten- 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35\\n 5  6  7  8  9  10Access latency (ms)\\n(a) Minimum free blocks before cleaning starts (%)Access Latency vs. Minimum Free Blocks\\nTPC-C\\nIozone\\nPostmark\\nExchange\\n 0 200 400 600 800 1000 1200 1400 1600\\n 5  6  7  8  9  10Pages moved (in 1000s)\\n(b) Minimum free blocks before cleaning starts (%)Pages Moved During Cleaning\\nTPC-C\\nIozone\\nPostmark\\nExchange\\nFigure8: Impactofminimumfreeblocks\\ncies increase in TPC-C with the threshold, other work-\\nloadsshowlittledifference. Th', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1024: ('cess laten- 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35\\n 5  6  7  8  9  10Access latency (ms)\\n(a) Minimum free blocks before cleaning starts (%)Access Latency vs. Minimum Free Blocks\\nTPC-C\\nIozone\\nPostmark\\nExchange\\n 0 200 400 600 800 1000 1200 1400 1600\\n 5  6  7  8  9  10Pages moved (in 1000s)\\n(b) Minimum free blocks before cleaning starts (%)Pages Moved During Cleaning\\nTPC-C\\nIozone\\nPostmark\\nExchange\\nFigure8: Impactofminimumfreeblocks\\ncies increase in TPC-C with the threshold, other work-\\nloadsshowlittledifference. Thisdifferenceintheaccess\\nlatenciesamongdifferentworkloadsisexplainedbyFig-\\nure8(b),whichplotsthe numberofpagesmovedduring\\ncleaning against the free blocks threshold. Figures 8(a)\\nand 8(b) show that increasing the minimum free blocks\\nthresholdmayaffecttheoverallperformanceoftheSSD\\ndependinguponthe pagesmovedunderthe workload.\\n4.4 Tradeoff Summary\\nIn Table 6, we present a brief summary of the beneﬁts\\nanddrawbacksofthedesigntechniquesdiscussedabove.\\nWe believe that these tradeoffs are largely independent\\nof each other, but leave a rigorous examination of this\\nhypothesisforfuturework.\\nTechnique Positives Negatives\\nLargeallocation pool Load balancing Few intra-chip ops\\nLargepage size Small page table Read-modify-writes\\nOverprovisioning Less cleaning Reduced capacity\\nGanging Sparser wiring Reduced parallelism\\nStriping Concurrency Lossof locality\\nTable6: SSD DesignTradeoffsinBrief\\n5 Wear-leveling\\nInthediscussionbelow,weproposeacleaningandwear-\\nleveling algorithm applicable to NAND-ﬂash SSDs. We\\nassumethatanSSDimplementsablock-orienteddiskin-\\nterfacewhichprovidesno aprioriknowledgeofoptimal\\ndataplacementorlikelylongevity.\\nEfﬁcient cleaning, while it may reduce overall wear,\\ndoesnottranslate to evenwear. Thedrawbackof choos-\\ning a greedy approach (maximal cleaning efﬁciency) is\\nthat the same blocks may get used over and over again\\nanda largecollectionof blockswith relativelycoldcon-\\ntent may remain unused. For example, if 50% of the\\nblocks contain cold data that is never superseded, and\\ntherestcontainshotdatathatismodiﬁe', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1025: ('ntsablock-orienteddiskin-\\nterfacewhichprovidesno aprioriknowledgeofoptimal\\ndataplacementorlikelylongevity.\\nEfﬁcient cleaning, while it may reduce overall wear,\\ndoesnottranslate to evenwear. Thedrawbackof choos-\\ning a greedy approach (maximal cleaning efﬁciency) is\\nthat the same blocks may get used over and over again\\nanda largecollectionof blockswith relativelycoldcon-\\ntent may remain unused. For example, if 50% of the\\nblocks contain cold data that is never superseded, and\\ntherestcontainshotdatathatismodiﬁedfrequently,then\\nthe block to be erased will always be taken from the hot\\nblocks. This will lead to a situation where the life of the\\nhotblockswillbeconsumedwhilethatofthecoldblocks\\nwillbeunutilized,wastinghalfthetotallifeofthedevice .\\nOur objective is to design a block management algo-\\nrithm so as to delay the expiry time of any single block;\\nthat is, we wish to avoid the situation where one or a\\nfewblockshaveﬁnishedtheirlifewhenmostblockshave\\nmuchlifeleft. Thisgoalimpliesthatwemustensurethat\\ntheremaininglifetimeacrossallblocksisequalwithinan\\nacceptablevariance. Tothisend,weproposetrackingthe\\naverage lifetime remaining over all blocks. The remain-\\ninglifetimeofanyblockshouldbewithin ageV ariance\\n(say20%)oftheaverageremaininglifetime.\\nThis desired policy can be achieved by running the\\ngreedystrategyas longas it picksa pagewhose remain-\\ning lifetime is above the threshold. To do this, we must\\nmaintain some notion of block erase count in persistent\\nstorage (for example in the metadata portion of the ﬁrst\\npage). What then should we do for worn out blocks\\nthat drop below the threshold? A simple approach is to\\nonly allow recycling when a candidate’s remaining life-\\ntime exceeds the threshold. Doing this could exclude\\nlargenumbersofblocksfromconsiderationwhichinturn\\nwould cause the remaining blocks to be recycled more\\nfrequently and with poorer cleaning efﬁciency. For ex-\\nample if 25% of the blocks have cold data and the re-\\nmaining 75% have hot data accessed uniformly then af-\\nter a certain number of writes, the lat', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1026: (' What then should we do for worn out blocks\\nthat drop below the threshold? A simple approach is to\\nonly allow recycling when a candidate’s remaining life-\\ntime exceeds the threshold. Doing this could exclude\\nlargenumbersofblocksfromconsiderationwhichinturn\\nwould cause the remaining blocks to be recycled more\\nfrequently and with poorer cleaning efﬁciency. For ex-\\nample if 25% of the blocks have cold data and the re-\\nmaining 75% have hot data accessed uniformly then af-\\nter a certain number of writes, the latter will get worn\\nout and becomeineligible for erasure. Subsequently,re-\\ncycling will be concentrated on the 25% of the blocks\\ncontaining cold data. So these blocks will be reused 4\\ntimes faster and yield commensurately fewer pages per\\nerasure. Hence,weneedtoavoidmakingalargenumber\\nofblocksineligibleforrecyclingoveranextendedperiod\\noftime.\\nInstead of freezing the recycling of worn out blocks,\\nwecanrate-limittheirusage. Randomizationcanbeused\\nhere to evenlyspreadout the effect of a rate-limit on the\\nwornoutblocks. We useanapproachsimilartoRandom\\nEarly Discard [8] in which the probability of recycling\\ndropslinearlyfrom1to0asablock’sremaininglifetime\\ndropsfromsay 80%to0% ofthe average.\\nAnother way to slow down the usage of worn out\\nblocks is to migrate cold data into old blocks. When\\ndata is migrated, cleaning is performed as usual, but\\nthen rather than attaching the recycled block to the al-\\nlocation pool queue, instead data from a cold block is\\nused to ﬁll it. The cold block is then recycled and\\nadded to the free queue. This action can be triggered,for example, if the remaining lifetime in a block drops\\nbelow retirementAge (say 85% of the average re-\\nmaining lifetime). retirementAge should be less than\\nageV ariance ofaverageremaininglifetimesothatcold\\ndata can be migrated into a worn out block before rate-\\nlimitingkicksin.\\nOne methodto identifycold data is to lookfor blocks\\nthat have exceeded speciﬁed parameters for remaining\\nlifetime and time since last erasure. This approximation\\ncan be made more accurate by k', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1027: ('ree queue. This action can be triggered,for example, if the remaining lifetime in a block drops\\nbelow retirementAge (say 85% of the average re-\\nmaining lifetime). retirementAge should be less than\\nageV ariance ofaverageremaininglifetimesothatcold\\ndata can be migrated into a worn out block before rate-\\nlimitingkicksin.\\nOne methodto identifycold data is to lookfor blocks\\nthat have exceeded speciﬁed parameters for remaining\\nlifetime and time since last erasure. This approximation\\ncan be made more accurate by keeping track of when\\na block was last written in its metadata. In this case,\\nit is important that temperature metadata travel with the\\ncontent as it is moved to a new physical block. When\\na block is migrated, the migration should not affect its\\ntemperature metric. However, the process of cleaning\\ncan group pages of different temperatures in the same\\nblock,inthiscase, theresultantblocktemperatureneeds\\ntoreﬂect thatoftheaggregate.\\nSo in summary, we propose running the greedy strat-\\negy(e.g.,themostsupersededpages)forpickingthenext\\nblockto berecycled,asmodiﬁedbelow.\\n•If the remaining lifetime in the chosen block is be-\\nlowretirementAge of the averageremaining life-\\ntime then migrate cold data into this block from\\na migration-candidate queue, and recycle the head\\nblockof the queue. Populatethe queuewith blocks\\nexceedingparametricthresholdsforremaininglife-\\ntime and duration, or alternatively, choose migra-\\ntioncandidatesbytrackingcontenttemperature.\\n•Otherwise, if the remaining lifetime in the chosen\\nblock is below ageV ariance , then restrict recy-\\ncling of the block with a probability that increases\\nlinearlyasthe remaininglifetimedropsto 0.\\n5.1 Wear-levelingSimulation\\nWeranIOzone(duetoitshighcleaningrate)tostudythe\\nwear-leveling algorithm described above. We reduced\\nthe lifetime of a ﬂash block from 100K to 50 cycles for\\nour experiment so that the ageV ariance (set to 20%)\\nandretirementAge (setto85%)thresholdsbecomerel-\\nevant. Tables 7 and 8 present the results for 3 differ-\\nent techniques: the greedy algorithm, ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1028: ('ow ageV ariance , then restrict recy-\\ncling of the block with a probability that increases\\nlinearlyasthe remaininglifetimedropsto 0.\\n5.1 Wear-levelingSimulation\\nWeranIOzone(duetoitshighcleaningrate)tostudythe\\nwear-leveling algorithm described above. We reduced\\nthe lifetime of a ﬂash block from 100K to 50 cycles for\\nour experiment so that the ageV ariance (set to 20%)\\nandretirementAge (setto85%)thresholdsbecomerel-\\nevant. Tables 7 and 8 present the results for 3 differ-\\nent techniques: the greedy algorithm, greedy with rate-\\nlimited cleaning of worn-out blocks, and greedy with\\nrate-limiting and cold data migration. Although the av-\\nerage block lifetime is similar across the techniques, in-\\nvoking migration gives a much smaller standard devia-\\ntion of remaining block lifetimes at the end of the run.\\nMoreover, with migration, there were no block expiries\\n(e.g., blocks over the erasure limit). Since the sim-\\nplegreedytechniquedoesnotperformanyrate-limiting,\\nfewerblocksreachexpirywhenrate-limitingisusedthan\\nwithoutit. Table8presentsthedistributionofﬂash-block\\nlifetimes around the mean. One can observe that cold\\ndata migration offers better clustering around the mean\\nthantheotheroptions.\\nMean Lifetime Std.Dev. Expired blocks\\nGreedy 43.82 13.47 223\\n+Rate-limiting 43.82 13.42 153\\n+Migration 43.34 5.71 0\\nTable7: BlockwearinIOzone\\n<40% <80% <100% ≥100%\\nGreedy 1442 1323 523 13096\\n+Rate-limiting 1449 1341 501 13092\\n+Migration 0 08987 7397\\nTable8: Lifetimedistributionwithrespecttomean\\nThe cost of migrating cold pages across blocks im-\\nposes a performance cost that is workload-dependent.\\nOur simulation of wear-leveling for IOzone involved\\n7902 migrations per package which added a 4.7% over-\\nheadtotheaverageI/Ooperationlatency.\\n5.2 Opening the Box\\nA system that implements a traditional disk-block in-\\nterface incurs unnecessary overhead by managing disk\\nblocksthatarefreefromthepointofviewoftheﬁlesys-\\ntem. Under a random workload, a disk that is half full\\nwillhavetwicethecleaningefﬁciencyofafulldisk(and\\nall disks are full except ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1029: (' blocks im-\\nposes a performance cost that is workload-dependent.\\nOur simulation of wear-leveling for IOzone involved\\n7902 migrations per package which added a 4.7% over-\\nheadtotheaverageI/Ooperationlatency.\\n5.2 Opening the Box\\nA system that implements a traditional disk-block in-\\nterface incurs unnecessary overhead by managing disk\\nblocksthatarefreefromthepointofviewoftheﬁlesys-\\ntem. Under a random workload, a disk that is half full\\nwillhavetwicethecleaningefﬁciencyofafulldisk(and\\nall disks are full except those that are overprovisioned).\\nPreviousworkonSemantically-SmartDiskSystems[21]\\nhas shown the beneﬁts of greater ﬁle-system informa-\\ntion being available at the disk level. Although SSDs\\nthat implement a pure disk interface provide advantages\\nfroma perspectiveof compatibility,it is worth consider-\\ning whether the SSD API might support the abstraction\\nof an unused block. With such a modiﬁcation,SSD per-\\nformance would vary with the percentage of free space\\nrather than always suffering maximal cleaning load and\\nwear.\\nCleaning load can be reduced if an SSD has knowl-\\nedgeofcontentvolatility. Forexample,certainﬁle types\\nsuch as audio and video ﬁles are not often modiﬁed. If\\navailable at the disk block level, this information would\\nprovide a better predictive metric than the history-based\\napproximations above. More importantly, if cold data\\ncanbeidentiﬁed apriori,thenthereisabetterchanceof\\nestablishinglocalityforwarmdata,localizationofwarm\\ndatawill leadtobettercleaningefﬁciency.\\n6 Related Work\\nWe discuss related work in designing solid-state stor-\\nagedevices,ﬁlesystemsforimprovingperformance,and\\nworkonalgorithmsanddatastructuresforsuchdevices.6.1 Solid-State StorageDevices\\nPrevious work on solid-state storage design has focused\\nonresource-constrainedenvironmentssuchasembedded\\nsystems or sensor networks (e.g., Capsule [19], Micro-\\nHash [34]). This body of work has largely dealt with\\nsmall ﬂash devices(upto afew hundredMB),with low-\\npower, shock resistance and size being primary consid-\\nerations. The MicroHash index ', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1030: ('work in designing solid-state stor-\\nagedevices,ﬁlesystemsforimprovingperformance,and\\nworkonalgorithmsanddatastructuresforsuchdevices.6.1 Solid-State StorageDevices\\nPrevious work on solid-state storage design has focused\\nonresource-constrainedenvironmentssuchasembedded\\nsystems or sensor networks (e.g., Capsule [19], Micro-\\nHash [34]). This body of work has largely dealt with\\nsmall ﬂash devices(upto afew hundredMB),with low-\\npower, shock resistance and size being primary consid-\\nerations. The MicroHash index [34] attempts to support\\ntemporalqueriesondatastoredlocallyonaﬂash chipin\\nthe presence of a low energy budget. Nath and Kansal\\npropose FlashDB [23], a hybrid B+-tree index design.\\nThe key idea is to have different update strategies de-\\npending on the frequency of reads and writes: in-place\\nupdatesforpagesthatarefrequentlyreadorinfrequently\\nwritten,andloggingforthosethatarefrequentlywritten.\\nWhiletheworkinembeddedandsensorenvironments\\nhas given useful insights into the workings and con-\\nstraints of solid-state devices, our work systematically\\nexplores design issues in high-performancestorage sys-\\ntems. In these environments,operationthroughputis of-\\ntenthemost importantmetricofinterest.\\nHybriddisksareanotherareaofresearch[3]andcom-\\nmercial interest. These devices place a small amount of\\nﬂash memory alongside a much larger traditional disk\\nto improve performance. Flash is not the ﬁnal persis-\\ntent store, but rather a write-cache to improve latency.\\nThenon-volatilecacheonhybriddiskscanbecontrolled\\nthroughspeciﬁcATA commands[25].\\nFile systems have also used non-volatile memory to\\nlog data or requests. WAFL [13] is one such ﬁle system\\nthat uses non-volatile RAM (NVRAM) to keep a log of\\nNFS requests it has processed since the last consistency\\npoint. After an unclean shutdown, WAFL replays any\\nrequestsinthelogto preventthemfrombeinglost.\\nThe hybrid disk and NVRAM approaches use ﬂash\\nas an add-on storage for rotating disks. In our designs,\\nsolid-state devices serve as a replacement for rotating\\ndisks,providingabetterra', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1031: ('ATA commands[25].\\nFile systems have also used non-volatile memory to\\nlog data or requests. WAFL [13] is one such ﬁle system\\nthat uses non-volatile RAM (NVRAM) to keep a log of\\nNFS requests it has processed since the last consistency\\npoint. After an unclean shutdown, WAFL replays any\\nrequestsinthelogto preventthemfrombeinglost.\\nThe hybrid disk and NVRAM approaches use ﬂash\\nas an add-on storage for rotating disks. In our designs,\\nsolid-state devices serve as a replacement for rotating\\ndisks,providingabetterrateofoperationthroughput.\\nKimandAhn[17]proposeacache-managementstrat-\\negy that improves random-write performance for SSDs\\noperating with a block-sized logical page. They attempt\\nto ﬂush write-cachepagesthat occupythe same blockat\\nthesametime,therebyreducingread-modify-writeover-\\nhead. This works well if the workload does not over-\\nwhelmthecacheorrequireimmediatewritepersistence.\\nMoreover,write-cachingthathandlesburstyorrepetitive\\nwritesiscomplementarytoourapproach.\\n6.2 FileSystem Designs\\nFile systems speciﬁc to ﬂash devices have also been\\nproposed. Most of these designs are based on Log-\\nstructured File Systems [28], as a way to compensate\\nforthewrite latencyassociatedwith erasures. JFFS, and\\nits successor JFFS2 [27], are journaling ﬁle systems for\\nﬂash. TheJFFSﬁlesystemsarenotmemory-efﬁcientfor\\nstoringvolatile data structures,and requirea full scan to\\nreconstruct these data structures from persistent storage\\nupona crash. JFFS2 performswear-leveling,in a some-\\nwhat ad-hoc fashion, with the cleaner selecting a block\\nwith valid data at every 100th cleaning, and one with\\nmostinvaliddataat othertimes.\\nYAFFS [18] is ﬂash ﬁle system for use in embedded\\ndevices. It treats handling of wear-leveling akin to han-\\ndling bad blocks, which appear as the device gets used.\\nOther examples of embedded micro-controller ﬁle sys-\\ntems include the Transactional Flash File System [11]\\nand the Efﬁcient Log Structured Flash File System [6].\\nThe former was designed for more expensive, byte ad-\\ndressable NOR ﬂash memory, which has consid', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1032: ('block\\nwith valid data at every 100th cleaning, and one with\\nmostinvaliddataat othertimes.\\nYAFFS [18] is ﬂash ﬁle system for use in embedded\\ndevices. It treats handling of wear-leveling akin to han-\\ndling bad blocks, which appear as the device gets used.\\nOther examples of embedded micro-controller ﬁle sys-\\ntems include the Transactional Flash File System [11]\\nand the Efﬁcient Log Structured Flash File System [6].\\nThe former was designed for more expensive, byte ad-\\ndressable NOR ﬂash memory, which has considerably\\nfewer constraints than NAND ﬂash. The latter was de-\\nsigned for sensor nodes using NAND ﬂash. It supports\\nsimple garbage collection and provides an optional best\\neffortcrashrecoverymechanism.\\nIt is useful to compare our approach with improve-\\nments higher up in the storage stack, such as the spe-\\ncialized ﬁle systems for ﬂash devices. Enhancementsat\\ntheﬂashcontrollerwillobviatetheneedtoinvestsigniﬁ-\\ncanteffortinre-writingacustomﬂashﬁlesystem. Itwill\\nalso alleviate the overheadof transitioningfromrotating\\ndisks to ﬂash-based storage by exporting a “ﬂash-disk”\\nthatperformswellevenwithexistingﬁle systems.\\n6.3 Algorithms andData-structures\\nMuch prior work has been done on proposing and eval-\\nuatingalgorithmsanddatastructuresspeciallysuitedfor\\noperationinﬂashdevices. Arecentsurvey[12]discusses\\nmuchofthisworkin greaterdetail.\\nWear-leveling is an important constraint of ﬂash de-\\nvicesandseveralproposalshavebeenmadetoperformit\\nefﬁciently, increasing the usable life time of the device.\\nWu and Zwaenepoel [33] use a relative wear-count of\\nblocks for wear-leveling. Similar to our approach, data\\nis swapped when the block chosen for cleaning exceeds\\na wear-count. Wells [32] proposed a reclamation policy\\nbased on weighted combination of efﬁciency and wear-\\nleveling, while the work by Chiang and Chang [5] uses\\nthelikelihoodofablockbeingusedsoon,whichisequiv-\\nalenttothelogicalhotnessorcoldnessofdatawithinthe\\nblockchosenforcleaning.\\nRecent work by Myers [22] looks at ways to exploit\\nthe inherent parallelism offered by the', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1033: ('e a relative wear-count of\\nblocks for wear-leveling. Similar to our approach, data\\nis swapped when the block chosen for cleaning exceeds\\na wear-count. Wells [32] proposed a reclamation policy\\nbased on weighted combination of efﬁciency and wear-\\nleveling, while the work by Chiang and Chang [5] uses\\nthelikelihoodofablockbeingusedsoon,whichisequiv-\\nalenttothelogicalhotnessorcoldnessofdatawithinthe\\nblockchosenforcleaning.\\nRecent work by Myers [22] looks at ways to exploit\\nthe inherent parallelism offered by the ﬂash chip. He\\nfragments a block and stores it on multiple physical\\npageson differentchips,underthehypothesesthat a dy-\\nnamicstripingorreplicationstrategybasedonworkload\\nwill outperform a static one. His work focuses on ap-plicabilityofﬂashfordatabaseworkloadsandconcludes\\nthat widespreadadoptionisnot yetpossible. Incontrast,\\nour design and analysis shows that while there are sev-\\neral tradeoffs, SSDs are a viable and possibly an attrac-\\ntiveoptionfortransactionalworkloadssuchasTPC-C.\\n7 Conclusion\\nAs we have shown, there are numerousdesign tradeoffs\\nfor SSDs that impact performance. There is also sig-\\nniﬁcant interplay between both the hardware and soft-\\nware components and the workload. Our work pro-\\nvides insight into how all of these componentsmust co-\\noperate in order to produce an SSD design that meets\\nthe performance goals of the targeted workload. From\\nthe hardwarestandpoint,theSSD interface(SATA,IDE,\\nPCI-Express) and package organization dictate theoret-\\nical maximum I/O performance. On the software side,\\nthepropertiesoftheallocationpool,loadbalancing,data\\nplacement, and block management (wear-leveling and\\ncleaning) combined with workload characteristics de-\\ntermine overall SSD performance. Moreover, we have\\ndemonstrated that all designs can beneﬁt from plane in-\\nterleaving and some degreeof overprovisioning,and we\\nhave proposed a wear-leveling algorithm and shown its\\nefﬁcacyin atleast onescenario.\\nWe have demonstrated a simulation-based technique\\nfor modeling SSD performance driven by traces ex-\\ntracted', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1034: ('de,\\nthepropertiesoftheallocationpool,loadbalancing,data\\nplacement, and block management (wear-leveling and\\ncleaning) combined with workload characteristics de-\\ntermine overall SSD performance. Moreover, we have\\ndemonstrated that all designs can beneﬁt from plane in-\\nterleaving and some degreeof overprovisioning,and we\\nhave proposed a wear-leveling algorithm and shown its\\nefﬁcacyin atleast onescenario.\\nWe have demonstrated a simulation-based technique\\nfor modeling SSD performance driven by traces ex-\\ntracted from real hardware. In some cases, the traced\\nsystemsrequirestoragecomponentsthatwouldbemuch\\ntoo expensive for most organizations to provide for the\\npurposesofexperimentation. Oursimulationframework\\nhas proved both resilient and ﬂexible, and we expect to\\ncontinuetoaddtothesetofbehaviorsthatwecanmodel.\\nShared-control ganging and reﬁned wear-leveling data\\nareparticulartopicsofinterest.\\nThere is no ﬁxed rule that NAND ﬂash be integrated\\ninto computer systems as disk storage. However, the\\nblock-access nature of NAND suggests that a block-\\noriented interface will often be appropriate. Although\\noutside of the scope of this work, we suspect that our\\nsimulation techniqueswill be applicable to NAND-ﬂash\\nblock-storage independent of architecture because the\\nsameissues(e.g. cleaning,wear-leveling)willstill aris e.\\nFlash-basedstorageiscertaintoplayanimportantrole\\ninfuturestoragearchitectures. Onecorollaryofoursim-\\nulation results is that the storage systems necessary to\\nsupporta substantialTPC-Cworkload,whichinthepast\\nhaveinvolvedmanyhundredsofspindles, mightwell be\\nreplacedinfuturebysmallnumbersofSSD-likedevices.\\nOur work represents a step towards understanding and\\noptimizingtheperformanceofsuchsystems.\\nAcknowledgements\\nWe are grateful to the DiskSim team for making their\\nsimulator available, and to Dushyanth Narayanan for\\nporting it to Windows. Andrew Birrell, Chuck Thacker,\\nandJamesHamiltonparticipatedinmanyfruitfuldiscus-\\nsionsduringthecourseofthiswork. BruceWorthington\\nand Swaroop Kavalanekar gathered our TPC-C and E', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1035: ('aveinvolvedmanyhundredsofspindles, mightwell be\\nreplacedinfuturebysmallnumbersofSSD-likedevices.\\nOur work represents a step towards understanding and\\noptimizingtheperformanceofsuchsystems.\\nAcknowledgements\\nWe are grateful to the DiskSim team for making their\\nsimulator available, and to Dushyanth Narayanan for\\nporting it to Windows. Andrew Birrell, Chuck Thacker,\\nandJamesHamiltonparticipatedinmanyfruitfuldiscus-\\nsionsduringthecourseofthiswork. BruceWorthington\\nand Swaroop Kavalanekar gathered our TPC-C and Ex-\\nchange traces. And ﬁnally, we would like to honor the\\nmemoryofDr. Jim Gray,whoinspiredthiswork.\\nReferences\\n[1] AnandTech. MTRON SSD 32GB: Wile E. Coyote or Road\\nRunner? http://www.anandtech.com/storage/\\nshowdoc.aspx?i=3064 .\\n[2] A. Birrell, M. Isard, C. Thacker, and T. Wobber. A Design\\nfor High-Performance Flash Disks. Operating Systems Review ,\\n41(2):88–93, 2007.\\n[3] T.BissonandS.A.Brandt. Reducing HybridDiskWriteLat ency\\nwithFlash-Backed I/ORequests. In MASCOTS’07: Proceedings\\nof the 15th IEEE International Symposium on Modeling, Analy -\\nsis, and Simulation , 2007.\\n[4] J.S.Bucy,G.R.Ganger,andetal. TheDiskSimSimulation Envi-\\nronment Version 3.0 Reference Manual. http://citeseer.\\nist.psu.edu/bucy03disksim.html .\\n[5] M.-L. Chiang and R.-C. Chang. Cleaning Policies in Mobil e\\nComputers Using Flash Memory. Journal of Systems and Soft-\\nware, 48(3):213–231, 1999.\\n[6] H. Dai, M. Neufeld, and R. Han. ELF: An Efﬁcient Log-\\nStructured Flash File System for Micro Sensor Nodes. In SenSys\\n’04: Proceedingsofthe2ndInternational ConferenceonEmb ed-\\nded Networked Sensor Systems , pages 176–187, 2004.\\n[7] D. Dumitru. Understanding Flash SSD Performance.\\nhttp://managedflash.com/news/papers/\\neasyco-flashperformance-art.pdf .\\n[8] S. Floyd and V. Jacobson. Random early detection gateway s for\\ncongestion avoidance. IEEE/ACM Transactions on Networking ,\\n1(4):397–413, 1993.\\n[9] Freescale Semiconductor. 256K x 16-Bit 3.3-V Asynchron ous\\nMagnetoresistive RAM. http://www.freescale.\\ncom/files/microcontrollers/doc/data_sheet/\\nMR2A16A.pd', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1036: ('national ConferenceonEmb ed-\\nded Networked Sensor Systems , pages 176–187, 2004.\\n[7] D. Dumitru. Understanding Flash SSD Performance.\\nhttp://managedflash.com/news/papers/\\neasyco-flashperformance-art.pdf .\\n[8] S. Floyd and V. Jacobson. Random early detection gateway s for\\ncongestion avoidance. IEEE/ACM Transactions on Networking ,\\n1(4):397–413, 1993.\\n[9] Freescale Semiconductor. 256K x 16-Bit 3.3-V Asynchron ous\\nMagnetoresistive RAM. http://www.freescale.\\ncom/files/microcontrollers/doc/data_sheet/\\nMR2A16A.pdf .\\n[10] FusionIO Corporation. ioDrive Datasheet. http://www.\\nfusionio.com/iodrivedata.pdf .\\n[11] E.Gal and S.Toledo. ATransactional Flash File System f or Mi-\\ncrocontrollers. In Proceedings of the USENIX Annual Technical\\nConference , pages 89–104, 2005.\\n[12] E. Gal and S. Toledo. Algorithms and Data Structures for Flash\\nMemories. ACM Computing Surveys , 37(2):138–163, 2005.\\n[13] D.Hitz,J.Lau,andM.Malcolm. FileSystemDesign foran NFS\\nFile Server Appliance. In Proceedings of the USENIX Winter\\n1994 Technical Conference , pages 235–246, 1994.\\n[14] IBM Corporation. Promising New Memory Chip Technology\\nDemonstrated By IBM, Macronix & Qimonda Joint Research\\nTeam. http://domino.research.ibm.com/comm/\\npr.nsf/pages/news.20061211_phasechange.\\nhtml.\\n[15] IOzone.org. IOzone Filesystem Benchmark. http://www.\\niozone.org .[16] J.Katcher. PostMark: aNew File System Benchmark. Tech nical\\nReport TR3022,Network Appliance, October 1997.\\n[17] H. Kim and S. Ahn. A Buffer Management Scheme for Im-\\nproving Random Writes in Flash Storage. In Proceedings of the\\n6thUSENIXSymposiumonFileandStorage Technologies (FAST\\n’08), pages 239–252, 2008.\\n[18] C. Manning. YAFFS: Yet Another Flash File System. http:\\n//www.aleph1.co.uk/yaffs ,2004.\\n[19] G. Mathur, P. Desnoyers, D. Ganesan, and P. Shenoy. Cap-\\nsule: An Energy-Optimized Object Storage System for Memory -\\nConstrained Sensor Devices. In SenSys ’06: Proceedings of the\\n4th International Conference on Embedded Networked Sensor\\nSystems, pages 195–208, 2006.\\n[20] MTron Co., Ltd. MSD-SATA3025 Prod', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1037: ('age. In Proceedings of the\\n6thUSENIXSymposiumonFileandStorage Technologies (FAST\\n’08), pages 239–252, 2008.\\n[18] C. Manning. YAFFS: Yet Another Flash File System. http:\\n//www.aleph1.co.uk/yaffs ,2004.\\n[19] G. Mathur, P. Desnoyers, D. Ganesan, and P. Shenoy. Cap-\\nsule: An Energy-Optimized Object Storage System for Memory -\\nConstrained Sensor Devices. In SenSys ’06: Proceedings of the\\n4th International Conference on Embedded Networked Sensor\\nSystems, pages 195–208, 2006.\\n[20] MTron Co., Ltd. MSD-SATA3025 Product Speciﬁca-\\ntion.http://mtron.net/Upload_Data/Spec/ASiC/\\nMSD-SATA3025.pdf .\\n[21] Muthian Sivathanu and Vijayan Prabhakaran and Florent ina I.\\nPopovici andTimothyE.DenehyandAndreaC.Arpaci-Dusseau\\nand Remzi H. Arpaci-Dusseau. Semantically-Smart Disk Sys-\\ntems. InProceedings ofthe2ndUSENIXSymposium onFileand\\nStorage Technologies (FAST’03) , pages 73–88, 2003.\\n[22] D. Myers. On the Use of NAND Flash Memory in High-\\nPerformance Relational Databases. Master’s thesis, MIT,2 007.\\n[23] S.NathandA.Kansal. FlashDB:DynamicSelf-Tuning Dat abase\\nfor NAND Flash. In IPSN ’07: Proceedings of the 6th Inter-\\nnational Conference on Information Processing in Sensor Ne t-\\nworks, pages 410–419, 2007.\\n[24] Next Level Hardware. Battleship MTron. http://www.\\nnextlevelhardware.com/storage/battleship/ .\\n[25] N.ObrandF.Shu. ANon-Volatile CacheCommandProposal for\\nATA8-ACS. http://t13.org ,2005.\\n[26] D. Patterson, G. Gibson, and R. Katz. A Case for Redundan t\\nArraysofInexpensiveDisks(RAID).In ProceedingsoftheACM-\\nSIGMOD International Conference on the Management of Data ,\\npages 109–116, 1988.\\n[27] Red Hat Corporation. JFFS2: The Journalling Flash File Sys-\\ntem. http://sources.redhat.com/jffs2/jffs2.\\npdf,2001.\\n[28] M. Rosenblum and J. Ousterhout. The Design and Implemen -\\ntation of a Log-Structured File System. ACM Transactions on\\nComputer Systems , 10(1):26–52, 1992.\\n[29] Samsung Corporation. K9XXG08XXM Flash Memory Speciﬁ-\\ncation. http://www.samsung.com/global/system/\\nbusiness/semiconductor/product/2007/6/11/\\nNANDFlash/SLC_LargeBlock/8Gbi', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1038: ('ference on the Management of Data ,\\npages 109–116, 1988.\\n[27] Red Hat Corporation. JFFS2: The Journalling Flash File Sys-\\ntem. http://sources.redhat.com/jffs2/jffs2.\\npdf,2001.\\n[28] M. Rosenblum and J. Ousterhout. The Design and Implemen -\\ntation of a Log-Structured File System. ACM Transactions on\\nComputer Systems , 10(1):26–52, 1992.\\n[29] Samsung Corporation. K9XXG08XXM Flash Memory Speciﬁ-\\ncation. http://www.samsung.com/global/system/\\nbusiness/semiconductor/product/2007/6/11/\\nNANDFlash/SLC_LargeBlock/8Gbit/K9F8G08U0M/\\nds_k9f8g08x0m_rev10.pdf ,2007.\\n[30] STEC Incorporated. ZeusIOPSSolid State Drive.\\nhttp://www.stec-inc.com/downloads/flash_\\ndatasheets/iopsdatasheet.pdf .\\n[31] Transaction Processing Performance Council. TPC Benc hmark\\nC, Standard Speciﬁcation. http://www.tpc.org/tpcc/\\nspec/tpcc_current.pdf .\\n[32] S. E. Wells. Method for Wear Leveling in a Flash EEPROM\\nMemory. US patent 5,341,339,Aug 1994.\\n[33] M.Wuand W.Zwaenepoel. eNVy: ANon-Volatile, Main Mem-\\noryStorageSystem. In ASPLOS-VI:Proceedingsofthe6thInter-\\nnational Conference on Architectural Support for Programm ing\\nLanguages and Operating Systems , pages 86–97, 1994.\\n[34] D. Zeinalipour-Yazti, S. Lin, V. Kalogeraki, D. Gunopu los, and\\nW.A.Najjar. Microhash: AnEfﬁcient Index Structure for Fla sh-\\nBased Sensor Devices. In FAST’05: Proceedings of the 4th\\nUSENIXConferenceonFileandStorageTechnologies ,pages31–\\n44, 2005.\\nView publication stats', 'Design_Tradeoffs_for_SSD_Performance.pdf'), 1039: ('by J. A. Mandelman\\nR. H. Dennard\\nG. B. BronnerJ. K. DeBrosseR. DivakaruniY. LiC. J. RadensChallenges\\nand futuredirectionsfor the scalingof dynamicrandom-accessmemory (DRAM)\\nSigniﬁcant challenges face DRAM scaling\\ntoward and beyond the 0.10- /H9262m generation.\\nScaling techniques used in earlier generationsfor the array-access transistor and the storagecapacitor are encountering limitations whichnecessitate major innovation in electricaloperating mode, structure, and processing.Although a variety of options exist foradvancing the technology, such as low-voltageoperation, vertical MOSFETs, and novelcapacitor structures, uncertainties exist aboutwhich way to proceed. This paper discussesthe interrelationships among the DRAM scalingrequirements and their possible solutions.The emphasis is on trench-capacitor DRAMtechnology.\\nIntroduction\\nDRAM technology has progressed at a rapid pace since\\nthe invention of the one-transistor/one-capacitor cell(Figure 1 ) in the late 1960s [1], with an introduction\\nof a new generation and chip density quadruplingevery three years. The decade of the 1990s hasseen DRAM manufacturing advance from the 4Mbto the 256Mb generation [2]. In recent years therehas been a shift from a technology generation strategy(4 Mb/0.7\\n/H9262m, 16 Mb/0.5 /H9262m, etc.) to a shrink strategy\\n(64 Mb/0.35 /H9262m/0.25 /H9262m/0.2 /H9262m, etc.) with shorter\\ndevelopment cycles [3]. The high volumes that DRAMmanufacturing guarantees and the relatively predictableproduct roadmap have made DRAM the vehicle thatdrives a large part of the manufacturing infrastructurefor the microelectronics industry. DRAM technology isoptimized for low cost and high yield, with a particularfocus on low-leakage devices and the storage capacitor.\\nAs DRAM enters the 21st century, the course of\\nDRAM technology development continues to be drivenby the need for smaller cell sizes. To obtain a reasonablenumber of chips per wafer and to ﬁt within conventionalpackages, DRAM chips have increased in size by about40% per generation, while the numb', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1040: ('es a large part of the manufacturing infrastructurefor the microelectronics industry. DRAM technology isoptimized for low cost and high yield, with a particularfocus on low-leakage devices and the storage capacitor.\\nAs DRAM enters the 21st century, the course of\\nDRAM technology development continues to be drivenby the need for smaller cell sizes. To obtain a reasonablenumber of chips per wafer and to ﬁt within conventionalpackages, DRAM chips have increased in size by about40% per generation, while the number of bits per chip has\\n/H23040Copyright 2002 by International Business Machines Corporation. Copying in printed form for private use is permitted without payment of royalty provided that ( 1) each\\nreproduction is done without alteration and (2) the Journal reference and IBM copyright notice are included on the ﬁrst page. The title and abstract, but no other portions, of this\\npaper may be copied or distributed royalty free without further permission by computer-based and other information-service systems. Permission to republish any other portion of\\nthis paper must be obtained from the Editor.\\n0018-8646/02/$5.00 © 2002 IBM\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.187\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nincreased four times in every generation. Through\\nthe 1Mb DRAM generation (prior to 1988), cell sizereduction was realized primarily by reduction of the lineardimensions (i.e., minimum lithographic feature size, F).\\nReduction of feature size includes reduction of thewordline pitch (wordline width plus space betweenwordlines). The designed gate length of the array-accessMOSFET is typically equal to the designed width of thewordline; therefore, decreases in wordline pitch havetranslated into shorter channel lengths from generation togeneration. Conventional MOSFET scaling theory [4] wasapplied to provide shorter-channel-length MOSFETshaving electrical characteristics that are satis', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1041: (' minimum lithographic feature size, F).\\nReduction of feature size includes reduction of thewordline pitch (wordline width plus space betweenwordlines). The designed gate length of the array-accessMOSFET is typically equal to the designed width of thewordline; therefore, decreases in wordline pitch havetranslated into shorter channel lengths from generation togeneration. Conventional MOSFET scaling theory [4] wasapplied to provide shorter-channel-length MOSFETshaving electrical characteristics that are satisfactory forDRAM cell-access transistors; reduction in channellength was accompanied by increased channel dopingconcentration and decreased gate dielectric thickness.\\nHowever, lithography scaling provides only a factor of 2\\nreduction in area for each linear dimension reduction of0.7/H11003. To achieve close to a factor of 3 reduction in cell\\narea per generation, the remainder must come frominnovations in cell structure. The 4Mb generationintroduced the use of three-dimensional storage-capacitorstructures [5]. From the 16Mb through the 256Mb DRAMgenerations ( Figure 2 ), density-enhancing innovations\\nfocused on the use of techniques such as shallow-trenchisolation (STI) [6], bitline contact borderless to wordline[7], and self-aligned buried strap [8]. The most aggressive256Mb DRAM products in manufacturing in 2001 havecell sizes of approximately 0.16\\n/H9262m2, with minimum\\npitches of 0.28 /H9262m and designed array MOSFET channel\\nlength of 0.14 /H9262m (commonly referred to as the 0.14- /H9262m\\ntechnology node).\\nAt the present point on the DRAM technology timeline,\\nmechanisms that may limit further scaling of the channellength of MOSFETs in DRAM cells are receiving renewedattention. In order to store more charge on the capacitor,DRAM memory chips use longer channel lengths andhigher voltage levels on the gate compared to theperformance-oriented logic devices fabricated with equallithography capability. Most present circuits achieve avoltage on the capacitor, V\\nstorage, which is about 1.5 –1.8 V\\nless than the peak', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1042: ('.\\nAt the present point on the DRAM technology timeline,\\nmechanisms that may limit further scaling of the channellength of MOSFETs in DRAM cells are receiving renewedattention. In order to store more charge on the capacitor,DRAM memory chips use longer channel lengths andhigher voltage levels on the gate compared to theperformance-oriented logic devices fabricated with equallithography capability. Most present circuits achieve avoltage on the capacitor, V\\nstorage, which is about 1.5 –1.8 V\\nless than the peak voltage applied to the gate of thememory-cell devices. Part of this voltage difference resultsfrom the high threshold voltage, V\\nt, in the memory-cell\\ndevices ( /H110110.8 V) needed to prevent subthreshold\\nconduction of charge from the capacitor to the bitline attimes when the bitline is at a low voltage; body-effectand threshold-voltage tolerances add to the gate voltagerequired to turn on this device adequately to write thehigh level, V\\nstorage, into the capacitor. As DRAMs are\\nscaled to smaller dimensions, the voltage that can beapplied to the memory devices will follow a path similarto that for logic devices (but delayed in time) because theDRAM devices are at a maximum ﬁeld strength for gate-\\noxide reliability in any given generation [9]. Therefore, thestored voltage on the capacitor will shrink rapidly as thevoltages are scaled down unless a better technique isfound.\\nAnother major problem which must be considered in\\nscaling of the DRAM transistor is increased leakage dueFigure 2\\nProgression of DRAM scaling.Year1985 1990 1995 2000 20050.010.1110\\n0.1110Cell size  (   m2)\\n/H9262\\nMinimum feature size  (   m)/H9262Figure 1\\nSchematic of a one-transistor DRAM cell [1]. The array device \\n(transistor) is addressed by switching the wordline voltage from V\\nWLL (wordline-low) to VWLH (wordline-high), enabling the bitline \\nand the capacitor to exchange charge. In this example, a data state of either a “0” (0 V) or a “1” ( V\\nBLH) is written from the bitline to \\nthe storage capacitor. VBB is the electrical bias applied', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1043: ('ling.Year1985 1990 1995 2000 20050.010.1110\\n0.1110Cell size  (   m2)\\n/H9262\\nMinimum feature size  (   m)/H9262Figure 1\\nSchematic of a one-transistor DRAM cell [1]. The array device \\n(transistor) is addressed by switching the wordline voltage from V\\nWLL (wordline-low) to VWLH (wordline-high), enabling the bitline \\nand the capacitor to exchange charge. In this example, a data state of either a “0” (0 V) or a “1” ( V\\nBLH) is written from the bitline to \\nthe storage capacitor. VBB is the electrical bias applied to the p-well.Wordline (row)\\nCell node\\nCell plateStorage\\ncapacitorTransistor\\nBitline(column)/H11001\\n/H11002VWLL\\nVstorageVBB\\nVBLH0VWLH\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002188\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ntotunneli ng currents in the gate insulator and in the\\ndrain –body junction. This has been shown in numerous\\npapers [10] to be an important limit to scaling of logic\\ntransistors. It is much more critical in DRAM because ofthe extremely small allowable leakage [ /H110111 femtoampere\\n(10\\n/H1100215A)] per device to prevent any substantial decay\\nof the voltage stored on the capacitor. To make mattersworse, the increased doping in the body of the transistorin the normal path of scaling has been shown to causean increase in the number of transistors failing thespeci ﬁcations for retention of data, presumably due to\\nsome defect mechanism [11 –13]. Therefore, the bounds\\nimposed on the acceptable design space for the array-access transistor present a very serious challenge tothe continued scalability of the planar MOSFETDRAM cell.\\nThe storage capacitor is another area of focus for\\nDRAM cell-size reduction. IBM ’s 256Mb DRAM chip\\nwith a minimum lithographic feature size of 0.14\\n/H9262m and\\na cell size of 0.16 /H9262m2has a storage capacitor with a\\nsurface area of approximately 5 /H9262m2and a capacitance of\\napproximately 40 fF. Through the 0.14- /H9262m generation,\\nmethods of', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1044: ('mposed on the acceptable design space for the array-access transistor present a very serious challenge tothe continued scalability of the planar MOSFETDRAM cell.\\nThe storage capacitor is another area of focus for\\nDRAM cell-size reduction. IBM ’s 256Mb DRAM chip\\nwith a minimum lithographic feature size of 0.14\\n/H9262m and\\na cell size of 0.16 /H9262m2has a storage capacitor with a\\nsurface area of approximately 5 /H9262m2and a capacitance of\\napproximately 40 fF. Through the 0.14- /H9262m generation,\\nmethods of reducing the amount of silicon real estate\\noccupied by the storage capacitor while maintainingsufﬁcient capacitance have included the following:\\nThinning of the capacitor dielectric, use of insulatingmaterials with a higher dielectric constant, and three-dimensional capacitor structures [14]. The ability tomaintain large-surface-area capacitors in such small cellsis made possible by three-dimensional capacitor structuresthat are built either above the silicon surface (stackedcapacitors), or in the silicon substrate (trench capacitors)[15]. Figures 3 and 4respectively show examples of a\\nstacked-capacitor cell (STC) [16] and a trench-capacitorcell [17] suitable for the 0.15-\\n/H9262m generation. It is shown\\nin this paper that trench-capacitor DRAMs have a clearpath for scaling down to design rules for less than 0.1\\n/H9262m.\\nThe ability to scale stacked-capacitor cells is less clearbecause of challenges associated with the introduction ofnew dielectrics and array-device scaling problems. Sincethe scaling path of trench-capacitor cells appears to bemore tractable than that for stacked-capacitor cells, thispaper concentrates on the former.\\nTrench-capacitor cells also offer the advantage of being\\namenable to full planarization, making trench-storagetechnology more favorable for integration with high-performance CMOS logic for embedded memoryapplications [18 –20]. Integration of DRAM with high-\\nperformance CMOS logic, for embedded memoryapplications, is growing in importance to meetthe increased data bandwidth and red', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1045: (' trench-capacitor cells appears to bemore tractable than that for stacked-capacitor cells, thispaper concentrates on the former.\\nTrench-capacitor cells also offer the advantage of being\\namenable to full planarization, making trench-storagetechnology more favorable for integration with high-performance CMOS logic for embedded memoryapplications [18 –20]. Integration of DRAM with high-\\nperformance CMOS logic, for embedded memoryapplications, is growing in importance to meetthe increased data bandwidth and reduced latencyrequirements of speedier new generations of processors[21, 22]; however, density and performance improvementsmust not come at the expense of power dissipation per\\nchip, which means that data-retention time requirementsper cell remain very important.\\nThis paper examines two important factors challenging\\nDRAM cell-size scaling, which are driving the directionof DRAM technology development: 1) access-transistorscaling, which considers the competing requirements ofthreshold-voltage control, ultralow total leakage current,and MOSFET drive current suf ﬁcient for charge transfer,\\nand 2) scaling of the storage capacitor, addressing theneed to maintain adequate storage capacitance andsufﬁciently low series resistance.Figure 3\\nSchematic cross section of stacked capacitor cell suitable for 0.15    m. \\nReprinted with permission from [16]; © 1994 IEEE./H9262Ta2O5\\npoly-SiAl\\nW\\nWSi2\\nFigure 4\\nSEM photomicrograph of 0.25-  m trench DRAM cell suitable for \\nscaling to 0.15   m and below. Figure is from [17]./H9262\\n/H9262\\nCell node\\nNode dielectricBitline\\nWordlines\\nCell plate\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.189\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nScaling challenges for the DRAM array\\ntransistor\\nA DRAM cell (Figure 1) consists of a MOSFET (also\\nreferred to as the array-access transistor or transferdevice) in series with a storage capacitor. The wordlinecontacts the gate of the tr', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1046: ('9262\\nCell node\\nNode dielectricBitline\\nWordlines\\nCell plate\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.189\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nScaling challenges for the DRAM array\\ntransistor\\nA DRAM cell (Figure 1) consists of a MOSFET (also\\nreferred to as the array-access transistor or transferdevice) in series with a storage capacitor. The wordlinecontacts the gate of the transfer device, and the bitlinecontacts the source/drain of the transfer device that is notconnected to the storage capacitor. Data is written byturning on the transfer device by raising the wordlineand writing a high or low voltage level onto the storagecapacitor via the bitline. Data is stored by turning off thetransfer device by lowering the wordline, trapping thevoltage/charge on the storage capacitor. In industry-standard DRAM, data is conventionally read by prechargingthe bitline midway between the high and low levels, turningon the transfer device, and sensing the bitline voltagechange (the signal voltage) caused by charge sharingbetween the storage capacitor and the parasitic bitlinecapacitance. The signal voltage is given by\\nV\\nsignal/H110050.5/H11569Vstorage/H11569Cstorage//H20849Cbitline/H11001Cstorage/H20850,\\nwhere Vstorageis the voltage difference between the stored\\nhigh and low levels on the storage capacitor, and Cbitline\\nis the parasitic capacitance of the bitline including the\\ninput capacitance of the sense ampli ﬁer.\\nThe extent to which the actual voltage difference\\nbetween the stored high and low levels on the storagecapacitor, V\\nstorage, approaches the voltage swing on the\\nbitline (bitline-high voltage, VBLH, minus bitline-low\\nvoltage, which is usually zero), is determined by thecurrent provided by the access transistor, the value of thestorage capacitor, and the amount of time allocated forthe transfer of charge between the bitline and the storagecapacitor. To maximize the signal, it is desir', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1047: (' of the sense ampli ﬁer.\\nThe extent to which the actual voltage difference\\nbetween the stored high and low levels on the storagecapacitor, V\\nstorage, approaches the voltage swing on the\\nbitline (bitline-high voltage, VBLH, minus bitline-low\\nvoltage, which is usually zero), is determined by thecurrent provided by the access transistor, the value of thestorage capacitor, and the amount of time allocated forthe transfer of charge between the bitline and the storagecapacitor. To maximize the signal, it is desired to use avalue of bitline voltage swing that is as large as possiblewhile meeting the active-power-dissipation constraints andmaintaining compatibility with the chip circuitry outsidethe array area (the support area). As an example, in an\\noperating DRAM, V\\nsignalmay be in the range of 100 to\\n200 mV for a Vstorageapproaching 1.5 V. Furthermore, the\\narray-access MOSFET must operate as closely as possibleto an ideal switch; the lowest value of source-follower V\\nt\\nfor the highest drive current, while meeting the off-currentobjective, is desired. (As shown in Figure 1, the source-follower mode of operation occurs when charge istransferred between the bitline and the storage capacitor.)This implies a small subthreshold slope and minimal back-bias sensitivity. Although maximizing the transfer ratio[C\\nstorage/(Cbitline/H11001Cstorage)] is also a goal, the focus of this\\nsection is on scaling the channel length of the accesstransistor to ever-smaller design ground rules.\\nVoltage-scaling issues\\nA scenario for scaling DRAM to smaller dimensions isshown in Table 1 . The maximum voltage stress on the gate\\ninsulator of the DRAM access transistor occurs wheneither the bitline voltage or the storage capacitor voltageis zero (during writing, restoring, or reading data) and thewordline voltage is at its high level, V\\nWLH. Scaling down\\nVWLHas shown in the ﬁrst column of Table 1, along the\\nvoltage-scaling path already established for logic devices,\\nallows the effective gate-insulator thickness to be scaleddown as shown for the ma', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1048: ('DRAM to smaller dimensions isshown in Table 1 . The maximum voltage stress on the gate\\ninsulator of the DRAM access transistor occurs wheneither the bitline voltage or the storage capacitor voltageis zero (during writing, restoring, or reading data) and thewordline voltage is at its high level, V\\nWLH. Scaling down\\nVWLHas shown in the ﬁrst column of Table 1, along the\\nvoltage-scaling path already established for logic devices,\\nallows the effective gate-insulator thickness to be scaleddown as shown for the maximum electric ﬁeld of 5 MV/cm\\nconsidered necessary for reliability of the gate insulator[23]. The channel length can then also be scaled downby the same amount, assuming that the depletion depthin the channel region of the turned-off device is alsoscaled using increased channel doping and possibly somereduction of the body bias. This reverse body bias, V\\nBB\\n(Figure 1), is conventionally used to prevent any forwardbias of the source –body junction due to circuit noise on\\nthe bitline or body, which could cause injected electronsfrom the source to diffuse to a capacitor node diffusionTable 1 Array MOSFET scaling behavior, zero vs. negative wordline-low. Gate-oxide thickness, tox, is constrained by a 5-MV/cm\\nreliability-imposed limit on gate electric ﬁeld. Channel length follows the MOSFET scaling trend of being from 25 to 40 /H11003tox.\\nFor/H110020.5 V negative wordline-low, Vtcan be reduced to about 0.3 V and still keep the transistor well turned off. For a given\\ncapacitor voltage, the negative wordline approach allows a shorter, more scaled array transistor with a lower VWLHrequired to\\nwrite a “1”into the cell. For a given value of VWLH, the maximum capacitor voltage, VBLH, is increased by somewhat less than 0.5 V.\\nMaximum device\\nvoltage, VWLH\\n(V)Equivalent\\nSiO2tox\\n(nm)Nominal\\nchannel length,\\nLeff\\n(nm)Maximum capacitor\\nvoltage, VBLH\\n(V)\\nVWLL/H11005\\n0.0VWLL/H11005/H11002 0.5\\nV\\n3.3 6.6 250 1.80 2.28\\n2.5 5.0 150 1.19 1.641.8 3.6 100 0.63 1.071.5 3.0 80 0.36 0.801.2 2.4 60 0.21 0.65\\nJ. A. MANDELMAN ET AL. IBM J. RE', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1049: ('ch allows a shorter, more scaled array transistor with a lower VWLHrequired to\\nwrite a “1”into the cell. For a given value of VWLH, the maximum capacitor voltage, VBLH, is increased by somewhat less than 0.5 V.\\nMaximum device\\nvoltage, VWLH\\n(V)Equivalent\\nSiO2tox\\n(nm)Nominal\\nchannel length,\\nLeff\\n(nm)Maximum capacitor\\nvoltage, VBLH\\n(V)\\nVWLL/H11005\\n0.0VWLL/H11005/H11002 0.5\\nV\\n3.3 6.6 250 1.80 2.28\\n2.5 5.0 150 1.19 1.641.8 3.6 100 0.63 1.071.5 3.0 80 0.36 0.801.2 2.4 60 0.21 0.65\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002190\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\n(the drain diffusion of the transistor connected to the\\ncapacitor electrode) and discharge a stored “1”level.\\nReferring to Figure 1, as the wordline voltage VWLH\\nis reduced, the ability to write a voltage into the celldecreases rapidly, as shown in Table 1. Two differentcases are shown. In the ﬁrst, the wordline for the “off”\\ntransistor is at V\\nWLL/H110050. For the second case, the “off”\\nwordlines are kept at VWLL/H11005/H11002 0.5 to assist further in\\nturning off the transistor. We call this the “negative\\nwordline-low ”case. For the tox/H110056.6-nm zero wordline-\\nlow case, VWLHmust be about 1.5 V greater than VBLHto\\nwrite the full level into the cell. The required gate voltageabove the sum of the source follower V\\ntand VBLHis\\nassumed to scale down with tox, thus maintaining constant\\ninversion charge density at the end of the write “1”\\noperation.\\nFor the ﬁrst case, the limitations on writing a “1”into\\nthe cell are shown in Figure 5 , which plots the threshold\\nvoltage Vtvs. the source –body voltage for the saturated\\n(VDS/H11005VBLH) case and the linear ( VDS/H110050) case. To\\nretain a stored “0”voltage on the capacitor when the\\nwordline is at zero and the bitline is at VBLH(or to retain\\na stored “1”when the wordline and bitline are both at\\nzero) requires a Vtvalue of at least 0.8 V under the bias\\nconditions identi ﬁed in the ﬁgur', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1050: ('write “1”\\noperation.\\nFor the ﬁrst case, the limitations on writing a “1”into\\nthe cell are shown in Figure 5 , which plots the threshold\\nvoltage Vtvs. the source –body voltage for the saturated\\n(VDS/H11005VBLH) case and the linear ( VDS/H110050) case. To\\nretain a stored “0”voltage on the capacitor when the\\nwordline is at zero and the bitline is at VBLH(or to retain\\na stored “1”when the wordline and bitline are both at\\nzero) requires a Vtvalue of at least 0.8 V under the bias\\nconditions identi ﬁed in the ﬁgure (at the highest operating\\ntemperature) in order to keep the device current at about10\\n/H1100215A or less. Writing the high level (in this case 1.5 V,\\nwith a p-well bias of /H110020.5 V) into the capacitor causes the\\nVtto rise as shown because of the increased source –body\\nvoltage (body effect) and the reduced drain –source voltage\\n(the reverse of drain-induced barrier lowering, or DIBL).Some amount of gate –source signal above V\\nt(about\\n0.3 V) is also required to keep the transistor suf ﬁciently\\nturned on to charge the capacitor in a reasonable time,and some allowance must be made for manufacturingprocess tolerances (e.g., variations in channel length,width, and STI corner effect). Thus, V\\nWLHmust be about\\n1.5 V greater than VBLHin this case to write the full level\\ninto the cell, and VBLH/H11005VWLH/H110021.5 V /H110051.5 V for\\nVWLH/H110053.0 V.\\nScaling the transistor to thinner gate oxide ( tox) and\\nreducing the maximum wordline voltage VWLHwill reduce\\nthe voltage VBLHthat can be written into the cell, as\\nshown in Table 1. The numbers there are derived withthe understanding that the minimum V\\ntvalue for data\\nretention, 0.8 V, cannot be scaled, since the current at thethreshold must be reduced by about eight decades and thesubthreshold slope at T/H1100585/H11034C will remain at 100 mV\\nper decade of current change. The body effect and DIBLeffect are assumed to scale down with V\\nBLH, and the\\noverdrive and tolerances are assumed to scale down withV\\nWLHand tox. The net result is that the achievable stored\\ncapacit', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1051: ('shown in Table 1. The numbers there are derived withthe understanding that the minimum V\\ntvalue for data\\nretention, 0.8 V, cannot be scaled, since the current at thethreshold must be reduced by about eight decades and thesubthreshold slope at T/H1100585/H11034C will remain at 100 mV\\nper decade of current change. The body effect and DIBLeffect are assumed to scale down with V\\nBLH, and the\\noverdrive and tolerances are assumed to scale down withV\\nWLHand tox. The net result is that the achievable stored\\ncapacitor voltage falls rapidly as the DRAM transistor isscaled.A somewhat better result is predicted in the negative\\nwordline-low case, where the wordline is returned to a\\nnegative 0.5 value so that the worst-case array transistorV\\ntcan be reduced to about 0.3 V and still keep the\\ntransistor well turned off. In a given generation, this lowerV\\ntallows nearly 0.5 V greater voltage to be written into\\nthe capacitor, but it does require a larger wordline signalswing. More signi ﬁcantly, for a given capacitor voltage the\\nnegative wordline approach allows a shorter, more scaledarray transistor with a lower value of V\\nWLH.\\nAlthough projections by the National Technology\\nRoadmap for Semiconductors [24] call for operating\\nvoltages of CMOS logic to drop by about a factor of 0.7\\nto 0.8 per generation to keep power dissipation in check,DRAM designers have generally been very reluctant toconsider the possibility of reducing the voltage stored onthe capacitor because of the loss of signal when readingthe cell and because of soft-error concerns. On the otherhand, scaling principles suggest that a given design pointscaled down in all dimensions and voltage should workwell as far as the reduced signal level on the senseampli ﬁer is concerned. In principle, the important noise\\nsources are reduced with scaling, including mismatch inthe sense-ampli ﬁer devices down to the point at which\\nstatistical ﬂuctuation of impurities becomes important\\n[10]. The eventual voltage-scaling path for DRAMdepends as heavily on the capacitor as on the arra', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1052: ('error concerns. On the otherhand, scaling principles suggest that a given design pointscaled down in all dimensions and voltage should workwell as far as the reduced signal level on the senseampli ﬁer is concerned. In principle, the important noise\\nsources are reduced with scaling, including mismatch inthe sense-ampli ﬁer devices down to the point at which\\nstatistical ﬂuctuation of impurities becomes important\\n[10]. The eventual voltage-scaling path for DRAMdepends as heavily on the capacitor as on the arrayFigure 5\\nIllustration of the increase in array-access transistor threshold \\nvoltage between the electrical bias conditions of retaining a stored “0” and at the end of a write “1” operation. In this example, the \\ndelta in V\\nt is due solely to back-bias sensitivity and drain-induced \\nbarrier lowering (DIBL).Linear Vt\\nSaturation VtVt  (V)\\np-well to source bias  (V)1.10\\n1.000.900.800.700.600.50\\n0.0 /H110020.5 /H110021.0 /H110021.5 /H110022.0 /H110022.5 /H110023.0\\nRetention\\nof “0”End of write “1”\\nDelta Vt\\nBitline\\nWordline\\n(gate) n/H11001\\n(source)diffusionn\\n/H11001\\n(drain)diffusionStorage\\ncapacitor\\np-well\\n(/H110020.5 V)\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.191\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ntransistor. For some years, high-dielectric-constant ( k)\\nmaterials have been investigated and have been regarded\\nas a future requirement for DRAM capacitors. It is quitenatural that such materials could store more charge perunit area at lower voltage than today ’s lower- kmaterials.\\nFor the sense ampli ﬁer and other support circuits to\\nwork properly at reduced voltage requires the scaling oftheV\\ntof those devices. This will lead to the same types of\\noff-current problems faced today in scaled logic devices,where techniques are being developed to minimize theimpact on standby power. Such low- V\\ntdevices are very\\nachievable for DRAM embedded in a high-performancelogic technology base, but ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1053: ('uch materials could store more charge perunit area at lower voltage than today ’s lower- kmaterials.\\nFor the sense ampli ﬁer and other support circuits to\\nwork properly at reduced voltage requires the scaling oftheV\\ntof those devices. This will lead to the same types of\\noff-current problems faced today in scaled logic devices,where techniques are being developed to minimize theimpact on standby power. Such low- V\\ntdevices are very\\nachievable for DRAM embedded in a high-performancelogic technology base, but until now they have not beenconsidered affordable for industry-standard DRAM.Alternatively, different sensing circuits may be developedfor lower-voltage operation [25, 26]. Ultimately, current-sensing techniques would be ideal at very low voltages toobtain the full charge from the capacitor by holding thebitline voltage nearly constant during sensing.\\nAnother circuit design issue is posed by the negative\\nwordline-low level, which makes it signi ﬁcantly more\\ncomplicated to design and lay out wordline drivers in\\nthe available pitch. Interestingly, this problem could becompletely obviated by a technology change to a midgapgate material (e.g., tungsten instead of n\\n/H11001polysilicon\\n(“poly”) for an n-MOSFET) that would allow identical\\ndoping pro ﬁles, electric ﬁelds, and device function, with the\\ngate driven by the same magnitude of signal swing but with\\nVWLL/H110050. This device would have a minimum Vtof 0.8 V,\\nbut for a given wordline swing could be scaled further(i.e., thinner t\\noxthan the n/H11001poly-gated device using\\nVWLL/H110050) because of its reduced vertical electric ﬁeld.\\nAs with the negative wordline-low device, the electricﬁeld is increased in the turned-off condition relative to\\nthe grounded-wordline n\\n/H11001poly-gated case, which raises a\\nconcern about gate-induced drain leakage (GIDL) [27].\\nLeakage issues\\nAll leakage-current requirements for the DRAM arraytransistor are much more stringent than for logictransistors. In addition to the MOSFET subthreshold off-current already discussed, several com', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1054: ('device using\\nVWLL/H110050) because of its reduced vertical electric ﬁeld.\\nAs with the negative wordline-low device, the electricﬁeld is increased in the turned-off condition relative to\\nthe grounded-wordline n\\n/H11001poly-gated case, which raises a\\nconcern about gate-induced drain leakage (GIDL) [27].\\nLeakage issues\\nAll leakage-current requirements for the DRAM arraytransistor are much more stringent than for logictransistors. In addition to the MOSFET subthreshold off-current already discussed, several components of leakagecurrent seen by the array storage-node diffusion aresigni ﬁcantly affected by DRAM cell-size scaling: storage-\\njunction-to-well leakage, array MOSFET GIDL, tunnelingcurrent in the gate insulator, and storage-capacitordielectric leakage. The ﬁrst three of these components are\\nstrongly in ﬂuenced by channel-length scaling and voltage\\noperating conditions, and the last may be affected byscaling of the storage capacitor. To ensure that adequateretention time is achieved from cell to cell across a chip,from chip to chip, and from wafer to wafer, the medianvalue of the sum of all components of leakage currentseen by the storage-node diffusion must be less than about1 fA per cell. This ultralow value of storage-node leakageprovides a guard band for the distribution of leakage, thusensuring a suf ﬁciently low frequency of occurrence of cells\\nthat fail to provide adequate retention time. In contrast,acceptable subthreshold off-current leakage for high-performance logic MOSFETs is typically six orders ofmagnitude greater than for the DRAM array device.\\nDRAM devices use low-dose phosphorus doping for the\\ndrain in order to achieve a low-leakage graded junction.Figure 6 shows the simulated potential pro ﬁles in such a\\ndevice biased to the turned-off condition with a negative-wordline voltage. The highest electric ﬁeld in the\\ndrain –body junction occurs at the edge overlapped by the\\ngate, where the full drain –gate voltage appears across the\\ninsulator and a depleted portion of the drain. GIDL is aleakage me', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1055: (' ofmagnitude greater than for the DRAM array device.\\nDRAM devices use low-dose phosphorus doping for the\\ndrain in order to achieve a low-leakage graded junction.Figure 6 shows the simulated potential pro ﬁles in such a\\ndevice biased to the turned-off condition with a negative-wordline voltage. The highest electric ﬁeld in the\\ndrain –body junction occurs at the edge overlapped by the\\ngate, where the full drain –gate voltage appears across the\\ninsulator and a depleted portion of the drain. GIDL is aleakage mechanism in which this high ﬁeld can cause\\nband-to-band tunneling in regions where the bandgapvoltage is dropped across a suf ﬁciently small distance. For\\neither direct or trap-assisted band-to-band tunneling to bea signi ﬁcant contributor to leakage, the high ﬁeld must\\noccur over a distance of less than about 10 nm. Accordingto the model of a recent reference, a ﬁeld above 1 MV/cm\\nis necessary to cause 10\\n/H1100215A leakage current in this\\njunction area estimated at 10/H110022/H9262m2[10]. Although theFigure 6\\nModeled mid-bandgap potential contours for an exemplary DRAM \\nMOSFET, as may be used in a stacked-capacitor cell. Note that the maximum electric field in the silicon occurs near the drain edge when the transistor is biased in the off-state. In this negative wordline-low example, the MOSFET has a physical gate-oxide thickness of 5.4 nm and a metallurgical channel length of 100 nm.\\nGate sidewall\\noxideContact stud\\nContact studNitride\\nspacer\\nGate oxideVgate  /H11005/H110020.5 V\\nVp-well /H11005 /H11002 0.5 VVsource /H11005 0.0 Vdrain /H11005 1.5 V\\n2.0 V\\n1.8 V\\n1.0 V\\n0.0 V0.4 V\\n0.2 V0.0 V\\n/H110020.2 V\\n/H110020.4 V\\n/H110020.6 V\\n/H110020.8 V\\n/H110020.1 0.0 0.1\\nScale  (   m) /H92620.9\\n0.8\\n0.7\\n0.6\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002192\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\npeak electric ﬁeld in the silicon in this exemplary case\\n(Figure 6) is seen to be about 1 MV/cm, only about', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1056: ('Vsource /H11005 0.0 Vdrain /H11005 1.5 V\\n2.0 V\\n1.8 V\\n1.0 V\\n0.0 V0.4 V\\n0.2 V0.0 V\\n/H110020.2 V\\n/H110020.4 V\\n/H110020.6 V\\n/H110020.8 V\\n/H110020.1 0.0 0.1\\nScale  (   m) /H92620.9\\n0.8\\n0.7\\n0.6\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002192\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\npeak electric ﬁeld in the silicon in this exemplary case\\n(Figure 6) is seen to be about 1 MV/cm, only about 0.7 V\\nis dropped over a distance of 10 nm. GIDL ﬁeld reduction\\nis also helped by the tapered oxide at the gate edge dueto gate reoxidation, as shown in the ﬁgure. The rest of\\nthe junction area away from the gate edge has the usualleakage properties of a p –n junction, and the ﬁeld in that\\nregion in this case is seen to be somewhat less than at theedge of the gate. As the device is scaled along the pathindicated in the second column of Table 1 down to thelast entry, the GIDL electric ﬁeld remains fairly constant\\nbecause of the compensating effects of reduced applieddrain –gate voltage, V\\nBLH/H110010.5, vs. thinner tox. GIDL\\nleakage is therefore not expected to be a limitation.\\nHowever, very signi ﬁcantly, as seen in Figure 7 , the\\nhigher channel doping concentration required for scalingthe device results in a broadening of the cell fail-countdistribution due to increased junction leakage current.It has also been reported [11 –13] that increased channel\\ndoping concentration and reverse bias manifests itself as abroadening of the tail of the retention time distribution.This phenomenon is believed to be due to deep-trap-assisted tunneling. Although the origin of these randomlydistributed traps has not yet been determined, pointdefects and/or metallic atoms have been postulated aspossible causes. As seen in Figure 8 , retention-time\\nperformance begins to degrade noticeably as channeldoping rises to levels of the order of mid-10\\n17cm/H110023[11].\\nThis junction leakage component tends to limit themaximum doping that ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1057: (' abroadening of the tail of the retention time distribution.This phenomenon is believed to be due to deep-trap-assisted tunneling. Although the origin of these randomlydistributed traps has not yet been determined, pointdefects and/or metallic atoms have been postulated aspossible causes. As seen in Figure 8 , retention-time\\nperformance begins to degrade noticeably as channeldoping rises to levels of the order of mid-10\\n17cm/H110023[11].\\nThis junction leakage component tends to limit themaximum doping that can be used to reduce short-channel effects and set V\\nt.\\nBecause of the lower Vt, the negative wordline-low\\ndesign can be accomplished with less channel doping thanthe grounded-wordline case. With a V\\nBB(i.e., p-well\\nbias/H11005/H11002 0.5 V) of the design of Figure 6, the average\\ndoping in the depletion region is about 4 /H110031017cm/H110023.\\nSince the band-bending at VG/H11005Vtisﬁxed at 2 /H9278b/H11001 /H20841VBB/H20841,\\nscaling the depletion depth and maintaining the same Vt\\nsimply requires increasing the doping by the square ofthe scaling factor. Thus, a 1.4 /H11003reduction in dimension\\nrequires a 2 /H11003increase in doping concentration. The\\ngrounded wordline-low design requires about 2 /H11003more\\ndoping than the negative wordline-low design. Moreover,the doping must be peaked near the Si surface just belowthe gate oxide to avoid reducing the depletion depth (fora given V\\nBB), which would degrade the subthreshold slope.\\nAccording to the reported results for the relationshipbetween the defect leakage due to high channel dopingand electric ﬁeld [11 –13], the reduction in capacitor\\nvoltage, which is necessary for the scaling of the arraydevice, would possibly allow for heavier doping.\\nTunneling current through the gate insulator is also a\\nconcern. With the gate of the array transistor biased to anegative value (as in Figure 6), relatively few electrons cantunnel from the gate into the weakly inverted channel,\\nand only a portion of these will ﬂow to the drain. The\\npotentials are favorable for tunneling i', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1058: ('e due to high channel dopingand electric ﬁeld [11 –13], the reduction in capacitor\\nvoltage, which is necessary for the scaling of the arraydevice, would possibly allow for heavier doping.\\nTunneling current through the gate insulator is also a\\nconcern. With the gate of the array transistor biased to anegative value (as in Figure 6), relatively few electrons cantunnel from the gate into the weakly inverted channel,\\nand only a portion of these will ﬂow to the drain. The\\npotentials are favorable for tunneling in the gate –drain\\noverlap region, but the gate –drain insulator thickness\\ncan be locally increased relative to the t\\noxin the channel\\nregion by the taper created in the gate-reoxidation process(also known as a gate-conductor sidewall oxidation);Figure 7\\nIncreased channel doping concentration ( Vt implant dose) of the \\nDRAM array MOSFET results in a broadening of the junction \\nleakage distribution and increased fail count. The data was obtained from the BEST [8] cell./H110024.00\\n/H110024.05\\n/H110024.10\\n/H110024.15\\n/H110024.20\\n/H110024.25\\n/H110024.30\\n/H110024.35\\n/H110024.40\\n/H110024.45\\n/H110024.50\\nStandard deviation of\\naccumulated fail count19\\n17151311\\n975Leakage current  (nA)Dose 1 < Dose 2\\nn\\nLeakage\\n5 6 7 8 9 10\\nVt implant dose ( /H11003 1012/cm2)\\nFigure 8\\nAs the channel doping concentration, NA,0, of the DRAM array \\nMOSFET rises toward the mid-1017 cm/H110023 level, the tail of the \\nretention-time distribution begins to degrade noticeably.  N0 /H11005 3 /H11003 \\n1017 cm/H110023. Reprinted with permission from [11]; © 1998 IEEE.0.999\\n0.99\\n0.9\\n0.5\\n0.1\\n10/H110022\\n10/H110023\\n10/H110024\\n10/H110025\\n10/H110026\\n100 101 102 103 104\\n3/H9268\\n2/H9268\\n/H9268\\n0/H11002/H9268/H110022/H9268\\n/H110023/H9268\\n/H110024/H9268Cumulative probability\\nRetention time, tret  (arbitrary units)NA,0/N0 /H11005 1.5 \\n1\\n0.6\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.193\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ntherefo', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1059: ('m [11]; © 1998 IEEE.0.999\\n0.99\\n0.9\\n0.5\\n0.1\\n10/H110022\\n10/H110023\\n10/H110024\\n10/H110025\\n10/H110026\\n100 101 102 103 104\\n3/H9268\\n2/H9268\\n/H9268\\n0/H11002/H9268/H110022/H9268\\n/H110023/H9268\\n/H110024/H9268Cumulative probability\\nRetention time, tret  (arbitrary units)NA,0/N0 /H11005 1.5 \\n1\\n0.6\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.193\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ntherefore, the tunneling current is greatly reduced at the\\nedge of the gate conductor. It appears, therefore, that themost critical region is where the oxide is thinner but thechannel potential is still near that of the drain. In thisregion, a current density of 10\\n/H110024A/cm2can be tolerated.\\nThis corresponds to a toxof about 2.5 nm for the operating\\nvoltages of interest.DRAMs up to now have commonly used a thinner\\nequivalent oxide for the storage capacitors in the memory\\ncells compared to the toxused for the gate insulators.\\nThis has tended to maximize the charge stored on thecapacitors, considering the lower voltage stress on them.Sustaining this trend with further scaling appears to bechallenging. The leakage current requirement for thecapacitor (less than 10\\n/H110026A/cm2) is quite stringent because\\nof the large area involved for trench-capacitor structures.If SiO\\n2were used, the limiting thickness would be about\\n3 nm. The commonly used nitride –oxide composite can in\\nprinciple be scaled to a somewhat thinner equivalent oxidethickness than that, perhaps 2.5 nm. This is discussedfurther with respect to the trench-cell technology.\\nOn the scalability of the BEST (BuriEd-STrap)\\ntrench-capacitor cell\\nBuried-strap proximity\\nThe scaling challenges for the array transistor discussed\\nthus far are common to both stacked-capacitor and trenchDRAM technologies. A proximity effect unique to theBEST [8] cell used for trench-storage DRAM from the0.25-\\n/H9262m through the 0.14- /H9262m generations degrades the Vt\\ncontrol of the', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1060: (' equivalent oxidethickness than that, perhaps 2.5 nm. This is discussedfurther with respect to the trench-cell technology.\\nOn the scalability of the BEST (BuriEd-STrap)\\ntrench-capacitor cell\\nBuried-strap proximity\\nThe scaling challenges for the array transistor discussed\\nthus far are common to both stacked-capacitor and trenchDRAM technologies. A proximity effect unique to theBEST [8] cell used for trench-storage DRAM from the0.25-\\n/H9262m through the 0.14- /H9262m generations degrades the Vt\\ncontrol of the array MOSFET. This proximity effect is dueto the presence of the buried-strap diffusion, the structureof which is schematically illustrated in Figure 9 . The self-\\naligned buried strap as practiced for trench-storagetechnology is desirable from a manufacturing costperspective. However, it also exacerbates the DIBLeffect because of both its depth and the rate at which itsdistance from the bitline diffusion of the access transistorvaries with reduction in minimum lithographic featuresize, F. Achieving a shallow buried-strap diffusion has\\nbeen a challenge, since it is formed by outdiffusing dopantfrom the storage-trench polysilicon through an apertureon the wall of the trench [8]. The size and location of thisaperture are de ﬁned by recesses of the storage-trench\\npolysilicon, which are dif ﬁcult to control relative to the\\nminimum feature size. Furthermore, as the minimumlithographic feature size is scaled down, the proximity ofthe buried-strap diffusion to the bitline diffusion, D\\neff,\\nvaries at approximately twice the rate of the reductionin the width of the wordline conductor, as illustratedinFigure 10 .\\nAn additional contributor to encroachment of the\\nburied-strap diffusion upon the array-access MOSFET isoverlay variation between the deep storage trench andthe wordline (i.e., gate conductor) of the cell. Since thepatterns for the deep-trench capacitors and the wordlinesare formed from separate masking steps, requiringindependent alignment, there is a statistical variation inthe relative locations of these stru', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1061: ('wice the rate of the reductionin the width of the wordline conductor, as illustratedinFigure 10 .\\nAn additional contributor to encroachment of the\\nburied-strap diffusion upon the array-access MOSFET isoverlay variation between the deep storage trench andthe wordline (i.e., gate conductor) of the cell. Since thepatterns for the deep-trench capacitors and the wordlinesare formed from separate masking steps, requiringindependent alignment, there is a statistical variation inthe relative locations of these structures. Data taken froma test structure designed to intentionally introduce varyingFigure 9\\nSchematic illustration of the BEST [8] cell, which has been the \\nmainstay trench-capacitor DRAM cell from the 0.25-   m through the 0.14-   m generations. The presence of the buried-strap diffusion complicates the scalability of the cell./H9262\\n/H9262STIn/H11001\\nbitline\\ndiffusion\\nn/H11001\\nplateLeff\\nDeffWordline\\n(gate)Passing\\nwordlineWordline\\nwidthWordline\\nspace\\nTrench-\\nstorage\\ncapacitorBuried-strap\\ndiffusionp-well\\nn isolation band\\np substrateIsolationcollar\\nFigure 10\\nThe distance between the buried-strap diffusion and the bitline \\ndiffusion, Deff, shrinks by twice the amount of the reduction in the \\nminimum lithographic feature size (technology node). This ampli-fies the DIBL sensitivity of the MOSFET as the cell is scaled. For the case shown here, the extent of the buried-strap outdiffusion from the storage-trench sidewall is 0.07   m.\\n/H9262Deff\\nWordline\\nwidth0.45\\n0.350.250.150.05Critical dimension  (   m)/H9262\\n0.05 0.1 0.15 0.2 0.25 0.3\\nTechnology node  (   m) /H9262\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002194\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\namountso f misalignment between the trench capacitor\\nand the wordline is shown in Figure 11 . When a high\\nvoltage is stored on the storage node, and the buried\\nstrap is close to the transfer gate, drain-induced barrierlowering due to the pro', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1062: (' 0.1 0.15 0.2 0.25 0.3\\nTechnology node  (   m) /H9262\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002194\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\namountso f misalignment between the trench capacitor\\nand the wordline is shown in Figure 11 . When a high\\nvoltage is stored on the storage node, and the buried\\nstrap is close to the transfer gate, drain-induced barrierlowering due to the proximity of the buried-strap diffusionleads to an increased drop in V\\nt[28]. Since in the BEST\\ncell the buried-strap diffusion is deeper than the bitlinediffusion, the V\\nt-lowering effect is more pronounced when\\nthe array-access MOSFET is biased such that the storage-node diffusion is the drain, with the source being thebitline diffusion. The test structure used to obtain thisdata has a relatively long design gate length of 0.20\\n/H9262mt o\\nallow the strap diffusion proximity effect to dominate andbe decoupled from normal DIBL. The electrical resultsshown in Figure 11 suggest that the minimum usefullithographic feature size for a cell of this type isapproximately 0.14\\n/H9262m. At a design ground rule of\\n0.14 /H9262m (corresponding to a design distance between\\nthe storage trench and the far edge of the wordline of0.28\\n/H9262m), the amount of Vtrolloff introduced by the strap\\nproximity is approximately 200 mV. For the data shown inFigure 11, the amount of strap outdiffusion from the wallof the trench capacitor is approximately 0.08\\n/H9262m, with the\\nbottom of the strap diffusion at approximately 0.2 /H9262m\\nfrom the surface of the substrate. Although processenhancements that reduce the thermal budget and thestrap outdiffusion may be introduced, control of thethreshold voltage of the planar MOSFET in the BEST cellat minimum lithographic feature size less than 0.14\\n/H9262mi s\\na major challenge.\\nAnalysis of the manufacturing process window forthe scaled BEST cell\\nAs discussed earlier, an acceptable design point for the', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1063: ('approximately 0.08\\n/H9262m, with the\\nbottom of the strap diffusion at approximately 0.2 /H9262m\\nfrom the surface of the substrate. Although processenhancements that reduce the thermal budget and thestrap outdiffusion may be introduced, control of thethreshold voltage of the planar MOSFET in the BEST cellat minimum lithographic feature size less than 0.14\\n/H9262mi s\\na major challenge.\\nAnalysis of the manufacturing process window forthe scaled BEST cell\\nAs discussed earlier, an acceptable design point for theplanar MOSFET DRAM cell must, at a minimum,simultaneously satisfy the requirements of 1) limitedchannel doping concentration to avoid excessive storage-node junction leakage, and 2) a subthreshold off-currentof approximately 1 fA/cell. These requirements must besatis ﬁed for all possible variations of critical physical\\nparameters in the course of normal manufacturing processvariations, and at worst-case operating conditions (i.e.,temperature, voltages). The most signi ﬁcant physical\\nparameters for the BEST cell [8] in ﬂuencing these\\nrequirements are wordline width (i.e., gate length),alignment between the wordline and the storage trench,buried-strap outdiffusion toward the MOSFET and itsdepth from the top surface, and process biases andtolerances for these quantities.\\nThe extendibility of the BEST cell [8] has been\\ninvestigated by quantifying the manufacturing processdesign space (process window) at speci ﬁc minimum\\nlithographic feature sizes (i.e., technology nodes). Inparticular, the peak channel doping concentration meetingthe subthreshold off-current objective for given values of\\nwordline conductor width and proximity of buried-strapdiffusion was determined. As a design guideline, thepeak concentration of the channel doping concentrationadjacent to the storage-node diffusion must not exceed6/H1100310\\n17cm/H110023. An acceptable process window is de ﬁned\\nas points within the range of variation of these physicalparameters simultaneously falling below the 6 /H1100310\\n17-cm/H110023\\nchannel doping limit and meet', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1064: ('centration meetingthe subthreshold off-current objective for given values of\\nwordline conductor width and proximity of buried-strapdiffusion was determined. As a design guideline, thepeak concentration of the channel doping concentrationadjacent to the storage-node diffusion must not exceed6/H1100310\\n17cm/H110023. An acceptable process window is de ﬁned\\nas points within the range of variation of these physicalparameters simultaneously falling below the 6 /H1100310\\n17-cm/H110023\\nchannel doping limit and meeting the 1-fA off-current\\nconstraint. As indicated in Figure 12 , variation in wordline\\nwidth from the nominal value is speci ﬁed as a dimensional\\nchange per edge (nm/edge), /H9004GC; the total variation in\\nwordline width would be 2 /H11003/H9004 GC. Encroachment\\nof the buried-strap diffusion on the array MOSFET ischaracterized by the parameter\\n/H9251, which accounts for\\nfactors such as the extent of the strap outdiffusion from\\nthe storage-trench wall, the amount of misalignment of the\\nwordline ( GC) with respect to the storage trench, and the\\nprocess bias and tolerance of the width of the storagetrench.\\nThe analyses reported here compare the relative process\\nwindows of the BEST cell at two technology nodes:0.150\\n/H9262m and 0.135 /H9262m. Techniques such as an aggressively\\nscaled buried-strap diffusion (60 nm outdiffusion from thewall of the storage trench and 70 nm depth from the topFigure 11\\nThe proximity of the buried-strap diffusion to the array-access \\ntransistor has a strong influence on its threshold voltage. The designed channel length for this test structure is 0.20   m, with varying amounts of storage-trench-to-far-edge-of-wordline spacing, /H9004X. The relatively long channel length in this test vehicle allows \\ndecoupling of the effects of V\\nt lowering from buried-strap proximity \\nand from DIBL due to drain proximity. Strap outdiffusion is ap-\\nproximately 0.08   m from the edge of the deep trench. /H9262/H9262Wordline\\n(gate)Passing\\nwordline\\nStrap\\n/H9004XBitline1.0\\n0.90.80.70.60.50.40.30.20.10.0\\n0.15 ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1065: ('oltage. The designed channel length for this test structure is 0.20   m, with varying amounts of storage-trench-to-far-edge-of-wordline spacing, /H9004X. The relatively long channel length in this test vehicle allows \\ndecoupling of the effects of V\\nt lowering from buried-strap proximity \\nand from DIBL due to drain proximity. Strap outdiffusion is ap-\\nproximately 0.08   m from the edge of the deep trench. /H9262/H9262Wordline\\n(gate)Passing\\nwordline\\nStrap\\n/H9004XBitline1.0\\n0.90.80.70.60.50.40.30.20.10.0\\n0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65\\nLimit\\nDesign distance between trench edge and\\nfar edge of wordline  (   m) /H9262Vt  (V)\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.195\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nsurface), negative wordline-low level of /H110020.5 V, and\\nequivalent gate dielectric thickness of 5.4 nm (allowing a\\nwordline boost as high as 2.7 V without exceeding the5-MV/cm reliability ﬁeld limit) were applied to improve\\nthe process window at these small design ground rules.Process biases and tolerances representative of the state ofthe art were used. The devices were modeled using ﬁnite-\\nelement process [29] and device-simulation programs [30].\\nFrom the results of the analysis shown in Figures 13\\nand 14, it is apparent that the process window shrinks\\nrapidly between the 0.150-\\n/H9262m and 0.135- /H9262m nodes. At\\na minimum lithographic feature size of 0.135 /H9262m, the\\nprocess window is constrained by the maximum channeldoping limit. Without the use of the /H110020.5-V negative\\nwordline-low (i.e., customarily practiced zero wordline-low), the process window would vanish entirely at 0.135\\n/H9262m.\\nAs shown in Figure 15 , the process window may be expanded\\nsigni ﬁcantly by changing the wordline-low level to /H110020.7 V.\\nHowever, the GIDL [27, 31] mechanism may impose alimit on the negative wordline-low level.\\nIt should be noted that the planar MOSFET acce', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1066: ('.135 /H9262m, the\\nprocess window is constrained by the maximum channeldoping limit. Without the use of the /H110020.5-V negative\\nwordline-low (i.e., customarily practiced zero wordline-low), the process window would vanish entirely at 0.135\\n/H9262m.\\nAs shown in Figure 15 , the process window may be expanded\\nsigni ﬁcantly by changing the wordline-low level to /H110020.7 V.\\nHowever, the GIDL [27, 31] mechanism may impose alimit on the negative wordline-low level.\\nIt should be noted that the planar MOSFET access\\ntransistor scales slightly better in stacked-capacitor cellsthan in trench-storage cells because of the absence of arelatively deep strap diffusion, whose proximity to theMOSFET is sensitive to the alignment between the gateconductor and the storage trench. STC cells eliminate thestrap diffusion, since contact from the stacked capacitor ismade to the top of the diffusion (Figure 3). Therefore,in STC cells the source –drain diffusions are relatively\\nshallow. The analysis of the process window for the BESTtrench-storage cell, previously discussed, considers aburied-strap diffusion depth of 70 nm with a source –drain\\n(i.e., bitline and node diffusion) depth of 55 nm. Improvedcontrol of the buried-strap recesses in the BEST cell, orprocess innovations, would enable a strap diffusion depththat is not deeper than the implanted source –drain\\ndiffusions; in that case, the scalability difference betweenthe BEST cell and a stacked-capacitor cell occupying achip area of 8 F\\n2(F2is an area equal to one minimum\\nfeature size long by one minimum feature size wide,F/H11003F) would be negligible.\\nOther thoughts on scaling the DRAM MOSFET\\nAs discussed in previous sections, concurrently satisfyingthe competing requirements of ultralow off-current(/H1101110\\n/H1100215A for long data retention) and adequate on-\\ncurrent (for charge-transfer performance) is hinderedby dif ﬁculties in scaling the gate-oxide thickness and the\\nchannel doping concentration in the array MOSFET. Theminimum gate-oxide thickness and/or the maximum gatevolt', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1067: (' size long by one minimum feature size wide,F/H11003F) would be negligible.\\nOther thoughts on scaling the DRAM MOSFET\\nAs discussed in previous sections, concurrently satisfyingthe competing requirements of ultralow off-current(/H1101110\\n/H1100215A for long data retention) and adequate on-\\ncurrent (for charge-transfer performance) is hinderedby dif ﬁculties in scaling the gate-oxide thickness and the\\nchannel doping concentration in the array MOSFET. Theminimum gate-oxide thickness and/or the maximum gatevoltage are constrained by reliability considerations thatlimit the maximum allowable gate-oxide ﬁeld to about\\n5 MV/cm. The channel doping concentration is limited bydefect-enhanced deep-trap-assisted storage-node junctionFigure 13\\nManufacturing process window for the BEST [8] cell at the 0.150-   m \\nminimum feature size. A negative wordline-low level of /H110020.5 V \\nwas used. Refer to Figure 12 for definition of /H9004GC and /H9251. Positive \\nvalues of /H9004GC and /H9251 correspond respectively to shorter gates and \\ncloser strap diffusion proximity. /H92629.0 /H11003 1017\\n8.0 /H11003 1017\\n7.0 /H11003 1017\\n6.0 /H11003 1017\\n5.0 /H11003 1017\\n4.0 /H11003 1017\\n3.0 /H11003 1017Vt  tailor peak  (cm/H110023)\\nProcess window\\n/H1100210 nm/edge10 nm/edge/H9004GC /H11005 20 nm/edge\\n0.0F /H11005 0.150   m\\nVWLL /H11005 /H11002 0.5 V/H9262\\n0 50 100 150\\n/H9251  (nm)Doping constraintFigure 12\\nThe manufacturing process window is characterized by parameters significantly affecting the array MOSFET off-current,  /H9004GC, and \\n/H9251. /H9004GC is a measure of the deviation of the wordline (gate \\nconductor) width from the nominal value. /H9251 is a measure of the \\namount of encroachment of the strap diffusion on the MOSFET, and includes factors such as the extent of the strap outdiffusion from the storage-trench sidewall, the amount of misalignment of the wordline (GC) with respect to the storage trench, and the \\nprocess bias and tolerance of the width of the storage trench.Design\\nwordline\\nwidthDesign\\nWL–DT\\nspace\\nNominal\\nBitline diff', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1068: ('251. /H9004GC is a measure of the deviation of the wordline (gate \\nconductor) width from the nominal value. /H9251 is a measure of the \\namount of encroachment of the strap diffusion on the MOSFET, and includes factors such as the extent of the strap outdiffusion from the storage-trench sidewall, the amount of misalignment of the wordline (GC) with respect to the storage trench, and the \\nprocess bias and tolerance of the width of the storage trench.Design\\nwordline\\nwidthDesign\\nWL–DT\\nspace\\nNominal\\nBitline diffusion\\nBitline\\ndiffusionGC bias/edge /H11001\\nGC tol/edge\\n/H9004GC\\n/H9004GC\\nDT\\nGC\\nTop view/H9251 /H9251Gate conductor\\n(GC)\\nNode diffusion Strap\\nDeepstoragetrench(DT)\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002196\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nleakage, which degrades data retention. These limitations\\nforce the design of the array MOSFET to depart fromthe scalability path de ﬁned by logic-transistor technology,\\nunless the voltage swing on the storage capacitor, V\\nstorage,\\nis also reduced. Although scaling of the storage-capacitorvoltage allows for an array MOSFET that is morefavorably scaled (i.e., thinner t\\nox), it emphasizes the\\nneed for low-voltage sensing circuits, and also does noteliminate the sensitivity of junction leakage to channeldoping concentration.\\nNegative wordline-low is effective in reducing the\\nchannel doping requirements and expanding themanufacturing process window. Although a wordline-lowlevel as negative as /H110020.7 V would allow the off-current\\nrequirement to be satis ﬁed at a signi ﬁcantly reduced\\nchannel-surface doping concentration, the subsurfaceconcentration (anti-punchthrough implant) would haveto remain high to contain DIBL at sub-0.10-\\n/H9262m channel\\nlengths. At the same time, however, the depletion regiondepth must be limited such that it is properly scaled to t\\nox\\nand channel length, without encroaching on the highlydoped punchthrough stop re', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1069: ('ss window. Although a wordline-lowlevel as negative as /H110020.7 V would allow the off-current\\nrequirement to be satis ﬁed at a signi ﬁcantly reduced\\nchannel-surface doping concentration, the subsurfaceconcentration (anti-punchthrough implant) would haveto remain high to contain DIBL at sub-0.10-\\n/H9262m channel\\nlengths. At the same time, however, the depletion regiondepth must be limited such that it is properly scaled to t\\nox\\nand channel length, without encroaching on the highlydoped punchthrough stop region. Accordingly, very sharptransitions in the channel pro ﬁle as a function of depth\\nfrom the gated surface would be required. Considering thelarge thermal budget introduced by junction anneals inDRAM processes, which have been found to be essentialfor reducing leakage currents, achieving such a steepchannel pro ﬁle may not be possible. Another constraint is\\nthat the tail of the anti-punchthrough implant must be farenough away from the depletion region associated with thestorage-node diffusion to avoid increased junction leakage.\\nLateral channel pro ﬁle engineering (i.e., halos) has\\nlong been used to form asymmetric MOSFETs, where thechannel doping is highest at one source –drain diffusion.\\nAlthough this approach may be useful for limiting thechannel doping at the storage-node diffusion, whilemeeting the V\\ntand sub- Vtslope requirements, for\\nrelatively long-channel array MOSFETs (i.e., longer than0.15\\n/H9262m) its implementation at scaled channel lengths\\nmay not be possible. Because of lateral channel dopantredistribution during DRAM anneal processes, it may notbe possible to avoid encroachment of the halo upon thestorage-node diffusion.\\nGeometric approaches to scaling the channel length\\nof the array MOSFET include deviations from a purelyplanar channel. With the grooved gate MOSFET [32], thechannel is partially contained within a groove betweensource –drain diffusions, with the gate conductor shielding\\nthe source end of the channel from the drain ﬁeld. The\\nstep transfer device [33] also provides for drain ﬁe', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1070: ('tredistribution during DRAM anneal processes, it may notbe possible to avoid encroachment of the halo upon thestorage-node diffusion.\\nGeometric approaches to scaling the channel length\\nof the array MOSFET include deviations from a purelyplanar channel. With the grooved gate MOSFET [32], thechannel is partially contained within a groove betweensource –drain diffusions, with the gate conductor shielding\\nthe source end of the channel from the drain ﬁeld. The\\nstep transfer device [33] also provides for drain ﬁeld\\nshielding by a partially intervening gate conductor. Athird geometric variation for extending the scalability of apartially planar channel MOSFET is offered by the three-sided-gate transfer device [34]. This design provides a gateconductor which is intentionally wrapped around the sides\\nof the narrow array MOSFET; full depletion betweenside gates is obtained, and penetration of the drain ﬁeld\\ntoward the source is suppressed. Along the same lines asthe three-sided-gate transistor, double-gate (DG-FET) [35]MOSFETs offer signi ﬁcantly improved scalability, but with\\nnew process-integration challenges. SOI technology hasFigure 14\\nManufacturing process window for the BEST [8] cell at the 0.135-  m \\nminimum feature size. A negative wordline-low level of /H110020.5 V \\nwas used. The process window is only about half the size of the same cell at the 0.150-  m technology node (Figure 13). Only a maximum /H9004GC    5 nm/edge can be tolerated./H9262\\n/H92621.3 /H11003 1018\\n1.2 /H11003 1018\\n1.1 /H11003 1018\\n1.0 /H11003 1018\\n9.0 /H11003 1017\\n8.0 /H11003 1017\\n7.0 /H11003 1017\\n6.0 /H11003 1017\\n5.0 /H11003 1017\\n4.0 /H11003 1017\\n3.0 /H11003 1017\\n2.0 /H11003 1017Vt  tailor peak  (cm/H110023)\\nProcess window\\n/H1100210 nm/edge10 nm/edge/H9004GC /H11005 20 nm/edge\\n0.0F /H11005 0.135   m\\nVWLL /H11005 /H11002 0.5 V/H9262\\n0 50 100 150 200\\n/H9251  (nm)Doping constraint\\nProcess window\\nFigure 15\\nThe process window at 0.135-   m minimum feature size is expand-ed by increasing the negative wordline-low level from /H110020.5 V to \\n/H110027 ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1071: ('1018\\n9.0 /H11003 1017\\n8.0 /H11003 1017\\n7.0 /H11003 1017\\n6.0 /H11003 1017\\n5.0 /H11003 1017\\n4.0 /H11003 1017\\n3.0 /H11003 1017\\n2.0 /H11003 1017Vt  tailor peak  (cm/H110023)\\nProcess window\\n/H1100210 nm/edge10 nm/edge/H9004GC /H11005 20 nm/edge\\n0.0F /H11005 0.135   m\\nVWLL /H11005 /H11002 0.5 V/H9262\\n0 50 100 150 200\\n/H9251  (nm)Doping constraint\\nProcess window\\nFigure 15\\nThe process window at 0.135-   m minimum feature size is expand-ed by increasing the negative wordline-low level from /H110020.5 V to \\n/H110027 V . The /H9004GC range is no longer limited by the doping constraint. \\nHowever, leakage contributed by GIDL [27, 31] may prevent use of wordline-low more negative than /H110020.7 V ./H92621.10 /H11003 1018\\n1.00 /H11003 1018\\n9.00 /H11003 1017\\n8.00 /H11003 1017\\n7.00 /H11003 1017\\n6.00 /H11003 1017\\n5.00 /H11003 1017\\n4.00 /H11003 1017\\n3.00 /H11003 1017\\n2.00 /H11003 1017\\n1.00 /H11003 1017Vt  tailor peak  (cm/H110023)\\n/H1100210 nm/edge10 nm/\\nedge /H9004GC /H11005 20 nm/edge\\n0.0F /H11005 0.135   m\\nVWLL /H11005 /H11002 0.7 V/H9262\\n/H9251  (nm)Doping constraint\\n0 50 100 150 200 250Process window\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.197\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nalso been considered for DRAM [3] because of the\\nbene ﬁts of reduced junction-to-body area (e.g., lower\\nbitline junction capacitance, lower node junction leakage)and improved scalability arising from fully depletedoperation. However, dynamic leakage mechanismsampli ﬁed by the parasitic bipolar transistor contained\\nwithin the SOI MOSFET present a serious concern [36].Although these geometric variations extend the scalability\\nof a channel de ﬁned (or de ﬁned in part) by lithography,\\nthey provide only interim solutions at the cost of increasedprocess complexity.\\nTo sum it up, the continued scaling of the channel\\nlength of the planar MOSFET DRAM transfer devicebelow 0.135\\n/H9262m introduces new uncertainties into the\\npic', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1072: ('operation. However, dynamic leakage mechanismsampli ﬁed by the parasitic bipolar transistor contained\\nwithin the SOI MOSFET present a serious concern [36].Although these geometric variations extend the scalability\\nof a channel de ﬁned (or de ﬁned in part) by lithography,\\nthey provide only interim solutions at the cost of increasedprocess complexity.\\nTo sum it up, the continued scaling of the channel\\nlength of the planar MOSFET DRAM transfer devicebelow 0.135\\n/H9262m introduces new uncertainties into the\\npicture: successful implementation of low-voltage sensing,the tradeoff between voltage scaling and increased channeldoping on retention time, and extreme requirements onchannel pro ﬁle engineering.\\nIn light of the discussion regarding the scalability of\\nthe planar MOSFET in a DRAM cell, there is a need todecouple the channel length of the MOSFET from theminimum lithographic feature size. It is shown next thata paradigm shift to DRAM cells using MOSFETs whosechannel is oriented vertically meets this need. Althoughuse of vertical-MOSFET DRAM cells was consideredearlier [37], its adoption at the present time appearsto be essential for continued reduction of cell size.\\nA paradigm shift —vertical-MOSFET DRAM\\ncells\\nOne answer to the problem of scaling the array transistoris to begin using the third dimension for the device.When a transistor is built along the walls of a trench,the channel length is decoupled from the minimumlithographic feature size and the size of the memory cell;the scaling problems for the planar access MOSFET,discussed earlier, are thus avoided. DRAM cells usingtrench-storage capacitors are particularly well suited forthe integration of vertical transistors, since a portionof the wall of the trench above the storage capacitor isutilized for the channel, while the bitline wiring is formedabove the surface of the silicon substrate. The evolutionfrom today ’s BEST trench cell to a vertical-transistor\\ntrench cell is depicted in Figure 16 [38]. A deep strap\\nconnection, including n\\n/H11001strap diffusion,', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1073: ('ccess MOSFET,discussed earlier, are thus avoided. DRAM cells usingtrench-storage capacitors are particularly well suited forthe integration of vertical transistors, since a portionof the wall of the trench above the storage capacitor isutilized for the channel, while the bitline wiring is formedabove the surface of the silicon substrate. The evolutionfrom today ’s BEST trench cell to a vertical-transistor\\ntrench cell is depicted in Figure 16 [38]. A deep strap\\nconnection, including n\\n/H11001strap diffusion, is formed\\nbetween the wall of the trench and the storage-capacitorpolysilicon node in the trench. A second n\\n/H11001diffusion,\\nincluding bitline diffusion, is formed at the top surface ofthe substrate, with the channel of the MOSFET on thewall of the trench between the two n\\n/H11001diffusion regions.\\nIt appears that integration of a vertical transistor with astacked-capacitor type of cell would be more dif ﬁcult to\\nimplement than for a trench-storage capacitor cell, sincethe stacked capacitor is formed above the surface of thesilicon substrate. The bitlines would have to either runabove the substrate or be buried beneath the channel ofthe vertical MOSFET within the substrate. The formercase presents the problem of bringing the buriedsource –drain diffusion of the vertical MOSFET to the\\nsurface. The second option requires bitline conductors to beformed below the surface of the substrate, insulated fromFigure 16\\nEvolution from the 8 F2 planar MOSFET cell to vertical MOSFET \\ncells, adapted with permission from [38]; © 1999 IEEE. WL\\nSTIBitline\\n WL\\nSTIBitline\\n WLBitline8F2 BEST cell8F2 vertical\\nBEST cellSub-8 F2 \\nvertical cell\\nPassing WL Passing WL\\nn/H11001\\nn/H11001 buried plate n/H11001 buried platen/H11001n/H11001\\nChannel Channel\\nStrapDeep strapOxide\\nisolationcollar\\nNodedielectric\\nFigure 17\\nModeled vertical doping profile showing that the energy of the channel \\ndoping implant can be adjusted such that its peak is sufficiently far from the strap diffusion. This helps ensure low junction leakage while still meeting', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1074: ('[38]; © 1999 IEEE. WL\\nSTIBitline\\n WL\\nSTIBitline\\n WLBitline8F2 BEST cell8F2 vertical\\nBEST cellSub-8 F2 \\nvertical cell\\nPassing WL Passing WL\\nn/H11001\\nn/H11001 buried plate n/H11001 buried platen/H11001n/H11001\\nChannel Channel\\nStrapDeep strapOxide\\nisolationcollar\\nNodedielectric\\nFigure 17\\nModeled vertical doping profile showing that the energy of the channel \\ndoping implant can be adjusted such that its peak is sufficiently far from the strap diffusion. This helps ensure low junction leakage while still meeting the subthreshold off-current objective for long data retention. Reprinted with permission from [38]; ©1999 IEEE.0 0.1 0.2 0.3 0.4 0.5 0.6\\nDistance from top surface  (   m)Doping concentration\\n/H92621020\\n1019\\n1018\\n1017\\n1016\\n1015n/H11001 bitline\\ndiffusion n/H11001 strap\\ndiffusion\\np-well/\\nchannelp-substrate\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002198\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nthe substrate, and connected to the buried source –drain\\ndiffusion of the vertical MOSFET. Either stacked-\\ncapacitor case appears to involve more structural andprocess complexity than trench-storage vertical-MOSFETcells. Because of these complications, it is believed thattrench-storage DRAM technology is the preferredapproach to scaling vertical-MOSFET DRAM cells.\\nIn vertical-MOSFET DRAM cells, the channel of the\\ntransistor is made suf ﬁciently long to reduce threshold-\\nvoltage variations due to electrical and geometric\\nsensitivities (i.e., DIBL) to an acceptable level.Furthermore, the relatively long channel of the verticalMOSFET allows a thicker gate dielectric that is properlyscaled in proportion to the channel length, while providingreliability against wearout. Another advantage of thevertical MOSFET is that the channel doping pro ﬁle\\nmay be graded such that the doping concentration inthe vicinity of the buried-strap diffusion is minimized(providing reduced junction leakage) while meeting thes', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1075: (' electrical and geometric\\nsensitivities (i.e., DIBL) to an acceptable level.Furthermore, the relatively long channel of the verticalMOSFET allows a thicker gate dielectric that is properlyscaled in proportion to the channel length, while providingreliability against wearout. Another advantage of thevertical MOSFET is that the channel doping pro ﬁle\\nmay be graded such that the doping concentration inthe vicinity of the buried-strap diffusion is minimized(providing reduced junction leakage) while meeting thesubthreshold off-current objective needed for long dataretention. As shown in Figure 17 , the energy of the\\nthreshold implant may be adjusted to produce a peak\\nconcentration that is suf ﬁciently far from the buried-strap\\ndiffusion.\\nContinued reduction in cost per bit depends upon\\nthe ability to scale the cell area more rapidly than the\\nreduction in minimum lithographic feature size, whilecontaining increases in process complexity. This requiresthat the cell be scaled below 8 F\\n2. The 8 F2vertical-MOSFET\\ncell shown in Figure 16 utilizes a layout ( Figure 18 )\\nin which adjacent vertical transistors are arranged back-to-back within the same region of silicon and share acommon bitline diffusion. The 8 F\\n2layout shown also\\nprovides good bitline noise rejection because of its folded-\\nbitline architecture [39]. Although the 8 F2layout provides\\na space of ﬁve minimum lithographic features between\\npairs of storage trenches, this spacing decreases rapidlywith more compact cells. A generic layout of back-to-back-storage-trench vertical-MOSFET cells is shown in Figure 19 .\\nFor this rectangular layout, the distance between back-\\nto-back trenches decreases from 3 F,f o ra6 F\\n2cell, to 1 F,\\nf o ra4 F2cell. One of the scalability concerns for cells\\nusing this layout is the interaction between adjacentvertical MOSFETs. Another concern is noise immunitydue to the inherent open-bitline layout of sub-8 F\\n2cells.\\nOn the scalability of back-to-back vertical-\\nMOSFET cells\\nStatic leakage\\nAs the distance between back-to-back cells decre', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1076: ('trench vertical-MOSFET cells is shown in Figure 19 .\\nFor this rectangular layout, the distance between back-\\nto-back trenches decreases from 3 F,f o ra6 F\\n2cell, to 1 F,\\nf o ra4 F2cell. One of the scalability concerns for cells\\nusing this layout is the interaction between adjacentvertical MOSFETs. Another concern is noise immunitydue to the inherent open-bitline layout of sub-8 F\\n2cells.\\nOn the scalability of back-to-back vertical-\\nMOSFET cells\\nStatic leakage\\nAs the distance between back-to-back cells decreases,\\nleakage current between strap outdiffusions, due tolowering of the potential barrier, becomes a concern; thisFigure 18\\n8F2 vertical MOSFET cell layout in which the distance between \\nback-to-back storage trenches is 5 F, adapted with permission from \\n[38]; © 1999 IEEE.Passing\\nwordlineActivewordlineBitline\\ncontact\\nSTISTI\\nActive Si\\n(active area)Channel\\nTrench\\ncapacitor\\nBoundary\\nof unit cell\\nFigure 19\\nGeneric vertical MOSFET cell top view. As cell size is reduced \\nfrom 8 F2 to 6F2 to 4F2, the distance between back-to-back storage \\ntrenches, /H9004DT, decreases from 5 F to 3F to 1F. /H9004BSOD  is the dis-\\ntance between buried-strap outdiffusions of adjacent cells sharing a common bitline contact.Bitline\\npitchBitline\\ncontactWordline\\nWordlineWordlineWordline\\n/H9004DT\\n/H9004BSOD\\nVertical\\nchannelUnit cell\\nBuried-strapoutdiffusion\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.199\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nis a manifestation of the drain-induced barrier-lowering\\nmechanism (DIBL), due to penetration of the electricﬁeld, which is well known for MOSFETs [40]. The\\nmodeled geometry and approximate location of depletionregion edges of back-to-back vertical-MOSFET cells areshown in Figure 20 .T o ﬁrst order, the extent of the\\nbarrier lowering is a function of the p-well dopingconcentration between n\\n/H11001strap diffusions, and the\\ndistance between metallurgical junctions; the highes', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1077: ('EE Xplore.  Restrictions apply. \\nis a manifestation of the drain-induced barrier-lowering\\nmechanism (DIBL), due to penetration of the electricﬁeld, which is well known for MOSFETs [40]. The\\nmodeled geometry and approximate location of depletionregion edges of back-to-back vertical-MOSFET cells areshown in Figure 20 .T o ﬁrst order, the extent of the\\nbarrier lowering is a function of the p-well dopingconcentration between n\\n/H11001strap diffusions, and the\\ndistance between metallurgical junctions; the highestp-well concentration and smallest strap outdiffusionare desired. This static leakage mechanism results in anadjacent stored high level (i.e. “1”) and low level (i.e. “0”)\\nleaking toward each other, which results in degradation ofsignal margin.\\nSince the maximum p-well doping concentration is\\nconstrained by junction leakage considerations, scalability\\nof this cell depends on minimizing the extent of theburied-strap outdiffusion.\\nDynamic leakage\\nAlso of concern in scaling a cell of this type is a dynamicleakage mechanism for a stored “1”when the bitline and\\nthe wordline of the adjacent cell are cycled in the courseof data read, write, and refresh operations. As the cell iscycled, the distribution of majority carriers (i.e., holes) inthe p-well region between the two opposed vertical gatesis modulated by the time-varying electric ﬁeld. Majoritycarriers must be able to ﬂow freely between the portion\\nof the p-well between the gates and the region below the\\nstrap diffusions to maintain charge equilibration in thewell. The undepleted region between two back-to-backburied-strap outdiffusions narrows as the spacing betweenstorage trenches in two back-to-back cells is reduced, thusimpeding the ﬂow of holes and pumping the voltage on\\nthe p-well between the gates as the wordline is cycled.\\nModulation of the voltage on the p-well and the buried-\\nstrap diffusion (as the data state is changed) of theadjacent cell results in a loss of charge from the stored“1”due to both transient subthreshold leakage and\\ntransient exchange o', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1078: ('ell. The undepleted region between two back-to-backburied-strap outdiffusions narrows as the spacing betweenstorage trenches in two back-to-back cells is reduced, thusimpeding the ﬂow of holes and pumping the voltage on\\nthe p-well between the gates as the wordline is cycled.\\nModulation of the voltage on the p-well and the buried-\\nstrap diffusion (as the data state is changed) of theadjacent cell results in a loss of charge from the stored“1”due to both transient subthreshold leakage and\\ntransient exchange of electron charge between the twoadjacent strap diffusions. Finite-element device simulation[30] of the cell has determined that the worst-case datapattern for a loss of a stored “1”occurs when the adjacent\\ncell is repeatedly cycled between write “1”and write “0”;\\nmost of the loss occurs when a “0”is written over a cell\\nwith a stored “1.”It may seem unlikely that a DRAM cell\\nwould be exercised repeatedly with a write “1”–write “0”\\npattern; nevertheless, such a pattern is possible, and data\\nintegrity must be ensured. Although the loss of charge\\nFigure 20\\nModeled cross section illustrating the geometry of back-to-back \\nstorage trenches and approximate depletion region edge. A high level ( “1”) and a low level ( “0”) are stored on the left-hand and \\nright-hand capacitors, respectively./H9004DT\\n/H9004BSODn/H11001 bitline diffusion\\nDepletion edgeGate  oxide\\nn/H11001\\nBSODn/H11001\\nBSOD0.9\\n0.80.70.60.50.40.3TTO\\nStored “1”\\nStored “0”Left\\nWLRight\\nWL\\nTrench topoxide (TTO)\\nStrap StrapIsolationcollar\\nRight storagetrench\\nm\\n/H9262m/H9262\\n/H110020.2 /H110020.1 0.0 0.1 0.2 0.3\\nFigure 21\\nEquivalent circuit of back-to-back vertical MOSFET cells. M1, \\nCs1 and M2, Cs2 are respectively the access transistor and the storage capacitor of the right-hand and left-hand cells. The equivalent circuit contains many parasitic elements which account for the signal-loss mechanisms. Jw is a parasitic JFET whose channel represents the undepleted region between storage-node diffusions (i.e., buried-strap outdiffusions) N1 and N2. Qw1, Qw2, and Qw', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1079: ('\\n/H9262m/H9262\\n/H110020.2 /H110020.1 0.0 0.1 0.2 0.3\\nFigure 21\\nEquivalent circuit of back-to-back vertical MOSFET cells. M1, \\nCs1 and M2, Cs2 are respectively the access transistor and the storage capacitor of the right-hand and left-hand cells. The equivalent circuit contains many parasitic elements which account for the signal-loss mechanisms. Jw is a parasitic JFET whose channel represents the undepleted region between storage-node diffusions (i.e., buried-strap outdiffusions) N1 and N2. Qw1, Qw2, and Qw3 are parasitic npn bipolar transistors which may conduct when the well potential between access MOSFETs (Pwint) is allowed to bounce due to coupling from a cycling wordline and storage node. A high voltage (i.e., “1”) stored on Cs2 may degrade \\nprimarily because of conduction of Qw3.PWext\\nVbb = /H110020.5 VPWintBL\\nWL2 WL1CbwCww2 Cww1\\nQw2 Qw1\\nCnw2 Cnw1\\nCs2 Cs1N2 N1M1 M2\\nJwQw3\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002200\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nfrom a stored “1”may be less than a tenth of a microvolt\\nper cycle, inability to detect the “1”may occur since\\n106to 107wordline cycles are possible before data is\\nrefreshed. The interaction between cells is more easily\\nunderstood with the assistance of the equivalent-circuitmodel shown in Figure 21 .Figure 22 shows the average\\nloss per cycle of a stored “1”due repeated cycling\\nbetween write “1”and write “0”on the adjacent cell. The\\nrate of loss of a stored “1”has been calculated with a full\\n1.5 V on the storage capacitor as a function of spacingbetween back-to-back buried-strap outdiffusions, /H9004BSOD ,\\nwith the spacing between storage trenches, /H9004DT,a sa\\nparameter. The minimum acceptable end of process /H9004DT,\\narbitrarily considering that the maximum acceptable loss\\nof a stored “1”is 100 mV, is indicated after 10\\n7wordline\\ncycles. The rate of loss decreases slightly as the strengthof the stored “1”is reduced because ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1080: ('ell. The\\nrate of loss of a stored “1”has been calculated with a full\\n1.5 V on the storage capacitor as a function of spacingbetween back-to-back buried-strap outdiffusions, /H9004BSOD ,\\nwith the spacing between storage trenches, /H9004DT,a sa\\nparameter. The minimum acceptable end of process /H9004DT,\\narbitrarily considering that the maximum acceptable loss\\nof a stored “1”is 100 mV, is indicated after 10\\n7wordline\\ncycles. The rate of loss decreases slightly as the strengthof the stored “1”is reduced because of contraction of the\\ndepletion region and expansion of the undepleted widthbetween strap diffusions. Figure 23 shows the minimum\\nusable feature size ( F), as constrained by both static and\\ndynamic leakage mechanisms, as a function of normalizedcell area (i.e., number of square minimum features). Atypical buried-strap outdiffusion of 50 nm from the trenchsidewall is considered. It is noteworthy that the dynamicleakage mechanism sets the constraint for the minimumfeature size. These results based on conservativeassumptions support scaling of the 6 F\\n2cell to ground\\nrules smaller than 0.09 /H9262m, for a cell size smaller than\\n0.05 /H9262m2.\\nAs indicated by Figure 23, for a given buried-strap\\noutdiffusion, the scalability of the cell is limited by theminimum allowable spacing between back-to-back trenches.\\nAlternative layouts can be used to increase the bitlinepitch while maintaining desired cell area and trench-to-trench spacing. The 6 F\\n2cell shown in Figure 24Figure 22\\nModeled average loss of a stored “1” per cycle due to repeated \\nwrite “1” – write “0” pattern on adjacent cell.1000\\n100\\n10\\n1\\n0.1\\n0.01\\n0.001\\n0.0001\\n50 70 90 110 130 150 170 190 210\\n/H9004BSOD   (nm)/H9004DT  /H11005 200 nmAverage loss per WL cycle  (  V)/H9262\\n \\n \\n/H9004BSOD/H9004DT\\n“1”“1”–\\n“0”–\\n“1”Right\\nWLLeftWL0.0 V\\nn\\n/H11001n/H11001\\nn/H11001Bitline100 mVloss after10\\n7 cycles\\n300 nm250 nm\\nFigure 23\\nTradeoff between the minimum allowable feature size ( F) and the \\nnormalized cell area, expressed as the number of square minimum \\nfeatures, for the', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1081: ('r cycle due to repeated \\nwrite “1” – write “0” pattern on adjacent cell.1000\\n100\\n10\\n1\\n0.1\\n0.01\\n0.001\\n0.0001\\n50 70 90 110 130 150 170 190 210\\n/H9004BSOD   (nm)/H9004DT  /H11005 200 nmAverage loss per WL cycle  (  V)/H9262\\n \\n \\n/H9004BSOD/H9004DT\\n“1”“1”–\\n“0”–\\n“1”Right\\nWLLeftWL0.0 V\\nn\\n/H11001n/H11001\\nn/H11001Bitline100 mVloss after10\\n7 cycles\\n300 nm250 nm\\nFigure 23\\nTradeoff between the minimum allowable feature size ( F) and the \\nnormalized cell area, expressed as the number of square minimum \\nfeatures, for the layout shown in Figure 19. As the normalized area of the cell is reduced, the distance between back-to-back storage trenches decreases and the minimum usable feature size must be increased. Dynamic leakage is the limiting mechanism. A 6 F\\n2 \\nlayout is acceptable at F    90 nm.4 5 6 7 8\\nNormalized cell area\\n(number of square minimum features)300\\n250200150100\\n50\\n0Minimum usable feature size, F  (nm)Buried-strap outdiffusion /H11005 50 nm\\nDynamic leakage constraint\\nStatic leakage constraint\\nFigure 24\\nHerringbone active area (AA) pattern for a 6 F2 vertical MOSFET \\ncell, adapted with permission from [41]; © 2000 IEEE. The bitline \\npitch is increased to 3 F, while nearly 3 F spacing is maintained \\nbetween trenches (DT). The 3 F bitline pitch facilitates the layout of \\nthe sense amplifiers for this open-bitline architecture.2F3F\\nDTDT\\nContactWL\\nWL\\nWLBL BL BL\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.201\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\n[41] uses a herringbone active-area (AA) pattern\\nto increase the bitline pitch to 3 F(from 2 Fin the\\nrectangular layout shown in Figure 19), while maintainingclose to 3 Fspacing between trenches. The increased\\nbitline pitch is important with the 6 F\\n2cell because it\\nfacilitates the layout of the sense ampli ﬁers. While 8 F2\\nlayouts having a folded-bitline architecture pose noproblem for sense-ampli ﬁer layout with a single level of\\nbitline wiring, th', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1082: ('5 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\n[41] uses a herringbone active-area (AA) pattern\\nto increase the bitline pitch to 3 F(from 2 Fin the\\nrectangular layout shown in Figure 19), while maintainingclose to 3 Fspacing between trenches. The increased\\nbitline pitch is important with the 6 F\\n2cell because it\\nfacilitates the layout of the sense ampli ﬁers. While 8 F2\\nlayouts having a folded-bitline architecture pose noproblem for sense-ampli ﬁer layout with a single level of\\nbitline wiring, the inherent open-bitline architecture of6F\\n2cells requires two levels of bitline wiring to achieve\\nfolded-bitline operation.\\nArray architecture considerations for sub-8 F2\\ncells\\nContinued reduction in cost per bit of DRAMs dependsupon scaling of cell sizes faster than the scaling oflithography features alone would provide. Ever-shrinking\\ncell size also demands fundamental changes in the arrayarchitecture. Folded-bitline array architecture ( Figure 25 )has been used universally within the DRAM industry since\\nthe 1Mb era. In this architecture, the cell contains onebitline and two wordlines. The “active wordline ”forms the\\ngate of the transfer device, whereas the “passing wordline ”\\nsimply passes over the cell. The cells are arranged sothat the passing wordline of one cell becomes the activewordline of the adjacent cell, and vice versa. Thus, whena wordline is selected, signal charge is released onto everyother bitline. Each sense ampli ﬁer serves two adjacent\\nbitlines, allowing each sense ampli ﬁer to sense the “data\\nbitline ”using the adjacent bitline as a reference. The\\nadjacent nature of the data and reference bitlines providesexcellent matching and noise rejection. By includingmultiplexor devices on either side of the sense ampli ﬁer,\\neach sense ampli ﬁer can be shared between two bitlines\\nfrom the left array and two bitlines from the right array.Thus, each sense ampli ﬁer serves a total of four bitlines.\\nThe folded-bitline architecture requires a minimum cell\\nsize of 8 F\\n2, where Fis the minimum lithographic ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1083: ('“data\\nbitline ”using the adjacent bitline as a reference. The\\nadjacent nature of the data and reference bitlines providesexcellent matching and noise rejection. By includingmultiplexor devices on either side of the sense ampli ﬁer,\\neach sense ampli ﬁer can be shared between two bitlines\\nfrom the left array and two bitlines from the right array.Thus, each sense ampli ﬁer serves a total of four bitlines.\\nThe folded-bitline architecture requires a minimum cell\\nsize of 8 F\\n2, where Fis the minimum lithographic feature\\nsize of the technology. The minimum cell size equals oneminimum-bitline pitch (1 line /H110011 space /H110052F) times two\\nminimum-wordline pitches (2 lines /H110012 spaces /H110054F), or\\n8F\\n2. Until recently, this limit had not been reached, as\\nother structures within the cell (bitline contact, transferdevice, node diffusion, storage capacitor, and isolation)required more than 8 F\\n2and therefore limited the cell size.\\nHowever, since DRAM cell area historically scales morequickly (0.33 /H11003per generation) than lithographic\\nimprovements alone provide (0.70\\n2/H110050.49/H11003per\\ngeneration), the cell size measured in F2must decrease\\nover time. The cell size reached the 8 F2limit at the\\n0.175- /H9262m generation, with these technologies being quali ﬁed\\nin late 1999 or early 2000. For the cell area to continue toscale at the historic rate, the 8 F\\n2limit must be overcome.\\nThe vertical cell described in this paper allows the otherstructures within the cell to ﬁt into less than 8 F\\n2, but does\\nnot address the problem of providing the wiring requiredfor folded-bitline operation. DRAM designers around theworld have been aware of this approaching limit for sometime. Many solutions have been proposed; however, noconsensus on a preferred solution has been established.\\nThe most obvious solution is the open-bitline\\narchitecture seen in Figure 26 , which was used universally\\nwithin the industry prior to the introduction of the folded-bitline architecture. In this architecture, a cell containsone bitline and one wo', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1084: ('s the problem of providing the wiring requiredfor folded-bitline operation. DRAM designers around theworld have been aware of this approaching limit for sometime. Many solutions have been proposed; however, noconsensus on a preferred solution has been established.\\nThe most obvious solution is the open-bitline\\narchitecture seen in Figure 26 , which was used universally\\nwithin the industry prior to the introduction of the folded-bitline architecture. In this architecture, a cell containsone bitline and one wordline, and the sense ampli ﬁer\\nsenses the data bitline using a reference bitline from theadjacent, inactive array. The minimum cell size is 4 F\\n2,\\nalthough other constraints within the cell (i.e., minimumtrench-to-trench spacing) will limit the cell size tosomething greater than 4 F\\n2for some time. However, the\\nopen-bitline architecture has several drawbacks. Since thedata and reference bitline are located in adjacent arrays,the matching and noise rejection characteristics are notFigure 25\\nFolded-bitline array architecture.Sense\\namplifier... ... ... ...Selected wordline\\nReference bitlineData bitlineMultiplexor devices\\nCell\\nSelected cell\\nFigure 26\\nOpen-bitline array architecture.Sense\\namplifier... ... ... ...Selected wordline Reference bitline\\nData bitline\\nCell\\nSelected cell\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002202\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nas favorable as those of the folded-bitline architecture.\\nFurther, since each sense ampli ﬁer serves only two\\nbitlines as opposed to four bitlines for the folded-bitlinearchitecture, the chip will require twice as many senseampli ﬁers, assuming the same number of bits per bitline.\\nThis is a signi ﬁcant drawback, since sense ampli ﬁers\\noccupy approximately 10% of the total chip area in amodern DRAM.\\nAfter evaluating the open-bitline option and several\\nother sub-8 F\\n2DRAM array architectures [42 –44], IBM\\nhas focused its efforts ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1085: (' of the folded-bitline architecture.\\nFurther, since each sense ampli ﬁer serves only two\\nbitlines as opposed to four bitlines for the folded-bitlinearchitecture, the chip will require twice as many senseampli ﬁers, assuming the same number of bits per bitline.\\nThis is a signi ﬁcant drawback, since sense ampli ﬁers\\noccupy approximately 10% of the total chip area in amodern DRAM.\\nAfter evaluating the open-bitline option and several\\nother sub-8 F\\n2DRAM array architectures [42 –44], IBM\\nhas focused its efforts on the vertically twisted bitlinearray architecture seen in Figure 27 [45–48]. In this\\narchitecture, the reference bitline is located directly abovethe data bitline on the subsequent level of metal. For thisreason, this architecture requires an additional level ofmetal for the second level of bitlines. The cells areattached to the lower of the two bitline levels. The cellcontains two bitlines and one wordline, yet the minimumcell size which can be wired is 4 F\\n2, since the two bitlines\\nare on different levels. At intervals along the length of thebitline, the two bitlines exchange levels, or “twist. ”Each\\nbitline is on each level for equal lengths, so that the two\\nbitlines are matched. As in the folded-bitline architecture,the data and reference bitline are within the same array,leading to good matching and noise rejection. Also as inthe folded-bitline architecture, the sense ampli ﬁer can be\\nshared between two arrays, allowing each sense ampli ﬁer\\nto serve four bitlines. Since the twists involve only wiringand contacts, and no devices, the underlying array neednot be interrupted, and thus there is no area penalty forthe twists. This architecture is particularly well suitedto IBM ’s trench-DRAM technology, since the capacitor\\nstructure of a stacked-capacitor DRAM technology wouldlikely interfere with the second level of bitlines and thetwist contacts.\\nA very signi ﬁcant advantage of this architecture is\\nthe cancellation of bitline coupling noise, as shown inFigure 28 . When the twists are staggered relative to t', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1086: ('d contacts, and no devices, the underlying array neednot be interrupted, and thus there is no area penalty forthe twists. This architecture is particularly well suitedto IBM ’s trench-DRAM technology, since the capacitor\\nstructure of a stacked-capacitor DRAM technology wouldlikely interfere with the second level of bitlines and thetwist contacts.\\nA very signi ﬁcant advantage of this architecture is\\nthe cancellation of bitline coupling noise, as shown inFigure 28 . When the twists are staggered relative to those\\nof the adjacent bitline pairs, noise from adjacent bitlinescouples equally into the data and reference bitlines,eliminating a signi ﬁcant differential noise source. This is\\naccomplished by manipulating the matrix of inter-paircoupling capacitance such that the capacitance from anybitline “BLi”to any other bitline “BLj”exactly matches\\nthe capacitance from “i”to“j’s complement, ”BLj(bar).\\nTherefore, any change in the voltage on BLi couplesequally into BLj and BLj(bar), creating no differentialnoise on pair BLj. This method reduces bitline couplingnoise during both the initial signal development and thesubsequent signal ampli ﬁcation. Similar methods have\\nbeen used by IBM and others to reduce bitline couplingnoise in the folded-bitline architecture [49].\\nStorage-capacitor scaling challenges\\nStorage-capacitor requirements\\nIn addition to reducing the area occupied by the DRAM\\naccess transistor, cell-size scaling depends on the ability toscale the portion of the cell layout area allocated to thestorage capacitor. The voltage swing on the storagecapacitor, V\\nstorage, has scaled more slowly than the\\nreduction in minimum lithographic feature size becauseof concerns about providing suf ﬁcient overdrive to set the\\nsense ampli ﬁers quickly. Furthermore, the signal induced\\non the bitline, V\\nsignal, has been constrained to be at least\\n100 mV by concerns about reliably setting the senseFigure 27\\nVertically twisted bitline array architecture.Sense\\namplifier... ... ... ... ...Selected wordline\\nReference bitline\\nData bitlin', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1087: ('or. The voltage swing on the storagecapacitor, V\\nstorage, has scaled more slowly than the\\nreduction in minimum lithographic feature size becauseof concerns about providing suf ﬁcient overdrive to set the\\nsense ampli ﬁers quickly. Furthermore, the signal induced\\non the bitline, V\\nsignal, has been constrained to be at least\\n100 mV by concerns about reliably setting the senseFigure 27\\nVertically twisted bitline array architecture.Sense\\namplifier... ... ... ... ...Selected wordline\\nReference bitline\\nData bitline\\nCell\\nSelected cellMultiplexor devices\\nUpper bitline level\\nLower bitline levelTwist\\nFigure 28\\nCancellation of bitline coupling noise: (a) Staggered twist arrange-\\nment; (b) resulting matrix of interpair coupling capacitance (all capacitors of equal value).BL pair 0\\nUpper bitline level\\nLower bitline levelBL pair 1\\nBL pair 2\\nBL pair 3\\n... ...BL0 BL1 BL3 BL2\\nBL0(bar) BL1(bar) BL3(bar) BL2(bar)(a)\\n(b)\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.203\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nampli ﬁers in the presence of various sources of noise\\n(i.e., sense-ampli ﬁerVtmismatch, coupling of switching\\ndisturbances, leakage, transient radiation-induced charge,\\netc.). Since the 4Mb generation, bitline capacitance hasgenerally remained within a range from about 150 fFto 350 fF, since the reduction in capacitance per bitresulting from scaling of physical dimensions of the bitlineconductor and the cell width has been offset by increases inthe number of bits per bitline, with increasing bits per chip.\\nThe storage capacitance must be suf ﬁcient to ensure the\\nobjective of minimum signal induced on the bitline, V\\nsignal;\\nthis is dependent on the product of the transfer ratio andthe voltage swing on the capacitor, V\\nstorage. As a result of\\nthe constraints discussed in the previous paragraph, therequired storage capacitance is expected to remain in therange from 30 to 40 fF. Therefore, the ﬁrst challeng', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1088: ('he cell width has been offset by increases inthe number of bits per bitline, with increasing bits per chip.\\nThe storage capacitance must be suf ﬁcient to ensure the\\nobjective of minimum signal induced on the bitline, V\\nsignal;\\nthis is dependent on the product of the transfer ratio andthe voltage swing on the capacitor, V\\nstorage. As a result of\\nthe constraints discussed in the previous paragraph, therequired storage capacitance is expected to remain in therange from 30 to 40 fF. Therefore, the ﬁrst challenge\\nfaced by all DRAM manufacturers is fabricating a low-leakage storage capacitor with adequate capacitance in anever-decreasing cell area.\\nPlanar storage-capacitor structures were employed\\nthrough the 1Mb DRAM generation. With the arrival ofthe 4Mb DRAM, adequate cell capacitance could nolonger be obtained from simple planar capacitors,marking the introduction of trench- and stacked-capacitorstructures. In the mid-1980s, IBM, Texas Instruments, andToshiba introduced the trench capacitor; stacked-capacitordesigns were shown by other DRAM manufacturers atabout the same time. These three-dimensional trench-capacitor and stacked-capacitor structures were developedto maintain the capacitance of the array cell relative tothe bitline capacitance as the cell size and bitline wiringspacing were reduced with successive DRAM generations.In IBM DRAM products, deep-trench storage hasprovided a remarkable platform for the continuous scalingof the charge-storage element. The trench structure hasserved to decouple the effective surface area of thecapacitor, and hence its capacitance, from the area ofthe array cell, while maintaining 35 fF –45 fF per cell.\\nThe total capacitor surface area available in a stacked\\ndesign is considerably less than that in a trench capacitor.This comes about because the height of a stacked-capacitor cylinder as shown in Figure 3 is limited to1–1.5\\n/H9262m. Anything taller than this causes problems with\\nmechanical stability. Additionally, it becomes dif ﬁcult to\\nwire over the topography of such a tal', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1089: ('ive surface area of thecapacitor, and hence its capacitance, from the area ofthe array cell, while maintaining 35 fF –45 fF per cell.\\nThe total capacitor surface area available in a stacked\\ndesign is considerably less than that in a trench capacitor.This comes about because the height of a stacked-capacitor cylinder as shown in Figure 3 is limited to1–1.5\\n/H9262m. Anything taller than this causes problems with\\nmechanical stability. Additionally, it becomes dif ﬁcult to\\nwire over the topography of such a tall capacitor. Thisleads to a need to introduce capacitor dielectrics withhigher dielectric constants (more capacitance per unitarea) than the NO (nitride –oxide) dielectric commonly\\nused by DRAM manufacturers through the 0.15-\\n/H9262m\\ngeneration, for both stacked and trench designs. Stacked-capacitor manufacturers have been introducing a seriesof new structures and materials for smaller-ground-ruletechnologies. Conventional NO dielectric has beenadequate down to 0.15\\n/H9262m. After that, Ta2O5is beingintroduced for the 0.12- /H9262m generation. For the 0.1- /H9262m\\ngeneration, a new material with yet higher dielectricconstant (relative dielectric constant /H1102220) will be needed.\\nToday no material has yet been shown to be adequate forthis generation, but most companies have been researchingbarium strontium titanate (BSTO) as the most likelycandidate. Although the scaling path for trench capacitorsappears to be more certain than that for stacked capacitors,there are many challenges that must be addressed.\\nIn addition to minimum capacitance requirements,\\nthe series resistance of the storage capacitor must becontained such that it does not degrade the transfer ofcharge between the bitline and the capacitor. The currentthrough the array MOSFET is in ﬂuenced by the total\\nseries resistance of the cell: channel on-resistance of theMOSFET, source –drain resistance, resistance of the\\nbitline contact and of the connection between theMOSFET and the capacitor (the strap in the caseof a trench capacitor), and the series re', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1090: ('addition to minimum capacitance requirements,\\nthe series resistance of the storage capacitor must becontained such that it does not degrade the transfer ofcharge between the bitline and the capacitor. The currentthrough the array MOSFET is in ﬂuenced by the total\\nseries resistance of the cell: channel on-resistance of theMOSFET, source –drain resistance, resistance of the\\nbitline contact and of the connection between theMOSFET and the capacitor (the strap in the caseof a trench capacitor), and the series resistance of thecapacitor itself. As the minimum lithographic feature sizeis scaled in a trench-capacitor cell, the series resistance ofthe conductor in the storage trench becomes the dominantcontributor to the total resistance. For stacked-capacitorcells, the resistance of the interconnection between thenode diffusion of the MOSFET and the overlyingcapacitor is a scaling concern. To avoid degradingthe charge-transfer performance, the series resistancecontributed by the capacitor must not generally exceedabout 50 k /H9024.\\nEach physical component of the trench capacitor\\nintroduces potential limits to its continued aggressivescaling. Areas of concern include the processing (i.e.,etching and ﬁlling) of the increasingly high aspect ratio\\nof the trench, thinning the capacitor dielectric for highercapacitance while limiting leakage, reducing capacitanceloss due to formation of depletion regions on the surfaceof the electrodes, and minimizing the increase in seriesresistance of the trench ﬁll with reduced-size lithographic\\nfeatures. Process technology and structural innovationshave been introduced to overcome these limits and arediscussed in the following paragraphs.\\nExtending the deep-trench capacitor\\nProcess challenges\\nAs discussed earlier, the deep-trench storage capacitor hastopography advantages over the stacked capacitor; thetrench is fully planarized to the silicon surface [17] anddoes not degrade the subsequent lithographic stepsby introducing topography or high-aspect-ratio vias.Additionally, the trench is fo', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1091: ('graphic\\nfeatures. Process technology and structural innovationshave been introduced to overcome these limits and arediscussed in the following paragraphs.\\nExtending the deep-trench capacitor\\nProcess challenges\\nAs discussed earlier, the deep-trench storage capacitor hastopography advantages over the stacked capacitor; thetrench is fully planarized to the silicon surface [17] anddoes not degrade the subsequent lithographic stepsby introducing topography or high-aspect-ratio vias.Additionally, the trench is formed before the array-transistor and support-circuit CMOS, and may besubjected to high-temperature processing steps (includingreduction and oxidation) without degrading the support-\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002204\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ndevice performance. Furthermore, the electrical\\nconnection between the trench and the array transistormay be made without the introduction of a dedicatedlithographic masking level [8], and it does not requirethe formation of a contact level that is borderless to thebitline wiring level. DRAM using a trench capacitor isparticularly well suited for embedded-memory applicationsbecause the thermal budget associated with the capacitoroccurs before the CMOS support devices are fabricated,and because the interconnect can be optimized for low-RCdelay performance such as a copper damascene\\nmetallurgy.\\nThe IBM trench-storage capacitor consists of a very-\\nhigh-aspect-ratio contact-style hole pattern etched into thesubstrate, a thin storage-node dielectric insulator, a dopedlow-pressure chemical vapor deposition (LPCVD)polysilicon ﬁll, and a buried-plate diffusion in the\\nsubstrate. A trench capacitor at an intermediate point inthe fabrication process of the cell is shown in Figure 29 .\\nThe doped LPCVD silicon ﬁll and the buried plate serve\\nas the electrodes of the capacitor. A dielectric isolationcollar in the upper region of the t', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1092: ('pacitor consists of a very-\\nhigh-aspect-ratio contact-style hole pattern etched into thesubstrate, a thin storage-node dielectric insulator, a dopedlow-pressure chemical vapor deposition (LPCVD)polysilicon ﬁll, and a buried-plate diffusion in the\\nsubstrate. A trench capacitor at an intermediate point inthe fabrication process of the cell is shown in Figure 29 .\\nThe doped LPCVD silicon ﬁll and the buried plate serve\\nas the electrodes of the capacitor. A dielectric isolationcollar in the upper region of the trench prevents leakageof the signal charge from the storage-node diffusion (notshown) to the buried-plate diffusion of the capacitor.\\nDry-etch patterning of the deep trench has required a\\nprogression of process technology innovations, as showninFigure 30 . The formation of the deep trench directly\\ninto the silicon substrate was enabled by the commercialavailability of reactive-ion-etch systems. The silicon isetched with high selectivity to an oxide hard mask usingcommon halogen feed gases. Magnetically enhanced RIEat the 0.5-\\n/H9262m generation and dipole ring magnet RIE\\nat 0.25- /H9262m technologies were introduced to maintain\\netch-rate throughput and pro ﬁle control. A hard-mask\\ndoped-oxide material that is selectively removed earlyin the trench process was introduced for the 0.175-\\n/H9262m\\ngeneration. RF techniques such as dual-frequency RIEwill be used to extend the silicon etching in the 0.120-\\n/H9262m\\nregime. Beyond 0.1 /H9262m, the aspect ratio (depth/width) of\\nthe trench may be limited, and the introduction of area-enhancement techniques and/or high- kthin dielectric\\ninsulators may be necessary.\\nCapacitance challenges\\nThe thin dielectric insulator used for the deep-trenchcapacitor comprises a thermal nitridation at thesubstrate/plate interface, and an LPCVD silicon nitridethat is subjected to a thermal oxidation to reduce leakagecurrent and improve the dielectric reliability [50]. An H\\n2\\nanneal is used prior to the thermal nitridation to controlthe oxygen content at the substrate interface. Reliabilityp', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1093: ('uction of area-enhancement techniques and/or high- kthin dielectric\\ninsulators may be necessary.\\nCapacitance challenges\\nThe thin dielectric insulator used for the deep-trenchcapacitor comprises a thermal nitridation at thesubstrate/plate interface, and an LPCVD silicon nitridethat is subjected to a thermal oxidation to reduce leakagecurrent and improve the dielectric reliability [50]. An H\\n2\\nanneal is used prior to the thermal nitridation to controlthe oxygen content at the substrate interface. Reliabilityprojections for reoxidized nitrides support intrinsicbreakdown beyond a ten-year lifetime for DRAM storage-node dielectrics as thin as 2.9 nm (equivalent oxidethickness). However, a dielectric leakage limit of\\n0.1 fA/\\n/H9262m2at 1 V and 85 /H11034C is reached at the 0.15- /H9262m\\ntechnology generation [50]; reductions in the dielectricthickness below /H110113.0 nm result in unacceptably large\\ndielectric leakage currents. New materials such as high- k\\ndielectrics may be required to continue scaling of theFigure 29\\nCross section of the deep-trench capacitor at an intermediate point \\nin the fabrication process of the cell.Thin-node insulator dielectricIsolation collar\\nLPCVD n/H11001 silicon fill p/H11002 substraten/H11001 buried platen-band wellp-well n-well\\n5–6   m~1   m/H9262\\n/H9262\\nFigure 30\\nProgression of deep-storage-trench process technology innovations enabling etching of higher-aspect-ratio (depth/width) trenches.4Mb/\\n0.816Mb/\\n0.564Mb/\\n0.35256Mb/\\n0.254Gb/\\n0.121Gb/\\n0.175\\nGeneration/ground rule  (  m)Trench aspect ratio204060\\n016Gb/\\n0.09Dipole-ring magnet\\n(DRM)RIESelective removal\\nof thick hard mask Dual-frequency\\nRIE Aspect ratio\\ncontrol\\nMagnetically\\nenhanced (ME)RIE\\nReactive-ion\\netch (RIE)\\n/H9262\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.205\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\neffective thickness of the node dielectric into the\\nsub-0.1- /H9262m regime.\\nAlthough the scalabili', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1094: (' aspect ratio204060\\n016Gb/\\n0.09Dipole-ring magnet\\n(DRM)RIESelective removal\\nof thick hard mask Dual-frequency\\nRIE Aspect ratio\\ncontrol\\nMagnetically\\nenhanced (ME)RIE\\nReactive-ion\\netch (RIE)\\n/H9262\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.205\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\neffective thickness of the node dielectric into the\\nsub-0.1- /H9262m regime.\\nAlthough the scalability of nitride/oxide capacitor\\ndielectrics is running into limitations, trench-capacitorcells have still been successful in advancing the technologyby employing area-enhancement techniques. One exampleof area enhancement is the “bottle-shaped trench ”[51, 52],\\nin which the area of the trench is enhanced with anisotropic etch below the surface, as shown in Figure 31 .\\nAn SEM cross section of trenches fabricated with thisprocess is shown in Figure 32 . Extrapolation of current\\nprocess capability suggests that conventional dielectrics(Si\\n3N4/SiO2or NO) will be suf ﬁcient to allow trench\\ncapacitors to be scaled to a feature size of 0.1 /H9262m.\\nCapacitance loss due to majority-carrier depletion\\nTo balance the electric ﬁeld in the capacitor dielectric\\nwhen a “1”or a “0”is stored, the buried-plate diffusion\\nis customarily maintained at a constant voltage which ismidway between the high and low levels stored on thecapacitor; some of the reasons for seeking a balancedelectric ﬁeld are to maximize the reliability of the\\ndielectric and to minimize its leakage current. Therefore,\\nwhen a “0”is stored on the capacitor, the potential of\\nthe n\\n/H11001polysilicon ﬁll is negative with respect to the n/H11001\\nburied-plate diffusion, resulting in depletion of majoritycarriers from the surface of the buried-plate diffusion. Asstorage-node dielectrics are thinned, higher buried-platedoping is needed to reduce relative capacitance lossFigure 31\\nArea-enhancement techniques, such as the bottle-shaped capacitor, \\nare effective in pushin', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1095: ('e\\ndielectric and to minimize its leakage current. Therefore,\\nwhen a “0”is stored on the capacitor, the potential of\\nthe n\\n/H11001polysilicon ﬁll is negative with respect to the n/H11001\\nburied-plate diffusion, resulting in depletion of majoritycarriers from the surface of the buried-plate diffusion. Asstorage-node dielectrics are thinned, higher buried-platedoping is needed to reduce relative capacitance lossFigure 31\\nArea-enhancement techniques, such as the bottle-shaped capacitor, \\nare effective in pushing trench storage technology to 0.100-   m minimum feature size: (a) Resist recess for SiN barrier definition in lower portion of trench; (b) LOCOS sidewall oxidation (isolation collar) after barrier etch and resist strip; (c) bottle enlargement using isotropic Si etching; (d) buried-plate formation self-aligned to the collar, node dielectric formation. Adapted with permission from [52]; © 1999 IEEE.(a) (b) (c) (d)Pad\\nSi\\n/H9262\\nFigure 32\\nSEM cross section showing enlargement of the lower portion of the storage trench by use of an isotropic etch. Reprinted with permission from [52]; © 1999 IEEE.Figure 33\\nPercentage of capacitance loss due to depletion of majority carriers from either the surface of the buried-plate diffusion (for a stored “0”) or the polysilicon in the trench (for a stored “1”). As the capa-\\ncitor dielectric is thinned, the doping concentration must be in-creased to avoid excessive loss of capacitance. A storage node swing from 0.0 to 1.5 V with a plate voltage of 0.75 V is assumed.25\\n201510\\n5\\n0Capacitance loss  (%)\\n1 2 3 4 5 6\\nElectrode doping  (1019 cm/H110023)50 ÅNode dielectric thickness\\nequivalent SiO2 /H11005 35 Å\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002206\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ndue to the majority-carrier depletion layer. A similar\\ncapacitance loss occurs due to the depletion region inthe polysilicon ﬁll of the trench capacitor when a high\\nl', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1096: ('0Capacitance loss  (%)\\n1 2 3 4 5 6\\nElectrode doping  (1019 cm/H110023)50 ÅNode dielectric thickness\\nequivalent SiO2 /H11005 35 Å\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002206\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\ndue to the majority-carrier depletion layer. A similar\\ncapacitance loss occurs due to the depletion region inthe polysilicon ﬁll of the trench capacitor when a high\\nlevel is stored. Figure 33 illustrates the sensitivity of the\\ncapacitance loss to electrode (either buried-plate diffusionor polysilicon ﬁll) doping concentration. The introduction of\\nburied-plate dopant into the sidewall of the deep trenchhas required additional innovation in process technology.\\nDeposition and removal of a solid doping source [53](such as arsenic-doped glass) for the buried-plate diffusionon the lower portion of the deep trench are increasinglydifﬁcult as ground rules shrink and as trench aspect ratio\\nincreases. Gas-phase doping and plasma doping [54, 55]have been proposed to solve these problems. Regardingthe effect of doping concentration in the n\\n/H11001polysilicon\\nﬁll, besides capacitance loss due to depletion effects,\\ndoping limitations in the trench polysilicon pose seriesresistance concerns as the minimum feature size is scaleddown. Therefore, as dimensions are scaled, higher dopingconcentration is sought in both the buried-plate diffusionand the polysilicon trench ﬁll.\\nSeries-resistance considerations\\nThe series resistance of the polysilicon ﬁll of the trench\\ncapacitor is another factor that can potentially limit\\ncontinued scaling. The cross-sectional area of the trench\\ndiminishes approximately as the square of the minimumfeature size. On the other hand, the trench depth remainsapproximately constant, or increases, from generation togeneration. This causes the resistance to increase sharply.The storage-trench capacitor can be considered to be atransmission line consisting of resistance ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1097: ('ce considerations\\nThe series resistance of the polysilicon ﬁll of the trench\\ncapacitor is another factor that can potentially limit\\ncontinued scaling. The cross-sectional area of the trench\\ndiminishes approximately as the square of the minimumfeature size. On the other hand, the trench depth remainsapproximately constant, or increases, from generation togeneration. This causes the resistance to increase sharply.The storage-trench capacitor can be considered to be atransmission line consisting of resistance and capacitancedistributed along its depth. Figure 34 shows a simpli ﬁed\\nequivalent circuit from the bitline contact through thevarious contributors to series resistance and into thestorage capacitor. The channel of the MOSFET, theburied strap, and the trench top region (narrowedpolysilicon ﬁll adjacent to the isolation collar, as shown\\nin Figure 16) are represented by lumped resistances. Asillustrated in Figure 35 , during the writing of a high level\\n(i.e., “1”) to the storage capacitor, the charge distribution\\non the capacitor is a function of depth in the trench.Once the access transistor is shut off, the charge on thecapacitor equilibrates, and the stored voltage is lower thanthe high level of the bitline. In the representative caseshown for a trench capacitor having a circular opening of0.09\\n/H9262m diameter and a series resistance of 86 k /H9024, the\\nvoltage stored on the capacitor in a 10-ns write window isabout 350 mV less than the 1.5-V bitline-high level. ThisFigure 34\\nSimplified equivalent circuit for the trench storage capacitor and \\nresistance components of cell. Three sections of the RC (resis-\\ntance –capacitance) transmission-line representation of the trench \\nstorage capacitor are shown.Trench\\ncapacitorTrench top\\nCollar bottomCbitlineRchannel\\nRtrench topRstrap\\nBLFigure 35\\nSimulation of representative waveforms of a write “1” operation \\nfor a polysilicon-filled storage trench with a circular cross section \\nhaving a diameter of 0.090   m. Storage-trench, strap, and trench top resistances are 86 k ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1098: ('for the trench storage capacitor and \\nresistance components of cell. Three sections of the RC (resis-\\ntance –capacitance) transmission-line representation of the trench \\nstorage capacitor are shown.Trench\\ncapacitorTrench top\\nCollar bottomCbitlineRchannel\\nRtrench topRstrap\\nBLFigure 35\\nSimulation of representative waveforms of a write “1” operation \\nfor a polysilicon-filled storage trench with a circular cross section \\nhaving a diameter of 0.090   m. Storage-trench, strap, and trench top resistances are 86 k /H9024, 20 k /H9024, and 20 k /H9024, respectively. Storage-\\ntrench and bitline capacitances are 33 fF and 200 fF, respectively. Of importance is the voltage on the capacitor, which is a function of depth in the trench during the charging process. The charge in the trench equilibrates such that the stored voltage is about 350 mV lower than the bitline-high voltage when the array MOSFET is shut off./H92623\\n210\\n/H110021\\n0 10 20\\nTime  (ns)Node diffusion\\nCollar bottom\\nTrench bottomV\\nwordline\\nVbitlineV oltage  (V)\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.207\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nmeans that there is less charge available to be transferred\\nbetween the capacitor and the bitline for a read operation.As shown in Figure 36 , during the read operation the\\nvoltage on the capacitor is also a function of the depthin the trench. For read times less than 10 ns, the lowerportion of the capacitor contributes less to the transferredcharge than the upper portion, reducing the effectivestorage capacitance. In the case shown, only 56 mV of\\nsignal, V\\nsignal, is induced on the bitline after 10 ns. For\\nthis n/H11001polysilicon trench ﬁll, at ground rules smaller\\nthan about 0.100 /H9262m, the effect of storage-trench series\\nresistance is quite pronounced. Novel reduced-resistivitymaterials will be required to extend trench capacitors tosmaller ground rules.\\nConclusions\\nMajor challenges fac', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1099: (' of the capacitor contributes less to the transferredcharge than the upper portion, reducing the effectivestorage capacitance. In the case shown, only 56 mV of\\nsignal, V\\nsignal, is induced on the bitline after 10 ns. For\\nthis n/H11001polysilicon trench ﬁll, at ground rules smaller\\nthan about 0.100 /H9262m, the effect of storage-trench series\\nresistance is quite pronounced. Novel reduced-resistivitymaterials will be required to extend trench capacitors tosmaller ground rules.\\nConclusions\\nMajor challenges facing DRAM scaling to the 0.1- /H9262m\\ngeneration and beyond have been reviewed. ContinuedDRAM cost-per-bit productivity depends on reducing thecell size more rapidly than scaling minimum feature sizealone would allow. Thus, cell layouts which are morecompact than 8 F\\n2are required, along with successful\\nscaling of the chip area occupied by both the cell-accesstransistor and the storage capacitor. A crossroads on thepath to continued DRAM scaling has been reached, sincemultiple solutions exist for these challenges. Although thebest choice for continued cost-per-bit productivity is notyet clear, the most promising options have been identi ﬁed\\nand discussed.Possible options for reducing the area occupied by the\\naccess transistor include aggressive voltage scaling for\\nplanar MOSFETs or a paradigm shift to vertical-channelMOSFETs. Each of these approaches presents signi ﬁcant\\nchallenges, such as very severe channel doping pro ﬁle\\nrequirements for voltage-scaled planar MOSFETs, andovercoming cell-to-cell interactions that occur for certainvertical cell layouts. It appears that adoption of verticalMOSFETs in DRAM cells may provide longer-termscalability. However, the economics of manufacturabilitywill ultimately determine the actual limits of scalability.\\nRegarding choice of storage capacitor, trench-storage\\nDRAM cells promise much easier integration of verticalMOSFETs than do stacked-capacitor cells. Furthermore,a clear scaling path exists down to 0.10\\n/H9262m for trench\\ncapacitors, through the use of capacitance-enha', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1100: ('s that occur for certainvertical cell layouts. It appears that adoption of verticalMOSFETs in DRAM cells may provide longer-termscalability. However, the economics of manufacturabilitywill ultimately determine the actual limits of scalability.\\nRegarding choice of storage capacitor, trench-storage\\nDRAM cells promise much easier integration of verticalMOSFETs than do stacked-capacitor cells. Furthermore,a clear scaling path exists down to 0.10\\n/H9262m for trench\\ncapacitors, through the use of capacitance-enhancingtechniques such as the bottle-shaped trench. Scalingbeyond 0.10\\n/H9262m will require insulators with higher\\ndielectric capacitance and/or trench- ﬁll materials with\\nlower resistance. On the other hand, the scaling path forstacked-capacitor cells is less certain because of a numberof dif ﬁcult challenges which appear earlier than for the\\ntrench capacitor. To obtain suf ﬁcient capacitance per cell\\nfor the stacked capacitor, geometric constraints imposedby mechanical stability and topographic considerations willforce new materials to be introduced into manufacturing —\\nﬁrst Ta\\n2O5, by the 0.12- /H9262m generation, and then BSTO.\\nAlso, the need to contain the thermal budget seen byhigh-performance CMOS logic integrated with DRAMfavors the use of trench-capacitor storage.\\nFinally, as cells are made more compact than 8 F\\n2, the\\nlimit of the folded-bitline architecture, vertically twistedtwo-layer bitline wiring may have to be used to obtain therequired noise immunity. The introduction of 6 F\\n2and\\nsmaller cells favors trench-capacitor technology becauseof problems with integrating an additional level ofbitline metal over stacked-capacitor cell topography.\\nAcknowledgments\\nThe authors thank the members of the IBM –Inﬁneon\\nDRAM development team, as well as colleagues in theIBM Research Division, for valuable contributions to thedevelopment of the technology presented in this paper.\\nReferences\\n1. R. H. Dennard, “Field-Effect Transistor Memory, ”\\nU.S. Patent 3,387,286, 1968.\\n2. E. Adler, J. K. DeBrosse, S. F. Geissler,', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1101: ('favors trench-capacitor technology becauseof problems with integrating an additional level ofbitline metal over stacked-capacitor cell topography.\\nAcknowledgments\\nThe authors thank the members of the IBM –Inﬁneon\\nDRAM development team, as well as colleagues in theIBM Research Division, for valuable contributions to thedevelopment of the technology presented in this paper.\\nReferences\\n1. R. H. Dennard, “Field-Effect Transistor Memory, ”\\nU.S. Patent 3,387,286, 1968.\\n2. E. Adler, J. K. DeBrosse, S. F. Geissler, S. J. Holmes,\\nM. D. Jaffe, J. B. Johnson, C. W. Koburger III, J. B.\\nLasky, B. Lloyd, G. L. Miles, J. S. Nakos, W. P. Noble,Jr., S. H. Voldman, M. Armacost, and R. Ferguson, “The\\nEvolution of IBM CMOS DRAM Technology, ”IBM J.\\nRes. & Dev. 39,167–188 (1995).\\n3. K. Kim, C.-G. Hwang, and J. Lee, “DRAM Technology\\nPerspective for Gigabit Era, ”IEEE Trans. Electron\\nDevices 45,598–608 (1998).Figure 36\\nSimulation of representative waveforms of a read “1” operation, \\ncorresponding to the data written in Figure 35. For this polysilicon-\\nfilled trench-storage capacitor having a diameter of 0.90   m, a 56-mV change is induced on the bitline from the 0.75-V bitline pre-charge level after 10 ns. /H92621.5\\n1.0\\n0.5\\n00 10 20\\nTime  (ns)Node diffusionCollar bottomTrench bottom\\nV\\nwordlineVbitlineV oltage  (V)\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002208\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\n4. R. H. Dennard, F. H. Gaensslen, H. N. Yu, V. L.\\nRideout, E. Bassous, and A. R. LeBlanc, “Design of\\nIon-Implanted MOSFET ’s with Very Small Physical\\nDimensions, ”IEEE J. Solid-State Circuits SC-9, 256–268\\n(1974).\\n5. W. Noble and W. Walker, “Fundamental Limitations on\\nDRAM Storage Capacitors, ”IEEE Circuits & Devices\\nMagazine 1,45–51 (1985).\\n6. B. Davari, C. W. Koburger, R. Schulz, J. D. Warnock,\\nT. Furukawa, M. Jost, Y. Taur, W. G. Schwittek, J. K.\\nDeBrosse, M. L. Kerbaugh, and J. L. Mauer, “A New\\nPlanarization ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1102: ('. Dennard, F. H. Gaensslen, H. N. Yu, V. L.\\nRideout, E. Bassous, and A. R. LeBlanc, “Design of\\nIon-Implanted MOSFET ’s with Very Small Physical\\nDimensions, ”IEEE J. Solid-State Circuits SC-9, 256–268\\n(1974).\\n5. W. Noble and W. Walker, “Fundamental Limitations on\\nDRAM Storage Capacitors, ”IEEE Circuits & Devices\\nMagazine 1,45–51 (1985).\\n6. B. Davari, C. W. Koburger, R. Schulz, J. D. Warnock,\\nT. Furukawa, M. Jost, Y. Taur, W. G. Schwittek, J. K.\\nDeBrosse, M. L. Kerbaugh, and J. L. Mauer, “A New\\nPlanarization Technique, Using a Combination of RIEand Chemical Mechanical Polish (CMP), ”IEDM Tech.\\nDigest , p. 861 (1989).\\n7. D. Kenney, P. Parries, P. Pan, W. Tonti, W. Cote, S.\\nDash, P. Lorenz, W. Arden, R. Mohler, S. Roehl, A.Bryant, W. Haensch, B. Hoffman, M. Levy, A. J. Yu,and C. Zeller, “A Buried-Plate Trench Cell for 64-Mb\\nDRAM, ”IEEE Symposium on VLSI Technology, Digest\\nof Technical Papers , 1992, pp. 14, 15.\\n8. L. Nesbit, J. Alsmeier, B. Chen, J. DeBrosse, P. Fahey,\\nM. Gall, J. Gambino, S. Gernhardt, H. Ishiuchi, R.Kleinhenz, J. Mandelman, T. Mii, M. Morikado, A.Nitayama, S. Parke, H. Wong, and G. Bronner, “A\\n0.6\\n/H9262m2256Mb DRAM Cell with Self-Aligned BuriEd\\nStrap (BEST), ”IEDM Tech. Digest , pp. 627 –630 (1993).\\n9. R. H. Dennard, “Scaling Challenges for DRAM and\\nMicroprocessors in the 21st Century, ”Electrochemical\\nSociety Proceedings, Vol. 97-3, 1997, pp. 519 –532.\\n10. D. J. Frank, R. H. Dennard, E. Nowak, P. M. Solomon,\\nY. Taur, and H.-S. P. Wong, “Device Scaling Limits of Si\\nMOSFETs and Their Application Dependencies, ”Proc.\\nIEEE 89,259–288 (2001).\\n11. A. Hiraiwa, M. Ogasawara, N. Natsuaki, Y. Itoh, and\\nH. Iwai, “Local-Field-Enhancement Model of DRAM\\nRetention Failure, ”IEDM Tech. Digest , pp. 157 –160\\n(1998).\\n12. T. Hamamoto, S. Sugiura, and S. Sawada, “On the\\nRetention Time Distribution of Dynamic Random Access\\nMemory (DRAM), ”IEEE Trans. Electron Devices 45,1300\\n(1998).\\n13. K. Yamaguchi, “Theoretical Study of Deep-Trap-Assisted\\nAnomalous Currents in Worst-Bit Cells of DynamicRandom-Access Memories (DRAM ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1103: ('Dependencies, ”Proc.\\nIEEE 89,259–288 (2001).\\n11. A. Hiraiwa, M. Ogasawara, N. Natsuaki, Y. Itoh, and\\nH. Iwai, “Local-Field-Enhancement Model of DRAM\\nRetention Failure, ”IEDM Tech. Digest , pp. 157 –160\\n(1998).\\n12. T. Hamamoto, S. Sugiura, and S. Sawada, “On the\\nRetention Time Distribution of Dynamic Random Access\\nMemory (DRAM), ”IEEE Trans. Electron Devices 45,1300\\n(1998).\\n13. K. Yamaguchi, “Theoretical Study of Deep-Trap-Assisted\\nAnomalous Currents in Worst-Bit Cells of DynamicRandom-Access Memories (DRAM ’s),”IEEE Trans.\\nElectron Devices 47,774 (2000).\\n14. H. Sunami, T. Kure, N. Hashimoto, K. Itoh, T. Toyabe,\\nand S. Asai, “A Corrugated Capacitor Cell (CCC) for\\nMegabit Dynamic MOS Memories, ”IEDM Tech. Digest ,\\npp. 806 –808 (1982).\\n15. S. Wolf, Silicon Processing for the VLSI Era—Volume 2:\\nProcess Integration , Lattice Press, Sunset Beach, CA, 1990,\\npp. 600 –615.\\n16. H. Kang, K. Kim, Y. Shin, I. Park, K. Ko, C. Kim, K. Oh,\\nS. Kim, C. Hong, K. Kwon, J. Yoo, Y. Kim, C. Lee, W.Paick, D. Suh, C. Park, S. Lee, S. Ahn, C. Hwang, andM. Lee, “Highly Manufacturable Process Technology for\\nReliable 256 Mbit and 1 Gbit DRAMs, ”IEDM Tech.\\nDigest , pp. 635 –638 (1994).\\n17. G. Bronner, H. Aochi, M. Gall, J. Gambino, S.\\nGernhardt, E. Hammerl, H. Ho, J. Iba, H. Ishiuchi,M. Jaso, R. Kleinhenz, T. Mii, M. Narita, L. Nesbit, W.Neumueller, A. Nitayama, T. Ohiwa, S. Parke, J. Ryan, T.Sato, H. Takato, and S. Yoshikawa, “A Fully Planarized\\n0.25\\n/H9262m CMOS Technology for 256Mbit DRAM and\\nBeyond, ”IEEE Symposium on VLSI Technology, Digest\\nof Technical Papers , 1995, pp. 15, 16.\\n18. S. Crowder, S. Stif ﬂer, P. Parries, G. Bronner, L. Nesbit,\\nW. Wille, M. Powell, A. Ray, B. Chen, and B. Davari,“Trade-Offs in the Integration of High-Performance\\nDevices with Trench Capacitor DRAM, ”IEDM Tech.\\nDigest , pp. 45 –48 (1997).19. S. Crowder, R. Hannon, H. Ho, D. Sinitsky, S. Wu,\\nK. Winstel, B. Khan, S. R. Stif ﬂer, and S. S. Iyer,\\n“Integration of Trench DRAM into a High-Performance\\n0.18\\n/H9262m Logic Technology with Copper BEOL, ”IEDM\\nTech. Diges', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1104: ('igest\\nof Technical Papers , 1995, pp. 15, 16.\\n18. S. Crowder, S. Stif ﬂer, P. Parries, G. Bronner, L. Nesbit,\\nW. Wille, M. Powell, A. Ray, B. Chen, and B. Davari,“Trade-Offs in the Integration of High-Performance\\nDevices with Trench Capacitor DRAM, ”IEDM Tech.\\nDigest , pp. 45 –48 (1997).19. S. Crowder, R. Hannon, H. Ho, D. Sinitsky, S. Wu,\\nK. Winstel, B. Khan, S. R. Stif ﬂer, and S. S. Iyer,\\n“Integration of Trench DRAM into a High-Performance\\n0.18\\n/H9262m Logic Technology with Copper BEOL, ”IEDM\\nTech. Digest , pp. 1017 –1020 (1998).\\n20. H. Takato, H. Koike, T. Yoshida, and H. Ishiuchi,\\n“Embedded DRAM Technology: Past, Present and\\nFuture, ”Proceedings of the International Symposium on\\nVLSI Technology, Systems, and Applications , 1999, pp.\\n239–242.\\n21. S. S. Iyer and H. L. Kalter, “Embedded DRAM\\nTechnology: Opportunities and Challenges, ”IEEE\\nSpectrum 36,56–64 (1999).\\n22. O. Takahashi, S. Dong, M. Ohkubo, S. Onishi, R.\\nDennard, R. Hannon, S. Crowder, S. Iyer, M. Wordeman,\\nB. Davari, W. Weinberger, and N. Aoki, “1-MHz Fully\\nPipelined 3.7ns Address Access Time 8k /H110031024 Embedded\\nSynchronous DRAM Macro, ”IEEE J. Solid-State Circuits\\n35,1673 –1679 (2000).\\n23. R.-P. Vollertsen and W. W. Abadeer, “Comprehensive\\nGate-Oxide Reliability Evaluation for DRAM Processes, ”\\nMicroelectron. Reliabil. 36,1631 –1638 (1996).\\n24. Semiconductor Industry Association (SIA), National\\nTechnology Roadmap for Semiconductors , 2000; see http://\\nwww.sematech.org/public/publications/index.htm.\\n25. K. Itoh, Y. Nakagome, S. Kimura, and T. Watanabe,\\n“Limitations and Challenges of Multigigabit DRAM\\nChip Design, ”IEEE J. Solid-State Circuits 32,624–634\\n(1997).\\n26. T. Yamagata, S. Tomishima, M. Tsukude, Y. Hashizume,\\nand K. Arimoto, “Circuit Design Techniques for Low-\\nVoltage Operating and/or Giga-Scale DRAMs, ”\\nInternational Solid State Circuits Conference Digestof Technical Papers , 1995, pp. 248 –249, 374.\\n27. T. Y. Chan, J. Chen, P. K. Ko, and C. Hu, “The Impact\\nof Gate-Induced Drain Leakage Current on MOSFETScaling, ”IEDM Tech. Digest , p. ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1105: ('Watanabe,\\n“Limitations and Challenges of Multigigabit DRAM\\nChip Design, ”IEEE J. Solid-State Circuits 32,624–634\\n(1997).\\n26. T. Yamagata, S. Tomishima, M. Tsukude, Y. Hashizume,\\nand K. Arimoto, “Circuit Design Techniques for Low-\\nVoltage Operating and/or Giga-Scale DRAMs, ”\\nInternational Solid State Circuits Conference Digestof Technical Papers , 1995, pp. 248 –249, 374.\\n27. T. Y. Chan, J. Chen, P. K. Ko, and C. Hu, “The Impact\\nof Gate-Induced Drain Leakage Current on MOSFETScaling, ”IEDM Tech. Digest , p. 719 (1987).\\n28. Y. Li, J. Mandelman, P. Parries, Y. Matsubara, Q. Ye,\\nR. Rengarajan, J. Alsmeier, B. Flietner, D. Wheeler,\\nH. Akatsu, R. Divakaruni, R. Mohler, K. Sunouchi, G.Bronner, and T. C. Chen, “Array Pass Transistor Design\\nin Trench Cell for Gbit DRAM and Beyond, ”Proceedings\\nof the International Symposium on VLSI Technology,Systems, and Applications , 1999, pp. 251 –254.\\n29. TMA TSUPREM-4, Version 6.5, 1997, Technology\\nModeling Associates, Inc. (acquired in January 1998 byAvant! Corporation).\\n30. E. Buturla, J. Johnson, S. Furkay, and P. Cottrell, “A New\\nThree-Dimensional Device Simulation Formulation, ”\\nNASCODE VI: Proceedings of the Sixth InternationalConference on Numerical Analysis of SemiconductorDevices and Integrated Circuits , J. J. H. Miller, Ed.,\\nBoole Press Ltd., Dublin, 1989, p. 291.\\n31. W. Noble, S. Voldman, and A. Bryant, “The Effects of\\nGate Field on the Leakage Characteristics of HeavilyDoped Junctions, ”IEEE Trans. Electron Devices 36,\\n720–726 (1989).\\n32. G. Bronner, T. Furukawa, M. Hakey, S. Holmes, D.\\nHorak, J. Mandelman, and P. Rabidoux, “Method for\\nMaking a DRAM Cell with Grooved Transfer Device, ”\\nU.S. Patent 6,037,194, 2000.\\n33. D. Horak, T. Furukawa, S. Holmes, M. Hakey, W. Ma,\\nand J. Mandelman, “Methods of Making a Trench\\nStorage DRAM Cell Including a Step Transfer Device, ”\\nU.S. Patent 6,063,658, 2000.\\n34. T. Furukawa, D. Horak, S. Holmes, M. Hakey, and\\nJ. Mandelman, “DRAM Cell with Three-Sided-Gate\\nTransfer Device, ”U.S. Patent 6,121,651, 2000.\\n35. H.-S. Wong, K. Chan, and Y. ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1106: ('akey, S. Holmes, D.\\nHorak, J. Mandelman, and P. Rabidoux, “Method for\\nMaking a DRAM Cell with Grooved Transfer Device, ”\\nU.S. Patent 6,037,194, 2000.\\n33. D. Horak, T. Furukawa, S. Holmes, M. Hakey, W. Ma,\\nand J. Mandelman, “Methods of Making a Trench\\nStorage DRAM Cell Including a Step Transfer Device, ”\\nU.S. Patent 6,063,658, 2000.\\n34. T. Furukawa, D. Horak, S. Holmes, M. Hakey, and\\nJ. Mandelman, “DRAM Cell with Three-Sided-Gate\\nTransfer Device, ”U.S. Patent 6,121,651, 2000.\\n35. H.-S. Wong, K. Chan, and Y. Taur, “Self-Aligned (Top\\nand Bottom) Double-Gate MOSFET with a 25nm ThickSilicon Channel, ”IEDM Tech. Digest , pp. 427 –430 (1997).\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.209\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\n36. J. A. Mandelman, J. E. Barth, J. K. DeBrosse, R. H.\\nDennard, H. L. Kalter, J. Gautier, and H. I. Hana ﬁ,\\n“Floating-Body Concerns for SOI Dynamic Random\\nAccess Memory (DRAM), ”Proceedings of the IEEE\\nInternational SOI Conference , September 1996, pp.\\n136–137.\\n37. W. F. Richardson, D. M. Bordelon, G. P. Pollack, A. H.\\nShah, S. D. S. Malhi, H. Shichijo, S. K. Banerjee, M.\\nElahy, R. H. Womack, C.-P. Wang, J. Gallia, H. E. Davis,and P. K. Chatterjee, “A Trench Transistor Cross-Point\\nDRAM Cell, ”IEDM Tech. Digest , pp. 714 –717 (1985).\\n38. U. Gruening, C. J. Radens, J. A. Mandelman, A.\\nMichaelis, M. Seitz, N. Arnold, D. Lea, D. Casarotto, A.Knorr, S. Halle, T. H. Ivers, L. Economikos, S. Kudelka,S. Rahn, H. Tews, H. Lee, R. Divakaruni, J. J. Welser,T. Furukawa, T. S. Kanarsky, J. Alsmeier, and G. B.Bronner, “A Novel Trench DRAM Cell with a Vertical\\nAccess Transistor and Buried Strap (VERI BEST) for4Gb/16Gb, ”IEDM Tech. Digest , pp. 25 –29 (1999).\\n39. K. Itoh, “Trends in Megabit DRAM Circuit Design, ”\\nIEEE J. Solid-State Circuits 25,778–789 (1990).\\n40. Y. Taur and T. H. Ning, Fundamentals of Modern VLSI\\nDevices , Cambridge University Press, Cambridge, UK,\\n1998.\\n41. C. Rad', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1107: (', L. Economikos, S. Kudelka,S. Rahn, H. Tews, H. Lee, R. Divakaruni, J. J. Welser,T. Furukawa, T. S. Kanarsky, J. Alsmeier, and G. B.Bronner, “A Novel Trench DRAM Cell with a Vertical\\nAccess Transistor and Buried Strap (VERI BEST) for4Gb/16Gb, ”IEDM Tech. Digest , pp. 25 –29 (1999).\\n39. K. Itoh, “Trends in Megabit DRAM Circuit Design, ”\\nIEEE J. Solid-State Circuits 25,778–789 (1990).\\n40. Y. Taur and T. H. Ning, Fundamentals of Modern VLSI\\nDevices , Cambridge University Press, Cambridge, UK,\\n1998.\\n41. C. Radens, U. Gruening, J. Mandelman, M. Seitz, T.\\nDyer, D. Lea, D. Casarotto, L. Clevenger, L. Nesbit,R. Malik, S. Halle, S. Kudelka, H. Tews, R. Divakaruni,J. Sim, A. Strong, D. Tibbel, N. Arnold, S. Bukofsky,J. Preuninger, G. Kunkel, and G. Bronner, “A 0.135\\n/H9262m2\\n6F2Trench-Sidewall Vertical Device Cell for 4Gb/16Gb\\nDRAM, ”IEEE 2000 Symposium on VLSI Technology,\\nDigest of Technical Papers , 2000, pp. 80 –81.\\n42. D. Takashima, S. Watanabe, H. Nakano, Y. Oowaki, and\\nK. Ohuchi, “Open/Folded Bit-Line Arrangement for\\nUltra-High-Density DRAM ’s,”IEEE J. Solid-State Circuits\\n29,539–542 (1994).\\n43. T. Hamada, N. Tanabe, H. Watanabe, K. Takeuchi, N.\\nKasai, H. Hada, K. Shibahara, K. Tokashiki, K. Nakajima,S. Hirasawa, E. Ikawa, T. Saeki, E. Kakehashi, S. Ohya,\\nand T. Kunio, “A Split-Level Diagonal Bit-Line (SLDB)\\nStacked Capacitor Cell for 256Mb DRAMs, ”IEDM Tech.\\nDigest , pp. 799 –802 (1992).\\n44. H. Hidaka, Y. Matsuda, and K. Fujishima, “A\\nDivided/Shared Bit-Line Sensing Scheme for ULSIDRAM Cores, ”IEEE J. Solid-State Circuits 26,473–478\\n(1991).\\n45. T. Kirihata, G. Mueller, M. Clinton, S. Loef ﬂer, B. Ji,\\nH. Terletzki, D. Hanson, C. Hwang, G. Lehmann, D.Storaska, G. Daniel, L. Hsu, O. Weinfurtner, T. Boehler,J. Schnell, G. Frankowsky, D. Netis, J. Ross, A. Reith,O. Kiehl, and M. Wordeman, “A 113\\n/H9262m2600Mb/s/pin\\n512Mb DDR2 SDRAM with Vertically-Folded BitlineArchitecture, ”International Solid State Circuits Conference,\\nDigest of Technical Papers , 2001, pp. 382 –383, 468.\\n46. H. Hoenigschmid, A. Frey, J. DeBrosse, T.', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1108: (' Circuits 26,473–478\\n(1991).\\n45. T. Kirihata, G. Mueller, M. Clinton, S. Loef ﬂer, B. Ji,\\nH. Terletzki, D. Hanson, C. Hwang, G. Lehmann, D.Storaska, G. Daniel, L. Hsu, O. Weinfurtner, T. Boehler,J. Schnell, G. Frankowsky, D. Netis, J. Ross, A. Reith,O. Kiehl, and M. Wordeman, “A 113\\n/H9262m2600Mb/s/pin\\n512Mb DDR2 SDRAM with Vertically-Folded BitlineArchitecture, ”International Solid State Circuits Conference,\\nDigest of Technical Papers , 2001, pp. 382 –383, 468.\\n46. H. Hoenigschmid, A. Frey, J. DeBrosse, T. Kirihata,\\nG. Mueller, D. Storaska, G. Daniel, G. Frankowsky,K. Guay, D. Hanson, L. Hsu, B. Ji, D. Netis, S. Pararoni,C. Radens, A. Reith, H. Terletzki, O. Weinfurtner, J.Alsmeier, W. Weber, and M. Wordeman, “A7 F\\n2Cell and\\nBitline Architecture Featuring Tilted Array Devices andPenalty-Free Vertical BL Twists for 4-Gb DRAM ’s,”\\nIEEE J. Solid-State Circuits 35,713–718 (2000).\\n47. C. Radens, U. Gruening, M. Weybright, J. DeBrosse, R.\\nKleinhenz, H. Hoenigschmid, A. Thomas, J. Mandelman,J. Alsmeier, and G. Bronner, “A 0.21\\n/H9262m27F2Trench Cell\\nwith a Locally-Open Globally-Folded Dual Bitline for1Gb/4Gb DRAM, ”IEEE Symposium on VLSI Technology,\\nDigest of Technical Papers , 1998, pp. 36 –37.\\n48. H. Nakano, D. Takashima, K. Tsuchida, S. Shiratake, T.\\nInaba, M. Ohta, Y. Oowaki, S. Watanabe, K. Ohuchi, andJ. Matsunaga, “A Dual Layer Bitline DRAM Array withVcc/Vss Hybrid Precharge for Multi-Gigabit DRAMs, ”\\nIEEE Symposium on VLSI Circuits, Digest of Technical\\nPapers , 1996, pp. 190 –191.\\n49. H. Hidaka, K. Fujishima, Y. Matsuda, M. Asakura, and\\nT. Yoshihara, “Twisted Bit-Line Architectures for Multi-\\nMegabit DRAM ’s,”IEEE J. Solid-State Circuits 24,21–27\\n(1989).\\n50. E. Wu, C. Hwang, R. Vollertsen, H. Shen, R. Kleinhenz,\\nC. Radens, and A. Strong, “Thickness and Polarity\\nDependence of Intrinsic Breakdown of Ultra-ThinReoxidized Nitride for DRAM Technology Applications, ”\\nIEDM Tech. Digest , pp. 77 –80 (1997).\\n51. M. Schrems, J. Mandelman, J. Hoepfner, H. Schaefer,\\nand R. Stengl, “Bottle-Shaped Trench Capacitor with\\nEpi Bu', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1109: ('Y. Matsuda, M. Asakura, and\\nT. Yoshihara, “Twisted Bit-Line Architectures for Multi-\\nMegabit DRAM ’s,”IEEE J. Solid-State Circuits 24,21–27\\n(1989).\\n50. E. Wu, C. Hwang, R. Vollertsen, H. Shen, R. Kleinhenz,\\nC. Radens, and A. Strong, “Thickness and Polarity\\nDependence of Intrinsic Breakdown of Ultra-ThinReoxidized Nitride for DRAM Technology Applications, ”\\nIEDM Tech. Digest , pp. 77 –80 (1997).\\n51. M. Schrems, J. Mandelman, J. Hoepfner, H. Schaefer,\\nand R. Stengl, “Bottle-Shaped Trench Capacitor with\\nEpi Buried Layer, ”U.S. Patent 6,018,174, 2000.\\n52. T. Rupp, N. Chaudary, K. Dev, Y. Fukuzaki, J. Gambino,\\nH. Ho, J. Iba, E. Ito, E. Kiewra, B. Kim, M. Maldei,T. Matsunaga, J. Ning, R. Rengarajan, A. Sudo, Y.Takegawa, D. Tobben, M. Weybright, G. Worth, R.Divakaruni, R. Srinivasan, J. Alsmeier, and G. Bronner,“Extending Trench DRAM Technology to 0.15\\n/H9262m\\nGroundrule and Beyond, ”IEDM Tech. Digest , pp. 33 –36\\n(1999).\\n53. L. Economikos, C. Murthy, and R. Young, “Study of\\nArsenic Out-Diffusion for Buried Plate Formation inTrench Capacitors, ”Proceedings of the IEEE/CPMT\\nInternational Electronics Manufacturing TechnologySymposium , 1998, pp. 423 –432.\\n54. S. Saida, T. Sato, I. Mizushima, Y. Ozawa, and Y.\\nTsunashima, “Single Layer Nitride Capacitor Dielectric\\nFilm and High Concentration Doping Technology for1Gb/4Gb Trench-Type DRAMs, ”IEDM Tech. Digest , pp.\\n265–268 (1997).\\n55. K. Lee, B. Lee, J. Hoepfner, L. Economikos, C. Parks,\\nC. Radens, J. Bernstein, and P. Kellerman, “Plasma\\nImmersion Ion Implantation as an Alternative DeepTrench Buried-Plate Doping Technology, ”Proceedings of\\nthe Thirteenth International Conference on Ion ImplantationTechnology , 2000, pp. 460 –463.\\nReceived May 30, 2001; accepted for publication\\nOctober 9, 2001\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002210\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nJack A. Mandelman IBM Microelectronics Division, East\\nFishkill facility', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1110: ('ernative DeepTrench Buried-Plate Doping Technology, ”Proceedings of\\nthe Thirteenth International Conference on Ion ImplantationTechnology , 2000, pp. 460 –463.\\nReceived May 30, 2001; accepted for publication\\nOctober 9, 2001\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002210\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nJack A. Mandelman IBM Microelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533\\n(modelman@ieee.org). Dr. Mandelman received the B.E.E.\\nand M.E.E. degrees from the City College of New York in1969 and 1971, respectively, and the Ph.D.E.E. degree fromthe City University of New York in 1975. He subsequentlyjoined IBM in Burlington, Vermont, as a circuit designer in a32Kb DRAM program. Since then, Dr. Mandelman ’s primary\\nfocus has been on the application of simulation to devicedesign and process integration of advanced DRAM and logictechnologies. His contributions, which span more than eightgenerations of IBM MOS technology, involve the areas ofdevice reliability, SOI ﬂoating-body effects, parasitic leakage\\nmechanisms in trench isolation, and novel memory cell designs.In 1992 Dr. Mandelman joined the IBM/Siemens/Toshiba256Mb DRAM Development Alliance at the IBMSemiconductor Research and Development Center in\\nHopewell Junction, New York. Most recently, he has driventhe paradigm shift from planar to vertical MOSFET DRAM.He is currently a Senior Engineer and IBM ’s lead device\\ndesigner for advanced vertical-MOSFET DRAM technologyfor 1 Gb and beyond. Dr. Mandelman is one of IBM ’s most\\ndecorated inventors, holding more than 150 U.S. patentswith more than 100 pending. He has received numerousIBM valuable-patent awards for innovations in DRAM cellstructure, process integration, and SOI technology. At presenthe is a senior business counsel for Intellectual Property andchairs the IBM device and circuit invention review board. Dr.Mandelman is a Senior Membe', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1111: ('ineer and IBM ’s lead device\\ndesigner for advanced vertical-MOSFET DRAM technologyfor 1 Gb and beyond. Dr. Mandelman is one of IBM ’s most\\ndecorated inventors, holding more than 150 U.S. patentswith more than 100 pending. He has received numerousIBM valuable-patent awards for innovations in DRAM cellstructure, process integration, and SOI technology. At presenthe is a senior business counsel for Intellectual Property andchairs the IBM device and circuit invention review board. Dr.Mandelman is a Senior Member of the IEEE.\\nRobert H. Dennard IBM Research Division, Thomas J.\\nWatson Research Center, P.O. Box 218, Yorktown Heights, NewYork 10598 (dennard@us.ibm.com). Dr. Dennard is an IBM\\nFellow at the IBM Thomas J. Watson Research Center,Yorktown Heights, New York. He received B.S. and M.S.degrees in electrical engineering from Southern MethodistUniversity in 1954 and 1956 and the Ph.D. degree fromCarnegie Institute of Technology in 1958. He subsequentlyjoined the IBM Research Division, where he has beeninvolved in microelectronics research and development fromits early days. In 1967 he invented the one-transistor dynamicmemory cell (DRAM) used in most computers today. Withco-workers, he developed the concept of MOSFET scaling in1972. Dr. Dennard is a Fellow of the IEEE and received theirEdison Medal in June, 2001. He is a member of the NationalAcademy of Engineering and the American PhilosophicalSociety. His honors include the National Medal ofTechnology, presented by President Reagan in 1988, andinduction into the National Inventors ’Hall of Fame in 1997.\\nGary B. Bronner IBM Microelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533(gbronner@us.ibm.com). Dr. Bronner joined IBM in 1985\\nand is currently the DRAM alliance program manager, 1GbDRAM project manager, and an IBM Distinguished Engineer.He received a B.S. degree in electrical engineering fromBrown University and M.S. and Ph.D. degrees from StanfordUniversity. Subsequently he joined IBM at the Thomas J.Watson Research Center', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1112: (' National Inventors ’Hall of Fame in 1997.\\nGary B. Bronner IBM Microelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533(gbronner@us.ibm.com). Dr. Bronner joined IBM in 1985\\nand is currently the DRAM alliance program manager, 1GbDRAM project manager, and an IBM Distinguished Engineer.He received a B.S. degree in electrical engineering fromBrown University and M.S. and Ph.D. degrees from StanfordUniversity. Subsequently he joined IBM at the Thomas J.Watson Research Center and initially worked on CMOSand DRAM technology. In 1989 he became Manager ofDRAM Technology in IBM Research and led a jointYorktown/Burlington team that de ﬁned the 0.25-micron\\ntechnology that became the basis of the IBM/Siemens/ToshibaDRAM Development Alliance in 1993. In 1993 he transferredto the IBM Microelectronics Division to continue his rolemanaging the DRAM development team. In this capacity,he has helped de ﬁne and deliver the last ﬁve generations ofDRAM technology inside IBM. He has participated in several\\nIBM Academy of Technology study groups and organizedand co-chaired an IBM Academy workshop on mergedDRAM/logic. He is a Senior Member of the Institute ofElectrical and Electronics Engineers and was the technicalprogram chair of the IEDM Conference in 1998 and thegeneral chair of that conference in 1999. Dr. Bronnerorganized the ﬁrst International Symposium on ULSI Process\\nIntegration at the Fall 1999 Electrochemical Society Meeting.He has reached the 20th IBM Invention Achievement Plateau,with 27 patents issued and 31 patents pending. He haspublished 20 technical disclosures and 45 articles in refereedjournals. Dr. Bronner has received a Research DivisionOutstanding Contribution Award, a Division Award, anOutstanding Technical Achievement Award, a DivisionExcellence Award, and a Division Patent Portfolio Award.\\nJohn K. DeBrosse IBM Microelectronics Division,\\nBurlington facility, 100 River Street, Essex Junction, Vermont05452 (jdebros@us.ibm.com). Mr. DeBrosse received a\\nB.S.E.E. degree in 1983 and', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1113: ('7 patents issued and 31 patents pending. He haspublished 20 technical disclosures and 45 articles in refereedjournals. Dr. Bronner has received a Research DivisionOutstanding Contribution Award, a Division Award, anOutstanding Technical Achievement Award, a DivisionExcellence Award, and a Division Patent Portfolio Award.\\nJohn K. DeBrosse IBM Microelectronics Division,\\nBurlington facility, 100 River Street, Essex Junction, Vermont05452 (jdebros@us.ibm.com). Mr. DeBrosse received a\\nB.S.E.E. degree in 1983 and an M.S.E.E. degree in 1984, bothfrom Purdue University. In 1985 he joined IBM, where hehas contributed to ﬁve generations of DRAM technology\\ndevelopment and product design (4Mb –1Gb). He is an\\nauthor or co-author of 20 patents and 18 technical papers,and is currently involved in MRAM product design.\\nRama Divakaruni IBM Microelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533(rdivakar@us.ibm.com). Dr. Divakaruni received a B.Tech.\\ndegree in electrical engineering from the Indian Institute ofTechnology, Madras, in 1988 and a Ph.D. degree in electricalengineering from the University of California at Los Angelesin 1994. He subsequently joined the IBM MicroelectronicsDivision in Essex Junction, Vermont, where he worked onprocess characterization of 16Mb DRAM shrink technologiesand led the team that successfully installed IBM 0.25-\\n/H9262m\\nDRAM technology in manufacturing. In early 1998 Dr.Divakaruni moved to the IBM Semiconductor Research andDevelopment Center at the East Fishkill facility, where hewas the lead integrator for the 0.15-\\n/H9262m DRAM technology\\nplatform developed in the IBM/Siemens/Toshiba DRAMDevelopment Alliance. Since 1999, he has managed the\\nvertical-pass-transistor DRAM process integration groupwhich has demonstrated sub-8 F\\n2and 8 F2cell concepts\\nscalable below 100 nm. Dr. Divakaruni holds 17 patents, withmore than 60 pending. He has been an author or co-authoron several papers related to vertical-pass gate transistors forDRAMs.\\nYujun Li IBM Microelectronic', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1114: ('hkill facility, where hewas the lead integrator for the 0.15-\\n/H9262m DRAM technology\\nplatform developed in the IBM/Siemens/Toshiba DRAMDevelopment Alliance. Since 1999, he has managed the\\nvertical-pass-transistor DRAM process integration groupwhich has demonstrated sub-8 F\\n2and 8 F2cell concepts\\nscalable below 100 nm. Dr. Divakaruni holds 17 patents, withmore than 60 pending. He has been an author or co-authoron several papers related to vertical-pass gate transistors forDRAMs.\\nYujun Li IBM Microelectronics Division, East Fishkill\\nfacility, Route 52, Hopewell Junction, New York 12533(yujun@us.ibm.com). Dr. Li received a B.S. degree in physics\\nand electrical engineering from the University of Science andTechnology of China in 1992, and M.S., M.Phil., and Ph.D.degrees in electrical engineering from Yale University in 1993,1994, and 1997, respectively. She subsequently joined the IBMSemiconductor Research and Development Center at the EastFishkill facility, where she has worked on array device designof high-density, high-performance DRAM technologies. In1998, she received an IEEE Paul Rappaport Award for bestpaper in an EDS publication during that year. Dr. Li iscurrently an Engineering Manager in the Device DesignDepartment of the IBM/Siemens/Toshiba DRAMDevelopment Alliance.\\nIBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002 J. A. MANDELMAN ET AL.211\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. \\nCarl J. Radens IBM Microelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533\\n(radens@us.ibm.com). Dr. Radens is a Senior Engineer at\\nthe IBM Semiconductor Research and Development Centerworking in the area of process integration. He received a B.A.degree in physics from Oberlin College in 1983 and a Ph.D.degree in electrical engineering from the University ofCincinnati in 1990. Since joining IBM in 1990, he has workedin areas including dry-etch process development, integrationof self-aligned c', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1115: ('oelectronics Division, East\\nFishkill facility, Route 52, Hopewell Junction, New York 12533\\n(radens@us.ibm.com). Dr. Radens is a Senior Engineer at\\nthe IBM Semiconductor Research and Development Centerworking in the area of process integration. He received a B.A.degree in physics from Oberlin College in 1983 and a Ph.D.degree in electrical engineering from the University ofCincinnati in 1990. Since joining IBM in 1990, he has workedin areas including dry-etch process development, integrationof self-aligned contacts, and BEOL interconnect, storagecapacitor, and DRAM cell design. He led the introduction ofthe trench-sidewall vertical-transistor DRAM at IBM, and iscurrently lead engineer for the 90-nm ground-rule DRAMprogram. Dr. Radens has served on the IBM SemiconductorEquipment Council dry-etch tool committee and is a memberof the Integrated Circuits and Manufacturing subcommitteefor the IEEE International Electron Devices Meeting. He hasreached the 32nd IBM Invention Achievement Plateau, holdsmore than 50 U.S. patents, and is the author or coauthor ofmore than 25 technical publications.\\nJ. A. MANDELMAN ET AL. IBM J. RES. & DEV. VOL. 46 NO. 2/3 MARCH/MAY 2002212\\nAuthorized licensed use limited to: Univ of Calif Davis. Downloaded on March 08,2025 at 03:52:26 UTC from IEEE Xplore.  Restrictions apply. ', 'Challenges_and_future_directions_for_the_scaling_of_dynamic_random-access_memory_DRAM.pdf'), 1116: ('RESEARCH ARTICLE\\nSoftware-de ﬁned networking (SDN): a survey\\nKamal Benzekki *\\n, Abdeslam El Fergougui and Abdelbaki Elbelrhiti Elalaoui\\nLaboratory of Computer Networks and Systems, Department of Mathematics and Computer Science, Faculty of Sciences, Moulay\\nIsmail University, Meknes, Morocco\\nABSTRACT\\nWith the advent of cloud computing, many new networking concepts have been introduced to simplify network\\nmanagement and bring innovation through network programmability. The emergence of the software-de ﬁned networking\\n(SDN) paradigm is one of these adopted concepts in the cloud model so as to eliminate the network infrastructuremaintenance processes and guarantee easy management. In this fashion, SDN offers real-time performance and respondsto high availability requirements. However, this new emerging paradigm has been facing many technological hurdles; someof them are inherent, while others are inherited from existing adopted technologies. In this paper, our purpose is to shedlight on SDN related issues and give insight into the challenges facing the future of this revolutionary network model, fromboth protocol and architecture perspectives. Additionally, we aim to present different existing solutions and mitigationtechniques that address SDN scalability, elasticity, dependability, reliability, high availability, resiliency, security, andperformance concerns. Copyright © 2017 John Wiley & Sons, Ltd.\\nKEYWORDS\\nsoftware-de ﬁned networking; SDN challenges; SDN issues; SDN architecture; OpenFlow\\n*Correspondence\\nKamal Benzekki, Laboratory of Computer Networks and Systems, Department of Mathematics and Computer Science, Faculty ofSciences, Moulay Ismail University, Meknes, Morocco.E-mail: benzekki@gmail.com\\n1. INTRODUCTION\\nSoftware-de ﬁned networking (SDN) is facilitating organi-\\nzations to deploy applications and enable ﬂexible delivery,\\noffering the capability of scaling network resources inlockstep with application and data needs, and reducingboth CapEX and OpEX [1]. SDN is an innovative ap-proach to design, implement,', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1117: ('Benzekki, Laboratory of Computer Networks and Systems, Department of Mathematics and Computer Science, Faculty ofSciences, Moulay Ismail University, Meknes, Morocco.E-mail: benzekki@gmail.com\\n1. INTRODUCTION\\nSoftware-de ﬁned networking (SDN) is facilitating organi-\\nzations to deploy applications and enable ﬂexible delivery,\\noffering the capability of scaling network resources inlockstep with application and data needs, and reducingboth CapEX and OpEX [1]. SDN is an innovative ap-proach to design, implement, and manage networks thatseparate the network control (control plane) and theforwarding process (data plane) for a better user experi-ence. This network segmentation offers numerous bene ﬁts\\nin terms of network ﬂexibility and controllability. In the\\none hand, it allows combining the advantages of systemvirtualization and cloud computing and on the other hand,to create an implementation of a centralized intelligence\\nthat enables making a clear visibility over the network for\\nthe sake of easy network management and maintenanceas well as enhanced network control and reactivity. In theconventional infrastructure (Figure 1 and Table I), networkimplementation, con ﬁguration, and troubleshooting require\\nhigh-level technically skilled network and system engineerintervention and operational costs involved in provisioningand managing large multivendor networks. In fact, thevariety and the complexity [2] of network elements make\\ntheir maintenance very expensive and the underlying infra-structure less reliable in case of frequent network failures,especially if no backup plans are anticipated within theinfrastructure.\\nAs SDN separates the routing and forwarding decisions\\nof networking elements (e.g., routers, switches, and accesspoints) from the data plane, the network administration andmanagement become uncomplicated because the controlplane only deals with the information related to logical net-work topology, the routing of traf ﬁc, and so on. In contrast,\\nthe data plane orchestrates the network traf ﬁc in accordance\\nwith', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1118: (' frequent network failures,especially if no backup plans are anticipated within theinfrastructure.\\nAs SDN separates the routing and forwarding decisions\\nof networking elements (e.g., routers, switches, and accesspoints) from the data plane, the network administration andmanagement become uncomplicated because the controlplane only deals with the information related to logical net-work topology, the routing of traf ﬁc, and so on. In contrast,\\nthe data plane orchestrates the network traf ﬁc in accordance\\nwith the established con ﬁguration in the control plane.\\nIn SDN, the control operations are centralized in a\\ncontroller that dictates the network policies. Many\\ncontroller platforms are open source such as Floodlight\\n[3], OpenDayLight [4], and Beacon [5]. The managementof the network can be achieved on different layers(i.e., application, control, and data plane). For instance,service providers can allocate resources to customers viaapplication layer, con ﬁgure and modify network policies\\nand logical entities on control plane, and set up physicalnetwork elements on data plane.SECURITY AND COMMUNICATION NETWORKS\\nSecurity Comm. Networks 2016; 9:5803 –5833\\nPublished online 7 February 2017 in Wiley Online Library (wileyonlinelibrary.com). DOI: 10.1002/sec.1737\\nCopyright © 2017 John Wiley & Sons, Ltd. 5803\\nSoftware-de ﬁned networking has come to light in recent\\nyears. However, the concept of this approach has beenevolving since the mid-1990s. Ethane [6] (management ar-chitecture) and OpenFlow [7] (protocol for network ﬂow)\\nhave given birth to a real implementation of SDN.OpenFlow is a protocol that provides a standardized wayof managing traf ﬁc and describes how a controller commu-\\nnicates with network devices like switches and routers. Thedevices supporting OpenFlow consist of two logicalcomponents: a ﬂow table that de ﬁnes how to process and\\nforward packets within the network and an exposedOpenFlow application programming interface (API) thathandles the exchanges between switch/router andcontroller.\\nOpenFlow is standar', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1119: ('ﬂow)\\nhave given birth to a real implementation of SDN.OpenFlow is a protocol that provides a standardized wayof managing traf ﬁc and describes how a controller commu-\\nnicates with network devices like switches and routers. Thedevices supporting OpenFlow consist of two logicalcomponents: a ﬂow table that de ﬁnes how to process and\\nforward packets within the network and an exposedOpenFlow application programming interface (API) thathandles the exchanges between switch/router andcontroller.\\nOpenFlow is standardized by the Open Networking\\nFoundation [8]. There are other similar existingsouthbound interfaces such as the Forwarding and ControlElement Separation [9,10] standardized by the Internet\\nEngineering Task Force, Path Computation Element [11],the Locator/ID Separation Protocol [12], and SoftRouter[13].\\nFurthermore, the demand for cloud services in its vari-\\nous forms (e.g., SaaS, PaaS, IaaS, Network-as-a-Service[NaaS], DaaS, UCaaS, etc.) is increasing drastically. Al-though these services are centralized in data centers, theypose important challenges for service providers [14]. Withthe rapid growth of the clients ’demands, the operator is\\nrequired to respond accordingly by considering additionalservers, network components, high quality of service, andsecure architecture [15] abiding by the standards. Thisgenerally comes ﬁrst at the cost of non-negligible effort\\nin facing new challenges appearing within the corenetwork where SDN leads and governs. In particular, thechallenges and issues that appear of paramount importancein the SDN environment are the following:\\n(1)Scalability : This de ﬁnes the ability of SDN to, more\\nspeciﬁcally in the control plane, handle and process\\nan increasing workload. Scalability aims at enlarg-ing the capacity of the SDN by implementing mech-anisms such as devolving [16], clustering [17], andhigh processing [18] to cope with the growing load.\\n(2)Reliability : The SDN is considered reliable when it\\nnotiﬁes of delivery failures of the data in real time.\\nIn such network, there should be a', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1120: (' importancein the SDN environment are the following:\\n(1)Scalability : This de ﬁnes the ability of SDN to, more\\nspeciﬁcally in the control plane, handle and process\\nan increasing workload. Scalability aims at enlarg-ing the capacity of the SDN by implementing mech-anisms such as devolving [16], clustering [17], andhigh processing [18] to cope with the growing load.\\n(2)Reliability : The SDN is considered reliable when it\\nnotiﬁes of delivery failures of the data in real time.\\nIn such network, there should be a speci ﬁed mini-\\nmum reliability for the delivery of critical data. Intoday ’s implementations, SDN controllers [19]\\nmust be capable of meeting real-time requirementsfor reliable delivery and timeliness.\\n(3)High availability : HA is an important aspect of to-\\nday’s services that should be available each time a\\ncustomer requests a given service or resource.\\nTable I. Software-de ﬁned networking versus classical\\nnetworking.\\nCharacteristicsSDN\\narchitectureClassical\\narchitecture\\nProgrammability ✓\\nCentralized control ✓\\nError-prone\\nconﬁguration✓\\nComplex network\\ncontrol✓\\nNetwork ﬂexibility ✓\\nImproved performance ✓\\nEasy implementation ✓\\nEfﬁcient con ﬁguration ✓\\nEnhanced management ✓\\nFigure 1. Software-de ﬁned networking (SDN) versus classical architecture.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5804 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nAvailability is usually expressed as a percentage of\\nuptime in a given year. Unavailability of servicescan generally occur owing to network outages orsystem crashes [20,21]. Network providersgenerally deploy backup services to of', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1121: ('002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nAvailability is usually expressed as a percentage of\\nuptime in a given year. Unavailability of servicescan generally occur owing to network outages orsystem crashes [20,21]. Network providersgenerally deploy backup services to offer HA byimplementing redundant server hardware, serverOS and network components, and so on.\\n(4)Elasticity : Elasticity is the ability of SDN to dynam-\\nically adapt its capacity by scaling up or down theavailable resources [22,23] in order to meet the var-iation and ﬂuctuation of the workload. Generally,\\nelasticity is often focused on the control plane andmight be referred to as scalability.\\n(5)Security : SDN security consists of protecting the in-\\nformation from theft or damage to the hardware andthe software as well as from disruption of the ser-vices [24,25]. Securing SDN encompasses physicalsecurity of the hardware, as well as preventinglogical threats that may come from the network ordata. SDN vulnerabilities are the entrance door tosecurity attacks being intentional or accidental.\\n(6)Performance : Performance refers to the amount of\\ntasks achieved by SDN components compared with\\nthe time/resources (e.g., CPU and RAM) being used\\n[26]. There are many different ways to measure[27,28] the performance of a network, as eachnetwork is different in nature and design. As far asSDN is concerned, the important measures arebandwidth, throughput, latency, and jitter.\\n(7)Resilience : Resilience in SDN is the capability to\\nensure and maintain an acceptable level of serviceeven in case of a service, network or node failure.When an SDN element is faulty, the network shouldprovide a continuous operational service with thesame performance. In order to increase the resilienceof SDN, potential challenges/risks have to be iden', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1122: ('etwork, as eachnetwork is different in nature and design. As far asSDN is concerned, the important measures arebandwidth, throughput, latency, and jitter.\\n(7)Resilience : Resilience in SDN is the capability to\\nensure and maintain an acceptable level of serviceeven in case of a service, network or node failure.When an SDN element is faulty, the network shouldprovide a continuous operational service with thesame performance. In order to increase the resilienceof SDN, potential challenges/risks have to be identi-ﬁed and addressed to protect the services [29].\\n(8)Dependability : The dependability of SDN is\\nstrongly tied to availability and reliability terms.SDN dependability aims mainly at preventing faultsand implementing fault tolerance mechanisms toguarantee service delivery even at a degraded level[30]. In addition to HA and reliability, integrityand maintainability are also two important depend-ability attributes.\\nThe rest of this paper is organized as follows. Section 2\\ngives an overview of SDN technology and describes thegeneric architecture and the adopted communication proto-cols. Section 3 discusses scalability and elasticitychallenges/issues facing SDN in current deployments aswell as the existing solutions to meet SLA [31] require-ments. Section 4 introduces dependability, HA, and reli-ability and analyzes their challenges/issues, impacts, andworkarounds to satisfy the customer and abide by thedepicted speci ﬁcations in the SLA. SDN performance is\\ndiscussed and explored with the research efforts made so\\nfar to improve network responsiveness and minimizedelays in Section 5. Section 6 gives insight into how to\\nachieve SDN resilience and presents existing works in thissense. Security threats, vulnerabilities, and mitigationtechniques are provided in Section 7. Finally, Section 8summarizes and concludes this paper.\\n2. SOFTWARE-DEFINED\\nNETWORKING: AN OVERVIEW\\n2.1. Generic software-de ﬁned networking\\narchitecture\\nUnlike conventional IP networks (Figure 1) whose\\nfunctionalities are decentralized, SDN is centrali', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1123: ('\\nfar to improve network responsiveness and minimizedelays in Section 5. Section 6 gives insight into how to\\nachieve SDN resilience and presents existing works in thissense. Security threats, vulnerabilities, and mitigationtechniques are provided in Section 7. Finally, Section 8summarizes and concludes this paper.\\n2. SOFTWARE-DEFINED\\nNETWORKING: AN OVERVIEW\\n2.1. Generic software-de ﬁned networking\\narchitecture\\nUnlike conventional IP networks (Figure 1) whose\\nfunctionalities are decentralized, SDN is centralized tooffer connection network domains between the controland data plane in the same infrastructure. Additionally,SDN allows backward compatibility with existingprotocols and standards (e.g., IP, ARP, VLAN, Ethernet,etc.) [6].\\nIn Figure 2, the core architecture of SDN is divided into\\nthree layers. The upper layer of SDN architecture is an\\napplication layer that de ﬁnes rules and offers different\\nservices such as ﬁrewall, access control, IDS/IPS, quality\\nof service, routing, proxy service, and monitoring balancer.This layer is responsible of abstracting the SDN networkcontrol management through the northbound API(e.g., OpenDaylight) [4]. The second layer is known asthe control plane, which is an abstraction of the networktopology. The controller is the main componentresponsible for establishing ﬂow tables and data handling\\npolicies as well as abstracting the network complexityand collecting network information through thesouthbound API and maintaining an up-to-date networkholistic view. The southbound API communications canbe deployed in two different scenarios:\\n\\x81in-band communication: In this scenario, the traf ﬁc\\nbetween the controller and any network device shouldabide by the dictated ﬂow rules.\\n\\x81out-of-band communication: Here, the traf ﬁc does not\\nfollow ﬂow rules. This type of deployment requires\\nVLAN implementation to isolate the traf ﬁcﬂow from\\nthe communications, which depends on OpenFlowrules.\\nThere are also eastbound/westbound APIs\\n(e.g., HyperFlow) [17] that enable multiple controllers toexchange con', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1124: ('unications canbe deployed in two different scenarios:\\n\\x81in-band communication: In this scenario, the traf ﬁc\\nbetween the controller and any network device shouldabide by the dictated ﬂow rules.\\n\\x81out-of-band communication: Here, the traf ﬁc does not\\nfollow ﬂow rules. This type of deployment requires\\nVLAN implementation to isolate the traf ﬁcﬂow from\\nthe communications, which depends on OpenFlowrules.\\nThere are also eastbound/westbound APIs\\n(e.g., HyperFlow) [17] that enable multiple controllers toexchange control information regarding the ﬂow in the\\ndata plane. We can ﬁnd several existing controllers based\\non different programming languages (Python, C/C++,Java, Ruby, etc.) and platforms such as NOX [32], Flood-light [3], Beacon [5], Maestro [33], and Trema [34]. Thelowest layer, which is known as the data plane, provides\\nnetworking devices such as physical/virtual switches,\\nrouters, and access points and is responsible for all dataactivities including forwarding, fragmentation, andreassembly.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5805 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n2.2. Existing network cloud-based models\\nThere are multiple cloud-based models solutions for\\nenhancing network functionalities and facilitatingnetwork management of the underlying infrastructurelike in NaaS (Table II). For instance, an OpenFlow-basedSDN model [7] can be adopted to support [35] NaaS,enhance performance, and enforce the global visibilityof the network. Additionally, a wide array of reliable\\napplications is offered to the users to take bene ﬁt from\\nadvanced network functions', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1125: ('e Commons License\\n\\n2.2. Existing network cloud-based models\\nThere are multiple cloud-based models solutions for\\nenhancing network functionalities and facilitatingnetwork management of the underlying infrastructurelike in NaaS (Table II). For instance, an OpenFlow-basedSDN model [7] can be adopted to support [35] NaaS,enhance performance, and enforce the global visibilityof the network. Additionally, a wide array of reliable\\napplications is offered to the users to take bene ﬁt from\\nadvanced network functions. There are also two othercloud-based models: network virtualization model\\n[36,37] and evolutionary model [38]. The networkvirtualization model can be applied to SDN to providescalability in VLAN. This approach allows creatingseveral virtual network instances in a single physicalinfrastructure. This model has been introduced to resolveissues related to mobility across subnets and isolation injoint-tenant environments. The evolutionary model aimsat dividing the network into virtual segments and offers\\nquality of service, fault tolerance and con ﬁguration man-\\nagement, and so on.\\nFigure 2. A generic software-de ﬁned networking architecture.\\nTable II. Cloud-based models.\\nDescriptionCapabilities and\\nfeatures Limitations\\nOpenFlow-\\nbased SDNmodel [7]First designed standard interface\\ncommunication protocol for SDN controllersto allow programming the forwarding tablesof the network elements separation/centralization/programmability of the control\\nplaneSimplifying network\\noperationsImproving networkavailabilityProviding better control\\nand performance for\\nSDNOF switches support issues\\nCompatibility issues with controller and OFswitches\\nNetwork\\nvirtualizationmodel\\n[36,37]Coexisting multiple network instances on a\\ncommon physical network to facilitatenetwork provisioningAddressing the\\nscalability issues withmulticasting VLAN\\narchitectures\\nOffering multi-tenancyto the cloudAn implementation of deep packet inspection\\nmechanism is required to identify theindividual virtual network ’s header by the\\nnetwork nodes\\nEvolutionary\\nm', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1126: ('ng better control\\nand performance for\\nSDNOF switches support issues\\nCompatibility issues with controller and OFswitches\\nNetwork\\nvirtualizationmodel\\n[36,37]Coexisting multiple network instances on a\\ncommon physical network to facilitatenetwork provisioningAddressing the\\nscalability issues withmulticasting VLAN\\narchitectures\\nOffering multi-tenancyto the cloudAn implementation of deep packet inspection\\nmechanism is required to identify theindividual virtual network ’s header by the\\nnetwork nodes\\nEvolutionary\\nmodel [38]Partitioning the network into virtual\\ncommunities to manage traf ﬁc and quality of\\nservice on the basis of network standards (e.\\ng., MPLS, VXLAN) by using managementinterfacesEnhancing software\\ncontrol of the network\\nEnsuring ﬂexible virtual\\nnetworks extensionExisting interoperability issues between\\nvendors that may not consider the\\nimplementation of some standards/protocols\\n(Some existing solutions like OpenStack canhelp enabling interoperability of networkdevices.)\\nSDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5806 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n2.3. Communication protocol\\nThe most common southbound interface in SDN relies on\\nOpenFlow. The OpenFlow speci ﬁcation de ﬁnes the proto-\\ncol that enables the controller to command switches androuters.\\nThere exist three communication ways in the OpenFlow\\nprotocol: controller-to-switch, asynchronous, and symmet-ric communication. The controller-to-switch communica-tion is responsible for establishing handshakes, switch,andﬂow table con ﬁguration. The asynchronous commu', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1127: ('he applicable Creative Commons License\\n\\n2.3. Communication protocol\\nThe most common southbound interface in SDN relies on\\nOpenFlow. The OpenFlow speci ﬁcation de ﬁnes the proto-\\ncol that enables the controller to command switches androuters.\\nThere exist three communication ways in the OpenFlow\\nprotocol: controller-to-switch, asynchronous, and symmet-ric communication. The controller-to-switch communica-tion is responsible for establishing handshakes, switch,andﬂow table con ﬁguration. The asynchronous communi-\\ncation starts from OpenFlow-compliant switch to informthe controller by sending packet-in message, port statusmessage, and ﬂow-removed message (Figure 3a). For the\\nsymmetric communication, there is no restriction aboutwho initiates the exchanges. Examples of exchanged mes-sages are Hello and Echo that are used to aid in detectingproblems in the switch-controller connection; other mes-sages are Feature Request/Reply, Set Con ﬁg, and so on\\n(Figure 3b).\\nThe communication between the controller and the\\nswitch can be either run over Transport Layer Security(TLS) or without an encryption mechanism, depending\\non the security needs and deployments.\\n3. SCALABILITY AND ELASTICITY\\n3.1. Scalability challenges and solutions\\nAs the SDN design enables pushing all the control func-\\ntionality to a centralized controller with a completenetwork-wide view, developing control applications andenforcing policies become much easier with these prop-erties. However, controllers might potentially become abottleneck for network operations. As the size of the net-\\nwork grows, more events and requests are sent to thecontroller, and at some point, handling all the incomingrequests by the controller becomes a serious challenge.This is a common problem that exists in any systemand does not only apply to SDN design. By decouplingthe control and data planes and entrusting the controllerfor the control of the network traf ﬁc over a large net-\\nwork, the growth of network traf ﬁc may not scale with\\nthe capabilities of the controller in terms of', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1128: ('ations. As the size of the net-\\nwork grows, more events and requests are sent to thecontroller, and at some point, handling all the incomingrequests by the controller becomes a serious challenge.This is a common problem that exists in any systemand does not only apply to SDN design. By decouplingthe control and data planes and entrusting the controllerfor the control of the network traf ﬁc over a large net-\\nwork, the growth of network traf ﬁc may not scale with\\nthe capabilities of the controller in terms of performanceand thus engendering scalability and elasticity issues[22], [23]. Multiple works have been proposed to allevi-ate the workload on one single controller by distributingand sharing tasks across multiple controllers. These areonly workarounds to solve speci ﬁc concerns of SDNs\\noverhead on the control plane and latencies. These scal-ability solution proposals include DIFANE [16],DevoFlow [39], software-de ﬁned counters [40], Onix\\n[41], Kandoo [42], HyperFlow [17], Maestro [33] andNOX-MT [43], which mainly aim at reducing the over-head of the control plane by delegating some work tothe forwarding devices or trying to increase the through-put and latency of the controllers by implementing high-\\nperformance computing techniques such as buffering,\\npipelining, multithreading and parallelism. Several workshave been proposed to mitigate the scalability issue inthe control plane, and few researches are dealing withthe data plane [44 –46]. From another perspective, these\\nworks can be divided into three types, depending onthe mechanisms used to achieve scalability: controllercapacity improvement (e.g., high-processing techniques),controllers ’clusters (e.g., distributed event-based control\\nplane), and devolving/delegating some managementfunctions to the data plane. Table III presents a non-exhaustive list of the proposed solutions to addressscalability issues.\\nFigure 3. OpenFlow exchanges.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5807 Security Comm. Networks 201', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1129: ('depending onthe mechanisms used to achieve scalability: controllercapacity improvement (e.g., high-processing techniques),controllers ’clusters (e.g., distributed event-based control\\nplane), and devolving/delegating some managementfunctions to the data plane. Table III presents a non-exhaustive list of the proposed solutions to addressscalability issues.\\nFigure 3. OpenFlow exchanges.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5807 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nTable III. Scalability issues, solutions, and challenges.\\nReference Proposal Main purpose/challengeScalability\\n(technique)\\nTootoonchian\\net al. [17]HyperFlow localizes decision making to individual\\ncontrollers in order to minimize the control plane\\nresponse time to data plane requestsBy logically centralizing and physically distributing\\nthe network overhead across the control plane,\\nHyper ﬂow provides scalability for SDNClustering\\nKoponen et al.\\n[41]ONIX platform on top of which a network control\\nplane can be implemented as a distributed systemfor large-scale networksOnix allows trade-offs between scalability and\\nconsistency/durabilityClustering\\nprovides more general APIs for control plane\\nimplementations\\nBerde et al.[85]Open Network Operating System adopts a\\ndistributed architecture for high availability andscale-out. It provides a global network view to\\napplications, which is logically centralized even\\nthough it is physically distributed across multipleserversImproving scalability and performance to meet the\\nrequirements of large-scale networksClustering\\nKrishnamurthy\\net al. [51]Pratyaastha is ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1130: ('een scalability and\\nconsistency/durabilityClustering\\nprovides more general APIs for control plane\\nimplementations\\nBerde et al.[85]Open Network Operating System adopts a\\ndistributed architecture for high availability andscale-out. It provides a global network view to\\napplications, which is logically centralized even\\nthough it is physically distributed across multipleserversImproving scalability and performance to meet the\\nrequirements of large-scale networksClustering\\nKrishnamurthy\\net al. [51]Pratyaastha is a new way to partition SDN\\napplication state that considers the dependencies\\nbetween application state and SDN switchesImproving the performance of the current\\ndistributed SDN control platforms by proposing a\\nnovel approach for assigning SDN switches and\\npartitions of SDN application state to distributedcontroller instancesClustering\\nYeganeh and\\nGanjali [42]Kandoo is a framework that allows scalability\\npreservation without changing switches ’\\norganization. Kandoo consists of two layers: abottom layer grouping controllers with noknowledge of the network-wide state and a toplayer containing a logically centralized controller\\nthat maintains the network-wide stateOfﬂoading the control applications by separating\\nthe controllers into two different roles such as a\\nroot controller and a local controller; in this way,the root controller processes rare events and theoverhead will be pushed to the local controller inorder to provide scalabilityClustering\\nVeisllari et al.\\n[47]Investigating the scalability of the SDN controller\\nwith respect to performance. Scalability is relatedto performance when we consider metrics such asdelay, latency, and throughputThe current Internet ﬂow de ﬁnitions have high\\nrequirements on the processing rate of the SDNcontrollerClustering\\nPark et al. [48] RAON implementation consists of two parts: a\\nRAON switch and a RAON OpenFlow controllerabstraction module that communicates with theRAON switch. The networks of the lower-levelcontrollers are abstracted as big OpenFlow\\nswitchesSolving scalability', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1131: ('roller\\nwith respect to performance. Scalability is relatedto performance when we consider metrics such asdelay, latency, and throughputThe current Internet ﬂow de ﬁnitions have high\\nrequirements on the processing rate of the SDNcontrollerClustering\\nPark et al. [48] RAON implementation consists of two parts: a\\nRAON switch and a RAON OpenFlow controllerabstraction module that communicates with theRAON switch. The networks of the lower-levelcontrollers are abstracted as big OpenFlow\\nswitchesSolving scalability issues in OpenFlow networks by\\nreducing complexity and increasing manageabilityClustering\\nYuet al. [16] DIFANE is a distributed ﬂow management\\narchitecture that runs a partitioning algorithm todivide the rules over switches that will handle\\nﬂows instead of the controllerOffering a scalable and ef ﬁcient solution that\\nhandles the ﬂow in the data plane by forwarding\\npackets through intermediate switches that\\nmaintain necessary rulesDevolving\\nCurtis et al.\\n[39]DevoFlow aims at reducing the interactions\\nbetween OF switches and controller using ﬁltering\\nand sampling techniques such as rule aggregation,selective local action, and approximatingMaintaining a global visibility and providing a\\nscalable ﬂow management simulations for large-\\nscale networksDevolving\\nLuo et al. [45] Control-message quenching is a mechanism\\nwhereby a control-message quenching switchsends only one packet-in message for eachsource-destination pair, which reducesunnecessary packet-in messages from the\\nOpenFlow switch to the controllerEnhancing the controller responsiveness and\\nnetwork scalability with reduced ﬂow setup\\nlatency and higher network throughputDevolving\\nKempf et al.\\n[46]Devolving fault management to the OpenFlow\\nswitches by extending the OpenFlow protocol tosupport the monitoring function. OF switch emitsmonitoring messages without posing a processing\\nload on the controllerResolving scalability limitation of the centralized\\nfault management that is based on LLDPmessages for monitoringDevolving\\n(Continues )Software-defined networking', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1132: ('g the controller responsiveness and\\nnetwork scalability with reduced ﬂow setup\\nlatency and higher network throughputDevolving\\nKempf et al.\\n[46]Devolving fault management to the OpenFlow\\nswitches by extending the OpenFlow protocol tosupport the monitoring function. OF switch emitsmonitoring messages without posing a processing\\nload on the controllerResolving scalability limitation of the centralized\\nfault management that is based on LLDPmessages for monitoringDevolving\\n(Continues )Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5808 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n3.2. Elasticity\\nElasticity is another challenge facing cloud providers to\\nmanage and adapt responsiveness of SDN demands in realtime. In addition to this, cloud providers should offer moreelastic access to computing and network resources. Elasticitycan be seen from three dimensions as illustrated in Figure 4.\\n(1) elastic scalability: aims at ensuring the growth\\ndepending on network requirements. SDN can scale\\ndynamically in case of high demands.\\n(2) elastic con ﬁguration: gives an opportunity to add,\\nedit, and delete con ﬁguration to meet new network\\nrequirements and respond to new challenges interms of bandwidth and throughput.\\n(3) elastic discovery :anticipates discoveries as well as\\nbecoming aware of possible emerging technologicalopportunities and threats at the right time to reactand meet the new requirements and trends. The mainpurpose is to identify irrelevant tendencies and thinkof acquiring new ef ﬁcient techniques/strategies that\\nmight help in improving the SDN. The observationsshould be ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1133: ('add,\\nedit, and delete con ﬁguration to meet new network\\nrequirements and respond to new challenges interms of bandwidth and throughput.\\n(3) elastic discovery :anticipates discoveries as well as\\nbecoming aware of possible emerging technologicalopportunities and threats at the right time to reactand meet the new requirements and trends. The mainpurpose is to identify irrelevant tendencies and thinkof acquiring new ef ﬁcient techniques/strategies that\\nmight help in improving the SDN. The observationsshould be made quickly and the action must be takenin real time to take advantage of new possiblenetwork features and/or remove potential threats bydeploying novel countermeasures.Achieving elasticity leads to optimal use of SDN and\\nresources. An elastic SDN is simple and easy to deploy,conﬁgure, and change. Several works have been proposed\\nin this sense such as distributed controller architectures todynamically rise or contract the controller pool accordingto network conditions where the traf ﬁc load is\\nreapportioned among controllers [22,51,52]. Other worksfocus on load-balancing mechanisms [53] or SDNhierarchical methods [54]. For instance, in [22,23], anelastic distributed controller architecture is presented\\ncalled ElastiCon that utilizes a dynamic adaptation of\\nthe controllers ’number and their locations in the design\\nof SDN to grow or shrink the controllers ’pool depending\\non the network traf ﬁc load. A load-balancing mechanism\\nfor the control plane is also considered in ElastiCon aswell as in FreeFlow [53]. In [55], a hierarchicalSDN/OpenFlow control plane is proposed for mobilecloud computing and Follow me cloud (FMC)-basedsystems. The elastic control plane is reapportioned intotwo hierarchical levels: a ﬁrst level with a global FMC\\ncontroller and a second level with several local FMCcontrollers. The local FMC controllers are invoked whenthe load grows in the global systems.\\nTable IV illustrates the research papers that deal directly\\nwith elasticity issues and challenges and propose solutionsand enhancements.Tab', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1134: ('[55], a hierarchicalSDN/OpenFlow control plane is proposed for mobilecloud computing and Follow me cloud (FMC)-basedsystems. The elastic control plane is reapportioned intotwo hierarchical levels: a ﬁrst level with a global FMC\\ncontroller and a second level with several local FMCcontrollers. The local FMC controllers are invoked whenthe load grows in the global systems.\\nTable IV illustrates the research papers that deal directly\\nwith elasticity issues and challenges and propose solutionsand enhancements.Table III. (Continued)\\nReference Proposal Main purpose/challengeScalability\\n(technique)\\nBenzekki et al.\\n[49]Devolving IEEE 802.1X authentication capability to\\ndata plane by inserting a legacy switch that\\nsupports IEEE 802.1X port-based authentication\\nand placing the RADIUS server and other serversnear the legacy switch to reduce authenticationdelaysImproving access control and performance and\\nreducing the high demand on the SDN controller\\nwhen users attempt to authenticate against a\\nRADIUS serverDevolving\\nCaiet al.\\n[18,100]Maestro is a controller that has a task manager that\\nmanages incoming computations and distributes\\nthe processing to each controller instance at eachcore of the processor. Maestro exploits moreadditional throughput optimization techniquesImproving the capacity of the controller itself by\\nusing multicores with parallel processing and\\nmultithreads for a scalable SDNHigh-\\nprocessing\\nVoellmy et al.\\n[50]McNettle is an extensible SDN control system\\nimplemented in Haskell that leverages the\\nmulticore facilities of the Glasgow HaskellCompiler and runtime system.Scheduling event handlers, allocating memory, and\\nreducing system calls in order to optimize cache\\nusage and avoids contention on sockets andensures that each message is processed on asingle CPU coreHigh-\\nprocessing\\nSDN, software-de ﬁned networking.\\nFigure 4. Three dimensions of elasticity.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5809 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1135: (' facilities of the Glasgow HaskellCompiler and runtime system.Scheduling event handlers, allocating memory, and\\nreducing system calls in order to optimize cache\\nusage and avoids contention on sockets andensures that each message is processed on asingle CPU coreHigh-\\nprocessing\\nSDN, software-de ﬁned networking.\\nFigure 4. Three dimensions of elasticity.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5809 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n4. DEPENDABILITY, HIGH\\nAVAILABILITY, AND RELIABILITY\\n4.1. Dependability\\nWe consider dependability to be the ability of a system to\\nprovide dependable services in terms of availability,responsiveness, and reliability. Even if a system fails, itcan be considered dependable [30], if failures occur withan expected probability. Thus, dependability identi ﬁes the\\ntrust that can be placed on the service delivered by asystem. In this sense, dependability includes concepts inconnection with reliability and availability (Figure 5).\\nThe increased complexity in SDN is caused by the in-\\nteractions between the applications and workloads sharingthe physical infrastructure. The prediction of theseinteractions and adapting the SDN accordingly to provide\\ndependability guarantees in terms of availability andresponsiveness is a serious challenge that service providersare faced with. Identifying and deploying the neededresources to meet the service level agreement (SLA) isthe most important task to adapt to varying customer work-loads and load ﬂuctuations. Also determining the granular-\\nity at which resources (e.g., CPU cycles, cluster nodes,additi', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1136: ('aringthe physical infrastructure. The prediction of theseinteractions and adapting the SDN accordingly to provide\\ndependability guarantees in terms of availability andresponsiveness is a serious challenge that service providersare faced with. Identifying and deploying the neededresources to meet the service level agreement (SLA) isthe most important task to adapt to varying customer work-loads and load ﬂuctuations. Also determining the granular-\\nity at which resources (e.g., CPU cycles, cluster nodes,additional memory, extended storage capacity, andbandwidth) should be added actively is of paramountimportance for long-term respect of SLA.\\nDependability is still an open research problem and\\nrepresents a strict requirement for the adoption of SDN inpractical deployments. However, only few research workscan be found in the large body of the literature addressingdependability evaluation of SDN architecture with particu-lar attention to the control plane in different operatingconditions.\\nAs dependability is tied to HA and reliability, most of\\nthe proposed works deal with the two primitives and\\npropose various solutions, but we can only ﬁnd some few\\nstraightforward researches that shed light on dependabilityissues and evaluate the impact of load ﬂuctuation on SDN\\ndependability as demonstrated in Table V.Table IV. Elasticity issues, solutions, and challenges.\\nReference Proposal Main purpose/challengeElasticity\\n(technique)\\nDixit el al.\\n[22,23]ElastiCon is an elastic distributed controller\\narchitecture in which the controller pool dynamically\\nexpands or shrinks to automatically balance the loadacross controllersAddressing the load imbalance issues to offer\\nelasticity and load-balancing equityLoad-\\nbalancing/\\ndistribution\\nRajagopalan\\net al. [53]FreeFlow (split/merge) is a system that allows\\ntransparent and balanced elasticity for stateful\\nvirtual middleboxes to have the ability to migrate\\nﬂows dynamicallyProviding elasticity by the execution of virtual\\nmiddleboxesLoad-\\nbalancing\\nFang et al. [54] Hierarchical SDN is an arch', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1137: ('roller pool dynamically\\nexpands or shrinks to automatically balance the loadacross controllersAddressing the load imbalance issues to offer\\nelasticity and load-balancing equityLoad-\\nbalancing/\\ndistribution\\nRajagopalan\\net al. [53]FreeFlow (split/merge) is a system that allows\\ntransparent and balanced elasticity for stateful\\nvirtual middleboxes to have the ability to migrate\\nﬂows dynamicallyProviding elasticity by the execution of virtual\\nmiddleboxesLoad-\\nbalancing\\nFang et al. [54] Hierarchical SDN is an architectural solution that\\noffers a new way for the forwarding and controlplanes. Small forwarding tables are used in the\\nnetwork nodes to determine pathsAchieving elasticity and enabling more agile\\nmechanisms for disaster recovery/fastrestorationHierarchical\\nAissioui et al.\\n[55]Elastic distributed SDN controller tailored for mobile\\ncloud computing and FMC-based systems wherethe SDN/OpenFlow control plane is repartitioned ona two-level hierarchical architecture: a ﬁrst level\\nwith a global FMC controller and a second level with\\nseveral local FMC controllersEnsuring elasticity with better control plane\\nmanagement, performance maintenance andnetwork resources preservationDistribution\\nKrishnamurthy\\net al. [51]Pratyaastha is an elastic distributed SDN control\\nplane that permits to ef ﬁciently assign state\\npartitions and switches to controller instancesMinimizing intercontroller communication and\\nresource consumption to ensure better\\nperformancesDistribution\\nMueller et al.\\n[56]A cost-saving approach for on-demand elastic\\nnetwork design and active ﬂow placement in SDN\\nenvironments based on generic adaptive resourcecontrol function to manage topology and control\\nnetwork resources dynamically and on demandSolving the underlying network design problem\\nusing the state-of-the-art integer programmingMixed-\\nintegerprogramming\\nVegad et al.\\n[57]Elasticity analysis of middleboxes application using\\nNFV in SDN environment and SDN elementsSolving elasticity or dynamic scalability issue of\\nNFV (SDN)(Comparison)\\nSDN, software-de ﬁned n', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1138: ('tic\\nnetwork design and active ﬂow placement in SDN\\nenvironments based on generic adaptive resourcecontrol function to manage topology and control\\nnetwork resources dynamically and on demandSolving the underlying network design problem\\nusing the state-of-the-art integer programmingMixed-\\nintegerprogramming\\nVegad et al.\\n[57]Elasticity analysis of middleboxes application using\\nNFV in SDN environment and SDN elementsSolving elasticity or dynamic scalability issue of\\nNFV (SDN)(Comparison)\\nSDN, software-de ﬁned networking; NFV, network function virtualisation.\\nFigure 5. Dependability: high availability and reliability intersection.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5810 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n4.2. Service level agreement\\nAlthough SLAs [31] commonly include details of the\\nagreed aspects of the service such as scope, quality, perfor-mance, time delivery, and speed of memory and CPUs,there is no mechanism that could prevent the failure ofone or more elements in the SLA contract. In fact, somesystem or network misbehaviors and glitches are unpre-dictable owing to bugs, fake process, and/or malwares[61] running in the background, which might cause highCPU and memory usage. Consequently, services mightbe unreachable for end customers. Another issue thatmay emerge is purely related to hardware availability\\n[62]. Major cloud providers have experienced complete\\nblackouts because of minor miscon ﬁgurations or\\ndysfunctionings as reported in [20,21].\\nThe SLA typically dictates advanced technical speci ﬁ-\\ncations in terms of HA such as throughput, bandwi', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1139: ('re-dictable owing to bugs, fake process, and/or malwares[61] running in the background, which might cause highCPU and memory usage. Consequently, services mightbe unreachable for end customers. Another issue thatmay emerge is purely related to hardware availability\\n[62]. Major cloud providers have experienced complete\\nblackouts because of minor miscon ﬁgurations or\\ndysfunctionings as reported in [20,21].\\nThe SLA typically dictates advanced technical speci ﬁ-\\ncations in terms of HA such as throughput, bandwidth,transfer rates, jitter and latency, and HA metrics: meantime between failures (MTBF), mean time to recover(MTTR), mean time to repair (MTTRr), mean time to fail-ure (MTTF), and mean time to detect (MTTD). MTBF isthe“up-time ”between inherent failures of a repairable sys-\\ntem during operation. MTTR is the average time that adevice/ network will take to recover from any failure.MTTRr is the average time to repair the failed device afteridentifying the root cause of the malfunctioning. MTTF isthe mean time to failure starting from the moment the de-vice recovers. MTTD is an expected average time to detecta failed network component (Figure 6).The availability of SDN can be calculated using the\\nfollowing formula:\\nAvailability ¼\\nMTTF\\nMTBF¼MTBF /C0MTTD /C0MTTR\\nMTBF\\nwhereMTTR ¼MTTD þMTTRr\\nMTBF ¼MTTR þMTTF/C26\\nPercentages of availability are sometimes referred to by\\nthe class of nines (Table VI). For example, three ninesmeans nearly 9 h of unavailability per year.\\n4.3. High availability: challengesHigh availability is generally one of the most challenging\\ngoals in an operational cloud. In the conventional network,we can ﬁnd several HA mechanisms (e.g., link aggrega-\\ntion, multipath routing, system/network redundancy andbackup, state synchronization, failure detection andhandling) and protocols (e.g., link aggregation controlprotocol [63], EtherChannel [64], equal-cost multipath\\nrouting [65], virtual router redundancy protocol [66], host\\nstandby router protocol [67], resilient packet ring [68],nonstop routing [69], n', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1140: ('y is generally one of the most challenging\\ngoals in an operational cloud. In the conventional network,we can ﬁnd several HA mechanisms (e.g., link aggrega-\\ntion, multipath routing, system/network redundancy andbackup, state synchronization, failure detection andhandling) and protocols (e.g., link aggregation controlprotocol [63], EtherChannel [64], equal-cost multipath\\nrouting [65], virtual router redundancy protocol [66], host\\nstandby router protocol [67], resilient packet ring [68],nonstop routing [69], nonstop forwarding [70], statefulswitch-over [71], Ethernet automatic protection switching[72], Ethernet ring protection switching [73], and fastrerouting [74]).\\nLike every component of the cloud, SDN needs to be\\nrun continuously to meet the HA objectives that aim atTable V. Dependability issues, solutions, and challenges.\\nReference Proposal Main purpose/challenge\\nLongo\\net al. [58]A stochastic model to evaluate reliability and availability\\n(dependability) of SDN architectures, and represent SDN\\ncontroller whose components are organized in a hierarchical\\ntopology. This model is based on an algorithm thatrepresents realistic behaviors and changing operatingconditions of the network because of workloadsPresenting and evaluating a dependability model of SDN to\\npinpoint the key aspects of reliable and available SDN\\narchitecture. In particular, the evaluation is mainly based on\\na parametric controller model, instantiated and populatedwith different parameters and measures to evaluate thecontrol plane dependability and reliability\\nWuet al.\\n[59]A probabilistic model to analyze dependability of SDN with\\nthe PRISM tool. The results of the designed system model\\nare veri ﬁed and visualized using PRISM. SDN system is\\nmodeled using Markov chain modelImproving the dependability (reliability) of SDN by\\nimplementing multicontroller architecture\\nKreutz\\net al. [60]Discussing the important aspects of a secure and\\ndependable SDN architecture as well as threats/\\nvulnerabilities. A brief description of the mechanisms\\nrequired to build', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1141: ('nd reliability\\nWuet al.\\n[59]A probabilistic model to analyze dependability of SDN with\\nthe PRISM tool. The results of the designed system model\\nare veri ﬁed and visualized using PRISM. SDN system is\\nmodeled using Markov chain modelImproving the dependability (reliability) of SDN by\\nimplementing multicontroller architecture\\nKreutz\\net al. [60]Discussing the important aspects of a secure and\\ndependable SDN architecture as well as threats/\\nvulnerabilities. A brief description of the mechanisms\\nrequired to build a secure and dependable SDN controlplatform is also introducedDependability is of paramount importance when designing\\nSDN\\nFigure 6. Software-de ﬁned networking availability timeline.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5811 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nproviding nonstop physical and virtual resources\\n(e.g., applications, platforms, databases, and computationalservers). However, the separation between the data andcontrol planes, as well as centralizing the controllabilityin one entity, has brought new challenges. Most of theaforementioned mechanisms and protocols can be appliedto the cloud infrastructure, but unfortunately, they do notsupport speci ﬁc SDN feature requirements such as correla-\\ntion of failures between the control plane and the dataplane, HA interconnection, and synchronization between\\nthe SDN controllers. Obviously, dealing with the brain ofthe SDN is more crucial than with a decentralized networkwhere responsibilities are shared and partitioned amongevery component. Controllers are critical as long as HAis concerned because ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1142: ('mechanisms and protocols can be appliedto the cloud infrastructure, but unfortunately, they do notsupport speci ﬁc SDN feature requirements such as correla-\\ntion of failures between the control plane and the dataplane, HA interconnection, and synchronization between\\nthe SDN controllers. Obviously, dealing with the brain ofthe SDN is more crucial than with a decentralized networkwhere responsibilities are shared and partitioned amongevery component. Controllers are critical as long as HAis concerned because decisions and orders are in theirhands, which makes them a single point of failure. Sofar, few HA related works for data and control plane havebeen proposed as illustrated in Table VII.Table VI. Percentage of availability.\\nAvailability % Downtime per year Downtime per month Downtime per week Downtime per day\\n90 (“1 nine ”) 36.5 d 72 h 16.8 h 2.4 h\\n99 (“2 nines ”) 3.65 d 7.20 h 1.68 h 14.4 min\\n99.9 ( “3 nines ”) 8.76 h 43.8 min 10.1 min 1.44 min\\n99.99 ( “4 nines ”) 52.56 min 4.38 min 1.01 min 8.66 s\\n99.999 ( “5 nines ”) 5.26 min 25.9 s 6.05 s 864.3 ms\\n99.9999 ( “6 nines ”) 31.5 s 2.59 s 604.8 ms 86.4 ms\\n99.99999 ( “7 nines ”) 3.15 s 262.97 ms 60.48 ms 8.64 ms\\n99.999999 ( “8 nines ”) 315.569 ms 26.297 ms 6.048 ms 0.864 ms\\n99.9999999 ( “9 nines ”) 31.5569 ms 2.6297 ms 0.6048 ms 0.0864 ms\\nTable VII. HA issues, solutions, and challenges.\\nReference Data plane Control plane Proposal Main purpose\\nWilliams et al.\\n[83]✓ RuleBricks provides HA in existing OpenFlow\\npoliciesEmbedding HA policies into\\nOpenFlow ’s forwarding rules\\nDesai et al.\\n[84]✓ An algorithm: checking connectivity among\\nneighboring switches for fast failure detection\\nby using the OpenFlow switch ’s link signalFast failure detection in SDN\\nKempf et al.\\n[46]✓ Extending the OpenFlow protocol to support\\na monitoring function on OpenFlow switchesAchieve fault management\\nand recovery in the dataplane\\nKim et al. [75] ✓ CORONET (controller-based robust network):\\nSDN fault-tolerant architectureRecovering from multiple\\nlink failures in the data plane\\nBorokhovichet ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1143: ('g rules\\nDesai et al.\\n[84]✓ An algorithm: checking connectivity among\\nneighboring switches for fast failure detection\\nby using the OpenFlow switch ’s link signalFast failure detection in SDN\\nKempf et al.\\n[46]✓ Extending the OpenFlow protocol to support\\na monitoring function on OpenFlow switchesAchieve fault management\\nand recovery in the dataplane\\nKim et al. [75] ✓ CORONET (controller-based robust network):\\nSDN fault-tolerant architectureRecovering from multiple\\nlink failures in the data plane\\nBorokhovichet al. [76]✓ Local –fast failover algorithms Guaranteeing quick\\nreestablishment ofconnectivity in the data plane\\nHeller et al.\\n[77]✓ Placing OpenFlow switch to the closest\\ncontroller in the networkOptimizing the number of\\ncontrollers and their locationin the network\\nTootoonchianet al. [17]✓ HyperFlow: a distributed event-based control\\nplane for OpenFlowRedundancy and minimizing\\nthe control plane response\\ntime to data plane requests\\nResilience to networkcomponent failures\\nKoponen et al.\\n[41],✓ Onix: a distributed control platform that\\nprovides a general-purpose API for control\\nplane implementationsTurning networking\\nproblems into resolvable\\ndistributing systemsproblems\\nBerde et al.\\n[85]✓ ONOS (open network operating system): a\\ndistributed SDN control platformProviding HA and scalability\\nthrough a distributed SDN\\ncontrol\\n(Continues )Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5812 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nFurthermore, redundancy of controllers is a fundamen-\\ntal pillar in the HA concept. There are some methods[80] to achieve this in real time in ord', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1144: ('2/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nFurthermore, redundancy of controllers is a fundamen-\\ntal pillar in the HA concept. There are some methods[80] to achieve this in real time in order to ensure HAand reliability. Designing a redundant architecture is one\\nof the main challenging operations in a highly available\\nSDN. Additionally, latency [81,82] is another major issuefacing the network providers. The latency does not onlyaffect the traf ﬁc but also the failover times, and thus, this\\ncomes at the cost of HA. There are several causes of lowlatencies, among which are low power RAM/CPU innetwork component, longer network update/upgrade time,congestion, and insuf ﬁcient bandwidth. Basically, latency\\nin SDN can be divided into three categories:\\n(1) Data plane latencies: Switches and routers or any\\nother network components in the data plane havetheir speci ﬁc characteristics that determine their\\ncapacity in terms of memory, CPU, and so on. Forinstance, in an OpenFlow (OF) switch there is aninbound and an outbound latency from thecontroller perspective:\\n(a)Inbound latency: Represents the time between re-\\nceiving a packet from the data plane and sendingit to the controller. First, the switch relies on theforwarding engine to send packet for a lookupin the rule table. Here, two cases may emerge:In case of (i) reactive OpenFlow operation mode,the OpenFlow agent performs a lookup in theﬂow tables. If there is no match, the switch\\nautomatically creates an OpenFlow “packet-in ”\\npacket and sends it to the controller for orders.(ii) In proactive mode, ﬂow tables are already\\nprede ﬁned and thus no need to consult the\\ncontroller for instructions. This could be advanta-geous in eliminating the latencies resu', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1145: ('es on theforwarding engine to send packet for a lookupin the rule table. Here, two cases may emerge:In case of (i) reactive OpenFlow operation mode,the OpenFlow agent performs a lookup in theﬂow tables. If there is no match, the switch\\nautomatically creates an OpenFlow “packet-in ”\\npacket and sends it to the controller for orders.(ii) In proactive mode, ﬂow tables are already\\nprede ﬁned and thus no need to consult the\\ncontroller for instructions. This could be advanta-geous in eliminating the latencies resulting incontacting a controller.\\n(b)Outbound latency: The switch receives the ﬂow\\nfrom the controller and then parses OpenFlow\\nmessages that hold new rules to be applied tothe OpenFlow switch ’sﬂow table. The whole\\nupdate process could take a long time.There is another mode of operation called Hybrid mode\\nwhen OpenFlow is used. In this mode, the combination ofproactive and reactive mode has been made to allow moreﬂexibility and maintain low latencies.\\n(2)Control plane latencies : In the control plane, the\\nlatencies associated with an SDN controller are In-put/Output (I/O) performance, processing, and ﬂow\\nsetup time. These performance metrics heavily in ﬂu-\\nence when additional SDN controllers are deployed.If the OF switches ﬁre out too much ﬂows, the\\ncontroller would take longer time to respond, andthus, the latency is increased.\\n(3)Interconnection latencies : These low latencies are\\nmeasurable and depend mainly on the physicalmedium capacity (i.e., bandwidth and throughput).Generally, interconnection latencies are negligible.\\nIn [83], the authors presented RuleBricks that tackles\\nHA issues in the data plane for servers. In [84] and [46],the authors proposed fast failure detection and fastrecovery mechanisms. Other works focus on management\\nin the control plane such as those in [41] and [85]. An\\nextended list of related works with further details ispresented in Table VII.\\n4.4. Reliability\\nReliability is another important aspect of SDN where the\\ndelivery should be noti ﬁed in case of failures. The service\\nprovid', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1146: ('es are negligible.\\nIn [83], the authors presented RuleBricks that tackles\\nHA issues in the data plane for servers. In [84] and [46],the authors proposed fast failure detection and fastrecovery mechanisms. Other works focus on management\\nin the control plane such as those in [41] and [85]. An\\nextended list of related works with further details ispresented in Table VII.\\n4.4. Reliability\\nReliability is another important aspect of SDN where the\\ndelivery should be noti ﬁed in case of failures. The service\\nproviders deploy reliable applications and services that no-tify the end user of an eventual delivery failure. Reliabilityspeciﬁcations indicate the guarantees that the delivery of\\ndata must concern only the intended recipient through reli-able SDN architecture and reliable protocols (Table VIII).\\nImproving reliability is of paramount importance be-\\ncause network failures could easily cause disconnections\\nbetween the control and forwarding plane. A reliable\\nSDN should work continuously under an augmentedworkload without dropping messages from the controlplane or the data plane.Table VII. (Continued)\\nReference Data plane Control plane Proposal Main purpose\\nCaiet al. [100] ✓ Maestro: a controller for scalable OpenFlow\\nnetwork controlImplementing parallelism to\\nimprove the capacity of thecontroller.\\nSharma et al.\\n[78]✓ Fast failure recovery mechanism in OpenFlow\\nnetworksFast restoration mechanism\\nin OpenFlow\\nPark et al. [79] Link between\\ndata plane andcontrol planesControl path HA\\nalgorithms betweenthe control and data\\nplane\\nVirtualized controllerclusterFast failure detection and recovery to ensure\\nhigh availability of SDN\\nHA, high availability; SDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5813 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1147: ('a\\nplane\\nVirtualized controllerclusterFast failure detection and recovery to ensure\\nhigh availability of SDN\\nHA, high availability; SDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5813 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nThe reliability of the control plane is very critical for\\nSDN because it is the brain of the production network. Ifthe control plane fails, the SDN networks will systemati-cally lose packet forwarding and running processes. SDNreliability [92] is hard to analyze because of its characteris-tics of software and hardware components and complicatedinteractions among them.\\nThere are several types of failures that may in ﬂuence\\nthe reliability of SDN such as over ﬂow, timeout, unreach-\\nable resources, software failure, database failure, hardwarefailure, and link failure. These types of failures might bedependent and should be considered when designingreliable SDN networks. For example, network failuresmay disable invocation among software programs toretrieve the necessary informations.\\nService providers should isolate faulty elements in case\\nof failures and minimize their impact on the quality ofexperience [93] in order to respect SLA and satisfy thecustomers.\\n5. PERFORMANCE\\nSoftware-de ﬁned networking offers ﬂexible and program-\\nmable functionalities as well as centralized control, betteruser experience, and a decrease in network systems and\\nequipment costs. However, the offered capabilities and fea-tures of SDN infrastructure in ﬂuence the whole network\\nperformance (e.g., latency, jitter, throughput, and errorrate). ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1148: ('e faulty elements in case\\nof failures and minimize their impact on the quality ofexperience [93] in order to respect SLA and satisfy thecustomers.\\n5. PERFORMANCE\\nSoftware-de ﬁned networking offers ﬂexible and program-\\nmable functionalities as well as centralized control, betteruser experience, and a decrease in network systems and\\nequipment costs. However, the offered capabilities and fea-tures of SDN infrastructure in ﬂuence the whole network\\nperformance (e.g., latency, jitter, throughput, and errorrate). In fact, SDN may pay performance penalties due toworkload of the network traf ﬁc that the OpenFlow-based\\nSDN [26] systems handle. The control plane is the mainbottleneck of the SDN architecture where performance isa critical issue especially in large-scale networkimplementations because a heavy request load on anSDN controller might result in longer delays.\\nSubstantially, facing the challenges of SDN perfor-\\nmance is following a mainstream pattern by deployingnew solutions for classical issues. Many existing mecha-nisms can still be used in order to properly manage SDNperformance such as quality of service [94], load balancing[95], end-to-end congestion control [96], and data traf ﬁc\\nscheduling [97].\\nThe performance analysis of network controllers is gen-\\nerally carried out through benchmarking. Benchmarking isa commonly used method for analyzing the performance ofthe controllers as well as identifying performance bottle-necks in order to take a decision of increasing power\\nprocessing capabilities of a controller. In several works,\\nthe benchmarking procedure has been performed onTable VIII. Reliability issues, solutions, and challenges.\\nReference Method/description Challenge/main purpose\\nShalimov et al.\\n[19]Conducting ef ﬁciency tests with HCPROBE framework to\\nshow whether the SDN/OpenFlow controllers are reliable\\nin production environmentReliability analysis reveals that NOX, POX, Beacon,\\nFloodlight, MuL, Maestro, and Ryu are capable of dealing\\nwith average workloads\\nHuet al. [86] Placing controllers in SDN to', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1149: ('ller. In several works,\\nthe benchmarking procedure has been performed onTable VIII. Reliability issues, solutions, and challenges.\\nReference Method/description Challenge/main purpose\\nShalimov et al.\\n[19]Conducting ef ﬁciency tests with HCPROBE framework to\\nshow whether the SDN/OpenFlow controllers are reliable\\nin production environmentReliability analysis reveals that NOX, POX, Beacon,\\nFloodlight, MuL, Maestro, and Ryu are capable of dealing\\nwith average workloads\\nHuet al. [86] Placing controllers in SDN to maximize the reliability of\\nSDN control plane and considering it as a novel reliabilitymetric called expected percentage of control path lossand analyzes the dependent control path failures in SDNShowing that the placement of controller is not the only\\nkey to reliability. This latter depends on properly choosingthe number of controllers\\nYao and Bi [87] The cascading failures of controllers can affect the\\nreliability of SDN. In fact, the load of the controllers thatcarries the load of the failed controller can exceed theircapacity, and then cascading failures of controllers willlikely occurDisclosing failure threat to reliability of SDN networks and\\nproposing a model of these failures to prevent them\\nRos et al. [88] Determining the fault-tolerant controller placement using\\nheuristic mechanism that executes placement algorithmin order to achieve at least “5 nines ”reliability in the\\nsouthbound interface between controllers and nodesDeploying fault-tolerant SDNs by achieving 99.999% of\\nsouthbound reliability between controllers and nodes(i.e., switches, routers, and middleboxes)\\nXiao et al. [89] An approach based on partitioning a large network into\\nseveral small SDN domains by using the spectral\\nclustering placement algorithm to solve SDN controllerplacement problem for WANMaximizing the reliability of controller and minimizing the\\nlatency of WAN using spectral clustering placement\\nalgorithm\\nCapone et al.\\n[90]A failure management framework for SDN that uses\\nOpenState (an OpenFlow extension) capabilities to allow', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1150: ('tween controllers and nodes(i.e., switches, routers, and middleboxes)\\nXiao et al. [89] An approach based on partitioning a large network into\\nseveral small SDN domains by using the spectral\\nclustering placement algorithm to solve SDN controllerplacement problem for WANMaximizing the reliability of controller and minimizing the\\nlatency of WAN using spectral clustering placement\\nalgorithm\\nCapone et al.\\n[90]A failure management framework for SDN that uses\\nOpenState (an OpenFlow extension) capabilities to allow\\nfast path restoration. The framework can handle link andnode failures. When a failure is detected on a link,packets are recovered through a detour pathEnabling reliability through a reliable and scalable\\nmechanism named OpenState to provide protection\\nagainst a link or node failure\\nPfeiffenberger\\net al. [90]Exploiting features of OpenFlow to provide one-link fault\\ntolerance with negligible packet loss. The used approach\\nallows low recovery times from link failures andcontinuity of fault toleranceEvaluating the use of SDN for reliable communication\\nSDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5814 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nexisting SDN controllers [43,98,99]. An improved version\\nof NOX has been developed for better performance, whichis known as NOX-MT. Various [99] controllers have beentested for performance including Floodlight, Beacon,NOX-MT, and Maestro. The authors concluded that theperformance of OpenFlow-based controllers varies, de-pending on architectural features like packet batching,switch partitioning, ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1151: ('s) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nexisting SDN controllers [43,98,99]. An improved version\\nof NOX has been developed for better performance, whichis known as NOX-MT. Various [99] controllers have beentested for performance including Floodlight, Beacon,NOX-MT, and Maestro. The authors concluded that theperformance of OpenFlow-based controllers varies, de-pending on architectural features like packet batching,switch partitioning, and multicore support. They have no-ticed that the controllers that implement static switchpartitioning and static batching have high throughput per-formance. In contrast, controllers with adaptive batchingtechnique have reasonable latency performances.Benchmarking on NOX, NOX-MT, Maestro, and Beaconhas shown performance advantages of NOX-MT over theothers in terms of minimum and maximum response time,as well as maximum throughput. The NOX-MT controllerexploits multithreading based on the single thread C++ im-plementation of the network operating system (NOX) [43].The NOX-MT uses optimization techniques such as I/Obatching to improve baseline performance. These optimi-zations allow NOX-MT to outperform NOX by a factorof 33 on a server with two quad-core 2 GHz processors.Maestro [18,100] is a Java-based controller implementa-\\ntion. It utilizes both parallelism and throughput optimiza-\\ntion technique (e.g., input and output batching and coreand thread binding). It was revealed, in benchmarking, thatthe Maestro design can guarantee good performances andnear linear performance scalability on multicoreprocessors. In [101], the authors have used the standardCbench [27] tool to conduct performance tests in termsof latency and throughput of both OpenDaylight andFloodlight controllers. They have found that benchmarkingresults of OpenDaylight with Cbench have not been verysuccessful and claimed that the controller experiencedseveral memory issues like memory leakage. The Cbenchtool tests controller performance by generat', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1152: ('design can guarantee good performances andnear linear performance scalability on multicoreprocessors. In [101], the authors have used the standardCbench [27] tool to conduct performance tests in termsof latency and throughput of both OpenDaylight andFloodlight controllers. They have found that benchmarkingresults of OpenDaylight with Cbench have not been verysuccessful and claimed that the controller experiencedseveral memory issues like memory leakage. The Cbenchtool tests controller performance by generating requestsfor packet forwarding rules and watching responses fromthe controller. Cbench offers aggregated statistics ofcontroller throughput and response time for all theswitching devices. Aggregated statistics may not besufﬁcient enough to explore detailed controller behavior.Consequently, another tool named OFCBenchmark [28]\\nis considered to enable ﬁne-grained statistics.\\nOFCBenchmark provides statistics of response rate, re-sponse time, and number of unanswered packets for indi-vidual switching devices.\\nBenchmarks have been also conducted for the data\\nplane components. In [102], the authors comparedOpenFlow switching, layer-2 Ethernet switching, andlayer-3 IP routing performance and showed higherforwarding performance and better fairness of Linuxsoftware SDN switching. As performance indicators, theyhave used forwarding throughput and packet latencyforwarding throughput and packet latency under overload.\\nIn [103] and [104], mechanisms have been proposed to\\nincrease the performance of OpenFlow using an architec-tural model to improve the lookup performance ofOpenFlow switching. In [103], packet switching through-put increases to 25% compared with the throughput ofregular software-based OpenFlow switching. However, in[104], the authors have used network processor-basedacceleration cards to perform OpenFlow switching. Theresults have shown 20% reduction on packet delaycompared with classical models.\\nA framework called OpenFLow Operations Per Second\\n(OFLOPS) has been introduced to facilitate performancebenchma', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1153: ('chitec-tural model to improve the lookup performance ofOpenFlow switching. In [103], packet switching through-put increases to 25% compared with the throughput ofregular software-based OpenFlow switching. However, in[104], the authors have used network processor-basedacceleration cards to perform OpenFlow switching. Theresults have shown 20% reduction on packet delaycompared with classical models.\\nA framework called OpenFLow Operations Per Second\\n(OFLOPS) has been introduced to facilitate performancebenchmarks. OFLOPS supports multiple packet generationand capturing mechanisms [105]. OFLOPS allowsmeasurement of performance metrics for control planeoperations such as rule insertion delay and traf ﬁc statistic\\nquery delay as well as detailed performance measurementdata plane operations of SDN switching devices.\\nIn the literature, three main methods have been pro-\\nposed to enhance the performance of SDN: The ﬁrst one\\nis by handling request in the data plane on behalf of thecontroller [16,39], the second method is by structuringthe switching devices [42], and the third is byimplementing power processing mechanisms such asmultiple-core processing and mutithreading [43]. When itcomes to SDN, the tradeoffs between high performanceand programmability/ ﬂexibility should be carefully\\nconsidered (Figure 7 and Table IX).\\nFigure 7. Performance and programmability.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5815 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n6. RESILIENCE\\nAchieving resilient communication is a top purpose of\\nnetworking. As such, SDNs are expected to yield the samel', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1154: ('ons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n6. RESILIENCE\\nAchieving resilient communication is a top purpose of\\nnetworking. As such, SDNs are expected to yield the samelevels of reliability as a legacy and any new alternativetechnology. SDN architecture is resilient when it has theability to operate under load, failures, and attacks.\\nGenerally, resilience is based on both reliability and\\nsecurity concepts. As far as SDN is concerned, resilience\\nis the ability of one or more components of the SDNarchitecture to, either in the control plane or data plane,recover quickly and continue operating even when thereTable IX. Performance issues, solutions, and challenges.\\nReference Method/description Challenge/main purpose\\nYuet al. [16] Request handling in the data plane by distributing rules\\nacross “authority switches ”Ensuring low latencies by eliminating the need to ask the\\ncontroller for rules\\nCurtis et al.\\n[39]DevoFlow installs a given set of possible packet\\nforwarding rules in switching devicesOffering equal-cost multipath routing in case of port\\nfailures\\nYeganeh andGanjali [42]Kandoo is a layered architecture: The bottom layer is a\\ncluster of controllers with limited network view thathandles frequent events. The top layer is a logically\\ncentralized controller that has clear view and only handles\\nrare events. Heavy communication only occurs at thebottom layerImproving the overall control layer performance and\\nscalability by reorganizing the structure of switches\\nTootoonchian\\net al. [43]Enhancement of network operating system (NOX) to\\nsupport multithreadingIncreasing performances in terms of response times as\\nwell as throughput\\nKhattak et al.\\n[101]Performing benchmarking on OpenDayl', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1155: ('w thathandles frequent events. The top layer is a logically\\ncentralized controller that has clear view and only handles\\nrare events. Heavy communication only occurs at thebottom layerImproving the overall control layer performance and\\nscalability by reorganizing the structure of switches\\nTootoonchian\\net al. [43]Enhancement of network operating system (NOX) to\\nsupport multithreadingIncreasing performances in terms of response times as\\nwell as throughput\\nKhattak et al.\\n[101]Performing benchmarking on OpenDaylight SDN\\ncontroller and comparing latency and throughput resultswith Floodlight ’s benchmarksCarrying out a performance analysis and an evaluation of\\nOpenDaylight SDN controller\\nZhou et al.\\n[106]Using a caching mechanism for data network applications\\nwith SDN to speed up the service of northbound REST\\nAPIIncreasing the performance and maintaining ﬂexibility of\\nnorthbound REST API\\nEgilmez et al.\\n[107]OpenQoS is an approach for video streaming over\\nOpenFlow networks with dynamic QoS routing to ful ﬁll\\nend-to-end QoS support, which is possible with\\nOpenFlow ’s centralized control capabilities over the\\nnetworkGuaranteeing seamless video delivery through\\nprioritization in the control plane\\nXiong et al.\\n[108]Investigation of SDN ’s performance management of\\nanalytical queries in distributed data stores in a sharednetworking environment and analyzing the priority of\\nnetwork traf ﬁc in order to make network bandwidth\\nreservationsIncreasing performance management of analytical\\nqueries in distributed data stores through bandwidthreservations using queuing theory\\nWendong\\net al. [109]AQSDN: in AQSDN architecture, QoS features can be\\nconﬁgured autonomically in an OpenFlow switch by\\nextending the OpenFlow/OF Con ﬁg protocols. A QoS\\nmodel named packet context-aware QoS is suggested to\\nimprove the network QoSIntroducing a packet context-aware QoS model to provide\\nself con ﬁguration and high QoS in AQSDN architecture\\nMachado\\net al. [110]Policy re ﬁnement approach for QoS management: a\\nmethod that is capable of identifying QoS r', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1156: ('h bandwidthreservations using queuing theory\\nWendong\\net al. [109]AQSDN: in AQSDN architecture, QoS features can be\\nconﬁgured autonomically in an OpenFlow switch by\\nextending the OpenFlow/OF Con ﬁg protocols. A QoS\\nmodel named packet context-aware QoS is suggested to\\nimprove the network QoSIntroducing a packet context-aware QoS model to provide\\nself con ﬁguration and high QoS in AQSDN architecture\\nMachado\\net al. [110]Policy re ﬁnement approach for QoS management: a\\nmethod that is capable of identifying QoS requirementsand the resources that need to be con ﬁgured in\\naccordance with the SLAs based on uses of policy-based\\nmanagementAiming at removing manual workload of con ﬁguring\\nnetwork elements and implementing reactive dynamicactions to recon ﬁgure the SDN components and meet the\\nSLA requirements\\nJarschel et al.\\n[26]Analyzing the processing time, the forwarding speed, and\\nthe blocking in the forwarding queue to the controllerPresenting a model that helps in showing the importance\\nof the controller performance\\nJarschel et al.\\n[28]OFCBenchmark tool helps in conducting ﬂexible\\nbenchmarks to analyze the SDN controller performanceAchieving a ﬂexible OpenFlow controller benchmark\\nOF group\\n[111]Performance tests of NOX Beacon and Maestro\\ncontrollersProviding a performance comparison of SDN controllers:\\nNOX Beacon and Maestro\\nLiuet al. [112] Performance analysis of GMPLS-based, PCE/ GMPLS-\\nbased, and OpenFlow-based control planes for a\\ntranslucent wavelength switched optical networkAnalyzing the integration of the PCE with GMPLS\\nAQSDN, autonomic QoS management mechanism in software-de ﬁned network; SDN, software-de ﬁned networking; QoS, quality of service; SLA, service\\nlevel agreement; PCE, path computation element; API, application programming interface; GMPLS, Generalized multiprotocol label switching.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5816 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1157: ('with GMPLS\\nAQSDN, autonomic QoS management mechanism in software-de ﬁned network; SDN, software-de ﬁned networking; QoS, quality of service; SLA, service\\nlevel agreement; PCE, path computation element; API, application programming interface; GMPLS, Generalized multiprotocol label switching.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5816 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nhas been an equipment failure, power outage, or other\\ndisruption. SDN resilience should be planned as a part ofSLA to ensure continuous computing services.\\nAs the SDN network can be prone to failures, the devel-\\nopment of the OpenFlow protocol version 1.2 has includedthe capability of applying master –slave con ﬁguration to\\ndeal with faulty OpenFlow controllers and increase resil-ience. This indicates that a master controller has controlover all switches and on the master failure state; a backupcontroller (slave) can take the lead through a timely detec-tion of failure and fast failover process.\\nTo build a resilient network, the network topology must\\nconsider different challenges [29]. For instance, it must in-clude redundant paths between network nodes and ensurean identical synchronized network state between masterand slave controllers.\\nAdditionally, the inclusion of new modules and compo-\\nnents into the network should abide by the requirementswithout degrading the network performance and causingfailures.Several works have been proposed to increase network\\nresilience (Table X). The proposed research papers mainlydeal with replication [113], overlay networks [96,114,115],multihoming [115', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1158: ('For instance, it must in-clude redundant paths between network nodes and ensurean identical synchronized network state between masterand slave controllers.\\nAdditionally, the inclusion of new modules and compo-\\nnents into the network should abide by the requirementswithout degrading the network performance and causingfailures.Several works have been proposed to increase network\\nresilience (Table X). The proposed research papers mainlydeal with replication [113], overlay networks [96,114,115],multihoming [115,116] and multipath networking [89 –91].\\nResilience can be modeled as an unforeseeable cycle\\nthat starts from an SDN normal state, where every networknode behaves as intended and delivers an acceptableservice and communicates without any disruption undernormal operation S\\n0,to unacceptable service delivery un-\\nder severely degraded service S c. Anomalies are detected\\nearly to prevent failures or at least enable a partiallydegraded network to recover afterwards. However,escaping from severely degraded zone S\\ncto initial state\\nS0requires a successful remediation and then a fast recov-\\nery. Figure 8 illustrates a multilevel two-dimensional statespace that is characterized by two axes representing theoperational state N (horizontal) and service parameters P(vertical). This model is commonly used to identifypotential network threats and failures so as to anticipateand react in real time to ensure network resilience.\\nTable X. Resilience issues, solutions, and challenges.\\nReference Proposal Main purpose/challengeResilience\\n(technique)\\nFonseca\\net al. [113]Active and passive replication: In passive mode, the\\nclient connects with one controller that handles therequests and informs the rest of controllers. In activemode, the client communicates with multiple\\ncontrollersAs SDN relies on the control plane, this poses the\\nissue of a single point of failure. With replicationtechniques, SDN can be more resilient to failuresReplication\\nRohrer\\net al. [117]Path diversi ﬁcation to select multiple path metrics\\nfor evaluating path, ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1159: ('ilience\\n(technique)\\nFonseca\\net al. [113]Active and passive replication: In passive mode, the\\nclient connects with one controller that handles therequests and informs the rest of controllers. In activemode, the client communicates with multiple\\ncontrollersAs SDN relies on the control plane, this poses the\\nissue of a single point of failure. With replicationtechniques, SDN can be more resilient to failuresReplication\\nRohrer\\net al. [117]Path diversi ﬁcation to select multiple path metrics\\nfor evaluating path, node pair, and graph diversity.The path diversi ﬁcation mechanism is targeted at\\nthe end-to-end layer but can be applied at any level\\nfor which a path discovery service is available (e.g.,\\nintrarealm routing or interrealm routing)Improving ﬂow robustness in the presence of link\\nand node failures. Path diversi ﬁcation provides a\\nsubstantial performance improvement overconventional single-path mechanismsMultipath\\nZhang\\net al. [114]ROMCA allows combining centralized topology\\nconstruction control and distributed dynamic\\nmapping of paths onto the overlay topology\\naccording to network conditionsMitigating the shortcomings of the network\\ninfrastructure and providing resilience with low\\nrecovery times in response to network failuresOverlay-\\nbased\\nAkella\\net al. [116]Multihoming where data centers or enterprise\\nnetworks are connected to multiple providers couldincrease network resiliency if the right ISPs are\\nchosenImproving network performance and resilience\\nthrough multihomingMultihoming\\nHan et al.\\n[115]Using source-based single-hop overlay routing\\ncombined with a topology-aware node deploymentand increasing the usage of multihomingenvironmentDesigning a topology-aware network overlay using\\nmultihoming in order to enhance the resiliencepropertiesOverlay-\\nbased/multihoming\\nLiet al.\\n[118]SmartTunnel is a logical end-to-end tunnel between\\ntwo end points that combines several physicalnetwork paths. These paths forming the tunnel arechosen to be topologically diverseEnsuring resilience by strategically allocating traf ﬁc\\non', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1160: ('based single-hop overlay routing\\ncombined with a topology-aware node deploymentand increasing the usage of multihomingenvironmentDesigning a topology-aware network overlay using\\nmultihoming in order to enhance the resiliencepropertiesOverlay-\\nbased/multihoming\\nLiet al.\\n[118]SmartTunnel is a logical end-to-end tunnel between\\ntwo end points that combines several physicalnetwork paths. These paths forming the tunnel arechosen to be topologically diverseEnsuring resilience by strategically allocating traf ﬁc\\nonto multiple paths and performing forward errorcorrection codingMultipath\\nChiu et al.\\n[119]CORONET is an SDN fault-tolerant system that\\nrecovers from multiple link failures in the data plane.\\nCORONET uses information about the network statecoming from physical network routers, in particular,optical network routersUsing multipath in CORONET to provide a complete\\nfault-tolerant system that recovers from failures\\noccurring in other fault domains in SDN-basednetworksMultipath\\nCORONET, controller-based robust network; SDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5817 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n7. SDN SECURITY\\n7.1. Software-de ﬁned networking:\\nvulnerabilities\\nWhile SDN provides a new network design enabling a\\nwide range of network applications and services, security\\nconcerns have become an important pillar, as security isnot yet a built-in feature in the SDN architecture. Beingbased on existing technologies (e.g., routers, switches,servers, applications, etc.), it inherits systematically its re-lated security issues rangi', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1161: ('of use; OA articles are governed by the applicable Creative Commons License\\n\\n7. SDN SECURITY\\n7.1. Software-de ﬁned networking:\\nvulnerabilities\\nWhile SDN provides a new network design enabling a\\nwide range of network applications and services, security\\nconcerns have become an important pillar, as security isnot yet a built-in feature in the SDN architecture. Beingbased on existing technologies (e.g., routers, switches,servers, applications, etc.), it inherits systematically its re-lated security issues ranging from physical to applicationlayer of the Open Systems Interconnection model. However,SDN has brought new network elements (e.g., controllers,virtualized components, etc) and various applications intothe core network with a new splitting design.\\nDecoupling the data plane from the control plane would\\neliminate some existing minor threats in traditional net-work, but it has created new loopholes speci ﬁc to SDN.\\nAs SDN mainly relies on various software in the appli-\\ncation layer to interact with the underlying infrastructure,this has surely major drawbacks because code vulnerabil-ities can have a serious security impact. Additionally, bymaking the controller as the central location for manage-ment and control, this would result in creating a point offailure for the whole infrastructure. Controllers could bethreatened from different sides (i.e., interfaces). The south-bound and the northbound interfaces are respectively theentrance doors to the control, which themselves might bean appealing target for attackers. The data plane is also apotential target for attackers. Because of the exchanges be-\\ntween the control and data planes, an attacker could disruptthe data ﬂow by ﬂooding the switches or tampering the\\ncommunications. The OpenFlow protocol responsible forestablishing communications between the two planes canalso be vulnerable to some attacks [120].\\nThe SDN vulnerabilities [24,25,120 –126] can be\\nrepartitioned into ﬁve major axes (Figure 9):\\n1)Application layer : These are software-related\\nvulnerabilities th', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1162: ('s. The data plane is also apotential target for attackers. Because of the exchanges be-\\ntween the control and data planes, an attacker could disruptthe data ﬂow by ﬂooding the switches or tampering the\\ncommunications. The OpenFlow protocol responsible forestablishing communications between the two planes canalso be vulnerable to some attacks [120].\\nThe SDN vulnerabilities [24,25,120 –126] can be\\nrepartitioned into ﬁve major axes (Figure 9):\\n1)Application layer : These are software-related\\nvulnerabilities that might be exploited through codeinjection. Some works have been proposed to tacklecommon issues of the application layer. Such issuesinclude the challenge of detecting and reconcilingpotentially con ﬂicting ﬂow rules from OF apps\\n(FortNOX [127]) and dealing with networkapplications ’failures leading to loss of network\\ncontrol (ROSEMARY [128]), and enabling networkresilience to SDN application failures and faults(LegoSDN [129]).\\n2)Control layer : This includes vulnerabilities\\nassociated with the controller. Major works havebeen proposed in the literature to identify andmitigate/reduce vulnerabilities of the controller.Othman and Okamura [130] present a signaturealgorithm to securely transmit ﬂow installation\\nrequests from the controller to the network devices.The system assumes using secure communicationwith TLS so as to avoid the control channel frombeing tampered. In [131], the authors proposed an\\nFigure 8. Multilevel two-dimensional state space.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5818 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nalgorithm that offers a', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1163: ('ougui and A. Elbelrhiti Elalaoui\\n5818 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nalgorithm that offers a secure and resilient SDN\\narchitecture through the implementation of severalfault-tolerant controllers. A hierarchical system ofcontrollers is identi ﬁed in [132] to reduce the impact\\nof a malicious application that can lead to point offailures in the control plane. Other works such asformal methods [133 –136] have been proposed to verify\\nand prove the safety and correctness of the SDN controlplane and resolve issues related to security policies.\\n3)APIs: The control plane exposes two types of APIs:\\nvertical (i.e., southbound and northbound) and hori-zontal (i.e., eastbound, westbound, and managementinterface). The issue of exposing interfaces isdiscussed in [137]. The authors proposed PermOFthat applies minimum privilege on the applicationsto enforce permissions at the API entry. Similarworks have been introduced in [138] and [139],where the authors have mainly pinpointed the lack\\nof security in the communication processes betweenOpenFlow applications and the control plane. As asolution, the Security-Enhanced Floodlight is pro-posed that offers an authenticated northbound API.Another system named Frenetic [140] also focuseson the northbound API to resolve policy con ﬂicts.\\n4)Protocols : In OpenFlow-based SDN architecture, the\\nOpenFlow protocol can be exposed to variousthreats according to vulnerability assessments[120], among which is the TLS security layer thathas been considered as optional in the speci ﬁcation\\nof the OpenFlow protocol. A de ﬁnition of security\\nrequirements and a detailed analysis of theOpenF', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1164: (' Floodlight is pro-posed that offers an authenticated northbound API.Another system named Frenetic [140] also focuseson the northbound API to resolve policy con ﬂicts.\\n4)Protocols : In OpenFlow-based SDN architecture, the\\nOpenFlow protocol can be exposed to variousthreats according to vulnerability assessments[120], among which is the TLS security layer thathas been considered as optional in the speci ﬁcation\\nof the OpenFlow protocol. A de ﬁnition of security\\nrequirements and a detailed analysis of theOpenFlow protocol are presented in [25] and [8].\\n5)Infrastructure layer : Vulnerabilities related to data\\nplane components (e.g., switchs, and routers) could\\nFigure 9. Various threats/attacks against SDN.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5819 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nengender different attack vectors such as fraudulent\\nrule insertion, rule modi ﬁcations, and ﬂooding\\n[120]. FlowChecker [141] has been introduced tosolve issues of miscon ﬁgurations in OpenFlow\\nswitches causing variance in ﬂow rules. Anteater\\n[142] is a similar work that introduces a static analy-sis approach to diagnose network con ﬁguration\\nproblems. OFHIP [143] is proposed to provide se-cure mobility with OpenFlow to avoid disruptedﬂow processing, active TLS session teardown, and\\nmutual authentication issues.\\n7.2. Software-de ﬁned networking: threats\\nand attacks\\nVulnerabilities in the management, application control,\\nand data planes entail different threats for the SDN modeland could be classi ﬁed into four categories depending on\\nthe motivations:\\n(1)Internal : Internal thr', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1165: ('roduces a static analy-sis approach to diagnose network con ﬁguration\\nproblems. OFHIP [143] is proposed to provide se-cure mobility with OpenFlow to avoid disruptedﬂow processing, active TLS session teardown, and\\nmutual authentication issues.\\n7.2. Software-de ﬁned networking: threats\\nand attacks\\nVulnerabilities in the management, application control,\\nand data planes entail different threats for the SDN modeland could be classi ﬁed into four categories depending on\\nthe motivations:\\n(1)Internal : Internal threats come from the inside of\\nSDN, generally from authorized individuals who\\ncan have full access to the SDN network (e.g., man-\\naging applications, modifying security policies, pro-gramming scripts for SDN, etc). Accordingimproperly high privileges can lead to seriousmalicious actions [127,137,144] into the networkeither being intentional or accidental. Although in-tentional malicious activities are rare, they are themost dangerous threats for a productive network.\\nAccidental undesired network manipulations arealso non-negligible, which can cause undesiredtrafﬁc or network loops.\\n(2)External : External threats are mainly initiated from\\nthe outside of the corporate network and aimed ataltering the SDN network by relying on denial ofservice (DoS) attacks (Table XVI) or trying to haveunauthorized access (Table XV) by relying onadvanced techniques such as malwares [61], socialengineering, man in the middle, and spoo ﬁng\\n(Table XII).\\n(3)Unstructured : Generally, this type of threat comes\\nfrom script kiddies, bugs/miscon ﬁgurations, or\\nconﬂicting rules [141,145] in the SDN components\\n(e.g., applications, security policies, con ﬂicting rule\\ntables in the switches, etc.).\\n(4)Structured : This threat can entail very sophisticated\\nattacks leading to serious damages in the SDN net-work. In fact, this threat comes from high-leveltechnically skilled attackers who can penetrate intonetworks by varying their advanced techniques(e.g., spoo ﬁng, code exploits, social engineering,\\nmalwares, etc.). Skilled hackers can join their ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1166: ('miscon ﬁgurations, or\\nconﬂicting rules [141,145] in the SDN components\\n(e.g., applications, security policies, con ﬂicting rule\\ntables in the switches, etc.).\\n(4)Structured : This threat can entail very sophisticated\\nattacks leading to serious damages in the SDN net-work. In fact, this threat comes from high-leveltechnically skilled attackers who can penetrate intonetworks by varying their advanced techniques(e.g., spoo ﬁng, code exploits, social engineering,\\nmalwares, etc.). Skilled hackers can join their forces\\nand lead an organized crime against organizationsand network providers.\\nThe attackers can lead one or more attacks depending\\non their motivations and skills. Generally, attacks againstSDN can be classi ﬁed into two types: passive and active\\nTable XI. Anomalies and scanning attacks.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nMehdi et al.\\n[146]Anomaly detection algorithms that use\\nOpenFlow ﬂow information for traf ﬁc\\nanomaly detection including the detection of\\nscanning wormsExploiting programmability of SDN to provide\\naccurate anomaly detection capabilities in\\nhome networkingIN/EX\\nST\\nUSTAC/\\nPSCT/\\nSB/\\nAP\\nHand et al. [147] Exploiting the programmability of SDN\\ninfrastructure to provide active security bysensing and countering threatsNetwork control in order to detect intrusions,\\nmemory content capture, and scanningIN/EX\\nSTUSTAC/\\nPSCT/\\nSB/AP/\\nDT\\nJafarian et al.\\n[148]OpenFlow Random Host Mutation where\\nhosts ’identities should be continuously and\\nrandomly changed by mutating IP addressesOpenFlow Random Host Mutation deceives\\nhosts ’scanning attacks and IP address\\ndiscoveryIN/EX\\nSTUSTAC/\\nPSCT/\\nSBDT\\nKampanakis\\net al. [149]SDN-based moving target defense network\\nprotection enables increasing the attacker ’s\\noverhead and obfuscation to confuse theattackerProviding protection against reconnaissance,\\nﬁngerprinting, and service discoveryIN/EX\\nST\\nUSTPS CT/\\nSB/\\nAP/DT\\nGiotis et al. [150] Solution architecture combines OpenFlow\\nand sFlow where ﬂow statistics are gathere', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1167: ('hanged by mutating IP addressesOpenFlow Random Host Mutation deceives\\nhosts ’scanning attacks and IP address\\ndiscoveryIN/EX\\nSTUSTAC/\\nPSCT/\\nSBDT\\nKampanakis\\net al. [149]SDN-based moving target defense network\\nprotection enables increasing the attacker ’s\\noverhead and obfuscation to confuse theattackerProviding protection against reconnaissance,\\nﬁngerprinting, and service discoveryIN/EX\\nST\\nUSTPS CT/\\nSB/\\nAP/DT\\nGiotis et al. [150] Solution architecture combines OpenFlow\\nand sFlow where ﬂow statistics are gathered\\nand analyzed to identify anomalies that are\\nneutralized by an anomaly mitigation moduleEnabling anomaly detection and mitigation\\nagainst network attacks such as port\\nscanning attacks, worm propagation, and\\noverloads due to potential DoS attacksIN/EX\\nST\\nUSTAC/\\nPSCT/\\nSB/\\nAP/\\nDT\\nType of threat –EX, External; IN, Internal; ST, Structured; UST, Unstructured. Type of attack –AC, Active; PS, Passive. SDN layer/API –CT, Control plane; DT,\\nData plane; SB, southbound; NB, northbound; OF, OpenFlow; AP, application plane; SDN, software-de ﬁned networking.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5820 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nattacks. In a typical scenario, a sophisticated attack com-\\nbines the two modes of attacks. In the ﬁrst mode, the at-\\ntacker is only interested in monitoring, gatheringinformation, eavesdropping message contents, and analyz-ing the traf ﬁc in order to identify IP addresses, open ports,\\nand active services and communications by using scanningtools. Afterwards, on the basis of the collected data aboutthe network and the identi ﬁed po', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1168: ('of use; OA articles are governed by the applicable Creative Commons License\\n\\nattacks. In a typical scenario, a sophisticated attack com-\\nbines the two modes of attacks. In the ﬁrst mode, the at-\\ntacker is only interested in monitoring, gatheringinformation, eavesdropping message contents, and analyz-ing the traf ﬁc in order to identify IP addresses, open ports,\\nand active services and communications by using scanningtools. Afterwards, on the basis of the collected data aboutthe network and the identi ﬁed potential holes, he or she\\ncan proceed to an active attack so as to gain illegitimateaccess for spying and/or exhaust a resource or service inthe SDN infrastructure, which is known as a DoS attack(Tables XI –XVI).\\nSeveral countermeasures have been proposed in the\\nliterature to eliminate or mitigate SDN threats in the\\nTable XII. IP and ARP spoo ﬁng.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nMatias et al.\\n[151]Address resolution mapping is an\\nembedded module in the controller thatveriﬁes MAC addresses from authorized\\nusers or hosts by tracking themMitigating ARP poisoning attacks\\nthat could take place between thecontroller and OF switchesIN/EX\\nSTAC/\\nPSCT/\\nSB/DT\\nYao et al. [152] Solving the address resolution problem\\nwith the help of OpenFlow VAVE. VAVEis a module that examines the records intheﬂow tableEnabling protection feature against\\nIP spoo ﬁng, on a NOX-based\\nOpenFlow controller, which couldlead to DoS attackIN/EX\\nSTAC/\\nPSCT/\\nSB/DT\\nYao et al. [153] Software-de ﬁnedﬁltering architecture is\\na method based on VAVE. Software-\\ndeﬁnedﬁltering architecture allows\\nadding ﬁltering rules based on spoo ﬁng\\noccurrencesEnhancing VAVE to counter IP\\nspoo ﬁng by applying new ﬁltering\\nrulesIN/EX\\nSTAC/\\nPSCT/\\nSB/\\nDT\\nFeng et al. [154] Extending the solution of VAVE using\\nOpenRouter where every router has a\\nglobal network view of addressassignmentAdding the support of IP spoo ﬁng\\ndetecting through OpenFlow routersIN/EX\\nSTAC/\\nPSCT/\\nSB/\\nDT\\nSDN, software-de ﬁned networking; VAVE, v', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1169: ('e-de ﬁnedﬁltering architecture is\\na method based on VAVE. Software-\\ndeﬁnedﬁltering architecture allows\\nadding ﬁltering rules based on spoo ﬁng\\noccurrencesEnhancing VAVE to counter IP\\nspoo ﬁng by applying new ﬁltering\\nrulesIN/EX\\nSTAC/\\nPSCT/\\nSB/\\nDT\\nFeng et al. [154] Extending the solution of VAVE using\\nOpenRouter where every router has a\\nglobal network view of addressassignmentAdding the support of IP spoo ﬁng\\ndetecting through OpenFlow routersIN/EX\\nSTAC/\\nPSCT/\\nSB/\\nDT\\nSDN, software-de ﬁned networking; VAVE, virtual source address validation edge; API, application programming interface; ARP, Address Resolution\\nProtocol.\\nTable XIII. Tampering and information disclosure.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nMeyer and\\nSchwenk [155]Overview on attacks and countermeasures on\\nthe TLS handshake protocol, the TLS record andapplication data protocols and the PKI\\ninfrastructure of TLSIdentifying current SSL/TLS security\\nconcerns in OpenFlow. SSL/TLS is anoptional security featureIN/EX\\nSTPS CT/\\nSB/OF\\nBenton et al.\\n[120]Overview of man in the middle attacks that are\\ncurrently seen to be a signi ﬁcant possible threat\\nin the current OpenFlow architectureDiscussing man in the middle attack,\\nwhich is an information disclosure attackthat targets information in transitIN/EX\\nSTPS CT/\\nSB/OF\\nSchehlmann and\\nBaier [179]COFFEE is a framework that enables detection\\nand mitigation of botnets. The detection is based\\non NetFlow to ﬁlter, detect, and alter SDN\\ncomponentsCountering botnets that can lead to data\\nmodi ﬁcation or disclosureIN/EX\\nSTPS AP/\\nCT/\\nSB/OF\\nKloti et al. [25] Security analysis and modeling methodology for\\nthe OpenFlow protocol and network using\\nSTRIDE [156]Discussing vulnerabilities such as\\ninformation disclosure and denial of\\nserviceIN/EX\\nSTPS AP/\\nCT/\\nSB/\\nOF\\nPKI, Public Key Infrastructure; SSL, Secure Socket Layer.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5821 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wil', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1170: ('ts that can lead to data\\nmodi ﬁcation or disclosureIN/EX\\nSTPS AP/\\nCT/\\nSB/OF\\nKloti et al. [25] Security analysis and modeling methodology for\\nthe OpenFlow protocol and network using\\nSTRIDE [156]Discussing vulnerabilities such as\\ninformation disclosure and denial of\\nserviceIN/EX\\nSTPS AP/\\nCT/\\nSB/\\nOF\\nPKI, Public Key Infrastructure; SSL, Secure Socket Layer.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5821 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nTable XIV. Privilege escalation.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nPorras et al.\\n[127]Fort-Nox is a ﬂow-based authorization\\nsystem that provides various securitycomponents such as security audit trail forﬂow rule commands, rules ’conﬂicts, and\\nresolution outcomes by exploiting\\ninformation like application ID, privilege\\nlevel, and ﬂow timeFort-Nox helps in detecting and handling\\nconﬂicts of ﬂow rules from OF apps and\\nproviding security enforcement kernel forprioritizing ﬂow rules with role-based\\nauthorizationIN/EX\\nSTAC/\\nPSCT/\\nSBNB/OF\\nWen et al. [137] PermOF is an access control system that\\nrelies on a set of permissions and anisolation technique to deal with permissions\\nat the API entry by applying privilege\\nrestrictions to applicationsProtecting SDN from privilege escalation\\nand unauthorized access on the controlplaneIN/EX\\nSTPS AP/NB\\nHayward et al.\\n[144]Operation-Checkpoint is a permission\\nsystem that de ﬁnes a set of permissions\\nagainst which applications must be checked\\nbefore being authorized to executionLimiting the exposure of the control plane to\\napplication pl', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1171: ('cess control system that\\nrelies on a set of permissions and anisolation technique to deal with permissions\\nat the API entry by applying privilege\\nrestrictions to applicationsProtecting SDN from privilege escalation\\nand unauthorized access on the controlplaneIN/EX\\nSTPS AP/NB\\nHayward et al.\\n[144]Operation-Checkpoint is a permission\\nsystem that de ﬁnes a set of permissions\\nagainst which applications must be checked\\nbefore being authorized to executionLimiting the exposure of the control plane to\\napplication plane in order to avoid SDNapplication layer attacksIN/EX\\nSTUSTAC/\\nPSAP/\\nCT/NB\\nTable XV. SDN intrusions and unauthorized access.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nCasado et al.\\n[157]SANE system provides a single\\nprotection layer where controller\\nincludes access control rules insteadof having them in ﬁrewalls as in\\ntraditional networksLogically centralizing routing and\\naccess control decisions to allow or\\ndeny access. SANE offers morevisibility on security policiesIN/EX\\nST\\nUSTAC/\\nPSCT/\\nSBDT\\nJia and Wang\\n[158]SDN-based ﬁrewalls for P2P\\nnetworks that are provided as an API\\nfor SDN. Due to the nature of P2Pnetworks, SDN requires speci ﬁc\\nsecurity mechanism to preventintrusionsNetwork demand is frequently\\nchanging and P2P ﬁrewall solution\\nshould be integratedIN/EX\\nST\\nUSTAC/\\nPSCT/\\nSBDT/\\nAP\\nKatta et al. [159] Flog implements stateful ﬁrewalls in\\norder to inspect connection statesfrom insiders by analyzing alreadyestablished communicationsImplementation of stateful ﬁrewalls to\\ndetect possible malicious codeIN/EX\\nSTUSTAC/\\nPSAP/\\nNBDT/CT\\nHayward et al.\\n[144]Operation-Checkpoint is a permission\\nsystem that de ﬁnes a set of\\npermissions against whichapplications must be checked beforebeing authorized to executionLimiting the exposure of the control\\nplane to application plane in order to\\navoid SDN application layer attacksIN/EX\\nST\\nUSTAC/\\nPSAP/CT\\nNB\\nMattos et al.\\n[170]AuthFlow is based on a RADIUS\\nauthentication system where anauthenticator handles authenticationrequest', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1172: ('teful ﬁrewalls to\\ndetect possible malicious codeIN/EX\\nSTUSTAC/\\nPSAP/\\nNBDT/CT\\nHayward et al.\\n[144]Operation-Checkpoint is a permission\\nsystem that de ﬁnes a set of\\npermissions against whichapplications must be checked beforebeing authorized to executionLimiting the exposure of the control\\nplane to application plane in order to\\navoid SDN application layer attacksIN/EX\\nST\\nUSTAC/\\nPSAP/CT\\nNB\\nMattos et al.\\n[170]AuthFlow is based on a RADIUS\\nauthentication system where anauthenticator handles authenticationrequests between hosts and theRADIUS server and then provides a\\nresponse to the OpenFlow controller\\nthat allows or denies traf ﬁcStrengthening the network security\\non the basis of authentication and\\naccess controlIN/EX\\nSTUSTAC/\\nPSCT/DT\\nSB\\n(Continues )Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5822 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nTable XV. (Continued)\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nDangovas et al.\\n[160]AAA-SDN is an access control system\\nto enforce SDN security. The access\\ncontrol system uses the controller toauthenticate switches/hosts and tomanage ﬂows and user/host mobilityPreventing security issues of\\nunauthorized access of hosts to SDNIN/EX\\nST\\nUSTAC/\\nPSCT/DT\\nSB\\nZhu et al. [161] SFA is a stateful forwarding\\nabstraction in the SDN data plane that\\nuses a forwarding processor toperform packet inspectionEnabling packet inspection that may\\nrequire upper layers (L4 –L7)\\ninformationIN/EX\\nST\\nUSTAC/\\nPSAP/\\nCTNB/\\nSB DT\\nStoenescu\\net al. [162]Sym-Net is a tool used to model basic\\nstateful middleboxes that', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1173: ('he controller toauthenticate switches/hosts and tomanage ﬂows and user/host mobilityPreventing security issues of\\nunauthorized access of hosts to SDNIN/EX\\nST\\nUSTAC/\\nPSCT/DT\\nSB\\nZhu et al. [161] SFA is a stateful forwarding\\nabstraction in the SDN data plane that\\nuses a forwarding processor toperform packet inspectionEnabling packet inspection that may\\nrequire upper layers (L4 –L7)\\ninformationIN/EX\\nST\\nUSTAC/\\nPSAP/\\nCTNB/\\nSB DT\\nStoenescu\\net al. [162]Sym-Net is a tool used to model basic\\nstateful middleboxes that perform\\nstateful checking in order to help in\\nmaking contextual ﬁrewall decisions\\nthat depend on L2 to L7 informationGathering all network layer\\ninformation to have a global view to\\nperform stateful inspectionsIN/EX\\nST\\nUSTAC/\\nPSAP/\\nCTNB/\\nSB DT\\nFayaz and Sekar\\n[163]FlowTest is a tool that allows testing\\nﬁrewall policies in SDN in order to\\nmake accurate decision regarding\\nﬂow states as some SDN policies\\nhave no knowledge about a traf ﬁc\\nstate in the L4 and thus making an\\ninappropriate decision by relying only\\non L2/L3 informationTesting stateful behaviors in the data\\nplane to support the process of\\nstateful inspection in L4 for a valid\\ndecision because states are indicatedper TCP connectionsIN/EX\\nST\\nUSTAC/\\nPSCT/\\nNBSB/\\nDT\\nSkowyra et al.\\n[164]Learning intrusion detection system is\\nan OpenFlow-based NIDS. Learning\\nintrusion detection system takes\\nadvantage of the OpenFlow SDN\\narchitecture, and anomalies aredeﬁned based on several\\ncharacteristics: packets sent,position, time passed, size, etc.Anomaly detection processes are\\nbuilt into the OpenFlow network toidentify intrusions in embedded\\nmobile devicesIN/EX\\nSTUSTAC/\\nPSCT/OF\\nSB/DTAP\\nTable XVI. DoS attacks.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nShin et al. [171] Avant-Guard consists of limiting the\\nﬂow requests sent to the control\\nplane using a connection migrationtool that removes failed TCPsessions at the data planeHandling and mitigating DoS attacks\\nas well as eliminating their impact onthe networkIN/EX\\nSTAC ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1174: ('cesses are\\nbuilt into the OpenFlow network toidentify intrusions in embedded\\nmobile devicesIN/EX\\nSTUSTAC/\\nPSCT/OF\\nSB/DTAP\\nTable XVI. DoS attacks.\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nShin et al. [171] Avant-Guard consists of limiting the\\nﬂow requests sent to the control\\nplane using a connection migrationtool that removes failed TCPsessions at the data planeHandling and mitigating DoS attacks\\nas well as eliminating their impact onthe networkIN/EX\\nSTAC CT/\\nDTSB\\nFonseca et al.\\n[113]CPRecovery provides network\\nresilience through a transition fromthe failed primary controller to abackup controllerQuick and seamless backup to\\nsecondary controller in case of DoSattack on the primary controllerEX/\\nINSTUSTAC CT/DT/\\nSB\\nNaous et al.\\n[173]Ident++ protocol queries end hosts/\\nnetwork on the path of a ﬂow for\\nadditional information in order tomake forwarding decisions. In thisway end hosts participate in security\\nenforcementDynamic ﬂow table management\\nand distributed control help inreducing the impact of DoS attackEX/\\nINSTUSTAC CT/DT/\\nSB/APNB/OF\\n(Continues )Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5823 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\ndata/control plane, API, and in the OpenFlow protocol. In\\n[127 –129], the authors discussed application failures and\\ntheir risk in SDN implementations and respectivelyproposed FortNOX, ROSEMARY, and LegoSDN to dealwith application issues. In terms of securely implementingthe SDN, a number of solutions have been presented suchas FRESCO [165], OFHIP [143], Secure SDMN [166],and De', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1175: ('rms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\ndata/control plane, API, and in the OpenFlow protocol. In\\n[127 –129], the authors discussed application failures and\\ntheir risk in SDN implementations and respectivelyproposed FortNOX, ROSEMARY, and LegoSDN to dealwith application issues. In terms of securely implementingthe SDN, a number of solutions have been presented suchas FRESCO [165], OFHIP [143], Secure SDMN [166],and Debugger for SDN [167]. For unauthorized accessissues in SDN, several work have been presented likeSecuring Distributed Control [130], Byzantine-ResilientSDN [131], Authentication for Resilience [132],PermOF [137], Operation Checkpoint [114],\\nSE-Floodlight [168], Flowtags [169], and AuthFlow[170]. In [113,143,166,171 –179], analysis, enhancements,\\nand solutions to counter DoS attacks have beenpresented. Other works, as shown in the followingtables, deal with IP/ARP spoo ﬁng attacks (Table XII),\\nSDN intrusions (Table XV), tampering (Table XIII),\\nand anomalies/scanning attacks (Table XI). For clearvisibility, we have classi ﬁed the existing works\\ndepending on the security threats they can fully orpartially address.Table XVI. (Continued)\\nCountermeasure Method/description Purpose/challengeType\\nof\\nthreatType\\nof\\nattackSDN\\nlayer/\\nAPI\\nBraga et al. [174] The system monitors OpenFlow\\nswitches registered to an NOX\\ncontroller at regular intervals toretrieve traf ﬁc data for analysisAchieving DDoS attack detection\\nbased on statistical information with\\nself-organizing maps to classifytrafﬁc as normal or maliciousEX/\\nINST\\nUSTAC/\\nPSCT/SB/\\nAP/OF\\nSuh et al. [175] CONA is based on an OpenFlow\\nagent to detect DDoS as soon as a\\nrate of requests from a given host to\\na content server exceeds aprede ﬁned valueOpenFlow agent is used to intercept\\ncontent request messages in order\\nto analyzed them so as to mitigate\\nagainst DDoS attacksEX/\\nINSTAC/\\nPSCT/\\nDTSB/\\nAP\\nYuHunag et al.\\n[176]DDoS defender uses locator/ID\\nseparation protocol to detect', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1176: ('statistical information with\\nself-organizing maps to classifytrafﬁc as normal or maliciousEX/\\nINST\\nUSTAC/\\nPSCT/SB/\\nAP/OF\\nSuh et al. [175] CONA is based on an OpenFlow\\nagent to detect DDoS as soon as a\\nrate of requests from a given host to\\na content server exceeds aprede ﬁned valueOpenFlow agent is used to intercept\\ncontent request messages in order\\nto analyzed them so as to mitigate\\nagainst DDoS attacksEX/\\nINSTAC/\\nPSCT/\\nDTSB/\\nAP\\nYuHunag et al.\\n[176]DDoS defender uses locator/ID\\nseparation protocol to detect and\\ndrop DDoS traf ﬁc based on traf ﬁc\\nvolume. Locator is changing and ID isunchanged that help in identifyingauthorized/malicious hostsDDoS attack is detected based on\\ntrafﬁc analysis. For a given host, if\\nthe rate of traf ﬁc exceeds a\\nthreshold, then, the traf ﬁc is dropped\\nby the controllerEX/\\nIN/STAC/\\nPSCT/\\nDTSB/\\nAP\\nLim et al. [177] DDoS blocking application counters\\nbotnet-based attack by monitoring\\nﬂow metrics in the SDN controller to\\ndetect DDoS attacks and blockbotnetsHelping in detecting and blocking\\nDDoS in case of botnet-based\\nattacksEX/\\nINSTAC/\\nPSCT/\\nDTSB/\\nAP\\nZaalouk et al.\\n[178]OrchSec utilizes network monitoring\\ncapabilities and SDN control to\\ndevelop security applicationsThis architecture helps in detecting\\nand overcoming DoS, worms, andDNS ampli ﬁcation attacksEX/\\nINSTUSTAC/\\nPSCT/\\nDTSB/AP\\nSchehlmannet al. [179]COFFEE utilizes SDN capabilities to\\nparse all network traf ﬁc in order to\\nmake more accurate detections and\\nreduce the rate of false detectionsDetect and mitigate botnets based\\non an OpenFlow detection approach.\\nBotnets are used to perform DDoS\\nattacksEX/\\nINSTAC/\\nPSCT/\\nDTSB/\\nAP\\nNamal et al.\\n[143]Switch mobility and secure change\\nof IP addressesResilience against known TCP\\nattacks to securely change IPaddress during OF switch mobilityEX/\\nINSTAC/\\nPSSB\\nLiyanage et al.\\n[166]Secure SDMN uses a security layer\\nto coordinate the communicationbetween the controller and theOpenFlow switchesExtended version of OFHIP to tackle\\nthe issues in the software-de ﬁned\\nmobile network control channelEX/\\nINSTA', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1177: ('enFlow detection approach.\\nBotnets are used to perform DDoS\\nattacksEX/\\nINSTAC/\\nPSCT/\\nDTSB/\\nAP\\nNamal et al.\\n[143]Switch mobility and secure change\\nof IP addressesResilience against known TCP\\nattacks to securely change IPaddress during OF switch mobilityEX/\\nINSTAC/\\nPSSB\\nLiyanage et al.\\n[166]Secure SDMN uses a security layer\\nto coordinate the communicationbetween the controller and theOpenFlow switchesExtended version of OFHIP to tackle\\nthe issues in the software-de ﬁned\\nmobile network control channelEX/\\nINSTAC/\\nPSSB\\nBenton et al.\\n[120]Assessment of OpenFlow\\nvulnerabilities for DoS attacksThey showed that OpenFlow\\nprotocol and its related\\ncommunication mechanismsbetween controller and switchesshould be thoroughly investigatedEX/\\nINST\\nUSTAC/\\nPSOF/SB\\nSDN, software-de ﬁned networking; SDMN, Software de ﬁned mobile networks; DOS, denial of service; DDoS, distributed denial of service.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5824 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n8. SUMMARY AND CONCLUSION\\nWe have investigated the issues/challenges as well as the\\nsolutions for SDN in terms of scalability, elasticity, de-pendability, reliability, high availability, resiliency, secu-rity, and performance. As SDN is a new networkingapproach, several solutions to classical network problemshave been revisited using this architecture, and many prob-lems continue to be challenging. In this paper, we tried tosimplify and explain each SDN issue and provided anoverall view. It is important to note that the landscape ofSDN-related issues changes according to the advances inSDN development', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1178: ('r SDN in terms of scalability, elasticity, de-pendability, reliability, high availability, resiliency, secu-rity, and performance. As SDN is a new networkingapproach, several solutions to classical network problemshave been revisited using this architecture, and many prob-lems continue to be challenging. In this paper, we tried tosimplify and explain each SDN issue and provided anoverall view. It is important to note that the landscape ofSDN-related issues changes according to the advances inSDN development. For instance, a new design modi ﬁca-\\ntion or protocol introduced to SDN API might bring a\\nnew solution and at the same time incur new challengesor issues. Furthermore, many challenges in SDN still needfurther research attention such as the standardization ofSDN components and adoption of new speci ﬁc protocols\\ndesigned to SDN in order to avoid inherited problems fromthe legacy networks. Research must focus more on thecontrol plane to come up with novel solutions for control-lers, which are the brains of the SDN architecture. The con-trol plane is a point of failure of the whole network, andmany security measures should be considered. Also, newHA and performance mechanisms should be implementedto abide by the SLA and deliver services accordingly.Service providers are willing to meet carrier-grade SDNrequirements by ensuring scalability, reliability, andresilience of their infrastructure. However, by adopting anextensive range of sophisticated features into their\\nnetworks, reliability of SDN becomes a challenging goal.\\nIn fact, this is challenging when it comes to sticking withservice requirements and respect today ’s telecommunica-\\ntion and network commitments in terms of fast fault\\nFigure 10. Major challenges and objectives for a carrier-grade SDN.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5825 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1179: ('ging goal.\\nIn fact, this is challenging when it comes to sticking withservice requirements and respect today ’s telecommunica-\\ntion and network commitments in terms of fast fault\\nFigure 10. Major challenges and objectives for a carrier-grade SDN.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5825 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nmanagement, detection and recovery, prevention from\\nunauthorized access and Dos attacks, high throughput,very low latency, and software upgrades and patches.\\nFigure 10 summarizes all SDN challenges to be consid-\\nered when designing a resilient SDN network, which is stillan open research area. To achieve resilience, the serviceproviders must deploy secure components/policies andreliable mechanisms. As for dependability, both highlyavailable and reliable infrastructures are required to ensurea continuous and reliable service delivery to endcostumers. Elasticity and scalability are also two importantgoals in designing carrier-grade networks, but those can beonly established in a highly available network with lowlatencies and high performance.\\nREFERENCES\\n1. Naudts B, Kind M, Westphal FJ, Verbrugge S, Colle\\nD, Pickavet M. Techno-economic analysis of soft-\\nware de ﬁned networking as architecture for the\\nvirtualization of a mobile network. Software De ﬁned\\nNetworking (EWSDN ),European Workshop on .\\nIEEE, 2012, pp. 67 –72.\\n2. Benson T, Akella A, Maltz D. Unraveling the com-\\nplexity of network management. Proc.6th USENIX\\nSymp .Networked Syst .Design Implement . USENIX\\nAssociation, 2009, pp. 335 –348.\\n3. Floodlight controller, Floodlight docu', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1180: ('formance.\\nREFERENCES\\n1. Naudts B, Kind M, Westphal FJ, Verbrugge S, Colle\\nD, Pickavet M. Techno-economic analysis of soft-\\nware de ﬁned networking as architecture for the\\nvirtualization of a mobile network. Software De ﬁned\\nNetworking (EWSDN ),European Workshop on .\\nIEEE, 2012, pp. 67 –72.\\n2. Benson T, Akella A, Maltz D. Unraveling the com-\\nplexity of network management. Proc.6th USENIX\\nSymp .Networked Syst .Design Implement . USENIX\\nAssociation, 2009, pp. 335 –348.\\n3. Floodlight controller, Floodlight documentation, for\\ndevelopers, architecture. [Online]. Retrieved from:http://www.project ﬂoodlight.org/ ﬂoodlight/.\\n4. OpenDaylight: a Linux Foundation Collaborative\\nProject, 2014. [Online]. Retrieved from: http://www.opendaylight.org.\\n5. Erickson D. The Beacon OpenFlow controller. Pro-\\nceedings of the Second ACM SIGCOMM Workshopon Hot Topics in Software De ﬁned Networking .\\nACM, 2013, pp. 13 –18.\\n6. Casado M, Freedman M, Pettit J, Luo J, McKeown\\nN, Shenker S. Ethane: Taking control of the enter-\\nprise. Proceedings of the 2007 Conference on Appli-\\ncations ,Technologies ,Architectures ,and Protocols\\nfor Computer Communications . ACM, 2007, pp. 12.\\n7. McKeown N, Anderson T, Balakrishnan H, et al.\\nOpenFlow: enabling innovation in campus networks.ACM SIGCOMM Computer Communication Review\\n2008; 38(2):69 –74.\\n8. Open Networking Foundation Security Working\\nGroup. [Online]. Retrieved from: https://www.\\nopennetworking.org/technical-communities/areas/\\nservices.\\n9. Doria A, Salim JH, Haas R, et al. Forwarding and\\nControl Element Separation (ForCES) protocol spec-\\niﬁcation, RFC 5810 (proposed standard), 2010.[online]. Available: https://datatracker.ietf.org/doc/\\nrfc5810/.\\n10. Yang L, Dantu R, Anderson T, Gopal R. Forwarding\\nand Control Element Separation (ForCES) frame-\\nwork, RFC 3746 (Informational), 2004. Available\\n[online] : http://datatracker.ietf.org/doc/rfc3746/.\\n11. Farrel A, Vasseur JP, Ash J. A path computation ele-\\nment (PCE)-based architecture (No. RFC 4655). 2006.\\n12. Rodriguez-Natal A, Barkai S, Ermagan V, Lewis D', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1181: ('ement Separation (ForCES) protocol spec-\\niﬁcation, RFC 5810 (proposed standard), 2010.[online]. Available: https://datatracker.ietf.org/doc/\\nrfc5810/.\\n10. Yang L, Dantu R, Anderson T, Gopal R. Forwarding\\nand Control Element Separation (ForCES) frame-\\nwork, RFC 3746 (Informational), 2004. Available\\n[online] : http://datatracker.ietf.org/doc/rfc3746/.\\n11. Farrel A, Vasseur JP, Ash J. A path computation ele-\\nment (PCE)-based architecture (No. RFC 4655). 2006.\\n12. Rodriguez-Natal A, Barkai S, Ermagan V, Lewis D,\\nMaino F, Farinacci D. Software de ﬁned networking\\nextensions for the locator/ID separation protocol, in-\\nternet draft (experimental), 2014. Available [online]:http://wiki.tools.ietf.org/id/draft-rodrigueznatal-lisp-\\nsdn-00.txt.\\n13. Lakshman TV, Nandagopal T, Ramjee R, Sabnani K,\\nWoo T. The SoftRouter architecture. Proceedings of\\nthe ACM Workshop on Hot Topics in Networks\\n(\\nHotNets ), San Diego, CA, USA, 2004.\\n14. Brocade Communications Systems, Network trans-\\nformation with software-de ﬁned networking and\\nEthernet fabrics, California, USA. [online]. Avail-able: http://www.brocade.com/downloads/docu-\\nments/positioningpapers/network-transformation-\\nsdn-wp.pdf, 2012.\\n15. Benzekki K, El Fergougui A, ElBelrhiti ElAlaoui A.\\nA secure cloud computing architecture using homo-\\nmorphic encryption. International Journal of Ad-\\nvanced Computer Science & Applications 2016;\\n1(7):293 –298.\\n16. Yu M, Rexford J, Freedman MJ, Wang J. Scalable\\nﬂow-based networking with DIFANE. SIGCOMM\\nComputer Communication Review 2010;\\n41(4):351 –362.\\n17. Tootoonchian A, Ganjali Y. HyperFlow: a distributed\\ncontrol plane for OpenFlow. Proceedings of the 2010\\nInternet Network Management Conference on Re-search on Enterprise Networking . USENIX Associa-\\ntion, 2010, p. 3.\\n18. Cai Z. Maestro: achieving scalability and coordina-\\ntion in centralized network control plane, Ph.D.dis-\\nsertation , Rice Univ., Houston, TX, USA, 2011.\\n19. Shalimov A, Zuikov D, Zimarina D, Pashkov V,\\nSmeliansky R. Advanced study of SDN/OpenFlow\\ncontrollers. Proceedings of th', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1182: ('351 –362.\\n17. Tootoonchian A, Ganjali Y. HyperFlow: a distributed\\ncontrol plane for OpenFlow. Proceedings of the 2010\\nInternet Network Management Conference on Re-search on Enterprise Networking . USENIX Associa-\\ntion, 2010, p. 3.\\n18. Cai Z. Maestro: achieving scalability and coordina-\\ntion in centralized network control plane, Ph.D.dis-\\nsertation , Rice Univ., Houston, TX, USA, 2011.\\n19. Shalimov A, Zuikov D, Zimarina D, Pashkov V,\\nSmeliansky R. Advanced study of SDN/OpenFlow\\ncontrollers. Proceedings of the 9th Central and East-\\nern European Software Engineering Conference inRussia . ACM, 2013, p.1.\\n20. Rimal BP, Jukan A, Katsaros D, Goeleven Y. Archi-\\ntectural requirements for cloud computing systems:an enterprise cloud approach. Journal of Grid Com-\\nputing 2011; 9:3–26.\\n21. Armbrust M, Fox A, Grif ﬁth R, et al. A view of cloud\\ncomputing. Communication of the ACM, ACM 2010;\\n53(4):50 –58.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5826 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n22. Dixit A, Hao F, Mukherjee S, Lakshman T, Kompella\\nR. Towards an elastic distributed SDN controller. In\\nProceedings of the Second ACM SIGCOMM Work-\\nshop on Hot Topics in Software De ﬁned Networking,\\nser. HotSDN ’13. ACM: New York, NY, USA, 2013;\\n7–12.\\n23. Dixit A, Hao F, Mukherjee S, Lakshman TV,\\nKompella R. ElastiCon: an elastic distributed SDN\\ncontroller. Proceedings of the Tenth ACM /IEEE Sym-\\nposium on Architectures for Networking and Commu-\\nnications Systems . ACM, 2014, pp. 17 –28.\\n24. Scott-Hayward S, O ’Callaghan G,Sezer S. SDN secu-\\nrity: a survey, IEEE SDN for Future Networks ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1183: ('ted SDN controller. In\\nProceedings of the Second ACM SIGCOMM Work-\\nshop on Hot Topics in Software De ﬁned Networking,\\nser. HotSDN ’13. ACM: New York, NY, USA, 2013;\\n7–12.\\n23. Dixit A, Hao F, Mukherjee S, Lakshman TV,\\nKompella R. ElastiCon: an elastic distributed SDN\\ncontroller. Proceedings of the Tenth ACM /IEEE Sym-\\nposium on Architectures for Networking and Commu-\\nnications Systems . ACM, 2014, pp. 17 –28.\\n24. Scott-Hayward S, O ’Callaghan G,Sezer S. SDN secu-\\nrity: a survey, IEEE SDN for Future Networks and\\nServices (SDN4FNS ), 2013, pp. 1 –7.\\n25. Kloeti R. OpenFlow: a security analysis. April 2013.\\n[Online]. Available: ftp://yosemite.ee.ethz.ch/pub/\\nstudents/2012-HS/MA-2012-20signed.pdf.\\n26. Jarschel M, Oechsner S, Schlosser D, Pries R, Goll S,\\nTranGia P. Modeling and performance evaluation of\\nan OpenFlow architecture. Teletraf ﬁc Congress\\n(ITC), 2011 23rd International, Sept 2011, pp. 1 –7.\\n27. Cbench (Controller Benchmarker). [Online]. Avail-\\nable: http://www.open ﬂow.org/wk/index.php/O ﬂops\\n28. Jarschel M, Lehrieder F, Magyari Z, Pries R. A ﬂex-\\nible OpenFlow-controller benchmark. Proc.EWSDN ,\\n2012, pp. 48 –53\\n29. Tipper D. Resilient network design: challenges and\\nfuture directions. Telecommunication Systems 2014;\\n56(1):5 –16.\\n30. Avi žienis A, Laprie JC, Randell B, Landwehr C. Ba-\\nsic concepts and taxonomy of dependable and secure\\ncomputing, Dependable and Secure Computing ,\\nIEEE Transactions on . IEEE, 2004, pp. 11 –33.\\n31. PatelP, Ranabahu AH, Sheth AP. Service level agree-\\nment in cloud computing, 2009.\\n32. Gude N, Koponen T, Pettit J, et al. NOX: towards an\\noperating system for networks. ACM SIGCOMM Com-\\nputer Communication Review 2008; 38(3):105 –110.\\n33. Maestro platform. [Online]. Available: http://code.\\ngoogle.com/p/maestro-platform/.\\n34. Trema, full-stack OpenFlow framework in Ruby and\\nC. [Online]. Available: http://trema.github.com/trema/.\\n35. Manthena MPV, van Adrichem NL, van den Broek\\nC, Kuipers F. An SDN-based architecture for\\nnetwork-as-a-service.\\n36. Pfaff B, Pettit J, Amidon K, Casado M, ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1184: ('09.\\n32. Gude N, Koponen T, Pettit J, et al. NOX: towards an\\noperating system for networks. ACM SIGCOMM Com-\\nputer Communication Review 2008; 38(3):105 –110.\\n33. Maestro platform. [Online]. Available: http://code.\\ngoogle.com/p/maestro-platform/.\\n34. Trema, full-stack OpenFlow framework in Ruby and\\nC. [Online]. Available: http://trema.github.com/trema/.\\n35. Manthena MPV, van Adrichem NL, van den Broek\\nC, Kuipers F. An SDN-based architecture for\\nnetwork-as-a-service.\\n36. Pfaff B, Pettit J, Amidon K, Casado M, Koponen T,\\nShenker S. Extending networking into thevirtualization layer. Proc.HotNets . 2009.\\n37. Wang A, Iyer M, Dutta R, Rouskas GN, Baldine I.\\nNetwork virtualization: technologies, perspectives,and frontiers. Journal of Lightwave Technology\\n2013; 31(4):523 –537.38. Manthena MPV. Network-as-a-service architecture\\nwith SDN and NFV: a proposed evolutionary ap-\\nproach for service provider networks, Doctoral dis-\\nsertation , TU Delft, Delft University of Technology.\\n2015.\\n39. Curtis AR, Mogul JC, Tourrilhes J, Yalagandula P,\\nSharma P, Banerjee S. DevoFlow: scaling ﬂow man-\\nagement for high-performance networks. Comput.\\nCommun. Rev. 2011; 41(4):254 –265.\\n40. Mogul JC, Congdon P. Hey, you darned counters!:\\nGet off my ASIC!. Proceedings of the First Workshop\\non Hot Topics in Software De ﬁned Networks ,ser.\\nHotSDN ’12. New York, NY, USA. ACM, 2012,\\npp. 25 –30.\\n41. Koponen T, Casado M, Gude N, et al. Onix: a\\ndistributed control platform for large-scale produc-\\ntion networks. In Proceedings of the 9th USENIX\\nConference on Operating Systems Design and Im-plementation, ser. OSDI ’10. USENIX Association:\\nBerkeley, CA, USA, 2010; 1 –6.\\n42. Hassas Yeganeh S, Ganjali Y. Kandoo: a framework\\nfor ef ﬁcient and scalable of ﬂoading of control applica-\\ntions. In Proceedings of the First Workshop on Hot\\nTopics in Software De ﬁned Networks, ser. HotSDN ’12.\\nACM: New York, NY, USA, 2012; 19 –24.\\n43. Tootoonchian A, Gorbunov S, Ganjali Y, Casado M,\\nSherwood R. On controller performance in software-deﬁned networks. Proc.2nd USENIX Conf', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1185: ('ce on Operating Systems Design and Im-plementation, ser. OSDI ’10. USENIX Association:\\nBerkeley, CA, USA, 2010; 1 –6.\\n42. Hassas Yeganeh S, Ganjali Y. Kandoo: a framework\\nfor ef ﬁcient and scalable of ﬂoading of control applica-\\ntions. In Proceedings of the First Workshop on Hot\\nTopics in Software De ﬁned Networks, ser. HotSDN ’12.\\nACM: New York, NY, USA, 2012; 19 –24.\\n43. Tootoonchian A, Gorbunov S, Ganjali Y, Casado M,\\nSherwood R. On controller performance in software-deﬁned networks. Proc.2nd USENIX Conf .Hot-ICE\\nNetw .Serv.USENIX Association, 2012, p. 10.\\n44. Sherwood R, Gibb G, Yap K-K, et al. FlowVisor: a\\nnetwork virtualization layer, Deutsche Telekom Inc.\\nR&D Lab, Stanford, Nicira Networks, Tech. Rep.,\\n2009.\\n45. Luo T, Tan H-P, Quan P, Law YW, Jin J. Enhancing\\nresponsiveness and scalability for OpenFlow net-\\nworks via control-message quenching. Proceedings\\nof International Conference on ICT Convergence\\n(ICTC ).IEEE, 2012, pp. 348 –353.\\n46. Kempf J, Bellagamba E, Kern A, Jocha D, Takacs A,\\nSkoldstrom P. Scalable fault management for\\nOpenFlow. Proceedings of IEEE International\\nConference on Communications (ICC). IEEE, 2012,\\npp. 6606 –6610.\\n47. Veisllari R, Stol N, Bjornstad S, Raffaelli C.\\nScalability analysis of SDN-controlled optical ringMAN with hybrid traf ﬁc.Communications (ICC),\\nIEEE International Conference on . IEEE, 2014,\\npp. 3283 –3288.\\n48. Park SH, Lee B, You J, Shin J, Kim T, Yang S.\\nRAON: recursive abstraction of OpenFlow networks.\\nProceedings of the Third European Workshop onSoftware De ﬁned Networks (EWSDN ). IEEE, 2014,\\npp. 115 –116.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5827 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for r', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1186: ('Networks (EWSDN ). IEEE, 2014,\\npp. 115 –116.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5827 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n49. Benzekki K, El Fergougui A, ElBelrhiti ElAlaoui A.\\nDevolving IEEE 802.1X authentication capability to\\ndata plane in software de ﬁned networking (SDN)\\narchitecture. Security and Communication Networks ,\\n9(17), 4369 –4377.\\n50. Voellmy A, Wang J. Scalable software de ﬁned net-\\nwork controllers. Proc.ACM SIGCOMM Conf .Appl.,\\nTechnol .,Archit .,Protocols Comput .Commun .\\nACM, 2012, pp. 289 –290.\\n51. Krishnamurthy A, Chandrabose SP, Gember-\\nJacobson A. Pratyaastha: An ef ﬁcient elastic distrib-\\nuted SDN control plane. Proceedings of the Third\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworking ,ser.HotSDN ’14. New York, NY, USA.\\nACM, 2014, pp. 133 –138.\\n52. Bari MF, Roy AR, Chowdhury SR, et al. Dynamic\\ncontroller provisioning in software de ﬁned networks.\\n9th International Conference on Network and ServiceManagement, ser. CNSM ’13, 2013.\\n53. Rajagopalan S,Williams D, Jamjoom H, War ﬁeld A.\\nSplit/merge: system support for elastic execution invirtual middleboxes. NSDI . USENIX Association,\\n2013, pp. 227 –240.\\n54. Fang L, Chiussi F, Bansal D, et al. Hierarchical SDN\\nfor the hyper-scale, hyper-elastic data center and\\ncloud. Proceedings of the 1st ACM SIGCOMM Sym-\\nposium on Software De ﬁned Networking Research .\\nACM, 2015, p. 7.\\n55. Aissioui A, Ksentini A, Gueroui A, Taleb T. Towards\\nelastic distributed SDN/NFV controller for 5Gmobile cloud management systems, IEEE. 2015.\\n56. Mueller J, Wierz A, Vingarzan D, Magedanz T.\\nElastic netwo', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1187: ('ic execution invirtual middleboxes. NSDI . USENIX Association,\\n2013, pp. 227 –240.\\n54. Fang L, Chiussi F, Bansal D, et al. Hierarchical SDN\\nfor the hyper-scale, hyper-elastic data center and\\ncloud. Proceedings of the 1st ACM SIGCOMM Sym-\\nposium on Software De ﬁned Networking Research .\\nACM, 2015, p. 7.\\n55. Aissioui A, Ksentini A, Gueroui A, Taleb T. Towards\\nelastic distributed SDN/NFV controller for 5Gmobile cloud management systems, IEEE. 2015.\\n56. Mueller J, Wierz A, Vingarzan D, Magedanz T.\\nElastic network design and adaptive ﬂow\\nplacement in software de ﬁned networks. Computer\\nCommunications and Networks (ICCCN ),2013 22nd\\nInternational Conference on . IEEE, 2013, pp. 1 –6.\\n57. Vegad M. Elasticity in virtual middleboxes using\\nNFV/SDN, Doctoral dissertation , Indian Institute of\\nTechnology, Bombay. 2015.\\n58. Longo F, Distefano S, Bruneo D, Scarpa M. Depend-\\nability modeling of software de ﬁned networking.\\nComputer Networks 2015; 83.\\n59. Wu J, Huang Y, Kong J, Tang Q, Huang X. A study\\non the dependability of software de ﬁned networks.\\nInternational Conference on Materials Engineeringand Information Technology Applications (MEITA\\n2015 ). Atlantis Press. 2015.\\n60. Kreutz D, Ramos F, Verissimo P. Towards secure\\nand dependable software-de ﬁned networks. Proceed-\\nings of the Second ACM SIGCOMM Workshop on\\nHot Topics in Software De ﬁned Networking . ACM,\\n2013, pp. 55 –60.61. Jansen W. Cloud hooks: security and privacy issues\\nin cloud computing. System Sciences (HICSS ),44\\nthe Hawaii International Conference on . IEEE,\\n2011, 1 –10.\\n62. Ahuja SP, Komathukattil D. A survey of the state of\\ncloud security. Network and Communication Tech-\\nnologies 2012; 1(2):66.\\n63. Link aggregation control protocol (LACP), http://\\nwww.cisco.com/c/en/us/td/docs/ios/122sb/feature/guide/gigeth.html, Mar. 2007.\\n64. EtherChannels, http://www.cisco.com/c/en/us/td/\\ndocs/switches/lan/catalyst3550/software/release/12-113ea1/con ﬁguration/guide/3550scg /?swethchl.\\nhtml.\\n65. IP multicast load splitting –equal cost multipath\\n(ECMP), http://www.cisco.', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1188: ('EE,\\n2011, 1 –10.\\n62. Ahuja SP, Komathukattil D. A survey of the state of\\ncloud security. Network and Communication Tech-\\nnologies 2012; 1(2):66.\\n63. Link aggregation control protocol (LACP), http://\\nwww.cisco.com/c/en/us/td/docs/ios/122sb/feature/guide/gigeth.html, Mar. 2007.\\n64. EtherChannels, http://www.cisco.com/c/en/us/td/\\ndocs/switches/lan/catalyst3550/software/release/12-113ea1/con ﬁguration/guide/3550scg /?swethchl.\\nhtml.\\n65. IP multicast load splitting –equal cost multipath\\n(ECMP), http://www.cisco.com/c/en/us/td/docs/ios/\\n122sr/122srb/feature/guide/srbmpath.html.\\n66. Virtual router redundancy protocol (VRRP) version 3\\nfor IPv4 and IPv6, http://tools.ietf.org/html/rfc5798,\\nMar. 2010.\\n67. Cisco hot standby router protocol (HSRP), https://\\nwww.ietf.org/rfc/rfc2281.txt, Mar. 1998.\\n68. Resilient packet ring (RPR), http://www.ieee802.org/\\n17/docu-ments.htm.\\n69. Non-stop routing (NSR), http://www.cisco.com/c/en/\\nus/td/docs/iosxml/ios/iprouteospf/con ﬁguration/15-e/\\niro-15-e-book/iro-nsr-ospf.html.\\n70. Graceful OSPF restart: non-stop forwarding (NSF),\\nhttp://tools.ietf.org/html/rfc3623, Nov. 2003.\\n71. Stateful switch-over (SSO), http://www.cisco.com/c/\\nen/us/td/docs/ios/12 0s/feature/guide/sso120s.html.\\n72. Ethernet automatic protection switching (EAPS),\\nhttps://tools.ietf.org/html/rfc3619, Oct. 2003.\\n73. Ethernet ring protection switching (ERPS), http://\\nwww.cisco.com/c/en/us/td/docs/ios-xml/ios/cether/\\nconﬁguration/xe-3s/ce-xe-3s-book/ceg8032-ering-\\npro.html.\\n74. Fast re-routing (FRR), http://tools.ietf.org/html/\\nrfc4090, May 2005.\\n75. Kim H, Santos JR, Turner Y, Schlansker M,\\nTourrilhes J, Feamster N. CORONET: fault tolerance\\nfor software de ﬁned networks. Network Protocols\\n(ICNP ),\\n20th IEEE International Conference on .\\nIEEE, 2012, pp. 1 –2.\\n76. Borokhovich M, Schiff L, Schmid S. Provable data\\nplane connectivity with local fast failover: introduc-\\ning OpenFlow graph algorithms. Proc.3rd Workshop\\nHot Topics Softw .Deﬁned Netw . ACM, 2014, pp.\\n121–126.\\n77. Heller B, Sherwood R, McKeown N. The controller\\nplace', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1189: ('html/\\nrfc4090, May 2005.\\n75. Kim H, Santos JR, Turner Y, Schlansker M,\\nTourrilhes J, Feamster N. CORONET: fault tolerance\\nfor software de ﬁned networks. Network Protocols\\n(ICNP ),\\n20th IEEE International Conference on .\\nIEEE, 2012, pp. 1 –2.\\n76. Borokhovich M, Schiff L, Schmid S. Provable data\\nplane connectivity with local fast failover: introduc-\\ning OpenFlow graph algorithms. Proc.3rd Workshop\\nHot Topics Softw .Deﬁned Netw . ACM, 2014, pp.\\n121–126.\\n77. Heller B, Sherwood R, McKeown N. The controller\\nplacement problem. Proceedings of the ACM\\nSIGCOMM Workshop on Hot Topics in SoftwareSoftware-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5828 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nDeﬁned Networking (HotSDN ). ACM, 2012, pp.\\n7–12.\\n78. Sharma S, Staessens D, Colle D, Pickavet M,\\nDemeester P. Enabling fast failure recovery in\\nOpenFlow networks. Design of Reliable Communica-\\ntion Networks (DRCN ), 8th International Workshop\\non the. IEEE, 2011, pp. 164 –171.\\n79. Park H, Song S, Choi BY, Choi T. Toward control\\npath high availability for software-de ﬁned networks.\\nDesign of Reliable Communication Networks\\n(DRCN ),11th International Conference on . IEEE,\\n2015, pp. 165 –172.\\n80. Kuroki K, Fukushima M, Hayashi M, Matsumoto N.\\nRedundancy method for highly available OpenFlow\\ncontroller. International Journal on Advances in\\nInternet Technology 2014; 7(1 and 2).\\n81. Su Z, Wang T, Xia Y, Hamdi M. CheetahFlow:\\ntowards low latency software-de ﬁned network.\\nCommunications (ICC), 2014 IEEE International\\nConference on . IEEE, 2014, pp. 3076 –3081.\\n82. He K, Khalid J, Gember-Jacobson A, et a', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1190: ('eliable Communication Networks\\n(DRCN ),11th International Conference on . IEEE,\\n2015, pp. 165 –172.\\n80. Kuroki K, Fukushima M, Hayashi M, Matsumoto N.\\nRedundancy method for highly available OpenFlow\\ncontroller. International Journal on Advances in\\nInternet Technology 2014; 7(1 and 2).\\n81. Su Z, Wang T, Xia Y, Hamdi M. CheetahFlow:\\ntowards low latency software-de ﬁned network.\\nCommunications (ICC), 2014 IEEE International\\nConference on . IEEE, 2014, pp. 3076 –3081.\\n82. He K, Khalid J, Gember-Jacobson A, et al. Measur-\\ning control plane latency in SDN-enabled switches.\\nProceedings of the 1st ACM SIGCOMM Symposium\\non Software De ﬁned Networking Research . ACM,\\n2015, Article No 25.\\n83. Williams D, Jamjoom H. Cementing high availability\\nin OpenFlow with RuleBricks. Proc.of ACM\\nSIGCOMM Workshop on HotSDN . ACM, 2013,\\npp. 139 –144.\\n84. Desai M, Nandagopal T. Coping with link failures in\\ncentralized control plane architecture. Proceedings of\\nIEEE COMmunication Systems and NETworks\\n(COMSNET ). IEEE, 2010, pp. 79 –88.\\n85. Berde P, Gerola M, Hart J, et al. ONOS: towards an\\nopen, distributed SDN OS. Proceedings of the Third\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworking . ACM, 2014, pp. 1 –6.\\n86. Hu Y, Wang W, Gong X, Que X, Cheng S. On\\nreliability-optimized controller placement forsoftware-de ﬁned networks. China Communications\\n2014; 11:38–\\n54.\\n87. Yao G, Bi J, Guo L. On the cascading failures of\\nmulti-controllers in software de ﬁned networks.\\nNetwork Protocols (ICNP ),2013 21st IEEE\\nInternational Conference on . IEEE, 2013, pp. 1 –2.\\n88. Ros FJ, Ruiz PM. Five nines of southbound\\nreliability in software-de ﬁned networks. Proceedings\\nof the Third Workshop on Hot Topics in SoftwareDeﬁned Networking . ACM, 2014, pp. 31 –36.\\n89. Xiao P, Qu W, Qi H, Li Z, Xu Y. The SDN controller\\nplacement problem for WAN. Communications in\\nChina (ICCC ),IEEE /CIC International Conference\\non. IEEE, 2014, pp. 220 –224.90. Capone A, Cascone C, Nguyen AQ, Sansò B. Detour\\nplanning for fast and reliable failure recovery in SDN\\nwith OpenState', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1191: (' IEEE, 2013, pp. 1 –2.\\n88. Ros FJ, Ruiz PM. Five nines of southbound\\nreliability in software-de ﬁned networks. Proceedings\\nof the Third Workshop on Hot Topics in SoftwareDeﬁned Networking . ACM, 2014, pp. 31 –36.\\n89. Xiao P, Qu W, Qi H, Li Z, Xu Y. The SDN controller\\nplacement problem for WAN. Communications in\\nChina (ICCC ),IEEE /CIC International Conference\\non. IEEE, 2014, pp. 220 –224.90. Capone A, Cascone C, Nguyen AQ, Sansò B. Detour\\nplanning for fast and reliable failure recovery in SDN\\nwith OpenState, arXiv preprint arXiv :1411.7711.\\n2014.\\n91. Pfeiffenberger T, Du JL, Arruda PB, Anzaloni A. Re-\\nliable and ﬂexible communications for power systems:\\nfault-tolerant multicast with SDN/OpenFlow. New\\nTechnologies ,Mobility and Security (NTMS ),7th In-\\nternational Conference on . IEEE, 2015, pp. 1 –6.\\n92. Guan X, Choi BY, Song S. Reliability and scalability\\nissues in software de ﬁned network frameworks. Re-\\nsearch and Educational Experiment Workshop (GREE ),\\n2013 Second GENI . IEEE. 2013, pp. 102 –103.\\n93. Dong M, Kimata T, Sugiura K, Zettsu K. Quality-of-\\nexperience (QoE) in emerging mobile social net-works. IEICE Transactions on Information and Sys-\\ntems 2010; E97-D :2606 –2612.\\n94. Jeong K, Kim J, Kim Y. QoS-aware network operat-\\ning system for software de ﬁned networking with gen-\\neralized OpenFlows. Proc.IEEE NOMS . IEEE, 2012,\\npp. 1167 –1174.\\n95. Handigol N, Seetharaman S, Flajslik M, Johari R,\\nMcKeown N. Asterix: load-balancing as a networkprimitive. Proc.9th GENI Eng .Conf.(Plenary ),\\n2010, pp. 1 –2.\\n96. M. Ghobadi, S. Yeganeh, and Y. Ganjali, Rethinking\\nend-to-end congestion control in software-de ﬁned\\nnetworks. Proc.11th ACM Workshop Hot Topics\\nNetw . ACM, 2012, pp. 61 –66.\\n97. Al-Fares M, Radhakrishnan S, Raghavan B, Huang\\nN, Vahdat A. Hedera: dynamic ﬂow scheduling for\\ndata center networks. Proc.7th USENIX Conf .NSDI .\\nUSENIX Association, 2010, p. 19.\\n98. Marcial F. Evaluating OpenFlow controller para-\\ndigms. ICN 2013, The Twelfth International Confer-\\nence on Networks , 2013, pp. 151 –157.\\n99. Syed AS', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1192: (' M. Ghobadi, S. Yeganeh, and Y. Ganjali, Rethinking\\nend-to-end congestion control in software-de ﬁned\\nnetworks. Proc.11th ACM Workshop Hot Topics\\nNetw . ACM, 2012, pp. 61 –66.\\n97. Al-Fares M, Radhakrishnan S, Raghavan B, Huang\\nN, Vahdat A. Hedera: dynamic ﬂow scheduling for\\ndata center networks. Proc.7th USENIX Conf .NSDI .\\nUSENIX Association, 2010, p. 19.\\n98. Marcial F. Evaluating OpenFlow controller para-\\ndigms. ICN 2013, The Twelfth International Confer-\\nence on Networks , 2013, pp. 151 –157.\\n99. Syed AS, Jannet F, Maham F, Aamir S, Syed MA.\\nAn architectural evaluation of SDN controllers. Com-\\nmunications (ICC),2013 IEEE International Confer-\\nence on . IEEE, 2013. pp. 3504 –3508.\\n100. Cai Z, Cox AL, Ng TE. Maestro: a system for scal-\\nable OpenFlow control, Rice Univ., Houston, TX,USA, Tech. Rep. TR10-08, Dec. 2010.\\n101. Khattak ZK, Awais M, Iqbal A. Performance evalua-\\ntion of OpenDaylight SDN controller.\\n102. Bianco A, Birke R, Giraudo L, Palacin M. OpenFlow\\nswitching: data plane performance. Proc.IEEE ICC .\\nIEEE, 2010, pp. 1 –5.\\n103. Tanyingyong V, Hidell M, Sjodin P. Improving\\nPC-based OpenFlow switching performance.\\nProceedings of the 6th ACM /IEEE Symposium on\\nArchitectures for Networking and Communications\\nSystems , New York, NY, USA, 2010, p. 13:1.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5829 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n104. Luo Y, Cascon P, Murray E, Ortega J. Accelerating\\nOpenFlow switching with network processors. Pro-\\nceedings of the 5th ACM /IEEE Symposium on Archi-\\ntectures for Networking and Communications\\nSystems , New York, NY,', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1193: ('/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n104. Luo Y, Cascon P, Murray E, Ortega J. Accelerating\\nOpenFlow switching with network processors. Pro-\\nceedings of the 5th ACM /IEEE Symposium on Archi-\\ntectures for Networking and Communications\\nSystems , New York, NY, USA, 2009, pp. 70 –71.\\n105. Rotsos C, Sarrar N, Uhlig S, Sherwood R, Moore\\nAW. OFLOPS: an open framework for OpenFlow\\nswitch evaluation. Proc.13th Int .Conf. PAM, 2012,\\npp. 85 –95.\\n106. Zhou W, Li L, Chou W. SDN northbound REST API\\nwith ef ﬁcient caches. IEEE International Conference\\non Web Services (ICWS ), 2014, pp. 257 –264.\\n107. Egilmez H, Dane S, Bagci K, Tekalp A. OpenQoS:\\nan OpenFlow controller design for multimedia deliv-\\nery with end-to-end quality of service over software-deﬁned networks. Asia-Paci ﬁc Signal Information\\nProcessing Association Annual Summit and Confer-\\nence (APSIP A ASC ), 2012, pp. 1 –8.\\n108. Xiong P, Hacigumus H, Naughton JF. A\\nsoftware-de ﬁned networking based approach for\\nperformance management of analytical queries ondistributed data stores. Proceedings of the 2014\\nACM SIGMOD International Conference on\\nManagement of Data ,SIGMOD ’14, ACM, New\\nYork, NY, USA, Snowbird, Utah, USA, 2014,\\npp. 955 –966.\\n109. Wendong W, Qinglei Q, Xiangyang G, Yannan H,\\nXirong Q. Autonomic QoS management mechanism\\nin software de ﬁned network. China Communications\\n2014; 11:13–23.\\n110. Cleder Machado C, Zambenedetti Granville L,\\nSchaeffer-Filho A, Araujo Wickboldt J. Towards\\nSLA policy re ﬁnement for QoS management in\\nsoftware-de ﬁned networking, in IEEE 28th\\nInternational Conference on Advanced Information\\nNetworking and Applications (AINA ).IEEE, 2014,\\npp. 397 –404.\\n111. Open ﬂow controller performance comparison.\\n[Online]. Available: http://www.open ﬂow.org/wk/in-\\ndex.php/Controller_Performance_Compar', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1194: ('ment mechanism\\nin software de ﬁned network. China Communications\\n2014; 11:13–23.\\n110. Cleder Machado C, Zambenedetti Granville L,\\nSchaeffer-Filho A, Araujo Wickboldt J. Towards\\nSLA policy re ﬁnement for QoS management in\\nsoftware-de ﬁned networking, in IEEE 28th\\nInternational Conference on Advanced Information\\nNetworking and Applications (AINA ).IEEE, 2014,\\npp. 397 –404.\\n111. Open ﬂow controller performance comparison.\\n[Online]. Available: http://www.open ﬂow.org/wk/in-\\ndex.php/Controller_Performance_Comparisons.\\n112. Liu L, Tsuritani T, Morita I, Guo H, Wu J. Experi-\\nmental validation and performance evaluation ofOpenFlow-based wavelength path control in trans-\\nparent optical networks. Optics Express 2011;\\n19:26578 –26593.\\n113. Fonseca P, Bennesby R, Mota E, Passito A. A repli-\\ncation component for resilient OpenFlow-based net-\\nworking. Proc.IEEE Network Operations and\\nManagement Symposium (NOMS 2012 ). IEEE,\\n2012, pp. 933 –939.\\n114. Zhang X, Phillips C. Network operator independent\\nresilient overlay for mission critical applications\\n(ROMCA). Communications and Networking inChina COM .Fourth International Conference on .\\nIEEE, 2009, pp. 1 –5.\\n115. Han J, Watson D, Jahanian F. Enhancing end-to-end\\navailability and performance via topology-aware\\noverlay networks. Computer Networks 2008;\\n52(16):3029 –3046.\\n116. Akella A, Maggs B, Seshan S, Shaikh A, Sitaraman\\nR. A measurement-based analysis of multihoming.\\nProceedings of the 2003 Conference onApplications, Technologies, Architectures, and\\nProtocols for Computer Communications, ser.\\nSIGCOMM ’03. New York, NY, USA. ACM,\\n2003, pp. 353 –364.\\n117. Rohrer JP, Jabbarand A, Sterbenz JP. Path diversi ﬁ-\\ncation: a multipath resilience mechanism. Design of\\nReliable Communication Networks (DRCN ).7th In-\\nternational Workshop on . IEEE. 2009, pp. 343 –351.\\n118. Li Y, Zhang Y, Qiu L, Lam S. SmartTunnel: achiev-\\ning reliability in the Internet. INFOCOM 2007 .26th\\nIEEE International Conference on Computer Com-\\nmunications . IEEE, 2007, pp. 830 –838.\\n119. Chiu AL, Choudhury G, Clap', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1195: ('ommunications, ser.\\nSIGCOMM ’03. New York, NY, USA. ACM,\\n2003, pp. 353 –364.\\n117. Rohrer JP, Jabbarand A, Sterbenz JP. Path diversi ﬁ-\\ncation: a multipath resilience mechanism. Design of\\nReliable Communication Networks (DRCN ).7th In-\\nternational Workshop on . IEEE. 2009, pp. 343 –351.\\n118. Li Y, Zhang Y, Qiu L, Lam S. SmartTunnel: achiev-\\ning reliability in the Internet. INFOCOM 2007 .26th\\nIEEE International Conference on Computer Com-\\nmunications . IEEE, 2007, pp. 830 –838.\\n119. Chiu AL, Choudhury G, Clapp G, Doverspike R,\\nFeuer M, Gannett JW, Xu D. Architectures and pro-\\ntocols for capacity ef ﬁcient, highly dynamic and\\nhighly resilient core networks. Journal of Optical\\nCommunications and Networking, IEEE/OSA 2012;\\n4(1):1 –14.\\n120. Benton K, Camp LJ, Small C. OpenFlow vulnerabil-\\nity assessment. Proceedings of the Second ACM\\nSIGCOMM Workshop on Hot Topics in Software De-ﬁned Networking . ACM, 2013, pp. 151 –152.\\n121. Kreutz D, Ramos F, Verissimo P, Rothenberg CE,\\nAzodolmolky S, Uhlig S. Software-de ﬁned network-\\ning: a comprehensive survey, arXiv preprint\\narXiv :1406 .0440 , 2014.\\n122. Kreutz D, Ramos F, Verissimo P. Towards secure\\nand dependable software-de ﬁned networks. Proceed-\\nings of the Second ACM SIGCOMM Workshop on\\nHot Topics in Software De ﬁned Networking . ACM,\\n2013, pp. 55 –60.\\n123. Li D, Hong X, Bowman J. Evaluation of security vul-\\nnerabilities by using ProtoGENI as a launchpad.Global Telecommunications Conference\\n(GLOBECOM 2011 ). IEEE, 2011, pp. 1 –6.\\n124. Shin S, Gu G. Attacking software-de ﬁned networks:\\ntheﬁrst feasibility study. Proceedings of the Second\\nACM SIGCOMM Workshop on Hot Topics in\\nSoftware De ﬁned Networking . ACM, 2013, pp.\\n165–166.\\n125. Smeliansky R. SDN for network security. Science\\nand Technology Conference (Modern Networking\\nTechnologies )(MoNeTeC ),First International . IEEE,\\n2014, pp. 1 –5.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5830 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1196: ('ﬁned networks:\\ntheﬁrst feasibility study. Proceedings of the Second\\nACM SIGCOMM Workshop on Hot Topics in\\nSoftware De ﬁned Networking . ACM, 2013, pp.\\n165–166.\\n125. Smeliansky R. SDN for network security. Science\\nand Technology Conference (Modern Networking\\nTechnologies )(MoNeTeC ),First International . IEEE,\\n2014, pp. 1 –5.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5830 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\n126. Schehlmann L, Abt S, Baier H. Blessing or curse?\\nRevisiting security aspects of software-de ﬁned net-\\nworking. Network and Service Management (CNSM ),\\n10th International Conference on . IEEE, 2014, pp.\\n382–387.\\n127. Porras P, Shin S, Yegneswaran V, Fong M, Tyson M,\\nGu G. A security enforcement kernel for OpenFlow\\nnetworks. Proceedings of the First Workshop on\\nHot Topics in Software De ﬁned Networks . ACM,\\n2012, pp. 121 –126.\\n128. Shin S, Song Y, Lee T, et al. Rosemary: a robust, se-\\ncure, and high-performance network operating sys-tem. Proceedings of the 2014 ACM SIGSAC\\nConference on Computer and Communications Secu-\\nrity. ACM, 2014, pp. 78 –89.\\n129. Chandrasekaran B, Benson T. Tolerating SDN appli-\\ncation failures with LegoSDN. Proceedings of the\\n13th ACM Workshop on Hot Topics in Networks .\\nACM, 2014, p. 22.\\n130. Othman MM, Okamura K. Securing distributed con-\\ntrol of software de ﬁned networks. International Jour-\\nnal of Computer Science and Network Security 2013;\\n13(9).\\n131. Li H, Li P, Guo S, Yu S. Byzantine-resilient secure\\nsoftware de ﬁned networks with multiple controllers.\\nCommunications (ICC),2014 IEEE International\\nConference on . IEEE, 20', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1197: ('29. Chandrasekaran B, Benson T. Tolerating SDN appli-\\ncation failures with LegoSDN. Proceedings of the\\n13th ACM Workshop on Hot Topics in Networks .\\nACM, 2014, p. 22.\\n130. Othman MM, Okamura K. Securing distributed con-\\ntrol of software de ﬁned networks. International Jour-\\nnal of Computer Science and Network Security 2013;\\n13(9).\\n131. Li H, Li P, Guo S, Yu S. Byzantine-resilient secure\\nsoftware de ﬁned networks with multiple controllers.\\nCommunications (ICC),2014 IEEE International\\nConference on . IEEE, 2014, pp. 695 –700.\\n132. Yu D, Moore AW, Hall C, Anderson R. Authentica-\\ntion for resilience: the case of SDN, ser.Security Pro-\\ntocols XXI . Springer, 2013, pp. 39 –44.\\n133. Schlesinger C, Story A, Gutz S, Foster N, Walker D.\\nSplendid isolation: language-based security for\\nsoftware-de ﬁned networks. Proceedings of the First\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworks . ACM, 2012, pp. 79 –84.\\n134. Skowyra RW, Lapets A, Bestavros A, Kfoury A.\\nVeriﬁably safe software-de ﬁned networks for CPS.\\nProceedings of the 2nd ACM International Confer-\\nence on High Con ﬁdence Networked Systems .\\nACM, 2013, pp. 101 –110.\\n135. Guha A, Reitblatt M, Foster N. Machine-veri ﬁed net-\\nwork controllers. ACM SIGPLAN Notices 2013;\\n48:483 –494.\\n136. Ball T, Bjrner N, Gember A, et al. VeriCon: towards\\nverifying controller programs in software-de ﬁned\\nnetworks. Proceedings of the 35th ACM SIGPLAN\\nConference on Programming Language Design and\\nImplementation . ACM, 2014, p. 31.\\n137. Wen X, Chen Y, Hu C, Shi C, Wang Y. Towards a\\nsecure controller platform for OpenFlow applica-\\ntions. Proceedings of the Second ACM SIGCOMM\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworking . ACM, 2013, pp. 171 –172.138. OpenFlowSec.org. Security-enhanced Floodlight.\\n[Online]. Available: www.open ﬂowsec.org.\\n139. Porras P, Cheung S, Fong M, Skinner K,\\nYegneswaran V. Securing the software-de ﬁned net-\\nwork control layer. Proceedings of the Network and\\nDistributed System Security Symposium (NDSS ),\\nSan Diego, California. 2015.\\n140. Foster N, Harrison', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1198: ('cure controller platform for OpenFlow applica-\\ntions. Proceedings of the Second ACM SIGCOMM\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworking . ACM, 2013, pp. 171 –172.138. OpenFlowSec.org. Security-enhanced Floodlight.\\n[Online]. Available: www.open ﬂowsec.org.\\n139. Porras P, Cheung S, Fong M, Skinner K,\\nYegneswaran V. Securing the software-de ﬁned net-\\nwork control layer. Proceedings of the Network and\\nDistributed System Security Symposium (NDSS ),\\nSan Diego, California. 2015.\\n140. Foster N, Harrison R, Freedman MJ, et al. Frenetic: a\\nnetwork programming language. ACM SIGPLAN No-\\ntices 2011; 46(9):279 –291.\\n141. Al-Shaer E, Al-Haj S. FlowChecker: con ﬁguration\\nanalysis and veri ﬁcation of federated OpenFlow in-\\nfrastructures. Proceedings of the 3rd ACM Workshop\\non Assurable and Usable Security Con ﬁguration .\\nACM, 2010, pp. 37 –44.\\n142. Mai H, Khurshid A, Agarwal R, Caesar M, Godfrey\\nP, King ST. Debugging the data plane with Anteater.\\nACM SIGCOMM Computer Communication Review2011; 41(4):290 –301.\\n143. Namal S, Ahmad I, Gurtov A, Ylianttila M. Enabling\\nsecure mobility with OpenFlow. IEEE Software De-ﬁned Networks for Future Networks and Services.\\nIEEE, 2013.\\n144. Scott-Hayward S, Kane C, Sezer S. Operation Check-\\npoint: SDN application control. 22nd IEEE Interna-\\ntional Conference on Network Protocols (ICNP ).\\nIEEE, 2014, pp. 618 –623\\n145. Khurshid A, Zhou W, Caesar M, Godfrey P.\\nVeriFlow: verifying network-wide invariants in real\\ntime. ACM SIGCOMM Computer Communication\\nReview 2012; 42\\n(4):467 –472.\\n146. Mehdi SA, Khalid J, Khayam SA. Revisiting traf ﬁc\\nanomaly detection using software de ﬁned network-\\ning. In Recent Advances in Intrusion Detection .\\nSpringer Berlin Heidelberg, 2011; 161 –180.\\n147. Hand R, Michael T, Eric K. Active security. In\\nTwelfth ACM Workshop on Hot Topics in Networks\\n(HotNets-XII) . ACM: College Park, MD, 2013;\\n79–108.\\n148. Jafarian JH, Al-Shaer E, Duan Q. OpenFlow random\\nhost mutation: transparent moving target defense\\nusing software de ﬁned networking. Proceedings of\\nthe First Wor', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1199: (' Mehdi SA, Khalid J, Khayam SA. Revisiting traf ﬁc\\nanomaly detection using software de ﬁned network-\\ning. In Recent Advances in Intrusion Detection .\\nSpringer Berlin Heidelberg, 2011; 161 –180.\\n147. Hand R, Michael T, Eric K. Active security. In\\nTwelfth ACM Workshop on Hot Topics in Networks\\n(HotNets-XII) . ACM: College Park, MD, 2013;\\n79–108.\\n148. Jafarian JH, Al-Shaer E, Duan Q. OpenFlow random\\nhost mutation: transparent moving target defense\\nusing software de ﬁned networking. Proceedings of\\nthe First Workshop on Hot Topics in Software De-\\nﬁned Networks . ACM, 2012, pp. 127 –132.\\n149. Kampanakis P, Perros H, Beyene T. SDN-based solu-\\ntions for moving target defense network protection. A\\nWorld of Wireless ,Mobile and Multimedia Networks\\n(WoWMoM ),IEEE 15th International Symposium\\non. IEEE, 2014, pp. 1 –6.\\n150. Giotis K, Argyropoulos C, Androulidakis G,\\nKalogeras D, Maglaris V. Combining OpenFlowand sFlow for an effective and scalable anomaly de-\\ntection and mitigation mechanism on SDNSoftware-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5831 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nenvironments. Journal of Computer Networks 2014;\\n62:122 –136.\\n151. Matias J, Tornero B, Mendiola A, Jacob E, Toledo N.\\nImplementing layer 2 network virtualization using\\nOpenFlow: challenges and solutions. Software De-\\nﬁned Networking (EWSDN ),2012 European Work-\\nshop on . IEEE, 2012, pp. 30 –35.\\n152. Yao G, Bi, Xiao P. Source address validation solution\\nwith OpenFlow/NOX architecture. Network Protocols\\n(ICNP ),2011 19th IEEE International Conference on .\\nIEEE, 2011, pp. 7 –12.\\n153. Yao G, Bi J', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1200: ('mons License\\n\\nenvironments. Journal of Computer Networks 2014;\\n62:122 –136.\\n151. Matias J, Tornero B, Mendiola A, Jacob E, Toledo N.\\nImplementing layer 2 network virtualization using\\nOpenFlow: challenges and solutions. Software De-\\nﬁned Networking (EWSDN ),2012 European Work-\\nshop on . IEEE, 2012, pp. 30 –35.\\n152. Yao G, Bi, Xiao P. Source address validation solution\\nwith OpenFlow/NOX architecture. Network Protocols\\n(ICNP ),2011 19th IEEE International Conference on .\\nIEEE, 2011, pp. 7 –12.\\n153. Yao G, Bi J, Feng T, Xiao P, Zhou D. Performing\\nsoftware de ﬁned route-based IP spoo ﬁngﬁltering\\nwith SEFA. Computer Communication and Networks\\n(ICCCN ),23rd International Conference on . IEEE,\\n2014,pp. 1 –8.\\n154. Feng T, Bi J, Hu H, Yao G, Xiao P. InSAVO:\\nintra-AS IP source address validation solution withOpenRouter. Proceedings of the IEEE International\\nConference on Computer Communications\\n(INFOCOM ). Orlando Bi J, Liu B, Wu J, Shen Y\\nUSA. IEEE, 2012, pp. 33 –34.\\n155. Meyer C, Schwenk J. Lessons learned from previous\\nSSL/TLS Attacks —a brief chronology of attacks and\\nweaknesses. IACR Cryptology ePrint Archive, 2013,\\np. 49.\\n156. Hernan S, Lambert S, Ostwald T, Shostack. Threat\\nmodeling uncover security design ﬂaws using the\\nstride approach. MSDN Magazine-Louisville, 2006,\\npp. 68 –75.\\n157. Casado M, Gar ﬁnkel T, Akella A, et al. SANE: a pro-\\ntection architecture for enterprise networks. Usenix\\nSecurity Symposium .ser.USENIXSS ’06, Berkeley,\\nCA, USA, vol. 15. 2006.\\n158. Jia X, Wang JK. Distributed ﬁrewall for P2P network\\nin data center. ICCE-China Workshop (ICCE-China ).\\nIEEE, 2013, pp. 15 –19.\\n159. Katta NP, Rexford J, Walker D. Logic programming\\nfor software-de ﬁned networks. Workshop on Cross-\\nModel Design and Validation (XLDI ). Vol. 412.\\nACM, 2012.\\n160. Dangovas V, Kuliesius F. SDN-driven authentication\\nand access control system. The International\\nConference on Digital Information ,Networking ,\\nand Wireless Communications (DINWC2014 ). The\\nSociety of Digital Information and Wireless\\nCommunication, 2014, pp. 20 –23.\\n1', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1201: ('k\\nin data center. ICCE-China Workshop (ICCE-China ).\\nIEEE, 2013, pp. 15 –19.\\n159. Katta NP, Rexford J, Walker D. Logic programming\\nfor software-de ﬁned networks. Workshop on Cross-\\nModel Design and Validation (XLDI ). Vol. 412.\\nACM, 2012.\\n160. Dangovas V, Kuliesius F. SDN-driven authentication\\nand access control system. The International\\nConference on Digital Information ,Networking ,\\nand Wireless Communications (DINWC2014 ). The\\nSociety of Digital Information and Wireless\\nCommunication, 2014, pp. 20 –23.\\n161. Zhu S, Bi J, Sun C. SFA: stateful forwarding abstrac-\\ntion in SDN data plane. USENIX/?Open Networking\\nSummit Research Track (ONS14), Santa Clara, USA\\n2014.\\n162. Stoenescu R, Popovici M, Negreanu L, Raiciu C.\\nSymnet: static checking for stateful networks.Proceedings of the 2013 Workshop on Hot Topics in\\nMiddleboxes and Network Function Virtualization .\\nACM, 2013, pp. 31 –36\\n163. Fayaz SK, Sekar V. Testing stateful and dynamic\\ndata planes with FlowTest. Proceedings of the Third\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworking . ACM, 2014, pp. 79 –84.\\n164. Skowyra R, Bahargam S, Bestavros A. Software-de-\\nﬁned IDS for securing embedded mobile devices.\\nHigh Performance Extreme Computing Conference\\n(HPEC ).IEEE, 2013, pp.1 –7.\\n165. Shin S, Porras P, Yegneswaran V, Fong M, Gu G,\\nTyso M. FRESCO: modular composable security\\nservices for software-de ﬁned networks. Proceedings\\nof Network and Distributed Security Symposium ,\\n2013.\\n166. Liyanage M, Ylianttila M, Gurtov A. Securing the\\ncontrol channel of software-de ﬁned mobile networks.\\nWorld of Wireless ,Mobile and Multimedia Networks\\n(WoWMoM ),IEEE 15th International Symposium\\non. IEEE, 2014, pp. 1 –6.\\n167. Handigol N, Heller B, Jeyakumar V, Mazieres D,\\nMcKeown N. Where is the debugger for my\\nsoftware-de ﬁned network?. Proceedings of the First\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworks . ACM, 2012, pp. 55 –60.\\n168. OpenFlowSec.org. Security-enhanced FloodLight.\\n[Online]. Available: www.open ﬂowsec.org.\\n169. Fayazbakhsh SK, Sekar V, Yu M, Mogul JC.\\nFl', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1202: ('e-de ﬁned mobile networks.\\nWorld of Wireless ,Mobile and Multimedia Networks\\n(WoWMoM ),IEEE 15th International Symposium\\non. IEEE, 2014, pp. 1 –6.\\n167. Handigol N, Heller B, Jeyakumar V, Mazieres D,\\nMcKeown N. Where is the debugger for my\\nsoftware-de ﬁned network?. Proceedings of the First\\nWorkshop on Hot Topics in Software De ﬁned Net-\\nworks . ACM, 2012, pp. 55 –60.\\n168. OpenFlowSec.org. Security-enhanced FloodLight.\\n[Online]. Available: www.open ﬂowsec.org.\\n169. Fayazbakhsh SK, Sekar V, Yu M, Mogul JC.\\nFlowTags: enforcing network-wide policies in thepresence of dynamic middlebox actions. Proceedings\\nof the Second ACM SIGCOMM Workshop on Hot\\nTopics in Software De ﬁned Networking . ACM,\\n2013, pp. 19 –24.\\n170. Mattos DMF, Ferraz LHG, Duarte OCMB.\\nAuthFlow: authentication and access controlmechanism for software de ﬁned networking.\\n171. Shin S, Yegneswaran V, Porras P, Gu G. AVANT-\\nGUARD: scalable and vigilant switch ﬂow manage-\\nment in software-de ﬁned networks. Proceedings of\\nthe 2013 ACM SIGSAC Conference on Computer and\\nCommunications Security .A C M ,2 0 1 3 ,p p .4 1 3 –424.\\n172. Yao G, Bi J, Xiao P. Source address validation solu-\\ntion with OpenFlow/NOX architecture. 19th IEEE In-\\nternational Conference on Network Protocols(ICNP ). IEEE, 2011, pp. 7 –12.\\n173. Naous J, Stutsman R, Mazieres D, McKeown N,\\nZeldovich N. Delegating network security with moreinformation. Proceedings of the 1st ACM Workshop\\non Research on Enterprise Networking . ACM,\\n2009, pp. 19 –26.\\n174. Braga R, Mota E, Passito A. Lightweight DDoS\\nﬂooding attack detection using NOX/?OpenFlow.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5832 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library ', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1203: ('DoS\\nﬂooding attack detection using NOX/?OpenFlow.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5832 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n\\nIEEE 35th Conference on Local Computer Networks\\n(LCN). IEEE, 2010, pp. 408 –415.\\n175. Suh J, Choi H, Yoon W, You T, Kwon T, Choi Y.\\nImplementation of content-oriented networking\\narchitecture (CONA): a focus on DDoS\\ncountermeasure. European NetFPGA Developers\\nWorkshop , 2010.\\n176. YuHunag C, MinChi T, YaoTing C, YuChieh C,\\nYanRen C. A novel design for future on-demand ser-vice and security. Communication Technology\\n(ICCT ),12th IEEE International Conference on .\\nIEEE, 2010, pp. 385 –388.\\n177. Lim S, Ha J, Kim H, Kim Y, Yang S. A SDN-\\noriented DDoS blocking scheme for botnet-basedattacks. Ubiquitous and Future Networks (ICUFN ),\\n2014 Sixth International Conf on . IEEE, 2014, pp.\\n63–68.\\n178. Zaalouk A, Khondoker R, Marx R, Bayarou K.\\nOrchSec: an orchestrator-based architecture for en-\\nhancing network-security using network monitoringand SDN control functions. Network Operations\\nand Management Symposium (NOMS ). IEEE, 2014,\\npp. 1 –9.\\n179. Schehlmann L, Baier H. COFFEE: a concept based\\non OpenFlow to ﬁlter and erase events of botnet\\nactivity at high-speed nodes. GI-Jahrestagung ,\\n2013, pp. 2225 –2239.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5833 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Librar', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1204: (' 1 –9.\\n179. Schehlmann L, Baier H. COFFEE: a concept based\\non OpenFlow to ﬁlter and erase events of botnet\\nactivity at high-speed nodes. GI-Jahrestagung ,\\n2013, pp. 2225 –2239.Software-defined networking: a survey K. Benzekki, A. El Fergougui and A. Elbelrhiti Elalaoui\\n5833 Security Comm. Networks 2016; 9:5803 –5833 © 2017 John Wiley & Sons, Ltd.\\nDOI: 10.1002/sec\\n 19390122, 2016, 18, Downloaded from https://onlinelibrary.wiley.com/doi/10.1002/sec.1737 by University Of California - Davis, Wiley Online Library on [07/03/2025]. See the Terms and Conditions (https://onlinelibrary.wiley.com/terms-and-conditions) on Wiley Online Library for rules of use; OA articles are governed by the applicable Creative Commons License\\n', 'Security Comm Networks - 2017 - Benzekki - Software‐defined networking  SDN   a survey.pdf'), 1205: (' \\n \\n \\n \\n \\n \\nThe Feasibility of Google’s \\nProject Loon  \\n \\n \\nU535080 4 \\nJames Burr  \\n \\nUsing  a systems engineering approach, an analysis  was performed to determine the viability of \\nGoogle’s ‘Project Loon’; a system of high altitude balloons creating a moveable and adaptable \\ninternet network. The scope of the pro ject was determined based on its mission statement : “to provide \\ninternet access to rural  and poor  areas ” (Googl e, n.d.) . Australia and India were  selected to be case \\nstudy locations  when discussing the feasibility of Project Loon. The mater ial makeup of each balloon \\nwas asse ssed and an energy audit found  each balloon had 70225MJ of embodied energy and an \\nestimated  initial  cost of $17870. Over a five year period the total cost per balloon was determined to \\nbe $40318. To run at no cost to Google each customer would have to pay between $833.19 and \\n$1.86 for the two considered  scenarios assuming a 5% take -up rate  by use rs. Due to the relationship \\nbetween internet access and wealth it is recommended that Google implement Project Loon at no \\ncost to users  as the company would indirectly profit from more users due to ad vertisement revenue. \\nAt 5% take -up rate  Australia is not a viable  location for this project  as only 13.5% of the ongoing cost \\nwould be covered.  India  however,  would result  in Project Loon generating $96.1  million in \\nadvertisement  revenue, covering its total  cost by 6046.1 %. Furthermore Project Loon would provid e \\nvaluable infrastructure to the company ensuring a larger customer base for future projects.  \\n \\n \\n Contents  \\n \\nIntroduction……………………………………………… ………… …………………………………1  \\nScope……………………………………………………………… ……….. …………………………1  \\nPeople……………………………………………………… ……. …………………………………… 3 \\nBalloon Overview………………………………………… ..………………………………………… 4 \\nWireless Technology………………………………………………… ……………………………… 4 \\nMaterial Audit…………………………………………………………………..……………………..5  \\nEnergy Lifecycle………………………………………………………… ……… …………………… 6 \\nOperational Consumption…………………………………………………………………………… 8 \\nSafety………', 'Project_loon.pdf'), 1206: (' ensuring a larger customer base for future projects.  \\n \\n \\n Contents  \\n \\nIntroduction……………………………………………… ………… …………………………………1  \\nScope……………………………………………………………… ……….. …………………………1  \\nPeople……………………………………………………… ……. …………………………………… 3 \\nBalloon Overview………………………………………… ..………………………………………… 4 \\nWireless Technology………………………………………………… ……………………………… 4 \\nMaterial Audit…………………………………………………………………..……………………..5  \\nEnergy Lifecycle………………………………………………………… ……… …………………… 6 \\nOperational Consumption…………………………………………………………………………… 8 \\nSafety…………………………………………………………………………..………………………9  \\nDynamics and Control ……………………………………………….. ……………………………… 9 \\nCoverage………………………………………………………… ..………………………………… 10 \\nCost……………………………………………………………… ……... …………………………… 11 \\nRecommendations………………………………………… ..……………………………………… 15 \\nReference s……………… …………………………………………………..………………………16  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nCover image: Google, n.d., Project Loon  \\n \\n1 \\n Introduction  \\nA major limitation of existing  internet  networks is their general reliance on cables and fixed \\ninfrastructure to provide high speed and consistent connection.  Only 44% of people used the \\ninternet in 2013 (ITU, 2014) mostly due to remote and poor communities being unable to \\ninstall the required infrastructure  (IMF, 2015) . Google has envisioned a solution to this \\nknown as Project L oon; an interconnected network of high altitude balloons providing  \\nwireless internet access to remote communities.  The project is called Loon because even \\nGoogle sees it as a near impossible task. This paper will analyse the project using a systems \\nenginee ring approach in an attempt to determine whether the project is feasible.  \\n \\nScope  \\nUnfortunately not a huge wealth of information is available with regards to Project Loon. A \\ngreat way to develop this information would be to interview someone associated with  the \\nProject. If the opportunity had presented itself some key questions would be:  \\n1) What is the most important goal of Project Loon?  \\nAn answer to this question would help define the scope of this paper as it would \\ndisti', 'Project_loon.pdf'), 1207: ('ng a systems \\nenginee ring approach in an attempt to determine whether the project is feasible.  \\n \\nScope  \\nUnfortunately not a huge wealth of information is available with regards to Project Loon. A \\ngreat way to develop this information would be to interview someone associated with  the \\nProject. If the opportunity had presented itself some key questions would be:  \\n1) What is the most important goal of Project Loon?  \\nAn answer to this question would help define the scope of this paper as it would \\ndistinguish what areas or aspects of the pr oject should be focused upon.  \\n \\n2) Is Project Loon intended to be a not for profit venture?  \\nGoogle will in inherently earn advertising revenue from people using the internet but \\nit is not clear whether Google intends to charge for access to the network.  \\n \\n3) What is your biggest concern with regards to Project Loon?  \\nWithout inside information it is hard to determine exactly makes the project feasible. \\nIf one of googles key concerns is known then it signifies  a need for emphasized \\nanalysis into that specific area.  \\nWithout any of this information the scope of this project must be constructed from what \\ninformation is available. Google’s mission statement for Project Loon is as follows:  \\n“Many of us think of the internet as a global community. But two -thirds of the worl d’s \\npopulation does not yet have internet access. Project Loon is a network of balloons traveling \\non the edge of space, designed to connect people in rural and remote areas, help fill \\ncoverage gaps, and bring people back online after disasters.”  (Google, n .d.) \\nThis statement formed the basis for the scope of this project as it focussed on giving access \\nto people who do not currently have it , rather than providing an  alternative for people who  \\ncan already connect . Two different sets of scopes were examined i n this paper ; Project \\nLoon ’s application  in Australia compared to its application in  India. These two countries were \\nselected because they are on two extremes: Australia ha', 'Project_loon.pdf'), 1208: ('rage gaps, and bring people back online after disasters.”  (Google, n .d.) \\nThis statement formed the basis for the scope of this project as it focussed on giving access \\nto people who do not currently have it , rather than providing an  alternative for people who  \\ncan already connect . Two different sets of scopes were examined i n this paper ; Project \\nLoon ’s application  in Australia compared to its application in  India. These two countries were \\nselected because they are on two extremes: Australia has a population density of \\n3.11pop/km2 (ABS , 2012)  with an internet connectivity of 83.0% (ITU , 2014 ); India has a \\npopulation density of 388.78pop/km2 with an internet connectivity of 15.1%  (ITU, 2014) . If \\nProject Loon is shown to be unfeasible in one of these scenarios then it may provide better \\ninsight into what should be improved with in Project Loon.  \\n \\n2 \\n Using  the Paretto Principle , an analysis of Project Loon’s feasibility in Australia was \\nperformed. This principle assumes  that 20% of Australia’s population would make use of \\nProject Loon and that this popu lation is spread out over 80% of Australia’s land area.  This \\nassumption is supported by the fact that i n 2013 the percentage of households in Australia \\nwith internet access ranged from a minimum of 78% in Tasmania to  a maximum of  89% in \\nthe ACT (ABS , 2014 ). This leaves between 11 -22% without access which falls roughly within \\nthe Paretto Principle range.  Figure s 1 and 2 show a population density map of Australia and \\nan internet access quality map respectively. It is clear that there is a direct relationship \\nbetween population density and internet access. This indicates that the 20% without access \\nwill be in lower density or rural areas, which is defined in Project Loon’s mission statement \\nas the primary intended user base.  \\n \\nFigure 1 – Populati on density of Australia        Figure 2 – Internet coverage in Australia  \\n                          (ABS, 2012)                                (Department of Communications, 20', 'Project_loon.pdf'), 1209: ('ternet access quality map respectively. It is clear that there is a direct relationship \\nbetween population density and internet access. This indicates that the 20% without access \\nwill be in lower density or rural areas, which is defined in Project Loon’s mission statement \\nas the primary intended user base.  \\n \\nFigure 1 – Populati on density of Australia        Figure 2 – Internet coverage in Australia  \\n                          (ABS, 2012)                                (Department of Communications, 2013)  \\nApplying the  Paretto Principle  gives that Project Loon must be able to suppor t 4.75 million \\npeople  (ABS, 2012) over a total area of 6.13 million square kilometres  (Geoscience \\nAustralia, 2004) . This translates to one user in each 1.29 square kilometres.  \\nIn 2013 15.1% of India’s population used the internet (International Telecommunication \\nUnion). It was assumed for this report that the remaining 84.9%  of India’s population (total of \\n1.21 billion) would  be spread out over all of India’s land area of 2.97 m illion square \\nkilometres  (Ministry of Home Affairs India, 2011) . This gives that Project Loon must be able \\nto support 1.03 billion users over a total area of 2.97 million square kilometres.  \\n \\nTable 1 – Scenario Data  \\nScenario  Population  Area (km2) %Internet \\nAccess  Potential Users  Supported \\nArea  (km2) Users/km2 \\n#1 (Australia)  23,714,300  7,659,861  80% 4,742,860  6,127,889  0.77 \\n#2 (India)  1,210,569,573  2,973,190  15.1%  1,027,773,567  2,973,190  345.7  \\n \\n \\n\\n \\n3 \\n The large difference between the two scenarios  could highlight differing limitations of the \\nproject. For example, a low number of users over a larger area may put a strain on the cost \\nof the system as more materials would be expended  with less possible income . On the other \\nhand the second scenario may  put a strain on the technological limitations of the systems as \\na higher number of users per balloon would cons ume more transmission bandwidth.  \\n \\nPeople  \\nOne of the biggest hurdles with regards to gainin', 'Project_loon.pdf'), 1210: ('rge difference between the two scenarios  could highlight differing limitations of the \\nproject. For example, a low number of users over a larger area may put a strain on the cost \\nof the system as more materials would be expended  with less possible income . On the other \\nhand the second scenario may  put a strain on the technological limitations of the systems as \\na higher number of users per balloon would cons ume more transmission bandwidth.  \\n \\nPeople  \\nOne of the biggest hurdles with regards to gaining access to the internet is wealth. This \\ngeneral trend  was confirmed by compiling data from the International Telecommunications \\nUnion  (2014)  and the International Monetary Fund  (2015)  (Figure 3 ). It shows that there is a \\ncorrelation between GDP per capita and internet availability in countries.  \\nThe internet is a powerful tool which can be used to improve quality of life in many regards . It \\nacts as a  communication  network  which from an economic perspective would allow \\nbusinesses to reach new customers and from a social perspective allows people to contact \\neach  other when they otherwise may not be able to.  The internet also acts as a conduit for \\nentertainment, leisure and the arts which improves quality of life.  \\nThis report will opti mistically ignore the fact that  someone who cannot afford  an internet \\nconnection is likely to  not have a device capable of connecting to the internet. This falls \\noutside of the scope of this paper as it is concerned with the creation of the network, not \\npeople’s direct access to it.  \\n \\n \\nFigure 3 – percentage of people with in ternet access vs GDP per capita  \\n \\n 020000400006000080000100000120000140000\\n0.00 10.00 20.00 30.00 40.00 50.00 60.00 70.00 80.00 90.00 100.00GDP per Capita  \\n% Internet Connectivity  \\n \\n4 \\n Balloon Overview  \\nThe basis of Project Loon is the actual balloons which will form the network. Each balloon \\nuses LTE  (4G) technology to provide internet coverage over an area of 40km in diam eter. \\nEach balloon is designed to operate in th', 'Project_loon.pdf'), 1211: (' \\npeople’s direct access to it.  \\n \\n \\nFigure 3 – percentage of people with in ternet access vs GDP per capita  \\n \\n 020000400006000080000100000120000140000\\n0.00 10.00 20.00 30.00 40.00 50.00 60.00 70.00 80.00 90.00 100.00GDP per Capita  \\n% Internet Connectivity  \\n \\n4 \\n Balloon Overview  \\nThe basis of Project Loon is the actual balloons which will form the network. Each balloon \\nuses LTE  (4G) technology to provide internet coverage over an area of 40km in diam eter. \\nEach balloon is designed to operate in the stratosphere and use wind currents to \\ndynamically change the network to meet demand.  They are designed to operate on a 100 \\nday cycle, at which the end of they will descend and undergo maintenance.  Each balloon is \\ncomprised of:  \\n- Envelope: polyethylene plastic 15 meters wide and 12 meters tall when fully inflated  \\n- Solar p anels: To provide energy to on board equipment  \\n- Radio antenna: To communicate with other balloons in the network  \\n- LTE antenna: To generate coverage network  \\n- Lithium -ion battery: To store energy from solar panels  \\n- Parachute: To safely lower balloon  \\n- Gas cylinder : To control the balloons altitude  \\n \\nFigure 4 – A Project Loon balloon  \\n \\nWireless Technology  \\nThe biggest disadvan tage of wireless communications compared with traditional wired  \\nmethods,  is the limited bandwidth available for transmission. Data is transmitted by sending \\nsignals over certain frequencies. Limited  frequencies are available  and if two signals occupy \\nthe same  frequency  space they may interfere  with each other  (Goldsmith, 2013) . This means \\nthat the number of users that can be supported by each balloon has a n upper -limit and \\nadding more balloons to a densely populated area may not improve the situation.  \\n\\n \\n5 \\n A simpler way to imagine it is if the network is a single -phase multi -channel queue  (Figure \\n5). The bandwidth available is the channels, once you run out of b andwidth you cannot fit \\nany more queues into the system.  \\n \\nFigure 5  - Simplistic Representation of bandw', 'Project_loon.pdf'), 1212: ('ay interfere  with each other  (Goldsmith, 2013) . This means \\nthat the number of users that can be supported by each balloon has a n upper -limit and \\nadding more balloons to a densely populated area may not improve the situation.  \\n\\n \\n5 \\n A simpler way to imagine it is if the network is a single -phase multi -channel queue  (Figure \\n5). The bandwidth available is the channels, once you run out of b andwidth you cannot fit \\nany more queues into the system.  \\n \\nFigure 5  - Simplistic Representation of bandwidth network  \\nUnfortunately Google has not released information in regards to the number of users per \\nballoon. For this report it will be assumed that each balloon will not have a limit on the \\nnumber of supportable users. However there is a possible solution if this problem were to \\narise. If the balloons are able to shrink their coverage area when over high density \\npopulation zones then they will each ha ve fewer users to cover, meaning interference will be \\nless likely  (Goldsmith, 2013) . The trade -off to this is that in a more densely populated area \\nmore balloons will be required to cover the same space.  \\n \\nMaterial  Audit  \\nBased on information provided by go ogle about each individual balloons structure, a material \\naudit can be conducted (Table 2). The envelope was estimated as a rectangular prism \\nmeasuring 15mx15mx12m (Google) with a thickness  of 100μm. Little information is available \\nwith regards to the exac t types, weight or dimensions of the remainder of the balloon, so \\neach component was estimated.  \\nA large component of the embodied energy is the envelope. This is compounded by the fact \\nthat the envelope is the component of the system that will be replaced most ofte n; every 100 \\ndays. Therefore to reduce the total embodied energy of the system a different material could \\nbe used for the envelope. The major difficulty with selecting a replacement is that it must be \\ngas-tight.  \\n \\n \\n\\n \\n6 \\n Table 2 – Material audit for a  single balloon  \\nComponent  Specifics  Material/process  Amount  ', 'Project_loon.pdf'), 1213: ('as estimated.  \\nA large component of the embodied energy is the envelope. This is compounded by the fact \\nthat the envelope is the component of the system that will be replaced most ofte n; every 100 \\ndays. Therefore to reduce the total embodied energy of the system a different material could \\nbe used for the envelope. The major difficulty with selecting a replacement is that it must be \\ngas-tight.  \\n \\n \\n\\n \\n6 \\n Table 2 – Material audit for a  single balloon  \\nComponent  Specifics  Material/process  Amount  \\nEnvelope  \\n 12mx15m balloon \\nwith 100μm \\nthickness \\n(estimated as \\nrectangular prism)  polyethylene plastic  \\ndensity of 0.95g/cm3 \\n(British Plastics, n.d.)  1170m2 \\n111.5kg  \\nElectronics  \\n(antenna and \\nother \\ntransmission \\nequipment)  Estimated as 4 \\ndesktop \\ncomputers  \\n(Wattz O, n.d)  aluminium  \\nplastic  \\nsteel  \\ncopper  \\nglass  \\nnickel  \\ntin \\nlead \\n(Victoria University, n.d.)  4.368kg  \\n7.176kg  \\n6.552kg  \\n2.184kg  \\n7.800kg  \\n0.312kg  \\n0.312kg  \\n1.872kg  \\n30.577kg  \\nSolar Panels  \\n Estimated as 2 \\n20kg panels  silicon  \\naluminium  \\ncopper  \\nplastic  14kg  \\n16kg  \\n2kg \\n8kg \\n40kg  \\nBattery  Based on 12V \\n200AH Lithium Ion \\nBattery (Smart \\nBattery,  n.d.)   33kg  \\nGas cylinder  Based on Praxair \\n128bar \\npressurized \\ncylinder ( Praxair, \\nn.d.) Cylinder  \\nHydrogen (1.8m3 at \\n13.8MPa)  30kg  \\n18.65kg  \\n \\n \\n48.65kg  \\nParachute  Based on Mills G -\\n12E cargo \\nparachute (Mills \\nManufacturing, \\nn.d.) Nylon (Victoria \\nUniversity, n.d.)  57kg  \\nTOTAL    320.73kg  \\n \\nEnergy Lifecycle  \\nThe majority of embodied energy in the balloon is taken up  by the solar panels which power \\nit. It is arguable that this may be an acceptable amount because by using the solar panels \\nthe long term non -renewable energy consumption of the project is lowered. For example, if it \\nis assumed that each of the two panels generates 250W  of power (total of 500W), then it will \\ntake 4.45 years for each balloon to generate its own embodied energy in power.  \\n \\n \\n \\n \\n \\n \\n7 \\n Table 3 – Embodied Energy for single balloon  \\nComponent  Material/pro', 'Project_loon.pdf'), 1214: ('y in the balloon is taken up  by the solar panels which power \\nit. It is arguable that this may be an acceptable amount because by using the solar panels \\nthe long term non -renewable energy consumption of the project is lowered. For example, if it \\nis assumed that each of the two panels generates 250W  of power (total of 500W), then it will \\ntake 4.45 years for each balloon to generate its own embodied energy in power.  \\n \\n \\n \\n \\n \\n \\n7 \\n Table 3 – Embodied Energy for single balloon  \\nComponent  Material/process  Amount  Embodied \\nEnergy  % Total  \\nEnvelope  \\n polyethylene \\nplastic  \\nDensity of \\n0.95g/cm3 [2] 111.5kg  11484.5MJ  16.4%  \\nElectronics  \\n(antenna and \\nother \\ntransmission \\nequipment)  aluminium  \\nplastic  \\nsteel  \\ncopper  \\nglass  \\nnickel  \\ntin \\nlead \\nmanufacturing  \\n(Wattz O, n.d)  4.368kg  \\n7.176kg  \\n6.552kg  \\n2.184kg  \\n7.800kg  \\n0.312kg  \\n0.312kg  \\n1.872kg  \\n- \\n30.577kg  804MJ  \\n716MJ  \\n288MJ  \\n212MJ  \\n172MJ  \\n112MJ  \\n64MJ  \\n52MJ  \\n6000MJ  \\n8420MJ  12.0%  \\nSolar Panels  \\n silicon (Ashby, \\n2010)  \\naluminium  \\ncopper  \\nplastic  14kg  \\n \\n16kg  \\n2kg \\n8kg \\n40kg  26868MJ  \\n \\n2208MJ  \\n98MJ  \\n800MJ  \\n29974MJ  42.7%  \\nBattery  \\n  (Ashby, 2010)  33kg  10692MJ  15.2%  \\nGas cylinder  Cylinder (steel)  \\nHydrogen (1.8m3 at \\n13.8MPa)  30kg  \\n18.65kg  \\n \\n \\n48.65kg  1218.7MJ  \\n- 1.7%  \\nParachute  Nylon  \\n 57kg  8436MJ  12.0%  \\nTOTAL   320.73kg  70225.2MJ   \\n \\nFurthermore over a n entire  five year life span they would generate 78.84GJ of energy.   \\nConverting this amount of energy into an equivalent amount of gasoline burnt shows a \\nmassive reduction in emissions (Table 4) (U.S Department of Energy, 2011)(U.S Energy \\nInformation Administration, 2015) . \\nTable 4 – Energy and Emissions saved through Solar  Power  \\nScenario  Required \\nBalloons  Total Power \\nConsumed (GJ)  kg of Gasoline  Million Metric \\nTons of CO 2 \\n#1 (Australia)  4875.01  383,345  8,823,076  25,908  \\n#2 (India)  2365.31  186,552  4,293,684  12,608  \\n \\nMost of the other equipment on the balloon  will rarely be replaced and if so, most electronic \\nor m', 'Project_loon.pdf'), 1215: ('ine burnt shows a \\nmassive reduction in emissions (Table 4) (U.S Department of Energy, 2011)(U.S Energy \\nInformation Administration, 2015) . \\nTable 4 – Energy and Emissions saved through Solar  Power  \\nScenario  Required \\nBalloons  Total Power \\nConsumed (GJ)  kg of Gasoline  Million Metric \\nTons of CO 2 \\n#1 (Australia)  4875.01  383,345  8,823,076  25,908  \\n#2 (India)  2365.31  186,552  4,293,684  12,608  \\n \\nMost of the other equipment on the balloon  will rarely be replaced and if so, most electronic \\nor metallic components can be recycled. The plastic used to create the envelope is also \\nrecyclable. The major risk in regards to the envelope is pollution. Should the envelope be \\njettisoned for any reas on it poses a n environmental risk, especially to wildlife which may \\nbecome tangled in the remains. Therefore a major focus of the design should be to ensure \\nthat the envelope is securely fastened whereby  even if  it is damaged it remains attached to \\nthe ea sily locatable balloon.  \\n \\n8 \\n Operational Consumption  \\nFigure 6 is a Sankey Diagram  for the estimated flows of energy within Project Loon . The \\nmajor loss of energy is through the in efficiency of the solar panels (Hirst, Elkins -Daukes , \\n2010) . This loss is acceptable because  as discussed  all energy entering the system is \\nrenewable.  \\nThe mechanism by which the balloons control altitude is not fully detailed by Google but it is \\nassumed that they operate in the sam e manner as weather balloons, by altering the \\npressure in the envelope  through  the pumping or releasing of hydrogen  gas. To do so a  \\nsmall pump would have to be used which would consume more energy during operation.  \\nThe final major use of energy is through the actual creation of the network. Whether \\ncommunicating betwee n themselves or with users on the ground each balloon must transmit \\nmany signals over long distances.  If a signal is required to travel a further distance without \\ndistortion then it requires a greater amount of power  (Goldsmith, 2013) . This means that an \\ni', 'Project_loon.pdf'), 1216: ('  the pumping or releasing of hydrogen  gas. To do so a  \\nsmall pump would have to be used which would consume more energy during operation.  \\nThe final major use of energy is through the actual creation of the network. Whether \\ncommunicating betwee n themselves or with users on the ground each balloon must transmit \\nmany signals over long distances.  If a signal is required to travel a further distance without \\ndistortion then it requires a greater amount of power  (Goldsmith, 2013) . This means that an \\nincrease in energy that the battery and solar panels can supply would result in improved \\nperformance by the antennas. Therefore it is recommended that every few years the \\nballoons be updated with the most efficient solar technology. This will not be integra ted into \\nthe cost as this paper is concerned with the feasibility of Project Loon with presently \\navailable materials.  \\n \\n \\nFigure 6 – Sankey Diagram of a Project Loon  balloon  \\n \\nSafety  \\nA major safety concern with Project Loon is congestion of air space. Each balloon is \\ndesigned to operate at an altitude of roughly 20km (Google, n.d.) which is above the ~18km \\nmaximum of aircraft (Airservices Australia, n.d.). This means that during normal  operation \\n\\n \\n9 \\n there should be minimum risk of mid -air collisions involving Project Loon balloons and other \\naircraft as they should not occupy the same airspace. The exception to this rule is whilst the \\nballoons are ascending  or descending at the beginning or end of their 100 day operational \\ncycle . The  best workaround for this issue is to have certain restricted airspace locations \\nwhere balloons can safely rise and fall ; an exam ple would be a n airfield where the balloons  \\ncan take -off and then land after each cycle . Constructing such zones would require \\ncoordination with air traffic authorities.  \\nThe second concern is what happens if a balloon is da maged during operating, as a single \\npuncture to the envelope could render a balloon unable to maintain height. If currently \\nsuspended over a resid', 'Project_loon.pdf'), 1217: (' best workaround for this issue is to have certain restricted airspace locations \\nwhere balloons can safely rise and fall ; an exam ple would be a n airfield where the balloons  \\ncan take -off and then land after each cycle . Constructing such zones would require \\ncoordination with air traffic authorities.  \\nThe second concern is what happens if a balloon is da maged during operating, as a single \\npuncture to the envelope could render a balloon unable to maintain height. If currently \\nsuspended over a residential or populated area, the chance of the balloon falling on \\nsomeone or private property is unacceptable.  G oogle has indicated that this risk will be \\nmitigated by the emergency parachute installed onto the balloon (Google, n.d.).  The \\nparachute model was selected so that the rest of the balloon fell within its safe operating \\nrange (Mills Manufacturing, n.d.). C are must be taken when altering components of each \\nballoon as weight is an important factor when designing an air vessel. If a more powerful \\nantenna is desired to support a larger service area then it may weigh more; in turn the \\nenvelope may need to be lar ger to support the extra weight, more gas may be used and a \\nlarger parachute must be used to support the structure in the event of a failure.  \\n \\nDynamics and Control  \\nThe balloons control their location by riding wind currents in the stratosphere. Above the \\ntropopause traditional weather patterns stop, meaning that conditions at the balloons \\noperation level is more consistent. This means that to reach a desired destination, the \\nballoons merely have to raise or lower their altitude into the desired wind current . This \\nmeans that Project Loon is an inherently dynamic system as each balloon in the array will be \\nconstantly shifting. Another network solution with a similar dynamics nature  is satellite \\nnetworks. Satellites have two major upside s though, firstly the orbits of satellites are 100% \\npredictable; secondly a satellite ’s orbit can be made geostationary, where its position abo', 'Project_loon.pdf'), 1218: ('ans that to reach a desired destination, the \\nballoons merely have to raise or lower their altitude into the desired wind current . This \\nmeans that Project Loon is an inherently dynamic system as each balloon in the array will be \\nconstantly shifting. Another network solution with a similar dynamics nature  is satellite \\nnetworks. Satellites have two major upside s though, firstly the orbits of satellites are 100% \\npredictable; secondly a satellite ’s orbit can be made geostationary, where its position above \\nthe earth does not change. This stability means that or ganizing a satellite communication \\nnetwork is much easier then what Google intends to do. This can partially be  rectified by \\nusing feedback systems to effectively control the movement of the balloons (Franklin 2010). \\nA simple block structure of the altitud e control system is shown in Figure 7. As discussed a \\npump or motor is used to release or pump gas into the envelope, thereby changing altitude.  \\nFigure 7  – location to altitude processing  \\nThe balloons are also able to communicate between each other meanin g that they can \\norganise themselves into a network that best suits the area they are currently covering.  \\n\\n \\n10 \\n  \\nFigure 8 – addition of communication to prioritise locations  \\nAs the wind currents may gradually shift, a weather data feedback loop can be implemented \\nwhich allows balloons to adapt to shifting conditions. Furthermore using their communication \\nsystems  if one of them enters an unstable or undesirable condition then i t can warn other \\nballoons of the situation.  This is mainly a further safety precaution as the altitude at which \\nthey operate is largely devoid of traditional weather which could damage them.  \\n \\nFigure 9 – Feedback loop with weather and wind data  \\nThis contro l system is one of the most key aspects of the project. If not implemented \\ncorrectly then balloons may not be able to reach areas in need of coverage or may interfere \\nwith each other. The worst case scenario would be two balloons colliding due to', 'Project_loon.pdf'), 1219: ('t can warn other \\nballoons of the situation.  This is mainly a further safety precaution as the altitude at which \\nthey operate is largely devoid of traditional weather which could damage them.  \\n \\nFigure 9 – Feedback loop with weather and wind data  \\nThis contro l system is one of the most key aspects of the project. If not implemented \\ncorrectly then balloons may not be able to reach areas in need of coverage or may interfere \\nwith each other. The worst case scenario would be two balloons colliding due to a control ler \\nmalfunction. Therefore this paper recommends extensive testing of the control systems, \\nespecially in scenarios where several balloons are in the same area, for both safety and \\nefficiency reasons.  \\n \\nCoverage  \\nEach balloon only has a limited coverage area of 40km in diameter (Google). This translates \\nto a circle of 1257km2 on the ground. This area can be used to determine how many \\nballoons are re quired in each scenario (Table 5 ). This can then be extrapolated to determine \\nhow many users each balloon would h ave to support, assuming 100% take up rate.  \\nTable 5  – Coverage of each balloon  \\nScenario  Potential Users  Supported \\nArea (km2) Users/km2 Required \\nBalloons  Users/Balloon  \\n#1 (Australia)  4,742,860  6,127,889  0.77 4875.01  967.89  \\n#2 (India)  1,027,773,567  2,973,190  345.7  2365.31  434544.90  \\n \\nIt should be noted that the above numbers incur a slight error due to circle packing (Figure \\n10). With no overlap the balloons would only be able to cover 90.7% of the total area \\n\\n \\n11 \\n (Stephenson, 2003 ). To solve this , a greater number of balloons could be deployed so that a \\nslight overlapping occurs . The trade -off to this is that once again interference can occur \\nwhen several balloons are in each other’s operation area.  \\n \\nFigure 10 – Circle Packing Error Illustration  \\n \\nCost  \\nA major consideration for this project is whether to charge the public for access and if so, \\nhow much. This paper will assume that Google intends to make no profit directly off of \\nProject Loon', 'Project_loon.pdf'), 1220: (' \\n\\n \\n11 \\n (Stephenson, 2003 ). To solve this , a greater number of balloons could be deployed so that a \\nslight overlapping occurs . The trade -off to this is that once again interference can occur \\nwhen several balloons are in each other’s operation area.  \\n \\nFigure 10 – Circle Packing Error Illustration  \\n \\nCost  \\nA major consideration for this project is whether to charge the public for access and if so, \\nhow much. This paper will assume that Google intends to make no profit directly off of \\nProject Loon and that any costs  to the user merely keep the project from running at a deficit. \\nFirstly the material audit is used to estimate the cost per balloon.  \\nTable 6 – Estimated material c osts per Balloon  \\nComponent  Material/process  Amount  Cost  \\nEnvelope  \\n polyethylene plastic  \\nDensity of 0.95g/cm3 [2] 111.5kg  $1080  \\nElectronics  \\n(antenna and other \\ntransmission \\nequipment)  aluminium  \\nplastic  \\nsteel  \\ncopper  \\nglass  \\nnickel  \\ntin \\nlead \\n 4.368kg  \\n7.176kg  \\n6.552kg  \\n2.184kg  \\n7.800kg  \\n0.312kg  \\n0.312kg  \\n1.872kg  \\n30.577kg  $12100  \\nSolar Panels  \\n silicon  \\naluminium  \\ncopper  \\nplastic  14kg  \\n16kg  \\n2kg \\n8kg \\n40kg  $1140  \\nBattery  \\n   33kg  $2400  \\nGas cylinder  Cylinder (steel)  \\nHydrogen (1.8m3 at \\n13.8MPa)  30kg  \\n18.65kg  \\n \\n \\n48.65kg  $500 \\n$150  \\nParachute  Nylon  \\n 57kg  $500  \\nTOTAL   320.73kg  $17870  \\n\\n \\n12 \\n The total cost of implementing the required number of balloons for each of the scenarios  is \\nthen calculated . \\nTable 7 – Total initial  cost of each scenario  \\nScenario  Required \\nBalloons  Users/Balloon  Total Initial Cost  Total Cost over 5 \\nyears  \\n#1 \\n(Australia)  4875.01  967.89  $87,116,429  $196,550,250  \\n#2 (India)  2365.31  434544.90  $42,268,090  $95,364,569  \\n \\nTwo assumptions are now used to help estimate ongoing costs. If a balloon only operates \\nunder normal conditions and as such receives minimal wear and tear, the only components \\nthat should have to be replaced every 100 day cycle are the envelope and the gas; a total \\ncost of $1230. The next assumption is tha', 'Project_loon.pdf'), 1221: ('uired \\nBalloons  Users/Balloon  Total Initial Cost  Total Cost over 5 \\nyears  \\n#1 \\n(Australia)  4875.01  967.89  $87,116,429  $196,550,250  \\n#2 (India)  2365.31  434544.90  $42,268,090  $95,364,569  \\n \\nTwo assumptions are now used to help estimate ongoing costs. If a balloon only operates \\nunder normal conditions and as such receives minimal wear and tear, the only components \\nthat should have to be replaced every 100 day cycle are the envelope and the gas; a total \\ncost of $1230. The next assumption is that each balloon will be in operation for 5 years.  \\n \\nFigure 11 – pay-back period for cost parity  \\nIf the project  is to be run at no deficit to Google then the entirety of the cost of balloons must \\nbe carried over to the customer . A payback period plot (Figure 11 ) is used to determine the \\ncost to customers to fulfil this zero deficit requirement. Unlike a normal payb ack period plot \\nwhich compares two known quantities to each other, this one is designed to find the \\nunknown quantity of cost to customers over five years. This is found by selecting the \\ngradient of the line so that intersection occurs on the five year mark . As each balloon has an \\nongoing cost of $40318 over the five years, the gradient can be used to determine the cost \\nfor each group of customer per day. This is then divided between each scenario in table 8 to \\nfind the cost per user per day.  \\n \\n 05000100001500020000250003000035000400004500050000\\n0 500 1000 1500 2000 2500Cost ($)  \\nDay Balloon Cost\\nUser Cost\\n \\n13 \\n Table 8  – Cost per customer with 100% take -up rate  \\nScenario  Cost per Balloon \\nover 5 years  Users/Balloon  Cost/User over 5 \\nyears  Cost/User per \\nday \\n#1 (Australia)  $40318  967.89  $41.66  $0.023 \\n#2 (India)  $40318  434544.90  $0.093  $0.000051  \\n \\nThis is of course assuming that  every single person possible uses the service. Instead we \\nwill assume that only 5% of each user base actually makes use of the service, a much more \\nreasonable estimation.  \\nTable 9  – Cost per customer with 5% take -up rate  \\nScenario  Co', 'Project_loon.pdf'), 1222: (' customer with 100% take -up rate  \\nScenario  Cost per Balloon \\nover 5 years  Users/Balloon  Cost/User over 5 \\nyears  Cost/User per \\nday \\n#1 (Australia)  $40318  967.89  $41.66  $0.023 \\n#2 (India)  $40318  434544.90  $0.093  $0.000051  \\n \\nThis is of course assuming that  every single person possible uses the service. Instead we \\nwill assume that only 5% of each user base actually makes use of the service, a much more \\nreasonable estimation.  \\nTable 9  – Cost per customer with 5% take -up rate  \\nScenario  Cost per Balloon \\nover 5 years  Users/Balloon \\n(5%)  Cost/User over 5 \\nyears  Cost/User per \\nday \\n#1 (Australia)  $40318  48.39  $833.19  $0.46 \\n#2 (India)  $40318  21727.25  $1.86  $0.001  \\n \\nThe biggest hurdle for Project Loon is that monetizing it will make it less appealing for use. \\nThis is compounded by the fact (recalling back to Figure 3) that areas which are in greater \\nneed of access are also occupied by poorer people. This implies that Project Loon is \\ninherently unprofitable as charging for access will drive away the core user base.  \\nThis leads to the most important recommendation of this report. Google received 187 million \\nunique visitors in the month of February 2014  (ComScore , 2014) . For the quarter that \\nincluded February of that year Google.com reported total revenue of 10.47 billion dollars \\n(Google  investor , 2014). Making the simple assumption that this profit was spread evenly \\nover all the users this equates to $ 18.66  per user  per month . This may be  too high due  to \\nerror associated with th e fact that not all of the site ’s income will be  directly from user \\nadvertisement revenue . To compensate we will take that only 10% of this is due to \\nadvertising, or $ 1.87 for each user.  \\nBy taking t he 5% uptake assumption from each scenario table 10 shows th e estimated \\nincrease in profits and compares that to the calculated cost of the required balloons  over one \\nmonth (average per month calculated from previous 5 year data ). \\nTable 10 – Project Revenue of Project Loon in each sce', 'Project_loon.pdf'), 1223: ('iated with th e fact that not all of the site ’s income will be  directly from user \\nadvertisement revenue . To compensate we will take that only 10% of this is due to \\nadvertising, or $ 1.87 for each user.  \\nBy taking t he 5% uptake assumption from each scenario table 10 shows th e estimated \\nincrease in profits and compares that to the calculated cost of the required balloons  over one \\nmonth (average per month calculated from previous 5 year data ). \\nTable 10 – Project Revenue of Project Loon in each scenario  \\nScenario  Potential Users \\n(5% take up rate)  Required \\nBalloons  Cost per \\nMonth  Revenue per \\nUser  per \\nMonth  Total Revenue  \\nIncrease  per \\nmonth % of cost \\nCovered  \\n#1 (Australia)  237,143  4875.01  $3,275,844  $1.87  $4,445,257 13.5% \\n#2 (India)  51,388,678  2365.31  $1,589,409  $1.87  $96,096,827  6046.1 % \\n \\nClearly based on these assumptions Project Loon would not be remotely profitable  in \\nAustralia due to the fact that there are far less possible users and the coverage area is  much  \\ntoo large. Conversely it would  be extremely  profitable in India  and make back its running \\ncosts by 6046.1%. Using this 5% take -up rate data and the associated cos ts of each balloon, \\nthe critical  user density to make Loon profitable was found to be 5.72 users/km2 (Figure 12 ). \\n \\n14 \\n  \\nFigure 12 – The critical user density for cost parity  \\nIt must be kept in mind that these numbers are estimations and several sources of error or \\naspects that are outside the scope of this report can be identified. For example, the total \\ncalculated costs only estimates the physical cost of each balloon; it does not take into \\naccount wages of people constructing or maintaining the network. The distinction between \\nrevenue and profit must also be highlighted; the total money gained will  be significantly \\nreduced once taxes and other unaccounted for fees are applied.  \\nA way to limit any risks associated with the project is to complete test trials, something that \\nGoogle has already begun completing (Google, n.d.). By', 'Project_loon.pdf'), 1224: ('For example, the total \\ncalculated costs only estimates the physical cost of each balloon; it does not take into \\naccount wages of people constructing or maintaining the network. The distinction between \\nrevenue and profit must also be highlighted; the total money gained will  be significantly \\nreduced once taxes and other unaccounted for fees are applied.  \\nA way to limit any risks associated with the project is to complete test trials, something that \\nGoogle has already begun completing (Google, n.d.). By slowly rolling out coverage, if an \\narea is found to be unviable then resources can be shifted from the area. For example with \\nthe scenarios discussed, if Australia was determined to not be viable for the project, all \\nBalloons constructed for it could be diverted to more appr opriate locations. This not only \\nsaves money but embodied energy as fewer resources would be consumed.  \\n \\nRecommendations  \\nThe control systems of the balloons must be rigorously designed and tested. Failing to do so \\nwould lead to inefficiency in the network du e to coverage gaps or interference between \\nballoons. Poorly coordinated balloons also have a much greater risk of collision which would \\nnot only be a financial liability but could also prove to be a safety risk.  \\nSafety should also be further emphasized by ensuring that the balloons weight conforms to \\nthe installed safety parachute. Google should also coordinate with air traffic authorities to \\ncreate safe zones for balloon ascent and descent.  \\n 0100002000030000400005000060000\\n0 1 2 3 4 5 6 7 8Revenue for a Balloon  \\nUsers per km2 Cost of Balloon\\nEstimated Revenue\\n \\n15 \\n The major finding of this report is that Project Loon  would be feasible if Google consider ed \\nimplementing Project Loon at no cost to users because this would  indirectly  generate income \\ndue to advertisement revenue . Furthermore Project Loon would act as an investment into \\nfuture infrastructure for the company as an increased number of internet users results in  a \\nlarger potential number of custome', 'Project_loon.pdf'), 1225: ('0060000\\n0 1 2 3 4 5 6 7 8Revenue for a Balloon  \\nUsers per km2 Cost of Balloon\\nEstimated Revenue\\n \\n15 \\n The major finding of this report is that Project Loon  would be feasible if Google consider ed \\nimplementing Project Loon at no cost to users because this would  indirectly  generate income \\ndue to advertisement revenue . Furthermore Project Loon would act as an investment into \\nfuture infrastructure for the company as an increased number of internet users results in  a \\nlarger potential number of customers for future endeavours . However Google should \\ncarefully inspect each intended operational area to ensure that implementing the project will \\nat least result in no financial losse s. The minimum user density in an area should be 5.72 \\nusers/km2. Financial risk can also be minimized by undergoing a staggered rollout so that \\nalready completed balloons and resources can be redirected should an area become \\nunviable.  \\n \\n \\n16 \\n References  \\nAirservices Australia, n.d., How airspace is managed , viewed 5 October 2015  \\n<http://www.airservicesaustralia.com/services/how -air-traffic -control-works/how -airspace -is-\\nmanaged/ > \\nAshby M. F., 2010, Materials and the Environment: Eco -informed Material Choice  \\nAustralian Bureau of Statistics, 2012, Year Book Australia 2012 , viewed 5 October 2015, \\n<http://www.abs.gov.au/ausstats/abs@.nsf/mf/1301.0 > \\nAustralian Bureau of Statistics, 2014, Household internet Access ; 25/02/14; viewed 5 \\nOctober 2015  \\n<http://www.abs.gov.au/ausstats/abs@.nsf/Lookup/8146.0Chapter12012 -13> \\nAustralian Bureau of Statistics, 2015, Australian Demographic Statistics, Mar 2015 , 5 \\nOctober 2015,  \\n<http://www.abs.gov.au/au sstats/abs@.nsf/mf/3101.0 > \\nBritish Plastics Federation, n.d., Polyethylene (High Density) Fact Sheet,  viewed 5 October \\n2015  \\n<http://www.bpf.co.uk/plastipedia/polymers/HDPE.aspx > \\nComScore, 2014, comScore ranks top 50 U.S desktop web properties for February 2014 , \\nviewed 12 October 2015  \\n<http://www.comscore.com/Insights/Press -Releases/2014/3/comScore -Media -M', 'Project_loon.pdf'), 1226: ('012 -13> \\nAustralian Bureau of Statistics, 2015, Australian Demographic Statistics, Mar 2015 , 5 \\nOctober 2015,  \\n<http://www.abs.gov.au/au sstats/abs@.nsf/mf/3101.0 > \\nBritish Plastics Federation, n.d., Polyethylene (High Density) Fact Sheet,  viewed 5 October \\n2015  \\n<http://www.bpf.co.uk/plastipedia/polymers/HDPE.aspx > \\nComScore, 2014, comScore ranks top 50 U.S desktop web properties for February 2014 , \\nviewed 12 October 2015  \\n<http://www.comscore.com/Insights/Press -Releases/2014/3/comScore -Media -Metrix -Ranks -\\nTop-50-US-Desktop -Web-Properties -for-February -2014 > \\nDepartment of Communications, 2013, Broadband Availability and Quality Report , Australia, \\nviewed 5 October 2015 \\n<https://www.mybroadband.communications.gov.au/upload/documents/Final_report%20(2).\\npdf> \\nFranklin G. F., Powell J. D., Emami -Naeini A, 2010, Feedback Control of D ynamic Systems, \\nSixth Edition , Pearson  \\nGeoscience Australia, 2004, Geodata coast 100K 2004 , Department of Industry, Tourism \\nand Resources, Australia  \\nGoldsmith A, 2013, Wireless Communications , Cambridge University Press  \\nGoogle , n.d.,  What is Loon? ; viewed 5 October 2015  \\n<http://www.google.com/loon/ > \\nGoogle Investor , 2014 , Q1 2014 Quarterly Earnings Summary , viewed 12 October 2015  \\n<https://investor.google.com/pdf/2014Q1_google_earnings_slides.pdf > \\nHirst L. C., Elkins -Daukes N. J., 2010 Fundamental Losses in Solar Cells ; Department of \\nPhysics, Imperial College London, viewed 5 October 2015  \\n<http://sun.anu.edu.au/files/pvsec2009_Hirst2009.pdf > \\nInternational Monetary Fund, 2015, World Economic Outlook Database  \\n \\n17 \\n International Telecommunications Union, 201 4, ICT Data and Statistics,  United Nations  \\nMills Manufacturing,  n.d., G-12 Cargo Parachute Factsheet , viewed 5 October 2015  \\n<http://www.millsmanufacturing.com/products/cargo -parachutes/14 -products/45 -g-12-cargo -\\nparachute -assembly > \\nMinistry of Home  Affairs India, 2011,  Indian Census Data , published 2011 , viewed 5 October \\n2015  \\n<http://censusindia.gov.in/2011cen', 'Project_loon.pdf'), 1227: ('9.pdf > \\nInternational Monetary Fund, 2015, World Economic Outlook Database  \\n \\n17 \\n International Telecommunications Union, 201 4, ICT Data and Statistics,  United Nations  \\nMills Manufacturing,  n.d., G-12 Cargo Parachute Factsheet , viewed 5 October 2015  \\n<http://www.millsmanufacturing.com/products/cargo -parachutes/14 -products/45 -g-12-cargo -\\nparachute -assembly > \\nMinistry of Home  Affairs India, 2011,  Indian Census Data , published 2011 , viewed 5 October \\n2015  \\n<http://censusindia.gov.in/2011census/censusinfod ashboard/index.html > \\nPraxair, n.d.,  Compressed Hydrogen Cylinder Factsheet , viewed 5 October 2015  \\n<http://www.praxair.com/~/media/North%20America/US/Documents/Specification%20Sheet\\ns%20and% 20Brochures/Gases/Hydrogen%20H2%20Spec%20Sheet%20SS%20P4604.pdf\\n> \\nSmart Battery,  n.d., Lithium Ion Battery Factsheet , viewed 5 October 2015  \\n<http://www.lithiumion -batteries.com/products/12v -200ah -lithium -ion-battery/12v -200ah -\\nlithium -ion-battery.php > \\nStephenson K, 2003, Circle Packing: A Mathematical Tale , Notices of the AMS, December \\n2003  \\nU.S D epartment of Energy , 2011,  Biomass Energy Databook , viewed 5 October 2015  \\n<http://cta.ornl.gov/bedb/appendix_a/Lower_and_Higher_Heating_Values_of_Gas_Liquid_a\\nnd_Solid_Fuels.pdf > \\nU.S En ergy Information Administration, 2015,  CO 2 emissions of fuels , viewed 5 October \\n2015 < http://www.eia.gov/tools/faqs/faq.cfm?id=73&t=11 > \\nVictoria University, n.d.,  Embodied energy coefficients , Wellington,  viewed 6 October 2015  \\n<http://www.victoria.ac.nz/architecture/centres/cbpr/resources/pdfs/ee -coefficients.pdf > \\nWattz O, n.d.,  Embodied energy of a desktop computer , viewed 6 Octo ber 2015  \\n<http://legacy.wattzon.com/stuff/items/k49t7pnp5206tyaa72nyws146d > \\n ', 'Project_loon.pdf'), 1228: ('148ExplainableAI for Medical Data:Current Methods,\\nLimitations, andFuture Directions\\nMD IMRAN HOSSAIN andGHADAZAMZMI ,Universityof SouthFlorida,USA\\nPETER R. MOUTON ,SRC Biosciences, USA\\nMD SIRAJUS SALEKIN ,YUSUN,a n dDMITRY GOLDGOF ,Universityof SouthFlorida,USA\\nWiththepowerofparallelprocessing,largedatasets,andfastcomputationalresources,deepneuralnetworks\\n(DNNs)haveoutperformedhighlytrainedandexperiencedhumanexpertsinmedicalapplications.However,\\nthelargeglobalcommunityofhealthcareprofessionals,manyofwhomroutinelyfacepotentiallylife-or-death\\noutcomeswithcomplexmedicolegalconsequences,haveyettoembracethispowerfultechnology.Themajor\\nproblemisthatmostcurrentAIsolutionsfunctionasametaphoricalblack-boxpositionedbetweeninputdata\\nandoutputdecisionswithoutarigorousexplanationfortheirinternalprocesses.Withthegoalofenhancing\\ntrustandimprovingacceptance of artificial intelligence– (AI) basedtechnologyin clinical medicine, thereis\\na large and growing effort to address this challenge using eXplainable AI (XAI), a set of techniques, strate-\\ngies, and algorithms with an explicit focus on explaining the “hows and whys” of DNNs. Here, we provide\\na comprehensive review of the state-of-the-art XAI techniques concerning healthcare applications and dis-\\ncuss current challenges and future directions. We emphasize the strengths and limitations of each category,\\nincluding image, tabular, and textual explanations, and explore a range of evaluation metrics for assessing\\ntheeffectivenessofXAIsolutions.Finally,wehighlightpromisingopportunitiesforXAIresearchtoenhance\\nthe acceptance of DNNs by thehealthcare community.\\nCCS Concepts: • Computing methodologies →Machine learning ;•General and reference →Evalu-\\nation;\\nAdditionalKeyWordsandPhrases:Explainability,medicaldata,responsibleAI,deepneuralnetworks,inter-\\npretable AI\\nACM Reference format:\\nMd Imran Hossain, Ghada Zamzmi, Peter R. Mouton, Md Sirajus Salekin, Yu Sun, and Dmitry Goldgof. 2025.\\nExplainable AI for Medical Data: Current Methods, Limitations, and Future Directions. ACM Comput. Surv', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1229: ('itiesforXAIresearchtoenhance\\nthe acceptance of DNNs by thehealthcare community.\\nCCS Concepts: • Computing methodologies →Machine learning ;•General and reference →Evalu-\\nation;\\nAdditionalKeyWordsandPhrases:Explainability,medicaldata,responsibleAI,deepneuralnetworks,inter-\\npretable AI\\nACM Reference format:\\nMd Imran Hossain, Ghada Zamzmi, Peter R. Mouton, Md Sirajus Salekin, Yu Sun, and Dmitry Goldgof. 2025.\\nExplainable AI for Medical Data: Current Methods, Limitations, and Future Directions. ACM Comput. Surv.\\n57, 6, Article148 (February 2025), 46 pages.\\nhttps://doi.org/10.1145/3637487\\n1 INTRODUCTION\\nSince the early 2010s, artificial intelligence (AI) powered by deep learning has demonstrated\\nremarkable performance in the medical domain with applications for skin disease identification\\nAuthors’ addresses: Md I. Hossain, G. Zamzmi, Md S. Salekin, Y. Sun, and D. Goldgof, Department of Computer Science\\nandEngineering,ENB,UniversityofSouthFlorida,4202E.FowlerAve,Tampa,FL33620,USA;e-mails:{mdimranh,ghadh,\\nsalekin, yusun}@usf.edu, goldgof@mail.usf.edu; P. R. Mouton, SRC Biosciences, 1810 W. Kennedy Blvd, Tampa, Florida\\n33606,USA; e-mail:petermouton@usf.edu.\\nPermission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee\\nprovided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\\nthe full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be\\nhonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,\\nrequires prior specific permission and/or a fee.Request permissions from permissions@acm.org .\\n© 2025Copyrightheld bytheowner/author(s). Publicationrights licensed toACM.\\n0360-0300/2025/02-ART148$15.00\\nhttps://doi.org/10.1145/3637487\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n\\n148:2 Md I.Hossain et al.\\n[172], COVID-19 detection [ 193], early pain detection in neonates [ ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1230: ('ed.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,\\nrequires prior specific permission and/or a fee.Request permissions from permissions@acm.org .\\n© 2025Copyrightheld bytheowner/author(s). Publicationrights licensed toACM.\\n0360-0300/2025/02-ART148$15.00\\nhttps://doi.org/10.1145/3637487\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n\\n148:2 Md I.Hossain et al.\\n[172], COVID-19 detection [ 193], early pain detection in neonates [ 178], the diagnosis of retinal\\ndisease [113], image segmentation [ 83], and classification of various malignancies from patholog-\\nicalimagesofbreast[ 11]andbraincancer[ 93].Despitetheseadvancements,implementing deep\\nneural networks (DNNs) has been slow to gain wide acceptance in various clinical healthcare\\nsettings.Thisreluctancearisesduetoprioritizingaccuracyovermakingthedecision-makingpro-\\ncesses explainable [ 142]. Explainability adds a powerful tool for verifying and improving perfor-\\nmance by detecting weaknesses, learning patterns in the input data, and identify clinically mean-\\ningless features in the millions of input parameters and hundreds of network layers [ 180]. Most\\nimportantly,usingXAItomakehealthcarealgorithmsmoretransparentwillhelpcliniciansbuild\\ngreatertrustintheirdecision-makingprocesses.\\nExisting XAI approaches for image analysis can be classified as attribution based and non-\\nattributionbased.Attribution-basedapproacheshighlightthedecision-makingregionoftheimage\\nby generating a heatmap, while non-attribution-based approaches help analyze model behavior,\\nmodel debugging, and even explain the prediction decision step by step. Attribution-based ap-\\nproaches have been used with several medical imaging applications, including COVID detection\\n[4], knee pain assessment [ 24], Alzheimer’s disease classification [ 22], and diagnosing multiple\\nsclerosis (MS) [ 44]. Examples of non-attribution-based approaches include clinically meaningful\\nconceptsselectionforexplainingcardiac magneticresonanceimaging', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1231: ('hile non-attribution-based approaches help analyze model behavior,\\nmodel debugging, and even explain the prediction decision step by step. Attribution-based ap-\\nproaches have been used with several medical imaging applications, including COVID detection\\n[4], knee pain assessment [ 24], Alzheimer’s disease classification [ 22], and diagnosing multiple\\nsclerosis (MS) [ 44]. Examples of non-attribution-based approaches include clinically meaningful\\nconceptsselectionforexplainingcardiac magneticresonanceimaging(MRI) segmentation[ 64],\\nimage perturbation for knee osteoarthritis severity [ 183], and prototypical images for classifying\\ncanceror non-cancer[ 212].\\nIn addition, the multimodal XAI method is becoming more and more prevalent in healthcare\\napplications due to the variety of medical data sources involved. Instead of concentrating on a\\nsingledatatype,themultimodalXAIexplainsdifferentimagingmodalitieslikeX-ray,CT,andMRI\\nordifferentdatakindslikeimages,time-seriesdata,sequentialdata,clinicalrecords,andmetadata.\\nXAI clarifies the roles of different data types [ 222], explicates the relationship and significance of\\ndifferentdatatypes[ 235],elucidatesthecriticalfeatures[ 89],andoffersinsightsintotheinfluential\\ndatapointsfrom differentmodalities.\\nThe importance of explainability and its role in creating trustworthy AI pushed researchers to\\nconductcomprehensivereviewsofcurrentXAImethods.Forinstance,generalXAIconcept,taxon-\\nomy,variousdefinitions,reviewsofbothdeepandshallowmodels,programmingimplementation,\\nresearchtopicsassociatedwithexplainability,challengesofXAI,andguidelinesforresponsibleAI\\nhavebeenpresentedinReferences[ 8,36,42,79,123,219,232].Similarly,theauthorsofReference\\n[21] categorized the explanations methods, described the methods based on three popular data\\ntypes(images,tabulardata,andtext),andadditionallyreportedacomparisontoassessseveralvi-\\nsualXAImethods.Formulti-modaldata,Joshietal.[ 87]reviewedrelatedmethods,presentedthe\\nchallenges of XAI in multi-modal datasets, and discussed the significance, challeng', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1232: ('csassociatedwithexplainability,challengesofXAI,andguidelinesforresponsibleAI\\nhavebeenpresentedinReferences[ 8,36,42,79,123,219,232].Similarly,theauthorsofReference\\n[21] categorized the explanations methods, described the methods based on three popular data\\ntypes(images,tabulardata,andtext),andadditionallyreportedacomparisontoassessseveralvi-\\nsualXAImethods.Formulti-modaldata,Joshietal.[ 87]reviewedrelatedmethods,presentedthe\\nchallenges of XAI in multi-modal datasets, and discussed the significance, challenges, and future\\ntrends.SeveralreviewershavebeenpublishedinthecaseofXAIformedicalimagingapplications.\\nFor example, Huff et al. [ 78] reviewed the visualization methods to highlight the important parts\\nof medical images. In addition, the applications of the XAI methods in medical image analysis ac-\\ncordingtotheanatomicallocationarepresentedinReference[ 215];otherreviewscanbefoundin\\nReferences[ 127,177,211]wheretheauthorspresentXAImethodsforunderstandingthedecision\\nofmedical imaging tasksin termsof clinicaloverflow.\\nUnlike the previous works, this article presents a comprehensive review of XAI techniques for\\nmedical data, including image, tabular, textual, and multimodal; provides a summary of evalu-\\nation metrics; highlights the strengths, weaknesses, and recommendations of each explanation\\ncategory; and focuses on future research direction. This review covers various XAI factors that\\ncontributetotheprinciplesofresponsibleAI,whicharepresentedinFigure 1.Asshowninthefig-\\nure,understandingexplainability(intermsofdata,taxonomy,metrics,etc.)isthefirststeptowards\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:3\\nFig.1. KeyXAI challenges discussedinthisreview, as wellas their impact on theresponsibleAI principles.\\ndevelopingtransparent,robust,fair,andreproducibleAI;i.e.,explainabilityisthecentralpillarof\\nresponsibleAIasprovidinganexplanationofwhyAImodelsbehaveinaspecificwaycanleadto\\nbetter transparency while making it easier to detect wrong and unfair decisio', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1233: ('ta,taxonomy,metrics,etc.)isthefirststeptowards\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:3\\nFig.1. KeyXAI challenges discussedinthisreview, as wellas their impact on theresponsibleAI principles.\\ndevelopingtransparent,robust,fair,andreproducibleAI;i.e.,explainabilityisthecentralpillarof\\nresponsibleAIasprovidinganexplanationofwhyAImodelsbehaveinaspecificwaycanleadto\\nbetter transparency while making it easier to detect wrong and unfair decisions, which is critical\\nto buildinguser’strust.\\nThemain contributionsof thisreview paperaresummarized asfollows:\\n—ThisarticlecomprehensivelyreviewsandanalysescurrentXAImethodsappliedtovarious\\ntypesofmedicaldata,includingimage,text,tabular,andmultimodal.Italsointroducessev-\\neral XAI methods not yet utilized in medical data analysis but that have the potential to\\nexplain theoutcomeof DNNswithmedical image input.\\n—It provides a taxonomy of XAI techniques for medical images, which clearly demonstrates\\ntheunderlyingrelationshipsbetweendifferenttechniquesandallowssystematicanalysisof\\nexplainable algorithms.\\n—It summarizes existing evaluation metrics to determine the validity and trustworthiness of\\ndifferent medical dataexplanationmethods.\\n—It discusses the strengths and limitations of existing attribution-based, non-attribution-\\nbased,tabular,andtextualXAItechniquestohelpresearchersselectthedesiredXAImethod,\\ndependingontheapplication.Italsohighlightsseveralfutureresearchopportunitiesanddi-\\nrectionsfordevelopingdifferent interpretabilitymethods.\\nBeforeproceedingfurther,wewanttonotethatweusetheterms“interpretability”and“explain-\\nability” interchangeably, considering that there is a lack of consensus in defining these terms [ 8].\\nMiller[143]saysinterpretableMLreferstothedegreetowhichahumancanunderstandthecause\\nofadecision(ofamodel).InReference[ 96],interpretabilityisdefinedasthedegreetowhichahu-\\nmancanconsistentlypredictthemodel’sresult,whileinReference[ 36],interpretabilityisdefined\\nas a desirable quality or feature of a', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1234: ('ent interpretabilitymethods.\\nBeforeproceedingfurther,wewanttonotethatweusetheterms“interpretability”and“explain-\\nability” interchangeably, considering that there is a lack of consensus in defining these terms [ 8].\\nMiller[143]saysinterpretableMLreferstothedegreetowhichahumancanunderstandthecause\\nofadecision(ofamodel).InReference[ 96],interpretabilityisdefinedasthedegreetowhichahu-\\nmancanconsistentlypredictthemodel’sresult,whileinReference[ 36],interpretabilityisdefined\\nas a desirable quality or feature of an algorithm that provides enough expressive data to under-\\nstand how the algorithm works. The Cambridge Dictionary defines it as follows: “If something\\nis interpretable, it is possible to find its meaning or possible to find a particular meaning in it.”\\nHence,explainabilityorinterpretabilitycanbedefinedastheadditionalinformationtoreasonthe\\ndecisionprocess,featurerelevance,oridentifyinginfluentialfeaturesgeneratedbytheMLmodel\\nitself oranotheralgorithm.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:4 Md I.Hossain et al.\\nFig. 2. PRISMA flow diagram of our review. It shows the number of papers identified, screened, assessed,\\nand included in thisreview.\\n1.1 Literature Review Design\\nThe search and selection process for this review are presented as a PRISMA [ 145]fl o wd i a g r a m\\ninFigure 2.Thissystematicreviewisbasedonresearcharticlescollectedusingvarioussearchen-\\nginessuchasGoogleScholar,IEEEXplore,ACMDigitalLibrary,Scopus,Pubmed,andCiteSeer.We\\nretrievedrelevantjournalarticles,scientificconferences,technicalreports,andonlinearticlespub-\\nlished up to August 2023 using keywords such as explainable deep learning, XAI review/ survey,\\nexplainability,interpretability,explainableAIinthemedicaldata,XAIinmedicaldata,explainable\\nmachine learning, and explainability assessment/evaluation. We identified a total of 639 studies\\nusing the search keywords. We then filtered out irrelevant articles and selected relevant articles\\nbased on the following criteria: (1) the study is written in Englis', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1235: ('s,scientificconferences,technicalreports,andonlinearticlespub-\\nlished up to August 2023 using keywords such as explainable deep learning, XAI review/ survey,\\nexplainability,interpretability,explainableAIinthemedicaldata,XAIinmedicaldata,explainable\\nmachine learning, and explainability assessment/evaluation. We identified a total of 639 studies\\nusing the search keywords. We then filtered out irrelevant articles and selected relevant articles\\nbased on the following criteria: (1) the study is written in English; (2) the publication includes a\\nnovel or existing explainable method applicable to medical data; (3) the study contains published\\njournal articles, conference papers, technical reports, open-access articles, or highly cited arXiv\\npapers; (4) the study is related to explainable deep learning in medical data applications; and (5)\\ntheXAImethodhasthepotentialtobeappliedtomedicaldataanalysis,i.e.,themethodhasbeen\\nappliedinseveraldatasets,providesavisualexplanationorexplainsthedecision-makingprocess,\\nand shows significant results with existing evaluation metrics. We screened the identified paper\\ncarefully,includedatotalof 218studiesand excluded thestudythatfailedto fulfillthesecriteria.\\n1.2 Organization oftheSurvey\\nThis review is organized as follows. Section 2provides a general taxonomy of XAI techniques\\nfor medical data analysis. In Section 3, we discuss four categories of XAI approaches for medical\\nimages based on the nature of their explanations and present applications of these methods in\\nmedical images. Section 4discusses non-image-based explanation methods with applications in\\nthemedicalfield.WesummarizethemultimodaldataexplanationsinSection 5.Variousevaluation\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:5\\nmetrics for XAI techniques are provided in Section 6, and, finally, limitations and future research\\ndirectionsarehighlightedin Section 7.\\n2 TYPESOF XAI\\nExplainability follows the statement that no single algorithm is enough to solve all the', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1236: ('tion 4discusses non-image-based explanation methods with applications in\\nthemedicalfield.WesummarizethemultimodaldataexplanationsinSection 5.Variousevaluation\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:5\\nmetrics for XAI techniques are provided in Section 6, and, finally, limitations and future research\\ndirectionsarehighlightedin Section 7.\\n2 TYPESOF XAI\\nExplainability follows the statement that no single algorithm is enough to solve all the problems\\nbetter than every single algorithm. A hybrid approach often provides a concrete solution where\\nmultiple algorithms can be used. Explainability methods can be categorized into the following\\nfour categories.\\n2.1 Attributionvs. Non-Attribution\\nAn attribution-based method generates a visual explanation by highlighting the image region as-\\nsociatedwiththemodelprediction[ 10,25,90,149,163,170,185,190,197,202,250].Alocalization\\nmap can be produced by a gradient-based process [ 25,185,250] or perturbing the input pixel to\\nidentify important features such as occlusion [ 241],Randomized Input Sampling for Expla-\\nnation(RISE) [163],andLocalInterpretableModel-agnosticExplanations(LIME) [10].The\\nnon-attributionmethodfocusesonhowandwhyadecisionhasbeenmadeandexplainsthepredic-\\ntionusingtheconcept[ 55,56,97,237],prototype[ 27,102],andalteredprediction[ 29,37].Instead\\nof only focusing on the pixels, they also deal with model behavior, analyze model sensitivity and\\nstability,or helpinmodel debugging.\\n2.2 Intrinsic vs. PostHoc\\nIntrinsic methods are usually integrated into the model and inherently interpretable and backed\\nby various models (e.g., rule-based model [ 114] and decision tree [ 3]). Intrinsic explainers are\\ndirectly dependent on the model architecture and are not usually transferable to another neural\\nnetwork without redesigning the XAI algorithm for a new model. However, the Post-Hoc XAI\\nmethod is independent of the model architecture and can be applied to any trained CNN model.\\nThe accuracy of the existing ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1237: ('. PostHoc\\nIntrinsic methods are usually integrated into the model and inherently interpretable and backed\\nby various models (e.g., rule-based model [ 114] and decision tree [ 3]). Intrinsic explainers are\\ndirectly dependent on the model architecture and are not usually transferable to another neural\\nnetwork without redesigning the XAI algorithm for a new model. However, the Post-Hoc XAI\\nmethod is independent of the model architecture and can be applied to any trained CNN model.\\nThe accuracy of the existing network does not change; however, another algorithm is needed to\\nexplain.Forexample, attribution-based[ 25,90,149,163,170,185,190,197,202],conceptlearning\\nexplanation [ 55,56,97,237] can explain externally of a trained network without sacrificing the\\npredictionaccuracy.\\n2.3 Localvs.Global\\nThe local explanation method involves working on specific data instances and interpreting the\\nreasonforadecisionofaclassifierbasedonthesedatapoints.Thisexplanationprovidesinsights\\ninto specific features that positively or negatively impact the decision. Most of the perturbation-\\nbased methods such as Contrastive Explanations Method (CEM) [37],Learning to Explain\\n(L2X)[29], saliency or attribution map methods, i.e., Class Activation Mapping (CAM) [250],\\nGradCAM [ 185], and RISE [ 163], are in this category. However, the global explanation interprets\\nthe entire behavior of the model. It gives insights into the overall knowledge of the model. For\\ninstance, analyzing important features that help to improve the overall model performance is a\\nglobalexplanationmethod.Variouscomplexnetworksadaptedintothelinear,tree-based,orrule-\\nbased models are also in this category, as they provide inherently global interpretation. Some of\\ntheglobalexplanationsmethodsinclude TestingwithConceptActivationVectors(TCAV) [97]\\nandAutomatic Concept-based Explanations (ACE) [55].\\n2.4 Model-specificvs. Model-agnostic\\nModel-specific methods are based on the internal model architecture and parameters and\\nare appropriate for explaining specific structures (e.g.', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1238: ('ormance is a\\nglobalexplanationmethod.Variouscomplexnetworksadaptedintothelinear,tree-based,orrule-\\nbased models are also in this category, as they provide inherently global interpretation. Some of\\ntheglobalexplanationsmethodsinclude TestingwithConceptActivationVectors(TCAV) [97]\\nandAutomatic Concept-based Explanations (ACE) [55].\\n2.4 Model-specificvs. Model-agnostic\\nModel-specific methods are based on the internal model architecture and parameters and\\nare appropriate for explaining specific structures (e.g., a specific CNN model). For example,\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:6 Md I.Hossain et al.\\nTable 1. A Listof Different XAIMethods inComputer VisionTasks,Especially for Image\\nAnalysis,andTheir Categories\\nCategory XAI methodandreference Year Remarks\\nAttribution-\\nbasedLayerwiserelevance propagation (LRP) [ 10]\\nCAM [250]\\nLIME[170]\\nSHAP (Shapley additiveexplanations) [ 133]\\nDeepLIFT [ 190]\\nGradient-weighted CAM (Grad-CAM) [ 185]\\nIntegratedGradient (IG) [ 202]\\nSmoothGrad[ 197]\\nGradCAm++ [ 25]\\nRISE [163]\\nAnchor [171]\\nXRAI [90]\\nSimilarityDifference andUniqueness [ 149]2015\\n2016\\n2016\\n2016\\n2017\\n2017\\n2017\\n2017\\n2018\\n2018\\n2018\\n2019\\n2020Post hocvisualexplanation\\nmethods highlight theimage\\nregion that the DNN model\\nthinks isimportant.\\nGradient-based and\\nperturbation-basedapproaches\\narevery popular forproducing\\nheat maps.The\\nvisualization-based methodis\\neasytoimplement but has\\nseverallimitations.\\nConcept-\\nbasedTCAV [97]\\nACE [55]\\nCausalConcept Effect (CACE) [ 56]\\nCONCEPTSHAP [ 237]2018\\n2019\\n2019\\n2020High-level concepts are\\nmanually or automatically\\nse lec teda ndusedtoe x pla in\\ntheprediction.\\nCounter-\\nfactual-basedCEM[37]\\nL2X [29]\\nGuided Prototypes[ 128]\\nABELE [60]2018\\n2018\\n2021Purturedinput images arefed\\nintothemodel togenerate an\\naltered prediction.\\nPrototype-\\nbasedMaximumMeanDiscrepancycritic(MMD-critic)[ 96]\\nInfluence Function [ 102]\\nPrototypicalPart Network(ProtoPNet) [ 27]2016\\n2017\\n2019Prototypical part selection and\\ncomparison among train and\\ntest image\\nOthers DecisionT', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1239: ('[ 237]2018\\n2019\\n2019\\n2020High-level concepts are\\nmanually or automatically\\nse lec teda ndusedtoe x pla in\\ntheprediction.\\nCounter-\\nfactual-basedCEM[37]\\nL2X [29]\\nGuided Prototypes[ 128]\\nABELE [60]2018\\n2018\\n2021Purturedinput images arefed\\nintothemodel togenerate an\\naltered prediction.\\nPrototype-\\nbasedMaximumMeanDiscrepancycritic(MMD-critic)[ 96]\\nInfluence Function [ 102]\\nPrototypicalPart Network(ProtoPNet) [ 27]2016\\n2017\\n2019Prototypical part selection and\\ncomparison among train and\\ntest image\\nOthers DecisionTree [ 245]\\nRahul et el. [ 159]\\nAdaptive Wavelet Distillation [ 66]\\nHuman–AI Interfaces [ 70]2019\\n2019\\n2021\\n2021Wavelet-based, tree,or feature\\ncorrelation-based methods can\\nbe applied to medical images\\nfor interpretation.\\nGNNExplainer [ 239] is model specific due to its ability to only explain the graph neural network\\nmodel. Neural additive model [ 3] is another example, which combines generalized additive mod-\\nels with the expressivity of DNNs to learn the relationships between the input and the output.\\nHowever, the model agnostic method is independent of the model, can be applied to other do-\\nmains, and does not deal with the model weights and the parameter directly. Different post hoc\\n[25,29,37,55,56,90,97,149,163,197,237]XAImethodsareinthiscategory,asthesemethodsare\\nindependentof themodelarchitecture.\\n3 IMAGE-BASEDXAIMETHODS ANDAPPLICATIONS\\nXAI for image data can be broadly categorized into two main categories: attribution and\\nnon-attribution. Within the attribution-based methods, we further divide them into gradient-\\nbased,perturbation-based,andlayerwiserelevancepropagation-basedtechniques.However,non-\\nattributionmethodscanbedividedintoconcept-based,counterfactual-based,andprototype-based\\ntechniques.Tables 1–3liststechniquesappropriatefor medicalimage analysis.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:7\\n3.1 Attribution-basedExplanations\\nSaliency map (SM) , used in Reference [ 192], generates heatmaps on the image predicted by a\\ndeeplearni', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1240: ('to gradient-\\nbased,perturbation-based,andlayerwiserelevancepropagation-basedtechniques.However,non-\\nattributionmethodscanbedividedintoconcept-based,counterfactual-based,andprototype-based\\ntechniques.Tables 1–3liststechniquesappropriatefor medicalimage analysis.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:7\\n3.1 Attribution-basedExplanations\\nSaliency map (SM) , used in Reference [ 192], generates heatmaps on the image predicted by a\\ndeeplearningnetwork.ThepurposeofanSMistohighlighttheprominentregionofanimageon\\nwhich a human’s eye would focus first to recognize an object. An SM can be produced by either\\nassigning a saliency value to every pixel or segmenting an image into several pixel groups and\\nassigninga saliencyvalue toeverygroup of pixels.\\n3.1.1 Gradient-based Methods. Thesetypesproduceattributionmapsofinputimagesusingthe\\ngradient or backpropagation to highlight the important part of the prediction. The explanations\\nare usuallymodelagnosticand posthoc.\\nCAM [250] is one of the popular visualization methods, which creates an activation map and\\ncanlocalizethedecision-makingfeaturesonanimage.CAMuses globalaveragepooling(GAP)\\nafterthelastconvolutionallayersandbeforethefinal fullyconnected(FC) layer.Given fk(x,y)\\ncorresponds to the activation of unit k(convolution filters) in the last layer at location (x,y)for\\na particular image. The weight corresponding to class cfor unitkiswk\\nc. Then, the input to the\\nsoftmaxlayerforagivenclass ciscomputedas Sc=/summationtext\\nx,y/summationtext\\nkwk\\ncfk(x,y)Theclassactivationmap\\nMciscomputedas Mc(x,y)=/summationtext\\nkwk\\nCfk(x,y),whereMcindicateshowimportanttheactivationin\\nthespatiallocation (x,y)isforclassifyinganimagetoclass c.Theclassactivationmapisoverlaid\\non the input image, and a highlighted region is generated for each class. CAM can be applied to\\nthenetwork,whichsequentiallyhasaGAP FC layer andsoftmax.\\nGradCAM[ 185]isalocalexplainerthatsolvestheissuesofCAM,i.e.,noneedforarchitectural\\nmodification or retraining', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1241: ('summationtext\\nx,y/summationtext\\nkwk\\ncfk(x,y)Theclassactivationmap\\nMciscomputedas Mc(x,y)=/summationtext\\nkwk\\nCfk(x,y),whereMcindicateshowimportanttheactivationin\\nthespatiallocation (x,y)isforclassifyinganimagetoclass c.Theclassactivationmapisoverlaid\\non the input image, and a highlighted region is generated for each class. CAM can be applied to\\nthenetwork,whichsequentiallyhasaGAP FC layer andsoftmax.\\nGradCAM[ 185]isalocalexplainerthatsolvestheissuesofCAM,i.e.,noneedforarchitectural\\nmodification or retraining the network. It uses the gradients of the network flowing into the last\\nconvolutionlayertoassignanimportantscoretoeachneuronandproducesacoarselocalization\\nmaphighlightingimportantpixelsofanimagetopredictthetargetclass.Atfirst,GradCAMcom-\\nputes the gradient for each class score ycwith respect to the features maps activation Akof the\\nlast convolution layer. Next, neuron importance scores wc\\nkare calculated by averaging the gradi-\\nent flowing back over the activation map’s size Z. The weights wc\\nkfor a particular feature map\\nAkand class cis expressed as wc\\nk=1\\nZ/summationtext\\ni/summationtext\\nj∂Yc\\n∂Ak\\nij. The heatmap Lc\\nGrad−CAMis generated by com-\\nbining the weights and the forward activation map followed by a rectified linear unit (ReLU) ,\\nLc\\nGrad−CAM=ReLU(/summationtext\\nkwc\\nkAk). An up-sampling technique is employed via bilinear interpolation\\nof the same size as the input images to produce the class activation map. The paper additionally\\npresentsGuidedGrad-CAM,whereapointwisemultiplicationisdoneamongupsampledsaliency\\nmapLcwiththepixel-spacevisualizationgeneratedby GuidedBackpropagation.\\nGradCAM++[ 25]solvestheshortcomingsofGradCAM,i.e.,providesbettervisualexplanation\\nand localizes when multiple objects are present in a single image. GradCAM++ reformulates the\\nstructureofweights wc\\nkasinEquation( 1)sothatallrelevantregionsoftheinputimagegetequal\\npriority,\\nwc\\nk=/summationdisplay\\ni/summationdisplay\\nj⎡⎢⎢⎢⎢⎢⎢⎣∂2Yc\\n(∂Ak\\nij)2\\n2∂2Yc\\n(∂Ak\\nij)2+/summationtext\\na/summationtext\\nbAk\\nab{∂3Yc\\n(∂Ak\\nij)3}⎤⎥⎥⎥⎥⎥⎥⎦.relu /parenleft', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1242: ('saliency\\nmapLcwiththepixel-spacevisualizationgeneratedby GuidedBackpropagation.\\nGradCAM++[ 25]solvestheshortcomingsofGradCAM,i.e.,providesbettervisualexplanation\\nand localizes when multiple objects are present in a single image. GradCAM++ reformulates the\\nstructureofweights wc\\nkasinEquation( 1)sothatallrelevantregionsoftheinputimagegetequal\\npriority,\\nwc\\nk=/summationdisplay\\ni/summationdisplay\\nj⎡⎢⎢⎢⎢⎢⎢⎣∂2Yc\\n(∂Ak\\nij)2\\n2∂2Yc\\n(∂Ak\\nij)2+/summationtext\\na/summationtext\\nbAk\\nab{∂3Yc\\n(∂Ak\\nij)3}⎤⎥⎥⎥⎥⎥⎥⎦.relu /parenlefttpA\\n/parenleftbtA∂Yc\\n∂Ak\\nij/parenrighttpA\\n/parenrightbtA. (1)\\nSimilarly to GradCAM, the saliency map is computed as Lc\\nij=ReLU(/summationtext\\nkwc\\nk.Ak\\nij)using ReLU\\nand a forwardactivationmap.\\nIntegratedGradient(IG) [202]requiresnochangeoftheoriginalnetworkandcanevaluatethe\\nmodel performance,understandfeatureimportance,and identify data skew.Themethodsatisfies\\ntwoaxioms,i.e.,sensitivityandimplementationinvariance.Toevaluatethesensitivity,abaseline\\nimage, which could be a black/white or a random image, is considered as a starting point. If the\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:8 Md I.Hossain et al.\\nbaseline image differs from the input image in one feature and if the network predicts a different\\noutcomeforthebaselineandinputimage,thenadifferingfeatureshouldhaveanon-zerorelevance\\nscore. Implementation invariance is satisfied when two networks whose predictions are identical\\nfor all inputs, despite implementation differences, have identical attributes for the same baseline\\nandtheinputimage.Formally,ifadeepnetwork F,aninput x,abaselineinput x/prime,andthegradient\\n∂F(x)\\n∂xi,thentheIGalong ithdimensioncan beexpressedas\\nIGi(x)=(xi−x/prime\\ni)/integraldisplay1\\nα=0∂F(x/prime+α(x−x/prime))\\n∂xidα, (2)\\nwhereαis distributed in the range [0,1]. In practice, the definite integral computation is costly;\\ntherefore,Riemman approximation( 3)solves theissueandcanbe writtenas\\nIGapprox\\ni(x)::=(xi−x/prime\\ni)m/summationdisplay\\nk=1∂F(x/prime+k\\nm(x−x/prime))\\n∂xi1\\nm, (3)\\nwheremis the step si', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1243: ('baseline\\nandtheinputimage.Formally,ifadeepnetwork F,aninput x,abaselineinput x/prime,andthegradient\\n∂F(x)\\n∂xi,thentheIGalong ithdimensioncan beexpressedas\\nIGi(x)=(xi−x/prime\\ni)/integraldisplay1\\nα=0∂F(x/prime+α(x−x/prime))\\n∂xidα, (2)\\nwhereαis distributed in the range [0,1]. In practice, the definite integral computation is costly;\\ntherefore,Riemman approximation( 3)solves theissueandcanbe writtenas\\nIGapprox\\ni(x)::=(xi−x/prime\\ni)m/summationdisplay\\nk=1∂F(x/prime+k\\nm(x−x/prime))\\n∂xi1\\nm, (3)\\nwheremis the step size in the approximation of the integral, the weakness of the method is that\\nIGdoesnotgiveemphasisonglobalfeatureimportanceordoesnotinterpretfeatureinteractions.\\nSmoothgrad [ 197] sharpens the gradient-based saliency map by adding noise to the input im-\\nageandsmoothsthesaliencymapwhenaveragingisdoneonsensitivitymapscreatedfromthese\\nperturbedimages.Asaliencymapforanyinputimage( x)canbeexpressedas Mc(x)=∂Sc(x)/∂x,\\nwhere∂Sc(x)isthederivationoftheclassfunction Scforaclass c.Itsignifiestheeffectofchang-\\ning a tiny amount in each pixel of xon the classification score. Due to these local variations\\nin∂Sc(x)/∂x, noise is added to the saliency map, i.e., raw gradient-based SM tends to be noisy.\\nSmoothGrad uses a Gaussian Kernel to smooth the gradient. Hence, the new smoothed version,\\nwhichtakestheaverageof thesensitivitymap canbeformulated asfollows:\\nˆMc(x)=1\\nnn/summationdisplay\\n1Mc(x+N(0,σ2)), (4)\\nwherenis the number of samples, N(0,σ2)is the Gaussian noise. Another advantage is that\\nSmoothGradcanbecombinedwithgradient-basedmethodslikeIGorvanillagradienttoimprove\\nvisualizationmaps usingtheabove averagingprocedure.\\nXRAI [90] is an INTGRAD-based method that can be applied to any DNN model to determine\\nthe most salient image regions. The method is divided into three stages: segmentation, gathering\\nattribution, and choosing appropriate regions. First, image segmentation is performed multiple\\ntimesusingdifferentparameters,andthereforetheattributionresultsdonotdependonaspecific\\nhyper-parameterorimagesegmentationmethod.Second,', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1244: ('t-basedmethodslikeIGorvanillagradienttoimprove\\nvisualizationmaps usingtheabove averagingprocedure.\\nXRAI [90] is an INTGRAD-based method that can be applied to any DNN model to determine\\nthe most salient image regions. The method is divided into three stages: segmentation, gathering\\nattribution, and choosing appropriate regions. First, image segmentation is performed multiple\\ntimesusingdifferentparameters,andthereforetheattributionresultsdonotdependonaspecific\\nhyper-parameterorimagesegmentationmethod.Second,themethodusesIGwithabaselineasa\\nblack-and-white average for generating an attribution map. Third, for selecting the region, XRAI\\nleveragesthatthesumofallattributionsforinputisequaltothedifferencebetweeninputsoftmax\\nand baseline softmax. Further, among the two regions, the one that sums more positively should\\ngetmorepriorityfromtheclassifier.Forthisconsideration,XRAIselectsanemptymaskandthen\\nadds the region having maximum gain in the combined attribution per area. The algorithm runs\\nuntil the mask is filled on the baseline image and the desired SM is obtained. Additionally, the\\npaperintroducestwometrics(softmaxInformationCurvesandAccuracyInformationCurves)for\\nevaluatingtheattributionmapquality.\\nOther earlier gradient-based methods like DeConvNet [ 241] consist of deconvolution and un-\\npoolinglayersandgenerateasaliencymapbyzeroingthenegativegradientduringthebackward\\npass.GuidedBackPropagation[ 198]isafurtherimprovementoftheDeConvNetforabettervisual\\nexplanation.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:9\\n3.1.2 Perturbation-based Methods. Thesetechniquesmeasuretheimpactofperturbationofthe\\ndifferent parts of an input image on the model’s prediction. For example, the occlusion method\\n[241]isusedtovisualizevariouspartsoftheimagemostcloselyassociatedwiththeclassification.\\nThe authors found that the feature activity map also changed when a specific image region was\\noccluded.\\nLIME was developed by Ribeiro et al. [ 170] in which the image is perturbed b', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1245: ('icationdate:February 2025.\\nExplainableAIfor Medical Data 148:9\\n3.1.2 Perturbation-based Methods. Thesetechniquesmeasuretheimpactofperturbationofthe\\ndifferent parts of an input image on the model’s prediction. For example, the occlusion method\\n[241]isusedtovisualizevariouspartsoftheimagemostcloselyassociatedwiththeclassification.\\nThe authors found that the feature activity map also changed when a specific image region was\\noccluded.\\nLIME was developed by Ribeiro et al. [ 170] in which the image is perturbed by changing on\\nandoffacertainamountofthesuper-pixel.TheQuickshiftsegmentationalgorithmgeneratesthe\\nsuper-pixel;auniformsolidcolorisusedtomakeitonandoff.Subsequently,theperturbedimage\\nis fed into the neural network, and each perturbed image’s prediction score is recorded. In the\\nnextstep,thecosinemetrichelpstocomputethedistancebetweeneachperturbedimageandthe\\noriginalimage.Akernelfunctionmapsthedistancebetweenzeroandone(weights).Afterward,a\\nlinearregressionmodelislearnedontopusingthedataandresultsfromtheperturbation,predic-\\ntionscore,andweights.Eachlearnedcoefficientfromthelinearmodelbelongstoeachsuper-pixel\\nofthesegmentedimage.Thiscoefficientsignifiestheimportanceofeachsuper-pixelforpredicting\\na targetclass.\\nAnchor[171]isbasedoncreatinganchorsorconditionsbydeterminingadecisionrulethatpro-\\nvidesastableexplanationforaspecificinstanceregardlessofperturbationormodelvariations.The\\nmethodusestheif-thenruletoanchorapredictiontoidentifytheimportantimagesegmentsuch\\nthat the variation among the remaining segments does not influence the prediction.The image is\\nsegmentedasLIMEtoobservevariationsofthemodelprediction,andafeatureisananchorfeature\\nif it consistently leads to a particular prediction. Anchor searches a set, D=z|f(z)=f(x),zϵx,\\nwherezispartof theimages, xis theinputimage,and f(·)is a black-boxmodel[ 45].\\nRISE[163]isamodelagnostic,i.e.,itcangeneratethesaliencymapwithoutmodelmodification\\nand can be applied directly to any existing network. In RISE, the input image xis perturbed via a\\nrandom mask, and only a subset of ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1246: ('t influence the prediction.The image is\\nsegmentedasLIMEtoobservevariationsofthemodelprediction,andafeatureisananchorfeature\\nif it consistently leads to a particular prediction. Anchor searches a set, D=z|f(z)=f(x),zϵx,\\nwherezispartof theimages, xis theinputimage,and f(·)is a black-boxmodel[ 45].\\nRISE[163]isamodelagnostic,i.e.,itcangeneratethesaliencymapwithoutmodelmodification\\nand can be applied directly to any existing network. In RISE, the input image xis perturbed via a\\nrandom mask, and only a subset of the input image pixels is kept preserved. The masked images\\nwork as input to the base model, then the response for each masked image is recorded; more\\nspecifically, the confidence score is calculated by the black-box model on the masked image. The\\nfinal saliency map is a result of combining the random binary mask Mand combined weights\\ncoming from the output probabilities of the predicted class working on the masked image. When\\nthemaskpixelisimportant,thevalue f(x⊙M)ishigh,where fdenotestheblack-boxmodel,and\\n⊙indicateselement-wisemultiplication.\\nSimilarity Difference and Uniqueness [ 149] is another visual explanation method based on the\\nperturbation of the input image. First, masks are generated from the last CNN layer, converting\\nthe feature activation maps of class c, i.e.,fc=[fc\\n1,fc\\n2......fc\\nN], into a binary mask Mc\\ni.N e x t ,\\nfeature activation image mask Ai\\ncis obtained by a pointwise multiplication of the input image x\\nandaninterpolatedbinarymask Mc\\ni,whichcanbeexpressedas Ai\\nc=F(x⊙Mc\\ni).Thenprobability\\nprediction scores ( Pc\\ni) and (Pc\\norд) for all the feature activation image masks and original input\\nimagesarecomputed,respectively,toobtainthesimilaritydifference, SDc\\ni=exp(−1\\n2σ2||Pc\\norд−Pc\\ni||).\\nThe uniqueness ( Uc\\ni) among the prediction score vectors of feature image masks is measured to\\nfigureoutthehighsalientregionsas Uc\\ni=/summationtextN\\nj=1||Pc\\ni−Pc\\nj||.Finally,featureimportanceweight Wc\\ni\\niscomputedforavisualexplanationas Wc\\ni=SDc\\ni·Uc\\ni.Thefeatureimportanceweightdetermines\\nwhichfeaturehasmo', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1247: ('lity\\nprediction scores ( Pc\\ni) and (Pc\\norд) for all the feature activation image masks and original input\\nimagesarecomputed,respectively,toobtainthesimilaritydifference, SDc\\ni=exp(−1\\n2σ2||Pc\\norд−Pc\\ni||).\\nThe uniqueness ( Uc\\ni) among the prediction score vectors of feature image masks is measured to\\nfigureoutthehighsalientregionsas Uc\\ni=/summationtextN\\nj=1||Pc\\ni−Pc\\nj||.Finally,featureimportanceweight Wc\\ni\\niscomputedforavisualexplanationas Wc\\ni=SDc\\ni·Uc\\ni.Thefeatureimportanceweightdetermines\\nwhichfeaturehasmore influencein predictingaclass.\\n3.1.3 Layerwise Relevance Propagation. Layerwiserelevancepropagation(LRP) [10]ispost\\nhocandmodelspecificandprovideslocalexplanationsforimagedata.LRPusesthedecomposition\\nmethodtoexplaintheneuralnetwork’sprediction.Itredistributesoutputorprediction f(x)ofthe\\nnetwork fbackward direction to input space with the help of local distribution rules, and in the\\nprocess, a relevance score Riis assigned to each pixel. Given iindexes neuron activation at a\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:10 Md I.Hossain etal.\\nparticularlayer l,pixelwiserelevancescores Rjatlayerl+1andwijistheweightslearningfrom\\nthe data of neuron ito neuron j, then the simple LRP rule using a local redistribution rule can be\\nexpressedas ( 5)\\nR(l)\\ni=/summationdisplay\\njxi·wij/summationtext\\ni/primexi/prime·wi/primejR(l+1)\\nj. (5)\\nIf a neuron gets more activated, then it gets a larger share of redistributed relevance. If the\\nrelevance is redistributed from the network output to the input, then it is possible to find the\\nimportantpixelof theimage and generatetheheatmapor relevancemap.\\n3.1.4 Other Methods. Deep Learning Important FeaTures (DeepLIFT) [190]i sa\\nbackpropagation-based method similar to LRP and uses a reference input like the IG for expla-\\nnation. It describes how the output changes from the baseline in terms of changes in the input.\\nFormally,thetargetoutput tandreferenceoutput toandΔt=t−to,whichisthedifference-from-\\nreference for output, x1,x2,x3......xnis some neurons i', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1248: ('he input, then it is possible to find the\\nimportantpixelof theimage and generatetheheatmapor relevancemap.\\n3.1.4 Other Methods. Deep Learning Important FeaTures (DeepLIFT) [190]i sa\\nbackpropagation-based method similar to LRP and uses a reference input like the IG for expla-\\nnation. It describes how the output changes from the baseline in terms of changes in the input.\\nFormally,thetargetoutput tandreferenceoutput toandΔt=t−to,whichisthedifference-from-\\nreference for output, x1,x2,x3......xnis some neurons in the intermediate layer, and Δxis the\\ndifferenceof xandx/prime,thenthecontributionscores CΔxiΔtassignedbyDeepLIFTforinputfeature\\nxican be expressed as Δt=/summationtextN\\ni=1CΔxiΔt,w h e r eNis the input neuron to compute t.H e r e ,CΔxiΔt\\ncan be thought of how much influence the difference-from-reference of xihas onΔt. The contri-\\nbution score can be computed by some rules like the linear rule, rescale rule, or revealcancel rule,\\nwhich is elaborated on in the original paper. Additionally, the amount of relevance among input\\nandoutputdifferencescanbedeterminedbyamultiplier mΔxΔtas:mΔxΔt=CΔxΔt\\nΔx.Itispossibleto\\napplythechainruleformultipliersaswrittenin( 6)wheremΔxiΔtfollowsthemultiplierequation’s\\nproperties,\\nmΔxiΔt=/summationdisplay\\njmΔxiΔyjmΔyjΔt. (6)\\nThischainrulehelpstocomputerelevancescoreslayerbylayerviabackpropagationwhilethe\\nsaliency map on the image is generated, similarly to the LRP method. Lundberg and Lee [ 133]\\nfirstproposed Shapleyadditiveexplanations(SHAP) valuesformeasuringfeatureimportance\\nand then introduced the Deep SHAP method by combining DeepLIFT and Shapley values for the\\nexplanation.\\n3.2 Attribution-basedExplanationsfor Medical Images\\nVisual methods have been used in the medical field to aid clinicians by explaining the decision of\\na deep neural network (Table 2). For instance, in Reference [ 4], the authors utilized the saliency\\nmap produced by CAM to obtain superior performance over baseline results on COVID datasets.\\nSnapMIX [ 75], an augmentation method, is used by utilizing the heatm', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1249: (' then introduced the Deep SHAP method by combining DeepLIFT and Shapley values for the\\nexplanation.\\n3.2 Attribution-basedExplanationsfor Medical Images\\nVisual methods have been used in the medical field to aid clinicians by explaining the decision of\\na deep neural network (Table 2). For instance, in Reference [ 4], the authors utilized the saliency\\nmap produced by CAM to obtain superior performance over baseline results on COVID datasets.\\nSnapMIX [ 75], an augmentation method, is used by utilizing the heatmap in each box generated\\non COVID-19 positive and negative images, where the label of the virtual training image is gen-\\nerated by combining the labels of these source images. Then, the paper delineates the link be-\\ntweenwhetherCAM-heatmapisrelatedtotheobtainedclassification.Furthermore,theyusedthe\\nheatmap to validate the stability of the classification outcome by the location of the image most\\nrelevant to classification. In Reference [ 189], the authors produced high-resolution CAM by com-\\nbiningfeaturemapsfrommultipleCNNlayersandaccuratelylocalizingbraintumorsonMRIdata.\\nDenseNet and CAM are used to produce robust visual explanations by improving the resolution\\nof CAM for the brain gender classification [ 51]. Deep-learning-assisted CAM-based visualization\\nhasbeenusedforclassificationsofkneeMRI[ 20]andinkneepainassessmentbygeneratingheat\\nmaps of the MR image [ 24]. Another modification of the CAM, RESpond CAM [ 248], performed\\nbetter than GradCAM for biomedical three-dimensional (3D) imaging inputs. Lee et al. [ 111]g e n -\\nerated attention heatmaps of benign and metastatic lymph nodes by CAM and superimposed on\\ntheCTimagetocomparethepositionoftheactuallymphnodeandtheimageregionhighlighted\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:11\\nTable 2. Applicationof Attribution-basedInterpretabilityMethodstoHighlight Salient Pixels inMedical\\nImaging\\nMethods Modality Reference Application\\nCAM [250]M R I\\nCT\\nUltrasound\\nX-ray\\nHistology\\nEndoscopy\\nDermatosco', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1250: ('l. [ 111]g e n -\\nerated attention heatmaps of benign and metastatic lymph nodes by CAM and superimposed on\\ntheCTimagetocomparethepositionoftheactuallymphnodeandtheimageregionhighlighted\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:11\\nTable 2. Applicationof Attribution-basedInterpretabilityMethodstoHighlight Salient Pixels inMedical\\nImaging\\nMethods Modality Reference Application\\nCAM [250]M R I\\nCT\\nUltrasound\\nX-ray\\nHistology\\nEndoscopy\\nDermatoscopy\\nFundus Image[20,24,51,189]\\n[106,110–112,134,224]\\n[122,167,220]\\n[9,41,77,94,169]\\n[76,95,200]\\n[221]\\n[118]\\n[85,106],[124]CAM has been usedforvarious\\napplications suchas COVID-19detection,\\ncancer identification, tumor classification,\\nor even medical image augmentation\\npurposes;CAMvisualizes salient pixels in\\nvarious locations i,g., Bladder Brain,Breast,\\nSkin, Cardiovascular,Chest,\\nGastrointestinal,andThyroid.\\nGradCAM [ 185]M R I\\nCT\\nUltrasound\\nX-ray\\nHistology\\nOCT\\nEndoscopy\\nFundus Image[119,152,162]\\n[160,164]\\n[158]\\n[23,92,121,242]\\n[64,84,101,104,206]\\n[208]\\n[80]\\n[100,139]GradCAM visualizes thesalient pixels in\\nCNN-based image classifierssuchas\\nglaucoma detection from optical coherence\\ntomography, COVID-19detection, polyps\\nclassification, andpathological pattern\\ndiagnosis fromendocytoscopic images.\\nLRP[10]M R I\\nHistology[22,44,58,234]\\n[67]LRPfor Alzheimer’s disease classification,\\ndiagnosingMS, discriminating\\nschizophrenia.\\nSHAP [133]M R I\\nDermatoscopy[214]\\n[240]Breast densityestimation\\nMelanoma detection\\nIntegrated Gra-\\ndient [202]MRI\\nEye[156]\\n[182]Estrogen receptor statusclassification.\\nDR severitylevel prediction.\\nGuided-back\\npropagation\\n[198]MRI\\nEndoscopy[82]\\n[226]Pathological region localization\\nColorectal polypssegmentation\\nDeepLIFT [ 190]M R I [ 129] Diagnosis of MultipleSclerosis\\nLIME[170] DaTscan\\nChestRadiograph[137]\\n[184]Parkinson’sdisease detection\\nCongestiveheart failurevisualization\\nSmoothGrad\\n[197]MRI\\nUltrasound[156]\\n[54]Classificationof estrogenreceptor\\nInterpretationof echocardiograms\\nNote:MRI =magne', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1251: ('ed Gra-\\ndient [202]MRI\\nEye[156]\\n[182]Estrogen receptor statusclassification.\\nDR severitylevel prediction.\\nGuided-back\\npropagation\\n[198]MRI\\nEndoscopy[82]\\n[226]Pathological region localization\\nColorectal polypssegmentation\\nDeepLIFT [ 190]M R I [ 129] Diagnosis of MultipleSclerosis\\nLIME[170] DaTscan\\nChestRadiograph[137]\\n[184]Parkinson’sdisease detection\\nCongestiveheart failurevisualization\\nSmoothGrad\\n[197]MRI\\nUltrasound[156]\\n[54]Classificationof estrogenreceptor\\nInterpretationof echocardiograms\\nNote:MRI =magneticresonance imaging;CT:computed tomography,OCT:opticalcoherence tomography.\\nby the CNN model. Additionally, Rajpurkar et al. [ 169] developed CheXNeXt to detect different\\npathologies from the ChestX-ray8 dataset and used CAM to identify which region on the chest\\nradiographwasmost responsibleforthefinalprediction.\\nInReference[ 227],GradCAMfocusesontheareacontainingaglioblastoma,vestibularschwan-\\nnoma, or no tumor of brain MRI slices. The authors used GradCAM to visualize features and\\nsignificant regions in whole-slide images to classify various types of polyps in Reference [ 104].\\nIn Reference [ 208], the Grad-CAM visualization technique was applied to highlight the relevant\\nimage region for glaucoma detection from optical coherence tomography (OCT) probability\\nmap images and to understand the reason for ambiguity in false negatives and false positives.Be-\\nsides, Itoh et al. [ 80] used a CNN-based classifier and Grad-CAM to visualize decision-reasoning\\nregions of pathological pattern diagnosis from a large endocytoscopic image dataset. They\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:12 Md I.Hossain etal.\\ngenerated Grad-CAM visualization from three convolutional layers of the trained CNN to differ-\\nentiate decision-making regions. Moreover, Grad-CAM and Guided Grad-CAM [ 121] explain the\\ndecisiontodetectCOVID-19fromchestradiographyimagesandidentifythemostdiscriminative\\nimage region.\\nYan et al. [ 234]utilizedLRPtodistinguishschizophreniapatients,whereLRPhelpedtoidentify\\nfunc', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1252: ('docytoscopic image dataset. They\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:12 Md I.Hossain etal.\\ngenerated Grad-CAM visualization from three convolutional layers of the trained CNN to differ-\\nentiate decision-making regions. Moreover, Grad-CAM and Guided Grad-CAM [ 121] explain the\\ndecisiontodetectCOVID-19fromchestradiographyimagesandidentifythemostdiscriminative\\nimage region.\\nYan et al. [ 234]utilizedLRPtodistinguishschizophreniapatients,whereLRPhelpedtoidentify\\nfunctional network connectivity patterns in fMRI data. LRP has been used to diagnose multiple\\nsclerosis by visualizing diagnosis-relevant features to make the CNN model transparent [ 44]. In\\naddition, in Reference [ 58], the authors used 3D-CNN with LRP for neonatal magnetic resonance\\nimaging.Theyanalyzedtheimpactofdifferentregistrationtechniquesontheimagedatasetusing\\nthegeneratedrelevancemapsfromtheLRP.Furthermore,Boehleetal.[ 22]utilizedLRPtoproduce\\naheatmapon MRIdatain theimage region responsibleforAlzheimer’s disease.\\nTang et al. [ 205] proposed the Discovery CAM to visually explain the skin lesion and chest\\nX-raydatasets.Theyusedcalibratedconfidencemethodstointegratetheweightsinthefinalclas-\\nsification layer to ensure that explanations align with doctors’ ground truth. A model-agnostic,\\noptimization-based, saliency method was proposed in Reference [ 138], using mammography and\\nthecuratedbreastimagingdata,whereasaliencymapisproducedinfourstages:(i)classification\\nscoreisobtained;(ii)amaskedimageisproduced,inpainted,andclassified;(iii)saliencylossisad-\\njustedbetweentheoriginalimageandmapqualitybasedonscoredifference;and(iv)optimization\\nofsaliencylossisperformedseveralstepstogettheresultingmap.Further,anin-modelexplainer\\n[173]wasproposedtoexplainvisuallypredictedclasslabelsforthecervicalcancerdataset.AVGG-\\nbased classifier was trained using the visual explanations created by an encoder–decoder, which\\nallows theexplainer only tousethepertinentpartsof theimage forclassification.\\nInReference[ 182],IGwasusedtogenerate', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1253: ('inted,andclassified;(iii)saliencylossisad-\\njustedbetweentheoriginalimageandmapqualitybasedonscoredifference;and(iv)optimization\\nofsaliencylossisperformedseveralstepstogettheresultingmap.Further,anin-modelexplainer\\n[173]wasproposedtoexplainvisuallypredictedclasslabelsforthecervicalcancerdataset.AVGG-\\nbased classifier was trained using the visual explanations created by an encoder–decoder, which\\nallows theexplainer only tousethepertinentpartsof theimage forclassification.\\nInReference[ 182],IGwasusedtogenerateexplanatoryheatmapsfordiabeticretinopathy(DR)\\nseverity. This technique produces pixel-based maps that calculate each pixel contribution for a\\nDR severity level prediction. Further, in Reference [ 129], DeepLIFT was used to identify salient\\nfeatures for MS classifications. The method was selected among other visual XAI algorithms de-\\npending on the quantitative evaluation of the trained model’s perturbation. Further, Table 2pro-\\nvidestheapplicationofvisualization-basedmethodsinmedicalimageanalysis.Inaddition,acom-\\nprehensivelistshowingtheapplicationsof visualXAI in themedicalimage accordingtoanatom-\\nicallocationcan befound inReference[ 215].\\n3.3 Concept-basedExplanations\\nAdeeplearningalgorithmextractslow-level featuresfromtheimage, likelinesor edges,thatare\\nhardtounderstandforahuman,asthesefeaturesdonotconstructameaningfulhigh-levelconcept.\\nFeature-basedexplanationsappliedtoablackboxmodeloftencreatenon-sensibleinterpretations\\n[2]. However, concept-based explanations construct the explanation in a way humans can under-\\nstandthebehaviorof aDNN modelbyevaluatingconcepts’contributionto concludea particular\\ndecision[ 237].Forinstance,stripescan bea conceptforpredictinga zebra.\\nTCAVs method is a global explanation method that uses human-friendly concepts to interpret\\ntheinternalstateofatrainedCNNmodel.Theconceptisdeterminedbytheuser,whichcouldbe\\ninputfeaturesfromthetrainingdataoruser-provideddata.Thereisgreatflexibilitytodefineand\\nrefineconceptsevenfornon-expertMLmodelanalystsasahypothesestestisdoneduringanalysis.\\nInt', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1254: ('n under-\\nstandthebehaviorof aDNN modelbyevaluatingconcepts’contributionto concludea particular\\ndecision[ 237].Forinstance,stripescan bea conceptforpredictinga zebra.\\nTCAVs method is a global explanation method that uses human-friendly concepts to interpret\\ntheinternalstateofatrainedCNNmodel.Theconceptisdeterminedbytheuser,whichcouldbe\\ninputfeaturesfromthetrainingdataoruser-provideddata.Thereisgreatflexibilitytodefineand\\nrefineconceptsevenfornon-expertMLmodelanalystsasahypothesestestisdoneduringanalysis.\\nInthismethod,theconceptisrepresentedasavector,anddirectionalderivativesareappliedtosee\\nhowtheconceptvectoraffectsthefinalclassificationscore.Themethodneedshigh-levelconcepts\\n(positive sets) and some random images (negative sets) to construct such a concept vector. To\\ndifferentiatebetweenactivationlayersoftwosets,i.e.,interestedconceptsandrandomexamples,\\nabinarylinear classifieristrained. ConceptActivation Vector (CAV) vl\\nCforconcept Cinlayer\\nlis orthogonal to the decision-making boundaries for this binary linear classifier. CAV signifies\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:13\\nFig.3. Concept-basedexplanation,inwhichpatchesareobtainedfromtheinputimage;humaninterpretable\\nconcepts(e.g., c1,c2,c3,c4)areselectedfromthesepatches;clusteringoftheconceptsisperformed,andthe\\nTCAV score is calculated, which determines how important these concepts are for a particular prediction.\\nInput images before CNN are taken from the Cancer Genome Atlas (TCGA) database ( https://www.cancer.\\ngov/ccg/research/genome-sequencing/tcga ).\\nthe direction pointing away from the random examples to the concept of interest. For example,\\nthe directional derivativedp(z)\\nd(vl\\nC)of zebra class zdetermines how much a concept (‘strips,’ ‘dotted\\nline,’ ‘meshed’) has an impact on the classification of zebra. TCAV score analyses the importance\\nofeachconcept,i.e.,ifthedirectionalderivativeschangepositively,thentheconceptisimportant;\\notherwise,not.\\nACE[55]automaticallyextractsrandomexampl', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1255: ('abase ( https://www.cancer.\\ngov/ccg/research/genome-sequencing/tcga ).\\nthe direction pointing away from the random examples to the concept of interest. For example,\\nthe directional derivativedp(z)\\nd(vl\\nC)of zebra class zdetermines how much a concept (‘strips,’ ‘dotted\\nline,’ ‘meshed’) has an impact on the classification of zebra. TCAV score analyses the importance\\nofeachconcept,i.e.,ifthedirectionalderivativeschangepositively,thentheconceptisimportant;\\notherwise,not.\\nACE[55]automaticallyextractsrandomexamplesandhigh-levelvisualconceptsfromtheimage\\npresented in the training data. This method selects segments of multiple resolutions from the\\ntrainingimagesbelongingtothesameclass.Allthesegmentsresizedasoriginalimagesaregiven\\nasinputtotheCNNmodel.Similarsegmentsareclusteredintheactivationspaceofthefinallayer\\nusingEuclideandistance,andlow-similarityclustersegmentsareremovedasanoutlier.Afterthat,\\nan importance score like TCAV is computed for the clusters that contributed to the prediction of\\na class. Besides, the explanation results were evaluated quantitatively by human involvement in\\ntwo experiments:(i)identifyingtheintruderconceptand (ii) identifyingtheconcept’smeaning.\\nConceptShap[ 237]isaposthoc,concept-basedmethodusedtoenhancetheinterpretabilityof\\nTCAV and ACE by answering how much a concept contributes to a prediction. It uses a concept\\ndiscoverymethodtofindaparticularsetofcompleteandinterpretableconcepts,wherecomplete\\nmeanstheconceptcanfullyexplainthemodel’sdecision.ThedifferencewiththeACEmethodis\\nthat concepts are consistently clustered to certain coherent spatial regions to find the closeness\\nwith the concept and its nearest neighbors. If the concept vector with a high completeness score\\nisCs={c1,c2,....cn}, then the method uses Shapley Value [ 187] to find the importance of each\\nconceptforquantifyingtheimportantattributesof an image.\\nCausal Concept Effect (CACE) [56] can be defined as the causal effect of an understandable\\nhuman concept on the DNN model’s prediction. TCAV method faces difficulties finding co', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1256: ('ts are consistently clustered to certain coherent spatial regions to find the closeness\\nwith the concept and its nearest neighbors. If the concept vector with a high completeness score\\nisCs={c1,c2,....cn}, then the method uses Shapley Value [ 187] to find the importance of each\\nconceptforquantifyingtheimportantattributesof an image.\\nCausal Concept Effect (CACE) [56] can be defined as the causal effect of an understandable\\nhuman concept on the DNN model’s prediction. TCAV method faces difficulties finding concepts\\nif the training data consists of multiple classes, biases in data, and the presence of color variation\\ninthedata.However,CACEexplainsthecausaleffectoftheconcept’spresenceorabsenceonthe\\nclassifier’soutput.Additionally,theauthorsused VariationalAutoEncoders(VAEs) forapprox-\\nimating VAE-CaCE, which estimates the causal effect of the generated concept. Experimentation\\nshowsthatCACE performsbetterin thepresenceof biasesand correlationindata.\\n3.4 Concept-basedExplanationsfor Medical Images\\nSeveral studies have used concept-based explanations for medical image analysis (Table 3).\\nFigure3shows a general overflow of how concept-based explanation can be applied where the\\nfinal prediction is relevant to selected clinical concepts or deep features. Kim et al. [ 97] utilized\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:14 Md I.Hossain etal.\\nTCAV to explain the predictions of DR levels. The clinical concepts related to the diagnosis of\\nDR level show a high TCAV score, whereas low scores for non-diagnostic concepts. For example,\\nDR-level diagnosis by doctors depends on microaneurysms or aneurysms; therefore, these diag-\\nnostic concepts showed a comparatively high TCAV score. Further, the TCAV method is applied\\nto cardiac MRI image data to provide clinically meaningful explanations for the predictions of a\\nblack-box classifier in Reference [ 83]. Moreover, MRI images are processed by selecting the re-\\ngionofinterestorpatchesandextractingsuperpixelsfromtheobtainedpatches.Next,theresiz', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1257: (' scores for non-diagnostic concepts. For example,\\nDR-level diagnosis by doctors depends on microaneurysms or aneurysms; therefore, these diag-\\nnostic concepts showed a comparatively high TCAV score. Further, the TCAV method is applied\\nto cardiac MRI image data to provide clinically meaningful explanations for the predictions of a\\nblack-box classifier in Reference [ 83]. Moreover, MRI images are processed by selecting the re-\\ngionofinterestorpatchesandextractingsuperpixelsfromtheobtainedpatches.Next,theresized\\npatches are fed into the network (UNET) to get activation from the middle layer. Then, concept\\nclustering is done on the latent space of superpixels; therefore, it helps to get to CAVs defined as\\na perpendicular vector to the decision boundary between cluster data and random counterparts\\nobtainedby traininga binaryclassifier.\\nIn Reference [ 57], the authors extended TCAV into a regression problem as the diagnostic con-\\nceptsareusuallyassessedcontinuouslybycalculating regressionconceptvectors(RCVs) .Usu-\\nally, TCAV finds a discriminator between user-defined concepts and random images using direc-\\ntional derivatives, whereas they measured the direction of the greatest increase for a continuous\\nconcept.ThemethodcalculatestherelevanceofaconceptusingtheRCVwiththehelpofbidirec-\\ntional relevance scores. Further, the authors detected tumor tissue in breast lymph node samples\\nandfoundthatnucleitexturewasanimportantconcept.Moreover,correlationandnucleicontrast\\nwererelevant forclassifyingbreasttissuepatches.\\nClough et al. [ 33] identified the disease of cardiac MR segmentation and used a concept acti-\\nvation vectorto interpretthedecision concerningclinically standardmeasurements.The authors\\nused a variational autoencoder to get a latent representation and a decoder to reconstruct the im-\\nageforlocalexplanation.Intheintermediatelayersofthenetwork,TCAVwasusedtofindwhich\\ndiagnostically meaningful or clinical biomarkers were most associated with cardiac disease. For\\nexample, filling rates and ventricular ejection had a sig', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1258: ('t al. [ 33] identified the disease of cardiac MR segmentation and used a concept acti-\\nvation vectorto interpretthedecision concerningclinically standardmeasurements.The authors\\nused a variational autoencoder to get a latent representation and a decoder to reconstruct the im-\\nageforlocalexplanation.Intheintermediatelayersofthenetwork,TCAVwasusedtofindwhich\\ndiagnostically meaningful or clinical biomarkers were most associated with cardiac disease. For\\nexample, filling rates and ventricular ejection had a significant score related to the disease; there-\\nfore, the network recognized these clinical features as significant. In another extension of TCAV,\\nthe author introduced a new metric called Uniform unit Ball surface Sampling [ 236] to show the\\nconcept’s importance in CNN layers and explained the radiomics concept using mammographic\\nimages.Moreover,TCAVwasusedforskinlesionclassificationinReference[ 130]tolearnhuman\\nunderstandabledermoscopicconceptssuchaspigmentnetworks,streaks,dotsandglobules,blue-\\nwhitishveils,asymmetry,regressionstructure,andcolor.InReference[ 50],theauthorspresented\\nTCAV for interpreting the estimation of breast cancer biomarkers using six concepts, e.g., high-\\ngradecarcinoma,invasive lobularcarcinoma,low-grade carcinoma,tumor-adjacentdesmoplastic\\nstromalchanges,ductalcarcinoma insitu,andtumor-infiltratinglymphocytes.\\nFang et al. [ 46]p r o p o s e da visual concept mining (VCM) method based on human-\\nunderstandable concepts to interpret infectious keratitis classification. VCM comprises two main\\ncomponents: (i) the concept generator automatically searches the relevant concepts and (ii) the\\nvisual concept extractor learns concepts’ similarity and diversity by clustering the concepts of\\ndifferent classes. Moreover, Sauter et al. [ 181] used the ACE method to extract visual concepts\\nautomatically from digital histopathology data. They demonstrated that ACE helped to discover\\nclass-correlatedbias,samplingbias,measurementbias,andclasssamplingratio bias.\\n3.5 Counterfactual-based Explanations\\nA counte', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1259: ('ain\\ncomponents: (i) the concept generator automatically searches the relevant concepts and (ii) the\\nvisual concept extractor learns concepts’ similarity and diversity by clustering the concepts of\\ndifferent classes. Moreover, Sauter et al. [ 181] used the ACE method to extract visual concepts\\nautomatically from digital histopathology data. They demonstrated that ACE helped to discover\\nclass-correlatedbias,samplingbias,measurementbias,andclasssamplingratio bias.\\n3.5 Counterfactual-based Explanations\\nA counterfactual explanation for images makes a minimal change in the images to alter a prede-\\nfined output and interpret predictions of an individual instance [ 218]. VAE and generative ad-\\nversarial network (GAN) are usually used to generate counterfactual explanations by realistic\\nsynthesisoftheinputimages[ 88,126].Thepredictiondependsonspecificpixelvariationsoreven\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:15\\nFig. 4. An example of counterfactual explanation where the original image can be perturbed to alter the\\nprediction. For example, a benign class can be predicted as malignant or vice versa. Input images before\\nCNN are taken from theTCGA database.\\non the whole altered image. For instance, predicting 03 from a counterfactual XAI is possible by\\nperturbingthepixels of digit 08.\\nGuidedbyPrototypes[ 128]proposesamodel-agnosticmethodthatsearchesinterpretablecoun-\\nterfactual instances to provide powerful insights about model prediction. It analyses the decision\\nprocess to find the important features of a decision. The method demonstrates the changes in in-\\nputfeaturesthatcanhelpalterthepredictionofapredefinedoutput.Itperturbstheinputfeatures\\nfrom the test data until the desired prediction is obtained. In the case of image perturbation, the\\npixel is modified until the closest image to the original one is found, and of course, a different\\nclassification result for the perturbed image is achieved. To get the meaningful perturbation, the\\nobjectivelossfunc', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1260: ('the decision\\nprocess to find the important features of a decision. The method demonstrates the changes in in-\\nputfeaturesthatcanhelpalterthepredictionofapredefinedoutput.Itperturbstheinputfeatures\\nfrom the test data until the desired prediction is obtained. In the case of image perturbation, the\\npixel is modified until the closest image to the original one is found, and of course, a different\\nclassification result for the perturbed image is achieved. To get the meaningful perturbation, the\\nobjectivelossfunctioncanbedefinedas L=c·Lpred+β·L1+L2+LAE+Lproto,wherethe c·Lpred\\nhelps to predict another class using the perturbed images and other terms for regularization. In\\nFigure4, an application of the method is presented where perturbation of the image can alter the\\nprediction, i.e., if the classifier predicts an image as benign, then the counterfactual explanation\\nwould give theoutputasmalignant orviceversa.\\nCEM[37]issuitablewhentheclassesareclose,i.e.,changingafewpixelsaltersclassprediction.\\nTo explain the classification, the technique finds which pixels should be present or absent in an\\nimage. It uses the fact that an image xis classified as class ybecause the features fa......fd\\nare present, and features fm....fpare absent, formally known as pertinent positives (PP) or\\npertinent negatives (PN) , respectively. Pertinent positives are the factors (pixel for the image)\\nthat lead to the same classification as original instances and pertinent negatives lead to different\\nclassesw.r.toriginalclass.Ifaninput x0,thentheperturbation δ,themodifiedinputexample xϵχ\\nisdefinedas x=x0+δ,whereχrepresentsdataspace,thenPN’scanbefoundusingthefollowing\\noptimization equation,\\nmin\\nδϵχ/x0c·fneд\\nk(x0,δ)+β||δ||1+||δ)||2\\n2+γ||x0+δ−AE(x)||2\\n2), (7)\\nwherefneд\\nk(x0,δ)isthelossfunctionthatencouragesthepredictiontobeadifferentclass, β||δ||1+\\n||δ)||2\\n2helpstoselectefficientfeatures,and ||x0+δ−AE(x)||2\\n2isthereconstructionerrorof xwhen\\nanautoencoderisused.Forpertinentpositives,featuresthatareeasilyavailableintheinputdata\\nare considered.PPsarealso c', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1261: ('rturbation δ,themodifiedinputexample xϵχ\\nisdefinedas x=x0+δ,whereχrepresentsdataspace,thenPN’scanbefoundusingthefollowing\\noptimization equation,\\nmin\\nδϵχ/x0c·fneд\\nk(x0,δ)+β||δ||1+||δ)||2\\n2+γ||x0+δ−AE(x)||2\\n2), (7)\\nwherefneд\\nk(x0,δ)isthelossfunctionthatencouragesthepredictiontobeadifferentclass, β||δ||1+\\n||δ)||2\\n2helpstoselectefficientfeatures,and ||x0+δ−AE(x)||2\\n2isthereconstructionerrorof xwhen\\nanautoencoderisused.Forpertinentpositives,featuresthatareeasilyavailableintheinputdata\\nare considered.PPsarealso consideredas anoptimization problemthatisas follows:\\nmin\\nδϵχ∩x0c·fpos\\nk(x0,δ)+β||δ||1+||δ)||2\\n2+γ||δ−AE(δ)||2\\n2), (8)\\nwhereδϵχ∩x0is theinterpretableperturbation.\\nL2X [29] is a model agnostic approach that employs instance-wise feature selection, i.e., finds\\ntheimportancescoreforeachfeaturewhilepredictinganinstance.Itextractsthemostinformative\\nfeaturesforagiveninstanceviamutualinformation.Thetechniquecomputesmutualinformation\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:16 Md I.Hossain etal.\\nbetween selected features and response variables using a variational approximation and assigns\\na score for patches (groups of pixels). If the score for a selected patch is positive, then that patch\\npositivelyimpacts thepredictionof an instance,and if thescore is negative, thenthe patchis not\\ntheimportantone.\\nAdversarial Black box Explainer generating Latent Exemplars (ABELE) [60] is a local,\\nmodel-agnosticXAImethodthatprovidesasetofexemplars(examplesclassifiedwiththesamela-\\nbel) and counter-exemplar images (counterfactuals) and generates the saliency map. The method\\nturns the input image to its latent representation utilizing an adversarial autoencoder and gen-\\nerates a neighborhood in the latent space. A decision tree classifier is trained on the synthetic\\nimages found in the local neighborhood to mimic the behavior of the black box locally. The deci-\\nsion rule and counterfactual rules are extracted from the decision tree to generate the exemplars\\nandcounter-exemplars.Thesaliencymapiscrea', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1262: ('ter-exemplar images (counterfactuals) and generates the saliency map. The method\\nturns the input image to its latent representation utilizing an adversarial autoencoder and gen-\\nerates a neighborhood in the latent space. A decision tree classifier is trained on the synthetic\\nimages found in the local neighborhood to mimic the behavior of the black box locally. The deci-\\nsion rule and counterfactual rules are extracted from the decision tree to generate the exemplars\\nandcounter-exemplars.Thesaliencymapiscreatedfromtheimageregionthatcontributestothe\\nclassificationand theregionthatshiftstoanotherclass.\\n3.6 Counterfactual-based Explanationsfor Medical Images\\nThe counterfactual explanation is suitable for the medical image (Table 3) because it synthesizes\\nsmall, explainable changes to a query image to generate the desired alteration. For instance, the\\ntrainingcalibration-basedexplainers[ 210]isusedtointerpretthemodelpredictionforidentifying\\npneumonia-related anomalies in the chest X-ray images. In this work, a normal class xis trans-\\nformedintoitslatentrepresentationusinganencoder,andcounterfactual ¯xislearnedinthelatent\\nspace by a calibration-driven optimization such that the classifier’s output changes to abnormal\\nfromtheabnormalclass.\\nSchutte et al. [ 183] presented an explanation method using StyleGAN [ 91] to predict knee os-\\nteoarthritisseverityonX-rayimagesandtumorprobabilitypredictiononhistologyimagesbased\\nonalterationoftheimagestogeneratedifferentoutcomes.AStyleGANistrainedoninputimages\\ntocreateamappingbetweentheimageandlatentvectors.Themethodfindstheoptimaldirection\\ninthelatentrepresentationtogenerateafluctuationinmodelprediction.Afterward,thesynthetic\\nimagesfor alteringthepredictionaregeneratedbyshiftingtheinputimage latentrepresentation\\nalong the optimal direction. The generative method shows where the predictive features are lo-\\ncatedintheimages and howtheyimpact theprediction.\\nFurthermore,thecounterfactualgenerativenetwork[ 99]explainslesionpredictionbygenerat-\\ningdifferentcounterfactualexamplesfromthein', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1263: ('eentheimageandlatentvectors.Themethodfindstheoptimaldirection\\ninthelatentrepresentationtogenerateafluctuationinmodelprediction.Afterward,thesynthetic\\nimagesfor alteringthepredictionaregeneratedbyshiftingtheinputimage latentrepresentation\\nalong the optimal direction. The generative method shows where the predictive features are lo-\\ncatedintheimages and howtheyimpact theprediction.\\nFurthermore,thecounterfactualgenerativenetwork[ 99]explainslesionpredictionbygenerat-\\ningdifferentcounterfactualexamplesfromtheinputchestX-rayimages.Theframeworkgenerates\\ncounterfactuallesionalimagesfromqueryimagesusingcounterfactualmanipulationtraining.The\\nattribution maps of lesional regions are generated by subtracting the counterfactual image from\\nthe input images. Similarly, Singla et al. [ 195] provided counterfactual visual explanations that\\ntargeted three labels: cardiomegaly, pleural effusion, and edema for chest X-ray images based on\\nconditional Generative Adversarial Network. The framework generates the counterfactuals from\\ninputimageswhilepreservingtheanatomicalshapeandsmalldetailsusingspecializedreconstruc-\\ntionloss.\\nMertesetal.[ 140]proposedGANterfactualframeworktogeneratecounterfactualimageexpla-\\nnationsfor pneumonia detectionfrom X-ray images usingan adversarialimage-to-image transla-\\ntionalgorithm.TheauthorsusedCycleGAN[ 251]withamodifiedcounterfactuallossfunctionto\\naltertheinputimagesuchthattheclassifierpredictedtheincorrectclass.Anothercounterfactual\\napplicationusingimage-to-imagetranslationbasedonCycleGAN[ 251]wasappliedtojustifythe\\ndecisionofDiabeticMacularEdemapredictioninReference[ 151].Further,inReference[ 16],clas-\\nsification with feature attribution was proposed using VAE-GAN to disentangle class relevance\\nfeatures from the background for better interpretability in brain image datasets. Moreover, Gifs-\\nplanation[ 34]wasproposedusinganautoencoderandgradientupdatethatcanchangethelatent\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:17\\nrepresentation o', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1264: ('pliedtojustifythe\\ndecisionofDiabeticMacularEdemapredictioninReference[ 151].Further,inReference[ 16],clas-\\nsification with feature attribution was proposed using VAE-GAN to disentangle class relevance\\nfeatures from the background for better interpretability in brain image datasets. Moreover, Gifs-\\nplanation[ 34]wasproposedusinganautoencoderandgradientupdatethatcanchangethelatent\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:17\\nrepresentation of a particular input image. Multiple images were generated to produce a short\\nvideo (gif) by enhancing or reducing the features utilized for a prediction to explain the decision\\nof chest X-ray classifiers. Ghandeharioun et al. [ 52] presented a method named DISSECT that\\ntrains jointly a generator, a discriminator, and a concept disentangler to produce concept traver-\\nsals defined as a series of instances with increasing degrees of concepts that influence a model’s\\ndecision. The procedure was validated on melanoma classification, and it was found that large\\nlesions,asymmetricalshapes,and jagged bordersareresponsibleforprediction.\\nIn Reference [ 184],Generative Visual Rationales (GVRs) identify the features of conges-\\ntive heart failure on chest radiographs and detect bias and overfitted models. A neural network\\nandagenerativemodelweretrainedontheencodedrepresentationsofthelabeledandunlabeled\\ndatasets, respectively, to estimate B-type natriuretic peptides. The GVR was created by compar-\\ning the reconstructed healthy radiograph and the diseased radiograph produced by the genera-\\ntive model. Additionally, ABELE [ 60] was implemented to offer the practitioner with explanation\\nfor skin lesion diagnosis, where Progressive Growing Adversarial Autoencoder was trained to re-\\nconstruct low-resolution skin lesion images [ 141]. The method provides medical exemplars and\\ncounterexemplarsfor theclassificationdiagnosisto enhanceinterpretability.\\n3.7 Prototype-basedExplanations\\nPrototype explanation helps users to reason the mo', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1265: ('althy radiograph and the diseased radiograph produced by the genera-\\ntive model. Additionally, ABELE [ 60] was implemented to offer the practitioner with explanation\\nfor skin lesion diagnosis, where Progressive Growing Adversarial Autoencoder was trained to re-\\nconstruct low-resolution skin lesion images [ 141]. The method provides medical exemplars and\\ncounterexemplarsfor theclassificationdiagnosisto enhanceinterpretability.\\n3.7 Prototype-basedExplanations\\nPrototype explanation helps users to reason the model’s prediction by examining cases similar\\ntotheoriginalmodel.Humansoftenuserepresentativeexamplesforcategorizationanddecision-\\nmaking [ 21]. Similarly, prototype-based explanation models employ representative examples to\\ncluster and explain the data. For a particular class, the XAI finds the best-matched prototypical\\nimages.\\nInfluenceFunctions[ 102]helpsdeterminemodelbehavior,modeldebugging,anddetectingdata\\nerrors.Itanalyzesthetrainingdatatofindthemostresponsibletrainingpointforpredictingaclass.\\nIf the training examples z1,z2......zn,w h e r ezi=(xi,yi),t h e nxiis the input images, yiis the\\nlabels; if a single training image zis upweighted by a small amount, then the influence function\\ngives an approximation for parameter θϵΘand the new changed parameter ˆθϵ,zis formulated as\\nfollows:ˆθϵ,zdef=arд min θϵΘ(1−ϵ)1\\nn/summationtextn\\ni=1L(zi,θ)+ϵL(z,θ),w h e r el o s s L(z,θ)for a data point.\\nIn particular, at a test point ztest, the influence of upweighting zon the loss has the following\\nclosed-formexpression:\\nLup,loss(z,ztest)def=dL(ztest,ˆθϵ,z)\\ndϵ|ϵ=0 (9)\\n=−∇θL(ztest,ˆθ)TH−1\\nˆθ∇θL(z,ˆθ),\\nwhereHˆθdef=1\\nn/summationtextn\\ni=1∇2\\nθL(zi,ˆθ)istheHessian.Sotheinfluenceofatrainingpointwouldbehigher\\nif theupweightingof a trainingpointhasmore impacton thelossparameter.\\nPrototypicalPartNetwork(ProtoPNet) [27]isaposthocexplanationandamodel-agnostic\\nmethod that can be used to explain the image data. The method identifies some parts of the test\\nimagethatlooklikesomeprototypicalpartsofthetrainingimageandmakesafinalclassification', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1266: ('up,loss(z,ztest)def=dL(ztest,ˆθϵ,z)\\ndϵ|ϵ=0 (9)\\n=−∇θL(ztest,ˆθ)TH−1\\nˆθ∇θL(z,ˆθ),\\nwhereHˆθdef=1\\nn/summationtextn\\ni=1∇2\\nθL(zi,ˆθ)istheHessian.Sotheinfluenceofatrainingpointwouldbehigher\\nif theupweightingof a trainingpointhasmore impacton thelossparameter.\\nPrototypicalPartNetwork(ProtoPNet) [27]isaposthocexplanationandamodel-agnostic\\nmethod that can be used to explain the image data. The method identifies some parts of the test\\nimagethatlooklikesomeprototypicalpartsofthetrainingimageandmakesafinalclassification\\nbasedonaweightedcombinationofthesimilarityscorebetweenthelearnedprototypeandparts\\nofthetestimage.Toillustrate,let H×W×Dbetheshapeoftheconvolutionaloutput f(x),fora\\ngiveninputimage x,whereH=W=7andDcouldbe128,256,512,usingcross-validation.Then\\ntwo additional 1×1 convolutional layers help to learn the prototype of spatial dimension 1 ×1\\nwith the depth Dof each prototype. Since the channel dimension is the same for both prototype\\nand convolutional output, while the HandWof each prototype are smaller than the whole CNN\\noutput, each prototypedenotes an activation pattern in a patch of CNN output, which eventually\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:18 Md I.Hossain etal.\\nFig. 5. Visual comparison of the patch from test image and learned prototypical patch from training data.\\nThe explanation is based on how these patches are similar in texture, contrast, shape, hue, and saturation.\\nTrainingand test images beforeCNN are taken from theTCGA database.\\ncorresponds to some prototypical image patch in the original pixel space. Hence, each prototype\\nis the latent representation of some prototypical part of some training image. Afterward, a simi-\\nlarityscoredetermineshowstrongaprototypicalpartispresentintheimage,whiletheheatmap\\nhighlightsthatpartof theimage.\\nReference [ 153] is a modification of ProtoPNet, which explains why the model considers the\\nprototype and image patch similar. The modified method is especially applicable when the sim-\\nilarity between the prototype and patch i', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1267: ('totypical image patch in the original pixel space. Hence, each prototype\\nis the latent representation of some prototypical part of some training image. Afterward, a simi-\\nlarityscoredetermineshowstrongaprototypicalpartispresentintheimage,whiletheheatmap\\nhighlightsthatpartof theimage.\\nReference [ 153] is a modification of ProtoPNet, which explains why the model considers the\\nprototype and image patch similar. The modified method is especially applicable when the sim-\\nilarity between the prototype and patch is not very noticeable. It enhances the explanation of a\\nprototype with additional quantitative information about the visual characteristics of prototypes.\\nSpecifically, it figures out the influence of color hue, saturation, shape, texture, and contrast in a\\nprototype,makingit possibletounderstandwhythemodel deems twoimages similar.\\nFurthermore, Donnelly et al. [ 39] introduced Deformable ProtoPNet based on ProtoPNet that\\ncanprovidespatiallyadjustabledeformableprototypes.Adeformableprototypeconsistsofseveral\\nprototypicalpartsthataltertheirrelativespatialpositionstodetectsimilarpartsofaninputimage\\ninan adaptivemanner.\\nMaximumMeanDiscrepancycritic(MMD-critic) [96]canhelpunderstandcomplexorun-\\nlabeleddatadistribution.Itusestheprototypeandcriticismtocharacterizethedatasettoenhance\\nthe explainability. Criticism is defined as the data point in the input space that is not recorded\\nby prototypes or does not fit the model. It uses maximum mean discrepancy that measures the\\ndifferencebetweentheprototypedistributionandthetotaldatadistribution,andcriticismsarese-\\nlectedfrompartsofthedatasetthatareunderrepresentedbytheprototypes.Fordogclassification,\\ntheMMD-criticlearnsreasonableprototypes,whereasthecriticismselectsdogcategorieswithan\\nunusual type, such as pictures of dogs with costumes, having the movement of dogs. When data\\ndistributionsneedtobewellexplained,prototypes,togetherwithcriticism,arehelpfultofacilitate\\nhumanreasoningand understanding.\\n3.8 Prototype-basedExplanationsfor Medical Images\\nFigure5representsthetypicalp', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1268: ('etotaldatadistribution,andcriticismsarese-\\nlectedfrompartsofthedatasetthatareunderrepresentedbytheprototypes.Fordogclassification,\\ntheMMD-criticlearnsreasonableprototypes,whereasthecriticismselectsdogcategorieswithan\\nunusual type, such as pictures of dogs with costumes, having the movement of dogs. When data\\ndistributionsneedtobewellexplained,prototypes,togetherwithcriticism,arehelpfultofacilitate\\nhumanreasoningand understanding.\\n3.8 Prototype-basedExplanationsfor Medical Images\\nFigure5representsthetypicalprocessoftheprototypicalexplanationimplementationforthemed-\\nical image. Several studies used prototypical explanations in the medical image, as presented in\\nTable3.Forexample,theinfluencefunctionwasusedinReference[ 221]toexplainlesionclassifica-\\ntionbyidentifyingrelevantfeaturesandshowingwhichpartoftheimagecontainsthosefeatures.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:19\\nTable 3. ASummaryof Different Non-attribution-basedMethods’Applications forMedical Images\\nMethods Modality Paper Remarks\\nConcept-based MRI\\nFundus image\\nCT\\nOCT\\nMRI\\nHistopathology\\nMRI\\nSkin\\nHistology\\nEye\\nHistopathology[33]\\n[97]\\n[230]\\n[207]\\n[83]\\n[57]\\n[33]\\n[130]\\n[50]\\n[46]\\n[181]Coronaryarterydiseasedetection\\nDR prediction\\nPredictingthemalignancy of lungnodules\\nGlaucoma detection in optical coherence tomography\\nSegmentation of left ventricle, right ventricle and my-\\nocardium\\nRelevant concepts detection using Regression Concept\\nVectors\\nClinical biomarkers identification forcardiac disease\\nlearninghuman understandabledermoscopic concepts\\nEstimationof breast cancer biomarkers\\nInfectious keratitisclassification\\nVisualconcepts extraction automatically for skin\\ncancer\\nCounter-factual\\nbasedX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nMRI\\nX-ray\\nEye\\nX-ray\\nSkin[210]\\n[183]\\n[138]\\n[195]\\n[52]\\n[99]\\n[140]\\n[16]\\n[34]\\n[151]\\n[184]\\n[141]Pneumonia-related anomalies identification\\nKneeosteoarthritisseverityprediction\\nCategorizationof the samplewithmassesor healthy\\nLesionprediction\\nDetecting biases of amelano', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1269: ('disease\\nlearninghuman understandabledermoscopic concepts\\nEstimationof breast cancer biomarkers\\nInfectious keratitisclassification\\nVisualconcepts extraction automatically for skin\\ncancer\\nCounter-factual\\nbasedX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nX-ray\\nMRI\\nX-ray\\nEye\\nX-ray\\nSkin[210]\\n[183]\\n[138]\\n[195]\\n[52]\\n[99]\\n[140]\\n[16]\\n[34]\\n[151]\\n[184]\\n[141]Pneumonia-related anomalies identification\\nKneeosteoarthritisseverityprediction\\nCategorizationof the samplewithmassesor healthy\\nLesionprediction\\nDetecting biases of amelanoma classifier\\nLesion prediction by generatingcounterfactuals\\nPneumonia detection\\nDisentanglingclass relevance features\\nMassprediction bygenerating gif\\nDiabetic macular edema prediction\\nIdentifyingthefeatures of congestive heart failure\\nSkinlesion diagnosis\\nInfluence function MRI\\nSpectrogram[221]\\n[73]Explanation of lesionclassification\\nNeonatal pain assessment\\nPrototype-based Endoscopy\\nUltrasound\\nHistology\\nSkin\\nX-ray\\nX-ray\\nX-ray\\nSkin\\nX-ray\\nX-ray[221]\\n[117]\\n[212]\\n[172]\\n[98]\\n[193]\\n[15]\\n[14]\\n[74]\\n[191]Ulcer recognitionin wireless capsule endoscopy\\nThyroidnodulediagnosis\\nCancer or non-cancer classification\\nSkin cancer recognition\\nDiagnosis in chest radiography\\nCOVIDdetection\\nMasslesions classification\\nMelanoma classification\\nSimilar image retrievalfromtoexplain thechest X-ray\\nLocalization of salient image regions\\nRadiologist features importance score was determined by the influence function for classifying a\\nspecificlesion.\\nAdditionally, the influence function was employed in Reference [ 73] to explain neonatal pain\\nassessment from the spectrogram image of the neonate’s audio signal. The paper identifies the\\nmost helpful training examples to justify a decision and the harmful training images to remove\\nbad-quality data. In Reference [ 212], the author explained the decision of the neural network to\\nclassifycancerfromthepathologicalimageusingaprototype-basedinterpretation.Thepaperuses\\naVAEtoencodetheimagepatchesandclusterthepatchestogettheprototype.TheVAEdecodes\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicati', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1270: ('in\\nassessment from the spectrogram image of the neonate’s audio signal. The paper identifies the\\nmost helpful training examples to justify a decision and the harmful training images to remove\\nbad-quality data. In Reference [ 212], the author explained the decision of the neural network to\\nclassifycancerfromthepathologicalimageusingaprototype-basedinterpretation.Thepaperuses\\naVAEtoencodetheimagepatchesandclusterthepatchestogettheprototype.TheVAEdecodes\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:20 Md I.Hossain etal.\\ntheprototypestoobtainavisualinterpretation,allowinghumanstounderstandthecomponentvi-\\nsually.Inaddition,basedonprototypeoccurrences,aweightiscalculated,whichhelpstoascertain\\ntheprototype’scontributionto classifyingcancer.\\nContextual decomposition explanation penalization [ 172] explains skin cancer by ignoring the\\nspurious examples in the training data. The paper uses an explanation term that compares the\\nuser’sandmodel’sinterpretations.Inanotherapplication[ 117],theauthorappliedaprototypeto\\ninterpret the decision in thyroid nodule diagnosis. The method inputs the feature maps extracted\\nusingtheCNNintotheprototypelayer,whichutilizesthebuilt-inprototypestogeneratesimilarity\\nscoresbycomparingthemwiththefeaturemap.Theprototypehavingthelargestsimilarityscore\\ncontainstheinformation of thetargetclass.\\nKim et al. [ 98] presented XProtoNet to understand disease-specific features for identifying dis-\\nease in chest X-ray images. The technique adaptively predicts an occurrence area of disease by\\ncomparing it with the learned prototypes of an image. The author used transformation loss to\\ngenerate a suitable occurrence map and L1loss for covering small occurrence areas to avoid ir-\\nrelevant image regions. Singh et al. [ 193] introduced Generalized Prototypical Part Network for\\nCOVIDdetectionfromchestX-rayimagesthatusesageneralizedversionofdistancefunction L2\\nto compute the similarity between the prototypes. Unlike ProtoPNet, the generalized L2function\\nutilizesprototypepartsofan', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1271: ('nce area of disease by\\ncomparing it with the learned prototypes of an image. The author used transformation loss to\\ngenerate a suitable occurrence map and L1loss for covering small occurrence areas to avoid ir-\\nrelevant image regions. Singh et al. [ 193] introduced Generalized Prototypical Part Network for\\nCOVIDdetectionfromchestX-rayimagesthatusesageneralizedversionofdistancefunction L2\\nto compute the similarity between the prototypes. Unlike ProtoPNet, the generalized L2function\\nutilizesprototypepartsofanydimension,suchasrectangularspatialdimensionsandsquaredspa-\\ntialdimensions,forimageclassification.Furthermore,interpretableAIalgorithmforbreastlesions\\n[15]comparestestmammogramstoprototypicalimagesofdifferentmassmargintypesforclassi-\\nfying mass lesions. The method learns medically relevant prototypes and localizes relevant areas\\nin the images. Distance function L2compares each patch of the convolutional feature maps with\\neachlearnedprototypeandhelpstogeneratesimilaritymaps.Similarityscoresfromthesimilarity\\nmaps feed into the fully connected layers to predict benign or malignant lesions. Moreover, the\\nactivationprecisionmetricwasintroducedtomeasuretheproportionofpertinentdatamarkedby\\ntheradiologist-annotatorusedto classifymassmargin.\\nAnother similarity-based method was proposed in Reference [ 14] for melanoma classification\\nusing similar image retrieval to justify the diagnosis. The method uses a loss function with regu-\\nlarizationtermstoimprovethefeaturespaceandinterpretabilityinaclinicalworkflow.While,in\\nReference[ 68],asearchtoolforsimilarhistopathologyimageswasdevelopedbasedonretrieving\\nsimilar histologic features, cancer grades, and organ sites. Hu et al. [ 74] applied similarity-based\\nsaliency maps to explain the chest X-ray image retrieval approach. The method takes a retrieval\\nandqueryimagetoidentifythemostsimilarregionsbydeletionandinsertionmetrics.Moreover,\\nin Reference [ 191], the authors investigated the application of interpretability to localize salient\\nimage regions for better feature representati', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1272: ('erence[ 68],asearchtoolforsimilarhistopathologyimageswasdevelopedbasedonretrieving\\nsimilar histologic features, cancer grades, and organ sites. Hu et al. [ 74] applied similarity-based\\nsaliency maps to explain the chest X-ray image retrieval approach. The method takes a retrieval\\nandqueryimagetoidentifythemostsimilarregionsbydeletionandinsertionmetrics.Moreover,\\nin Reference [ 191], the authors investigated the application of interpretability to localize salient\\nimage regions for better feature representations and medical image retrieval. Experiments on the\\nchest X-ray dataset demonstrate that the method supports retrieval with visual explanations, im-\\nprovestheclassconsistencyoftheretrievedimages,andimprovestheinterpretabilityoftheentire\\nsystem.\\n3.9 Other XAI Approaches\\nThissectionprovidesadditionalXAImethodsbasedondecisiontrees,wavelettransforms,feature\\ncorrelation,and human–AIinterfaces.\\nInterpretingCNNsviaDecisionTrees[ 245]aimstotransformtheconvolutedfeaturesfromthe\\ndifferentfiltersinsideaneuralnetworkintosemanticallymeaningfulconceptsandevaluatewhich\\nfilterorpartoftheimagecontributeshowmuchtoaprediction.Apredictionisobtainedbybridg-\\ning the middle layer features into the semantic meaningful concepts. The decision tree indicates\\nall decision modes of a CNN, where the root node mostly consists of common decision modes\\nand represents prediction rationales shared by many images. Further, each leaf node represents a\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:21\\nspecificdecisionmodeofanindividualimage,whilenodesclosetotheleavescorrespondtomodes\\nshared by minority images. Decision modes help to explain how the filters/parts of the image are\\nassociatedwiththefinalprediction.\\nDescribing deep features through the lens of radiologist features [ 159], the authors have ex-\\nplained deep features extracted from the last layers before the classification layer of a CNN with\\nrespecttosemanticfeaturesandtraditionalquantitativefeatures.Anexperiencedradiologist', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1273: ('edical Data 148:21\\nspecificdecisionmodeofanindividualimage,whilenodesclosetotheleavescorrespondtomodes\\nshared by minority images. Decision modes help to explain how the filters/parts of the image are\\nassociatedwiththefinalprediction.\\nDescribing deep features through the lens of radiologist features [ 159], the authors have ex-\\nplained deep features extracted from the last layers before the classification layer of a CNN with\\nrespecttosemanticfeaturesandtraditionalquantitativefeatures.Anexperiencedradiologistgen-\\neratessemanticfeaturesfromaCTscanofalungtumorandincludesthecommoncharacteristics\\nofatumor.QuantitativefeaturesareextractedfromatumorphenotypebyDefinienssoftwareand\\na radiologist,whichprovidesinformationaboutthenodule,suchas nodulesize,histogram-based\\ninformation,andpixelintensity.Moreover,wrapperfeatureselectionandtherandomforestwere\\nappliedtotraditionalquantitativeorsemanticfeatures,respectively,toselectthebestsubsetoffea-\\ntures. The Pearson correlation coefficient was calculated for each semantic feature with the deep\\nfeatures,andthefivemostcorrelatedfeaturesforeachsemanticfeaturewereselected.Then,each\\nsemanticfeatureisreplacedwiththecorrelateddeepfeaturesandcheckedwhetherthesameclas-\\nsification accuracy could be achieved. Since the same original classification accuracy is obtained\\nwithtraditionalquantitativefeatures,shape-basedquantitativefeaturesexplain deepfeatures.\\nThe Adaptive Wavelet Distillation [ 66] method distills knowledge from a trained DNN into a\\nvalidwavelettransform.Themethodemploysthreetypesoflossesintheformulationofthetech-\\nniques: The reconstruction loss permits the reconstruction of the initial data and guarantees that\\nthe wavelet transform is invertible, the wavelet loss ensures an accurate wavelet transformation,\\nand the interpretation loss enables knowledge distillation into the wavelet model from the pre-\\ntrained model. During the transformation process, the wavelet coefficients help to explain the\\nmodel’sprediction.AnapplicationofthemethodsismolecularpartnerpredictionusingtheLSTM\\n', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1274: ('typesoflossesintheformulationofthetech-\\nniques: The reconstruction loss permits the reconstruction of the initial data and guarantees that\\nthe wavelet transform is invertible, the wavelet loss ensures an accurate wavelet transformation,\\nand the interpretation loss enables knowledge distillation into the wavelet model from the pre-\\ntrained model. During the transformation process, the wavelet coefficients help to explain the\\nmodel’sprediction.AnapplicationofthemethodsismolecularpartnerpredictionusingtheLSTM\\nmodel,wherethereasonablefeatureisextractedfromtheprocess,likethemaximumvalueofthe\\ntimes seriesor tracelength.\\nHuman–AIInterfacestoSupportExplainabilityReference[ 70]highlightsthefactthatahuman\\nexpertintheloopcanplayacrucialroleinmedicalXAIbyprovidingtheexperienceandconceptual\\nknowledgeofwhatanAIsystemcannotdoalone.Figure 6showsaprocessofexplanationwhere\\nexplanatory statements sare acquired by a machine smor a human shwheresis a function of\\nr,k,c, i.e.,s=f(r,k,c).H e r eris the representation of an unknown fact ueassociated with an\\nentity,where krepresentspreexistingknowledgeforamachinethatisembeddedinanalgorithm,\\nand for a human, it is made up of implicit, explicit, or/and tacit knowledge, and cis the context,\\nwhichforahuman,thephysicalenvironmentwherethedecisionismadeandforamachineisthe\\nruntimeenvironment.Theunknownentity uerepresentsthegroundtruth дt,modeledbyhuman\\nmhor a machine mm. The goal is to determine whether a human can understand the explanation\\ngiven by the machine and to what extent a human can understand it. In an ideal scenario, both\\nthemachineandhumanstatementsarehomogeneous( mh=mm)andsimilartothegroundtruth.\\nFor example, if a pathologist is satisfied with the result of the XAI algorithm, then mh=mmis\\nsatisfied,meaning acongruenceexistsbetweenhumansand machines.\\n4 NON-IMAGE-BASEDXAI METHODS ANDAPPLICATIONS\\nIn this section, we provide the explanation methods for non-image-based data such as tabular,\\ntextual, time-series,and sequentialdata.\\n4.1 TabularData Explanation\\nWebrieflypresentalistoftabula', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1275: ('nderstand it. In an ideal scenario, both\\nthemachineandhumanstatementsarehomogeneous( mh=mm)andsimilartothegroundtruth.\\nFor example, if a pathologist is satisfied with the result of the XAI algorithm, then mh=mmis\\nsatisfied,meaning acongruenceexistsbetweenhumansand machines.\\n4 NON-IMAGE-BASEDXAI METHODS ANDAPPLICATIONS\\nIn this section, we provide the explanation methods for non-image-based data such as tabular,\\ntextual, time-series,and sequentialdata.\\n4.1 TabularData Explanation\\nWebrieflypresentalistoftabulardataexplanationmethodsforblack-boxalgorithmsthatcanbe\\nimplemented for medical data, such as clinical records and patient metadata. We follow the same\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:22 Md I.Hossain etal.\\nFig. 6. Explanation from human and model need to be congruent with explanatory statements that are\\nrelatedtogroundtruth[ 70].\\ntaxonomy as in Reference [ 21], where the authors present four types of explanations for tabular\\ndatabasedon(i) FeaturesImportance,(ii)Rule,(iii) Counterfactual,and(iv) Prototype.\\nFeatures Importance-based XAI Method assigns an importance score to each feature to under-\\nstandthefeatures’contributiontoaprediction.Higherimportancescoresimplyafeaturehasmore\\ninfluence on the prediction, whereas lower importance scores imply a feature has less influence.\\nWe discuss some commonly used XAI methods for determining feature importance. For example,\\nLIME [170], already described in Section 3.1.2, returns justifications as feature importance score.\\nLIME creates a local interpretable model (decision tree or linear model) trained on a new dataset\\nbasedonrandomlyselecteddatapointsclosetotheinstancebeingexplained,whichapproximate\\ninterpretable representations of the actual data. Finally, Least Absolute Shrinkage and Selection\\nOperator regularisation is employed to maintain only the most required features, and regression\\ncoefficients are utilized as feature importance scores. Another similar approach, MAPLE [ 165],\\nusesalocallinearmodelingtechniqueandara', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1276: ('.\\nLIME creates a local interpretable model (decision tree or linear model) trained on a new dataset\\nbasedonrandomlyselecteddatapointsclosetotheinstancebeingexplained,whichapproximate\\ninterpretable representations of the actual data. Finally, Least Absolute Shrinkage and Selection\\nOperator regularisation is employed to maintain only the most required features, and regression\\ncoefficients are utilized as feature importance scores. Another similar approach, MAPLE [ 165],\\nusesalocallinearmodelingtechniqueandarandomforestforneighborhoodselectionwherethe\\nlinearmodel’s coefficientsdetermine eachfeature’slocalimpact.\\nSHAP[133]basedoncooperativegametheoryisanadditivefeatureattributiontechniquethat\\nlinearly combines simplified input features. SHAP follows three desirable properties: (i) local ac-\\ncuracyensures the model’s prediction for a specific instance should not deviate mainly from the\\nexpected average prediction for simplified inputs; (ii) missingness necessitates that features that\\nare absent from the original input have no attributed influence on SHAP values if the simplified\\ninputs serve to indicate feature presence; and (iii) consistency states that if a model changes, then\\nthe contribution of a simplified input should increase, and the SHAP value should also increase.\\nMoreover, Neural Additive Models (NAM) [3] are designed to combine the deep neural net-\\nworks’ predictability with additive models’ inherent interpretability. NAMs train multiple neural\\nnetwork architectures in an additive manner to interpret the contributions of each input feature.\\nAdditionally,inReference[ 32],Equi-explanationMaps(EEM) wasproposedtosummarizethe\\nlogic of the black-box model to provide a concise representation of global explanations by split-\\nting the desirable explanation features region into subspaces depending on similar logic. Further,\\nLRP [10], discussed in Section 3.1.3, attributes an importance score to each feature depending on\\nitscontributiontothefinalmodelpredictionusinglocalpropagationrulesbackwardthroughthe\\nmodel layers', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1277: (' contributions of each input feature.\\nAdditionally,inReference[ 32],Equi-explanationMaps(EEM) wasproposedtosummarizethe\\nlogic of the black-box model to provide a concise representation of global explanations by split-\\nting the desirable explanation features region into subspaces depending on similar logic. Further,\\nLRP [10], discussed in Section 3.1.3, attributes an importance score to each feature depending on\\nitscontributiontothefinalmodelpredictionusinglocalpropagationrulesbackwardthroughthe\\nmodel layers.\\nThe rule-based XAI method provides explanations based on predefined rules to the end user\\nby reasoning about the final model prediction. For example, Local Rule-Based Explanations\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:23\\nTable 4. A Listof XAI Techniques That CanBeEmployed toExplain Medical Tabular Data\\nCategory XAI method andreference Data Type Remarks\\nFeatures\\nImportance-\\nbasedLRP[10]\\nLocal Interpretable Model-agnostic Ex-\\nplanations\\nMAPLE [ 165]\\nSHAP [133]\\nNAMs [3]\\nEEM [32]Any\\nAny\\nTabular\\nAny\\nTabular\\nTabularTheexplainer assignsan\\nimportancescoretoeachfeature\\nfor aprediction. Ahigher\\nimportance scoreindicates that\\nthefeature contributes\\npositivelytopredictions.\\nRule-based LORE [ 60]\\nANCHOR [ 171]\\nRuleMatrix[ 144]\\nGLObal toloCAL eXplainer [ 186]Tabular\\nAny\\nTabular\\nTabularRule-basedexplainer extracts\\nrules orcounterfactual rules for\\ntheend-user about the decision\\nprocess.\\nCounterfactual-\\nbasedCEM[37]\\nDiverse Counterfactual Explanations\\n[147]\\nC-CHVAE[ 161]\\nActionable REcourseSummaries [ 115]\\nFeasible and Actionable Counterfactual\\nExplanations [ 166]Tabular\\nTabular\\nTabular\\nTabular\\nTabularCounterfactual-basedexplainers\\nmodifytheinput features to\\nproduce an altered prediction.It\\nidentifies thefeatures’\\ndependency thatledtoaspecific\\ndecision.\\nPrototype-\\nbasedPrototypeSelection [ 19]\\nMMD-critic [ 96]\\nPROTODASH [ 65]\\nTreeSpace Prototype[ 204]Tabular\\nText\\nText\\nTabularPrototype-basedexplainers\\nidentifysimilar dataor\\nexamples belonging tothe\\ntarget', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1278: ('[147]\\nC-CHVAE[ 161]\\nActionable REcourseSummaries [ 115]\\nFeasible and Actionable Counterfactual\\nExplanations [ 166]Tabular\\nTabular\\nTabular\\nTabular\\nTabularCounterfactual-basedexplainers\\nmodifytheinput features to\\nproduce an altered prediction.It\\nidentifies thefeatures’\\ndependency thatledtoaspecific\\ndecision.\\nPrototype-\\nbasedPrototypeSelection [ 19]\\nMMD-critic [ 96]\\nPROTODASH [ 65]\\nTreeSpace Prototype[ 204]Tabular\\nText\\nText\\nTabularPrototype-basedexplainers\\nidentifysimilar dataor\\nexamples belonging tothe\\ntargetedclass for aprediction.\\n(LORE)[60] uses a genetic algorithm for generating a synthetic neighborhood of the data point\\nbeing explained. An explanation utilizing the neighborhood includes a decision rule and a set of\\ncounterfactual rules. The counterfactual rules illustrate the conditions that can be changed on in-\\nput data to alter the prediction and enable the user to characterize the instance and its neighbor.\\nANCHOR[ 171],discussedinSection 3.1.2,providesrulesasexplanationsusingif-thenrulessuch\\nthat if some features represent precision conditions or rules for a prediction, then any modifica-\\ntions to other features should not influence model prediction. Another rule-based tabular expla-\\nnation method named RuleMatrix [ 144], a matrix-based rule visualizer to verify the rules. The\\ntechnique extracts and filters a list of rules based on confidence and support thresholds that ap-\\nproximate a trained classifier. Then, a visual interface allows users to analyze and navigate the\\nrulesbecausethemodelmaycontaintoomanyrules.Then,avisualinterfacehelpsusersanalyze\\nand navigate the rules since the rule-based method may contain too many rules or a complex\\nrules composition. Furthermore, GLObal to loCAL eXplainer [ 186] develops global explanation\\nby hierarchicallyaggregating localexplanations fromlocaldecisionrules.\\nCounterfactual-basedexplanations make a small changeto the inputdata toimpact a classifier\\nprediction positively from the user’s perspective. For example, Diverse Counterfactual Explana-\\ntions[147]returnsaset', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1279: ('manyrules.Then,avisualinterfacehelpsusersanalyze\\nand navigate the rules since the rule-based method may contain too many rules or a complex\\nrules composition. Furthermore, GLObal to loCAL eXplainer [ 186] develops global explanation\\nby hierarchicallyaggregating localexplanations fromlocaldecisionrules.\\nCounterfactual-basedexplanations make a small changeto the inputdata toimpact a classifier\\nprediction positively from the user’s perspective. For example, Diverse Counterfactual Explana-\\ntions[147]returnsasetofdiversecounterfactualsbysolvinganoptimizationproblemtoprovide\\nfeasibility and diversity. The feasibility ensures that the counterfactuals follow user constraints\\nand contexts, while diversity in generated counterfactuals provides various ways of altering the\\noutcome class by adding a regularization term in the loss function to penalize similar counter-\\nfactuals. Moreover, CEM [ 37], described in Section 5, uses PP and PN to generate contrastive ex-\\nplanations.Anothermodel-agnostictabulardataexplainernamed CounterfactualConditional\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:24 Md I.Hossain etal.\\nTable 5. AList of XAITechniques That Can BeEmployed toExplain Medical Text Data\\nCategory XAI method andreference Data\\nTypeRemarks\\nSentenceHigh-\\nlightingLRP[10]\\nSHAP [133]\\nDeepLIFT [ 190]\\nIG [202]\\nL2X [29]\\nXRAI [90]\\nLocal Interpretation Of Neural nETworkS\\nthrough penultimate layer decoding [ 29]\\nLIME[170]Any\\nAny\\nAny\\nAny\\nAny\\nAny\\nAny\\nAnyPost hocexplanation methods\\nassign animportance scoreto\\nevery wordor group of words\\nand highlight thewords in the\\nsentence for aprediction. The\\nimage-based attribution\\napproach needs aslight\\nmodification tosuit the\\ntext-based scenario.\\nAttention-\\nbasedVaswaniet al.[ 216]\\nLi et al.[116]\\nexBERT [ 72]Text\\nText\\nTextAttention mechanisms highlight\\nthe salient words,and attention\\nweight ranks tokens ina\\nsentence.\\nOthers DoctorXAI [ 155]\\nANCHOR [ 171]\\nXSPELLS[ 108]\\nLASTS [62]\\nLORE [61]\\nCAT[26]\\nPOLYJUICE[ 231]\\nQUINT [1]\\nRajani et al.[ 168]Any\\nAny\\nText\\nText\\nAny', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1280: ('ce scoreto\\nevery wordor group of words\\nand highlight thewords in the\\nsentence for aprediction. The\\nimage-based attribution\\napproach needs aslight\\nmodification tosuit the\\ntext-based scenario.\\nAttention-\\nbasedVaswaniet al.[ 216]\\nLi et al.[116]\\nexBERT [ 72]Text\\nText\\nTextAttention mechanisms highlight\\nthe salient words,and attention\\nweight ranks tokens ina\\nsentence.\\nOthers DoctorXAI [ 155]\\nANCHOR [ 171]\\nXSPELLS[ 108]\\nLASTS [62]\\nLORE [61]\\nCAT[26]\\nPOLYJUICE[ 231]\\nQUINT [1]\\nRajani et al.[ 168]Any\\nAny\\nText\\nText\\nAny\\nText\\nText\\nText\\nTextTextual explanations methods\\nthat may not fit in sentence\\nhighlighting orattention-based.\\nDoctorXAI, LORE,and\\nANCHOR are rule-based\\nexplanations, while XSPELLS\\nand LASTSfindexemplars and\\ncounter-exemplars.\\nHeterogeneousAutoencoder(C-CHVAE) [161]utilizesanautoencoderonheterogeneousdata\\nfor counterfactuals generation. A distance function in the real input space is not required for C-\\nCHVAEtogeneratecounterfactualssincemeasuringmeaningfuldistanceintabulardataisdifficult.\\nFeasibleandActionableCounterfactualExplanations[ 166]returnsactionablecounterfactualsthat\\nare coherent with the underlying data distribution and connected via feasible paths. These paths\\nare the shortest path determined via density-weighted metrics. Moreover, Actionable REcourse\\nSummaries[ 115]providesglobal counterfactualexplanationsfora wholereferencepopulation.\\nThe prototype-based method identifies a small subset of samples that can view as a condensed\\nrepresentationofwholedata.Forinstance,MMD-critic[ 96],describedinSection3.7,producespro-\\ntotypesandcriticismstoincreasetheexplanationsforcomplexdatadistributionusingMaximum\\nMeanDiscrepancy.Thedatapointsthatareclosertothedatadistributionareknownasprototypes,\\nand those that are further away are known as criticisms. Prototypes define the dataset’s overall\\nbehavior, while criticisms are recordings that the prototypes fail to explain adequately. A varia-\\ntion of MMD-critic is PROTODASH [ 65], which represents the significance of each prototype by\\nreturningnon-negativeweights.Protot', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1281: ('n3.7,producespro-\\ntotypesandcriticismstoincreasetheexplanationsforcomplexdatadistributionusingMaximum\\nMeanDiscrepancy.Thedatapointsthatareclosertothedatadistributionareknownasprototypes,\\nand those that are further away are known as criticisms. Prototypes define the dataset’s overall\\nbehavior, while criticisms are recordings that the prototypes fail to explain adequately. A varia-\\ntion of MMD-critic is PROTODASH [ 65], which represents the significance of each prototype by\\nreturningnon-negativeweights.PrototypeSelection[ 19]solvesasetcoveroptimizationproblem\\nand summarizes the dataset using selecting prototypical instances from the dataset. Afterward, a\\nnearest-neighborruleisappliedtothegroupofprototypessothatthemethodcanbeutilizedasa\\nclassifier. Moreover, Tree Space Prototype [ 204] selects prototypes adaptively from the dataset to\\nexplaintreeensemble methods.\\n4.2 Textual Data Explanation\\nCombiningimageandtextualXAItechniquescanprovideacomprehensivewayofexplainingthe\\nblack-box model compared to the image explanation alone. The textual XAI can take the form\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:25\\nof report generation and report generation with a visual explanation for an input image. Most\\ntextualexplanationsemploy(i)sentencehighlightingthatassignseachwordortokenapredicted\\nimportance score and highlights that word or token in the sentences and (ii) CNN for feature\\nextraction,and RNNforgeneratingtheword sentences.\\nSomeattribution-basedmethodscanbemodifiedtoobtainsentencehighlightingfortextexpla-\\nnation. LIME[ 170]canbeadoptedforhighlightingimportantwordsinasentence.Limegenerates\\na neighborhood of sentences from an input sentence by randomly replacing one or more words\\nwith blank spaces. Then, a linear model is trained using the perturbed texts that can mimic the\\noriginalblackboxmodel,i.e.,bothmodelsshouldpredicttheidenticalclasslabels.Thecoefficients\\nfrom thelinear modelindicatethesignificanceof eachword.\\nIntegratedGradient(IG) [202],discussed', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1282: ('scanbemodifiedtoobtainsentencehighlightingfortextexpla-\\nnation. LIME[ 170]canbeadoptedforhighlightingimportantwordsinasentence.Limegenerates\\na neighborhood of sentences from an input sentence by randomly replacing one or more words\\nwith blank spaces. Then, a linear model is trained using the perturbed texts that can mimic the\\noriginalblackboxmodel,i.e.,bothmodelsshouldpredicttheidenticalclasslabels.Thecoefficients\\nfrom thelinear modelindicatethesignificanceof eachword.\\nIntegratedGradient(IG) [202],discussedinSection 3.1,requiresabaselineimagetogenerate\\nexplanation, while for text-based networks, the baseline could be a zero embedding vector. The\\nbaseline calculates the saliency value of a specific word by evaluating the word’s contribution to\\nthemodeloutputintheabsenceofany inputinformation.\\nDeep Learning Important FeaTures (DeepLIFT) [190], described in Section 3.1,can also be\\nappliedforsentencehighlighting,employingthesameprincipleofINTGRAD.L2X[ 29]L2Xcanbe\\nadaptedtogeneratesentencehighlightingexplanationsfortextdata.Inthecaseoftext,thepatches\\nare the group of words or phrases. L2X assigns importance scores to each phrase rather than\\nindividual words for generating explanations. Local Interpretation Of Neural nETworkS through\\npenultimatelayerdecoding [ 146]constructsalocalneighborhoodofinputtextsatthepenultimate\\nlayer and records the decision of the network for the neighborhood and provides an explanation\\nusingalinearmodellikeLIME.Furthermore,LRP[ 10],XRAI[90],andSHAP[ 133]canbeusedto\\nexplain theblack-boxmodelfortextualdata.\\nThe attention-based method was introduced by Xu et al. [ 233] to demonstrate which parts\\nof the images are most important in realizing the caption. The attention mechanism directs the\\nmodel to learn attention weight, which aids in understanding the context of all the information\\ninasentence.Lietal.[ 116]employedanattention-basedmethodtogenerateavisualexplanation\\nanderroranalysisbyidentifyingtheimpactoferasingwords.Theweightsoftheattentionlayers\\nof RNN provide the importance score for every ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1283: ('lfortextualdata.\\nThe attention-based method was introduced by Xu et al. [ 233] to demonstrate which parts\\nof the images are most important in realizing the caption. The attention mechanism directs the\\nmodel to learn attention weight, which aids in understanding the context of all the information\\ninasentence.Lietal.[ 116]employedanattention-basedmethodtogenerateavisualexplanation\\nanderroranalysisbyidentifyingtheimpactoferasingwords.Theweightsoftheattentionlayers\\nof RNN provide the importance score for every word in a sentence. A higher score indicates red-\\nder highlighting, and the model is more sensitive to the deletion of a specific word. Furthermore,\\nexBERT [ 72] delivers users to explore the model’s reasoning process by providing insights about\\ntheattentionweightsand internalrepresentation.\\nFurther, we provide additional explainers that might not fall under sentence highlighting or\\nattention-based. For example, ANCHOR [ 171] can be used to provide text explanations at the\\nsentence level by identifying the important word related to a model’s decision. In the case of\\ntext, a sentence is perturbed by modifying or removing certain words to make an interpretable\\nrepresentation that includes specific tokens (words). Next, the anchor or high-precision rule is\\nestablishedsuchthatspecificwordsfromtheperturbedsentencehelptopredictaparticularclass\\nwith high confidence. An example of such words could be in the case of ‘This book is not bad.’\\nwheremode predicts‘positive’is ‘not’and ‘bad.’\\nXSPELLS [ 108] is a model-agnostic local method consisting of exemplar and counter-exemplar\\nsentencesasexplanations.Themethodgeneratesmeaningfulsynthetictextsfromthelatentspace\\nusing VAE and creates neighbors of the text to explain. The randomly generated neighbors are\\nusedtolearnadecisiontreethathelpstocharacterizeexemplarandcounter-exemplartexts.LORE\\n[60] utilizes a local interpretable predictor to explain a specific instance in the form of rules and\\ncounterfactualrules.Givenaninstance xandblack-box bwhereb(x)=y,LOREappliesagenetic\\nalgo', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1284: ('ic local method consisting of exemplar and counter-exemplar\\nsentencesasexplanations.Themethodgeneratesmeaningfulsynthetictextsfromthelatentspace\\nusing VAE and creates neighbors of the text to explain. The randomly generated neighbors are\\nusedtolearnadecisiontreethathelpstocharacterizeexemplarandcounter-exemplartexts.LORE\\n[60] utilizes a local interpretable predictor to explain a specific instance in the form of rules and\\ncounterfactualrules.Givenaninstance xandblack-box bwhereb(x)=y,LOREappliesagenetic\\nalgorithm to produce a balanced set of synthetic neighbors Zof that instance such that for some\\ninstances, b(z)=b(x), while for other cases, b(z)/nequalb(x). Then, the method constructs a decision\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:26 Md I.Hossain etal.\\ntree using the balanced set Zand derives the decision rule explaining the cause for the decision\\nandasetofcounterfactualrulesidentifyingconditionsleadingtoanalteredoutcome.Additionally,\\nPOLYJUICE[ 231]isamodel-agnosticthatproducestextualcounterfactualsforthepurposeofthe\\nexplanation.Othermethods,suchasLASTS[ 62],DoctorXAI[ 155],QUINT[ 1],andCAT[ 26]can\\nbeadoptedtoexplain thetextualdata.\\n4.3 ExplanationforOther Data Types\\nLASTS [62] is a modification of ABELE for time-series classification. The explanation by LASTS\\nconsistsof(i)ashapelet-basedruleandshapelet-basedcounterfactualrulesand(ii)asetwithexem-\\nplarsandcounter-exemplar.LikeABELE,LASTSalsoutilizegeneratedneighborhoodinthelatent\\nfeature space using the autoencoder to learn a latent decision tree that provides a local decision\\nruleandcounter-factualrules.Suchrulesidentifyexemplarsandcounter-exemplarsandtheasso-\\nciatedreconstructedtimeseriesisusedforlearningshapelets.Finally,toextractashapelet-based\\nrule and counterfactual rules, a shapelet-based tree is learned from the reconstructed exemplars\\nandcounter-exemplars.\\nPanigutti et al. [ 155] introduced DoctorXAI as a model-agnostic and local explainer based on\\nsequential,multi-labeled,andontology-linkeddatatopredictpati', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1285: (' to learn a latent decision tree that provides a local decision\\nruleandcounter-factualrules.Suchrulesidentifyexemplarsandcounter-exemplarsandtheasso-\\nciatedreconstructedtimeseriesisusedforlearningshapelets.Finally,toextractashapelet-based\\nrule and counterfactual rules, a shapelet-based tree is learned from the reconstructed exemplars\\nandcounter-exemplars.\\nPanigutti et al. [ 155] introduced DoctorXAI as a model-agnostic and local explainer based on\\nsequential,multi-labeled,andontology-linkeddatatopredictpatients’nextvisittime.DoctorXAI\\nperturbs the sequential data to create a local synthetic neighborhood of a patient by using the\\nsemantic data encoded in the ontology and uses a black-box algorithm for labeling. The health-\\nrecord data of such semantic patients is then transformed into a format suited for decision tree\\ntraining.DoctorXAI usessucha traineddecisiontreeto extracta rule-basedexplanation.\\n4.4 XAI Applicationsin Non-image Medical Data\\nInthissection,wepresenttheapplicationoftheexplainablealgorithminnon-imagemedicaldata\\n(Table6).Forexample,inReference[ 249],TRACERwasintroducedforinterpretableriskprediction\\nof acute kidney injury. TRACER relies on an RNN-based model that learns both time-variant and\\ninvariantfeatureimportanceforeachpatientusingafeaturewisetransformationmechanismand\\naself-attentionmechanism,respectively.InReference[ 107],theauthorsusedanattentionmecha-\\nnismandvisualization-basedexplanationforheartfailurediseasediagnosisfrom electronicmed-\\nical records (EMRs) data. In Reference [ 199], Time-aware and Co-occurrence-aware Network\\nwas proposed based on a self-attention mechanism and time-aware gated recurrent unit, which\\ninterpretsthepredictionandadiagnosisgraphforthepatient.InReference[ 154],aninterpretable\\nCOVID-19diagnosisframeworkwasdevelopedfromcoughsoundsandsymptomsmetadata.The\\nframeworkintegratestheattentionmechanismandshowsthatthemostrecurrentsymptomsforin-\\nfectedpatientsarefever,dizziness,cough,andchestpain.Atthesametime,the t-distributedSto-\\nchasticNeighborEmbedding(t-SNE) [213]findsth', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1286: ('-aware and Co-occurrence-aware Network\\nwas proposed based on a self-attention mechanism and time-aware gated recurrent unit, which\\ninterpretsthepredictionandadiagnosisgraphforthepatient.InReference[ 154],aninterpretable\\nCOVID-19diagnosisframeworkwasdevelopedfromcoughsoundsandsymptomsmetadata.The\\nframeworkintegratestheattentionmechanismandshowsthatthemostrecurrentsymptomsforin-\\nfectedpatientsarefever,dizziness,cough,andchestpain.Atthesametime,the t-distributedSto-\\nchasticNeighborEmbedding(t-SNE) [213]findsthemostdiscriminatingcoughsoundfeatures\\nforeachclass.InReference[ 188],anRNN-basedsurvivalmodelnamedDeepAISEwasdeveloped\\nfor periodical sepsis prediction. Feature important scores were computed as model explanations\\ntofindthetopcontributingfactorstoindividualsepsisriskw.r.t.inputfeatures,similartosaliency\\nmaps for CNN. Another attention-based explanation [ 148] was used to detect atrial fibrillation\\n(AF)using a single-lead ECG signal. The system learns clinically meaningful components for the\\ndetectiontaskfrominputsignals,suchaswaves andheartbeats.\\nA SHAP-based explanation for eye state detection was used in Reference [ 203] using an elec-\\ntroencephalogram (EEG) . The results of a gradient-boosted tree model and a DNN model were\\ncompared to evaluate the interpretability of each model. Shapley values indicate that both mod-\\nels shared the same top three important features with a slight variation. Moreover, in Reference\\n[38], the paper used Mel-Frequency Cepstral Coefficient (MFCC) features from PCG signals\\nfor heart anomaly detection. The framework utilizes a pre-trained LSTM model to segment the\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:27\\nTable6. A Listof XAI Applications inNon-image MedicalData\\nXAI Method Data Type Paper Remarks\\nAttention-based EMRs [ 107] Heart failurediagnosis usingthe RNNmodel.\\nAttention-based Longitudinal EMR [ 249] Acute kidney injuryriskprediction.\\nAttention-based Electrocardiogram(ECG)signals [ 148]A F d e t e c t i o n', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1287: ('eart anomaly detection. The framework utilizes a pre-trained LSTM model to segment the\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:27\\nTable6. A Listof XAI Applications inNon-image MedicalData\\nXAI Method Data Type Paper Remarks\\nAttention-based EMRs [ 107] Heart failurediagnosis usingthe RNNmodel.\\nAttention-based Longitudinal EMR [ 249] Acute kidney injuryriskprediction.\\nAttention-based Electrocardiogram(ECG)signals [ 148]A F d e t e c t i o n .\\nSHAP EEG [ 203] Eye statedetection usingEEG signal.\\nSHAP Electronic Health Record(EHR) [ 28] Forecasting adversesurgicalevents.\\nSHAP Phonocardiogram (PCG) signals [ 38] Heart anomaly detection usingMFCC\\nfeatures.\\nSHAP Electronic Health Record(EHR) [ 150] Riskof mortalitypredictionusingGRU.\\nSHAP Genomic data [ 228] Interpretable cancer classification.\\nAttention Coughsounds,andsymptoms [ 154] COVID-19diagnosis fromsoundsand\\nmetadata.\\nSaliency Map Electronic Health Record(EHR) [ 188] Periodical sepsisprediction.\\nGradCAM Electromyography (EMG) [ 63] Neuro-robotic systems.\\nAttention-based Electronic Health Record(EHR) [ 199] Mortalityprediction, diseaseprediction,\\nreadmission prediction, anddiagnosis\\nprediction.\\nLIME Electrocardiogram(ECG)signals [ 81]A F d e t e c t i o n .\\nLRP 3D motiondata [ 48] Freeze of Gait movement detection.\\ninput MFCC and a CNN learns spatial features. Additionally, both SHAP and occlusion maps ex-\\nplain the hidden representations of the model and reveal that a correct PCG signal classification\\noccurswhenthemodelfocusesonthefeaturesbetweenfundamentalheartsoundregions(S1and\\nS2 segments).\\nLIME has been used to explain the time series for AF detection from single-lead ECG signal\\n[81]. The framework highlights the most relevant segments of the signal that matched with the\\ncardiologists’ identified features for AF detection, e.g., the absence of P-wave, electrical activity,\\nand variability of R-R intervals. Further, Reference [ 48], in LRP, was used to explain the DNN de-\\ncisions for detectin', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1288: ('ification\\noccurswhenthemodelfocusesonthefeaturesbetweenfundamentalheartsoundregions(S1and\\nS2 segments).\\nLIME has been used to explain the time series for AF detection from single-lead ECG signal\\n[81]. The framework highlights the most relevant segments of the signal that matched with the\\ncardiologists’ identified features for AF detection, e.g., the absence of P-wave, electrical activity,\\nand variability of R-R intervals. Further, Reference [ 48], in LRP, was used to explain the DNN de-\\ncisions for detecting movement that anticipates freezing of gait (FOG) in Parkinson’s disease.\\nLRPvisualizestheunderlyingcharacteristicsthatCNNconsiderscrucialformodelingthepathol-\\nogy. Moreover,the method found that the most relevant features that characterizethe movement\\npreceding FOG are fixed knee extension during the stance period, fixed ankle dorsiflexion, and\\nreducedpeakkneeflexion duringthewingphase.\\n5 MULTIMODAL XAI APPLICATION IN MEDICALDATA\\nHealthcareapplicationsinherentlyrequireamultimodalapproachduetotheinterconnectionand\\ndiversity of data sources involved. The multi-modal system combines various imaging modalities\\nsuch as CT, MRI, and PET or blending of varied data types such as images, 1D signals, clinical\\nrecords,anddemographicmetadataratherthanfocusingonasingledatatype.Differentunimodal\\nXAI techniques can be extended to the multimodal explanation approach and can be applied in\\nmedical fields (Table 7). For example, DIME [ 135] extends the core idea of LIME to explain a mul-\\ntimodal model. The method determines the dominant factor of a multimodal prediction by disen-\\ntangling the model into unimodal contributions and multimodal interactions. More specifically,\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:28 Md I.Hossain etal.\\nDIME determines the importance of each modality from the linear model weights similar to the\\nLIMEtechniqueandutilizes theweightstogenerateinterpretablevisualization.\\nInthisstudy,wefocusonthesignificanceofmultimodalXAIinhealthcareapplicationssuchas\\nreport ge', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1289: ('he dominant factor of a multimodal prediction by disen-\\ntangling the model into unimodal contributions and multimodal interactions. More specifically,\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:28 Md I.Hossain etal.\\nDIME determines the importance of each modality from the linear model weights similar to the\\nLIMEtechniqueandutilizes theweightstogenerateinterpretablevisualization.\\nInthisstudy,wefocusonthesignificanceofmultimodalXAIinhealthcareapplicationssuchas\\nreport generation from images, medical image captioning with visual explanations, patient meta-\\ndata or tabular data, or a combination of imaging data (e.g., X-rays, MRIs, and CT scans) with\\nhealth records. Image captioning can be viewed as creating a textual description for interpret-\\ning the model decision, commonly used in Natural Language Processing tasks. Sun et al. [ 201]\\nemployed the joint model (CNN-RNN) to generate medical imaging reports from mammography\\ndata where the CNN produces a global feature of the image, and RNN decodes the text matching.\\nLikewise, Singh et al. [ 194] developed an encoder–decoder framework using CNN as an encoder\\nandastackedLSTMasadecodertogenerateradiologyreportsautomaticallyfromchestX-raysim-\\nages.Zhangetal.[ 247]proposedamultimodalapproachcomposedofalanguagemodelandimage\\nembedding model, MDNET, that takes pathology bladder cancer images as input, produces diag-\\nnosticreports,retrievesimagesbasedonsymptomdescriptions,andgeneratesnetworkattention.\\nAn auxiliary attention sharpening module improves the attention maps to highlight carcinoma-\\ninformative regions. Jing et al. [ 86] proposed a framework for multi-task learning that includes\\na co-attention mechanism for generating text according to the regions of radiology and pathol-\\nogyimagescontainingabnormalities.Moreover,theauthorsdevelopahierarchicalLSTMnetwork\\nthatcaptureslong-rangesemanticseffectivelyandgenerateshigh-qualitylongreports.Wangetal.\\n[225]proposedText-ImageEmbeddingnetworkforextractingthemostdistinctivepartsfromchest\\nX-ra', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1290: ('odule improves the attention maps to highlight carcinoma-\\ninformative regions. Jing et al. [ 86] proposed a framework for multi-task learning that includes\\na co-attention mechanism for generating text according to the regions of radiology and pathol-\\nogyimagescontainingabnormalities.Moreover,theauthorsdevelopahierarchicalLSTMnetwork\\nthatcaptureslong-rangesemanticseffectivelyandgenerateshigh-qualitylongreports.Wangetal.\\n[225]proposedText-ImageEmbeddingnetworkforextractingthemostdistinctivepartsfromchest\\nX-ray images and text representations.The authors showed how various parts of the radiological\\nfindings correspond to multiple saliency maps in the image. Similarly, Barata et al. [ 13]p r o p o s e d\\nanexplainablehierarchicalmodelusingattentionmodulesthatmimichierarchicaldecisionsmade\\nbyadermatologist.Thechannelandspatialattentioncanidentifyrelevantfeaturesandregionsin\\nthedermoscopyimagestoimprovetheexplainability.Leeetal.[ 109]providedtextualexplanation\\nandvisualjustificationtoexplainthediagnosticdecisionofabreastmassesclassifierbasedonthe\\nCNN-RNNmodel.Similarly,Galeetal.[ 49]proposedamodelagnosticmethodbasedontheLSTM\\nmodel to generate descriptive sentences to explain the decision of a CNN classifier. Furthermore,\\na visual attention mechanism highlights the relevant region for detecting hip fractures in pelvic\\nX-rays. In Reference [ 238], the authors presented an attention-based framework for detecting ab-\\nnormalitiesandgeneratingmedicalreportsautomaticallyfromchestX-rayimages.Ahierarchical\\nRNNmodelconsistsofasentenceRNN,whichproducestopicvectors,andawordRNNgenerates\\nanappropriatesentenceusingthetopicvectors.Moreover,amatchingmechanismmapsthetopic\\nvectors and sentences into the same semantic space to create more accurate reports. Similarly,\\nLiuetal.[ 125]presentedahierarchicalgenerationstrategyusingCNN-RNN-RNNarchitectureto\\nproducetopicsfromradiologicalimagesandthengeneratewordsfromtopics.Themethodusesa\\nfine-tuningtechniqueemployingreinforcementlearningtoproduceamorecoherentreport.Chen\\netal.[31]proposedamemory-dr', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1291: ('entenceRNN,whichproducestopicvectors,andawordRNNgenerates\\nanappropriatesentenceusingthetopicvectors.Moreover,amatchingmechanismmapsthetopic\\nvectors and sentences into the same semantic space to create more accurate reports. Similarly,\\nLiuetal.[ 125]presentedahierarchicalgenerationstrategyusingCNN-RNN-RNNarchitectureto\\nproducetopicsfromradiologicalimagesandthengeneratewordsfromtopics.Themethodusesa\\nfine-tuningtechniqueemployingreinforcementlearningtoproduceamorecoherentreport.Chen\\netal.[31]proposedamemory-driventransformermodeltogenerateradiologyreportsfromchest\\nX-ray images.\\nFurthermore, Das et al. [ 35] proposed visual dialog, where a human interacts with a machine\\naboutanimage’svisualcontent.Specifically,whenprovidedwithanimage,aconversationhistory,\\nand a question, the AI agent infers a context and provides a correct response to the inquiry. In\\n[105],thevisualdialogwasimplementedinthepublicradiologydataset,RadVisDial.Theauthors\\ndescribedhowAIagentscouldbepracticallyusefulandclinicallybeneficialtochestX-rayimages.\\nAdditionally,inReference[ 235],theauthorsimplementedattribution-basedXAIforimageclas-\\nsificationforCOVID-19patientsandsegmentationforhydrocephaluspatientsusingCTandMRI\\ndatasets via multi-modal and multi-center data fusion. For explaining classification, a modified\\nCAM highlights the salient pixels and locates the infected area in CT images. Kernel SHAP (as\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:29\\nTable 7. A Brief Summaryof XAIApplications inMultimodalSetting forMedical Data\\nXAIMethods used/based\\nonModality Paper Remarks\\nSHAP + grad-CAM Skin + Metadata [ 222] Skinlesion diagnosis based on patient metadata.\\nReportgeneration\\n(CNN-RNN)X-ray + Text [ 201] Medical reportsfrom mammography data.\\nReportgeneration\\n(CNN-RNN)X-ray + Text [ 194] Generation of radiology reportsautomatically\\nfromchest X-rayimages.\\nVisualDialog (CNN-RNN) X-ray+ Text [ 105] Generation of visual dialog in radiology.\\nConcept Activation\\nVectorsDermatology +\\nText[131]', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1292: ('plications inMultimodalSetting forMedical Data\\nXAIMethods used/based\\nonModality Paper Remarks\\nSHAP + grad-CAM Skin + Metadata [ 222] Skinlesion diagnosis based on patient metadata.\\nReportgeneration\\n(CNN-RNN)X-ray + Text [ 201] Medical reportsfrom mammography data.\\nReportgeneration\\n(CNN-RNN)X-ray + Text [ 194] Generation of radiology reportsautomatically\\nfromchest X-rayimages.\\nVisualDialog (CNN-RNN) X-ray+ Text [ 105] Generation of visual dialog in radiology.\\nConcept Activation\\nVectorsDermatology +\\nText[131] Visual andtextual XAIfor melanoma\\nclassification.\\nKernel SHAP + CAM+\\nt-SNECT+MRI [ 235] COVID-19detection andsegmentation.\\nDiagnosticreport\\ngeneration (CNN-RNN)Pathology + Text [ 247] Report generation, image retrieval,andvisual\\nattention toprovide justifications.\\nGeneration of medical\\nreports(CNN-RNN)X-ray + Text [ 86] Generating text from image regions containing\\nabnormalities and generatinglong reports.\\nMulti-levelattention\\n(CNN-RNN)X-ray + Text [ 225] Report generation, highlightingtheimportant\\nwords andimage regions.\\nSHAP Histology +\\nGenomic data[13] Morphologic andmolecular correlationof\\nprognosisfor 14cancer types.\\nAttention-based X-ray+ Tabular [ 30] COVID-19classification.\\nVisualand textual\\njustification (CNN-RNN)X-ray + Text [ 109] Explanation of thediagnosticdecision for a\\nbreast massesclassifier.\\nRadiologyreport\\ngenerationX-ray + Text [ 49] Descriptive sentence generation and an\\nattention mechanism for detectinghip fractures.\\nGeneration of medical\\nreports(CNN-RNN)X-ray + Text [ 238] Abnormalities detection and medical reports\\ngeneration fromchest X-rayimages.\\nReportgeneration\\n(CNN-RNN-RNN)X-ray + Text [ 125] ChestX-rayreportgeneration using\\nreinforcement learning.\\nRadiologyreport\\ngenerationX-ray + Text [ 31] Radiology reportsbymemory-driven\\ntransformer.\\nImageCaptioning X-ray+ Text [ 174] X-raycaptioning and pathology localization.\\nLIME MRI + gene data [ 89] Alzheimer’s disease(AD) classification.\\nImageCaptioning Histology + Text [ 136] Report generation with visualinterpretation.\\ndescribed in Refer', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1293: (' detection and medical reports\\ngeneration fromchest X-rayimages.\\nReportgeneration\\n(CNN-RNN-RNN)X-ray + Text [ 125] ChestX-rayreportgeneration using\\nreinforcement learning.\\nRadiologyreport\\ngenerationX-ray + Text [ 31] Radiology reportsbymemory-driven\\ntransformer.\\nImageCaptioning X-ray+ Text [ 174] X-raycaptioning and pathology localization.\\nLIME MRI + gene data [ 89] Alzheimer’s disease(AD) classification.\\nImageCaptioning Histology + Text [ 136] Report generation with visualinterpretation.\\ndescribed in Reference [ 133]) assesses the contributions of each super-pixel. Specifically, super-\\npixelsassociatedwithlesionareasinfluencethepositiveprediction,whilethosecorrespondingto\\ndisease-freeareasswaythepredictionnegatively.Further,toexplainbrainventriclesegmentation,\\nUNET with ResNet was trained on multi-modal MRI data obtained from hydrocephalus patients.\\nThe PCA [ 229] method projects the encoder’s lowest bottom features into a 2D latent space for\\nfeature space visualization. t-SNE [ 213] visualizes the learned features and distribution of the tar-\\ngeted image, revealing the method’s weaknesses and strengths. In Reference [ 131], a framework\\ntermed ExAID was proposed for a multi-modal explanation consisting of visual maps and textual\\nexplanations for melanoma classification from dermoscopic images. ExAID utilized CAVs for der-\\nmatologicalconceptidentificationandtheTCAVmethodforestimatingtheimpactofaparticular\\nconcept on a model decision. The framework used Concept Localization Map (CLM) [132]t o\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:30 Md I.Hossain etal.\\nlocatethelearnedconceptinthetrainedclassifier’slatentspace.CLMusesperturbation-basedcon-\\ncept localization to highlight the region connected with learned concepts, thus generating visual\\nexplanations. Further, ExAID provides textual explanations from concept predictions and direc-\\ntional derivatives utilized in TCAV. Wang et al. [ 222] proposed IM-CNN for skin lesion diagnosis\\nbased on patient metadata and skin lesion image', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1294: ('s, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:30 Md I.Hossain etal.\\nlocatethelearnedconceptinthetrainedclassifier’slatentspace.CLMusesperturbation-basedcon-\\ncept localization to highlight the region connected with learned concepts, thus generating visual\\nexplanations. Further, ExAID provides textual explanations from concept predictions and direc-\\ntional derivatives utilized in TCAV. Wang et al. [ 222] proposed IM-CNN for skin lesion diagnosis\\nbased on patient metadata and skin lesion images. Metadata comprises the patient’s basic infor-\\nmation (location, age, sex) and extracted features (globule, pigment network, border irregularity,\\nand asymmetry ) from skin images. SHAP analyzes the features of the metadata and assigns an\\nimportance score to each feature, whereas grad-CAM generates an interpretable visual output of\\nskinlesionimages.\\n6 EVALUATION OF XAI METHODS\\nDuetotheabsenceofgroundtruthforexplanations,currentexplanationmethodsdonotfollowa\\nspecificsetofevaluationmetrics.Therefore,theresearchers’decisionforselectingtheevaluation\\nmethodsdependshighly on theapplication.We presentbelowsome of theevaluation techniques\\nthatare widely usedbytheresearchcommunity.\\nATaxonomyofEvaluation: AframeworkproposedinReference[ 40]consistsofthreeevalu-\\nationmethods:(i) applicationgrounded ,whichrequiresahumanexpertforaspecificapplication,\\ne.g.,doctorsperformingdiagnoses;(ii) humangrounded ,whichisapplicablewhenthetaskissim-\\npleanddoesnotrequireanexperthumanwhilestillrequiresalayhumantoevaluatethequalityof\\ninterpretations,e.g.,anormalhumanevaluatingthequalityofsaliencymaps;and(iii) functionally\\ngrounded, which requires no human—however, it requires proxy tasks for evaluation. Comparing\\nthe results of the explanation method with radiologists’ manual delineations of tumors could be\\nan example. This evaluation is suitable when the method is not mature yet or human subject in-\\nvolvement is unethical.\\nAttribution Map Evaluation: Some of the commonly used evaluation metrics for attribution\\nmethodsaregivenbelow:Pointing', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1295: ('rpretations,e.g.,anormalhumanevaluatingthequalityofsaliencymaps;and(iii) functionally\\ngrounded, which requires no human—however, it requires proxy tasks for evaluation. Comparing\\nthe results of the explanation method with radiologists’ manual delineations of tumors could be\\nan example. This evaluation is suitable when the method is not mature yet or human subject in-\\nvolvement is unethical.\\nAttribution Map Evaluation: Some of the commonly used evaluation metrics for attribution\\nmethodsaregivenbelow:PointingGameMetric[ 243]extractsamaximumpointfromthesaliency\\nmap. If the point lies on the bounding box of a specified class, then a hit is considered; other-\\nwise, a miss. Then, the accuracy is obtained from the number of miss and hit for each object as\\nAccuracy =#Hits\\n#Misses+#Hits. Deletion and insertion [ 179] are saliency map metrics where the for-\\nmer finds the degraded class probability score when important pixels are removed, and the latter\\nmeasuresincreasedclassprobabilitywhenpixelsareinserted.Hookeretal.[ 71]claimedthatper-\\nturbing the highest-scoring regions cause a distribution shift in the data; hence they introduced\\nRemOveAndRetrain,whichretrainsontheperturbedimagesandcheckswhetheraccuracydrops\\norincreases.Moreover,inReference[ 175],theRemoveandDebiasmetriceliminatestheneedfor\\nretrainingandreducescomputationalcostsusingthemutualinformationbetweenlow-important\\npixelsand theclass.\\nTheAttributionLocalisationMetric[ 103]iscalculatedastheratioofthesumofpositiveattribu-\\ntionsintheboundingboxtotheoverallattribution.Ghorbanietal.[ 53]usedT op- kIntersectionas\\nanevaluationmetric,whichcalculatestheintersectionsizeofthemostrelevantfeatureoftheorig-\\ninalandperturbedimage.Ahighscoreispreferableastheoverlapbetweenthetwomasksshould\\nbe high. Another similar metric is the conceptinfluence score [ 209], which provides insights into\\nwhich semantic visual concept influences prediction and measures the amount of pixelwise inter-\\nsectionbetweenanexplanation andsegmentation mapusingtop- kfeatures.\\nTwo other metrics are describe', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1296: ('ution.Ghorbanietal.[ 53]usedT op- kIntersectionas\\nanevaluationmetric,whichcalculatestheintersectionsizeofthemostrelevantfeatureoftheorig-\\ninalandperturbedimage.Ahighscoreispreferableastheoverlapbetweenthetwomasksshould\\nbe high. Another similar metric is the conceptinfluence score [ 209], which provides insights into\\nwhich semantic visual concept influences prediction and measures the amount of pixelwise inter-\\nsectionbetweenanexplanation andsegmentation mapusingtop- kfeatures.\\nTwo other metrics are described in Reference [ 7]: (i)Relevance Mass Accuracy is computed as\\nthe ratio of the sum of positive or relevance values within the bounding box over the sum of\\noverallpositiveattributionsoftheentireimage,and(ii) RelevanceRankAccuracy determineshow\\nmuch high-intensity relevance is included inside the ground-truth mask. Moreover, Area Under\\nthe Curve [ 47] is another common metric for visual explanations. In Reference [ 244],Area over\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:31\\nPerturbationCurve(AOPC) [179]evaluatesthesaliencymapproducedfromultrasoundimages\\nwhere a high AOPC value indicates the heatmap is, in fact, relevant. Given an input image x,\\nNis the total number of images, Kis perturbation steps, and f(x)specifies the certainty of an\\nobject’spresenceintheimage x,thenAOPCisthedifferencebetween f(x)scoreswithandwithout\\nperturbation.Mathematically,AOPC isdefinedas ( 10)\\nAOPC=1\\nNN/summationdisplay\\nn=0(f(xn)(0)−1\\nKK/summationdisplay\\nn=0f(xn)(k)). (10)\\nZhang et al. [ 244] adapted AOPC for the quantitative evaluation of attributions maps for inter-\\npretability of a CNN for fetal head circumference estimation. In the case of model parameter ran-\\ndomization, the metrics are Model Parameter Randomization [ 2] and Random Logit Metric [ 196].\\nFurthermore, robustness metrics such as Local Lipschitz Estimate [ 6] determine the consistency\\nof the explanation for similar instances. To evaluate the faithfulness of the methods, faithfulness\\ncorrelation[ 18],P', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1297: ('). (10)\\nZhang et al. [ 244] adapted AOPC for the quantitative evaluation of attributions maps for inter-\\npretability of a CNN for fetal head circumference estimation. In the case of model parameter ran-\\ndomization, the metrics are Model Parameter Randomization [ 2] and Random Logit Metric [ 196].\\nFurthermore, robustness metrics such as Local Lipschitz Estimate [ 6] determine the consistency\\nof the explanation for similar instances. To evaluate the faithfulness of the methods, faithfulness\\ncorrelation[ 18],Pixel-Flipping[ 10],and RegionPerturbation[ 179]c a nbeu sed .\\nEvaluationofHuman-AIInterfaceTool: Holzingeretal.[ 69]introducedthe SystemCaus-\\nabilityScale(SCS) tomeasurethequalityofexplanationinthecaseofhuman–AIinterfaces.The\\ntechniqueevaluates the user’sperceptionof an explanation processusing the usability combined\\nwith causability. SCS was applied to measure the characteristics and quality of the human–AI in-\\nterfacein coronaryarterydiseaseestimation.\\nEvaluation Metrics for Counterfactual Explanation: The metrics utilized in Reference\\n[195] for the counterfactual explanation are Counterfactual Validity (CV) [147],Frechet In-\\nceptionDistance(FID) ,andForeignObjectPreservation(FOP) .CVscoredetermineswhether\\ncounterfactual explanation is associated with classifier prediction, i.e., if the classifier predicts an\\nimageasnormal,thencounterfactualpredictionshouldbeasabnormalbytheclassifier.FIDquan-\\ntifies the visual quality of the explanations by calculating the feature distance between the input\\nand counterfactual image. FOP metric checks the retention of the individual patient information\\nintheexplanations.Looverenetal.[ 128]usedIM1andIM2metricstoevaluatetheinterpretability\\nwhere IM1 calculates the reconstruction errors ratio between counterfactual instances, and IM2\\ncomparessimilaritiesamong reconstructedcounterfactualinstances.\\nQuantitativeEvaluationofConceptLearningModel: Concept-basedmodelssuchasTCAV\\nmay produce meaningless concept activation vectors if the random concept is selected. To avoid\\nspurious result', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1298: ('al image. FOP metric checks the retention of the individual patient information\\nintheexplanations.Looverenetal.[ 128]usedIM1andIM2metricstoevaluatetheinterpretability\\nwhere IM1 calculates the reconstruction errors ratio between counterfactual instances, and IM2\\ncomparessimilaritiesamong reconstructedcounterfactualinstances.\\nQuantitativeEvaluationofConceptLearningModel: Concept-basedmodelssuchasTCAV\\nmay produce meaningless concept activation vectors if the random concept is selected. To avoid\\nspurious results, a statisticalsignificance test for a specific concept provides the stability of a par-\\nticular concept [ 97]. A two-sided t-test of the TCAV score can determine the resulting concepts\\nrelevant to a class prediction when the null hypothesis is rejected. Furthermore, human involve-\\nment in evaluatingtheconceptensuresthecorrectselectionof theconcept[ 55,237].\\nEvaluation of Tabular Data Explanation Methods: XAI metric selection is an open issue\\nthat depends on the specific application or goal of the evaluation. For example, in Reference [ 21],\\nthe authors used fidelity and stability for tabular data explanation methods. Fidelity [ 59]e v a l u -\\nates how well the methods can resemble or mimic the decision-making process of the black box\\nmodel.Stabilityevaluatestheconsistencyorcoherenceofexplanationswhendealingwithsimilar\\ninstances. Stability for an input x, and explanation model fe(x)can be calculated using Lipschitz\\nconstant[ 5]asLx=max||fe(x)−fe(x/prime)||\\n||x−x/prime||,∀x/prime∈Nx,wher eNxistheneighbourhoodof instance x.\\nFurthermore,distancemetricscanbeusedtocomputethequalityofexplanations.Euclideandis-\\ntanceorpairwisedistancecanquantifyhowmuchtheXAImethod-generatedexplanationdeviates\\nfrom the ground-truth explanation. Root Mean Squared Error and Area Under the Curve are two\\ncommonevaluationmetricsthatcanbeemployedbasedonthespecificcharacteristicsoftheprob-\\nlem [3,65]. Moreover, most quantitative evaluations measure the model performance variation\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1299: ('of instance x.\\nFurthermore,distancemetricscanbeusedtocomputethequalityofexplanations.Euclideandis-\\ntanceorpairwisedistancecanquantifyhowmuchtheXAImethod-generatedexplanationdeviates\\nfrom the ground-truth explanation. Root Mean Squared Error and Area Under the Curve are two\\ncommonevaluationmetricsthatcanbeemployedbasedonthespecificcharacteristicsoftheprob-\\nlem [3,65]. Moreover, most quantitative evaluations measure the model performance variation\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:32 Md I.Hossain etal.\\nby adding or removing the features through the input perturbation process [ 5]. A robust expla-\\nnation should be robust to the minor perturbation of input data. Attribution and non-attribution\\nevaluationmethodscanbe adaptedaccordingtoparticularapplicationsfor tabularexplanations.\\nEvaluation of Textual Explanation Methods: Commonly used metrics for textual evalua-\\ntions are Bilingual Evaluation Understudy (BLEU) [157],M e t r i cf o rE v a l u a t i o no fT r a n s -\\nlation with Explicit Ordering (METEOR) [12],Recall-Oriented Understudy for Gisting\\nEvaluation (ROUGE) [120], andConsensus-Based Image Description Evaluation (CIDEr)\\n[217].\\nBLEU is a standard metric for textual explanation evaluation in natural language processing\\ntasks, which calculates the similarity between the generated sentence and the ground-truth sen-\\ntence. The metric count n-grams (sequences of n words) overlap between the generated and the\\nreferencesentence.TheBLEUisoftencalculatedusingn-gramsuptosize N,wher eN=1,2,3,4,\\nand the scores are geometrically averaged. Formally, the BLEU score is determined using the fol-\\nlowingformula: BLEU=BP.exp(/summationtextN\\nn=1wnloдpn),wherethebrevitypenalty( BP)penalizesshorter\\ngenerated sentences than the reference sentence, wnis the weight and pnis the modified n-gram\\nprecision.TheBLEU scoreis between0 and 1;closerto 1means bettertranslationquality.\\nTheROUGEpackageconsistsofmetrics(ROUGE-N,ROUGE-L,ROUGE-W,andROUGE-S)for\\nautomaticallyevaluatinggeneratedsentencesco', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1300: ('size N,wher eN=1,2,3,4,\\nand the scores are geometrically averaged. Formally, the BLEU score is determined using the fol-\\nlowingformula: BLEU=BP.exp(/summationtextN\\nn=1wnloдpn),wherethebrevitypenalty( BP)penalizesshorter\\ngenerated sentences than the reference sentence, wnis the weight and pnis the modified n-gram\\nprecision.TheBLEU scoreis between0 and 1;closerto 1means bettertranslationquality.\\nTheROUGEpackageconsistsofmetrics(ROUGE-N,ROUGE-L,ROUGE-W,andROUGE-S)for\\nautomaticallyevaluatinggeneratedsentencescomparedtoreferencesentences.ROUGE-Liscom-\\nmonlyused,whichmeasuresthe LongestCommonSubsequence(LCS) betweenthegenerated\\nsentence and the reference sentences regarding recall Rand precision P. F1-based ROUGE-L can\\nbecalculatedbetweentwosentences xoflength mandyoflength nasROUGE−Lf1=2Plcs.Rlcs\\nPlcs+Rlcs,\\nwherePlcs=LCS(x,y)\\nmandRlcs=LCS(x,y)\\nn. The reference and generated sentences should match\\nexactly fortheROUGEscorestobe 1,whichrange from0 to1.\\nAnother commonly used metric is METEOR, which utilizes synonyms, stemming, and para-\\nphrasestoevaluatethequalityoftranslations.METEORscoreiscomputedasfollows:(i)anF-score\\niscomputedas Fmean=10PR\\n(R+9P),(ii)afragmentationpenalty Mtoensurethediversityinthetrans-\\nlationisgivenby M=0.5#chunks\\n#uniдram−matched,and(iii)finallythescore, METEOR =Fmean(1−M).\\nAdditionally,CIDErcomparesthesimilaritybetweenahuman-generatedground-truthsentence\\nandthegeneratedsentence.TheCIDEscoreforn-gramsutilizesaveragecosinesimilaritybetween\\nthe ground-truth sentence and the generated sentence in terms of both precision and recall. Fur-\\nthermore, another cosine similarity-based method named BERTSCORE [ 246] measures the simi-\\nlarityof thetwosentencesbasedon embeddings obtainedfrom pre-trainedBERT.\\n7 LIMITATIONS AND FUTURE DIRECTIONS\\nThis article reviews XAI methods with a specific focus on medical data. Although these methods\\nshowgoodtoexcellentresults,thequestioniswhetherthesemethodscanbeimplementedinthe\\nclinical setting. Our extensive review of XAI methods uncovers several challenges and considera-', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1301: ('erms of both precision and recall. Fur-\\nthermore, another cosine similarity-based method named BERTSCORE [ 246] measures the simi-\\nlarityof thetwosentencesbasedon embeddings obtainedfrom pre-trainedBERT.\\n7 LIMITATIONS AND FUTURE DIRECTIONS\\nThis article reviews XAI methods with a specific focus on medical data. Although these methods\\nshowgoodtoexcellentresults,thequestioniswhetherthesemethodscanbeimplementedinthe\\nclinical setting. Our extensive review of XAI methods uncovers several challenges and considera-\\ntions associated with these methods that warrant careful evaluation before their integration into\\nmedicaldataapplications.Wesummarizethesechallenges(Table 8)andproposeseveraldirections\\nforfutureresearch.\\nLimitedClinicalApplicationsofAttributionMap: Mostexistingsaliencymap-basedmeth-\\nods highlight the important pixels of an image. However, these methods failed in various evalua-\\ntion testing. For example, the saliency map’s effectiveness was assessed in the context of medical\\nimaging.Toachievethis,eighttechniqueswereutilized,specificallytrainedontheSIIM-ACRPneu-\\nmothorax Segmentation and RSNA Pneumonia Detection datasets. The evaluation was based on\\nfour key trustworthiness criteria: utility, sensitivity to weight randomization, repeatability, and\\nreproducibility. The techniques examined were Gradient Explanation, Smoothgrad, IG, Smooth\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:33\\nTable 8. AnOverview of theStrengths,Weaknesses, andRecommendations of Different Types of XAI\\nMethods\\nCategory Strength Weakness Recommendation\\nAttribution-\\nbasedPost hoc, andlocalexplanations;\\neasy tounderstand with visual\\ninterpretation;simple\\nimplementation;determines\\nspecific features’importance.Inconsistent heatmapgeneration;\\nrepeatabilityandreproducibility\\nissues; noinformation aboutthe\\ndecision-making process;\\nsensitivity to perturbations.A non-visual method maybe\\nappliedsimultaneously to\\nexaminethe congruencewith\\nthevisual XAI based onthe\\napplication’scontext.', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1302: ('tions of Different Types of XAI\\nMethods\\nCategory Strength Weakness Recommendation\\nAttribution-\\nbasedPost hoc, andlocalexplanations;\\neasy tounderstand with visual\\ninterpretation;simple\\nimplementation;determines\\nspecific features’importance.Inconsistent heatmapgeneration;\\nrepeatabilityandreproducibility\\nissues; noinformation aboutthe\\ndecision-making process;\\nsensitivity to perturbations.A non-visual method maybe\\nappliedsimultaneously to\\nexaminethe congruencewith\\nthevisual XAI based onthe\\napplication’scontext.\\nConcept-based High-level conceptsexplainthe\\nmodel’s decision; human\\ninvolvementensures the selected\\nconcepts areaccurate;provide\\nbetterinterpretableinsights,\\nbetteranalysisof themodel’s\\nbehavior.Conceptselection is subjective\\nandrelies on humans;additional\\nannotationcosts; conceptsmay\\nsuffer thecompletenessissue;\\nin-depth mathematical\\nknowledgeis required.Easy toimplementbut\\nrecommendedin a\\nhuman-in-the-loop system;\\ncomparison of different\\nmodels’ behavior usingthe\\nsameconcepts.\\nCounter-\\nfactual-basedProvides causalrelationships\\nbetweeninputfeaturesand\\nprediction; highlights image\\nregions where themodel isless\\nrobust; identifiesbiasand\\nvulnerability.Generatingcounterfactualsis\\ncomputationallyexpensive;\\nperturbation of imagescouldbe\\nunrealistic; good dataqualityis\\nrequired.Suitabletoemploywhen\\nminimumchanges of features\\nleadtoalteredclassification or\\nwhenidentifyingsalient\\nfeaturesis essential.\\nPrototype-\\nbasedEasy to understand; bothglobal\\nandlocalexplanation;abletofind\\nbadquality trainingdata;errors\\nand biasesidentification.Expensive anddifficultto train;\\nsusceptibleto noise or artifacts;\\nhuman involvementin validating\\nthe correct prototype.Explainingindividual test\\npoints; whentheend-users\\narenon-experts.\\nTabular-based Most importantfeatures\\nidentification;behavior analysis\\nof differentmodels; outlier\\nfeatures detection;biasdetection.TabularXAI mightnotaccurately\\nexplainhighly correlated\\nfeatures;struggle toidentifythe\\nmost contributingfactorfor\\nhigh-dimensional data.Applicableif tabulardataor\\nmetadataareava', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1303: ('sesidentification.Expensive anddifficultto train;\\nsusceptibleto noise or artifacts;\\nhuman involvementin validating\\nthe correct prototype.Explainingindividual test\\npoints; whentheend-users\\narenon-experts.\\nTabular-based Most importantfeatures\\nidentification;behavior analysis\\nof differentmodels; outlier\\nfeatures detection;biasdetection.TabularXAI mightnotaccurately\\nexplainhighly correlated\\nfeatures;struggle toidentifythe\\nmost contributingfactorfor\\nhigh-dimensional data.Applicableif tabulardataor\\nmetadataareavailable;\\nMultipleXAI methods should\\nbeappliedtocompare\\nexplanationresults for\\nrobustness.\\nTextual-based Easily understandableto\\nnon-experts; both globaland\\nlocal interpretations;enhancethe\\nmodel transparencythrough\\ninteractivefeedback.Generatingcoherent\\nexplanationscan bechallenging;\\nlimiteddatasets;require more\\nannotationcost, bias,or\\nexplanationvariations.Suitableif textannotationis\\navailable;recommendedif the\\nend-user is non-expert.\\nIG,GradCAM,XRAI,Guided-backdrop,andGuidedGradCAM.Interestingly,noneofthesemeth-\\nods satisfied all the criteria set forth. The benchmarks for this evaluation were the area under\\nthe precision–recall curve and the structural similarity index. However, a standout observation\\nwas that XRAI excelled in terms of localization, utility, repeatability, and reproducibility when\\ncrafting a saliency map for radiology data. Further, the attribution-based method failed against\\nthe robustness test in several experiments. The robustness of four visualization-based methods,\\nnamely guided backpropagation, gradient input, LRP, and Occlusion, was tested for Alzheimer’s\\ndiseaseclassification[ 43].RepeatedlytrainingaCNNwiththeidenticalsettingshowedthatthese\\nfour methods generated an inconsistent heatmap. Moreover, saliency maps are susceptible to ad-\\nversarial attacks [ 53], i.e., a small perturbation in the input image may generate a large variation\\nin the saliency map, though the output prediction remains the same. The bias term is also non-\\nnegligibletowardsmakingtheattributionmap,whichcorrelateswit', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1304: ('pagation, gradient input, LRP, and Occlusion, was tested for Alzheimer’s\\ndiseaseclassification[ 43].RepeatedlytrainingaCNNwiththeidenticalsettingshowedthatthese\\nfour methods generated an inconsistent heatmap. Moreover, saliency maps are susceptible to ad-\\nversarial attacks [ 53], i.e., a small perturbation in the input image may generate a large variation\\nin the saliency map, though the output prediction remains the same. The bias term is also non-\\nnegligibletowardsmakingtheattributionmap,whichcorrelateswiththeoutputprediction[ 223].\\nFurther research shows that attribution methods fail in randomization tests. For example, Ade-\\nbayo et al. [ 2] showed that Guided Backprop and Guided GradCAM methods could produce the\\nvisualexplanationwithoutpropertraining.Hence,visualization-basedmethodsneedto beevalu-\\natedwithcautionwhenappliedtomedicalimages,andfutureresearchshouldfocusondeveloping\\nattributionsystemsthataremorerobust,effective,reproducible,andcapableofproducingconsis-\\ntentsaliencymaps.Anothermajorissueofthegradient-basedmethods(e.g.,integratedgradients)\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:34 Md I.Hossain etal.\\ndepends on selecting a reference point, such as a baseline image. Hence, future research should\\nfocuson convertingthereferencepointtoa hyperparameter.\\nLimitation of Non-attribution Explanation Methods: The shortcomings of existing non-\\nattribution (e.g., concept learning, counterfactual, or prototype-based) methods are computation-\\nallyexpensive,needadomainexpert,orrequirehighannotationcost.Forexample,themainlimita-\\ntionofconceptlearningmodelsisthattheyneedadditionalannotationcostsbecausetheyrequire\\na human to select concept examples. Some other drawbacks are that a misleading explanation is\\npossibleduetoconfoundingconcepts,andconceptsmaynotcausallyaffectthemodel’sprediction.\\nInsomecases,wherethemethods(e.g.,ACE)extractvisualconceptsautomaticallyfromtheimage,\\nhence, no human in the loop is necessary, while the concepts may suffer the completeness issue\\n[237].Toi', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1305: ('ert,orrequirehighannotationcost.Forexample,themainlimita-\\ntionofconceptlearningmodelsisthattheyneedadditionalannotationcostsbecausetheyrequire\\na human to select concept examples. Some other drawbacks are that a misleading explanation is\\npossibleduetoconfoundingconcepts,andconceptsmaynotcausallyaffectthemodel’sprediction.\\nInsomecases,wherethemethods(e.g.,ACE)extractvisualconceptsautomaticallyfromtheimage,\\nhence, no human in the loop is necessary, while the concepts may suffer the completeness issue\\n[237].Toillustrate,themethodmayselecttenconceptswithhighselectionscores;however,they\\nmay not be sufficient to explain the predictions. A limited method (e.g., ConceptSHAP) can solve\\ntheabove-mentionedissuesofselectingconcepts[ 56]byadaptinggame-theoreticconcept,which\\nneeds in-depth mathematical knowledge to understand. Hence, the future direction of concept\\nlearning should be developing less complex techniques, requiring minimum human involvement,\\nandautomatically selectingrobust,completeconcepts.\\nThe counterfactual explanation limitation is that the targeted image perturbation process may\\nbe unrealistic. Besides, an autoencoder is needed to generate counterfactual images; therefore, a\\ngood representation is limited due to poor data quality or insufficient data. Hence, importance\\nshouldbegiven to developingimage perturbationprocessapproaches.\\nFurthermore,prototype-basedmethodstakealongtimetotrainastheycomparethetestimage\\nwith every input in the train set and are susceptible to noise or compression artifacts. In some\\nXAI methods, a human is needed to validate the reason for prediction. In that case, the main\\nlimitation is that a specialist’s requirement adds additional cost. Therefore, future investigations\\nshouldemphasizetheseissuesanddesignimprovedprototype-basedmethodscapableofachieving\\nmaximum performance.\\nLimitation of Tabular Explanation: The majority of tabular explanations methods provide\\nlocal explanations, but fail to provide explanations of the global behavior of the black-box model.\\nIn addition, due to the di', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1306: ('AI methods, a human is needed to validate the reason for prediction. In that case, the main\\nlimitation is that a specialist’s requirement adds additional cost. Therefore, future investigations\\nshouldemphasizetheseissuesanddesignimprovedprototype-basedmethodscapableofachieving\\nmaximum performance.\\nLimitation of Tabular Explanation: The majority of tabular explanations methods provide\\nlocal explanations, but fail to provide explanations of the global behavior of the black-box model.\\nIn addition, due to the difficulty of distinguishing a specific feature’s contribution, tabular XAI\\napproachesmaynotexplainaccuratelyifthefeaturesarehighlycorrelated.Further,ifthetabular\\ndataishigh-dimensional,i.e.,datawithhighfeatures,thentheexplanationmethodsmightstruggle\\ntoidentify themostcontributingfeatures,or theircontributionsmay not beaccuratelycaptured.\\nLimitationofTextualExplanation: Theavailabilityofthedatasetplaysavitalroleinadvanc-\\ning the textual explanation in the medical field or report generation from the images. A domain-\\nspecific expert with language specialization can generate the ground-truth sentences, hence the\\nadditional annotation cost. Furthermore, generating coherent explanations may be challenging\\nbecausevariousword choicesor phrasings could result in various explanations. Therefore,in the\\nfuture,emphasiscanbeplacedongatheringexpert-generatedground-truthstatementsandcreat-\\ningnewXAI algorithms forcoherentand trustworthyreports.\\nLackofEvaluationMetrics: Anotherfuturedirectionofcouldbedevelopingevaluationtech-\\nniques. Although several evaluation metrics exist, these are not established, and mostly adopted\\ndirectlyfromdeeplearningorcomputervisionmetrics.Oneofthereasonsforlimitedquantitative\\nevaluationmetricsisthelackofgroundtruthfortheexplanation.Hence,anenormousopportunity\\nexiststo developXAI evaluationtechniquesasthefield isstillimmature.\\nInterpretability vs. Accuracy Tradeoff: A common myth in deep learning research is that a\\ntradeoffexistsbetweeninterpretabilityandaccuracy;i.e.,amodelwithhighaccuracyusuallyo', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1307: ('-\\nniques. Although several evaluation metrics exist, these are not established, and mostly adopted\\ndirectlyfromdeeplearningorcomputervisionmetrics.Oneofthereasonsforlimitedquantitative\\nevaluationmetricsisthelackofgroundtruthfortheexplanation.Hence,anenormousopportunity\\nexiststo developXAI evaluationtechniquesasthefield isstillimmature.\\nInterpretability vs. Accuracy Tradeoff: A common myth in deep learning research is that a\\ntradeoffexistsbetweeninterpretabilityandaccuracy;i.e.,amodelwithhighaccuracyusuallyoffers\\nlessexplainabilityandviceversa.Suchbeliefhasconfinedresearcherstoproducingmoreexplain-\\nable models. However, the interpretability vs. accuracy tradeoff is reversed; i.e., the model with\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:35\\nmoreinterpretabilityresultsinbetteraccuracy[ 176].Hence,futureresearchcanbeimplementing\\nand designingXAI algorithmsthathavehigh explainabilityability aswell ashigh performance.\\nComplexArchitecturesandMultimodalDatasets: Anotherresearchdirectioncouldfocus\\non assessing the quality of existing XAI methods on more complex deep models or datasets. For\\ninstance, while the influence function yields precise outcomes for shallow networks, its results\\ntendtobeinaccuratewhenappliedtodeepernetworks,asdiscussedinReference[ 17].Further,the\\nperformanceofanexistingmethodisoftenexaminedonasimplerdataset(e.g.,MNIST,CIFAR-10),\\nwhilemedicalimagedatasetsareoftencomplexandhavedifferentcharacteristics.Hence,current\\nXAI methodsshouldbeexamined forcomplexarchitecturesand multimodal datasets.\\n8 CONCLUSION\\nExplainable AI for understanding the decision-making process of deep neural networks is cru-\\ncial in critical applications (e.g., medical data analysis). In this article, we explored existing XAI\\ntechniques and summarized several applications of these methods to medical data such as im-\\nage, tabular, textual, and multimodal. We divided medical image XAI methods into four cate-\\ngories: attribution-based, concept learning-based, counterf', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1308: ('dbeexamined forcomplexarchitecturesand multimodal datasets.\\n8 CONCLUSION\\nExplainable AI for understanding the decision-making process of deep neural networks is cru-\\ncial in critical applications (e.g., medical data analysis). In this article, we explored existing XAI\\ntechniques and summarized several applications of these methods to medical data such as im-\\nage, tabular, textual, and multimodal. We divided medical image XAI methods into four cate-\\ngories: attribution-based, concept learning-based, counterfactual-based, and prototype-based ex-\\nplanations; at the same time, we presented XAI methods for tabular and text data and their ap-\\nplication in the medical field. We further explained the importance of interpretable ML research\\nandclarifieddifferentconcepts,definitions,andataxonomyunderlyingDNNmodelexplainability,\\nwhichhasrevolvedaroundmedicaldata,particularlymedicalimages.Thepaperalsosummarizes\\ncommonlyusedevaluationmetricsforevaluatingXAImethods.Further,thisarticleoutlineseach\\ncategory’s current challenges and limitations to assist researchers in selecting the XAI method\\ncarefullyaccordingtotheirproblemanddataset.Finally,wehighlightedthepotentialfuturedirec-\\ntionsfor explainableresearchinmedicaldata.\\nIn summary, this article provided a comprehensive review of current XAI techniques applied\\nto medical data, addressed the limitations, and provided future research directions to obtain a\\ntrustworthyandresponsibleAIsystems.\\nREFERENCES\\n[1] Abdalghani Abujabal, Rishiraj Saha Roy, Mohamed Yahya, and Gerhard Weikum. 2017. Quint: Interpretable ques-\\ntion answering over knowledge bases. In Proceedings of the Conference on Empirical Methods in Natural Language\\nProcessing: System Demonstrations .61–66.\\n[2] JuliusAdebayo,JustinGilmer,MichaelMuelly,IanGoodfellow,MoritzHardt,andBeenKim.2018.Sanitychecksfor\\nsaliencymaps. Adv.Neural Inf.Process.Syst. 31(2018).\\n[3] Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich, Rich Caruana, and Geoffrey E\\nHinton.2021.Neuraladditivemodels:Interpretablemachinelea', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1309: ('m. 2017. Quint: Interpretable ques-\\ntion answering over knowledge bases. In Proceedings of the Conference on Empirical Methods in Natural Language\\nProcessing: System Demonstrations .61–66.\\n[2] JuliusAdebayo,JustinGilmer,MichaelMuelly,IanGoodfellow,MoritzHardt,andBeenKim.2018.Sanitychecksfor\\nsaliencymaps. Adv.Neural Inf.Process.Syst. 31(2018).\\n[3] Rishabh Agarwal, Levi Melnick, Nicholas Frosst, Xuezhou Zhang, Ben Lengerich, Rich Caruana, and Geoffrey E\\nHinton.2021.Neuraladditivemodels:Interpretablemachinelearningwithneuralnets. Adv.NeuralInf.Process.Syst.\\n34(2021).\\n[4] Ameen Ali, Tal Shaharabany, and Lior Wolf. 2021. Explainability guided multi-site COVID-19 CT Classification.\\narXiv:2103.13677.Retrievedfrom https://arxiv.org/abs/2103.13677\\n[5] DavidAlvarezMelisandTommiJaakkola.2018.Towardsrobustinterpretabilitywithself-explainingneuralnetworks.\\nAdv.Neural Inf.Process.Syst. 31(2018).\\n[6] David Alvarez-Melis and Tommi S. Jaakkola. 2018. On the robustness of interpretability methods. arXiv:1806.08049.\\nRetrievedfrom https://arxiv.org/abs/1806.08049\\n[7] Leila Arras, Ahmed Osman, and Wojciech Samek. 2020. Ground truth evaluation of neural network explanations\\nwithclevr-xai. arXiv:2003.07258.Retrieved from https://arxiv.org/abs/2003.07258\\n[8] Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado,\\nSalvador García, Sergio Gil-López, Daniel Molina, Richard Benjamins, et al. 2020. Explainable artificial intelligence\\n(XAI): Concepts,taxonomies,opportunities andchallengestowardresponsible AI. Inf. Fusion 58(2020),82–115.\\n[9] WorawateAusawalaithong,ArjareeThirach,SanparithMarukatat,andTheerawitWilaiprasitporn.2018.Automatic\\nlungcancerpredictionfromchestX-rayimagesusingthedeeplearningapproach.In Proceedingsofthe11thBiomed-\\nical Engineering International Conference(BMEiCON’18) . IEEE, 1–5.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:36 Md I.Hossain etal.\\n[10] Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Kl', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1310: ('engestowardresponsible AI. Inf. Fusion 58(2020),82–115.\\n[9] WorawateAusawalaithong,ArjareeThirach,SanparithMarukatat,andTheerawitWilaiprasitporn.2018.Automatic\\nlungcancerpredictionfromchestX-rayimagesusingthedeeplearningapproach.In Proceedingsofthe11thBiomed-\\nical Engineering International Conference(BMEiCON’18) . IEEE, 1–5.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:36 Md I.Hossain etal.\\n[10] Sebastian Bach, Alexander Binder, Grégoire Montavon, Frederick Klauschen, Klaus-Robert Müller, and Wojciech\\nSamek. 2015. On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation.\\nPLoSOne 10,7(2015),e0130140.\\n[11] Jun Bai, Russell Posner, Tianyu Wang, Clifford Yang, and Sheida Nabavi. 2021. Applying deep learning in digital\\nbreasttomosynthesis for automaticbreast cancerdetection:A review. Med. Image Anal. 71(2021),102049.\\n[12] SatanjeevBanerjeeandAlonLavie.2005.METEOR:AnautomaticmetricforMTevaluationwithimprovedcorrela-\\ntion with human judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for\\nMachine Translation and/orSummarization . 65–72.\\n[13] Catarina Barata, M. Emre Celebi, and Jorge S. Marques. 2021. Explainable skin lesion diagnosis using taxonomies.\\nPattern Recogn. 110(2021),107413.\\n[14] Catarina Barata and Carlos Santiago. 2021. Improving the explainability of skin cancer diagnosis using CBIR. In\\nProceedingsoftheInternationalConferenceonMedicalImageComputingandComputer-AssistedIntervention .Springer,\\n550–559.\\n[15] AlinaJadeBarnett,FidesReginaSchwartz,ChaofanTao,ChaofanChen,YinhaoRen,JosephY.Lo,andCynthiaRudin.\\n2021.Acase-basedinterpretabledeeplearningmodelforclassificationofmasslesionsindigitalmammography. Nat.\\nMach. Intell. 3,12(2021),1061–1070.\\n[16] CherBass,MarianadaSilva,CaroleSudre,Petru-DanielTudosiu,StephenSmith,andEmmaRobinson.2020.ICAM:\\nInterpretableclassificationviadisentangledrepresentationsandfeatureattributionmapping. Adv.NeuralInf.Process.\\nSyst.33(2020),7697–7709.\\n[17] Samyadeep Basu, ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1311: ('er,\\n550–559.\\n[15] AlinaJadeBarnett,FidesReginaSchwartz,ChaofanTao,ChaofanChen,YinhaoRen,JosephY.Lo,andCynthiaRudin.\\n2021.Acase-basedinterpretabledeeplearningmodelforclassificationofmasslesionsindigitalmammography. Nat.\\nMach. Intell. 3,12(2021),1061–1070.\\n[16] CherBass,MarianadaSilva,CaroleSudre,Petru-DanielTudosiu,StephenSmith,andEmmaRobinson.2020.ICAM:\\nInterpretableclassificationviadisentangledrepresentationsandfeatureattributionmapping. Adv.NeuralInf.Process.\\nSyst.33(2020),7697–7709.\\n[17] Samyadeep Basu, Phil Pope, and Soheil Feizi. 2020. Influence functions in deep learning are fragile. In International\\nConferenceonLearning Representations .\\n[18] Umang Bhatt, Adrian Weller, and José M. F. Moura. 2021. Evaluating and aggregating feature-based model explana-\\ntions. InProceedings of the 29th International Conference on International Joint Conferences on Artificial Intelligence .\\n3016–3022.\\n[19] Jacob Bienand RobertTibshirani.2011.Prototype selection for interpretableclassification.\\n[20] Nicholas Bien, Pranav Rajpurkar, Robyn L. Ball, Jeremy Irvin, Allison Park, Erik Jones, Michael Bereket, Bhavik N.\\nPatel,KristenW.Yeom,KatieShpanskaya,etal.2018.Deep-learning-assisteddiagnosisforkneemagneticresonance\\nimaging:Developmentandretrospective validationof MRNet. PLoSMed. 15,11(2018),e1002699.\\n[21] Francesco Bodria, Fosca Giannotti, Riccardo Guidotti, Francesca Naretto, Dino Pedreschi, and Salvatore Rinzivillo.\\n2023.Benchmarkingandsurveyofexplanationmethodsforblackboxmodels. DataMin.Knowl.Discov. (2023),1–60.\\n[22] MoritzBöhle,FabianEitel,MartinWeygandt,andKerstinRitter.2019.Layer-wiserelevancepropagationforexplain-\\ning deep neural network decisions in MRI-based Alzheimer’s disease classification. Front. Aging Neurosci. (2019),\\n194.\\n[23] Luca Brunese, Francesco Mercaldo, Alfonso Reginelli, and Antonella Santone. 2020. Explainable deep learning for\\npulmonary disease and coronavirus COVID-19 detection from X-rays. Comput. Methods Progr. Biomed. 196 (2020),\\n105608.\\n[24] Gary H. Chang, David T. Felson, Shangran Qiu, Ali Guerma', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1312: ('zBöhle,FabianEitel,MartinWeygandt,andKerstinRitter.2019.Layer-wiserelevancepropagationforexplain-\\ning deep neural network decisions in MRI-based Alzheimer’s disease classification. Front. Aging Neurosci. (2019),\\n194.\\n[23] Luca Brunese, Francesco Mercaldo, Alfonso Reginelli, and Antonella Santone. 2020. Explainable deep learning for\\npulmonary disease and coronavirus COVID-19 detection from X-rays. Comput. Methods Progr. Biomed. 196 (2020),\\n105608.\\n[24] Gary H. Chang, David T. Felson, Shangran Qiu, Ali Guermazi, Terence D. Capellini, and Vijaya B. Kolachalama.\\n2020. Assessment of knee pain from MR imaging using a convolutional Siamese network. Eur. Radiol. 30, 6 (2020),\\n3538–3548.\\n[25] AdityaChattopadhay,AnirbanSarkar,PrantikHowlader,andVineethN.Balasubramanian.2018.Grad-cam++:Gen-\\neralizedgradient-basedvisualexplanationsfordeepconvolutionalnetworks.In ProceedingsoftheIEEEWinterCon-\\nference on Applications ofComputer Vision (WACV’18) .IEEE, 839–847.\\n[26] Saneem Chemmengath, Amar Prakash Azad, Ronny Luss, and Amit Dhurandhar. 2022. Let the CAT out of the bag:\\nContrastive attributed explanations for text. In Proceedings of the Conference on Empirical Methods in Natural Lan-\\nguage Processing . 7190–7206.\\n[27] Chaofan Chen, Oscar Li, Daniel Tao, Alina Barnett, Cynthia Rudin, and Jonathan K. Su. 2019. This looks like that:\\nDeeplearningfor interpretableimagerecognition. Adv.Neural Inf.Process.Syst. 32(2019).\\n[28] HughChen,ScottM.Lundberg,GabrielErion,JerryH.Kim,andSu-InLee.2021.Forecastingadversesurgicalevents\\nusing self-supervised transferlearningfor physiological signals. NPJ Digit. Med. 4,1 (2021),167.\\n[29] JianboChen,LeSong,MartinWainwright,andMichaelJordan.2018.Learningtoexplain:Aninformation-theoretic\\nperspective onmodel interpretation.In International Conferenceon Machine Learning . PMLR,883–892.\\n[30] Richard J. Chen, Ming Y. Lu, Drew F. K. Williamson, Tiffany Y. Chen, Jana Lipkova, Zahra Noor, Muhammad Sha-\\nban, Maha Shady, Mane Williams, Bumjin Joo, et al. 2022. Pan-cancer integrative histology-genomic analysis ', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1313: ('lf-supervised transferlearningfor physiological signals. NPJ Digit. Med. 4,1 (2021),167.\\n[29] JianboChen,LeSong,MartinWainwright,andMichaelJordan.2018.Learningtoexplain:Aninformation-theoretic\\nperspective onmodel interpretation.In International Conferenceon Machine Learning . PMLR,883–892.\\n[30] Richard J. Chen, Ming Y. Lu, Drew F. K. Williamson, Tiffany Y. Chen, Jana Lipkova, Zahra Noor, Muhammad Sha-\\nban, Maha Shady, Mane Williams, Bumjin Joo, et al. 2022. Pan-cancer integrative histology-genomic analysis via\\nmultimodaldeeplearning. CancerCell 40,8(2022),865–878.\\n[31] ZhihongChen,YanSong,Tsung-HuiChang,andXiangWan.2020.Generatingradiologyreportsviamemory-driven\\ntransformer. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’20) .\\n1439–1449.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:37\\n[32] Tanya Chowdhury, Razieh Rahimi, and James Allan. 2022. Equi-explanation maps: Concise and informative global\\nsummaryexplanations.In ProceedingsoftheACMConferenceonFairness,Accountability,andTransparency .464–472.\\n[33] James R. Clough, Ilkay Oksuz, Esther Puyol-Antón, Bram Ruijsink, Andrew P. King, and Julia A. Schnabel. 2019.\\nGlobalandlocalinterpretabilityforcardiacMRIclassification.In ProceedingsoftheInternationalConferenceonMed-\\nical Image Computing andComputer-Assisted Intervention .Springer,656–664.\\n[34] JosephPaulCohen,RupertBrooks,SovannEn,EvanZucker,AnujPareek,MatthewP.Lungren,andAkshayChaud-\\nhari. 2021. Gifsplanation via latent shift: A simple autoencoder approach to counterfactual generation for chest\\nx-rays. In Medical Imaging with Deep Learning . PMLR,74–104.\\n[35] Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, José M. F. Moura, Devi Parikh, and Dhruv\\nBatra.2017.Visualdialog.In ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition .326–335.\\n[36] Arun Das and Paul Rad. 2020. Opportunities and challenges in explainable artificial intelligence (xai): A survey.\\narXiv:2006.11371', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1314: ('lanation via latent shift: A simple autoencoder approach to counterfactual generation for chest\\nx-rays. In Medical Imaging with Deep Learning . PMLR,74–104.\\n[35] Abhishek Das, Satwik Kottur, Khushi Gupta, Avi Singh, Deshraj Yadav, José M. F. Moura, Devi Parikh, and Dhruv\\nBatra.2017.Visualdialog.In ProceedingsoftheIEEEConferenceonComputerVisionandPatternRecognition .326–335.\\n[36] Arun Das and Paul Rad. 2020. Opportunities and challenges in explainable artificial intelligence (xai): A survey.\\narXiv:2006.11371.Retrievedfrom https://arxiv.org/abs/2006.11371\\n[37] AmitDhurandhar,Pin-YuChen,RonnyLuss,Chun-ChenTu,PaishunTing,KarthikeyanShanmugam,andPayelDas.\\n2018. Explanations based on the missing: Towards contrastive explanations with pertinent negatives. Adv. Neural\\nInf.Process.Syst. 31(2018).\\n[38] Theekshana Dissanayake, Tharindu Fernando, Simon Denman, Sridha Sridharan, Houman Ghaemmaghami, and\\nClintonFookes.2020.Arobustinterpretabledeeplearningclassifierforheartanomalydetectionwithoutsegmenta-\\ntion.IEEEJ.Biomed. Health Inf. 25,6 (2020),2162–2171.\\n[39] JonDonnelly,AlinaJadeBarnett,andChaofanChen.2022.Deformableprotopnet:Aninterpretableimageclassifier\\nusingdeformableprototypes.In ProceedingsoftheIEEE/CVFConferenceonComputerVisionandPatternRecognition .\\n10265–10275.\\n[40] Finale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. STAT1050\\n(2017),2.\\n[41] Jared A. Dunnmon, Darvin Yi, Curtis P. Langlotz, Christopher Ré, Daniel L. Rubin, and Matthew P. Lungren. 2019.\\nAssessment of convolutional neural networks for automated classification of chest radiographs. Radiology 290,\\n2(2019),537–544.\\n[42] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Omer Rana, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal\\nShah, Graham Morgan, et al. 2022. Explainable AI (XAI): Core ideas, techniques and solutions. ACM Comput. Surv.\\n(2022).\\n[43] Fabian Eitel, Kerstin Ritter, Alzheimer’s Disease Neuroimaging Initiative (ADNI, et al. 2019. Testing the robustness\\nof attribution methods for convolutional ne', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1315: (' convolutional neural networks for automated classification of chest radiographs. Radiology 290,\\n2(2019),537–544.\\n[42] Rudresh Dwivedi, Devam Dave, Het Naik, Smiti Singhal, Omer Rana, Pankesh Patel, Bin Qian, Zhenyu Wen, Tejal\\nShah, Graham Morgan, et al. 2022. Explainable AI (XAI): Core ideas, techniques and solutions. ACM Comput. Surv.\\n(2022).\\n[43] Fabian Eitel, Kerstin Ritter, Alzheimer’s Disease Neuroimaging Initiative (ADNI, et al. 2019. Testing the robustness\\nof attribution methods for convolutional neural networks in MRI-based Alzheimer’s disease classification. In Inter-\\npretabilityofMachineIntelligenceinMedicalImageComputingandMultimodalLearningforClinicalDecisionSupport .\\nSpringer, 3–11.\\n[44] Fabian Eitel, Emily Soehler, Judith Bellmann-Strobl, Alexander U. Brandt, Klemens Ruprecht, René M Giess, Joseph\\nKuchling, Susanna Asseyer, Martin Weygandt, John-Dylan Haynes, et al. 2019. Uncovering convolutional neural\\nnetwork decisions for diagnosing multiple sclerosis on conventional MRI using layer-wise relevance propagation.\\nNeuroImage: Clin. 24(2019),102003.\\n[45] Feng-Lei Fan, Jinjun Xiong, Mengzhou Li, and Ge Wang. 2021. On interpretability of artificial neural networks: A\\nsurvey.IEEETrans.Radiat. PlasmaMed. Sci. 5,6(2021),741–760.\\n[46] ZhengqingFang,KunKuang,YuxiaoLin,FeiWu,andYu-FengYao.2020.Concept-basedexplanationforfine-grained\\nimagesanditsapplicationininfectiouskeratitisclassification.In Proceedingsofthe28thACMInternationalConference\\non Multimedia . 700–708.\\n[47] TomFawcett.2006.An introduction to ROCanalysis. PatternRecogn. Lett. 27,8(2006),861–874.\\n[48] Benjamin Filtjens, Pieter Ginis, Alice Nieuwboer, Muhammad Raheel Afzal, Joke Spildooren, Bart Vanrumste, and\\nPeter Slaets. 2021. Modelling and identification of characteristic kinematic features preceding freezing of gait with\\nconvolutionalneuralnetworksandlayer-wiserelevancepropagation. BMCMed.Inf.Decis.Making 21,1(2021),1–11.\\n[49] William Gale, Luke Oakden-Rayner, Gustavo Carneiro, Lyle J. Palmer, and Andrew P. Bradley. 2019. Producing\\nradiologist-', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1316: ('Canalysis. PatternRecogn. Lett. 27,8(2006),861–874.\\n[48] Benjamin Filtjens, Pieter Ginis, Alice Nieuwboer, Muhammad Raheel Afzal, Joke Spildooren, Bart Vanrumste, and\\nPeter Slaets. 2021. Modelling and identification of characteristic kinematic features preceding freezing of gait with\\nconvolutionalneuralnetworksandlayer-wiserelevancepropagation. BMCMed.Inf.Decis.Making 21,1(2021),1–11.\\n[49] William Gale, Luke Oakden-Rayner, Gustavo Carneiro, Lyle J. Palmer, and Andrew P. Bradley. 2019. Producing\\nradiologist-quality reports for interpretable deep learning. In Proceedings of the IEEE 16th International Symposium\\non Biomedical Imaging (ISBI’19) . IEEE, 1275–1279.\\n[50] Paul Gamble, Ronnachai Jaroensri, Hongwu Wang, Fraser Tan, Melissa Moran, Trissia Brown, Isabelle Flament-\\nAuvigne,EmadA.Rakha,MichaelToss,DavidJ.Dabbs,etal.2021.Determiningbreastcancerbiomarkerstatusand\\nassociated morphological featuresusingdeep learning. Commun. Med. 1,1 (2021),14.\\n[51] Kai Gao, Hui Shen, Yadong Liu, Lingli Zeng, and Dewen Hu. 2019. Dense-cam: Visualize the gender of brains with\\nmriimages.In Proceedings oftheInternational JointConferenceonNeural Networks (IJCNN’19) .IEEE, 1–7.\\n[52] AsmaGhandeharioun,BeenKim,Chun-LiangLi,BrendanJou,BrianEoff,andRosalindPicard.2021.DISSECT:Dis-\\nentangledsimultaneousexplanationsviaconcepttraversals.In InternationalConferenceonLearningRepresentations .\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:38 Md I.Hossain etal.\\n[53] AmirataGhorbani,AbubakarAbid,andJamesZou.2019.Interpretationofneuralnetworksisfragile.In Proceedings\\nof theAAAIConferenceonArtificial Intelligence ,Vol. 33.3681–3688.\\n[54] Amirata Ghorbani, David Ouyang, Abubakar Abid, Bryan He, Jonathan H. Chen, Robert A. Harrington, David H.\\nLiang, Euan A. Ashley, and James Y. Zou. 2020. Deep learning interpretation of echocardiograms. NPJ Digit. Med. 3,\\n1(2020),10.\\n[55] AmirataGhorbani,JamesWexler,JamesY.Zou,andBeenKim.2019.Towardsautomaticconcept-basedexplanations.\\nAdvances in Neural Information Processing System', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1317: ('9.Interpretationofneuralnetworksisfragile.In Proceedings\\nof theAAAIConferenceonArtificial Intelligence ,Vol. 33.3681–3688.\\n[54] Amirata Ghorbani, David Ouyang, Abubakar Abid, Bryan He, Jonathan H. Chen, Robert A. Harrington, David H.\\nLiang, Euan A. Ashley, and James Y. Zou. 2020. Deep learning interpretation of echocardiograms. NPJ Digit. Med. 3,\\n1(2020),10.\\n[55] AmirataGhorbani,JamesWexler,JamesY.Zou,andBeenKim.2019.Towardsautomaticconcept-basedexplanations.\\nAdvances in Neural Information Processing Systems 32(2019).\\n[56] Yash Goyal, Amir Feder, Uri Shalit, and Been Kim. 2019. Explaining classifiers with causal concept effect (cace).\\narXiv:1907.07165.Retrievedfrom https://arxiv.org/abs/1907.07165\\n[57] MaraGraziani,VincentAndrearczyk,andHenningMüller.2018.Regressionconceptvectorsforbidirectionalexpla-\\nnationsinhistopathology.In UnderstandingandInterpretingMachineLearninginMedicalImageComputingApplica-\\ntions.Springer, 124–132.\\n[58] IrinaGrigorescu,LucilioCordero-Grande,A.DavidEdwards,JosephV.Hajnal,MarcModat,andMariaDeprez.2019.\\nInvestigatingimageregistrationimpactonpretermbirthclassification:Aninterpretabledeeplearningapproach.In\\nInternational Workshopon Preterm, Perinatal and Paediatric Image Analysis .Springer, 104–112.\\n[59] Riccardo Guidotti, Anna Monreale, Fosca Giannotti, Dino Pedreschi, Salvatore Ruggieri, and Franco Turini. 2019.\\nFactual andcounterfactualexplanationsfor blackboxdecision making. IEEEIntell.Syst. 34,6(2019),14–23.\\n[60] RiccardoGuidotti,AnnaMonreale,StanMatwin,andDinoPedreschi.2020.Blackboxexplanationbylearningimage\\nexemplarsinthelatentfeaturespace.In ProceedingsoftheEuropeanConferenceonMachineLearningandKnowledge\\nDiscovery in Databases (ECMLPKDD’19), PartI .Springer, 189–205.\\n[61] Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, and Fosca Giannotti. 2018.\\nLocalrule-basedexplanationsofblackboxdecisionsystems.arXiv:1805.10820.Retrievedfrom https://arxiv.org/abs/\\n1805.10820\\n[62] Riccardo Guidotti, Anna Monreale, Francesco Spinnato, Dino Pedreschi, and Fosca G', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1318: ('explanationbylearningimage\\nexemplarsinthelatentfeaturespace.In ProceedingsoftheEuropeanConferenceonMachineLearningandKnowledge\\nDiscovery in Databases (ECMLPKDD’19), PartI .Springer, 189–205.\\n[61] Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi, Franco Turini, and Fosca Giannotti. 2018.\\nLocalrule-basedexplanationsofblackboxdecisionsystems.arXiv:1805.10820.Retrievedfrom https://arxiv.org/abs/\\n1805.10820\\n[62] Riccardo Guidotti, Anna Monreale, Francesco Spinnato, Dino Pedreschi, and Fosca Giannotti. 2020. Explaining\\nany time series classifier. In Proceedings of the IEEE 2nd International Conference on Cognitive Machine Intelligence\\n(CogMI’20) . IEEE, 167–176.\\n[63] ParasGulati,QinHu,andSFarokhAtashzar.2021.Towarddeepgeneralizationofperipheralemg-basedhuman-robot\\ninterfacing:A hybrid explainablesolution for neurorobotic systems. IEEERobot. Autom.Lett. 6,2(2021),2650–2657.\\n[64] ManishGupta,ChetnaDas,ArnabRoy,PrashantGupta,G.RadhakrishnaPillai,andKamlakarPatole.2020.Regionof\\ninterestidentificationforcervicalcancerimages.In ProceedingsoftheIEEE17thInternationalSymposiumonBiomed-\\nical Imaging (ISBI’20) . IEEE, 1293–1296.\\n[65] Karthik S. Gurumoorthy, Amit Dhurandhar, Guillermo Cecchi, and Charu Aggarwal. 2019. Efficient data represen-\\ntation by selecting prototypes with importance weights. In Proceedings of the IEEE International Conference on Data\\nMining (ICDM’19) . IEEE, 260–269.\\n[66] WooseokHa,ChandanSingh,FrancoisLanusse,SrigokulUpadhyayula,andBinYu.2021.Adaptivewaveletdistilla-\\ntion from neuralnetworks through interpretations. Adv. Neural Inf.Process. Syst. 34(2021).\\n[67] Miriam Hägele, Philipp Seegerer, Sebastian Lapuschkin, Michael Bockmayr, Wojciech Samek, Frederick Klauschen,\\nKlaus-Robert Müller, and Alexander Binder. 2020. Resolving challenges in deep learning-based analyses of\\nhistopathological imagesusingexplanationmethods. Sci. Rep.10,1 (2020),1–12.\\n[68] NarayanHegde,JasonD.Hipp,YunLiu,MichaelEmmert-Buck,EmilyReif,DanielSmilkov,MichaelTerry,CarrieJ.\\nCai, Mahul B. Amin, Craig H. Mermel, et a', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1319: ('tworks through interpretations. Adv. Neural Inf.Process. Syst. 34(2021).\\n[67] Miriam Hägele, Philipp Seegerer, Sebastian Lapuschkin, Michael Bockmayr, Wojciech Samek, Frederick Klauschen,\\nKlaus-Robert Müller, and Alexander Binder. 2020. Resolving challenges in deep learning-based analyses of\\nhistopathological imagesusingexplanationmethods. Sci. Rep.10,1 (2020),1–12.\\n[68] NarayanHegde,JasonD.Hipp,YunLiu,MichaelEmmert-Buck,EmilyReif,DanielSmilkov,MichaelTerry,CarrieJ.\\nCai, Mahul B. Amin, Craig H. Mermel, et al. 2019. Similar image search for histopathology: SMILY. NPJ Digit. Med.\\n2,1 (2019),56.\\n[69] Andreas Holzinger, André Carrington, and Heimo Müller. 2020. Measuring the quality of explanations: The system\\ncausabilityscale(SCS). Künstl.Intell. 34,2(2020),193–198.\\n[70] AndreasT.HolzingerandHeimoMuller.2021.Towardhuman–AIinterfacestosupportexplainabilityandcausability\\nin medicalAI. Computer 54,10(2021),78–86.\\n[71] SaraHooker,DumitruErhan,Pieter-JanKindermans,andBeenKim.2019.Abenchmarkforinterpretabilitymethods\\nin deep neuralnetworks. Adv.Neural Inf.Process.Syst. 32(2019).\\n[72] BenjaminHooverHendrikStrobelt,andSebastianGehrmann.2020.exBERT:Avisualanalysistooltoexplorelearned\\nrepresentationsintransformermodels.In Proceedingsofthe58thAnnualMeetingoftheAssociationforComputational\\nLinguistics: SystemDemonstrations .\\n[73] Md Imran Hossain, Ghada Zamzmi, Peter Mouton, Yu Sun, and Dmitry Goldgof. 2023. Enhancing neonatal pain as-\\nsessmenttransparencyviaexplanatorytrainingexamplesidentification.In ProceedingsoftheIEEE36thInternational\\nSymposium on Computer-Based Medical Systems (CBMS’23) . IEEE, 311–316.\\n[74] BrianHu,BhavanVasu,andAnthonyHoogs.2022.X-mir:Explainablemedicalimageretrieval.In Proceedingsofthe\\nIEEE/CVFWinterConferenceonApplications ofComputer Vision .440–450.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:39\\n[75] Shaoli Huang, Xinchao Wang, and Dacheng Tao. 2021. Snapmix: Semantically proportional mixing for augmenting\\nfine-graineddata.In Proceedin', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1320: ('International\\nSymposium on Computer-Based Medical Systems (CBMS’23) . IEEE, 311–316.\\n[74] BrianHu,BhavanVasu,andAnthonyHoogs.2022.X-mir:Explainablemedicalimageretrieval.In Proceedingsofthe\\nIEEE/CVFWinterConferenceonApplications ofComputer Vision .440–450.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:39\\n[75] Shaoli Huang, Xinchao Wang, and Dacheng Tao. 2021. Snapmix: Semantically proportional mixing for augmenting\\nfine-graineddata.In Proceedings oftheAAAIConferenceonArtificial Intelligence , Vol. 35.1628–1636.\\n[76] Yongxiang Huang and Albert Chung. 2019. Evidence localization for pathology images using weakly supervised\\nlearning.In ProceedingsoftheInternationalConferenceonMedicalImageComputingandComputer-assistedInterven-\\ntion.Springer, 613–621.\\n[77] Zhicheng Huang and Dongmei Fu. 2019. Diagnose chest pathology in X-ray images by learning multi-attention\\nconvolutionalneuralnetwork.In ProceedingsoftheIEEE8thJointInternationalInformationTechnologyandArtificial\\nIntelligenceConference (ITAIC’19) .IEEE, 294–299.\\n[78] DanielT.Huff,AmyJ.Weisman,andRobertJeraj.2021.Interpretationandvisualizationtechniquesfordeeplearning\\nmodels inmedicalimaging. Phys.Med. Bio. 66,4(2021),04TR01.\\n[79] RamiIbrahimandM.OmairShafiq.2023.Explainableconvolutionalneuralnetworks:Ataxonomy,review,andfuture\\ndirections. ACMComputing Surveys 55,10(2023),1–37.\\n[80] Hayato Itoh, Zhongyang Lu, Yuichi Mori, Masashi Misawa, Masahiro Oda, Shin-ei Kudo, and Kensaku Mori. 2020.\\nVisualisingdecision-reasoningregionsincomputer-aidedpathologicalpatterndiagnosisofendoscytoscopicimages\\nbasedon CNNweightsanalysis. In Medical Imaging 2020: Computer-Aided Diagnosis ,Vol. 11314.SPIE, 761–768.\\n[81] PraharshIvaturi,MatteoGadaleta,AmitabhC.Pandey,MichaelPazzani,StevenR.Steinhubl,andGiorgioQuer.2021.\\nA comprehensive explanation framework for biomedical time series classification. IEEE J. Biomed. Health Inf. 25,\\n7(2021),2398–2408.\\n[82] Amir Jamaludin, Timor Kadir, and Andrew Zisserman. 2017. SpineNet: Automat', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1321: ('ision-reasoningregionsincomputer-aidedpathologicalpatterndiagnosisofendoscytoscopicimages\\nbasedon CNNweightsanalysis. In Medical Imaging 2020: Computer-Aided Diagnosis ,Vol. 11314.SPIE, 761–768.\\n[81] PraharshIvaturi,MatteoGadaleta,AmitabhC.Pandey,MichaelPazzani,StevenR.Steinhubl,andGiorgioQuer.2021.\\nA comprehensive explanation framework for biomedical time series classification. IEEE J. Biomed. Health Inf. 25,\\n7(2021),2398–2408.\\n[82] Amir Jamaludin, Timor Kadir, and Andrew Zisserman. 2017. SpineNet: Automated classification and evidence visu-\\nalizationin spinalMRIs. Med.Image Anal. 41(2017),63–73.\\n[83] Adrianna Janik, Jonathan Dodd, Georgiana Ifrim, Kris Sankaran, and Kathleen Curran. 2021. Interpretability of a\\ndeep learning model in the application of cardiac MRI segmentation with an ACDC challenge dataset. In Medical\\nImaging 2021: Image Processing ,Vol. 11596.InternationalSociety for OpticsandPhotonics, 1159636.\\n[84] Junyi Ji. 2019. Gradient-based interpretation on convolutional neural network for classification of pathological im-\\nages. InProceedings of the International Conference on Information Technology and Computer Application (ITCA’19) .\\nIEEE, 83–86.\\n[85] HongyangJiang,KangYang,MengdiGao,DongdongZhang,HeMa,andWeiQian.2019.Aninterpretableensemble\\ndeep learning model for diabetic retinopathy disease classification. In Proceedings of the 41st Annual International\\nConferenceoftheIEEEEngineering inMedicine and Biology Society (EMBC’19) .IEEE, 2045–2048.\\n[86] BaoyuJing,PengtaoXie,andEricXing.2018.Ontheautomaticgenerationofmedicalimagingreports.In Proceedings\\nofthe56th AnnualMeeting of theAssociationfor Computational Linguistics (Volume1: LongPapers) . 2577–2586.\\n[87] Gargi Joshi, Rahee Walambe, and Ketan Kotecha. 2021. A review on explainability in multimodal deep neural nets.\\nIEEEAccess 9(2021),59800–59821.\\n[88] Shalmali Joshi, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. Towards realistic\\nindividualrecourseandactionableexplanationsinblack-boxdecisionmakingsystems. J.Environ.Sc', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1322: ('aticgenerationofmedicalimagingreports.In Proceedings\\nofthe56th AnnualMeeting of theAssociationfor Computational Linguistics (Volume1: LongPapers) . 2577–2586.\\n[87] Gargi Joshi, Rahee Walambe, and Ketan Kotecha. 2021. A review on explainability in multimodal deep neural nets.\\nIEEEAccess 9(2021),59800–59821.\\n[88] Shalmali Joshi, Oluwasanmi Koyejo, Warut Vijitbenjaronk, Been Kim, and Joydeep Ghosh. 2019. Towards realistic\\nindividualrecourseandactionableexplanationsinblack-boxdecisionmakingsystems. J.Environ.Sci.(Chin.) (2019).\\n[89] MdSarwarKamal,AdenNorthcote,LinkonChowdhury,NilanjanDey,RubénGonzálezCrespo,andEnriqueHerrera-\\nViedma. 2021. Alzheimer’s patient analysis using image and gene expression data and explainable-AI to present\\nassociated genes. IEEETrans.Instrum.Meas. 70(2021),1–7.\\n[90] Andrei Kapishnikov, Tolga Bolukbasi, Fernanda Viégas, and Michael Terry. 2019. Xrai: Better attributions through\\nregions. In Proceedings oftheIEEE/CVFInternational ConferenceonComputer Vision .4948–4957.\\n[91] Tero Karras, Samuli Laine, and Timo Aila. 2019. A style-based generator architecture for generative adversarial\\nnetworks. In Proceedings oftheIEEE/CVFConferenceonComputerVisionand PatternRecognition . 4401–4410.\\n[92] SatyanandaKashyap,AlexandrosKarargyris,JoyWu,YanivGur,ArjunSharma,KenC.L.Wong,MehdiMoradi,and\\nTanveerSyeda-Mahmood.2020.Lookingintherightplaceforanomalies:ExplainableAithroughautomaticlocation\\nlearning.In Proceedings oftheIEEE17th International Symposium on Biomedical Imaging (ISBI’20) . IEEE, 1125–1129.\\n[93] Justin Ker, Yeqi Bai, Hwei Yee Lee, Jai Rao, and Lipo Wang. 2019. Automated brain histology classification using\\nmachinelearning. J.Clin.Neurosci. 66(2019),239–245.\\n[94] Ashkan Khakzar, Shadi Albarqouni, and Nassir Navab. 2019. Learning interpretable features via adversarially ro-\\nbustoptimization.In ProceedingsoftheInternationalConferenceonMedicalImageComputingandComputer-Assisted\\nIntervention .Springer,793–800.\\n[95] Amirhossein Kiani, Bora Uyumazturk, Pranav Rajpurkar, Alex Wang, Rebecca Gao, Erik Jones', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1323: ('] Justin Ker, Yeqi Bai, Hwei Yee Lee, Jai Rao, and Lipo Wang. 2019. Automated brain histology classification using\\nmachinelearning. J.Clin.Neurosci. 66(2019),239–245.\\n[94] Ashkan Khakzar, Shadi Albarqouni, and Nassir Navab. 2019. Learning interpretable features via adversarially ro-\\nbustoptimization.In ProceedingsoftheInternationalConferenceonMedicalImageComputingandComputer-Assisted\\nIntervention .Springer,793–800.\\n[95] Amirhossein Kiani, Bora Uyumazturk, Pranav Rajpurkar, Alex Wang, Rebecca Gao, Erik Jones, Yifan Yu, Curtis P.\\nLanglotz, Robyn L. Ball, Thomas J. Montine, et al. 2020. Impact of a deep learning assistant on the histopathologic\\nclassificationof livercancer. NPJ Digit. Med. 3,1(2020),1–8.\\n[96] BeenKim,RajivKhanna,andOluwasanmiO.Koyejo.2016.Examplesarenotenough,learntocriticize!criticismfor\\ninterpretability. Adv.Neural Inf.Process.Syst. 29(2016).\\n[97] BeenKim,MartinWattenberg,JustinGilmer,CarrieCai,JamesWexler,FernandaViegas,etal.2018.Interpretability\\nbeyond feature attribution: Quantitative testing with concept activation vectors (tcav). In International Conference\\non Machine Learning . PMLR,2668–2677.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:40 Md I.Hossain etal.\\n[98] Eunji Kim, Siwon Kim, Minji Seo, and Sungroh Yoon. 2021. XProtoNet: Diagnosis in chest radiography with global\\nand local explanations. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition .\\n15719–15728.\\n[99] Junho Kim, Minsu Kim, and Yong Man Ro. 2021. Interpretation of lesional detection via counterfactual generation.\\nInProceedings of theIEEEInternational ConferenceonImage Processing (ICIP’21) . IEEE, 96–100.\\n[100] Mijung Kim, Jong Chul Han, Seung Hyup Hyun, Olivier Janssens, Sofie Van Hoecke, Changwon Kee, and Wesley\\nDe Neve. 2019. Medinoid: Computer-aided diagnosis and localization of glaucoma using deep learning. Appl. Sci. 9,\\n15(2019),3064.\\n[101] Kranthi Kiran G. V. and G. Meghana Reddy. 2019. Automatic classification of whole slide pap smear images using\\nCNN', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1324: ('ation of lesional detection via counterfactual generation.\\nInProceedings of theIEEEInternational ConferenceonImage Processing (ICIP’21) . IEEE, 96–100.\\n[100] Mijung Kim, Jong Chul Han, Seung Hyup Hyun, Olivier Janssens, Sofie Van Hoecke, Changwon Kee, and Wesley\\nDe Neve. 2019. Medinoid: Computer-aided diagnosis and localization of glaucoma using deep learning. Appl. Sci. 9,\\n15(2019),3064.\\n[101] Kranthi Kiran G. V. and G. Meghana Reddy. 2019. Automatic classification of whole slide pap smear images using\\nCNN with PCA based feature interpretation. In Proceedings of the IEEE/CVF Conference on Computer Vision and\\nPattern Recognition Workshops .0–0.\\n[102] Pang Wei Koh and Percy Liang. 2017. Understanding black-box predictions via influence functions. In International\\nConferenceonMachine Learning .PMLR,1885–1894.\\n[103] Maximilian Kohlbrenner, Alexander Bauer, Shinichi Nakajima, Alexander Binder, Wojciech Samek, and Sebastian\\nLapuschkin. 2020. Towards best practice in explaining neural network decisions with LRP. In Proceedings of the\\nInternational JointConferenceonNeural Networks (IJCNN’20) .IEEE, 1–7.\\n[104] BrunoKorbar,AndreaM.Olofson,AllenP.Miraflor,CatherineM.Nicka,MatthewA.Suriawinata,LorenzoTorresani,\\nArief A. Suriawinata, and Saeed Hassanpour. 2017. Looking under the hood: Deep neural network visualization\\nto interpret whole-slide image analysis outcomes for colorectal polyps. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition Workshops .69–75.\\n[105] Olga Kovaleva, Chaitanya Shivade, Satyananda Kashyap, Karina Kanjaria, Joy Wu, Deddeh Ballah, Adam Coy,\\nAlexandros Karargyris, Yufan Guo, David Beymer Beymer, et al. 2020. Towards visual dialog for radiology. In Pro-\\nceedings ofthe19th SIGBioMed Workshopon Biomedical Language Processing . 60–69.\\n[106] DevinderKumar,GrahamW.Taylor,andAlexanderWong.2019.DiscoveryradiomicswithCLEAR-DR:Interpretable\\ncomputer aideddiagnosis of diabeticretinopathy. IEEEAccess 7(2019),25891–25896.\\n[107] Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi,', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1325: ('e, Satyananda Kashyap, Karina Kanjaria, Joy Wu, Deddeh Ballah, Adam Coy,\\nAlexandros Karargyris, Yufan Guo, David Beymer Beymer, et al. 2020. Towards visual dialog for radiology. In Pro-\\nceedings ofthe19th SIGBioMed Workshopon Biomedical Language Processing . 60–69.\\n[106] DevinderKumar,GrahamW.Taylor,andAlexanderWong.2019.DiscoveryradiomicswithCLEAR-DR:Interpretable\\ncomputer aideddiagnosis of diabeticretinopathy. IEEEAccess 7(2019),25891–25896.\\n[107] Bum Chul Kwon, Min-Je Choi, Joanne Taery Kim, Edward Choi, Young Bin Kim, Soonwook Kwon, Jimeng Sun,\\nand Jaegul Choo. 2018. Retainvis: Visual analytics with interpretable and interactive recurrent neural networks on\\nelectronic medicalrecords. IEEETrans.Vis.Comput. Graph. 25,1(2018),299–309.\\n[108] OrestisLampridis,RiccardoGuidotti,andSalvatoreRuggieri.2020.Explainingsentimentclassificationwithsynthetic\\nexemplars and counter-exemplars. In Proceedings of the 23rd International Conference on Discovery Science (DS’20) .\\nSpringer, 357–373.\\n[109] Hyebin Lee, Seong Tae Kim, and Yong Man Ro. 2019. Generation of multimodal justification using visual word con-\\nstraint model for explainable computer-aided diagnosis. In Proceedings of the 2nd International Workshop on Inter-\\npretabilityofMachineIntelligenceinMedicalImageComputingandMultimodalLearningforClinicalDecisionSupport\\n(iMIMIC2019)and9thInternationalWorkshop(ML-CDS2019),HeldinConjunctionwithMICCAI2019 .Springer,21–29.\\n[110] Hyunkwang Lee, Sehyo Yune, Mohammad Mansouri, Myeongchan Kim, Shahein H. Tajmir, Claude E. Guerrier,\\nSarahA.Ebert,StuartR.Pomerantz,JavierM.Romero,ShahmirKamalian,etal.2019.Anexplainabledeep-learning\\nalgorithm for the detection of acute intracranial haemorrhage from small datasets. Nat. Biomed. Eng. 3, 3 (2019),\\n173–182.\\n[111] JeongHoonLee,EunJuHa,DaYoungKim,YongJunJung,SubinHeo,Yong-HoJang,SungHyunAn,andKyungmin\\nLee.2020.Applicationofdeeplearningtothediagnosisofcervicallymphnodemetastasisfromthyroidcancerwith\\nCT:External validationandclinicalutility forresident training. Eur.Radiol. 30(2020),3066–3072.\\n', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1326: (',\\nSarahA.Ebert,StuartR.Pomerantz,JavierM.Romero,ShahmirKamalian,etal.2019.Anexplainabledeep-learning\\nalgorithm for the detection of acute intracranial haemorrhage from small datasets. Nat. Biomed. Eng. 3, 3 (2019),\\n173–182.\\n[111] JeongHoonLee,EunJuHa,DaYoungKim,YongJunJung,SubinHeo,Yong-HoJang,SungHyunAn,andKyungmin\\nLee.2020.Applicationofdeeplearningtothediagnosisofcervicallymphnodemetastasisfromthyroidcancerwith\\nCT:External validationandclinicalutility forresident training. Eur.Radiol. 30(2020),3066–3072.\\n[112] Yiming Lei, Yukun Tian, Hongming Shan, Junping Zhang, Ge Wang, and Mannudeep K. Kalra. 2020. Shape and\\nmargin-aware lung nodule classification in low-dose CT images via soft activation mapping. Med. Image Anal. 60\\n(2020),101628.\\n[113] H. A. Leopold, A. Singh, S. Sengupta, J. S. Zelek, and V. Lakshminarayanan. 2020. Recent advances in deep learning\\napplicationsforretinaldiagnosis using OCT. TateoftheArtin Neural Networks (2020).\\n[114] Benjamin Letham, Cynthia Rudin, Tyler H. McCormick, and David Madigan. 2015. Interpretable classifiers using\\nrules and bayesiananalysis:Buildinga betterstroke predictionmodel. Ann.Appl.Stat. 9,3 (2015),1350–1371.\\n[115] Dan Ley, Saumitra Mishra, and Daniele Magazzeni. 2022. Global counterfactual explanations: Investigations, im-\\nplementations and improvements. In ICLR 2022 Workshop on PAIR@2Struct: Privacy, Accountability, Interpretability,\\nRobustness,Reasoning onStructured Data .\\n[116] Jiwei Li, Will Monroe, and Dan Jurafsky. 2016. Understanding neural networks through representation erasure.\\narXiv:1612.08220.Retrievedfrom https://arxiv.org/abs/1612.08220\\n[117] MengzeLi,KunKuang,QiangZhu,XiaohongChen,QingGuo,andFeiWu.2020.IB-M:Aflexibleframeworktoalign\\nan interpretable model and a black-box model. In Proceedings of the IEEE International Conference on Bioinformatics\\nand Biomedicine (BIBM’20) . IEEE, 643–649.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:41\\n[118] Weipeng Li, Jiaxin Zhuang, Ruixuan Wang, Jianguo Z', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1327: ('esentation erasure.\\narXiv:1612.08220.Retrievedfrom https://arxiv.org/abs/1612.08220\\n[117] MengzeLi,KunKuang,QiangZhu,XiaohongChen,QingGuo,andFeiWu.2020.IB-M:Aflexibleframeworktoalign\\nan interpretable model and a black-box model. In Proceedings of the IEEE International Conference on Bioinformatics\\nand Biomedicine (BIBM’20) . IEEE, 643–649.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:41\\n[118] Weipeng Li, Jiaxin Zhuang, Ruixuan Wang, Jianguo Zhang, and Wei-Shi Zheng. 2020. Fusing metadata and der-\\nmoscopy images for skin disease diagnosis. In Proceedings of the IEEE 17th International Symposium on Biomedical\\nImaging (ISBI’20) . IEEE, 1996–2000.\\n[119] WangMin Liao, BeiJi Zou, RongChang Zhao, YuanQiong Chen, ZhiYou He, and MengJie Zhou. 2019. Clinical inter-\\npretabledeeplearningmodelfor glaucomadiagnosis. IEEEJ.Biomed. Health Inf. 24,5(2019),1405–1412.\\n[120] Chin-YewLin.2004.Rouge:Apackageforautomaticevaluationofsummaries.In TextSummarizationBranchesOut .\\n74–81.\\n[121] Tsung-Chieh Lin and Hsi-Chieh Lee. 2020. Covid-19 chest radiography images analysis based on integration of\\nimagepreprocess,guidedgrad-CAM,machinelearningandriskmanagement.In Proceedingsofthe4thInternational\\nConferenceon Medical andHealth Informatics . 281–288.\\n[122] ZehuiLin,ShengliLi,DongNi,YimeiLiao,HuaxuanWen,JieDu,SipingChen,TianfuWang,andBaiyingLei.2019.\\nMulti-task learningforquality assessment of fetalheadultrasound images. Med. Image Anal. 58(2019),101548.\\n[123] Pantelis Linardatos, Vasilis Papastefanopoulos, and Sotiris Kotsiantis. 2020. Explainable ai: A review of machine\\nlearninginterpretabilitymethods. Entropy23,1(2020),18.\\n[124] ChiLiu,XiaotongHan,ZhixiLi,JasonHa,GuankaiPeng,WeiMeng,andMingguangHe.2019.Aself-adaptivedeep\\nlearning method for automated eye laterality detection based on color fundus photography. PLoS One 14, 9 (2019),\\ne0222025.\\n[125] Guanxiong Liu, Tzu-Ming Harry Hsu, Matthew McDermott, Willie Boag, Wei-Hung Weng, Peter Szolovits, and\\nMarzyehGhassemi.2019.Clini', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1328: ('atos, Vasilis Papastefanopoulos, and Sotiris Kotsiantis. 2020. Explainable ai: A review of machine\\nlearninginterpretabilitymethods. Entropy23,1(2020),18.\\n[124] ChiLiu,XiaotongHan,ZhixiLi,JasonHa,GuankaiPeng,WeiMeng,andMingguangHe.2019.Aself-adaptivedeep\\nlearning method for automated eye laterality detection based on color fundus photography. PLoS One 14, 9 (2019),\\ne0222025.\\n[125] Guanxiong Liu, Tzu-Ming Harry Hsu, Matthew McDermott, Willie Boag, Wei-Hung Weng, Peter Szolovits, and\\nMarzyehGhassemi.2019.Clinicallyaccuratechestx-rayreportgeneration.In MachineLearningforHealthcareCon-\\nference. PMLR,249–269.\\n[126] S. Liu, B. Kailkhura, D. Loveland, and H. Yong. 2019. Generative Counterfactual Introspection for Explainable Deep\\nLearning. TechnicalReport.LawrenceLivermore NationalLaboratory, Livermore,CA.\\n[127] Hui Wen Loh, Chui Ping Ooi, Silvia Seoni, Prabal Datta Barua, Filippo Molinari, and U Rajendra Acharya. 2022.\\nApplication of explainable artificial intelligence for healthcare: A systematic review of the last decade (2011–2022).\\nComput.Methods Progr.Biomed. (2022),107161.\\n[128] Arnaud Van Looveren and Janis Klaise. 2021. Interpretable counterfactual explanations guided by prototypes. In\\nProceedings of the Joint European Conference on Machine Learning and Knowledge Discovery in Databases . Springer,\\n650–665.\\n[129] Alina Lopatina, Stefan Ropele, Renat Sibgatulin, Jürgen R. Reichenbach, and Daniel Güllmar. 2020. Investigation\\nof deep-learning-driven identification of multiple sclerosis patients based on susceptibility-weighted images using\\nrelevanceanalysis. Front.Neurosci. 14(2020),609468.\\n[130] Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun, Muhammad Imran Malik, Andreas Dengel,\\nand Sheraz Ahmed. 2020. On interpretability of deep learning based skin lesion classifiers using concept activation\\nvectors. In Proceedings of theInternational JointConference onNeural Networks (IJCNN’20) .IEEE, 1–10.\\n[131] Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun, Muhammad Imran Malik, Andreas Denge', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1329: ('lity-weighted images using\\nrelevanceanalysis. Front.Neurosci. 14(2020),609468.\\n[130] Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun, Muhammad Imran Malik, Andreas Dengel,\\nand Sheraz Ahmed. 2020. On interpretability of deep learning based skin lesion classifiers using concept activation\\nvectors. In Proceedings of theInternational JointConference onNeural Networks (IJCNN’20) .IEEE, 1–10.\\n[131] Adriano Lucieri, Muhammad Naseer Bajwa, Stephan Alexander Braun, Muhammad Imran Malik, Andreas Dengel,\\nandSherazAhmed.2022.ExAID:Amultimodalexplanationframeworkforcomputer-aideddiagnosisofskinlesions.\\nComput.Methods Progr.Biomed. 215(2022),106620.\\n[132] Adriano Lucieri, Muhammad Naseer Bajwa, Andreas Dengel, and Sheraz Ahmed. 2020. Explaining ai-based deci-\\nsion support systems using concept localization maps. In Proceedings of the 27th International Conference on Neural\\nInformation Processing (ICONIP’20),PartIV 27 .Springer, 185–193.\\n[133] ScottM.LundbergandSu-InLee.2017.Aunifiedapproachtointerpretingmodelpredictions. Adv.NeuralInf.Process.\\nSyst.30(2017).\\n[134] LuyangLuo,HaoChen,XiWang,QiDou,HuangjingLin,JuanZhou,GongjieLi,andPheng-AnnHeng.2019.Deep\\nangularembeddingandfeaturecorrelationattentionforbreastMRIcanceranalysis.In ProceedingsoftheInternational\\nConferenceonMedical Image Computing and Computer-AssistedIntervention .Springer, 504–512.\\n[135] YiweiLyu,PaulPuLiang,ZihaoDeng,RuslanSalakhutdinov,andLouis-PhilippeMorency.2022.Dime:Fine-grained\\ninterpretations of multimodal models via disentangled local explanations. arXiv:2203.02013. Retrieved from https:\\n//arxiv.org/abs/2203.02013\\n[136] KaiMa,KaijieWu,HaoCheng,ChaochenGu,RuiXu,andXinpingGuan.2018.Apathologyimagediagnosisnetwork\\nwith visual interpretability and structured diagnostic report. In Proceedings of the 25th International Conference on\\nNeural Information Processing(ICONIP’18),Proceedings, Part VI25 .Springer, 282–293.\\n[137] Pavan Rajkumar Magesh, Richard Delwin Myloth, and Rijo Jackson Tom. 2020. An explainable machine learning\\nmodel for early dete', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1330: ('planations. arXiv:2203.02013. Retrieved from https:\\n//arxiv.org/abs/2203.02013\\n[136] KaiMa,KaijieWu,HaoCheng,ChaochenGu,RuiXu,andXinpingGuan.2018.Apathologyimagediagnosisnetwork\\nwith visual interpretability and structured diagnostic report. In Proceedings of the 25th International Conference on\\nNeural Information Processing(ICONIP’18),Proceedings, Part VI25 .Springer, 282–293.\\n[137] Pavan Rajkumar Magesh, Richard Delwin Myloth, and Rijo Jackson Tom. 2020. An explainable machine learning\\nmodel for early detection of Parkinson’s disease using LIME on DaTSCAN imagery. Comput. Biol. Med. 126 (2020),\\n104041.\\n[138] DavidMajor,DimitriosLenis,MariaWimmer,GertSluiter,AstridBerg,andKatjaBühler.2020.Interpretingmedical\\nimage classifiers by optimization based counterfactual impact analysis. In Proceedings of the IEEE 17th International\\nSymposium on Biomedical Imaging (ISBI’20) . IEEE, 1096–1100.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:42 Md I.Hossain etal.\\n[139] QierMeng,YoheiHashimoto,andShin’ichiSatoh.2020.Howtoextractmoreinformationwithlessburden:Fundus\\nimage classification and retinal disease localization with ophthalmologist intervention. IEEE J. Biomed. Health Inf.\\n24,12(2020),3351–3361.\\n[140] Silvan Mertes, Tobias Huber, Katharina Weitz, Alexander Heimerl, and Elisabeth André. 2022. Ganterfactual–\\ncounterfactualexplanationsformedicalnon-expertsusinggenerativeadversariallearning. Front.Artif.Intell. 5(2022),\\n825565.\\n[141] CarloMetta,RiccardoGuidotti,YuanYin,PatrickGallinari,andSalvatoreRinzivillo.2021.Exemplarsandcounterex-\\nemplars explanations for image classifiers, targeting skin lesion labeling. In Proceedings of the IEEE Symposium on\\nComputers andCommunications (ISCC’21) .IEEE, 1–7.\\n[142] Richard Meyes, Constantin Waubert de Puiseau, Andres Posada-Moreno, and Tobias Meisen. 2020. Under the hood\\nofneuralnetworks:Characterizinglearnedrepresentationsbyfunctionalneuronpopulationsandnetworkablations.\\narXiv:2004.01254.Retrievedfrom https://arxiv.org/abs/2004.01254\\n[143] TimMiller', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1331: ('ndSalvatoreRinzivillo.2021.Exemplarsandcounterex-\\nemplars explanations for image classifiers, targeting skin lesion labeling. In Proceedings of the IEEE Symposium on\\nComputers andCommunications (ISCC’21) .IEEE, 1–7.\\n[142] Richard Meyes, Constantin Waubert de Puiseau, Andres Posada-Moreno, and Tobias Meisen. 2020. Under the hood\\nofneuralnetworks:Characterizinglearnedrepresentationsbyfunctionalneuronpopulationsandnetworkablations.\\narXiv:2004.01254.Retrievedfrom https://arxiv.org/abs/2004.01254\\n[143] TimMiller.2019.Explanationinartificialintelligence:Insightsfromthesocialsciences. Artif.Intell. 267(2019),1–38.\\n[144] Yao Ming, Huamin Qu, and Enrico Bertini. 2018. Rulematrix: Visualizing and understanding classifiers with rules.\\nIEEETrans.Vis.Comput. Graph. 25,1(2018),342–352.\\n[145] David Moher, Alessandro Liberati, Jennifer Tetzlaff, Douglas G. Altman, and PRISMA Group*. 2009. Preferred re-\\nporting items for systematic reviews and meta-analyses: The PRISMA statement. Ann. Intern. Med. 151, 4 (2009),\\n264–269.\\n[146] Ioannis Mollas, Nikolaos Bassiliades, and Grigorios Tsoumakas. 2020. Lionets: Local interpretation of neural net-\\nworks through penultimate layer decoding. In Proceedings of the International Workshops of Machine Learning and\\nKnowledge Discovery in Databases (ECML PKDD’19),Part I .Springer, 265–276.\\n[147] Ramaravind K. Mothilal, Amit Sharma, and Chenhao Tan. 2020. Explaining machine learning classifiers through\\ndiverse counterfactual explanations. In Proceedings of the Conference on Fairness, Accountability, and Transparency .\\n607–617.\\n[148] Sajad Mousavi, Fatemeh Afghah, and U. Rajendra Acharya. 2020. HAN-ECG: An interpretable atrial fibrillation de-\\ntection modelusing hierarchical attentionnetworks. Comput. Biol.Med. 127(2020),104057.\\n[149] Satya M. Muddamsetty, N. S. Jahromi Mohammad, and Thomas B. Moeslund. 2020. Sidu: Similarity difference and\\nuniquenessmethodforexplainableai.In ProceedingsoftheIEEEInternationalConferenceonImageProcessing(ICIP’20) .\\nIEEE, 3269–3273.\\n[150] Thanakron Na Pattalung, Thamma', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1332: ('ty, and Transparency .\\n607–617.\\n[148] Sajad Mousavi, Fatemeh Afghah, and U. Rajendra Acharya. 2020. HAN-ECG: An interpretable atrial fibrillation de-\\ntection modelusing hierarchical attentionnetworks. Comput. Biol.Med. 127(2020),104057.\\n[149] Satya M. Muddamsetty, N. S. Jahromi Mohammad, and Thomas B. Moeslund. 2020. Sidu: Similarity difference and\\nuniquenessmethodforexplainableai.In ProceedingsoftheIEEEInternationalConferenceonImageProcessing(ICIP’20) .\\nIEEE, 3269–3273.\\n[150] Thanakron Na Pattalung, Thammasin Ingviya, and Sitthichok Chaichulee. 2021. Feature explanations in recurrent\\nneural networks forpredictingrisk of mortalityin intensivecarepatients. J.Personal.Med. 11,9(2021),934.\\n[151] Arunachalam Narayanaswamy, Subhashini Venugopalan, Dale R. Webster, Lily Peng, Greg S. Corrado, Paisan Ru-\\namviboonsuk,PinalBavishi,MichaelBrenner,PhilipC.Nelson,andAvinashV.Varadarajan.2020.Scientificdiscov-\\nery by generating counterfactuals using image translation. In Proceedings of the 23rd International Conference on\\nMedical Image Computing andComputer AssistedIntervention(MICCAI’20),PartI 23 .Springer, 273–283.\\n[152] Parth Natekar, Avinash Kori, and Ganapathy Krishnamurthi. 2020. Demystifying brain tumor segmentation net-\\nworks: Interpretabilityanduncertainty analysis. Front.Comput. Neurosci. 14(2020),6.\\n[153] MeikeNauta,AnnemarieJutte,JesperProvoost,andChristinSeifert.2021.Thislookslikethat,because...explaining\\nprototypesforinterpretableimagerecognition.In ProceedingsoftheJointEuropeanConferenceonMachineLearning\\nand KnowledgeDiscovery in Databases . Springer,441–456.\\n[154] Ankit Pal and Malaikannan Sankarasubbu. 2021. Pay attention to the cough: Early diagnosis of COVID-19 using\\ninterpretable symptoms embeddings with cough sound signal processing. In Proceedings of the 36th Annual ACM\\nSymposium on Applied Computing .620–628.\\n[155] Cecilia Panigutti, Alan Perotti, and Dino Pedreschi. 2020. Doctor XAI: An ontology-based approach to black-box\\nsequential data classification explanations. In Proceedings of the Conference on', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1333: ('KnowledgeDiscovery in Databases . Springer,441–456.\\n[154] Ankit Pal and Malaikannan Sankarasubbu. 2021. Pay attention to the cough: Early diagnosis of COVID-19 using\\ninterpretable symptoms embeddings with cough sound signal processing. In Proceedings of the 36th Annual ACM\\nSymposium on Applied Computing .620–628.\\n[155] Cecilia Panigutti, Alan Perotti, and Dino Pedreschi. 2020. Doctor XAI: An ontology-based approach to black-box\\nsequential data classification explanations. In Proceedings of the Conference on Fairness, Accountability, and Trans-\\nparency. 629–639.\\n[156] Zachary Papanastasopoulos, Ravi K. Samala, Heang-Ping Chan, Lubomir Hadjiiski, Chintana Paramagul, Mark A.\\nHelvie, and Colleen H. Neal. 2020. Explainable AI for medical imaging: deep-learning CNN ensemble for classifi-\\ncation of estrogen receptor status from breast MRI. In Medical Imaging 2020: Computer-aided Diagnosis , Vol. 11314.\\nInternationalSociety for OpticsandPhotonics, 113140Z.\\n[157] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. Bleu: A method for automatic evaluation\\nof machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics .\\n311–318.\\n[158] Arijit Patra and J. Alison Noble. 2019. Incremental learning of fetal heart anatomies using interpretable saliency\\nmaps.InProceedings oftheAnnual Conferenceon Medical Image Understanding and Analysis .Springer, 129–141.\\n[159] Rahul Paul, Matthew Schabath, Yoganand Balagurunathan, Ying Liu, Qian Li, Robert Gillies, Lawrence O. Hall, and\\nDmitryB.Goldgof.2019.Explainingdeepfeaturesusingradiologist-definedsemanticfeaturesandtraditionalquan-\\ntitativefeatures. Tomography 5,1(2019),192–200.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:43\\n[160] Rahul Paul,MatthewSchabath, RobertGillies,LawrenceHall,andDmitry Goldgof.2020.Convolutional neural net-\\nworkensemblesforaccuratelungnodulemalignancyprediction2yearsinthefuture. Comput.Biol.Med. 122(2020),\\n103882.\\n[161] Martin Pawel', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1334: ('Hall, and\\nDmitryB.Goldgof.2019.Explainingdeepfeaturesusingradiologist-definedsemanticfeaturesandtraditionalquan-\\ntitativefeatures. Tomography 5,1(2019),192–200.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:43\\n[160] Rahul Paul,MatthewSchabath, RobertGillies,LawrenceHall,andDmitry Goldgof.2020.Convolutional neural net-\\nworkensemblesforaccuratelungnodulemalignancyprediction2yearsinthefuture. Comput.Biol.Med. 122(2020),\\n103882.\\n[161] Martin Pawelczyk, Klaus Broelemann, and Gjergji Kasneci. 2020. Learning model-agnostic counterfactual explana-\\ntions for tabulardata.In Proceedings oftheWeb Conference .3126–3132.\\n[162] SérgioPereira,RaphaelMeier,VictorAlves,MauricioReyes,andCarlosA.Silva.2018.Automaticbraintumorgrad-\\ning from MRI data using convolutional neural networks and quality assessment. In Understanding and Interpreting\\nMachine Learning in Medical Image Computing Applications .Springer,106–114.\\n[163] Vitali Petsiuk, Abir Das, and Kate Saenko. 2018. Rise: Randomized input sampling for explanation of black-box\\nmodels.arXiv:1806.07421.Retrievedfrom https://arxiv.org/abs/1806.07421\\n[164] KennethA.Philbrick,KotaroYoshida,DaiInoue,ZeynettinAkkus,TimothyL.Kline,AlexanderD.Weston,Panagio-\\ntisKorfiatis,NaokiTakahashi,andBradleyJ.Erickson.2018.Whatdoesdeeplearningsee?Insightsfromaclassifier\\ntrainedto predictcontrast enhancementphasefrom CTimages. A m .J.R oentg enol. 211,6(2018),1184–1193.\\n[165] Gregory Plumb, Denali Molitor, and Ameet S. Talwalkar. 2018. Model agnostic supervised local explanations. Adv.\\nNeural Inf.Process.Syst. 31(2018).\\n[166] RafaelPoyiadzi,KacperSokol,RaulSantos-Rodriguez,TijlDeBie,andPeterFlach.2020.FACE:Feasibleandaction-\\nablecounterfactualexplanations.In Proceedings of theAAAI/ACMConferenceonAI,Ethics,and Society . 344–350.\\n[167] Xiaofeng Qi, Lei Zhang, Yao Chen, Yong Pi, Yi Chen, Qing Lv, and Zhang Yi. 2019. Automated diagnosis of breast\\nultrasonography imagesusing deep neuralnetworks. Med. Image Anal. 52(2019),185–198.\\n[168] Nazneen', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1335: ('Model agnostic supervised local explanations. Adv.\\nNeural Inf.Process.Syst. 31(2018).\\n[166] RafaelPoyiadzi,KacperSokol,RaulSantos-Rodriguez,TijlDeBie,andPeterFlach.2020.FACE:Feasibleandaction-\\nablecounterfactualexplanations.In Proceedings of theAAAI/ACMConferenceonAI,Ethics,and Society . 344–350.\\n[167] Xiaofeng Qi, Lei Zhang, Yao Chen, Yong Pi, Yi Chen, Qing Lv, and Zhang Yi. 2019. Automated diagnosis of breast\\nultrasonography imagesusing deep neuralnetworks. Med. Image Anal. 52(2019),185–198.\\n[168] Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain Yourself! Leveraging\\nlanguage models for commonsense reasoning. In Proceedings of the 57th Annual Meeting of the Association for Com-\\nputational Linguistics . 4932–4942.\\n[169] Pranav Rajpurkar, Jeremy Irvin, Robyn L. Ball, Kaylie Zhu, Brandon Yang, Hershel Mehta, Tony Duan, Daisy Ding,\\nAartiBagul,CurtisP.Langlotz,etal.2018.Deeplearningforchestradiographdiagnosis:Aretrospectivecomparison\\nof the CheXNeXt algorithm to practicingradiologists. PLoSMed. 15,11(2018),e1002686.\\n[170] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2016.“Whyshoulditrustyou?”Explainingthepredictions\\nofanyclassifier.In Proceedingsofthe22ndACMSIGKDDInternationalConferenceonKnowledgeDiscoveryandData\\nMining. 1135–1144.\\n[171] MarcoTulioRibeiro,SameerSingh,andCarlosGuestrin.2018.Anchors:High-precisionmodel-agnosticexplanations.\\nInProceedings oftheAAAIConferenceonArtificial Intelligence ,V o l .3 2 .\\n[172] LauraRieger,ChandanSingh,WilliamMurdoch,andBinYu.2020.Interpretationsareuseful:Penalizingexplanations\\ntoalignneuralnetworkswithpriorknowledge.In InternationalConferenceonMachineLearning .PMLR,8116–8126.\\n[173] Isabel Rio-Torto, Kelwin Fernandes, and Luís F. Teixeira. 2020. Understanding the decisions of CNNs: An in-model\\napproach. Pattern Recogn. Lett. 133(2020),373–380.\\n[174] IvanRodin,IrinaFedulova,ArtemShelmanov,andDmitryV.Dylov.2019.Multitaskandmultimodalneuralnetwork\\nmodelforinterpretableanalysisofx-rayimages.In ProceedingsoftheIEEEInternationalConferenceonBioin', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1336: ('retationsareuseful:Penalizingexplanations\\ntoalignneuralnetworkswithpriorknowledge.In InternationalConferenceonMachineLearning .PMLR,8116–8126.\\n[173] Isabel Rio-Torto, Kelwin Fernandes, and Luís F. Teixeira. 2020. Understanding the decisions of CNNs: An in-model\\napproach. Pattern Recogn. Lett. 133(2020),373–380.\\n[174] IvanRodin,IrinaFedulova,ArtemShelmanov,andDmitryV.Dylov.2019.Multitaskandmultimodalneuralnetwork\\nmodelforinterpretableanalysisofx-rayimages.In ProceedingsoftheIEEEInternationalConferenceonBioinformatics\\nand Biomedicine (BIBM’19) . IEEE, 1601–1604.\\n[175] Yao Rong, Tobias Leemann, Vadim Borisov, Gjergji Kasneci, and Enkelejda Kasneci. 2022. A consistent and effi-\\ncientevaluationstrategyforattributionmethods.In ProceedingsoftheInternationalConferenceonMachineLearning .\\nPMLR,18770–18795.\\n[176] Cynthia Rudin. 2019. Stop explaining black box machine learning models for high stakes decisions and use inter-\\npretablemodels instead. Nat.Mach. Intell. 1,5(2019),206–215.\\n[177] ZohaibSalahuddin,HenryC.Woodruff,AvishekChatterjee,andPhilippeLambin.2022.Transparencyofdeepneural\\nnetworks for medicalimageanalysis:A review of interpretabilitymethods. Comput.Biol. Med. 140(2022),105111.\\n[178] Md Sirajus Salekin, Ghada Zamzmi, Dmitry Goldgof, Rangachar Kasturi, Thao Ho, and Yu Sun. 2021. Multimodal\\nspatio-temporal deep learning approach for neonatal postoperative pain assessment. Comput. Biol. Med. 129 (2021),\\n104150.\\n[179] WojciechSamek,AlexanderBinder,GrégoireMontavon,SebastianLapuschkin,andKlaus-RobertMüller.2016.Eval-\\nuatingthevisualizationofwhatadeepneuralnetworkhaslearned. IEEETrans.NeuralNetw.Learn.Syst. 28,11(2016),\\n2660–2673.\\n[180] Wojciech Samek, Thomas Wiegand, and Klaus-Robert Müller. 2017. Explainable artificial intelligence: Understand-\\ning,visualizingandinterpretingdeeplearningmodels.tarXiv:1708.08296.Retrievedfrom https://arxiv.org/abs/1708.\\n08296\\n[181] Daniel Sauter, Georg Lodde, Felix Nensa, Dirk Schadendorf, Elisabeth Livingstone, and Markus Kukuk. 2022. Vali-\\ndatingautomaticconcept-based explanationsf', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1337: ('al-\\nuatingthevisualizationofwhatadeepneuralnetworkhaslearned. IEEETrans.NeuralNetw.Learn.Syst. 28,11(2016),\\n2660–2673.\\n[180] Wojciech Samek, Thomas Wiegand, and Klaus-Robert Müller. 2017. Explainable artificial intelligence: Understand-\\ning,visualizingandinterpretingdeeplearningmodels.tarXiv:1708.08296.Retrievedfrom https://arxiv.org/abs/1708.\\n08296\\n[181] Daniel Sauter, Georg Lodde, Felix Nensa, Dirk Schadendorf, Elisabeth Livingstone, and Markus Kukuk. 2022. Vali-\\ndatingautomaticconcept-based explanationsforAI-Based digitalhistopathology. Sensors22,14(2022),5346.\\n[182] Rory Sayres, Ankur Taly, Ehsan Rahimy, Katy Blumer, David Coz, Naama Hammel,Jonathan Krause, Arunachalam\\nNarayanaswamy, Zahra Rastegar, Derek Wu, et al. 2019. Using a deep learning algorithm and integrated gradients\\nexplanationtoassist grading fordiabeticretinopathy. Ophthalmology 126,4(2019),552–564.\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:44 Md I.Hossain etal.\\n[183] Kathryn Schutte, Olivier Moindrot, Paul Hérent, Jean-Baptiste Schiratti, and Simon Jégou. 2021. Using stylegan for\\nvisual interpretability of deep learning models on medical images. arXiv:2101.07563. Retrieved from https://arxiv.\\norg/abs/2101.07563\\n[184] Jarrel C. Y. Seah, Jennifer S. N. Tang, Andy Kitchen, Frank Gaillard, and Andrew F. Dixon. 2019. Chest radiographs\\nin congestiveheart failure:Visualizing neuralnetwork learning. Radiology 290,2(2019),514–522.\\n[185] RamprasaathR.Selvaraju,MichaelCogswell,AbhishekDas,RamakrishnaVedantam,DeviParikh,andDhruvBatra.\\n2017. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE\\nInternational Conference onComputerVision .618–626.\\n[186] MattiaSetzu,RiccardoGuidotti,AnnaMonreale,FrancoTurini,DinoPedreschi,andFoscaGiannotti.2021.Glocalx-\\nfrom localtoglobalexplanationsof blackboxaimodels. Artif. Intell. 294(2021),103457.\\n[187] L.S.Shapley.1953.Avalueforn-persongames.In ContributionstotheTheoryofGames(AM28) ,VolumeII,307–317.\\n[188] Supreeth P. Shashikum', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1338: ('arikh,andDhruvBatra.\\n2017. Grad-cam: Visual explanations from deep networks via gradient-based localization. In Proceedings of the IEEE\\nInternational Conference onComputerVision .618–626.\\n[186] MattiaSetzu,RiccardoGuidotti,AnnaMonreale,FrancoTurini,DinoPedreschi,andFoscaGiannotti.2021.Glocalx-\\nfrom localtoglobalexplanationsof blackboxaimodels. Artif. Intell. 294(2021),103457.\\n[187] L.S.Shapley.1953.Avalueforn-persongames.In ContributionstotheTheoryofGames(AM28) ,VolumeII,307–317.\\n[188] Supreeth P. Shashikumar, Christopher S. Josef, Ashish Sharma, and Shamim Nemati. 2021. DeepAISE–an inter-\\npretableandrecurrent neuralsurvival modelfor earlyprediction of sepsis. Artif.Intell.Med. 113(2021),102036.\\n[189] Sumeet Shinde, Tanay Chougule, Jitender Saini, and Madhura Ingalhalikar. 2019. HR-CAM: Precise localization of\\npathologyusingmulti-levellearninginCNNs.In ProceedingsoftheInternationalConferenceonMedicalImageCom-\\nputing andComputer-AssistedIntervention .Springer, 298–306.\\n[190] Avanti Shrikumar, Peyton Greenside, and Anshul Kundaje. 2017. Learning important features through propagating\\nactivationdifferences. In Proceedings of theInternational ConferenceonMachine Learning . PMLR,3145–3153.\\n[191] Wilson Silva, Alexander Poellinger, Jaime S. Cardoso, and Mauricio Reyes. 2020. Interpretability-guided content-\\nbased medical image retrieval. In Proceedings of the 23rd International Conference on Medical Image Computing and\\nComputer AssistedIntervention(MICCAI’20),Part I23 .Springer, 305–314.\\n[192] Karen Simonyan, Andrea Vedaldi, and Andrew Zisserman. 2014. Deep inside convolutional networks: Visualising\\nimageclassificationmodelsandsaliencymaps.In ProceedingsoftheWorkshopatInternationalConferenceonLearning\\nRepresentations . Citeseer.\\n[193] GurmailSinghandKin-ChoongYow.2021.AninterpretabledeeplearningmodelforCOVID-19detectionwithchest\\nX-ray images. IEEEAccess 9(2021),85198–85208.\\n[194] Sonit Singh, Sarvnaz Karimi, Kevin Ho-Shon, and Len Hamey. 2019. From chest x-rays to radiology reports: A mul-\\ntimodal machine learning appr', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1339: ('Vedaldi, and Andrew Zisserman. 2014. Deep inside convolutional networks: Visualising\\nimageclassificationmodelsandsaliencymaps.In ProceedingsoftheWorkshopatInternationalConferenceonLearning\\nRepresentations . Citeseer.\\n[193] GurmailSinghandKin-ChoongYow.2021.AninterpretabledeeplearningmodelforCOVID-19detectionwithchest\\nX-ray images. IEEEAccess 9(2021),85198–85208.\\n[194] Sonit Singh, Sarvnaz Karimi, Kevin Ho-Shon, and Len Hamey. 2019. From chest x-rays to radiology reports: A mul-\\ntimodal machine learning approach. In Proceedings of the Digital Image Computing: Techniques and Applications\\n(DICTA’19) .IEEE, 1–8.\\n[195] Sumedha Singla, Motahhare Eslami, Brian Pollack, Stephen Wallace, and Kayhan Batmanghelich. 2023. Explaining\\nthe black-boxsmoothly–a counterfactualapproach. Med.Image Anal. 84(2023),102721.\\n[196] Leon Sixt, Maximilian Granz, and Tim Landgraf. 2020. When explanations lie: Why many modified bp attributions\\nfail.InProceedings oftheInternational ConferenceonMachine Learning . PMLR,9046–9057.\\n[197] Daniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Viégas, and Martin Wattenberg. 2017. Smoothgrad: Removing\\nnoise byaddingnoise. arXiv:1706.03825.Retrievedfrom https://arxiv.org/abs/1706.03825\\n[198] J.Springenberg,AlexeyDosovitskiy,ThomasBrox,andM.Riedmiller.2015.Strivingforsimplicity:Theallconvolu-\\ntionalnet.In Proceedings of theICLR(WorkshopTrack) .\\n[199] Chenxi Sun, Hongna Dui, and Hongyan Li. 2021. Interpretable time-aware and co-occurrence-aware network for\\nmedicalprediction. B M CM ed .I n f .Dec i s.M a k i n g 21,1(2021),1–12.\\n[200] Hao Sun, Xianxu Zeng, Tao Xu, Gang Peng, and Yutao Ma. 2019. Computer-aided diagnosis in histopathological\\nimagesoftheendometriumusingaconvolutionalneuralnetworkandattentionmechanisms. IEEEJ.Biomed.Health\\nInf.24,6(2019),1664–1676.\\n[201] Li Sun, Weipeng Wang, Jiyun Li, and Jingsheng Lin. 2019. Study on medical image report generation based on im-\\nprovedencoding-decodingmethod.In Proceedingsofthe15thInternationalConferenceonIntelligentComputingThe-\\nories andApplication (ICIC’19),', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1340: (' i n g 21,1(2021),1–12.\\n[200] Hao Sun, Xianxu Zeng, Tao Xu, Gang Peng, and Yutao Ma. 2019. Computer-aided diagnosis in histopathological\\nimagesoftheendometriumusingaconvolutionalneuralnetworkandattentionmechanisms. IEEEJ.Biomed.Health\\nInf.24,6(2019),1664–1676.\\n[201] Li Sun, Weipeng Wang, Jiyun Li, and Jingsheng Lin. 2019. Study on medical image report generation based on im-\\nprovedencoding-decodingmethod.In Proceedingsofthe15thInternationalConferenceonIntelligentComputingThe-\\nories andApplication (ICIC’19),Part I15 . Springer,686–696.\\n[202] Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In Proceedings of\\ntheInternational Conference onMachine Learning .PMLR,3319–3328.\\n[203] Amirhessam Tahmassebi, Jennifer Martin, Anke Meyer-Baese, and Amir H. Gandomi. 2020. An interpretable deep\\nlearningframeworkforhealthmonitoringsystems:Acasestudyofeyestatedetectionusingeegsignals.In Proceed-\\nings oftheIEEESymposium Series on Computational Intelligence(SSCI’20) . IEEE, 211–218.\\n[204] SarahTan,MatveySoloviev,GilesHooker,andMartinT.Wells.2020.Treespaceprototypes:Anotherlookatmaking\\ntree ensemblesinterpretable.In Proceedings oftheACM-IMSonFoundations ofData Science Conference .23–34.\\n[205] ClaireTang.2020.Discoveringunknowndiseaseswithexplainableautomatedmedicalimaging.In Proceedingsofthe\\n24th AnnualConferenceon Medical Image Understanding andAnalysis (MIUA’20) . Springer, 346–358.\\n[206] Ziqi Tang, Kangway V. Chuang, Charles DeCarli, Lee-Way Jin, Laurel Beckett, Michael J. Keiser, and Brittany N.\\nDugger. 2019. Interpretable classification of Alzheimer’s disease pathologies with a convolutional neural network\\npipeline.Nat.Commun. 10,1(2019),1–14.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:45\\n[207] KaveriA.Thakoor,SharathC.Koorathota,DonaldC.Hood,andPaulSajda.2020.Robustandinterpretableconvolu-\\ntional neural networks to detect glaucoma in optical coherence tomography images. IEEE Trans. Biomed. Eng. 68, 8\\n(2020),2456–246', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1341: ('d Brittany N.\\nDugger. 2019. Interpretable classification of Alzheimer’s disease pathologies with a convolutional neural network\\npipeline.Nat.Commun. 10,1(2019),1–14.\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\nExplainableAIfor Medical Data 148:45\\n[207] KaveriA.Thakoor,SharathC.Koorathota,DonaldC.Hood,andPaulSajda.2020.Robustandinterpretableconvolu-\\ntional neural networks to detect glaucoma in optical coherence tomography images. IEEE Trans. Biomed. Eng. 68, 8\\n(2020),2456–2466.\\n[208] Kaveri A. Thakoor, Xinhui Li, Emmanouil Tsamis, Paul Sajda, and Donald C. Hood. 2019. Enhancing the accuracy\\nof glaucoma detection from OCT probability maps using convolutional neural networks. In Proceedings of the 41st\\nAnnualInternationalConferenceoftheIEEEEngineeringinMedicineandBiologySociety(EMBC’19) .IEEE,2036–2040.\\n[209] JonasTheiner,EricMüller-Budack,andRalphEwerth.2022.Interpretablesemanticphotogeolocation.In Proceedings\\noftheIEEE/CVFWinterConferenceonApplications ofComputer Vision .750–760.\\n[210] Jayaraman J. Thiagarajan, Kowshik Thopalli, Deepta Rajan, and Pavan Turaga. 2022. Training calibration-based\\ncounterfactualexplainersfordeeplearningmodels inmedicalimageanalysis. Sci. Rep.12,1 (2022),1–15.\\n[211] Erico Tjoa and Cuntai Guan. 2020. A survey on explainable artificial intelligence (xai): Toward medical xai. IEEE\\nTrans.Neural Netw.Learn.Syst. 32,11(2020),4793–4813.\\n[212] Kazuki Uehara, Masahiro Murakawa, Hirokazu Nosato, and Hidenori Sakanashi. 2019. Prototype-based interpreta-\\ntion of pathological image analysis by convolutional neural networks. In Proceedings of the Asian Conference on\\nPattern Recognition . Springer, 640–652.\\n[213] LaurensVan der MaatenandGeoffrey Hinton. 2008.Visualizing datausing t-SNE. J.Mach. Learn.Res. 9,11(2008).\\n[214] BasH.M.vanderVelden,MarkusH.A.Janse,MaxA.A.Ragusi,ClaudetteE.Loo,andKennethG.A.Gilhuijs.2020.\\nVolumetric breastdensityestimationon MRIusing explainabledeep learningregression. Sci. Rep.10,1 (2020),1–9.\\n[215] Bas H. M. van der Velden, Hugo J. Kuijf, K', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1342: ('athological image analysis by convolutional neural networks. In Proceedings of the Asian Conference on\\nPattern Recognition . Springer, 640–652.\\n[213] LaurensVan der MaatenandGeoffrey Hinton. 2008.Visualizing datausing t-SNE. J.Mach. Learn.Res. 9,11(2008).\\n[214] BasH.M.vanderVelden,MarkusH.A.Janse,MaxA.A.Ragusi,ClaudetteE.Loo,andKennethG.A.Gilhuijs.2020.\\nVolumetric breastdensityestimationon MRIusing explainabledeep learningregression. Sci. Rep.10,1 (2020),1–9.\\n[215] Bas H. M. van der Velden, Hugo J. Kuijf, Kenneth G. A. Gilhuijs, and Max A. Viergever. 2022. Explainable artificial\\nintelligence(XAI) in deeplearning-basedmedicalimageanalysis. Med.Image Anal. (2022),102470.\\n[216] AshishVaswani,NoamShazeer,NikiParmar,JakobUszkoreit,LlionJones,AidanN.Gomez,ŁukaszKaiser,andIllia\\nPolosukhin. 2017.Attentionis allyou need. Adv.Neural Inf.Process.Syst. 30(2017).\\n[217] Ramakrishna Vedantam, C. Lawrence Zitnick, and Devi Parikh. 2015. Cider: Consensus-based image description\\nevaluation. In Proceedings oftheIEEEConferenceonComputerVision andPattern Recognition . 4566–4575.\\n[218] SahilVerma,JohnDickerson,andKeeganHines.2020.Counterfactualexplanationsformachinelearning:Areview.\\narXiv:2010.10596.Retrievedfrom https://arxiv.org/abs/2010.10596\\n[219] Giulia Vilone and Luca Longo. 2020. Explainable artificial intelligence: A systematic review. arXiv:2006.00093. Re-\\ntrievedfrom https://arxiv.org/abs/2006.00093\\n[220] Lituan Wang, Lei Zhang, Minjuan Zhu, Xiaofeng Qi, and Zhang Yi. 2020. Automatic diagnosis for thyroid nodules\\ninultrasound imagesbydeep neural networks. Med.Image Anal. 61(2020),101665.\\n[221] SenWang,YuxiangXing,LiZhang,HeweiGao,andHaoZhang.2019.Deepconvolutionalneuralnetworkforulcer\\nrecognition in wireless capsule endoscopy: Experimental feasibility and optimization. Comput. Math. Methods Med.\\n2019(2019).\\n[222] SutongWang,YunqiangYin,DujuanWang,YanzhangWang,andYaochuJin.2021.Interpretability-basedmultimodal\\nconvolutional neuralnetworks for skin lesion diagnosis. IEEETrans.Cybernet. 52,12(2021),12623–12637.\\n[223] Shengjie W', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1343: ('und imagesbydeep neural networks. Med.Image Anal. 61(2020),101665.\\n[221] SenWang,YuxiangXing,LiZhang,HeweiGao,andHaoZhang.2019.Deepconvolutionalneuralnetworkforulcer\\nrecognition in wireless capsule endoscopy: Experimental feasibility and optimization. Comput. Math. Methods Med.\\n2019(2019).\\n[222] SutongWang,YunqiangYin,DujuanWang,YanzhangWang,andYaochuJin.2021.Interpretability-basedmultimodal\\nconvolutional neuralnetworks for skin lesion diagnosis. IEEETrans.Cybernet. 52,12(2021),12623–12637.\\n[223] Shengjie Wang, Tianyi Zhou, and Jeff Bilmes. 2019. Bias also matters: Bias attribution for deep neural network\\nexplanation.In Proceedings oftheInternational ConferenceonMachine Learning . PMLR,6659–6667.\\n[224] XiWang,HaoChen,An-RanRan,LuyangLuo,PoemenP.Chan,ClementC.Tham,RobertT.Chang,SuriaS.Mannil,\\nCarol Y. Cheung, and Pheng-Ann Heng. 2020. Towards multi-center glaucoma OCT image screening with semi-\\nsupervised jointstructure andfunctionmulti-task learning. Med.Image Anal. 63(2020),101695.\\n[225] Xiaosong Wang, Yifan Peng, Le Lu, Zhiyong Lu, and Ronald M. Summers. 2018. Tienet: Text-image embedding\\nnetworkforcommonthoraxdiseaseclassificationandreportinginchestx-rays.In ProceedingsoftheIEEEConference\\non Computer Vision andPattern Recognition . 9049–9058.\\n[226] KristofferWickstrøm,MichaelKampffmeyer,andRobertJenssen.2020.Uncertaintyandinterpretabilityinconvolu-\\ntionalneuralnetworks for semanticsegmentationof colorectalpolyps. Med. Image Anal. 60(2020),101619.\\n[227] Paul Windisch, Pascal Weber, Christoph Fürweger, Felix Ehret, Markus Kufeld, Daniel Zwahlen, and Alexander\\nMuacevic.2020.Implementationofmodelexplainabilityforabasicbraintumordetectionusingconvolutionalneural\\nnetworks on MRIslices. Neuroradiology 62,11(2020),1515–1518.\\n[228] Eloise Withnell, Xiaoyu Zhang, Kai Sun, and Yike Guo. 2021. XOmiVAE: An interpretable deep learning model for\\ncancerclassification using high-dimensional omicsdata. Brief. Bioinf. 22,6(2021),bbab315.\\n[229] SvanteWold,KimEsbensen,andPaulGeladi.1987.Principalcomponentanalysis. Chemometr.Intell', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1344: ('hret, Markus Kufeld, Daniel Zwahlen, and Alexander\\nMuacevic.2020.Implementationofmodelexplainabilityforabasicbraintumordetectionusingconvolutionalneural\\nnetworks on MRIslices. Neuroradiology 62,11(2020),1515–1518.\\n[228] Eloise Withnell, Xiaoyu Zhang, Kai Sun, and Yike Guo. 2021. XOmiVAE: An interpretable deep learning model for\\ncancerclassification using high-dimensional omicsdata. Brief. Bioinf. 22,6(2021),bbab315.\\n[229] SvanteWold,KimEsbensen,andPaulGeladi.1987.Principalcomponentanalysis. Chemometr.Intell.Lab.Syst. 2,1-3\\n(1987),37–52.\\n[230] BotongWu,ZhenZhou,JianweiWang,andYizhouWang.2018.Jointlearningforpulmonarynodulesegmentation,\\nattributesandmalignancyprediction.In ProceedingsoftheIEEE15thInternationalSymposiumonBiomedicalImaging\\n(ISBI’18). IEEE, 1109–1113.\\n[231] T.Wu,M.TulioRibeiro,J.Heer,andD.Weld.2021.Polyjuice:Generatingcounterfactualsforexplaining,evaluating,\\nand improving models. In Proceedings of the Joint Conference of the 59th Annual Meeting of the Association for Com-\\nputational Linguistics and the11th International JointConferenceon Natural Language Processing (ACL-IJCNLP’21) .\\nACM ComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.\\n148:46 Md I.Hossain etal.\\n[232] GabrielleRas,NingXie,MarcelVanGerven,andDerekDoran.2020.Explainabledeeplearning:Afieldguideforthe\\nuninitiated. Journal of Artificial Intelligence Research 73(2022),329–396.\\n[233] KelvinXu,JimmyBa,RyanKiros,KyunghyunCho,AaronCourville,RuslanSalakhudinov,RichZemel,andYoshua\\nBengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. In Proceedings of the\\nInternational Conference on Machine Learning .PMLR,2048–2057.\\n[234] Weizheng Yan, Sergey Plis, Vince D. Calhoun, Shengfeng Liu, Rongtao Jiang, Tian-Zi Jiang, and Jing Sui. 2017. Dis-\\ncriminatingschizophreniafromnormalcontrolsusingrestingstatefunctionalnetworkconnectivity:Adeepneural\\nnetwork and layer-wise relevance propagation method. In Proceedings of the IEEE 27th International Workshop on\\nMachine Learning for Signal Processing (MLSP', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1345: ('al image caption generation with visual attention. In Proceedings of the\\nInternational Conference on Machine Learning .PMLR,2048–2057.\\n[234] Weizheng Yan, Sergey Plis, Vince D. Calhoun, Shengfeng Liu, Rongtao Jiang, Tian-Zi Jiang, and Jing Sui. 2017. Dis-\\ncriminatingschizophreniafromnormalcontrolsusingrestingstatefunctionalnetworkconnectivity:Adeepneural\\nnetwork and layer-wise relevance propagation method. In Proceedings of the IEEE 27th International Workshop on\\nMachine Learning for Signal Processing (MLSP’17) .IEEE, 1–6.\\n[235] Guang Yang, Qinghao Ye, and Jun Xia. 2022. Unbox the black-box for the medical explainable AI via multi-modal\\nandmulti-centre datafusion: A mini-review,twoshowcases andbeyond. Inf.Fusion 77(2022),29–52.\\n[236] Hugo Yeche, Justin Harrison, and Tess Berthier. 2019. UBS: A dimension-agnostic metric for concept vector inter-\\npretability applied to radiomics. In Interpretability of Machine Intelligence in Medical Image Computing and Multi-\\nmodal Learning for Clinical Decision Support . Springer,12–20.\\n[237] Chih-Kuan Yeh, Been Kim, Sercan Arik, Chun-Liang Li, Tomas Pfister, and Pradeep Ravikumar. 2020. On\\ncompleteness-aware concept-based explanations in deep neural networks. Adv. Neural Inf. Process. Syst. 33 (2020),\\n20554–20565.\\n[238] ChangchangYin,BuyueQian,JishangWei,XiaoyuLi,XianliZhang,YangLi,andQinghuaZheng.2019.Automatic\\ngeneration of medical imaging diagnostic report with hierarchical recurrent neural network. In Proceedings of the\\nIEEEInternational ConferenceonData Mining (ICDM’19) .IEEE, 728–737.\\n[239] Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. 2019. Gnnexplainer: Generating\\nexplanationsforgraph neuralnetworks. Adv.Neural Inf.Process.Syst. 32(2019).\\n[240] KyleYoung,GarethBooth,BecksSimpson,ReubenDutton,andSallyShrapnel.2019.Deepneuralnetworkorderma-\\ntologist?In InterpretabilityofMachineIntelligenceinMedicalImageComputingandMultimodalLearningforClinical\\nDecision Support . Springer, 48–55.\\n[241] Matthew D. Zeiler and Rob Fergus. 2014. Visualizing and u', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1346: ('IEEE, 728–737.\\n[239] Zhitao Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. 2019. Gnnexplainer: Generating\\nexplanationsforgraph neuralnetworks. Adv.Neural Inf.Process.Syst. 32(2019).\\n[240] KyleYoung,GarethBooth,BecksSimpson,ReubenDutton,andSallyShrapnel.2019.Deepneuralnetworkorderma-\\ntologist?In InterpretabilityofMachineIntelligenceinMedicalImageComputingandMultimodalLearningforClinical\\nDecision Support . Springer, 48–55.\\n[241] Matthew D. Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In Proceedings of\\ntheEuropean ConferenceonComputer Vision .Springer, 818–833.\\n[242] Bofei Zhang, Jimin Tan, Kyunghyun Cho, Gregory Chang, and Cem M. Deniz. 2020. Attention-based cnn for kl\\ngrade classification: Data from the osteoarthritis initiative. In Proceedings of the IEEE 17th International Symposium\\non Biomedical Imaging (ISBI’20) . IEEE, 731–735.\\n[243] Jianming Zhang, Sarah Adel Bargal, Zhe Lin, Jonathan Brandt, Xiaohui Shen, and Stan Sclaroff. 2018. Top-down\\nneural attentionbyexcitationbackprop. Int.J.Comput.Vis. 126,10(2018),1084–1102.\\n[244] Jing Zhang, Caroline Petitjean, Florian Yger, and Samia Ainouz. 2020. Explainability for regression CNN in fetal\\nheadcircumferenceestimationfromultrasoundimages.In InterpretableandAnnotation-EfficientLearningforMedical\\nImage Computing . Springer,73–82.\\n[245] Quanshi Zhang, Yu Yang, Haotian Ma, and Ying Nian Wu. 2019. Interpreting cnns via decision trees. In Proceedings\\nof theIEEE/CVFConferenceonComputer VisionandPattern Recognition . 6261–6270.\\n[246] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2019. BERTScore: Evaluating text\\ngenerationwith BERT.In Proceedings oftheInternational ConferenceonLearning Representations .\\n[247] ZizhaoZhang,YuanpuXie,FuyongXing,MasonMcGough,andLinYang.2017.Mdnet:Asemanticallyandvisually\\ninterpretablemedicalimagediagnosisnetwork.In ProceedingsoftheIEEEConferenceonComputerVisionandPattern\\nRecognition . 6428–6436.\\n[248] Guannan Zhao, Bo Zhou, Kaiwen Wang, Rui Jiang, and', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1347: ('nition . 6261–6270.\\n[246] Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q. Weinberger, and Yoav Artzi. 2019. BERTScore: Evaluating text\\ngenerationwith BERT.In Proceedings oftheInternational ConferenceonLearning Representations .\\n[247] ZizhaoZhang,YuanpuXie,FuyongXing,MasonMcGough,andLinYang.2017.Mdnet:Asemanticallyandvisually\\ninterpretablemedicalimagediagnosisnetwork.In ProceedingsoftheIEEEConferenceonComputerVisionandPattern\\nRecognition . 6428–6436.\\n[248] Guannan Zhao, Bo Zhou, Kaiwen Wang, Rui Jiang, and Min Xu. 2018. Respond-cam: Analyzing deep models for\\n3d imaging data by visualizations. In Proceedings of the International Conference on Medical Image Computing and\\nComputer-Assisted Intervention .Springer,485–492.\\n[249] Kaiping Zheng, Shaofeng Cai, Horng Ruey Chua, Wei Wang, Kee Yuan Ngiam, and Beng Chin Ooi. 2020. Tracer: A\\nframeworkforfacilitatingaccurateandinterpretableanalyticsforhighstakesapplications.In Proceedingsofthe2020\\nACMSIGMODInternational ConferenceonManagement ofData . 1747–1763.\\n[250] Bolei Zhou, Aditya Khosla, Agata Lapedriza, Aude Oliva, and Antonio Torralba. 2016. Learning deep features\\nfor discriminative localization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition .\\n2921–2929.\\n[251] Jun-YanZhu,TaesungPark,PhillipIsola,andAlexeiA.Efros.2017.Unpairedimage-to-imagetranslationusingcycle-\\nconsistent adversarial networks. In Proceedings oftheIEEEInternational ConferenceonComputer Vision .2223–2232.\\nReceived 14 October 2022; revised 28 August 2023; accepted 1December 2023\\nACMComputingSurveys, Vol. 57,No.6,Article 148.Publicationdate:February 2025.', 'Explainable AI for Medical Data- Current Methods, Limitations, and Future Directions.pdf'), 1348: ('ILLUMINATIONS\\nTeaching in an Era of Generative Artificial Intelligence\\nThe ChatGPT Fact-Check: exploiting the limitations of generative AI to develop\\nevidence-based reasoning skills in college science courses\\nUrsula Holzmann, Sulekha Anand, and\\n Alexander Y. Payumo\\nDepartment of Biological Sciences, San Jose State University, San Jose, California, United States\\nAbstract\\nGenerative large language models (LLMs) like ChatGPT can quickly produce informative essays on various topics. However, the\\ninformation generated cannot be fully trusted, as arti ﬁcial intelligence (AI) can make factual mistakes. This poses challenges for\\nusing such tools in college classrooms. To address this, an adaptable assignment called the ChatGPT Fact-Check was devel-\\noped to teach students in college science courses the bene ﬁts of using LLMs for topic exploration while emphasizing the impor-\\ntance of validating their claims based on evidence. The assignment requires students to use ChatGPT to generate essays,evaluate AI-generated sources, and assess the validity of AI-generated scienti ﬁc claims (based on experimental evidence in pri-\\nmary sources). The assignment reinforces student learning around responsible AI use for exploration while maintaining evi-dence-based skepticism. The assignment meets objectives around ef ﬁciently leveraging bene ﬁcial features of AI, distinguishing\\nevidence types, and evidence-based claim evaluation. Its adaptable nature allows integration across diverse courses to teachstudents to responsibly use AI for learning while maintaining a critical stance.\\nNEW & NOTEWORTHY Generative large language models (LLMs) (e.g., ChatGPT) often produce erroneous information unsup-\\nported by scienti ﬁc evidence. This article outlines how these limitations may be leveraged to develop critical thinking and teach\\nstudents the importance of evaluating claims based on experimental evidence. Additionally, the activity highlights positiveaspects of generative AI to ef ﬁciently explore new topics of interest, while maintaining skepti', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1349: ('learning while maintaining a critical stance.\\nNEW & NOTEWORTHY Generative large language models (LLMs) (e.g., ChatGPT) often produce erroneous information unsup-\\nported by scienti ﬁc evidence. This article outlines how these limitations may be leveraged to develop critical thinking and teach\\nstudents the importance of evaluating claims based on experimental evidence. Additionally, the activity highlights positiveaspects of generative AI to ef ﬁciently explore new topics of interest, while maintaining skepticism.\\nartiﬁcial intelligence; critical thinking; evidence-based reasoning; source evaluation; topic exploration\\nINTRODUCTION\\nGenerative arti ﬁcial intelligence (AI) encompasses a broad\\nspectrum of technologies that create content of various for-mats. Speci ﬁcally, large language models (LLMs), which\\ninclude generative pretrained transformers (GPTs) such asChatGPT by OpenAI, have revolutionized text-based tasks,ranging from searching for information on any topic, to writ-ing computer code, to generating prose. For most of thesetasks, LLMs produce fast and informative results and can\\noften serve as a time-saving shortcut for laborious internet\\nsearches, compilation of information from multiple sour-ces, writing, and grammar checking. Therefore, generativeAI technologies may facilitate learning about speci ﬁc\\ntopics and studying ( 1) and are popular in science and\\nmedicine.\\nIn the college classroom, however, numerous concerns are\\nassociated with the use of generative AI by students, and theline between original creation and plagiarism is blurred andoften misunderstood. Students regularly submit essays andassignments that have been partially or entirely completedwith tools like ChatGPT, which would usually be considered\\nacademic dishonesty in addition to precluding many impor-tant aspects of the learning, creative, and analytical proc-esses ( 2,3). Students, faculty, and institutions of higher\\neducation must carefully navigate and outline the fair use ofAI, and students require guidance on academic integrity inthis', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1350: ('creation and plagiarism is blurred andoften misunderstood. Students regularly submit essays andassignments that have been partially or entirely completedwith tools like ChatGPT, which would usually be considered\\nacademic dishonesty in addition to precluding many impor-tant aspects of the learning, creative, and analytical proc-esses ( 2,3). Students, faculty, and institutions of higher\\neducation must carefully navigate and outline the fair use ofAI, and students require guidance on academic integrity inthis realm. Indeed, there is a range of permissiveness in col-lege course syllabi; a curated list of syllabus policies pertain-ing to the use of AI is available at https://docs.google.com/\\ndocument/d/1RMVwzjc1o0Mi8Blw_-JUTcXv02b2WRH86vw\\n7mi16W3U/edit#heading=h.1cykjn2vg2wx . The majority of\\nsyllabi examined freely allow the use of generative AI by stu-dents ( /C2443%), whereas /C2430% disallow it and /C2427% entail a\\nconditional or limited allowance of generative AI. It is possi-ble that these numbers will shift as faculty learn more aboutgenerative AI. However, many faculty are yet to include anysyllabus policy addressing the use of generative AI in theirclasses for various reasons.\\nOf additional concern is the accuracy of information pro-\\nvided in the response to a generative AI prompt. LLMs arebuilt on deep learning models that generate text based on\\nCorrespondence: A. Y. Payumo (Alexander.Payumo@sjsu.edu).\\nSubmitted 15 July 2024 / Revised 27 August 2024 / Accepted 10 January 2025\\n1043-4046/25 Copyright ©2025 The Authors. Licensed under Creative Commons Attribution CC-BY-NC 4.0 .\\nPublished by the American Physiological Society.191\\nAdv Physiol Educ 49: 191 –196, 2025.\\nFirst published January 18, 2025; doi: 10.1152/advan.00142.2024\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nlanguage patterns learned in their pretraining datasets.\\nTherefore, information in their responses, as well as sources\\nin the response, can be inaccurate or even false, ', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1351: ('The Authors. Licensed under Creative Commons Attribution CC-BY-NC 4.0 .\\nPublished by the American Physiological Society.191\\nAdv Physiol Educ 49: 191 –196, 2025.\\nFirst published January 18, 2025; doi: 10.1152/advan.00142.2024\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nlanguage patterns learned in their pretraining datasets.\\nTherefore, information in their responses, as well as sources\\nin the response, can be inaccurate or even false, termed “hal-\\nlucination ”(4–6). In a detailed evaluation of ChatGPT-gener-\\nated review articles on speci ﬁc musculoskeletal research\\ntopics, a recent study reports that up to 70% of references\\ncited were inaccurate and could mislead readers ( 7). If stu-\\ndents rely on generative AI for learning, studying, and com-pleting assignments rather than their ability to evaluate andunderstand information, they run the risk of blindly believ-\\ning the text that is generated, as well as learning and propa-\\ngating misinformation. In many cases, citations provided inscienti ﬁc essays generated by ChatGPT are irrelevant to the\\nstated facts ( 8).\\nThe potential and limitations of generative AI for learning\\nby students enrolled in college science courses, along with\\nthe importance of evidence-based reasoning skills in science,motivated us to develop an adaptable assignment in whichstudents critically assess the validity of evidence used to sup-port the claims made in an essay written by ChatGPT ( 9–12).\\nGenerative AI is ubiquitous, making it important for collegestudents to be able to parse and evaluate the informationprovided in responses to a prompt. Science students mustmaster evidence-based reasoning skills, know the impor-tance of valid and relevant citations, and evaluate thevalidity of empirical evidence for scienti ﬁc claims. These\\nskills are critical for evaluating scienti ﬁc information and\\nworking as a scientist. The assignment therefore required\\nstudents to generate essays on scienti ﬁc topics using\\nChatGPT and then ', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1352: ('tous, making it important for collegestudents to be able to parse and evaluate the informationprovided in responses to a prompt. Science students mustmaster evidence-based reasoning skills, know the impor-tance of valid and relevant citations, and evaluate thevalidity of empirical evidence for scienti ﬁc claims. These\\nskills are critical for evaluating scienti ﬁc information and\\nworking as a scientist. The assignment therefore required\\nstudents to generate essays on scienti ﬁc topics using\\nChatGPT and then evaluate the cited evidence for the\\nclaims made in the essay.\\nCONTEXT\\nHere we describe the assignment, the “ChatGPT Fact-\\nCheck, ”which we implemented in ﬁve different college\\ncourses: a lower-division introductory biology course,\\nPrinciples of Biology; a lower-division general education\\ncourse, Ecological Biology; an upper-division majors course,\\nBiogeography; an upper-division required majors course,\\nCellular and Molecular Physiology; and an upper-division\\nmajors elective course, Vertebrate Neurophysiology. Although\\nmodiﬁcations were made to tailor the assignment for each\\nclass, all students engaged in the same central core activities:\\nuse of an LLM (i.e., ChatGPT) to explore a new topic of interest\\nand generate an essay with in-text citations, evaluation of\\nLLM-generated sources, and assessment of LLM-generated\\nclaims based on evidence ( Fig. 1 ).\\nAfter completing the assignment, we expect that students\\nwill have accomplished the following learning objectives:\\nFigure 1. Flow of tasks for the ChatGPT Fact-Check activity. General steps are indicated in the boxes, and the bullet points exemplify the adaptations\\nmade for the Cellular and Molecular Physiology course. These steps are further illustrated in Tables 1 –5. CFTR, cystic ﬁbrosis transmembrane conduct-\\nance regulator.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\n192 Advances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1353: ('heck activity. General steps are indicated in the boxes, and the bullet points exemplify the adaptations\\nmade for the Cellular and Molecular Physiology course. These steps are further illustrated in Tables 1 –5. CFTR, cystic ﬁbrosis transmembrane conduct-\\nance regulator.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\n192 Advances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\n1) Understand the value of ChatGPT and other similar\\nLLMs to explore a new topic of interest quickly.\\n2) Realize that ChatGPT can make mistakes; therefore, the\\ninformation generated cannot be blindly trusted.\\n3) Accurately differentiate between types of evidence cited\\nby ChatGPT to support its statements.\\n4) Critically evaluate the validity of a claim based on exper-\\nimental evidence provided in primary research articles.\\nIn the following sections, we share a speci ﬁce x a m p l eo f\\nthis work ﬂow from the Cellular and Molecular Physiology\\ncourse.\\nCellular and Molecular Physiology is an upper-division\\ncourse required for all systems physiology majors at ourinstitution. Enrollment is typically 30 –40 junior and sen-\\nior students. An overall theme in the course is to high-light how cellular and molecular defects result insystems-level dysfunction. Monogenic diseases are dis-orders caused by mutations in a single gene ( 13).\\nExploring the molecular underpinnings driving thesediseases may engage students to better connect howchanges in DNA sequence cause perturbations in cellularfunction that lead to disruptions in physiological homeo-\\nstasis. We designed a ChatGPT Fact-Check activity to\\nteach students the bene ﬁts of using generative AI for\\ntopic exploration while also emphasizing the importanceof validating its claims based on evidence. We present aspeci ﬁc example of this activity to show students how\\nChatGPT may be used to quickly investigate the molecu-lar and cellular etiol', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1354: ('iseases may engage students to better connect howchanges in DNA sequence cause perturbations in cellularfunction that lead to disruptions in physiological homeo-\\nstasis. We designed a ChatGPT Fact-Check activity to\\nteach students the bene ﬁts of using generative AI for\\ntopic exploration while also emphasizing the importanceof validating its claims based on evidence. We present aspeci ﬁc example of this activity to show students how\\nChatGPT may be used to quickly investigate the molecu-lar and cellular etiology underlying a monogenic diseaseof interest and corroborate AI-generated claims with ex-perimental evidence.\\nTwo 75-min class periods are scheduled for the activity.\\nTheﬁrst class period is devoted entirely to organizing stu-\\ndents in groups and instructing them to use ChatGPT toselect a monogenic disease of interest, generate backgroundessays to familiarize them with the disease quickly, and thenproduce subtopic-focused essays with in-text citations forfurther analysis ( Tables 1 –3). Students are then expected to\\nevaluate all ChatGPT-provided sources ( Table 4 ) and corrob-\\norate a claim based on experimental evidence from primaryresearch articles ( Table 5 ), followed by a postactivity re ﬂec-\\ntion. The second class period is reserved to summarize theactivity, with a portion of the class dedicated to opening a\\ndiscussion in which students share their experiences using\\nChatGPT with their peers.\\nTOPIC IDENTIFICATION AND EXPLORATION\\nIn groups of three or four, students are ﬁrst tasked to use\\nChatGPT to quickly generate a list of known monogenic dis-\\neases and the genes affected ( Table 1 ). Each group then choo-\\nses a single disease for further exploration. In our example\\nassignment, which we generated, we investigate cystic ﬁbro-\\nsis and its associated gene, cystic ﬁbrosis transmembrane\\nconductance regulator (CFTR).\\nAfter selecting a monogenic disease to pursue, each group\\nthen asks ChatGPT to quickly generate a background essay\\nthat provides them with a general overview of their chosen\\ntopic. When asked to ', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1355: ('kly generate a list of known monogenic dis-\\neases and the genes affected ( Table 1 ). Each group then choo-\\nses a single disease for further exploration. In our example\\nassignment, which we generated, we investigate cystic ﬁbro-\\nsis and its associated gene, cystic ﬁbrosis transmembrane\\nconductance regulator (CFTR).\\nAfter selecting a monogenic disease to pursue, each group\\nthen asks ChatGPT to quickly generate a background essay\\nthat provides them with a general overview of their chosen\\ntopic. When asked to elaborate on the role of CFTR in cystic\\nﬁbrosis, ChatGPT generated an essay comprised of many dif-\\nferent subtopics ( Table 2 ), one of which pertained to a com-\\nmon CFTR mutation, F508del, which was stated to account\\nfor the majority of cystic ﬁbrosis cases worldwide. All stu-\\ndents in the group are instructed to review this background\\nessay to better familiarize themselves with their chosen\\nmonogenic disease.\\nAI-GENERATED CLAIMS AND CITATIONS\\nAfter they become familiar with their chosen disease,\\neach student in the group selects a unique subtopic identi-\\nﬁed within the general background essay that they wish to\\ninvestigate individually. Subtopics may range from explor-\\ning the function of the protein encoded by the affected\\ngene to the molecular mechanisms of currently used treat-\\nments. Students next ask ChatGPT to generate a new essay\\nthat elaborates on their chosen subtopic and includes in-\\ntext citations for all statements made ( Table 3 ). In our\\nexample, ChatGPT produced an essay about how the\\nF508del mutant impairs CFTR function consisting of mul-\\ntiple statements associated with in-text citations. In the\\nTable 1. Topic identi ﬁcation\\nPrompt\\nGenerate a list of currently known monogenic diseases and genes\\naffected.\\nChatGPT /C3response (excerpt)\\nAs of my last update in January 2022, here is a list of some known\\nmonogenic diseases along with the corresponding genes affected:\\n1) Cystic ﬁbrosis (CFTR gene)\\n2) Duchenne muscular dystrophy (DMD gene)\\n3) Huntington ’s disease (HTT gene)\\n4) Hemophilia (F8 gene f', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1356: (' mutant impairs CFTR function consisting of mul-\\ntiple statements associated with in-text citations. In the\\nTable 1. Topic identi ﬁcation\\nPrompt\\nGenerate a list of currently known monogenic diseases and genes\\naffected.\\nChatGPT /C3response (excerpt)\\nAs of my last update in January 2022, here is a list of some known\\nmonogenic diseases along with the corresponding genes affected:\\n1) Cystic ﬁbrosis (CFTR gene)\\n2) Duchenne muscular dystrophy (DMD gene)\\n3) Huntington ’s disease (HTT gene)\\n4) Hemophilia (F8 gene for Hemophilia A, F9 gene for Hemophilia B)\\n5) Sickle cell disease (HBB gene)\\n6) Tay –Sachs disease (HEXA gene)\\n7) Phenylketonuria (PKU) (PAH gene)\\n8) Marfan syndrome (FBN1 gene)\\n9) Fragile X syndrome (FMR1 gene)\\n10) Spinal muscular atrophy (SMA) (SMN1 gene)\\nBoldface indicates the example used in the text. /C3ChatGPT 3.5\\n(openai.com ); accessed February 2024.Table 2. Topic exploration\\nPrompt\\nEssay on CFTR function and its role in cystic ﬁbrosis\\nChatGPT /C3Response (excerpt)\\nTitle: CFTR Function and Its Role in Cystic Fibrosis\\nIntroduction:\\nCystic ﬁbrosis (CF) is a hereditary disorder characterized by the dys-\\nfunction of the cystic ﬁbrosis transmembrane conductance regulator\\n(CFTR) protein. CFTR plays a pivotal role in regulating the ﬂow of\\nchloride ions across cell membranes. Dysfunction of CFTR leads to\\nthe accumulation of thick, sticky mucus in various organs, particularlyaffecting the respiratory and digestive systems. This essay exploresthe function of CFTR and its critical role in the pathogenesis of cystic\\nﬁbrosis.\\nRole of CFTR Dysfunction in Cystic Fibrosis:Mutations in the CFTR gene result in defective CFTR protein produc-\\ntion or impaired function, leading to the development of cystic ﬁbro-\\nsis. Over 2,000 mutations have been identi ﬁed in the CFTR gene,\\nwith varying degrees of impact on protein function. The most com-\\nmon mutation associated with CF is the deletion of phenylalanineat position 508 (F508del), which accounts for approximately two-\\nthirds of CF cases worldwide.\\nBoldface indicates the exam', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1357: ('tic\\nﬁbrosis.\\nRole of CFTR Dysfunction in Cystic Fibrosis:Mutations in the CFTR gene result in defective CFTR protein produc-\\ntion or impaired function, leading to the development of cystic ﬁbro-\\nsis. Over 2,000 mutations have been identi ﬁed in the CFTR gene,\\nwith varying degrees of impact on protein function. The most com-\\nmon mutation associated with CF is the deletion of phenylalanineat position 508 (F508del), which accounts for approximately two-\\nthirds of CF cases worldwide.\\nBoldface indicates the example used in the text. /C3ChatGPT 3.5\\n(openai.com ); accessed February 2024.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\nAdvances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org 193\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nassignment context, each pairing of an AI-generated state-\\nment and citation is considered a “claim. ”For example,\\none claim in the essay suggests that the F508del mutationcauses the CFTR protein to become trapped within theendoplasmic reticulum and undergo rapid degradation by\\nthe ubiquitin-proteasome system, citing Ward et al. (1995)\\nas a reference. Although the essay generated is rich withinformation and may help guide students to discover themolecular mechanisms underlying their chosen disease,they must learn to not blindly trust AI-generated information.To build this skepticism, students next analyze the citationsgenerated by ChatGPT.\\nDISTINGUISHING TYPES OF SOURCES\\nThe subtopic essays described above likely comprise\\nseveral statements supported by AI-generated citations.Students need to discern between types of sources andunderstand that some are more credible than others.Students should also be able to differentiate between pri-mary and secondary literature and place emphasis on ex-perimental evidence from primary research articles tosubstantiate claims. To develop their abilities to distin-guish between different types of evidence, students are\\ntasked to clo', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1358: ('SOURCES\\nThe subtopic essays described above likely comprise\\nseveral statements supported by AI-generated citations.Students need to discern between types of sources andunderstand that some are more credible than others.Students should also be able to differentiate between pri-mary and secondary literature and place emphasis on ex-perimental evidence from primary research articles tosubstantiate claims. To develop their abilities to distin-guish between different types of evidence, students are\\ntasked to closely examine each citation provided by\\nChatGPT ( Table 4 ). Since LLMs may generate incorrect in-\\nformation, students ﬁrst determine whether the AI-cited\\nsource is real. In our example, we determined that one ref-erence provided by ChatGPT did not exist. Although an ar-ticle titled “Protein quality control in the secretory\\npathway ”was indeed published in the Journal of CellBiology , the authors, year of publication, and journal\\nindexing were all misreported. By actively discovering\\nthese inconsistencies, a time-consuming and laborious\\nprocess, students may develop a sense of skepticism about\\nusing generative AI. They also gain experience in search-\\ning for sources. After determining the validity of the\\nsource, students then identify the type of source cited: pri-\\nmary research article, review article, commentary, opin-\\nion, editorial, news article, webpage, or something else.\\nThe ability of students to accurately evaluate and distin-\\nguish different types of sources can be assessed for credit\\nif desired.\\nEVIDENCE-BASED REASONING FOR CLAIM\\nEVALUATION\\nAfter assessing the different sources cited by ChatGPT,\\nstudents next evaluate the evidence provided by an identi-\\nﬁed primary research article and determine whether the\\nreported results support or refute the associated claim. In\\nsome instances, the essay generated by ChatGPT does not\\ncite any primary research articles. If so, a student may rerun\\nthe prompt to generate a new essay with in-text citations\\nuntil a primary research article is mentioned that can be\\neval', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1359: ('DENCE-BASED REASONING FOR CLAIM\\nEVALUATION\\nAfter assessing the different sources cited by ChatGPT,\\nstudents next evaluate the evidence provided by an identi-\\nﬁed primary research article and determine whether the\\nreported results support or refute the associated claim. In\\nsome instances, the essay generated by ChatGPT does not\\ncite any primary research articles. If so, a student may rerun\\nthe prompt to generate a new essay with in-text citations\\nuntil a primary research article is mentioned that can be\\nevaluated ( Table 3 ). Alternatively, a student may choose a\\nspeciﬁc claim made by ChatGPT and independently identify\\na primary research article relevant to addressing the claim.\\nStudents then locate their chosen primary research article,\\nread through the paper, and evaluate all experimental data\\nprovided. They next determine whether the associated state-\\nment made in the essay is supported or refuted by the actual\\nevidence provided in the primary research article. It is our\\nexperience that papers cited by ChatGPT can be irrelevant to\\nthe claim made. In our example, ChatGPT states that “the\\nF508del mutation ...cause(s) CFTR to become trapped in the\\n[endoplasmic reticulum] and undergo rapid degradation by\\nthe ubiquitin-proteasome system (5). ”We identi ﬁed“refer-\\nence 5 ”as a primary research article by Ward et al. (1995)\\nentitled “Degradation of CFTR by the ubiquitin-proteasome\\npathway ”published in Cell(Table 3 ). After reviewing the ar-\\nticle, we determined that Ward et al. (1995) only partiallyTable 3. Essay generation with in-text citations\\nPrompt\\nEssay on how the F508del mutation affects CFTR function, with in-text\\ncitations for all statements\\nChatGPT /C3Response (excerpt)\\nTitle: Impact of the F508del Mutation on CFTR Function\\nIntroduction:Cystic ﬁbrosis (CF) is a genetic disorder caused by mutations in the\\ncystic ﬁbrosis transmembrane conductance regulator (CFTR) gene.\\nAmong the various mutations associated with CF, the deletion of\\nphenylalanine at position 508 (F508del) is the most common,accounting for appr', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1360: ('eneration with in-text citations\\nPrompt\\nEssay on how the F508del mutation affects CFTR function, with in-text\\ncitations for all statements\\nChatGPT /C3Response (excerpt)\\nTitle: Impact of the F508del Mutation on CFTR Function\\nIntroduction:Cystic ﬁbrosis (CF) is a genetic disorder caused by mutations in the\\ncystic ﬁbrosis transmembrane conductance regulator (CFTR) gene.\\nAmong the various mutations associated with CF, the deletion of\\nphenylalanine at position 508 (F508del) is the most common,accounting for approximately two-thirds of CF cases worldwide. Thisessay explores how the F508del mutation affects CFTR function,\\nleading to the pathogenesis of cystic ﬁbrosis.\\nDefective Processing and Traf ﬁcking:\\nOne of the critical steps in CFTR biogenesis is its traf ﬁcking from the\\nendoplasmic reticulum (ER) to the cell surface. The F508del muta-\\ntion impairs this process by causing CFTR to become trapped in\\nthe ER and undergo rapid degradation by the ubiquitin-protea-some system (5).\\nReferences:\\n1. Zielenski J, Tsui LC. Cystic ﬁbrosis: genotypic and phenotypic var-\\niations. Annu Rev Genet 29: 777 –807, 1995.\\n2. Lukacs GL, Verkman AS. CFTR: folding, misfolding and correcting\\ntheDF508 conformational defect. Trends Mol Med 18: 81 –91, 2012.\\n3. Du K, Sharma M, Lukacs GL. The DF508 cystic ﬁbrosis mutation\\nimpairs domain-domain interactions and arrests post-translationalfolding of CFTR. Nat Struct Mol Biol 12: 17 –25, 2005.\\n4. Meacham GC, Brodsky JL. Protein quality control in the secretory\\npathway. J Cell Biol 172: 171 –174, 2006.\\n5. Ward CL, Omura S, Kopito RR. Degradation of CFTR by the ubiq-uitin-proteasome pathway. Cell83: 121 –127, 1995.\\nBoldface indicates the example used in the text. /C3ChatGPT 3.5\\n(openai.com ); accessed February 2024.Table 4. Source evaluation\\nReferences Provided by ChatGPT\\nZielenski J, Tsui LC. Cystic ﬁbrosis: genotypic and phenotypic varia-\\ntions. Annu Rev Genet 29: 777 –807, 1995.\\nReview article\\nLukacs GL, Verkman AS. CFTR: folding, misfolding and correcting the\\nDF508 conformational defect. Trends Mo', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1361: ('006.\\n5. Ward CL, Omura S, Kopito RR. Degradation of CFTR by the ubiq-uitin-proteasome pathway. Cell83: 121 –127, 1995.\\nBoldface indicates the example used in the text. /C3ChatGPT 3.5\\n(openai.com ); accessed February 2024.Table 4. Source evaluation\\nReferences Provided by ChatGPT\\nZielenski J, Tsui LC. Cystic ﬁbrosis: genotypic and phenotypic varia-\\ntions. Annu Rev Genet 29: 777 –807, 1995.\\nReview article\\nLukacs GL, Verkman AS. CFTR: folding, misfolding and correcting the\\nDF508 conformational defect. Trends Mol Med 18: 81 –91, 2012.\\nReview article\\nDu K, Sharma M, Lukacs GL. The DF508 cystic ﬁbrosis mutation impairs\\ndomain-domain interactions and arrests post-translational folding ofCFTR. Nat Struct Mol Biol 12: 17 –25, 2005.\\nPrimary research article\\nMeacham GC, Brodsky JL. Protein quality control in the secretory path-\\nway. J Cell Biol 172: 171 –174, 2006.\\nReference does not exist /C3\\nWard CL, Omura S, Kopito RR. Degradation of CFTR by the ubiquitin-\\nproteasome pathway. Cell83: 121 –127, 1995.\\nPrimary research article\\n/C3Reference is similar to Sun Z, Brodsky JL. Protein quality con-\\ntrol in the secretory pathway. J Cell Biol 218: 3171 –3187, 2019.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\n194 Advances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nsupports the claim made by ChatGPT. Experimental evi-\\ndence was provided in the paper that the CFTR mutant is\\nubiquitinated and degraded by the proteasome; however, no\\nevidence indicates that that protein was trapped in the endo-\\nplasmic reticulum ( Table 5 ). Importantly, the activity chal-\\nlenges students to use their logic and reasoning skills to\\nevaluate the validity of claims based on evidence, regardless\\nof the outcome.\\nPOSTACTIVITY REFLECTION\\nUpon completion of the assignment, students provide\\nwritten answers to re ﬂection questions about what they\\nlearned regarding the evidence provided in Cha', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1362: ('FTR mutant is\\nubiquitinated and degraded by the proteasome; however, no\\nevidence indicates that that protein was trapped in the endo-\\nplasmic reticulum ( Table 5 ). Importantly, the activity chal-\\nlenges students to use their logic and reasoning skills to\\nevaluate the validity of claims based on evidence, regardless\\nof the outcome.\\nPOSTACTIVITY REFLECTION\\nUpon completion of the assignment, students provide\\nwritten answers to re ﬂection questions about what they\\nlearned regarding the evidence provided in ChatGPT essays,\\naccuracy, bene ﬁts, and disadvantages of ChatGPT, and what\\nthey would or would not use it for. Depending on class size\\nand time restrictions, the instructor may also lead a class dis-\\ncussion to allow students to openly share their experiences\\nwith their peers. The students ’responses to the re ﬂection\\nquestions and follow-up discussions can serve as qualitative\\nfeedback for the instructor to assess whether the learning\\nobjectives were attained.\\nCOURSE-SPECIFIC ADAPTATION\\nThe ChatGPT Fact-Check assignment may also be tailored\\nto other classes of different levels, sizes, and instructional\\nmodalities. It can additionally be blended with other assign-\\nments or projects such as the evaluation of more advanced\\nresearch papers or individual or group presentations. Using\\nthe assignment for students to explore diseases that impactspeciﬁc organ systems is an effective general approach\\nfor integration into physiology courses. For example, the\\nVertebrate Neurophysiology course is an upper-division elec-\\ntive for our systems physiology majors (20 –30 students). It is\\nan in-person class in which students learn about electrophysi-\\nology, synaptic transmission, and simple neural circuits. The\\nChatGPT Fact-Check variation we implemented in this course\\nrequired students to work in groups to learn about a neuro-\\nphysiological or neurological disorder, disease, or injury and\\nthen focus on a speci ﬁcc a u s e .\\nDeveloping students ’abilities to think critically and evalu-\\nate claims based on evidence is broadly import', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1363: ('e for our systems physiology majors (20 –30 students). It is\\nan in-person class in which students learn about electrophysi-\\nology, synaptic transmission, and simple neural circuits. The\\nChatGPT Fact-Check variation we implemented in this course\\nrequired students to work in groups to learn about a neuro-\\nphysiological or neurological disorder, disease, or injury and\\nthen focus on a speci ﬁcc a u s e .\\nDeveloping students ’abilities to think critically and evalu-\\nate claims based on evidence is broadly important, even\\nbeyond those majoring in the sciences. Another course that\\nused the ChatGPT Fact-Check assignment was an online syn-\\nchronous Principles of Biology course ( /C2430 students), primar-\\nily for non-biological sciences majors. This introductory\\nbiology course covers functions at the cellular and organismallevels, which includes the study of the basic principles of me-\\ntabolism, heredity, evolution, and ecology. Students workedindividually on the assignment to choose a biology-related\\nurban legend they had heard or read about. They had to ﬁnd\\nany scienti ﬁcs o u r c et os u p p o r tt h el e g e n dw h i l es i m u l t a n e -\\nously learning about primary versus secondary sources.\\nEcological Biology is a lower-division (90 –100 students), in-\\nperson general education course for non-biological sciences\\nmajors. This introductory course covers diversity, ecology,evolution, and behavior with the theme of sustainability.\\nStudents worked autonomously through the assignment and\\nused the generated results, after vetting for validity, to write ascienti ﬁc paper on a sustainability topic.\\nFinally, Biogeography is an upper-division course ( /C2424 stu-\\ndents) for biological sciences majors in which students exam-\\nine the biodiversity patterns over space and through time.With data and models from various sources including botany,\\nzoology, ecology, evolutionary biology, paleontology, and ge-\\nology, the effects of isolation, elevation, and latitude areexamined to understand spatial patterns of biodiversity. To\\nstart the', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1364: (' vetting for validity, to write ascienti ﬁc paper on a sustainability topic.\\nFinally, Biogeography is an upper-division course ( /C2424 stu-\\ndents) for biological sciences majors in which students exam-\\nine the biodiversity patterns over space and through time.With data and models from various sources including botany,\\nzoology, ecology, evolutionary biology, paleontology, and ge-\\nology, the effects of isolation, elevation, and latitude areexamined to understand spatial patterns of biodiversity. To\\nstart the assignment, students worked alone or in pairs to ﬁnd\\na claim from their textbook. They worked through the assign-ment tasks and postactivity re ﬂection to ascertain whether\\nChatGPT as well as their textbook are reliable sources.\\nOverall, we have successfully implemented the ChatGPT\\nFact-Check assignment described above across multiple, rep-resentative classroom environments. The core activities in\\nthe assignment may help destigmatize the usage of genera-\\ntive AI tools in the classroom and encourage students toresponsibly use the technology to ef ﬁciently explore new\\ntopics of interest while maintaining skepticism.\\nDATA AVAILABILITY\\nThe assignment details will be made available upon request.\\nDISCLOSURES\\nNo con ﬂicts of interest, ﬁnancial or otherwise, are declared by\\nthe authors.\\nAUTHOR CONTRIBUTIONS\\nU.H., S.A., and A.Y.P. conceived and designed research; per-\\nformed experiments; prepared ﬁgures; drafted manuscript; edited\\nand revised manuscript; and approved ﬁnal version of manuscript.\\nREFERENCES\\n1. Mitchell M. Artiﬁcial Intelligence: a Guide for Thinking Humans (1st\\nPicador paperback ed.). New York: Picador, 2020.\\n2. Lannoy V. AI-based plagiarism detectors: plagiarism ﬁghters or mak-\\ners? Med Writ 32: 44 –47, 2023. doi: 10.56012/ovnr4109 .\\n3. Steponenaite A ,Barakat B. Plagiarism in AI empowered world. In:\\nUniversal Access in Human-Computer Interaction ,e d i t e db yA n t o n a\\nM, Stephanidis C .Cham, Switzerland: Springer Nature, 2023, p.\\n434 –442.\\n4. Alkaissi H ,McFarlane SI. Artiﬁcial hallucinations in Ch', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1365: (' M. Artiﬁcial Intelligence: a Guide for Thinking Humans (1st\\nPicador paperback ed.). New York: Picador, 2020.\\n2. Lannoy V. AI-based plagiarism detectors: plagiarism ﬁghters or mak-\\ners? Med Writ 32: 44 –47, 2023. doi: 10.56012/ovnr4109 .\\n3. Steponenaite A ,Barakat B. Plagiarism in AI empowered world. In:\\nUniversal Access in Human-Computer Interaction ,e d i t e db yA n t o n a\\nM, Stephanidis C .Cham, Switzerland: Springer Nature, 2023, p.\\n434 –442.\\n4. Alkaissi H ,McFarlane SI. Artiﬁcial hallucinations in ChatGPT: impli-\\ncations in scienti ﬁcw r i t i n g . Cureus 15: e35179, 2023. doi: 10.7759/\\ncureus.35179 .\\n5. Cooperman SR ,Brandão RA. AI assistance with scienti ﬁcw r i t i n g :\\npossibilities, pitfalls, and ethical considerations. Foot Ankle Surg 4:\\n100350, 2024. doi: 10.1016/j.fastrc.2023.100350 .\\n6. Sallam M. ChatGPT utility in healthcare education, research, and\\npractice: systematic review on the promising perspectives and validTable 5. Evidence-based reasoning\\nChatGPT claim\\nThe F508del mutation impairs this process by causing CFTR to\\nbecome trapped in the ER and undergo rapid degradation by theubiquitin-proteasome system (5).\\nSource cited\\n5. Ward CL, Omura S, Kopito RR. Degradation of CFTR by the ubiquitin-\\nproteasome pathway. Cell83: 121 –127, 1995.\\nEvidence-based evaluation of claim\\nThe primary research article ChatGPT cited partially supports the\\nstated claim since it provides evidence that CFTR is ubiquitinatedand degraded by the proteasome. However, there is no evidence inthe article showing that the F508del mutant causes CFTR to become\\ntrapped in the ER.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\nAdvances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org 195\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nconcerns. Healthcare (Basel) 11: 887, 2023. doi: 10.3390/healthcare\\n11060887 .\\n7. Kacena MA ,Plotkin LI ,Fehrenbacher JC. The use of arti ﬁcial intelli-\\ngence in writing scienti ', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1366: ('e F508del mutant causes CFTR to become\\ntrapped in the ER.\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\nAdvances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org 195\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n\\nconcerns. Healthcare (Basel) 11: 887, 2023. doi: 10.3390/healthcare\\n11060887 .\\n7. Kacena MA ,Plotkin LI ,Fehrenbacher JC. The use of arti ﬁcial intelli-\\ngence in writing scienti ﬁcr e v i e wa r t i c l e s . Curr Osteoporos Rep 22:\\n115–121, 2024. doi: 10.1007/s11914-023-00852-0 .\\n8. Ariyaratne S ,Iyengar Karthikeyan P ,Nischal N ,Chitti Babu N ,\\nBotchu R. A comparison of ChatGPT-generated articles with human-\\nwritten articles. Skeletal Radiol 52: 1755 –1758, 2023. doi: 10.1007/\\ns00256-023-04340-5 .\\n9. Anderson LW (Editor). A Taxonomy for Learning, Teaching, and\\nassessing: a Revision of Bloom ’s Taxonomy of Educational\\nObjectives . New York: Longman, 2009.10. Cohen L ,Manion L ,Morrison K. Research Methods in Education\\n(8th ed). London: Routledge, 2017.\\n11. Kolb DA. Experiential Learning: Experience as the Source of\\nLearning and Development (2nd ed.). Upper Saddle River, NJ:\\nPearson Education, Inc, 2015.\\n12. Marzano RJ ,Pickering DJ ,Pollock JE. Classroom Instruction That\\nWorks: Research-Based Strategies for Increasing Student\\nAchievement . Alexandria, VA: Association for Supervision and\\nCurriculum Development, 2008.\\n13. Peltonen L ,Perola M ,Naukkarinen J ,Palotie A. Lessons from\\nstudying monogenic disease for common disease. Hum Mol Genet\\n15: R67 –R74, 2006. doi: 10.1093/hmg/ddl060 .\\nChatGPT FACT-CHECKS TO DEVELOP EVIDENCE-BASED REASONING\\n196 Advances in Physiology Education /C15doi:10.1152/advan.00142.2024 /C15http://advan.physiology.org\\nDownloaded from journals.physiology.org/journal/advances (2601:0647:6514:AC2A:2CA2:C625:10C6:9B11) on March 7, 2025.\\n', 'holzmann-et-al-2025-the-chatgpt-fact-check-exploiting-the-limitations-of-generative-ai-to-develop-evidence-based.pdf'), 1367: ('Institut Riset dan Publi kasi Indonesia  (IRPI)  \\nMALCOM : Indonesian Journal of  Machin e Learning  and Computer Science  \\nJournal Homepage:  https://journal.irpi.or.id/index.php/malcom  \\nVol. 4 Iss. 3 July 2024, pp: 936-942 \\nISSN (P): 2797 -2313 | ISSN(E): 2775 -8575  \\n     936 \\n \\nDOI: https://doi.org/10.57152/malcom.v 4i3.1324  \\nThe OSI and TCP/  IP Reference Models in the Era of Industry 4.0  \\n \\nEka Ramdan Permana1*, Fajar Nugraha Wahyu2,   \\nHandri Taufik3, Thoyyibah. T4 \\n \\n1,2,3,4Program Studi Teknik  Informatika, Universitas Pamulang, Indonesia  \\n \\nE-Mail : 1eka01ramdan@gmail.com , 2fajarnugraha06@gmail.com , \\n3handrith@gmail.com , 4dosen01116@unpam.ac.id  \\n \\nReceived Feb 22th 2024; Revised Mar 11th 202 4; Accepted May 14th 202 4 \\nCorresponding Author: Eka Ramdan Permana  \\n \\nAbstract  \\n \\nThe research aims to evaluate the integration and relevance of the Open Systems Interconnection  (OSI) and TCP/IP \\n(Transmission Control Protocol/Internet Protocol)  Reference Models in the context of Industry 4.0. This study seeks to \\nanalyze the suitability of these models with the complex and dynamic networking environment of the present era and to \\npropose modifications or strategies to enhance their performance and security within the context of Industry 4.0. The \\nresearch method employed is descriptive rese arch with a literature study design. This descriptive research method with a \\nliterature study design will aid in depicting and analyzing the OSI and TCP/IP reference models in the Industry 4.0 era. \\nPrimary data sources are derived from scholarly journals, reference books, and other relevant publications. Data analysis \\nis conducted using a qualitative approach, wherein information from various sources will be thoroughly analyzed to \\nidentify patterns, trends, and relationships among the studied concepts. The research findings indicate that the difference \\nbetween the OSI and TCP/IP models lies in their approaches and characteristics in regulating the process of data \\ncommunication within networks. OSI emphasizes ', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1368: (' sources are derived from scholarly journals, reference books, and other relevant publications. Data analysis \\nis conducted using a qualitative approach, wherein information from various sources will be thoroughly analyzed to \\nidentify patterns, trends, and relationships among the studied concepts. The research findings indicate that the difference \\nbetween the OSI and TCP/IP models lies in their approaches and characteristics in regulating the process of data \\ncommunication within networks. OSI emphasizes reliability at each layer, while TCP/IP views reli ability as an end -to-end \\nissue. Structure, application layer grouping, and the level of standardization also serve as points of differentiation betwee n \\nthe two.  \\n \\nKeyword: Critical Foundation, Function Separation, Industry 4.0 Relevance, Networks  \\n \\n \\n \\n1. INTRODU CTION  \\nA network is a collection of computers that can communicate with each other and share accessible \\nequipment collectively. Communication topologies connected to other computers are divided into four types: \\nstar topology, ring topology, bus topology  [1]. To enable communication between computers, a network \\nprotocol is required. A protoco l is a set of rules and standards that allow computers to communicate with each \\nother  [2]. The benefits gained from connecting computers to each other in a network using the Transmission \\nControl Protocol/Internet Protocol (TCP/IP ) protocol are significant. TC P/IP, besides being a layered protocol, \\nalso adheres to International Organization for Standardization  (ISO) and Open Systems Interconnection  (OSI) \\nstandards, enabling communication worldwide even if different platforms are used  [3]. The OSI Reference \\nModel for Open Networking is an architectural network model developed by the International Organization for \\nStanda rdization (ISO) in Europe in 1977  [4]. This model is also referred to as the \"OSI Seven Layer Model.\" \\nThis paper will discuss OSI Layers and TCP/IP.  \\nIn the world of computer networking, there are two reference models that ', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1369: ('Standardization  (ISO) and Open Systems Interconnection  (OSI) \\nstandards, enabling communication worldwide even if different platforms are used  [3]. The OSI Reference \\nModel for Open Networking is an architectural network model developed by the International Organization for \\nStanda rdization (ISO) in Europe in 1977  [4]. This model is also referred to as the \"OSI Seven Layer Model.\" \\nThis paper will discuss OSI Layers and TCP/IP.  \\nIn the world of computer networking, there are two reference models that are crucial for understanding \\nand developing complex communication s ystems: the OSI Reference Model and the TCP/IP  Model  [5]. Both \\nof these models remain critical foundations in the development of computer networks in the Industry 4.0 era. \\nThe OSI Reference Model, developed by the ISO, consists of seven layers  [6]. Each layer has a spec ific \\nfunction in the network communication process, ranging from governing the transmission of data bits to \\nproviding an interface for user applications. This model aids in understanding the fundamental concepts of \\nnetwork communication and separates netwo rk functions into smaller units  [7].  \\nOn the other hand, the TCP/IP model is the model used in designing network protocols utilized on the \\nInternet  [8]. Although comprising only four layers , this model is highly effective in managing end -to-end \\nconnectivity and data delivery between devices in the network. The TCP/IP protocol also adheres to ISO and \\nOSI standards, enabling smooth communication between various platforms worldwide  [9]. In the era of \\nIndustry 4.0, marked by the adoption of technologies such as the Internet of Things (IoT), cloud computing, \\nand big data, a good understanding of both models is crucial  [10]. They assist in t he design, implementation, \\n \\nISSN(P): 2797 -2313 ISSN(E): 2775 -8575  \\n \\n      \\n937 \\n \\n \\nMALCOM - Vol. 4 Iss. 3 July 2024, pp: 936-942 and management of efficient and secure networks, enabling smooth communication between various devices \\nand systems in an increasingly con', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1370: ('us platforms worldwide  [9]. In the era of \\nIndustry 4.0, marked by the adoption of technologies such as the Internet of Things (IoT), cloud computing, \\nand big data, a good understanding of both models is crucial  [10]. They assist in t he design, implementation, \\n \\nISSN(P): 2797 -2313 ISSN(E): 2775 -8575  \\n \\n      \\n937 \\n \\n \\nMALCOM - Vol. 4 Iss. 3 July 2024, pp: 936-942 and management of efficient and secure networks, enabling smooth communication between various devices \\nand systems in an increasingly connected environment. By using these models as guides, organizations can \\ndevelop robust and ad aptable network infrastructures in line with the technological changes occurring in the \\nIndustry 4.0 era  [11].  \\nIn the context of computer networks, the OSI and TCP/IP  reference models remain crucial foundations \\nin the development of complex communication systems, especially in the era of Industry 4.0. Although both \\nhave been around since  before this era began, their relevance and necessity remain high in understanding the \\nbasic principles of network communication. The OSI model consists of seven layers, each with a specific role \\nin the network communication process. Starting from the phys ical layer, which governs the transmission of \\ndata bits, to the application layer, which provides an interface for user applications, this model aids in \\nunderstanding the fundamental concepts of network communication and segregates network functions into \\nsmaller units. Meanwhile, the TCP/IP model, despite comprising only four layers, is effective in managing \\nend-to-end connectivity and data delivery between devices in the network. This protocol also adheres to ISO \\nand OSI standards, enabling seamless commun ication between various platforms worldwide.  Transmission \\nControl Protocol (TCP) is a protocol used for all nodes connected to the internet so that they can communicate \\nwith each other reliably. It is a connection -oriented protocol that, along with the IP protocol, has served as the \\nfoundation for the TCP/IP mod', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1371: ('y four layers, is effective in managing \\nend-to-end connectivity and data delivery between devices in the network. This protocol also adheres to ISO \\nand OSI standards, enabling seamless commun ication between various platforms worldwide.  Transmission \\nControl Protocol (TCP) is a protocol used for all nodes connected to the internet so that they can communicate \\nwith each other reliably. It is a connection -oriented protocol that, along with the IP protocol, has served as the \\nfoundation for the TCP/IP model, used since before the OSI model was established, and therefore the TCP/IP \\nmodel has been compared to the OSI model  [12]. The OSI model aids in the installation, configuration, \\nmaintenance, and troubleshooting of netwo rks, particularly in the context of the TCP/IP protocol, which is one \\nof many protocol suites used  [13]. The TCP -based intranet network system provides several significant \\nbenefits. Firstly, it efficiently resolves constraints in data  exchange among departments, saving time, cost, and \\neffort. Secondly, data can be transferred quickly and accurately as needed. Thirdly, direct communication \\nwithout using telephones accelerates collaboration. Fourthly, simultaneous printer usage enhances resource \\nutilization efficiency. Fifthly, high -level data security prevents unauthorized access. Finally, accessing \\napplications from the server without installation on clients speeds up overall application usage  [14]. In an era \\nwhere technologies like the IoT, cloud computing, and big data are becoming increasingly important, a solid \\nunderstanding of both models is paramount  [15]. They aid in the design, implementation, and management of \\nefficient and secure networks, facilitating smooth communication between various devices and systems in an \\nincreasingly interconnected environment. By utilizing these models as guides, organizations can develop \\nresilient network infrastructures that can evolve alongside the technological changes occurring in the Industry \\n4.0 era  [10]. The research aims to e', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1372: ('ecoming increasingly important, a solid \\nunderstanding of both models is paramount  [15]. They aid in the design, implementation, and management of \\nefficient and secure networks, facilitating smooth communication between various devices and systems in an \\nincreasingly interconnected environment. By utilizing these models as guides, organizations can develop \\nresilient network infrastructures that can evolve alongside the technological changes occurring in the Industry \\n4.0 era  [10]. The research aims to evaluate the integration and relevance of the OSI and TCP/IP Reference \\nModels in the context of Industry 4.0 . This study seeks to analyze the suitability of these models with the \\ncomplex and dynamic networking environment of the present era and to propose modifications or strategies to \\nenhance their performance and security within the context of Industry 4.0.  \\n \\n2. MATERIALS AND METHOD  \\nIn researching the OSI and TCP/IP reference models in the Industry 4.0 era, the methodology employed \\nwill play a crucial role. The descriptive research method will aid in portraying and analyzing both models and \\ntheir relevance within t he context of Industry 4.0. A fitting research design is literature review and content \\nanalysis. Literature review will facilitate gathering up -to-date information regarding the utilization of both \\nmodels in Industry 4.0, while content analysis will system atically dissect this information. Primary data sources \\nwill stem from scholarly journals, reference books, and other related publications. Secondary data can also be \\nused to bolster research arguments and findings. Data analysis will be approached qualita tively, wherein \\ninformation from various sources will be deeply scrutinized to identify patterns, trends, and relationships \\nbetween the concepts under scrutiny. The research findings will offer a better understanding of the OSI and \\nTCP/IP reference models and their relevance in the Industry 4.0 era. These findings can be employed to provide \\nfresh insights and recommendations f', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1373: ('lications. Secondary data can also be \\nused to bolster research arguments and findings. Data analysis will be approached qualita tively, wherein \\ninformation from various sources will be deeply scrutinized to identify patterns, trends, and relationships \\nbetween the concepts under scrutiny. The research findings will offer a better understanding of the OSI and \\nTCP/IP reference models and their relevance in the Industry 4.0 era. These findings can be employed to provide \\nfresh insights and recommendations for further development in the field of computer networking. By \\nemploying the appropriate research methodology, this study is expected  to provide valuable contributions to \\nunderstanding and further development in this domain. The right research methodology will ensure that the \\nresearch on the OSI and TCP/IP reference models in the Industry 4.0 era is conducted systematically and \\naccounta bly. Utilizing descriptive methods, this research will yield a better understanding of the fundamental \\nconcepts of both models and their application in the Industry 4.0 environment.  \\nLiterature review will serve as the primary foundation for this research,  allowing researchers to gather \\nrelevant and current information about the utilization of OSI and TCP/IP reference models in Industry 4.0. \\nContent analysis will assist in thorough analysis of this information, identifying potential patterns and trends, \\nand connecting interrelated concepts. Data sources from scholarly journals, reference books, and other related \\npublications will serve as the primary sources of information. Secondary data can also be used to support the \\nfindings and arguments generated in th e research. Qualitative data analysis will enable researchers to gain a \\ndeep understanding of the OSI and TCP/IP reference models and their relevance in the Industry 4.0 era. The \\nresults of this research are expected to provide fresh insights and valuable recommendations for further \\n \\n                MALCOM -04(03): 936-942 \\n     \\n 938 \\n \\nThe OSI and TCP/IP R', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1374: ('blications will serve as the primary sources of information. Secondary data can also be used to support the \\nfindings and arguments generated in th e research. Qualitative data analysis will enable researchers to gain a \\ndeep understanding of the OSI and TCP/IP reference models and their relevance in the Industry 4.0 era. The \\nresults of this research are expected to provide fresh insights and valuable recommendations for further \\n \\n                MALCOM -04(03): 936-942 \\n     \\n 938 \\n \\nThe OSI and TCP/IP Reference Models ... (Permana et al, 202 4) development in the field of computer networking. By using the appropriate research methodology, this research \\nis expected to make a significant contribution to understanding and developing the OSI and TCP/IP reference \\nmodels in the context of Industry 4.0.   \\n \\n3. RESULTS AND DISCUSSION  \\n3.1 Definition of Open Systems Interconnection (OSI)  \\nThe OSI reference model is a globally accepted framework for the development of complete and open \\nstandards. The OSI model helps create open standards for systems to interconnect and communicate, \\nparticularly in the field of information technology. The OSI  reference model is conceptually divided into 7 \\nlayers, each layer having specific network functions. This model was created based on a proposal by the ISO \\nas an initial step towards standardizing international protocols used across different layers.  \\nThe O SI Reference Model outlines a layered approach to networking. Each layer of the model represents \\na different portion of the communication process. By separating the communication process into layers, the \\nOSI model simplifies how software and hardware colla borate, thereby facilitating troubleshooting efforts by \\nproviding a specific method for understanding how components function  [16]. \\n \\n3.2 Seven OSI Layers  \\nThe OSI reference model was created with the aim of enabling data communication to proceed through \\nclear steps, commonly referred to as \"layers.\" The OSI model consists of seven layers. The principles used ', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1375: ('ion of the communication process. By separating the communication process into layers, the \\nOSI model simplifies how software and hardware colla borate, thereby facilitating troubleshooting efforts by \\nproviding a specific method for understanding how components function  [16]. \\n \\n3.2 Seven OSI Layers  \\nThe OSI reference model was created with the aim of enabling data communication to proceed through \\nclear steps, commonly referred to as \"layers.\" The OSI model consists of seven layers. The principles used for \\nthese seven layers are:  \\n1. A layer should be created if a different level of abstraction is required.  \\n2. Each layer must have specific functions.  \\n3. The functions of the lower layers serve to support the functions of the layers above.  \\n4. The functions of each layer must be carefully selected  in accordance with international protocol \\nstandards.  \\n5. Layer boundaries should be designed to minimize the flow of information passing through interfaces.  \\n6. The number of layers should be sufficient so that different functions do not need to be combined into a \\nsingle layer unnecessarily. However, the number of layers should also be kept as small as possible so \\nthat network architecture is not overly complicated.  \\n \\n \\nFigure 1. Image 1. OSI Seven -Layer Model  \\n \\nThe OSI reference model is conceptually divided into 7 layers, each layer having specific network \\nfunctions, as explained below, among others  [17]:  \\n1. Physical Layer  \\nThe Physical Layer functions as the transmission of raw bits over the communication channel. \\nDesign issues to be considered here include ensuring that when one side sends a data bit of 1, it is \\nreceived by the other side as a 1 bit as well, and not a 0 bit. Generally, the design issues found here \\nrelate to mechanical, electrical, and procedural interface issues, as well as the physical media beneath \\nthe physical layer  [18]. \\n \\n2. Data Link Layer  \\nThe primary task of the data link layer is to serve as a facility for transmitting raw data and \\ntransforming it into a tra', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1376: (\"e communication channel. \\nDesign issues to be considered here include ensuring that when one side sends a data bit of 1, it is \\nreceived by the other side as a 1 bit as well, and not a 0 bit. Generally, the design issues found here \\nrelate to mechanical, electrical, and procedural interface issues, as well as the physical media beneath \\nthe physical layer  [18]. \\n \\n2. Data Link Layer  \\nThe primary task of the data link layer is to serve as a facility for transmitting raw data and \\ntransforming it into a transmission channel free from transmission errors. Before being forwarded to the \\nNetwork Layer, the d ata link layer accomplishes this task by allowing the sender to group input data \\ninto a number of data frames (usually hundreds or thousands of bytes). Then, the data link layer \\n\\n \\nISSN(P): 2797 -2313 ISSN(E): 2775 -8575  \\n \\n      \\n939 \\n \\n \\nMALCOM - Vol. 4 Iss. 3 July 2024, pp: 936-942 sequentially transmits these frames and processes acknowledgment frames sent b ack by the receiver. \\nIssues that arise in the data link layer involve ensuring the smooth delivery of data from fast senders to \\nslow receivers. Traffic control mechanisms must allow the sender to know the amount of buffer space \\navailable to the receiver at  any given time.  \\nIn general, the main tasks of the data link layer in the data communication process encompass \\nseveral key functions. Firstly, there's framing, where the data link divides the bit stream received from \\nthe network layer into data units calle d frames. Additionally, there's physical addressing, involving the \\ndefinition of the sender's and/or receiver's identities added in the header. Furthermore, flow control is \\nimplemented to maintain the stability of the bit rate if the bit stream rate is exc essive or diminished. \\nError control includes the addition of mechanisms for detecting and retransmitting failed frames. \\nFinally, communication control determines which device should be controlled when there are two \\nsimilar connections. All of these functio ns together form the crucia\", 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1377: (\"ysical addressing, involving the \\ndefinition of the sender's and/or receiver's identities added in the header. Furthermore, flow control is \\nimplemented to maintain the stability of the bit rate if the bit stream rate is exc essive or diminished. \\nError control includes the addition of mechanisms for detecting and retransmitting failed frames. \\nFinally, communication control determines which device should be controlled when there are two \\nsimilar connections. All of these functio ns together form the crucial role of the data link layer in \\nfacilitating efficient and reliable data communication processes.  \\n \\n3. Network Layer  \\nThe network layer functions to control subnet operations. Issues that arise in the network layer \\ninvolve determinin g the route for packet delivery from the source to the destination. When multiple \\npackets exist simultaneously within a subnet, there is a possibility that these packets may arrive \\nsimultaneously  [19].  This can lead to bottleneck occurrences. Managing congestion like this is also a \\ntask of the network layer, enabling different networks, with different protocols, addressing, and network \\narchitectures, to interconnect with each other.  \\nIn general, the main tasks of the network layer in the data communication process include several \\nimportant functions . Firstly, there is logical addressing, where logical addressing is added to the network \\nlayer header. In TCP/IP networks, this logical addressing is known as the IP Address. Next, there's \\nrouting, which involves the relationship between  networks forming an internet -work and requires a \\nmethod of addressing routes so that packets can be transferred from one device originating from one \\nnetwork to another device on another network. Routing functionality is supported by routing protocols, \\nwhich aim to find the best path to the destination and exchange information about network topology \\nwith other routers. These two functions work together to ensure efficient and accurate data delivery \\nacross the network  [20]. \\n \\n4. T\", 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1378: ('elationship between  networks forming an internet -work and requires a \\nmethod of addressing routes so that packets can be transferred from one device originating from one \\nnetwork to another device on another network. Routing functionality is supported by routing protocols, \\nwhich aim to find the best path to the destination and exchange information about network topology \\nwith other routers. These two functions work together to ensure efficient and accurate data delivery \\nacross the network  [20]. \\n \\n4. Transport Layer  \\nThe transport layer functions to segment data into data packets and a ssigns sequence numbers to \\nthese packets so they can be reassembled at the destination side after being received. Additionally, at \\nthis layer, acknowledgments are generated to indicate successful packet reception, and retransmissions \\nare initiated for pack ets lost in transit. All these tasks must be executed efficiently and aim to shield the \\nupper layers from inevitable hardware technology changes.  \\n \\n5. Session Layer  \\nThe session layer controls the \"dialogue\" during communication, responsible for establishing \\nconnections, managing their use, and terminating connections after a communication session ends. It \\nadds control headers to data packets during data exchange and allows users to establish sessions with \\neach other. Besides enabling regular data  transport like the transport layer, sessions also provide special \\nservices for specific applications, such as logging into remote timesharing systems or transferring files \\nbetween machines.  \\n \\n6. Presentation Layer  \\nThe main task of the presentation layer is to  ensure that data or information is transmitted in a \\nlanguage or syntax understandable by the destination host. Protocols at the presentation layer can \\ntranslate data into a understandable language or syntax, and compress data before delivering it to the \\nsession layer. It performs specific functions requested to find a general solution to certain problems, \\nfocusing on the syntax and information being tran', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1379: (' files \\nbetween machines.  \\n \\n6. Presentation Layer  \\nThe main task of the presentation layer is to  ensure that data or information is transmitted in a \\nlanguage or syntax understandable by the destination host. Protocols at the presentation layer can \\ntranslate data into a understandable language or syntax, and compress data before delivering it to the \\nsession layer. It performs specific functions requested to find a general solution to certain problems, \\nfocusing on the syntax and information being transmitted. One example service of the presentation layer \\nis data encoding.  \\n \\n7. Application Layer  \\nThe application layer functions as the interface between applications and network functionality, \\nmanaging how applications can access the network and handling error messages. It determines an \\nabstract virtual network terminal, enabling editors and other pr ograms to be written to match each other. \\nTo handle each type of terminal, a software component must be written to map virtual network terminal \\nfunctions to the actual terminal. Another function of the application layer is file transfer. Different file \\n \\n                MALCOM -04(03): 936-942 \\n     \\n 940 \\n \\nThe OSI and TCP/IP Reference Models ... (Permana et al, 202 4) systems have different naming conventions and ways of representing text lines. File transfer between \\ndifferent systems requires handling to address inconsistencies. Tasks of the application layer include \\nemail, remote job entry, directory lookup, and various other general -purpose and specific -purpose \\nfacilities. Protocols found in this application layer include FTP, SMTP, and HTTP  [21]. \\nThe seven layers of the OSI reference model can be divided into two categories: the upper layer s \\nand the lower layers. The upper layers of the OSI model, consisting of the Application layer, \\nPresentation Layer, Session Layer, and Transport Layer, deal with application -related issues and are \\ngenerally implemented only in software. The Application lay er is the top layer before reaching the user. ', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1380: (\"specific -purpose \\nfacilities. Protocols found in this application layer include FTP, SMTP, and HTTP  [21]. \\nThe seven layers of the OSI reference model can be divided into two categories: the upper layer s \\nand the lower layers. The upper layers of the OSI model, consisting of the Application layer, \\nPresentation Layer, Session Layer, and Transport Layer, deal with application -related issues and are \\ngenerally implemented only in software. The Application lay er is the top layer before reaching the user. \\nUsers and the application layer interact with each other through application software containing a \\ncommunication component.  \\nThe lower layers of the OSI model, consisting of the Network Layer, Data Link Layer, a nd \\nPhysical Layer, control data transmission issues. These lower layers are implemented in hardware. The \\nbottom layer, the Physical layer, acts as the interface to the physical network media (such as cable \\nnetworks) and is responsible for placing informati on on the network media.  \\n \\n3.3 The operation of the OSI Reference  \\nModel begins at the top layer, which is the Application layer. Data is sent from this layer to the layer \\nbelow, which is the Presentation layer. In the Presentation layer, data is provided w ith headers or trailers and \\nthen transmitted to the layer below it. This process continues to the layers below, where each layer adds headers \\nor trailers before passing it down to the layer below it again, until it reaches the Physical layer. In the Physic al \\nlayer, data is transmitted through the media to the destination host. Thus, each layer handles specific processes \\nin the formation and transmission of data packets.  \\n \\n \\nFigure 2. Structure of the OSI Model's Operation  \\n \\nAt the destination host, the data packet flows in the opposite direction, from the bottom layer to the top \\nlayer. The protocol at the physical layer in the destination host retrieves the data packet from the transmission \\nmedia and then sends it to the data link layer. The data link la yer examines the data l\", 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1381: ('ed through the media to the destination host. Thus, each layer handles specific processes \\nin the formation and transmission of data packets.  \\n \\n \\nFigure 2. Structure of the OSI Model\\'s Operation  \\n \\nAt the destination host, the data packet flows in the opposite direction, from the bottom layer to the top \\nlayer. The protocol at the physical layer in the destination host retrieves the data packet from the transmission \\nmedia and then sends it to the data link layer. The data link la yer examines the data link layer header added by \\nthe sending host to the packet. If the host is not the intended recipient of the packet, it will be discarded. \\nHowever, if the host is the intended recipient, the packet will be forwarded to the network laye r. This process \\ncontinues until it reaches the application layer at the destination host. The process of sending packets from \\nlayer to layer is called \"peer layer communication.\"  \\n   \\n4. CONCLUSION  \\nThe analysis of the research findings regarding the differences between the OSI model and the TCP/IP \\nmodel reveals significant distinctions in their approaches and characteristics in regulating data communication \\nprocesses within networks. The OSI model em phasizes reliability in data transfer services at each layer, \\nwhereas TCP/IP views reliability as an end -to-end issue. This indicates that OSI places emphasis on reliability \\n\\n \\nISSN(P): 2797 -2313 ISSN(E): 2775 -8575  \\n \\n      \\n941 \\n \\n \\nMALCOM - Vol. 4 Iss. 3 July 2024, pp: 936-942 at every stage of the communication process, while TCP/IP addresses this issue at the end -to-end level. \\nFurthermore, OSI distributes responsibilities for detecting and handling errors in data across each layer, \\nwhereas TCP/IP centralizes reliability control at the Transport Layer. Additionally, TCP/IP employs \\nmechanisms such as checksum s, acknowledgments, and timeouts at the Transport Layer to control transmission \\nand provide end -to-end verification. Another difference lies in the grouping of application layers, where OSI \\nseparates the ap', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1382: ('ess, while TCP/IP addresses this issue at the end -to-end level. \\nFurthermore, OSI distributes responsibilities for detecting and handling errors in data across each layer, \\nwhereas TCP/IP centralizes reliability control at the Transport Layer. Additionally, TCP/IP employs \\nmechanisms such as checksum s, acknowledgments, and timeouts at the Transport Layer to control transmission \\nand provide end -to-end verification. Another difference lies in the grouping of application layers, where OSI \\nseparates the application, presentation, and session layers, while  TCP/IP consolidates them into one layer (the \\nApplication Layer). TCP/IP also combines the physical and data link layers into one layer (the Network/Access \\nLayer), while OSI separates them into distinct layers. Structurally, OSI comprises seven layers that  describe \\nthe data communication process within networks, whereas TCP/IP has five layers. Finally, while OSI functions \\nas a standard model used as a reference for explaining data communication processes, TCP/IP is a standardized \\ndata communication protocol  with established protocols. This indicates a difference in the level of \\nstandardization between the two.  \\n \\nREFERENCES  \\n[1]  J. Bentham, TCP/IP Lean: Web servers for embedded systems . CMP Media, Inc., 2001. Access ed: Mar. \\n21, 2024. [Online]. Available: https://dl.acm.org/doi/abs/10.5555/365145  \\n[2]  A. M. Lukman and Y. Bachtiar, “Analisis Sistem Pengelolaan, Pemeliharaan dan Keamanan Jaringan \\nInternet Pada IT Telkom Purwokerto,” J. Khatulistiwa Inform. , vol. 6, no. 2, p. 486692, 2018.  \\n[3]  Latifah, “Perancangan dan implementasi sistem diskless pada laboratorium Sekolah Menengah Pertma \\nNegeri 252 Jakarta,” Dec. 2011, Accessed: Mar. 21, 2024. [Online]. Available: \\nhttps://repository.uinjkt.ac.id/dspace/handle/123456789/ 1787  \\n[4]  A. P. Manginsela, “Modul 2: Model Referensi OSI dan TCP/IP, MK Jaringan Komputer,” 2019, \\nAccessed: Mar. 21, 2024. [Online]. Available: https://repository.polimdo.ac.id/3019/1/Modul%202 -\\nTeori.pdf  \\n[5]  Y. Chris', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1383: ('iwa Inform. , vol. 6, no. 2, p. 486692, 2018.  \\n[3]  Latifah, “Perancangan dan implementasi sistem diskless pada laboratorium Sekolah Menengah Pertma \\nNegeri 252 Jakarta,” Dec. 2011, Accessed: Mar. 21, 2024. [Online]. Available: \\nhttps://repository.uinjkt.ac.id/dspace/handle/123456789/ 1787  \\n[4]  A. P. Manginsela, “Modul 2: Model Referensi OSI dan TCP/IP, MK Jaringan Komputer,” 2019, \\nAccessed: Mar. 21, 2024. [Online]. Available: https://repository.polimdo.ac.id/3019/1/Modul%202 -\\nTeori.pdf  \\n[5]  Y. Christian, “Analisis Sistem Pengamanan Akse s Autentikasi Jaringan dengan Metode Port Knocking \\ndan Action Tarpit pada Router Mikrotik,” Telcomatics , vol. 4, no. 1, Art. no. 1, Jul. 2019.  \\n[6]  K. Anugrah, “Tugas Jaringan Komputer (Klarisa Anugrah 175100018) Pengenalan Osi Layer,” Open \\nScience Framewo rk, preprint, Apr. 2019. doi: 10.31219/osf.io/nkzc3.  \\n[7]  M. Syafrizal, Pengantar Jaringan Komputer . Yogyakarta: Penerbit Andi, 2020.  \\n[8]  W. Buana, A. Hariyandi, and F. R. S, “Pengembangan Jaringan Local Area Network (Lan) Dan Wide \\nArea Network (Wan) Pada  SMKN 4 Padang Dengan Metode Research Dan Development,” JOISIE J. \\nInf. Syst. Inform. Eng. , vol. 7, no. 1, Art. no. 1, Jul. 2023, doi: 10.35145/joisie.v7i1.3268.  \\n[9]  R. Sharma, C. J. C. Jabbour, and A. B. Lopes de Sousa Jabbour, “Sustainable manufacturing and \\nindustry 4.0: what we know and what we don’t,” J. Enterp. Inf. Manag. , vol. 34, no. 1, pp. 230 –266, \\nJan. 2020, doi: 10.1108/JEIM -01-2020 -0024.  \\n[10]  A. Deni, Manajemen Strategi di Era Industri 4.0 . Cendikia Mulia Mandiri, 2023. Accessed: Mar. 21, \\n2024.  [Online]. Available: \\nhttps://books.google.com/books?hl=en&lr=&id=YcLOEAAAQBAJ&oi=fnd&pg=PA223&dq=info:K\\npcDQf_dv8kJ:scholar.google.com&ots=7c3sY0N7RP&sig=PLcLK5x5Q11ErFxw7u5_2ICZQPA  \\n[11]  S. Maesaroh, R. R. Lubis, L. N. Husna, R. Widyaningsih, R. Susilawat i, and P. M. Yasmin, “Efektivitas \\nImplementasi Manajemen Business Intelligence pada Industri 4.0,” ADI Bisnis Digit. Interdisiplin J. , \\nvol. 3, no. 2, pp. 69 –75, Jul. 2022, doi: 10.', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1384: ('stri 4.0 . Cendikia Mulia Mandiri, 2023. Accessed: Mar. 21, \\n2024.  [Online]. Available: \\nhttps://books.google.com/books?hl=en&lr=&id=YcLOEAAAQBAJ&oi=fnd&pg=PA223&dq=info:K\\npcDQf_dv8kJ:scholar.google.com&ots=7c3sY0N7RP&sig=PLcLK5x5Q11ErFxw7u5_2ICZQPA  \\n[11]  S. Maesaroh, R. R. Lubis, L. N. Husna, R. Widyaningsih, R. Susilawat i, and P. M. Yasmin, “Efektivitas \\nImplementasi Manajemen Business Intelligence pada Industri 4.0,” ADI Bisnis Digit. Interdisiplin J. , \\nvol. 3, no. 2, pp. 69 –75, Jul. 2022, doi: 10.34306/abdi.v3i2.764.  \\n[12]  A. B. Pawar, M. A. Jawale, P. William, and B. S. Sonawane, “Efficacy of TCP/IP Over ATM \\nArchitecture Using Network Slicing in 5G Environment,” in Smart Data Intelligence , Springer, \\nSingapore, 2022, pp. 79 –93. doi: 10.1007/978 -981-19-3311 -0_8. \\n[13]  C. Panek, Networking Fundamentals , 1st ed. Wiley, 2019. doi: 10.1002/9781119650768.  \\n[14]  A. Halim, “Sistem Jaringan Intranet Berbasis Tcp,” J. Ilm. Sist. Inf. , vol. 1, no. 1, Art. no. 1, Jun. 2021, \\ndoi: 10.46306/sm.v1i1.4.  \\n[15]  A. B. L. de Sousa Jabbour, C. J. C. Jabbour, C. Foropon, and M. Godinho Filho, “When titans meet –\\nCan industry 4.0 revolutionise the environmentally -sustainable manufacturing wave? The role of critical \\nsuccess factors,” Technol. Forecast. Soc. Change , vol. 132, pp. 18 –25, 2018.  \\n[16]  V. Jacobson, RFC1144: Compressing TCP/IP headers for low -speed serial links . USA: RFC Editor, \\n1990.  \\n[17]  E. A. Hernández, J. C. Bautista, A. E. G. Zenil, A. A. H. Medellín, S. H. Hernández, and G. H. \\nHernández, “Comparación de los modelos OSI y TCP/IP,” Cienc. Huasteca Bol. Científico Esc. Super. \\nHuejutla , vol. 5, no. 10, Art. no. 10, Jul. 2017, doi: 10.29057 /esh.v5i10.2461.  \\n[18]  M. T. Rose and K. McCloghrie, “Management Information Base for Network Management of TCP/IP -\\nbased internets: MIB -II,” Internet Engineering Task Force, Request for Comments RFC 1213, Mar. \\n1991. doi: 10.17487/RFC1213.  \\n \\n                MALCOM -04(03): 936-942 \\n     \\n 942 \\n \\nThe OSI and TCP/IP Reference Models ... (Perman', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1385: ('nández, “Comparación de los modelos OSI y TCP/IP,” Cienc. Huasteca Bol. Científico Esc. Super. \\nHuejutla , vol. 5, no. 10, Art. no. 10, Jul. 2017, doi: 10.29057 /esh.v5i10.2461.  \\n[18]  M. T. Rose and K. McCloghrie, “Management Information Base for Network Management of TCP/IP -\\nbased internets: MIB -II,” Internet Engineering Task Force, Request for Comments RFC 1213, Mar. \\n1991. doi: 10.17487/RFC1213.  \\n \\n                MALCOM -04(03): 936-942 \\n     \\n 942 \\n \\nThe OSI and TCP/IP Reference Models ... (Permana et al, 202 4) [19]  A. P. Mangi nsela, “Modul 2: Model Referensi OSI dan TCP/IP, MK Jaringan Komputer,” 2019, \\nAccessed: Mar. 20, 2024. [Online]. Available: https://repository.polimdo.ac.id/3019/1/Modul%202 -\\nTeori.pdf  \\n[20]  S. J. Murdoch and S. Lewis, “Embedding Covert Channels into TCP/IP ,” in Information Hiding , vol. \\n3727, M. Barni, J. Herrera -Joancomartí, S. Katzenbeisser, and F. Pérez -González, Eds., in Lecture \\nNotes in Computer Science, vol. 3727. , Berlin, Heidelberg: Springer Berlin Heidelberg, 2005, pp. 247 –\\n261. doi: 10.1007/1155885 9_19.  \\n[21]  C. H. Rowland, “Covert channels in the TCP/IP protocol suite,” First Monday , May 1997, doi: \\n10.5210/fm.v2i5.528.  \\n \\n ', 'The OSI and TCP: IP Reference Models in the Era of Industry 4.0.pdf'), 1386: ('Be Realistic: Automated Program Repair is a Combination of\\nUndecidable Problems\\nAmirfarhad Nilizadeh\\nUniversity of Central Florida, Orlando, Florida, USA\\naf.nilizadeh@knights.ucf.eduGary T. Leavens\\nUniversity of Central Florida, Orlando, Florida, USA\\nleavens@ucf.edu\\nABSTRACT\\nAutomated program repair (APR) tools have promising results,\\nbut what are APR’s limits? The answer could help researchers\\ndesign tool trade-offs and manage user expectations. Since APRis undecidable, as are two of its typical phases, tools must use\\nconservativeapproximations.SuchapproximationscanhelpAPR\\ntools be better understood and can lead to a theory of sound APR.\\nKEYWORDS\\nAutomated Program Repair, Undecidable Problem\\nACM Reference Format:\\nAmirfarhadNilizadehand GaryT.Leavens. 2022.BeRealistic:Automated\\nProgramRepairisaCombinationofUndecidableProblems.In International\\nWorkshop on Automated Program Repair (APR’22), May 19, 2022, Pittsburgh,\\nPA,USA.ACM,NewYork,NY,USA,2pages.https://doi.org/10.1145/3524459.\\n3527346\\n1 INTRODUCTION AND MOTIVATION\\nAutomated Program Repair (APR)aims toautomatically detect and\\nrepairbugs,andthustodecreasethecostofdevelopingsystems[ 4].\\nAPR has proven useful, e.g., atFacebook. However,some studies\\nhave shown that APR tools only work well on repairing bugs in\\nknownbenchmarks[ 3],APRtoolscannotrepairhardandimpor-\\ntant bugs (like bugs in loops) [ 7], and that some results in APR\\nresearch are biased [ 5]. The source of these challenges is APR’s\\nundecidability. We aim to provide realistic expectations for APR.\\nThe inputs to an APR tool are a buggy program and a “specifica-\\ntion”(i.e.,atestsuiteoraformalspecification)thatdescribesthe\\nprogram’s intended behavior. An APR tool should output eithera repaired program or a message that no such repaired program\\nexiststhatcanbefoundwithinthetool’sresourcelimits.APRtools\\nfollow three main phases [ 4]: (P1) bug localization, (P2) generating\\npatches, and (P3) checking candidate patches for correctness.\\nMostAPRresearchisrelatedtogenerating(P2)andvalidatingthe\\ncorrectnessofpatches(P', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1387: ('puts to an APR tool are a buggy program and a “specifica-\\ntion”(i.e.,atestsuiteoraformalspecification)thatdescribesthe\\nprogram’s intended behavior. An APR tool should output eithera repaired program or a message that no such repaired program\\nexiststhatcanbefoundwithinthetool’sresourcelimits.APRtools\\nfollow three main phases [ 4]: (P1) bug localization, (P2) generating\\npatches, and (P3) checking candidate patches for correctness.\\nMostAPRresearchisrelatedtogenerating(P2)andvalidatingthe\\ncorrectnessofpatches(P3).Althoughbuglocalization(P1)andvali-dationofpatches(P3)areundecidable,buglocalizationisthoughtto\\nhave reasonable solutions.1In contrast, generating correct patches,\\ni.e., avoiding overfitting, is an outstanding problem [8, 10].\\n1However, a recent study [3] shows the effect of incorrect bug localization in APR.\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nforprofitorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\\non the first page. Copyrights for components of this work owned by others than ACMmustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,orrepublish,topostonserversortoredistributetolists,requirespriorspecificpermissionand/ora\\nfee. Request permissions from permissions@acm.org.\\nAPR’22, May 19, 2022, Pittsburgh, PA, USA\\n© 2022 Association for Computing Machinery.\\nACM ISBN 978-1-4503-9285-3/22/05...$15.00\\nhttps://doi.org/10.1145/3524459.3527346ThispaperdefinestheproblemscorrespondingtoAPRandnotes\\nthe undecidability of (P1) and (P3). We also discuss conservative\\nsolutions and realistic expectations for APR.\\n2 FORMALIZED PROBLEMS IN APR\\nOverall,APRcan beformalizedasa function, 𝐴𝑃𝑅(𝑃,𝑆,𝜖),where\\n𝑃denotes a program, 𝑆is the associated specification (which is\\na relation between inputs and outputs), and 𝜖is the allowed edit\\ndistance, i.e., the number of possible changes the tool is allowed\\ntomaketo 𝑃tosatisfy 𝑆.2The,outputiseitheraprogram 𝑃/primethat\\nsatisfies𝑆s', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1388: ('definestheproblemscorrespondingtoAPRandnotes\\nthe undecidability of (P1) and (P3). We also discuss conservative\\nsolutions and realistic expectations for APR.\\n2 FORMALIZED PROBLEMS IN APR\\nOverall,APRcan beformalizedasa function, 𝐴𝑃𝑅(𝑃,𝑆,𝜖),where\\n𝑃denotes a program, 𝑆is the associated specification (which is\\na relation between inputs and outputs), and 𝜖is the allowed edit\\ndistance, i.e., the number of possible changes the tool is allowed\\ntomaketo 𝑃tosatisfy 𝑆.2The,outputiseitheraprogram 𝑃/primethat\\nsatisfies𝑆such that distance(𝑃,𝑃/prime)≤𝜖or a message (“no”) if there\\nisnoprogram 𝑃/primethatsatisfies 𝑆suchthat distance(𝑃,𝑃/prime)≤𝜖.Most\\nAPR tools use a maximum edit distance ( 𝜖) that is a small number,\\nmeasuredintokenreplacements.Asmalleditdistancecorresponds\\nto thecompetent programmer hypothesis [2]. If programs are nearly\\ncorrect, then only small changes are needed to repair them, and\\nthese changes should correspond to small edit distances.\\nWhile it might seem that, for a given programming language,\\n𝐴𝑃𝑅(𝑃,𝑆,𝜖)could be solved by enumerating all programs that are\\nwithin distance 𝜖from𝑃and checking to see if they satisfy 𝑆,\\nthat cannot work because an exact solution would decide some\\nknownundecidableproblems.3Forexample,iftheparameter 𝜖is\\n0, then𝐴𝑃𝑅(𝑃,𝑆,0)checks if 𝑃satisfies𝑆, and so𝐴𝑃𝑅performs\\nprogram verification, which is undecidable [ 6] if the specifications\\nare sufficiently powerful; for example, verifying that a program\\nterminateswould solve thehaltingproblem.Therefore, mostAPR\\ntools use a test suite with a resource limit (e.g., a time bound) as\\naspecification,butsuchspecificationsareinherentlyincomplete\\n(forprogramswithinfinitedomains),whichmayleadtooverfitting.\\nConversely, if 𝜖is∞, then𝐴𝑃𝑅(𝑃,𝑆,∞)is synthesizing a program\\nthat satisfies 𝑆, which may also be undecidable, depending on the\\nspecification language used [1].\\nSince APR is undecidable, it is important to understand what\\nasafe,conservativeapproximationwouldbe. 𝐴𝑃𝑅(𝑃,𝑆,𝜖)should\\nguaranteethatifitproducesarepairedprogram 𝑃/prime,then𝑃/primesatisfies\\n𝑆and', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1389: ('resource limit (e.g., a time bound) as\\naspecification,butsuchspecificationsareinherentlyincomplete\\n(forprogramswithinfinitedomains),whichmayleadtooverfitting.\\nConversely, if 𝜖is∞, then𝐴𝑃𝑅(𝑃,𝑆,∞)is synthesizing a program\\nthat satisfies 𝑆, which may also be undecidable, depending on the\\nspecification language used [1].\\nSince APR is undecidable, it is important to understand what\\nasafe,conservativeapproximationwouldbe. 𝐴𝑃𝑅(𝑃,𝑆,𝜖)should\\nguaranteethatifitproducesarepairedprogram 𝑃/prime,then𝑃/primesatisfies\\n𝑆and the distance between 𝑃and𝑃/primeis no greater than 𝜖. However,\\nwhen no solution is found, instead of asserting that no such repair\\nexists, the safe, conservative, alternative is to only say that the tool\\ncould not find a repair.\\n3 SUB-PROBLEMS IN APR\\n3.1 Bug Localization Undecidability\\nWe define program locations as nodes ina program’s parse tree. A\\nset of locations 𝐿/primeiscontained in another such set 𝐿if for every\\n2Aprogram 𝑃satisfiesaspecification 𝑆ifforeveryinput, 𝑖,theresult 𝑣ofrunning\\n𝑃(𝑖)is defined and such that (𝑃(𝑖),𝑣)∈𝑆; this means that 𝑃must halt on input 𝑖.\\n3A problem is undecidable (or unsolvable) if there is no algorithm that can give a\\nprecise answer in a finite amount of time .\\n31International Workshop on Automated Program Repair\\n\\nnode𝑛/prime∈𝐿/primethereis anode 𝑛∈𝐿suchthat 𝑛/primeiscontained inthe\\nsubtree rooted at 𝑛.𝐿/primeisstrictly smaller than𝐿if𝐿/primeis contained\\nin𝐿, but𝐿/prime≠𝐿. Thus, bug localization can be formalized as a\\nfunction FINDBUG (𝑃,𝑆,𝜖)that returns a set of locations 𝐿in the\\nprogram such that it is possible to make the program 𝑃satisfy the\\nspecification 𝑆by no more than 𝜖edits at the locations 𝐿, and such\\nthat there is no such set that is strictly smaller. This is undecidable\\nbecauseFINDBUG (𝑃,𝑆,0)canbe usedtosolve theprogramverifi-\\ncationproblem.Asafe,conservativeanswerfor FINDBUG (𝑃,𝑆,𝜖)\\ncan begiven if 𝜖≠0; suchan answer would onlysay that thebug\\nis contained in the returned set of locations; safer answers are thus\\nhigher in the parse tree (towards the root).\\n3.2 Cand', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1390: ('𝐿in the\\nprogram such that it is possible to make the program 𝑃satisfy the\\nspecification 𝑆by no more than 𝜖edits at the locations 𝐿, and such\\nthat there is no such set that is strictly smaller. This is undecidable\\nbecauseFINDBUG (𝑃,𝑆,0)canbe usedtosolve theprogramverifi-\\ncationproblem.Asafe,conservativeanswerfor FINDBUG (𝑃,𝑆,𝜖)\\ncan begiven if 𝜖≠0; suchan answer would onlysay that thebug\\nis contained in the returned set of locations; safer answers are thus\\nhigher in the parse tree (towards the root).\\n3.2 Candidate Patch Generation\\nGenerating a candidate patch can be formalized as a function\\nGENPATCH (𝑃,𝑆,𝜖,𝐿,𝑡 ), where𝐿=FINDBUG (𝑃,𝑆,𝜖)and𝑡is a\\nnon-negative integer, such that the result 𝑅is a set of programs\\nthat has no more than 𝑡<∞elements, and each 𝑃/prime∈𝑅is such\\nthatdistance(𝑃,𝑃/prime)≤𝜖. The parameter 𝑡is a resource limit. Al-\\nthoughpatchgenerationisdecidable,selectinganefficientstrategy\\nto generate suitable candidate patches may still be difficult.\\n3.3 Patch Validation Undecidability\\nCheckingthatacandidateprogramsatisfiesaspecificationcanalso\\nbeformalizedasafunction VALIDATE (𝑃/prime,𝑆)thattakesacandidate\\nprogram 𝑃/primeand a specification 𝑆and returns a Boolean telling\\nif𝑃/primesatisfies𝑆. This is exactly the program verification problem,\\nand so for a sufficiently powerful specification it is undecidable.\\nTypically,however,APRtoolsuseatest suiteandaresourcelimit\\nasaspecification.Ifthespecificationsarepowerfulenoughtomake\\nthe problem undecidable, a safe, conservative answer is to say that\\n𝑃/primedoesnotsatisfy 𝑆;thatis,when VALIDATE (𝑃/prime,𝑆)istrue,itmust\\nbe that𝑃/primesatisfies𝑆, but when VALIDATE (𝑃/prime,𝑆)is false, it only\\nmeans that 𝑃/primemight not satisfy 𝑆.\\n4 DISCUSSION\\nAPR is an undecidable problem overall. However, that does not\\nmean APR tools cannot be practically useful; it only means that\\nAPR tools must use safe, conservative approximations.\\nAPR tools typically rely on a generate-and-test architecture that\\ninvolvesundecidablesub-problems.Ofthesesub-problems,validat-\\ning candidate repairs is fu', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1391: ('isfy 𝑆;thatis,when VALIDATE (𝑃/prime,𝑆)istrue,itmust\\nbe that𝑃/primesatisfies𝑆, but when VALIDATE (𝑃/prime,𝑆)is false, it only\\nmeans that 𝑃/primemight not satisfy 𝑆.\\n4 DISCUSSION\\nAPR is an undecidable problem overall. However, that does not\\nmean APR tools cannot be practically useful; it only means that\\nAPR tools must use safe, conservative approximations.\\nAPR tools typically rely on a generate-and-test architecture that\\ninvolvesundecidablesub-problems.Ofthesesub-problems,validat-\\ning candidate repairs is fundamental, as it is undecidable for thesame reason as APR as a whole, since it is essentially automated\\nprogramverification.APRsystemsgivesafeanswersoveralland\\nforthevalidationphasethroughtwomechanisms:usingtestsuites\\nwitharesourcelimitasaspecificationandanswering“sorry”when\\na repair cannot be found (instead of asserting no repair exists).\\nBecause program synthesis is decidable for some types of spec-\\nification [ 1] an alternative would be to use program synthesis in\\ndomains where that is decidable.\\nHowever, when APR is applied to specifications that are (in-\\ncomplete) test suites or standard specifications in Hoare logic and\\nif APR is expected to repair standard programs, then a tool must\\nnecessarilyuseconservativeapproximations.First,thereisanap-\\nproximation in detecting a bug, since test suites are incomplete\\nspecifications of behavior (although that makes them computable);\\naconservativeansweristosaythatthereisabugwhenindoubt(e.g.,whenthereisatimeout),becauseanAPRtoolshouldavoid\\ncertifying that a repaired program is correct when it might not\\nbe.Second,thereisanapproximationwhenvalidatingcandidate\\nrepairs;aconservativeansweristosaytherepairmaybeincorrect.\\nAPR systems already seem to follow these ideas. In particular,\\nthey return a message (“sorry”) when they cannot find a repair,\\nwithoutassertingthatthereisnorepairavailable.However,usersof\\nAPRsystemsshouldrealizethat:(a)anAPRtoolhasonlyexamined\\na limited space of possible repairs, and (b) validated repairs maynot be correct with respect to the intended specif', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1392: ('program is correct when it might not\\nbe.Second,thereisanapproximationwhenvalidatingcandidate\\nrepairs;aconservativeansweristosaytherepairmaybeincorrect.\\nAPR systems already seem to follow these ideas. In particular,\\nthey return a message (“sorry”) when they cannot find a repair,\\nwithoutassertingthatthereisnorepairavailable.However,usersof\\nAPRsystemsshouldrealizethat:(a)anAPRtoolhasonlyexamined\\na limited space of possible repairs, and (b) validated repairs maynot be correct with respect to the intended specification, since a\\ntest suite may not capture the intended specification.\\nUsersofAPRsystemsshouldalsorecognizethatthereareseveral\\nengineeringtrade-offsbeingmade.Inparticular,theefficiencyof\\nan APR system (measured by the number of repairs per minute)\\nmust be tradedoff againstthe accuracyof thesystem, sincemore\\ncompletespecifications(e.g.,largertestsuites)wouldresultinmore\\naccurate decisions about repairs [9], but would also slow it down.\\n5 CONCLUSIONS\\nBecauseofAPR’sundecidabilityproblems,usersofAPRsystems\\nmust be realistic about what APR can do. Despite the success of\\nAPR,APRtoolswillnotbeabletorepairallprogramsinastandard\\nprogramming language and the lack of a repair for a program does\\nnot mean that the program cannot be repaired. Tool builders must\\nalsoberealisticinprovidingsafe,conservativeanswerstotheAPR’ssub-problems.However,theundecidabilityofAPRmeansthatthere\\nwill always be work in improving APR tools.\\nACKNOWLEDGEMENT\\nThanks to Elaine Weyuker for feedback on an earlier version.\\nREFERENCES\\n[1]RastislavBodíkandBarbaraJobstmann.2013. Algorithmicprogramsynthesis:\\nintroduction. International journal on software tools for technology transfer 15, 5\\n(2013), 397–411.\\n[2]RichardADeMillo,RichardJLipton,andFrederickGSayward.1978. Hintson\\ntestdataselection:Helpforthepracticingprogrammer. Computer 11,4(1978),\\n34–41.\\n[3]Thomas Durieux, Fernanda Madeiral, Matias Martinez, and Rui Abreu. 2019.\\nEmpiricalreviewofJavaprogramrepairtools:Alarge-scaleexperimenton2,141\\nbugsand23,551repairattempts.In Proceedingsofthe201927thACMJoi', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1393: ('íkandBarbaraJobstmann.2013. Algorithmicprogramsynthesis:\\nintroduction. International journal on software tools for technology transfer 15, 5\\n(2013), 397–411.\\n[2]RichardADeMillo,RichardJLipton,andFrederickGSayward.1978. Hintson\\ntestdataselection:Helpforthepracticingprogrammer. Computer 11,4(1978),\\n34–41.\\n[3]Thomas Durieux, Fernanda Madeiral, Matias Martinez, and Rui Abreu. 2019.\\nEmpiricalreviewofJavaprogramrepairtools:Alarge-scaleexperimenton2,141\\nbugsand23,551repairattempts.In Proceedingsofthe201927thACMJointMeeting\\non European Software Engineering Conference and Symposium on the Foundations\\nof Software Engineering. 302–313.\\n[4]LucaGazzola,DanielaMicucci,andLeonardoMariani.2017. Automaticsoftware\\nrepair: A survey. IEEE Transactions on Software Engineering 45, 1 (2017), 34–67.\\n[5]Kui Liu, Li Li, Anil Koyuncu, Dongsun Kim, Zhe Liu, Jacques Klein, and\\nTegawendé F Bissyandé. 2021. A critical review on the evaluation of automated\\nprogram repair systems. Journal of Systems and Software 171 (2021), 110817.\\n[6]Umang Mathur, P Madhusudan, and Mahesh Viswanathan. 2019. Decidable\\nverification of uninterpreted programs. Proceedings of the ACM on Programming\\nLanguages 3, POPL (2019), 1–29.\\n[7] Manish Motwani, Sandhya Sankaranarayanan, René Just, and Yuriy Brun. 2018.\\nDo automated program repair techniques repair hard and important bugs? Em-\\npirical Software Engineering 23, 5 (2018), 2901–2947.\\n[8]AmirfarhadNilizadeh.2022. Automatedprogramrepairandtestoverfitting:mea-\\nsurementsandapproachesusingformalmethods.In 202215thIEEEConference\\non Software Testing, Verification and Validation (ICST) (In Press). IEEE.\\n[9]AmirfarhadNilizadeh,MarlonCalvo,GaryT.Leavens,andXuan-BachD.Le.2021.\\nMore reliable test suites for dynamic APR by using counterexamples. In 2021\\nIEEE32ndInternationalSymposiumonSoftwareReliabilityEngineering(ISSRE).\\nIEEE, 208–219.\\n[10]Amirfarhad Nilizadeh, Gary T Leavens, Xuan-Bach D Le, Corina S Păsăreanu,and David R Cok. 2021. Exploring true test overfitting in dynamic automated\\nprogram repair using formal methods. In 2', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1394: ('onference\\non Software Testing, Verification and Validation (ICST) (In Press). IEEE.\\n[9]AmirfarhadNilizadeh,MarlonCalvo,GaryT.Leavens,andXuan-BachD.Le.2021.\\nMore reliable test suites for dynamic APR by using counterexamples. In 2021\\nIEEE32ndInternationalSymposiumonSoftwareReliabilityEngineering(ISSRE).\\nIEEE, 208–219.\\n[10]Amirfarhad Nilizadeh, Gary T Leavens, Xuan-Bach D Le, Corina S Păsăreanu,and David R Cok. 2021. Exploring true test overfitting in dynamic automated\\nprogram repair using formal methods. In 2021 14th IEEE Conference on Software\\nTesting, Verification and Validation (ICST). IEEE, 229–240.\\n32', 'Be Realistic- Automated Program Repair is a Combination of Undecidable Problems.pdf'), 1395: ('November 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n1\\nQUANTUM COMPUTING AND\\nTHE ENTANGLEMENT FRONTIER\\nJOHN PRESKILL\\nInstitute for Quantum Information and Matter\\nCalifornia Institute of Technology\\nPasadena, CA 91125, USA\\nQuantum information science explores the frontier of highly complex quantum states,\\nthe \\\\entanglement frontier.\" This study is motivated by the observation (widely believed\\nbut unproven) that classical systems cannot simulate highly entangled quantum systems\\ne\\x0eciently, and we hope to hasten the day when well controlled quantum systems can\\nperform tasks surpassing what can be done in the classical world. One way to achieve\\nsuch \\\\quantum supremacy\" would be to run an algorithm on a quantum computer which\\nsolves a problem with a super-polynomial speedup relative to classical computers, but\\nthere may be other ways that can be achieved sooner, such as simulating exotic quantum\\nstates of strongly correlated matter. To operate a large scale quantum computer reliably\\nwe will need to overcome the debilitating e\\x0bects of decoherence, which might be done\\nusing \\\\standard\" quantum hardware protected by quantum error-correcting codes, or by\\nexploiting the nonabelian quantum statistics of anyons realized in solid state systems,\\nor by combining both methods. Only by challenging the entanglement frontier will we\\nlearn whether Nature provides extravagant resources far beyond what the classical world\\nwould allow.\\nRapporteur talk at the 25th Solvay Conference on Physics\\n\\\\The Theory of the Quantum World\"\\nBrussels, 19-22 October 2011\\n1. Introduction: toward quantum supremacy\\nMy assignment is to report on the current status of quantum information science ,\\nbut I will not attempt to give a comprehensive survey of this rapidly growing \\x0celd.\\nIn particular, I will not discuss recent experimental advances, which will be covered\\nby other rapporteurs.\\nTo convey the spirit driving the subject, I will focus on one Big Question:\\nCan we control complex quantum systems and if we can, so ', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1396: ('\\\\The Theory of the Quantum World\"\\nBrussels, 19-22 October 2011\\n1. Introduction: toward quantum supremacy\\nMy assignment is to report on the current status of quantum information science ,\\nbut I will not attempt to give a comprehensive survey of this rapidly growing \\x0celd.\\nIn particular, I will not discuss recent experimental advances, which will be covered\\nby other rapporteurs.\\nTo convey the spirit driving the subject, I will focus on one Big Question:\\nCan we control complex quantum systems and if we can, so what?\\nQuantum information science explores, not the frontier of short distances as in\\nparticle physics, or of long distances as in cosmology, but rather the frontier of\\nhighly complex quantum states, the entanglement frontier . I will address whether\\nwe can probe deeply into this frontier and what we might \\x0cnd or accomplish by\\ndoing so. This Big Question does not encompass everything of interest in quantumarXiv:1203.5813v3  [quant-ph]  10 Nov 2012\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n2\\ninformation science, but it gets to the heart of what makes the \\x0celd compelling.\\nThe quantum informationists are rebelling against a fundamental dualism we\\nlearned in school:\\nThe macroscopic world is classical.\\nThe microscopic world is quantum.\\nWe fervently wish for controlled quantum systems that are large yet exhibit pro-\\nfoundly quantum behavior. The reason we \\x0cnd this quest irresistible can be stated\\nsuccinctly:\\nClassical systems cannot in general simulate quantum systems e\\x0eciently.\\nWe cannot yet prove this claim, either mathematically or experimentally, but we\\nhave reason to believe it is true; arguably, it is one of the most interesting distinc-\\ntions ever made between quantum and classical. It means that well controlled large\\nquantum systems may \\\\surpass understanding,\" behaving in ways we \\x0cnd surprising\\nand delightful.\\nWe therefore hope to hasten the onset of the era of quantum supremacy , when we\\nwill be able to perform tasks with controlled quantum systems goi', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1397: (' systems e\\x0eciently.\\nWe cannot yet prove this claim, either mathematically or experimentally, but we\\nhave reason to believe it is true; arguably, it is one of the most interesting distinc-\\ntions ever made between quantum and classical. It means that well controlled large\\nquantum systems may \\\\surpass understanding,\" behaving in ways we \\x0cnd surprising\\nand delightful.\\nWe therefore hope to hasten the onset of the era of quantum supremacy , when we\\nwill be able to perform tasks with controlled quantum systems going beyond what\\ncan be achieved with ordinary digital computers. To realize that dream, we must\\novercome the formidable enemy of decoherence , which makes typical large quantum\\nsystems behave classically. So another question looms over the subject:\\nIs controlling large-scale quantum systems merely really, really hard , or\\nis itridiculously hard ?\\nIn the former case we might succeed in building large-scale quantum computers\\nafter a few decades of very hard work. In the latter case we might not succeed for\\ncenturies, if ever.\\nThis question is partly about engineering but it is about physics as well (and\\nindeed the boundary between the two is not clearly de\\x0cned). If quantum supremacy\\nturns out to be unattainable, it may be due to physical laws yet to be discovered.\\nIn any case, the quest for large-scale quantum computing will push physics into a\\nnew regime never explored before. Who knows what we\\'ll \\x0cnd?\\n2. Quantum entanglement and the vastness of Hilbert space\\nAt the core of quantum information science is entanglement, the characteristic cor-\\nrelations among the parts of a quantum system, which have no classical analog. We\\nmay imagine a quantum system with many parts, like a 100 page quantum book.\\nIf the book were classical, we could read 10 of the pages and learn about 10% of\\nthe content of the book. But for a typical 100-page quantum book, if we read 10\\npages we learn almost nothing about the content of the book; the information is\\nnot printed on the individual pages | rather nearly all the information in the bo', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1398: ('lement, the characteristic cor-\\nrelations among the parts of a quantum system, which have no classical analog. We\\nmay imagine a quantum system with many parts, like a 100 page quantum book.\\nIf the book were classical, we could read 10 of the pages and learn about 10% of\\nthe content of the book. But for a typical 100-page quantum book, if we read 10\\npages we learn almost nothing about the content of the book; the information is\\nnot printed on the individual pages | rather nearly all the information in the book\\nis encoded in the correlations among the pages. (See Fig. 1.) These correlations are\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n3\\nvery complex, so that recording a complete classical description of the quantum\\nstate would require a classical book of astronomical size.\\nDoes Nature really indulge in such extravagant resources, and how can we verify\\nit?\\nThis \\nPage \\nBlank \\nThis \\nPage \\nBlank \\nThis \\nPage \\nBlank \\nThis \\nPage \\nBlank \\nThis \\nPage \\nBlank …. …. \\nFig. 1. For a typical quantum state with many parts, a measurement acting on just one part\\ncollects a negligible amount of information about the state.\\nThe issue is subtle. Yes, the Hilbert space of a large quantum system is vast,\\nbecause the classical description of a typical pure quantum state is enormously long.\\nBut we don\\'t really care about typical quantum states, because preparing them is\\ncompletely infeasible.1The only quantum states that are physically relevant are\\nthose that can be prepared with reasonable (quantum) resources, which are con\\x0cned\\nto an exponentially small portion of the full Hilbert space (Fig. 2a). Only these\\ncan arise in Nature, and only these will ever be within the reach of the quantum\\nengineers as technology advances.\\nMathematically, we may model the feasible quantum states this way: Imagine\\nwe havenqubits (two-level quantum systems) which are initially in an uncorrelated\\nproduct state. Then we perform a quantum circuit, a sequence of unitary operations\\n(\\\\quantum gates\") acting on', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1399: ('asonable (quantum) resources, which are con\\x0cned\\nto an exponentially small portion of the full Hilbert space (Fig. 2a). Only these\\ncan arise in Nature, and only these will ever be within the reach of the quantum\\nengineers as technology advances.\\nMathematically, we may model the feasible quantum states this way: Imagine\\nwe havenqubits (two-level quantum systems) which are initially in an uncorrelated\\nproduct state. Then we perform a quantum circuit, a sequence of unitary operations\\n(\\\\quantum gates\") acting on pairs of qubits, where the total number of quantum\\ngates is \\\\reasonable,\" let us say growing no faster than polynomially with n. Equiv-\\nalently, we may say that a state is feasible if it can be constructed, starting with a\\nproduct state, by evolving with a local Hamiltonian for a reasonable time. Likewise,\\nwe say a measurement is feasible if it can be constructed as a quantum circuit of\\nsize polynomial in n, followed by single-qubit measurements.\\nThese quantumly feasible states and measurements are plausibly allowed by\\nNature. Though far from \\\\typical,\" they may nevertheless be hard to simulate\\nclassically. That is why quantum computing is exciting and potentially powerful.\\n3. Separating classical from quantum\\nThe best evidence for such a separation between quantum and classical complexity\\ncomes from quantum algorithms that perform tasks going beyond what we know\\nhow to do with classical digital computers (Fig. 2b). The most famous examples are\\nShor\\'s algorithms for \\x0cnding the prime factors of integers and evaluating discrete\\nlogarithms,2which are based on using a fast quantum Fourier transform to probe\\nthe period of a function.\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n4\\nHilbert \\nSpace \\nwhat we \\ncare about \\n(a)\\nClassically \\nEasy Quantumly Hard \\nQuantumly \\nEasy (b)\\nFig. 2. (a) Hilbert space is vast, but the quantum states that can be prepared with reasonable\\nresources occupy only a small part of it. (b) We believe that quantum computers can solve some\\npro', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1400: ('valuating discrete\\nlogarithms,2which are based on using a fast quantum Fourier transform to probe\\nthe period of a function.\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n4\\nHilbert \\nSpace \\nwhat we \\ncare about \\n(a)\\nClassically \\nEasy Quantumly Hard \\nQuantumly \\nEasy (b)\\nFig. 2. (a) Hilbert space is vast, but the quantum states that can be prepared with reasonable\\nresources occupy only a small part of it. (b) We believe that quantum computers can solve some\\nproblems that are hard for classical computers, but even quantum computers have limitations.\\nThere are other such \\\\superpolynomial\" speedups known, in which the time\\nrequired to solve a problem scales polynomially with the input size when a quan-\\ntum computer is used, but faster than polynomially when a classical computer is\\nused. For example, by e\\x0eciently simulating topological quantum \\x0celd theory using\\na quantum computer, we can evaluate approximately certain topological invariants\\nof links and 3-manifolds ( e.g., the Jones polynomial3,4or Turaev-Viro invariant5).\\nIn fact, approximate evaluation of such topological invariants is a BQP-hard prob-\\nlem, meaning that any problem that a quantum computer can solve e\\x0eciently can\\nbe reduced to an instance of the problem of additively approximating the Jones\\npolynomial of a link.\\nA superpolynomial speedup is also achieved by a quantum algorithm for com-\\nputing properties of solutions to systems of linear equations.6For example, if Ais\\nanN\\x02NHermitian matrix, and xsolvesAx=bwherexandbareN-component\\nvectors, then a quantum algorithm can estimate xyMxin a time scaling like a power\\nof logN, providedjbiis an e\\x0eciently preparable quantum state, Ais sparse, and\\nMis an e\\x0eciently measurable operator. This problem, too, is BQP-hard.\\nSomeday, we hope to probe quantum physics in a previously unexplored regime\\nby running fast quantum algorithms on quantum computers. For this purpose, it is\\nconvenient that the problems with superpolynomial speedups include some problems\\n(like factoring', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1401: ('Ax=bwherexandbareN-component\\nvectors, then a quantum algorithm can estimate xyMxin a time scaling like a power\\nof logN, providedjbiis an e\\x0eciently preparable quantum state, Ais sparse, and\\nMis an e\\x0eciently measurable operator. This problem, too, is BQP-hard.\\nSomeday, we hope to probe quantum physics in a previously unexplored regime\\nby running fast quantum algorithms on quantum computers. For this purpose, it is\\nconvenient that the problems with superpolynomial speedups include some problems\\n(like factoring) in the class NP, where the solution can be checked e\\x0eciently with a\\nclassical computer. Running the factoring algorithm, and checking it classically, we\\nwill be able to test whether Nature admits quantum processes going beyond what\\ncan be classically simulated. (However, this test is not airtight, because we have no\\nproof that factoring is really classically hard.)\\nWhile quantum algorithms achieving superpolynomial speedups relative to clas-\\nsical algorithms are relatively rare, those achieving less spectacular polynomial\\nspeedups are more common. For example, a quantum computer can perform ex-\\nhaustive search for a solution to a constraint satisfaction problem in a time scaling\\nlike the square root of the classical time,7essentially because in quantum theory a\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n5\\nprobability is the square of an amplitude. By simulating a quantum walk on a graph,\\na quantum computer can also speed up the evaluation of a Boolean formula,8and\\nhence determine, for example, whether a two-player game has a winning strategy.\\nBut again the speedup is merely polynomial.\\nIt seems that superpolynomial speedups are possible only for problems with\\nspecial structure well matched to the power of a quantum computer. We do not\\nexpect superpolynomial speedups for the worst-case instances of problems in the\\nNP class, such as 3-SAT or the Traveling Salesman Problem. For such problems\\nwith no obvious structure, we might not be able to do better than q', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1402: ('ormula,8and\\nhence determine, for example, whether a two-player game has a winning strategy.\\nBut again the speedup is merely polynomial.\\nIt seems that superpolynomial speedups are possible only for problems with\\nspecial structure well matched to the power of a quantum computer. We do not\\nexpect superpolynomial speedups for the worst-case instances of problems in the\\nNP class, such as 3-SAT or the Traveling Salesman Problem. For such problems\\nwith no obvious structure, we might not be able to do better than quadratically\\nspeeding up exhaustive search for a solution.9\\nBut problems outside the class NP are also potentially of interest. Indeed, the\\n\\\\natural\" application for a quantum computer is simulating evolution governed by\\na local Hamiltonian, preceded by the preparation of a reasonable state and followed\\nby measurement of a reasonable observable.10In such cases the \\x0cndings of the\\nquantum computer might not be easy to check with a classical computer; instead\\none quantum computer could be checked by another, or by doing an experiment\\n(which is almost the same thing).\\nAs we strive toward the goal of quantum supremacy, it will be useful to gain\\na deeper understanding of two questions: (1) What quantum tasks are feasible?\\n(2) What quantum tasks are hard to simulate classically? Conceivably, it will turn\\nout that the extravagant exponential resources seemingly required for the classi-\\ncal description and simulation of generic quantum states are illusory; perhaps the\\nquantum states realized in Nature really do admit succinct classical descriptions,\\neither because the laws of physics governing complex quantum systems are di\\x0berent\\nthan we currently expect, or because there are clever ways to simulate the quantum\\nworld classically that have somehow eluded us so far.\\n4. Easiness and hardness\\nThough we have sound reasons for believing that general quantum computations are\\nhard to simulate classically, in some special cases the simulation is known to be easy.\\nSuch examples provide guidance as we seek a path toward quantum su', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1403: ('succinct classical descriptions,\\neither because the laws of physics governing complex quantum systems are di\\x0berent\\nthan we currently expect, or because there are clever ways to simulate the quantum\\nworld classically that have somehow eluded us so far.\\n4. Easiness and hardness\\nThough we have sound reasons for believing that general quantum computations are\\nhard to simulate classically, in some special cases the simulation is known to be easy.\\nSuch examples provide guidance as we seek a path toward quantum supremacy.\\nSuppose for example, that nqubits are arranged in a line, and consider a quan-\\ntum circuit such that, for any way of cutting the line into two segments, the number\\nof gates that cross the cut is modest, only logarithmic in n. Then, if the initial state\\nis a pure product state, the quantum state has a succinct classical description at\\nall times, and the classical simulation of the quantum computation can be done\\ne\\x0eciently.11,12The quantum computation does not achieve a super-classical task,\\nbecause the quantum state becomes only slightly entangled.\\nCorrespondingly, if you receive multiple copies of an n-qubit state that is only\\nslightly entangled, you would be able to identify the state with a feasible number\\nof measurements. In general, quantum state tomography is hard | Hilbert space\\nis so large that a number of measurements exponential in nwould be required to\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n6\\ndetermine a typical n-qubit state. But for a slightly entangled state, a number of\\nmeasurements linear in nsu\\x0eces.13We can perform tomography on segments of\\nconstant size, then do an e\\x0ecient classical computation to determine how the pieces\\nare stitched together.\\nGaussian quantum dynamics is also easy to simulate.14Consider an interferome-\\nter assembled from linear optical elements, which can be described by a Hamiltonian\\nquadratic in bosonic creation and annihilation operators. Suppose that a Gaussian\\ninitial state (a coherent state, for example', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1404: ('or a slightly entangled state, a number of\\nmeasurements linear in nsu\\x0eces.13We can perform tomography on segments of\\nconstant size, then do an e\\x0ecient classical computation to determine how the pieces\\nare stitched together.\\nGaussian quantum dynamics is also easy to simulate.14Consider an interferome-\\nter assembled from linear optical elements, which can be described by a Hamiltonian\\nquadratic in bosonic creation and annihilation operators. Suppose that a Gaussian\\ninitial state (a coherent state, for example) enters the input ports, and that we\\nmeasure quadrature amplitudes at the output ports. Then the state has a suc-\\ncinct description at all times and can be simulated classically. But if we introduce\\nsome optical nonlinearity, or single photon sources together with adaptive photon\\ncounting measurements, then this system has the full power of a universal quantum\\ncomputer, and presumably it cannot be simulated classically.15,16Here \\\\adaptive\"\\nmeans that subsequent operations can be conditioned on the outcomes of earlier\\nmeasurements.\\nFree fermions are likewise easy to simulate classically, and, in contrast to free\\nbosons, adaptive measurements of the fermion mode numbers do not add compu-\\ntational power.17,18But if we add four-fermion operators to the Hamiltonian, or\\nif we allow nondestructive measurements of four-fermion operators, then universal\\nquantum computation is achievable.19\\nU| 0 |1 〉+〉\\n( )1 1 1 Re tr 2p U d+\\uf8eb \\uf8f6 = + \\uf8ec \\uf8f7 \\uf8ed \\uf8f8 Measure | 0 |1 〉±〉\\nmaximally \\nmixed \\nFig. 3. The trace of a large matrix can be computed in the \\\\one-clean-qubit\" model of quantum\\ncomputation, for which the input is one pure qubit and many maximally mixed qubits.\\n|n⊗+〉UZ|n⊗+〉Measure \\nX\\n(a)\\nm×m\\nunitary nphotons \\nin\\nmmodes (b)\\nFig. 4. Two quantum systems that may be hard to simulate classically. (a) A quantum circuit\\nwith commuting gates. (b) Nonadaptive linear optics with photon sources and photon detectors.\\nSome computational models, though apparently weaker than the full blown\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1405: (' computed in the \\\\one-clean-qubit\" model of quantum\\ncomputation, for which the input is one pure qubit and many maximally mixed qubits.\\n|n⊗+〉UZ|n⊗+〉Measure \\nX\\n(a)\\nm×m\\nunitary nphotons \\nin\\nmmodes (b)\\nFig. 4. Two quantum systems that may be hard to simulate classically. (a) A quantum circuit\\nwith commuting gates. (b) Nonadaptive linear optics with photon sources and photon detectors.\\nSome computational models, though apparently weaker than the full blown\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n7\\nquantum circuit model, nevertheless seem to have surprising power. One intriguing\\ncase is the \\\\one-clean-qubit model\", in which the input to the computation is one\\nqubit in a pure state and many qubits in a maximally mixed state;20see Fig. 3.\\nThe study of this model was motivated initially by the nuclear-magnetic-resonance\\napproach to quantum computing, where the initial state may be highly mixed.21,22\\nThe one-clean-qubit quantum computer can evaluate the trace of an exponentially\\nlarge unitary operator if the operator can be realized by an e\\x0ecient quantum circuit.\\nThis capability can be exploited to approximate the Jones polynomial of the trace\\nclosure of a braid23or the Turaev-Viro invariant of a three-dimensional mapping\\ntorus,24problems for which no e\\x0ecient classical algorithms are known; in fact these\\nproblems are complete for the one-clean-qubit class.\\nAnother provocative example is the \\\\instantaneous quantum computing\"\\nmodel.25Here all the gates executed by our quantum computer are mutually com-\\nmuting, simultaneously diagonal in the standard Zbasis. In addition we can prepare\\nsingle qubits in eigenstates of the conjugate operator X, and measure qubits in the\\nXbasis; see Fig. 4a. (Because all the gates commute, in principle they can be\\nexecuted simultaneously.) It is not obvious how to simulate this simple quantum\\ncircuit classically, and there is evidence from complexity theory that the simulation\\nis actually hard.25Even though the model does not seem to have', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1406: ('our quantum computer are mutually com-\\nmuting, simultaneously diagonal in the standard Zbasis. In addition we can prepare\\nsingle qubits in eigenstates of the conjugate operator X, and measure qubits in the\\nXbasis; see Fig. 4a. (Because all the gates commute, in principle they can be\\nexecuted simultaneously.) It is not obvious how to simulate this simple quantum\\ncircuit classically, and there is evidence from complexity theory that the simulation\\nis actually hard.25Even though the model does not seem to have the full power\\nof universal quantum (or even classical) computing, nevertheless it may in a sense\\nperform a super-classical task.\\nYet another tantalizing case is linear optics accompanied by photon sources and\\nphoton detectors, but now without adaptive measurements; see Fig. 4b. Suppose we\\nhavemoptical modes, where initially n<m are occupied by single photons and the\\nrest are empty. A linear optics array mixes the mmodes, and then a measurement\\nis performed to see which of the output modes are occupied. Though this system is\\nnot a universal quantum computer, we do not know how to simulate it classically,\\nand there is evidence from complexity theory that the simulation is hard.26\\nSuch examples illustrate that there may be easier ways to achieve quantum\\nsupremacy than by operating a general purpose quantum computer. Admittedly,\\nthough, this linear optics experiment is still not at all easy | to reach the regime\\nwhere digital simulation is currently infeasible one should detect a coincidence of\\nabout 30 photons, whose paths through the interferometer can interfere. Further-\\nmore, it is not clear how the hardness of simulating this system classically would\\nbe a\\x0bected by including realistic noise sources, such as photon loss.\\n5. Local Hamiltonians\\nAn important task that a quantum computer can perform e\\x0eciently is simulating\\nthe dynamics of a quantum system governed by a local Hamiltonian H.27By \\\\local\"\\nI do not necessarily mean geometrically local in some spatial dimension; instead,\\nI mean that the Hilbert space ha', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1407: (', whose paths through the interferometer can interfere. Further-\\nmore, it is not clear how the hardness of simulating this system classically would\\nbe a\\x0bected by including realistic noise sources, such as photon loss.\\n5. Local Hamiltonians\\nAn important task that a quantum computer can perform e\\x0eciently is simulating\\nthe dynamics of a quantum system governed by a local Hamiltonian H.27By \\\\local\"\\nI do not necessarily mean geometrically local in some spatial dimension; instead,\\nI mean that the Hilbert space has a decomposition into qubits (or other small\\nsystems), and Hcan be expressed as a sum of terms, each of which acts on a\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n8\\nconstant number of qubits (independent of the system size). More generally, the\\nsimulation is feasible if His a sparse matrix.28\\nThis capability can be exploited to measure the energy of the system, as in\\nFig. 5. The quantum circuit shown evolves an initial state j ifor a timetstored\\nin an auxiliary register, then performs a quantum Fourier transform and reads\\nout the register to sample from the frequency spectrum of the operator e\\x00iHt, a\\nprocedure called phase estimation .29The accuracy of the measured eigenvalue, in\\naccord with the energy-time uncertainty relation, is inversely proportional to the\\nmaximal evolution time; hence, for an n-qubit system, accuracy scaling like an\\ninverse polynomial in ncan be achieved by a quantum circuit with size polynomial\\ninn.\\niHt e−QFT \\n|ψ〉2 1 \\n0|m\\ntt−\\n=〉∑ 1 2 1 0 m m k k k k k − − … =\\n| exp(2 / 2 ) m\\nk ik \\nλ π ≈ 〉\\nFig. 5. The energy of a system governed by a local Hamiltonian can be measured e\\x0eciently by\\na quantum computer, using a procedure called \\\\phase estimation.\"\\nIf the initial state j ihas an overlap with the ground state of Hwhich is not\\nsmaller than inverse polynomial in n, it follows that we can measure the ground-\\nstate energy to inverse polynomial accuracy in polynomial time using a quantum\\ncomputer. This algorithm has noteworthy applications; for', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1408: ('1 2 1 0 m m k k k k k − − … =\\n| exp(2 / 2 ) m\\nk ik \\nλ π ≈ 〉\\nFig. 5. The energy of a system governed by a local Hamiltonian can be measured e\\x0eciently by\\na quantum computer, using a procedure called \\\\phase estimation.\"\\nIf the initial state j ihas an overlap with the ground state of Hwhich is not\\nsmaller than inverse polynomial in n, it follows that we can measure the ground-\\nstate energy to inverse polynomial accuracy in polynomial time using a quantum\\ncomputer. This algorithm has noteworthy applications; for example, a quantum\\ncomputer can compute the ground-state energy of a large molecule.30\\nBut there is a catch | preparing an initial state that overlaps substantially\\nwith the ground state could be very hard in some cases. This is already true clas-\\nsically; \\x0cnding the ground state of a classical spin glass is NP-hard, as hard as any\\nproblem whose solution can be checked e\\x0eciently by a classical computer. Finding\\nthe ground state for a quantum system with a local Hamiltonian seems to be even\\nharder; it is QMA-hard,31as hard as any problem whose solution can be checked\\ne\\x0eciently by a quantum computer, and we expect that QMA is a larger class than\\nNP. Surprisingly, computing the ground-state energy seems to be a hard problem\\nfor a quantum computer even for the case of a geometrically local translationally-\\ninvariant quantum system in one dimension.32\\nA general procedure for preparing ground states is adiabatic evolution. We can\\nprepare a state having sizable overlap with the ground state of Hby starting with\\nthe easily prepared ground state of a simpler Hamiltonian H(0), then slowly de-\\nforming the Hamiltonian along a path H(s) connecting H(0) toH(1) =H. This\\nprocedure succeeds in polynomial time provided the energy gap \\x01( s) between the\\nground and \\x0crst excited states of H(s) is no smaller than inverse polynomial in n\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n9\\nfor alls2[0;1] along the path. For problem instances that are quantumly hard,\\nthen, the gap becomes', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1409: (' easily prepared ground state of a simpler Hamiltonian H(0), then slowly de-\\nforming the Hamiltonian along a path H(s) connecting H(0) toH(1) =H. This\\nprocedure succeeds in polynomial time provided the energy gap \\x01( s) between the\\nground and \\x0crst excited states of H(s) is no smaller than inverse polynomial in n\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n9\\nfor alls2[0;1] along the path. For problem instances that are quantumly hard,\\nthen, the gap becomes superpolynomially small somewhere along the path.33\\nThough the general problem is quantumly hard, we may surmise that there\\nare many local quantum systems for which computing the ground-state energy is\\nquantumly easy yet classically hard. Furthermore, a quantum computer may be\\nable to simulate the evolution of excited states in cases where the simulation is\\nclassically hard, such as chemical reactions34or the scattering of particles described\\nby quantum \\x0celd theory.35Even in the case of quantum gravity, evolution may\\nbe governed by a local Hamiltonian, and therefore admit e\\x0ecient simulation by a\\nquantum computer.\\n6. Quantum error correction\\nClassical digital computers exist, and have had a transformative impact on our lives.\\nLarge-scale quantum computers do not yet exist. Why not?\\nBuilding reliable quantum hardware is challenging because of the di\\x0eculty of\\ncontrolling quantum systems accurately. Small errors in quantum gates accumulate\\nin a large circuit, eventually leading to large errors that foil the computation. Fur-\\nthermore, qubits in a quantum computer inevitably interact with their surroundings;\\ndecoherence arising from unwanted correlations with the environment is harmless\\nin a classical computer (and can even be helpful, by introducing friction which im-\\npedes accidental bit \\rips), but decoherence in a quantum computer can irreparably\\ndamage the delicate superposition states processed by the machine.\\nQuantum information might be better protected against noise by using a quan-\\ntum error-correcting cod', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1410: ('utation. Fur-\\nthermore, qubits in a quantum computer inevitably interact with their surroundings;\\ndecoherence arising from unwanted correlations with the environment is harmless\\nin a classical computer (and can even be helpful, by introducing friction which im-\\npedes accidental bit \\rips), but decoherence in a quantum computer can irreparably\\ndamage the delicate superposition states processed by the machine.\\nQuantum information might be better protected against noise by using a quan-\\ntum error-correcting code, in which \\\\logical\" information is encoded redundantly\\nin a block of many physical qubits.36,37Quantum error correction is in some ways\\nmuch like classical error correction, but more di\\x0ecult, because while a classical code\\nneed only protect against bit \\rips, a quantum code must protect against both bits\\n\\rips and phase errors.\\nSuppose for example, that we want to encode a single logical qubit, with or-\\nthonormal basis states denoted j0iandj1i, which is protected against all the errors\\nspanned by a setfEag. For the distinguishability of the basis states to be maintained\\neven when errors occur, we require\\nEaj0i?Ebj1i; (1)\\nwhereEa;Ebare any two elements of the error basis. This condition by itself would\\nsu\\x0ece for reliable storage of a classical bit.\\nBut for storage of a qubit we also require protection against phase errors, which\\noccur when information about whether the state is j0iorj1ileaks to the environ-\\nment; equivalently, distinguishability should be maintained for the dual basis states\\nj0i\\x06j1i:\\nEa(j0i+j1i)?Eb(j0i\\x00j1i); (2)\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n10\\nwhereEa;Ebare any two errors. In fact, the two distinguishability conditions Eq. (1)\\nand (2) su\\x0ece to ensure the existence of a recovery map that corrects any error\\nspanned byfEagacting on any linear combination of j0iandj1i.38\\nTogether, Eq. (1) and (2) imply\\nh0jEy\\naEbj0i=h1jEy\\naEbj1i; (3)\\nno measurement of any operator in the set fEy\\naEbgcan distinguish the two basis\\nstates of the logica', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1411: ('i)?Eb(j0i\\x00j1i); (2)\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n10\\nwhereEa;Ebare any two errors. In fact, the two distinguishability conditions Eq. (1)\\nand (2) su\\x0ece to ensure the existence of a recovery map that corrects any error\\nspanned byfEagacting on any linear combination of j0iandj1i.38\\nTogether, Eq. (1) and (2) imply\\nh0jEy\\naEbj0i=h1jEy\\naEbj1i; (3)\\nno measurement of any operator in the set fEy\\naEbgcan distinguish the two basis\\nstates of the logical qubit. Typically, because we expect noise acting collectively on\\nmany qubits at once to be highly suppressed, we are satis\\x0ced to correct low-weight\\nerrors, those that act nontrivially on a su\\x0eciently small fraction of all the qubits\\nin the code block. Then Eq. (3) says that all the states of the logical qubit look\\nthe same when we examine a small subsystem of the code block. These states are\\nhighly entangled, like the hundred-page book that reveals no information when we\\nread the individual pages.\\nclassical memory: \\nferromagnet order quantum memory: \\ntopological order XZ\\nFig. 6. A prototypical classical memory is a ferromagnet, and a prototypical quantum memory\\nis a topologically ordered medium.\\nIt is useful to formulate the distinction between classical and quantum error\\ncorrection in more physical terms (see Fig. 6). The prototype for a protected classical\\nmemory is a ferromagnet, where a single bit is encoded according to whether most\\nof the spins are up or down. The encoded bit can be read out by performing local\\nmeasurements on all spins, and then executing a majority vote to protect against\\nerrors that \\rip a minority of the spins. Errors in the memory create domain walls\\nwhere neighboring spins misalign, and a logical error occurs when a domain wall\\nsweeps across the sample, inducing a global operation acting on many spins. The\\nmemory is robust at a su\\x0eciently small nonzero temperature because the energy\\ncost of a large droplet of \\ripped spins is large. This memory is a particularly simple\\nphysically mo', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1412: ('ming local\\nmeasurements on all spins, and then executing a majority vote to protect against\\nerrors that \\rip a minority of the spins. Errors in the memory create domain walls\\nwhere neighboring spins misalign, and a logical error occurs when a domain wall\\nsweeps across the sample, inducing a global operation acting on many spins. The\\nmemory is robust at a su\\x0eciently small nonzero temperature because the energy\\ncost of a large droplet of \\ripped spins is large. This memory is a particularly simple\\nphysically motivated example of a classical error-correcting code; there are more\\nsophisticated examples.\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n11\\nThe prototype for a protected quantum memory is a medium in two dimensions\\nwithZ2topological order.39We may consider a planar sample with a large hole\\nin the middle. In contrast to the ferromagnet, errors in the medium create point-\\nlike quasiparticles (\\\\anyons\") rather than domains walls. There are two types of\\nanyons (which we may regard as \\\\electric\" and \\\\magnetic\" excitations), having Z2\\nAharonov-Bohm interactions with one another. The space of quantum states with\\nno particles present is two-dimensional | this space is the encoded qubit. Logical\\nerrors can be induced by the transport of particles; a logical Xacts on the encoded\\nqubit if an electric particle travels between the inner and outer boundaries of the\\nsample, and a logical Zerror acts if a magnetic particle travels around the hole. Cor-\\nrespondingly, we read out the logical qubit in the Xbasis by measuring a nonlocal\\nstring-like operator which connects the inner and outer boundaries, simulating the\\npropagation of an electric particle, while we read it out in the Zbasis by measuring\\na string operator that encloses the hole in the sample, simulating the propagation\\nof a magnetic particle.\\nThe system is protected by a nonzero energy gap, the energy cost of creating a\\npair of particles. Hence the storage time is long if the temperature is small compared\\nto the g', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1413: ('ad out the logical qubit in the Xbasis by measuring a nonlocal\\nstring-like operator which connects the inner and outer boundaries, simulating the\\npropagation of an electric particle, while we read it out in the Zbasis by measuring\\na string operator that encloses the hole in the sample, simulating the propagation\\nof a magnetic particle.\\nThe system is protected by a nonzero energy gap, the energy cost of creating a\\npair of particles. Hence the storage time is long if the temperature is small compared\\nto the gap, but unlike the case of a two-dimensional ferromagnet the storage time\\ndoes not improve as the system size increases. However, if we monitor the particles\\nas they di\\x0buse through the sample, then a logical error occurs only if particles\\npropagate across the sample without being noticed, an event which does become\\nincreasingly unlikely as the system size grows.40\\nA topologically ordered medium on a topologically nontrivial surface is a special\\ntype of quantum error-correcting code, one that can be realized as the ground\\nstate of a system with a geometrically local Hamiltonian; in this respect its status\\nis similar to that of the ferromagnet in classical coding theory. The locality of the\\nHamiltonian has advantages. For one, we might be able to realize a relatively robust\\nquantum memory described by a Hamiltonian in the universality class of the code.\\nFrom a more abstract viewpoint, we can collect information about the errors in the\\ncode block by making localized measurements, e.g., by identifying domain walls in\\nthe ferromagnet or quasiparticle excitations (anyons) in the topologically ordered\\nmedium.\\n7. Scalable quantum computing\\nThe theory of quantum error correction establishes that quantum computing is\\n\\\\scalable\" in principle. This means that, if the noise strength is below a critical\\nvalue (the \\\\accuracy threshold\"), then we can simulate an ideal quantum circuit\\naccurately using a circuit of noisy gates, with a reasonable overhead cost in addi-\\ntional gates and additional qubits.41{45The numerical value o', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1414: ('s in\\nthe ferromagnet or quasiparticle excitations (anyons) in the topologically ordered\\nmedium.\\n7. Scalable quantum computing\\nThe theory of quantum error correction establishes that quantum computing is\\n\\\\scalable\" in principle. This means that, if the noise strength is below a critical\\nvalue (the \\\\accuracy threshold\"), then we can simulate an ideal quantum circuit\\naccurately using a circuit of noisy gates, with a reasonable overhead cost in addi-\\ntional gates and additional qubits.41{45The numerical value of the threshold, and\\nthe overhead cost, depend on the fault-tolerant scheme used and on how we model\\nthe noise.\\nEngineering considerations favor a two-dimensional layout with short-range in-\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n12\\nteractions among the qubits, for which the computation can be protected against\\nnoise by using a topological code like the one described in Sec. 6. A topological\\nmedium can be simulated using any convenient type of quantum hardware, with\\nthe physical qubits carried by, for example, trapped ions, electron spins in quan-\\ntum dots, or superconducting circuits. To encode many logical qubits, the simulated\\nmedium has many holes, and logical errors are suppressed by ensuring that the holes\\nare su\\x0eciently large and distantly separated from one another. A complete set of\\nuniversal quantum gates can be executed on the encoded qubits; hence arbitrary\\nquantum circuits can be simulated e\\x0eciently and reliably.40,46\\nThere are many challenges to making large-scale fault-tolerant quantum com-\\nputing practical, including serious systems engineering issues. There are also issues\\nof principle to consider, such as, what is required for a fault-tolerant scheme to be\\nscalable, and what conditions must be satis\\x0ced by the noise model? One essential\\nrequirement is some form of cooling, to extract the entropy introduced by noise.47\\nParallel operations are also necessary, so noise can be controlled in di\\x0berent parts\\nof the computer simultaneously.\\nIt ', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1415: ('enges to making large-scale fault-tolerant quantum com-\\nputing practical, including serious systems engineering issues. There are also issues\\nof principle to consider, such as, what is required for a fault-tolerant scheme to be\\nscalable, and what conditions must be satis\\x0ced by the noise model? One essential\\nrequirement is some form of cooling, to extract the entropy introduced by noise.47\\nParallel operations are also necessary, so noise can be controlled in di\\x0berent parts\\nof the computer simultaneously.\\nIt is natural to describe noise using a Hamiltonian that includes a coupling\\nbetween the system and its unobserved environment, and proofs of scalability require\\nthe noise to be suitably local. For example, we may write the noise Hamiltonian as\\na sum of terms, each acting on just a few of the physical qubits in the quantum\\ncomputer, but possibly acting on the environment in a complicated way. Then\\nthe proof of scalability applies if each such term in the noise Hamiltonian has a\\nsu\\x0eciently small norm.44,48,49If the noise Hamiltonian includes terms that act on\\nk >> 1 qubits in the quantum computer (and in some complicated way on the\\nenvironment), the proof of scalability works if these terms decay exponentially with\\nk, and also decay rapidly enough as the qubits separate in space. A drawback of\\nsuch scalability criteria is that the condition on the noise is not expressed in terms\\nof directly measurable properties; an advantage is that the state and dynamics of\\nthe environment need not be speci\\x0ced.\\nAlternatively, we may suppose that the environment is described by a Gaussian\\nfree \\x0celd, so the noise can be completely characterized by its two-point correlation\\nfunction. Then the proof of scalability goes through if the noise is su\\x0eciently weak,\\nwith correlations decaying su\\x0eciently rapidly in both time and space.50This crite-\\nrion has the advantage that it is expressed in terms of measurable quantities, but\\nit applies only for if the initial state and the dynamics of the environment obey\\nsuitable restrictions.\\nThus qua', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1416: ('e may suppose that the environment is described by a Gaussian\\nfree \\x0celd, so the noise can be completely characterized by its two-point correlation\\nfunction. Then the proof of scalability goes through if the noise is su\\x0eciently weak,\\nwith correlations decaying su\\x0eciently rapidly in both time and space.50This crite-\\nrion has the advantage that it is expressed in terms of measurable quantities, but\\nit applies only for if the initial state and the dynamics of the environment obey\\nsuitable restrictions.\\nThus quantum error correction works in principle for noise that is su\\x0eciently\\nweak and not too strongly correlated, but may fail if the noise acts collectively on\\nmany qubits at once. As quantum hardware continues to advance, it will be impor-\\ntant to see whether the noise in actual devices has adequately weak correlations,\\nkeeping in mind that there are possible ways to suppress correlations, for example\\nby using dynamical decoupling sequences.51\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n13\\n8. Topological quantum computing\\nTo a theorist, a particularly appealing and elegant way to achieve fault-tolerant\\nquantum computing is by using the exotic statistics of nonabelian anyons.39,52,53\\nQuantum information, stored in the exponentially large fusion Hilbert space of n\\nanyons, is well protected if the temperature is low compared to the energy gap (to\\nprevent unwanted thermal production of anyon pairs) and if the anyons are kept\\nfar apart from one another (to prevent unwanted nontopological interactions due to\\nquantum tunneling). Robust information processing can be achieved by exchanging\\nthe particles, exploiting their exotic quantum statistics, and information can be read\\nout by measuring charges of anyon pairs (for example, using an interferometer54,55).\\nAn early proposal for achieving quantum computing with anyons was based on\\nfractional quantum Hall states;56,57more recent proposals exploit exotic properties\\nof topological superconductors and topological insulators', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1417: ('unwanted nontopological interactions due to\\nquantum tunneling). Robust information processing can be achieved by exchanging\\nthe particles, exploiting their exotic quantum statistics, and information can be read\\nout by measuring charges of anyon pairs (for example, using an interferometer54,55).\\nAn early proposal for achieving quantum computing with anyons was based on\\nfractional quantum Hall states;56,57more recent proposals exploit exotic properties\\nof topological superconductors and topological insulators.58{64In most such propos-\\nals, the anyon braiding by itself is not su\\x0ecient for universal quantum computing,\\nbut can be supplemented by unprotected (and possibly quite noisy) nontopologi-\\ncal operations to realize a universal gate set.65Indeed, in some cases64braiding of\\nanyons can be modeled faithfully by a time-dependent free-fermion Hamiltonian;\\ntherefore, the nonuniversality of braiding operations follows from the observation\\nthat free-fermion systems can be simulated classically, together with the presump-\\ntion that e\\x0ecient classical simulations of general quantum circuits are impossible.\\nSince the error rate is suppressed by the energy gap for anyon pair creation, and\\ndoes not improve as the system size increases, we may anticipate that for very large-\\nscale applications topological quantum computing will need to be supplemented by\\n\\\\standard\" methods of quantum error correction. However, if topological protection\\nenforces a very low gate error rate, the overhead cost of using quantum error-\\ncorrecting codes may be relatively modest.\\nClassical information in a ferromagnet is protected \\\\passively,\" because mem-\\nory errors occur only when the system surmounts an energy barrier whose height\\nincreases sharply with system size. Could there be topologically ordered quantum\\nsystems that likewise store quantum information passively, providing a mechanism\\nfor a \\\\self-correcting\" quantum memory?66Models realizing this vision are known\\nin four spatial dimensions.40,67,68A recently discovered three-dimensional quantu', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1418: ('codes may be relatively modest.\\nClassical information in a ferromagnet is protected \\\\passively,\" because mem-\\nory errors occur only when the system surmounts an energy barrier whose height\\nincreases sharply with system size. Could there be topologically ordered quantum\\nsystems that likewise store quantum information passively, providing a mechanism\\nfor a \\\\self-correcting\" quantum memory?66Models realizing this vision are known\\nin four spatial dimensions.40,67,68A recently discovered three-dimensional quantum\\nmodel has a barrier height increasing logarithmically with system size, but for this\\nmodel the storage time is bounded above, and declines once the system grows be-\\nyond an optimal size.69,70\\n9. Quantum computing vs. quantum simulation\\nOne of the most important applications for quantum computing will be simulating\\nhighly entangled matter such as quantum antiferromagnets, exotic superconductors,\\ncomplex biomolecules, bulk nuclear matter, and spacetime near singularities. A gen-\\neral purpose quantum computer could function as a \\\\digital\" quantum simulator,\\nin contrast to \\\\analog\" quantum simulators based on customizable systems of (for\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n14\\nexample) ultracold atoms or molecules. The goal of either digital or analog quantum\\nsimulation should be achieving quantum supremacy, i.e., learning about quantum\\nphenomena that cannot be accurately simulated using classical systems. In partic-\\nular, we hope to discover new and previously unsuspected phenomena, rather than\\njust validate or refute predictions made by theorists.\\nA universal quantum computer will be highly adaptable, capable of simulating\\ne\\x0eciently any reasonable physical system, while analog quantum simulators have\\nintrinsic limitations. In particular, it is not clear to what degree the classical hard-\\nness hinges on the accuracy of the simulation, and present day quantum simulators,\\nunlike the universal quantum computers of the future, are not fault tolerant. On\\nth', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1419: (\"previously unsuspected phenomena, rather than\\njust validate or refute predictions made by theorists.\\nA universal quantum computer will be highly adaptable, capable of simulating\\ne\\x0eciently any reasonable physical system, while analog quantum simulators have\\nintrinsic limitations. In particular, it is not clear to what degree the classical hard-\\nness hinges on the accuracy of the simulation, and present day quantum simulators,\\nunlike the universal quantum computers of the future, are not fault tolerant. On\\nthe other hand, analog quantum simulators may be able to probe, at least qualita-\\ntively, exotic quantum phenomena that are su\\x0eciently robust and universal as to\\nbe studied without tuning the Hamiltonian precisely. Furthermore, since the char-\\nacteristic imperfections in analog quantum simulations vary from one experimental\\nplatform to another, obtaining compatible results using distinct simulation methods\\nwill boost con\\x0cdence in the results.\\n10. Conclusions and questions\\nI have emphasized the goal of quantum supremacy (super-classical behavior of con-\\ntrollable quantum systems) as the driving force behind the quest for a quantum\\ncomputer, and the idea of quantum error correction as the basis for our hope that\\nscalable quantum computing will be achievable. To focus the talk, I have neglected\\nother deeply engaging themes of quantum information science, such as quantum\\ncryptography and the capacities of quantum channels. Also, I have not discussed\\nthe impressive progress in building quantum hardware, a topic covered by other rap-\\nporteurs. I'll conclude by raising a few questions posed or suggested in the preceding\\nsections.\\nRegarding quantum supremacy, might we already have persuasive evidence that\\nNature performs tasks going beyond what can be simulated e\\x0eciently by classi-\\ncal computers? For example, there are many mathematical questions we cannot\\nanswer concerning strongly correlated materials and complex molecules, yet Na-\\nture provides answers; have we failed because these problems are intrinsically hard\\nclas\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1420: (\"red by other rap-\\nporteurs. I'll conclude by raising a few questions posed or suggested in the preceding\\nsections.\\nRegarding quantum supremacy, might we already have persuasive evidence that\\nNature performs tasks going beyond what can be simulated e\\x0eciently by classi-\\ncal computers? For example, there are many mathematical questions we cannot\\nanswer concerning strongly correlated materials and complex molecules, yet Na-\\nture provides answers; have we failed because these problems are intrinsically hard\\nclassically, or because of our lack of cleverness so far?\\nIs quantum simulation (e.g. with cold atoms and molecules) a feasible path to\\nquantum supremacy? Or will the di\\x0eculty of controlling these systems precisely\\nprevent us from performing super-classical tasks?\\nHow can we best achieve quantum supremacy with the relatively small systems\\nthat may be experimentally accessible fairly soon, systems with of order 100 qubits?\\nIn contemplating this issue we should keep in mind that such systems may be too\\nsmall to allow full blown quantum error correction, but also on the other hand that\\na super-classical device need not be capable of general purpose quantum computing.\\nRegarding quantum error correction, what near-term experiments studying noise\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n15\\nin quantum hardware will strengthen the case that scalable fault-tolerant quantum\\ncomputing is feasible? What pitfalls might thwart progress as the number of physical\\nqubits scales up?\\nDo the observed properties of topologically ordered media such as fractional\\nquantum Hall systems and topological superconductors already provide strong evi-\\ndence that highly robust quantum error-correcting codes are physically realizable?\\nHow much more persuasive will this evidence become if and when the exotic statis-\\ntics of nonabelian anyons can be con\\x0crmed directly?\\nWhich is a more promising path toward scalable quantum computing: topological\\nquantum computing with nonabelian anyons, or fault\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1421: ('ales up?\\nDo the observed properties of topologically ordered media such as fractional\\nquantum Hall systems and topological superconductors already provide strong evi-\\ndence that highly robust quantum error-correcting codes are physically realizable?\\nHow much more persuasive will this evidence become if and when the exotic statis-\\ntics of nonabelian anyons can be con\\x0crmed directly?\\nWhich is a more promising path toward scalable quantum computing: topological\\nquantum computing with nonabelian anyons, or fault-tolerance based on standard\\nqubits and quantum error-correcting codes? Will the distinction between these two\\napproaches fade as hardware advances?\\nCan a quantum memory, like a classical one, be self-correcting, with storage\\ntime increasing as the system grows? Can quantum information protected by self-\\ncorrecting systems be processed e\\x0eciently and reliably?\\nHow might quantum computers change the world? Predictions are never easy,\\nbut it would be especially presumptuous to believe that our limited classical minds\\ncan divine the future course of quantum information science. Attaining quantum\\nsupremacy and exploring its consequences will be among the great challenges facing\\n21st century science, and our imaginations are poorly equipped to envision the\\nscienti\\x0cc rewards of manipulating highly entangled quantum states, or the potential\\nbene\\x0cts of advanced quantum technologies. As we rise to the call of the entanglement\\nfrontier, we should expect the unexpected.\\nAcknowledgments\\nI am grateful to the organizers for the opportunity to attend this exciting meeting.\\nThis work was supported in part by NSF grant PHY-0803371, DOE grant DE-\\nFG03-92-ER40701, and NSA/ARO grant W911NF-09-1-0442.\\nReferences\\n1. D. Poulin, A. Qarry, R. Somma, and F. Verstraete, Quantum simulation of time-\\ndependent Hamiltonians and the convenient illusion of Hilbert space, Phys. Rev. Lett.\\n106, 170501 (2011).\\n2. P. W. Shor, Algorithms for quantum computation: discrete logarithms and factoring,\\nProceedings of the 35th Symposium on Foundations of C', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1422: (\" the opportunity to attend this exciting meeting.\\nThis work was supported in part by NSF grant PHY-0803371, DOE grant DE-\\nFG03-92-ER40701, and NSA/ARO grant W911NF-09-1-0442.\\nReferences\\n1. D. Poulin, A. Qarry, R. Somma, and F. Verstraete, Quantum simulation of time-\\ndependent Hamiltonians and the convenient illusion of Hilbert space, Phys. Rev. Lett.\\n106, 170501 (2011).\\n2. P. W. Shor, Algorithms for quantum computation: discrete logarithms and factoring,\\nProceedings of the 35th Symposium on Foundations of Computer Science, 124-134\\n(1994).\\n3. M. H. Freedman, M. Larsen, and Z. Wang, A modular functor which is universal for\\nuniversal quantum computation, Comm. Math. Phys. 227, 605-622 (2002).\\n4. D. Aharonov, V. Jones, and Z. Landau, A polynomial quantum algorithm for approxi-\\nmating the Jones polynomial, Algorithmica 55, 395-421 (2009).\\n5. G. Alagic, S. P. Jordan, R. K\\x7f onig, and B. W. Reichardt, Estimating Turaev-Viro three-\\nmanifold invariants is universal for quantum computation, Phys. Rev. A 82, 040302\\n(2010).\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n16\\n6. A. W. Harrow, A. Hassidim, and S. Lloyd, Quantum algorithm for linear systems of\\nequations, Phys. Rev. Lett. 103, 150502 (2009).\\n7. L. K. Grover, A fast quantum mechanical algorithm for database search, STOC '96:\\nProceedings of the 28th annual ACM symposium on theory of computing (1996).\\n8. E. Farhi, J. Goldstone, and S. Gutmann, A quantum algorithm for the Hamiltonian\\nNAND tree, Theory of Computing 4, 169-190 (2008).\\n9. C. H. Bennett, E. Bernstein, G. Brassard, and U. Vazirani, Strengths and weaknesses\\nof quantum computing, SIAM Journal on Computing, 26, 1510-1523 (1997).\\n10. R. P. Feynman, Simulating physics with computers, International Journal of Theoret-\\nical Physics 21, 467-488 (1982).\\n11. G. Vidal, E\\x0ecient classical simulation of slightly entangled quantum computations,\\nPhys. Rev. Lett. 91, 147902 (2003).\\n12. R. Jozsa, On the simulation of quantum circuits, arXiv:quant-ph/0603163 (2006).\\n13. M. Cr\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1423: (\" 169-190 (2008).\\n9. C. H. Bennett, E. Bernstein, G. Brassard, and U. Vazirani, Strengths and weaknesses\\nof quantum computing, SIAM Journal on Computing, 26, 1510-1523 (1997).\\n10. R. P. Feynman, Simulating physics with computers, International Journal of Theoret-\\nical Physics 21, 467-488 (1982).\\n11. G. Vidal, E\\x0ecient classical simulation of slightly entangled quantum computations,\\nPhys. Rev. Lett. 91, 147902 (2003).\\n12. R. Jozsa, On the simulation of quantum circuits, arXiv:quant-ph/0603163 (2006).\\n13. M. Cramer, M. B. Plenio, S. T. Flammia, R. Somma, D. Gross, S. D. Bartlett, O.\\nLandon-Cardinal, D. Poulin, and Y.-K. Liu, E\\x0ecient quantum state tomography, Na-\\nture Communications 1, 149 (2010).\\n14. S. D. Bartlett and B. C. Sanders, Requirement for quantum computation, J. Mod.\\nOptics 50, 2331-2340 (2003).\\n15. E. Knill, R. La\\ramme, and G. J. Milburn, A scheme for e\\x0ecient quantum computation\\nwith linear optics, Nature 409, 46-52 (2001).\\n16. D. Gottesman, A. Kitaev, and J. Preskill, Encoding a qubit in an oscillator, Phys.\\nRev. A 64, 012310 (2001).\\n17. L. G. Valiant, Quantum computers that can be simulated classically in polynomial\\ntime, STOC '01: Proceedings of the 33rd annual ACM symposium on theory of com-\\nputing (2001).\\n18. B. Terhal and D. P. DiVincenzo, Classical simulation of noninteracting-fermion quan-\\ntum circuits, Phys. Rev. A 65, 032325 (2002).\\n19. S. B. Bravyi and A. Yu. Kitaev, Fermionic quantum computation, Annals of Physics\\n298, 210-226 (2002).\\n20. E. Knill and R. La\\ramme, Power of one bit of quantum information, Phys. Rev. Lett.\\n81, 5672-5675 (1998).\\n21. N. A. Gershenfeld and I. L. Chuang, Bulk spin-resonance quantum computation, Sci-\\nence 275, 350-356 (1997).\\n22. D. G. Cory, A. F. Fahmy, and T. F. Havel, Ensemble quantum computing by NMR\\nspectroscopy, Proc. Nat. Acad. Sci. 95, 1634-1639 (1997).\\n23. P. Shor and S. P. Jordan, Estimating Jones polynomials is a complete problem for one\\nclean qubit, Quant. Inf. Comput. 8, 681 (2008).\\n24. S. P. Jordan and G. Alagic, Approximating the Turaev-Viro invariant o\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1424: (\"information, Phys. Rev. Lett.\\n81, 5672-5675 (1998).\\n21. N. A. Gershenfeld and I. L. Chuang, Bulk spin-resonance quantum computation, Sci-\\nence 275, 350-356 (1997).\\n22. D. G. Cory, A. F. Fahmy, and T. F. Havel, Ensemble quantum computing by NMR\\nspectroscopy, Proc. Nat. Acad. Sci. 95, 1634-1639 (1997).\\n23. P. Shor and S. P. Jordan, Estimating Jones polynomials is a complete problem for one\\nclean qubit, Quant. Inf. Comput. 8, 681 (2008).\\n24. S. P. Jordan and G. Alagic, Approximating the Turaev-Viro invariant of mapping tori\\nis complete for one clean qubit, arXiv:1105.5100 (2011).\\n25. M. J. Bremner, R. Jozsa, and D. J. Shepherd, Classical simulation of commuting\\nquantum computations implies collapse of the polynomial hierarchy, Proc. R. Soc. A\\n467, 459-472 (2011).\\n26. S. Aaronson and A. Arkhipov, The computational complexity of linear optics,\\narXiv:1011.3245 (2010).\\n27. S. Lloyd, Universal quantum simulators, Science 273, 1073-1078 (1996).\\n28. D. Aharonov and A. Ta-Shma, Adiabatic quantum state generation and statistical\\nzero knowledge, STOC '03: Proceeding of the 35th ACM symposium on the theory of\\ncomputing (2003).\\n29. A. Yu Kitaev, Quantum measurements and the Abelian stabilizer problem,\\narXiv:quant-ph/9511026 (1995).\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n17\\n30. A, Aspuru-Guzik, A. D. Dutoi, P. J. Love, and M. Head-Gordon, Simulated quantum\\ncomputation of molecular energies, Science 309, 1704 (2005).\\n31. A. Yu. Kitaev, A. Shen, and M. N. Vyalyi, Classical and Quantum Computation\\n(American Mathematical Society, 2002).\\n32. D. Gottesman and S. Irani, The quantum and classical complexity of translationally\\ninvariant tiling and Hamiltonian problems, Proceedings of 50th Symposium on Foun-\\ndations of Computer Science, 95-105 (2009).\\n33. E. Farhi, J. Goldstone, S. Gutmann, and M. Sipser, Computation by adiabatic evolu-\\ntion, arXiv:quant-ph/0001106 (2000).\\n34. I. Kassal, S. P. Jordan, P. J. Love, M. Mohseni, and A. Aspuru-Guzik, Polynomial-\\ntime quantum algorithm \", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1425: (\"al and Quantum Computation\\n(American Mathematical Society, 2002).\\n32. D. Gottesman and S. Irani, The quantum and classical complexity of translationally\\ninvariant tiling and Hamiltonian problems, Proceedings of 50th Symposium on Foun-\\ndations of Computer Science, 95-105 (2009).\\n33. E. Farhi, J. Goldstone, S. Gutmann, and M. Sipser, Computation by adiabatic evolu-\\ntion, arXiv:quant-ph/0001106 (2000).\\n34. I. Kassal, S. P. Jordan, P. J. Love, M. Mohseni, and A. Aspuru-Guzik, Polynomial-\\ntime quantum algorithm for the simulation of chemical dynamics, Proc. Nat. Acad. Sci.\\n105, 18681-18686 (2008).\\n35. S. P. Jordan, K. S. M. Lee, and J. Preskill, Quantum algorithms for quantum \\x0celd\\ntheories, arXiv:1111.3633 (2011).\\n36. P. Shor, Scheme for reducing decoherence in quantum memory, Phys. Rev. A 52,\\nR2493-R2496 (1995).\\n37. A. M. Steane, Error correcting codes in quantum theory, Phys. Rev. Lett. 77, 793-797\\n(1995).\\n38. E. Knill and R. La\\ramme, Theory of quantum error-correcting codes, Phys. Rev. A\\n55, 900911 (1997).\\n39. A. Yu. Kitaev, Fault-tolerant quantum computation by anyons, Annals of Physics 303,\\n2-30 (2003).\\n40. E. Dennis, A. Kitaev, A. Landahl, and J. Preskill, Topological quantum memory, J.\\nMath. Phys. 43, 4452 (2002).\\n41. D. Aharonov and M. Ben-Or, Fault-tolerant quantum computation with constant er-\\nror, STOC '97: Proceedings of the 29th annual ACM symposium on theory of computing\\n(1997).\\n42. A. Yu. Kitaev, Quantum computations: algorithms and error correction, Russian\\nMath. Surveys 52, 1191-1249 (1997).\\n43. R. La\\ramme, E. Knill, and W. Zurek, Resilient quantum computation: error models\\nand thresholds, Proc. R. Soc. Lond. A 454, 365-384 (1998).\\n44. P. Aliferis, D. Gottesman, and J. Preskill, Quantum accuracy threshold for concate-\\nnated distance-3 codes, Quant. Inf. Comput. 6, 97-165 (2006).\\n45. B. W. Reichardt, Fault-tolerance threshold for a distance-three quantum code, Lecture\\nNotes in Computer Science 4051,50-61 (2006).\\n46. R. Raussendorf and J. Harrington, Fault-tolerant quantum computation with high\\nthreshol\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1426: ('La\\ramme, E. Knill, and W. Zurek, Resilient quantum computation: error models\\nand thresholds, Proc. R. Soc. Lond. A 454, 365-384 (1998).\\n44. P. Aliferis, D. Gottesman, and J. Preskill, Quantum accuracy threshold for concate-\\nnated distance-3 codes, Quant. Inf. Comput. 6, 97-165 (2006).\\n45. B. W. Reichardt, Fault-tolerance threshold for a distance-three quantum code, Lecture\\nNotes in Computer Science 4051,50-61 (2006).\\n46. R. Raussendorf and J. Harrington, Fault-tolerant quantum computation with high\\nthreshold in two dimensions, Phys. Rev. Lett. 98, 190504 (2007).\\n47. D. Aharonov, M. Ben-Or, R. Impagliazzo, and N. Nisan, Limitations of noisy reversible\\ncomputation, arXiv:quant-ph/9611028 (1996).\\n48. B. Terhal and G. Burkhard, Fault-tolerant quantum computation for local non-\\nMarkovian noise, Phys. Rev. A 71, 012336 (2005).\\n49. D. Aharonov, A. Kitaev, and J. Preskill, Fault-tolerant quantum computation with\\nlong-range correlated noise, Phys. Rev. Lett. 96, 050504 (2006).\\n50. H.-K. Ng and J. Preskill, Fault-tolerant quantum computation versus Gaussian noise,\\nPhys. Rev. A 79, 032318 (2009).\\n51. L. Viola, E. Knill, and S. Lloyd, Dynamical decoupling of open quantum systems,\\nPhys. Rev. Lett. 82, 2417-2421 (1999).\\n52. R. W. Ogburn and J. Preskill, Topological quantum computation, Lecture Notes in\\nComputer Science 1509, 341-356 (1999).\\n53. M. H. Freedman, A. Kitaev, M. J. Larsen, and Z. Wang, Topological quantum com-\\nNovember 27, 2024 5:50 WSPC - Proceedings Trim Size: 9.75in x 6.5in solvay-preskill-2011-arXiv-v3\\n18\\nputation, Bull. AMS 40, 31-38 (2002).\\n54. A. Stern and B. I. Halperin, Proposed experiments to probe the non-Abelian nu=5/2\\nquantum Hall state, Phys. Rev. Lett. 96, 016802 (2006).\\n55. P. Bonderson, A. Kitaev, and K. Shtengel, Detecting non-Abelian statistics in the\\nnu=5/2 fractional quantum Hall state, Phys. Rev. Lett. 96, 016803 (2006).\\n56. S. Das Sarma, M. Freedman, and C. Nayak, Topologically protected qubits from a\\npossible non-Abelian fractional quantum Hall state, Phys. Rev. Lett. 94, 166802 (2005).\\n57. ', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1427: ('ation, Bull. AMS 40, 31-38 (2002).\\n54. A. Stern and B. I. Halperin, Proposed experiments to probe the non-Abelian nu=5/2\\nquantum Hall state, Phys. Rev. Lett. 96, 016802 (2006).\\n55. P. Bonderson, A. Kitaev, and K. Shtengel, Detecting non-Abelian statistics in the\\nnu=5/2 fractional quantum Hall state, Phys. Rev. Lett. 96, 016803 (2006).\\n56. S. Das Sarma, M. Freedman, and C. Nayak, Topologically protected qubits from a\\npossible non-Abelian fractional quantum Hall state, Phys. Rev. Lett. 94, 166802 (2005).\\n57. C. Nayak, S. H. Simon, A. Stern, M. Freedman, and S. Das Sarma, Non-Abelian\\nanyons and topological quantum computation, Rev. Mod. Phys. 80, 1083-1159 (2008).\\n58. A. Yu. Kitaev, Unpaired Majorana fermions in quantum wires, Physics-Uspekhi 44,\\n131 (2001).\\n59. L. Fu and C. Kane, Superconducting proximity e\\x0bect and Majorana fermions at the\\nsurface of a topological insulator, Phys. Rev. Lett. 100, 096407 (2008).\\n60. J. D. Sau, R. M. Lutchyn, S. Tewari, and S. Das Sarma, Generic new platform for\\ntopological quantum computation using semiconductor heterostructures, Phys. Rev.\\nLett. 104, 040502 (2010).\\n61. J. Alicea, Majorana fermions in a tunable semiconductor device, Phys. Rev. B 81,\\n125318 (2010).\\n62. R. M. Lutchyn, J. D. Sau, and S. Das Sarma, Majorana Fermions and a topological\\nphase transition in semiconductor-superconductor heterostructures, Phys. Rev. Lett.\\n105, 077001 (2010).\\n63. Y. Oreg, G. Refael, and F. von Oppen, Helical liquids and Majorana bound states in\\nquantum wires, Phys. Rev. Lett. 105, 177002 (2010).\\n64. J. Alicea, Y. Oreg, G. Refael, F. von Oppen, M. P. A. Fisher, Non-Abelian statistics\\nand topological quantum information processing in 1D wire networks, Nature Physics\\n7, 412417 (2011).\\n65. S. Bravyi and A. Kitaev, Universal quantum computation with ideal Cli\\x0bord gates\\nand noisy ancillas, Phys. Rev. A 71, 022316 (2005).\\n66. D. Bacon, Operator quantum error-correcting subsystems for self-correcting quantum\\nmemories, Phys. Rev. A 73, 012340 (2006).\\n67. R. Alicki, M. Horodecki, P. Horodecki, and R. Ho', 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1428: (\"10).\\n64. J. Alicea, Y. Oreg, G. Refael, F. von Oppen, M. P. A. Fisher, Non-Abelian statistics\\nand topological quantum information processing in 1D wire networks, Nature Physics\\n7, 412417 (2011).\\n65. S. Bravyi and A. Kitaev, Universal quantum computation with ideal Cli\\x0bord gates\\nand noisy ancillas, Phys. Rev. A 71, 022316 (2005).\\n66. D. Bacon, Operator quantum error-correcting subsystems for self-correcting quantum\\nmemories, Phys. Rev. A 73, 012340 (2006).\\n67. R. Alicki, M. Horodecki, P. Horodecki, and R. Horodecki, On thermal stability of\\ntopological qubit in Kitaev's 4D model, Open Syst. Inf. Dyn. 17 (2010).\\n68. S. Chesi, D. Loss, S. Bravyi, and B. Terhal, Thermodynamic stability criteria for a\\nquantum memory based on stabilizer and subsystem codes, New Journal of Physics 12,\\n025013 (2010).\\n69. J. Haah, Local stabilizer codes in three dimensions without string logical operators,\\nPhys. Rev. A 83, 042330 (2011).\\n70. S. Bravyi and J. Haah, Energy landscape of 3D spin Hamiltonians with topological\\norder, Phys. Rev. Lett. 107, 150504 (2011).\", 'QUANTUM COMPUTING AND THE ENTANGLEMENT FRONTIER.pdf'), 1429: ('TensorFlow:\\nLarge-Scale Machine Learning on Heterogeneous Distributed Systems\\n(Preliminary White Paper, November 9, 2015)\\nMart ´ın Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro,\\nGreg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow,\\nAndrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser,\\nManjunath Kudlur, Josh Levenberg, Dan Man ´e, Rajat Monga, Sherry Moore, Derek Murray,\\nChris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar,\\nPaul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Vi ´egas, Oriol Vinyals,\\nPete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng\\nGoogle Research\\x03\\nAbstract\\nTensorFlow [1] is an interface for expressing machine learn-\\ning algorithms, and an implementation for executing such al-\\ngorithms. A computation expressed using TensorFlow can be\\nexecuted with little or no change on a wide variety of hetero-\\ngeneous systems, ranging from mobile devices such as phones\\nand tablets up to large-scale distributed systems of hundreds\\nof machines and thousands of computational devices such as\\nGPU cards. The system is ﬂexible and can be used to express\\na wide variety of algorithms, including training and inference\\nalgorithms for deep neural network models, and it has been\\nused for conducting research and for deploying machine learn-\\ning systems into production across more than a dozen areas of\\ncomputer science and other ﬁelds, including speech recogni-\\ntion, computer vision, robotics, information retrieval, natural\\nlanguage processing, geographic information extraction, and\\ncomputational drug discovery. This paper describes the Ten-\\nsorFlow interface and an implementation of that interface that\\nwe have built at Google. The TensorFlow API and a reference\\nimplementation were released as an open-source package under\\nthe Apache 2.0 license in November, 2015 and are available at\\nwww.tensorﬂow.org.\\n1 Introduction\\nThe Google Brain project started in 2011', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1430: ('ecogni-\\ntion, computer vision, robotics, information retrieval, natural\\nlanguage processing, geographic information extraction, and\\ncomputational drug discovery. This paper describes the Ten-\\nsorFlow interface and an implementation of that interface that\\nwe have built at Google. The TensorFlow API and a reference\\nimplementation were released as an open-source package under\\nthe Apache 2.0 license in November, 2015 and are available at\\nwww.tensorﬂow.org.\\n1 Introduction\\nThe Google Brain project started in 2011 to explore the\\nuse of very-large-scale deep neural networks, both for\\nresearch and for use in Google’s products. As part of\\nthe early work in this project, we built DistBelief, our\\nﬁrst-generation scalable distributed training and infer-\\nence system [14], and this system has served us well. We\\nand others at Google have performed a wide variety of re-\\nsearch using DistBelief including work on unsupervised\\nlearning [31], language representation [35, 52], models\\nfor image classiﬁcation and object detection [16, 48],\\nvideo classiﬁcation [27], speech recognition [56, 21, 20],\\n\\x03Corresponding authors: Jeffrey Dean and Rajat Monga:\\nfjeff,rajatmonga g@google.comsequence prediction [47], move selection for Go [34],\\npedestrian detection [2], reinforcement learning [38],\\nand other areas [17, 5]. In addition, often in close collab-\\noration with the Google Brain team, more than 50 teams\\nat Google and other Alphabet companies have deployed\\ndeep neural networks using DistBelief in a wide variety\\nof products, including Google Search [11], our advertis-\\ning products, our speech recognition systems [50, 6, 46],\\nGoogle Photos [43], Google Maps and StreetView [19],\\nGoogle Translate [18], YouTube, and many others.\\nBased on our experience with DistBelief and a more\\ncomplete understanding of the desirable system proper-\\nties and requirements for training and using neural net-\\nworks, we have built TensorFlow, our second-generation\\nsystem for the implementation and deployment of large-\\nscale machine learning models. TensorFlow takes co', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1431: ('e Search [11], our advertis-\\ning products, our speech recognition systems [50, 6, 46],\\nGoogle Photos [43], Google Maps and StreetView [19],\\nGoogle Translate [18], YouTube, and many others.\\nBased on our experience with DistBelief and a more\\ncomplete understanding of the desirable system proper-\\nties and requirements for training and using neural net-\\nworks, we have built TensorFlow, our second-generation\\nsystem for the implementation and deployment of large-\\nscale machine learning models. TensorFlow takes com-\\nputations described using a dataﬂow-like model and\\nmaps them onto a wide variety of different hardware\\nplatforms, ranging from running inference on mobile\\ndevice platforms such as Android and iOS to modest-\\nsized training and inference systems using single ma-\\nchines containing one or many GPU cards to large-scale\\ntraining systems running on hundreds of specialized ma-\\nchines with thousands of GPUs. Having a single system\\nthat can span such a broad range of platforms signiﬁ-\\ncantly simpliﬁes the real-world use of machine learning\\nsystem, as we have found that having separate systems\\nfor large-scale training and small-scale deployment leads\\nto signiﬁcant maintenance burdens and leaky abstrac-\\ntions. TensorFlow computations are expressed as stateful\\ndataﬂow graphs (described in more detail in Section 2),\\nand we have focused on making the system both ﬂexible\\nenough for quickly experimenting with new models for\\nresearch purposes and sufﬁciently high performance and\\nrobust for production training and deployment of ma-\\nchine learning models. For scaling neural network train-\\ning to larger deployments, TensorFlow allows clients to\\neasily express various kinds of parallelism through repli-\\ncation and parallel execution of a core model dataﬂow\\n1arXiv:1603.04467v2  [cs.DC]  16 Mar 2016\\ngraph, with many different computational devices all col-\\nlaborating to update a set of shared parameters or other\\nstate. Modest changes in the description of the com-\\nputation allow a wide variety of different approaches\\nto parallelism', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1432: (' of ma-\\nchine learning models. For scaling neural network train-\\ning to larger deployments, TensorFlow allows clients to\\neasily express various kinds of parallelism through repli-\\ncation and parallel execution of a core model dataﬂow\\n1arXiv:1603.04467v2  [cs.DC]  16 Mar 2016\\ngraph, with many different computational devices all col-\\nlaborating to update a set of shared parameters or other\\nstate. Modest changes in the description of the com-\\nputation allow a wide variety of different approaches\\nto parallelism to be achieved and tried with low effort\\n[14, 29, 42]. Some TensorFlow uses allow some ﬂexibil-\\nity in terms of the consistency of parameter updates, and\\nwe can easily express and take advantage of these relaxed\\nsynchronization requirements in some of our larger de-\\nployments. Compared to DistBelief, TensorFlow’s pro-\\ngramming model is more ﬂexible, its performance is sig-\\nniﬁcantly better, and it supports training and using a\\nbroader range of models on a wider variety of hetero-\\ngeneous hardware platforms.\\nDozens of our internal clients of DistBelief have al-\\nready switched to TensorFlow. These clients rely on\\nTensorFlow for research and production, with tasks as\\ndiverse as running inference for computer vision mod-\\nels on mobile phones to large-scale training of deep\\nneural networks with hundreds of billions of parame-\\nters on hundreds of billions of example records using\\nmany hundreds of machines [11, 47, 48, 18, 53, 41].\\nAlthough these applications have concentrated on ma-\\nchine learning and deep neural networks in particular,\\nwe expect that TensorFlow’s abstractions will be useful\\nin a variety of other domains, including other kinds of\\nmachine learning algorithms, and possibly other kinds\\nof numerical computations. We have open-sourced the\\nTensorFlow API and a reference implementation under\\nthe Apache 2.0 license in November, 2015, available at\\nwww.tensorﬂow.org.\\nThe rest of this paper describes TensorFlow in more\\ndetail. Section 2 describes the programming model and\\nbasic concepts of the TensorFlow inter', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1433: ('networks in particular,\\nwe expect that TensorFlow’s abstractions will be useful\\nin a variety of other domains, including other kinds of\\nmachine learning algorithms, and possibly other kinds\\nof numerical computations. We have open-sourced the\\nTensorFlow API and a reference implementation under\\nthe Apache 2.0 license in November, 2015, available at\\nwww.tensorﬂow.org.\\nThe rest of this paper describes TensorFlow in more\\ndetail. Section 2 describes the programming model and\\nbasic concepts of the TensorFlow interface, and Section 3\\ndescribes both our single machine and distributed imple-\\nmentations. Section 4 describes several extensions to\\nthe basic programming model, and Section 5 describes\\nseveral optimizations to the basic implementations. Sec-\\ntion 6 describes some of our experiences in using Ten-\\nsorFlow, Section 7 describes several programming id-\\nioms we have found helpful when using TensorFlow, and\\nSection 9 describes several auxiliary tools we have built\\naround the core TensorFlow system. Sections 10 and 11\\ndiscuss future and related work, respectively, and Sec-\\ntion 12 offers concluding thoughts.\\n2 Programming Model and Basic Concepts\\nA TensorFlow computation is described by a directed\\ngraph , which is composed of a set of nodes . The graph\\nrepresents a dataﬂow computation, with extensions for\\nallowing some kinds of nodes to maintain and update\\npersistent state and for branching and looping controlstructures within the graph in a manner similar to Naiad\\n[36]. Clients typically construct a computational graph\\nusing one of the supported frontend languages (C++ or\\nPython). An example fragment to construct and then ex-\\necute a TensorFlow graph using the Python front end is\\nshown in Figure 1, and the resulting computation graph\\nin Figure 2.\\nIn a TensorFlow graph, each node has zero or more in-\\nputs and zero or more outputs, and represents the instan-\\ntiation of an operation . Values that ﬂow along normal\\nedges in the graph (from outputs to inputs) are tensors ,\\narbitrary dimensionality arrays where the underlying', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1434: ('ph\\nusing one of the supported frontend languages (C++ or\\nPython). An example fragment to construct and then ex-\\necute a TensorFlow graph using the Python front end is\\nshown in Figure 1, and the resulting computation graph\\nin Figure 2.\\nIn a TensorFlow graph, each node has zero or more in-\\nputs and zero or more outputs, and represents the instan-\\ntiation of an operation . Values that ﬂow along normal\\nedges in the graph (from outputs to inputs) are tensors ,\\narbitrary dimensionality arrays where the underlying el-\\nement type is speciﬁed or inferred at graph-construction\\ntime. Special edges, called control dependencies , can\\nalso exist in the graph: no data ﬂows along such edges,\\nbut they indicate that the source node for the control de-\\npendence must ﬁnish executing before the destination\\nnode for the control dependence starts executing. Since\\nour model includes mutable state, control dependencies\\ncan be used directly by clients to enforce happens before\\nrelationships. Our implementation also sometimes in-\\nserts control dependencies to enforce orderings between\\notherwise independent operations as a way of, for exam-\\nple, controlling the peak memory usage.\\nOperations and Kernels\\nAnoperation has a name and represents an abstract com-\\nputation (e.g., “matrix multiply”, or “add”). An opera-\\ntion can have attributes , and all attributes must be pro-\\nvided or inferred at graph-construction time in order to\\ninstantiate a node to perform the operation. One com-\\nmon use of attributes is to make operations polymorphic\\nover different tensor element types (e.g., add of two ten-\\nsors of type ﬂoat versus add of two tensors of type int32).\\nAkernel is a particular implementation of an operation\\nthat can be run on a particular type of device (e.g., CPU\\nor GPU). A TensorFlow binary deﬁnes the sets of opera-\\ntions and kernels available via a registration mechanism,\\nand this set can be extended by linking in additional op-\\neration and/or kernel deﬁnitions/registrations. Table 1\\nshows some of the kinds of operations built into the core\\n', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1435: ('different tensor element types (e.g., add of two ten-\\nsors of type ﬂoat versus add of two tensors of type int32).\\nAkernel is a particular implementation of an operation\\nthat can be run on a particular type of device (e.g., CPU\\nor GPU). A TensorFlow binary deﬁnes the sets of opera-\\ntions and kernels available via a registration mechanism,\\nand this set can be extended by linking in additional op-\\neration and/or kernel deﬁnitions/registrations. Table 1\\nshows some of the kinds of operations built into the core\\nTensorFlow library.\\nSessions\\nClients programs interact with the TensorFlow system by\\ncreating a Session . To create a computation graph, the\\nSession interface supports an Extend method to augment\\nthe current graph managed by the session with additional\\nnodes and edges (the initial graph when a session is cre-\\nated is empty). The other primary operation supported\\n2\\nimport tensorflow as tf\\nb = tf.Variable(tf.zeros([100])) # 100-d vector, init to zeroes\\nW = tf.Variable(tf.random_uniform([784,100],-1,1)) # 784x100 matrix w/rnd vals\\nx = tf.placeholder(name=\"x\") # Placeholder for input\\nrelu = tf.nn.relu(tf.matmul(W, x) + b) # Relu(Wx+b)\\nC = [...] # Cost computed as a function\\n# of Relu\\ns = tf.Session()\\nfor step in xrange(0, 10):\\ninput = ...construct 100-D input array ... # Create 100-d vector for input\\nresult = s.run(C, feed_dict={x: input}) # Fetch cost, feeding x=input\\nprint step, result\\nFigure 1: Example TensorFlow code fragment\\nWb\\nxMatMulAddReLU...C\\nFigure 2: Corresponding computation graph for Figure 1\\nCategory Examples\\nElement-wise mathematical operations Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal, ...\\nArray operations Concat, Slice, Split, Constant, Rank, Shape, Shufﬂe, ...\\nMatrix operations MatMul, MatrixInverse, MatrixDeterminant, ...\\nStateful operations Variable, Assign, AssignAdd, ...\\nNeural-net building blocks SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool, ...\\nCheckpointing operations Save, Restore\\nQueue and synchronization operations Enqueue, Dequeue, MutexAcquire, MutexRelease, ...\\nControl ﬂow ', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1436: ('y Examples\\nElement-wise mathematical operations Add, Sub, Mul, Div, Exp, Log, Greater, Less, Equal, ...\\nArray operations Concat, Slice, Split, Constant, Rank, Shape, Shufﬂe, ...\\nMatrix operations MatMul, MatrixInverse, MatrixDeterminant, ...\\nStateful operations Variable, Assign, AssignAdd, ...\\nNeural-net building blocks SoftMax, Sigmoid, ReLU, Convolution2D, MaxPool, ...\\nCheckpointing operations Save, Restore\\nQueue and synchronization operations Enqueue, Dequeue, MutexAcquire, MutexRelease, ...\\nControl ﬂow operations Merge, Switch, Enter, Leave, NextIteration\\nTable 1: Example TensorFlow operation types\\nby the session interface is Run, which takes a set of out-\\nput names that need to be computed, as well as an op-\\ntional set of tensors to be fed into the graph in place of\\ncertain outputs of nodes. Using the arguments to Run,\\nthe TensorFlow implementation can compute the transi-\\ntive closure of all nodes that must be executed in order\\nto compute the outputs that were requested, and can thenarrange to execute the appropriate nodes in an order that\\nrespects their dependencies (as described in more detail\\nin 3.1). Most of our uses of TensorFlow set up a Session\\nwith a graph once, and then execute the full graph or a\\nfew distinct subgraphs thousands or millions of times via\\nRun calls.\\n3\\nVariables\\nIn most computations a graph is executed multiple times.\\nMost tensors do not survive past a single execution of the\\ngraph. However, a Variable is a special kind of opera-\\ntion that returns a handle to a persistent mutable tensor\\nthat survives across executions of a graph. Handles to\\nthese persistent mutable tensors can be passed to a hand-\\nful of special operations, such as Assign andAssignAdd\\n(equivalent to +=) that mutate the referenced tensor. For\\nmachine learning applications of TensorFlow, the param-\\neters of the model are typically stored in tensors held in\\nvariables, and are updated as part of the Runof the train-\\ning graph for the model.\\n3 Implementation\\nThe main components in a TensorFlow system are the\\nclient , which', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1437: ('nsor\\nthat survives across executions of a graph. Handles to\\nthese persistent mutable tensors can be passed to a hand-\\nful of special operations, such as Assign andAssignAdd\\n(equivalent to +=) that mutate the referenced tensor. For\\nmachine learning applications of TensorFlow, the param-\\neters of the model are typically stored in tensors held in\\nvariables, and are updated as part of the Runof the train-\\ning graph for the model.\\n3 Implementation\\nThe main components in a TensorFlow system are the\\nclient , which uses the Session interface to communicate\\nwith the master , and one or more worker processes , with\\neach worker process responsible for arbitrating access to\\none or more computational devices (such as CPU cores\\nor GPU cards) and for executing graph nodes on those\\ndevices as instructed by the master. We have both lo-\\ncalanddistributed implementations of the TensorFlow\\ninterface. The local implementation is used when the\\nclient, the master, and the worker all run on a single ma-\\nchine in the context of a single operating system process\\n(possibly with multiple devices, if for example, the ma-\\nchine has many GPU cards installed). The distributed\\nimplementation shares most of the code with the local\\nimplementation, but extends it with support for an en-\\nvironment where the client, the master, and the workers\\ncan all be in different processes on different machines.\\nIn our distributed environment, these different tasks are\\ncontainers in jobs managed by a cluster scheduling sys-\\ntem [51]. These two different modes are illustrated in\\nFigure 3. Most of the rest of this section discusses is-\\nsues that are common to both implementations, while\\nSection 3.3 discusses some issues that are particular to\\nthe distributed implementation.\\nDevices\\nDevices are the computational heart of TensorFlow. Each\\nworker is responsible for one or more devices, and\\neach device has a device type, and a name. Device\\nnames are composed of pieces that identify the de-\\nvice’s type, the device’s index within the worker, and,\\nin our distributed setti', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1438: ('re illustrated in\\nFigure 3. Most of the rest of this section discusses is-\\nsues that are common to both implementations, while\\nSection 3.3 discusses some issues that are particular to\\nthe distributed implementation.\\nDevices\\nDevices are the computational heart of TensorFlow. Each\\nworker is responsible for one or more devices, and\\neach device has a device type, and a name. Device\\nnames are composed of pieces that identify the de-\\nvice’s type, the device’s index within the worker, and,\\nin our distributed setting, an identiﬁcation of the job\\nand task of the worker (or localhost for the case where\\nthe devices are local to the process). Example device\\nnames are \"/job:localhost/device:cpu:0\" or\\n\"/job:worker/task:17/device:gpu:3\" . Wehave implementations of our Device interface for CPUs\\nand GPUs, and new device implementations for other de-\\nvice types can be provided via a registration mechanism.\\nEach device object is responsible for managing alloca-\\ntion and deallocation of device memory, and for arrang-\\ning for the execution of any kernels that are requested by\\nhigher levels in the TensorFlow implementation.\\nTensors\\nA tensor in our implementation is a typed, multi-\\ndimensional array. We support a variety of tensor ele-\\nment types, including signed and unsigned integers rang-\\ning in size from 8 bits to 64 bits, IEEE ﬂoat and double\\ntypes, a complex number type, and a string type (an ar-\\nbitrary byte array). Backing store of the appropriate size\\nis managed by an allocator that is speciﬁc to the device\\non which the tensor resides. Tensor backing store buffers\\nare reference counted and are deallocated when no refer-\\nences remain.\\n3.1 Single-Device Execution\\nLet’s ﬁrst consider the simplest execution scenario: a sin-\\ngle worker process with a single device. The nodes of the\\ngraph are executed in an order that respects the depen-\\ndencies between nodes. In particular, we keep track of\\na count per node of the number of dependencies of that\\nnode that have not yet been executed. Once this count\\ndrops to zero, the node is eligibl', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1439: ('or resides. Tensor backing store buffers\\nare reference counted and are deallocated when no refer-\\nences remain.\\n3.1 Single-Device Execution\\nLet’s ﬁrst consider the simplest execution scenario: a sin-\\ngle worker process with a single device. The nodes of the\\ngraph are executed in an order that respects the depen-\\ndencies between nodes. In particular, we keep track of\\na count per node of the number of dependencies of that\\nnode that have not yet been executed. Once this count\\ndrops to zero, the node is eligible for execution and is\\nadded to a ready queue. The ready queue is processed in\\nsome unspeciﬁed order, delegating execution of the ker-\\nnel for a node to the device object. When a node has\\nﬁnished executing, the counts of all nodes that depend\\non the completed node are decremented.\\n3.2 Multi-Device Execution\\nOnce a system has multiple devices, there are two main\\ncomplications: deciding which device to place the com-\\nputation for each node in the graph, and then managing\\nthe required communication of data across device bound-\\naries implied by these placement decisions. This subsec-\\ntion discusses these two issues.\\n3.2.1 Node Placement\\nGiven a computation graph, one of the main responsi-\\nbilities of the TensorFlow implementation is to map the\\ncomputation onto the set of available devices. A sim-\\npliﬁed version of this algorithm is presented here. See\\nSection 4.3 for extensions supported by this algorithm.\\nOne input to the placement algorithm is a cost model,\\nwhich contains estimates of the sizes (in bytes) of the\\n4\\nclient master\\nsession\\nrun\\nexecute\\nsubgraph\\nworker\\nGPU 0GPU 1 ... CPU 0client\\nprocesssession\\nrun\\nexecute\\nsubgraph\\nworker\\nprocess 1\\nGPU 0\\nGPU 1...\\nCPU 0GPU 0\\nGPU 1...\\nCPU 0GPU 0\\nGPU 1...\\nCPU 0master\\nprocess\\nworker\\nprocess 2worker\\nprocess 3single processFigure 3: Single machine and distributed system structure\\ninput and output tensors for each graph node, along with\\nestimates of the computation time required for each node\\nwhen presented with its input tensors. This cost model is\\neither statically estimated', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1440: ('e\\n4\\nclient master\\nsession\\nrun\\nexecute\\nsubgraph\\nworker\\nGPU 0GPU 1 ... CPU 0client\\nprocesssession\\nrun\\nexecute\\nsubgraph\\nworker\\nprocess 1\\nGPU 0\\nGPU 1...\\nCPU 0GPU 0\\nGPU 1...\\nCPU 0GPU 0\\nGPU 1...\\nCPU 0master\\nprocess\\nworker\\nprocess 2worker\\nprocess 3single processFigure 3: Single machine and distributed system structure\\ninput and output tensors for each graph node, along with\\nestimates of the computation time required for each node\\nwhen presented with its input tensors. This cost model is\\neither statically estimated based on heuristics associated\\nwith different operation types, or is measured based on\\nan actual set of placement decisions for earlier execu-\\ntions of the graph.\\nThe placement algorithm ﬁrst runs a simulated execu-\\ntion of the graph. The simulation is described below and\\nends up picking a device for each node in the graph using\\ngreedy heuristics. The node to device placement gener-\\nated by this simulation is also used as the placement for\\nthe real execution.\\nThe placement algorithm starts with the sources of the\\ncomputation graph, and simulates the activity on each\\ndevice in the system as it progresses. For each node that\\nis reached in this traversal, the set of feasible devices is\\nconsidered (a device may not be feasible if the device\\ndoes not provide a kernel that implements the particular\\noperation). For nodes with multiple feasible devices, the\\nplacement algorithm uses a greedy heuristic that exam-\\nines the effects on the completion time of the node of\\nplacing the node on each possible device. This heuristic\\ntakes into account the estimated or measured execution\\ntime of the operation on that kind of device from the cost\\nmodel, and also includes the costs of any communica-\\ntion that would be introduced in order to transmit inputs\\nto this node from other devices to the considered device.\\nThe device where the node’s operation would ﬁnish the\\nsoonest is selected as the device for that operation, and\\nthe placement process then continues onwards to make\\nplacement decisions for other nodes in the graph, includ-\\n', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1441: ('istic\\ntakes into account the estimated or measured execution\\ntime of the operation on that kind of device from the cost\\nmodel, and also includes the costs of any communica-\\ntion that would be introduced in order to transmit inputs\\nto this node from other devices to the considered device.\\nThe device where the node’s operation would ﬁnish the\\nsoonest is selected as the device for that operation, and\\nthe placement process then continues onwards to make\\nplacement decisions for other nodes in the graph, includ-\\ning downstream nodes that are now ready for their own\\nsimulated execution. Section 4.3 describes some exten-\\nsions that allow users to provide hints and partial con-\\nstraints to guide the placement algorithm. The placement\\nalgorithm is an area of ongoing development within the\\nsystem.3.2.2 Cross-Device Communication\\nOnce the node placement has been computed, the graph\\nis partitioned into a set of subgraphs, one per device. Any\\ncross-device edge from xtoyis removed and replaced\\nby an edge from xto a new Send node in x’s subgraph\\nand an edge from a corresponding Receive node to yin\\ny’s subgraph. See Figure 4 for an example of this graph\\ntransformation.\\nab c\\nxy\\nrecv\\nsendrecv\\nsend\\nab c\\nxy\\nDevice AW W\\nDevice ADevice B Device B\\nFigure 4: Before & after insertion of Send/Receive nodes\\nAt runtime, the implementations of the Send and Re-\\nceive nodes coordinate to transfer data across devices.\\nThis allows us to isolate all communication inside Send\\nand Receive implementations, which simpliﬁes the rest\\nof the runtime.\\nWhen we insert Send and Receive nodes, we canoni-\\ncalize all users of a particular tensor on a particular de-\\nvice to use a single Receive node, rather than one Re-\\nceive node per downstream user on a particular device.\\nThis ensures that the data for the needed tensor is only\\ntransmitted once between a source device !destination\\ndevice pair, and that memory for the tensor on the desti-\\nnation device is only allocated once, rather than multiple\\ntimes (e.g., see nodes bandcin Figure 4)\\nBy handling communicatio', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1442: ('hen we insert Send and Receive nodes, we canoni-\\ncalize all users of a particular tensor on a particular de-\\nvice to use a single Receive node, rather than one Re-\\nceive node per downstream user on a particular device.\\nThis ensures that the data for the needed tensor is only\\ntransmitted once between a source device !destination\\ndevice pair, and that memory for the tensor on the desti-\\nnation device is only allocated once, rather than multiple\\ntimes (e.g., see nodes bandcin Figure 4)\\nBy handling communication in this manner, we also\\nallow the scheduling of individual nodes of the graph\\non different devices to be decentralized into the work-\\ners: the Send and Receive nodes impart the necessary\\n5\\nsynchronization between different workers and devices,\\nand the master only needs to issue a single Run request\\nper graph execution to each worker that has any nodes for\\nthe graph, rather than being involved in the scheduling of\\nevery node or every cross-device communication. This\\nmakes the system much more scalable and allows much\\nﬁner-granularity node executions than if the scheduling\\nwere forced to be done by the master.\\n3.3 Distributed Execution\\nDistributed execution of a graph is very similar to multi-\\ndevice execution. After device placement, a subgraph is\\ncreated per device. Send/Receive node pairs that com-\\nmunicate across worker processes use remote communi-\\ncation mechanisms such as TCP or RDMA to move data\\nacross machine boundaries.\\nFault Tolerance\\nFailures in a distributed execution can be detected in a\\nvariety of places. The main ones we rely on are (a) an\\nerror in a communication between a Send and Receive\\nnode pair, and (b) periodic health-checks from the master\\nprocess to every worker process.\\nWhen a failure is detected, the entire graph execution\\nis aborted and restarted from scratch. Recall however\\nthat Variable nodes refer to tensors that persist across ex-\\necutions of the graph. We support consistent checkpoint-\\ning and recovery of this state on a restart. In partcular,\\neach Variable node is connected to ', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1443: (' of places. The main ones we rely on are (a) an\\nerror in a communication between a Send and Receive\\nnode pair, and (b) periodic health-checks from the master\\nprocess to every worker process.\\nWhen a failure is detected, the entire graph execution\\nis aborted and restarted from scratch. Recall however\\nthat Variable nodes refer to tensors that persist across ex-\\necutions of the graph. We support consistent checkpoint-\\ning and recovery of this state on a restart. In partcular,\\neach Variable node is connected to a Save node. These\\nSave nodes are executed periodically, say once every N\\niterations, or once every N seconds. When they execute,\\nthe contents of the variables are written to persistent stor-\\nage, e.g., a distributed ﬁle system. Similarly each Vari-\\nable is connected to a Restore node that is only enabled\\nin the ﬁrst iteration after a restart. See Section 4.2 for\\ndetails on how some nodes can only be enabled on some\\nexecutions of the graph.\\n4 Extensions\\nIn this section we describe several more advanced fea-\\ntures of the basic programming model that was intro-\\nduced in Section 2.\\n4.1 Gradient Computation\\nMany optimization algorithms, including common ma-\\nchine learning training algorithms like stochastic gradi-\\nent descent [45], compute the gradient of a cost function\\nwith respect to a set of inputs. Because this is such a\\nWb\\nxMatMulAddReLU...C\\nWb\\nxMatMulAddReLU...C\\ndC/dWdMatMuldAdddReLU...1\\ndC/db\\ndC/dxFigure 5: Gradients computed for graph in Figure 2\\ncommon need, TensorFlow has built-in support for au-\\ntomatic gradient computation. If a tensor Cin a Ten-\\nsorFlow graph depends, perhaps through a complex sub-\\ngraph of operations, on some set of tensors fXkg, then\\nthere is a built-in function that will return the tensors\\nfdC=dX kg. Gradient tensors are computed, like other\\ntensors, by extending the TensorFlow graph, using the\\nfollowing procedure.\\nWhen TensorFlow needs to compute the gradient of\\na tensorCwith respect to some tensor Ion whichC\\ndepends, it ﬁrst ﬁnds the path in the computation graph\\nfromItoC. Then i', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1444: ('ic gradient computation. If a tensor Cin a Ten-\\nsorFlow graph depends, perhaps through a complex sub-\\ngraph of operations, on some set of tensors fXkg, then\\nthere is a built-in function that will return the tensors\\nfdC=dX kg. Gradient tensors are computed, like other\\ntensors, by extending the TensorFlow graph, using the\\nfollowing procedure.\\nWhen TensorFlow needs to compute the gradient of\\na tensorCwith respect to some tensor Ion whichC\\ndepends, it ﬁrst ﬁnds the path in the computation graph\\nfromItoC. Then it backtracks from CtoI, and for\\neach operation on the backward path it adds a node to\\nthe TensorFlow graph, composing the partial gradients\\nalong the backwards path using the chain rule. The newly\\nadded node computes the “gradient function” for the cor-\\nresponding operation in the forward path. A gradient\\nfunction may be registered by any operation. This func-\\ntion takes as input not only the partial gradients com-\\nputed already along the backward path, but also, option-\\nally, the inputs and outputs of the forward operation. Fig-\\nure 5 shows gradients for a cost computed from the ex-\\nample of Figure 2. Grey arrows show potential inputs\\nto gradient functions that are not used for the particular\\noperations shown. The addition needed to Figure 1 to\\ncompute these gradients is:\\n[db,dW,dx] = tf.gradients(C, [b,W,x])\\nIn general an operation may have multiple outputs, and\\nCmay only depend on some of them. If, for example,\\noperationOhas two outputs y1andy2, andConly de-\\npends ony2, then the ﬁrst input to O’s gradient function\\nis set to 0sincedC=dy 1= 0.\\nAutomatic gradient computation complicates opti-\\nmization, particularly of memory usage. When execut-\\ning “forward” computation subgraphs, i.e., those that are\\nexplicitly constructed by the user, a sensible heuristic\\nbreaks ties when deciding which node to execute next by\\nobserving the order in which the graph was constructed.\\n6\\nThis generally means that temporary outputs are con-\\nsumed soon after being constructed, so their memory can\\nbe reused quickly. When the heurist', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1445: ('function\\nis set to 0sincedC=dy 1= 0.\\nAutomatic gradient computation complicates opti-\\nmization, particularly of memory usage. When execut-\\ning “forward” computation subgraphs, i.e., those that are\\nexplicitly constructed by the user, a sensible heuristic\\nbreaks ties when deciding which node to execute next by\\nobserving the order in which the graph was constructed.\\n6\\nThis generally means that temporary outputs are con-\\nsumed soon after being constructed, so their memory can\\nbe reused quickly. When the heuristic is ineffective, the\\nuser can change the order of graph construction, or add\\ncontrol dependencies as described in Section 5. When\\ngradient nodes are automatically added to the graph, the\\nuser has less control, and the heuristics may break down.\\nIn particular, because gradients reverse the forward com-\\nputation order, tensors that are used early in a graph’s\\nexecution are frequently needed again near the end of a\\ngradient computation. Such tensors can hold on to a lot\\nof scarce GPU memory and unnecessarily limit the size\\nof computations. We are actively working on improve-\\nments to memory management to deal better with such\\ncases. Options include using more sophisticated heuris-\\ntics to determine the order of graph execution, recom-\\nputing tensors instead of retaining them in memory, and\\nswapping out long-lived tensors from GPU memory to\\nmore plentiful host CPU memory.\\n4.2 Partial Execution\\nOften a client wants to execute just a subgraph of the\\nentire execution graph. To support this, once the client\\nhas set up a computation graph in a Session, our Run\\nmethod allows them to execute an arbitrary subgraph of\\nthe whole graph, and to inject arbitrary data along any\\nedge in the graph, and to retrieve data ﬂowing along any\\nedge in the graph.\\nEach node in the graph has a name, and each output of\\na node is identiﬁed by the source node name and the out-\\nput port from the node, numbered from 0 (e.g., “bar:0”\\nrefers to the 1st output of the “bar” node, while “bar:1”\\nrefers to the 2nd output).\\nTwo arguments to the Run cal', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1446: (' up a computation graph in a Session, our Run\\nmethod allows them to execute an arbitrary subgraph of\\nthe whole graph, and to inject arbitrary data along any\\nedge in the graph, and to retrieve data ﬂowing along any\\nedge in the graph.\\nEach node in the graph has a name, and each output of\\na node is identiﬁed by the source node name and the out-\\nput port from the node, numbered from 0 (e.g., “bar:0”\\nrefers to the 1st output of the “bar” node, while “bar:1”\\nrefers to the 2nd output).\\nTwo arguments to the Run call help deﬁne the exact\\nsubgraph of the computation graph that will be executed.\\nFirst, the Run call accepts inputs, an optional mapping\\nofname :port names to “fed” tensors values. Second,\\nthe Run call accepts output names , a list of output\\nname [:port ]speciﬁcations indicating which nodes\\nshould be executed, and, if the port portion is present in a\\nname, that that particular output tensor value for the node\\nshould be returned to the client if the Run call completes\\nsuccessfully.\\nThe graph is transformed based on the values of in-\\nputs and outputs. Each node:port speciﬁed in inputs is\\nreplaced with a feed node, which will pick up the pro-\\nvided input tensor from specially-initialized entries in a\\nRendezvous object used for the Run call. Similarly, each\\noutput name with a port is connected to a special fetch\\nnode that arranges to save the output tensor and return it\\nto the client when the Run call is complete. Finally, once\\nthe graph has been rewritten with the insertion of these\\na bce\\ndf\\na\\nbc\\ne\\ndf\\nfeedfetchFigure 6: Before and after graph transformation for par-\\ntial execution\\nspecial feed andfetch nodes, the set of nodes to execute\\ncan be determined by starting at each of the nodes named\\nby any output and working backwards in the graph using\\nthe graph dependencies to determine the full set of nodes\\nthat must be executed in the rewritten graph in order to\\ncompute the outputs. Figure 6 shows an original graph\\non the left, and the transformed graph that results when\\nRun is invoked with inputs== fbgand outputs==ff', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1447: ('gure 6: Before and after graph transformation for par-\\ntial execution\\nspecial feed andfetch nodes, the set of nodes to execute\\ncan be determined by starting at each of the nodes named\\nby any output and working backwards in the graph using\\nthe graph dependencies to determine the full set of nodes\\nthat must be executed in the rewritten graph in order to\\ncompute the outputs. Figure 6 shows an original graph\\non the left, and the transformed graph that results when\\nRun is invoked with inputs== fbgand outputs==ff:0g.\\nSince we only need to compute the output of node f, we\\nwill not execute nodes dande, since they have no con-\\ntribution to the output of f.\\n4.3 Device Constraints\\nTensorFlow clients can control the placement of nodes\\non devices by providing partial constraints for a node\\nabout which devices it can execute on. For ex-\\nample, “only place this node on a device of type\\nGPU” , or “this node can be placed on any device in\\n/job:worker/task:17 ”, or “Colocate this node\\nwith the node named variable13 ”. Within the con-\\nﬁnes of these constraints, the placement algorithm is re-\\nsponsible for choosing an assignment of nodes to de-\\nvices that provides fast execution of the computation and\\nalso satisﬁes various constraints imposed by the devices\\nthemselves, such as limiting the total amount of memory\\nneeded on a device in order to execute its subset of graph\\nnodes.\\nSupporting such constraints requires changes to the\\nplacement algorithm described in Section 3.2.1. We ﬁrst\\ncompute the feasible set of devices for each node, and\\nthen use union-ﬁnd on the graph of colocation constraints\\nto compute the graph components that must be placed\\ntogether. For each such component, we compute the in-\\ntersection of the feasible device sets. The computed fea-\\nsible device set per node ﬁts easily into the placement\\nalgorithm’s simulator.\\n7\\n4.4 Control Flow\\nAlthough dataﬂow graphs without any explicit control\\nﬂow are quite expressive, we have observed a number of\\ncases where supporting conditionals and loops can lead\\nto more concise and ef', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1448: ('e, and\\nthen use union-ﬁnd on the graph of colocation constraints\\nto compute the graph components that must be placed\\ntogether. For each such component, we compute the in-\\ntersection of the feasible device sets. The computed fea-\\nsible device set per node ﬁts easily into the placement\\nalgorithm’s simulator.\\n7\\n4.4 Control Flow\\nAlthough dataﬂow graphs without any explicit control\\nﬂow are quite expressive, we have observed a number of\\ncases where supporting conditionals and loops can lead\\nto more concise and efﬁcient representations of machine\\nlearning algorithms.\\nMuch as in the dataﬂow-machine approach described\\nby Arvind [3], we introduce a small set of primitive con-\\ntrol ﬂow operators into TensorFlow and generalize Ten-\\nsorFlow to handle cyclic dataﬂow graphs. The Switch\\nandMerge operators allow us to skip the execution of\\nan entire subgraph based on the value of a boolean ten-\\nsor. The Enter ,Leave , and NextIteration operators allow\\nus to express iteration. High-level programming con-\\nstructs such as if-conditionals and while-loops can be\\neasily compiled into dataﬂow graphs with these control\\nﬂow operators.\\nThe TensorFlow runtime implements a notion of tags\\nand frames conceptually similar to the MIT Tagged-\\nToken machine [4]. Each iteration of a loop is uniquely\\nidentiﬁed by a tag, and its execution state is represented\\nby a frame. An input can enter an iteration whenever it\\nbecomes available; thus, multiple iterations can be exe-\\ncuted concurrently.\\nTensorFlow uses a distributed coordination mecha-\\nnism to execute graphs with control ﬂow. In general, a\\nloop can contain nodes that are assigned to many dif-\\nferent devices. Therefore, managing the state of a loop\\nbecomes a problem of distributed termination detection.\\nTensorFlow’s solution is based on graph rewriting. Dur-\\ning the graph partitioning, we automatically add control\\nnodes to each partition. These nodes implement a small\\nstate machine that orchestrates the start and termination\\nof each iteration, and decides the termination of the loop.\\nFor each itera', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1449: ('xecute graphs with control ﬂow. In general, a\\nloop can contain nodes that are assigned to many dif-\\nferent devices. Therefore, managing the state of a loop\\nbecomes a problem of distributed termination detection.\\nTensorFlow’s solution is based on graph rewriting. Dur-\\ning the graph partitioning, we automatically add control\\nnodes to each partition. These nodes implement a small\\nstate machine that orchestrates the start and termination\\nof each iteration, and decides the termination of the loop.\\nFor each iteration, the device that owns the loop termi-\\nnation predicate sends a tiny control message to every\\nparticipating device.\\nAs explained above, we often train machine learning\\nmodels by gradient descent, and represent gradient com-\\nputations as part of dataﬂow graphs. When a model\\nincludes control-ﬂow operations, we must account for\\nthem in the corresponding gradient computation. For ex-\\nample, the gradient computation for a model with an if-\\nconditional will need to know which branch of the con-\\nditional was taken, then apply the gradient logic to this\\nbranch. Similarly, the gradient computation for a model\\nwith a while-loop will need to know how many iterations\\nwere taken, and will also rely on the intermediate values\\ncomputed during those iterations. The basic technique is\\nto rewrite the graph so to memorize the values needed for\\nthe gradient computation. We omit the somewhat intri-\\ncate details of this encoding.4.5 Input Operations\\nAlthough input data can be provided to a computation via\\nfeed nodes, another common mechanism used for train-\\ning large-scale machine learning models is to have spe-\\ncial input operation nodes in the graph, which are typi-\\ncally conﬁgured with a set of ﬁlenames and which yield\\na tensor containing one or more examples from the data\\nstored in that set of ﬁles each time they are executed.\\nThis allows data to be read directly from the underlying\\nstorage system into the memory of the machine that will\\nperform subsequent processing on the data. In conﬁgura-\\ntions where the client process i', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1450: ('ommon mechanism used for train-\\ning large-scale machine learning models is to have spe-\\ncial input operation nodes in the graph, which are typi-\\ncally conﬁgured with a set of ﬁlenames and which yield\\na tensor containing one or more examples from the data\\nstored in that set of ﬁles each time they are executed.\\nThis allows data to be read directly from the underlying\\nstorage system into the memory of the machine that will\\nperform subsequent processing on the data. In conﬁgura-\\ntions where the client process is separate from the worker\\nprocess, if the data were fed, it typically would require an\\nextra network hop (from the storage system to the client\\nand then from the client to the worker vs. directly from\\nthe storage system to ther worker when using an input\\nnode).\\n4.6 Queues\\nQueues are a useful feature that we have added to Ten-\\nsorFlow. They allow different portions of the graph to\\nexecute asynchronously, possibly at different candences,\\nand to hand off data through Enqueue and Dequeue op-\\nerations. Enqueue operations can block until space be-\\ncomes available in the queue, and Dequeue operations\\ncan block until a desired minimum number of elements\\nare available in the queue. One use of queues is to allow\\ninput data to be prefetched from disk ﬁles while a previ-\\nous batch of data is still being processed by the compu-\\ntational portion of a machine learning model. They can\\nalso be used for other kinds of grouping, including accu-\\nmulating many gradients in order to compute some more\\ncomplex combination of gradients over a larger batch,\\nor to group different input sentences for recurrent lan-\\nguage models into bins of sentences that are approxi-\\nmately the same length, which can then be processed\\nmore efﬁciently.\\nIn addition to normal FIFO queues, we have also im-\\nplemented a shufﬂing queue, which randomly shufﬂes its\\nelements within a large in-memory buffer. This shufﬂing\\nfunctionality is useful for machine learning algorithms\\nthat want to randomize the order in which they process\\nexamples, for example.\\n4.7 Contai', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1451: ('nts over a larger batch,\\nor to group different input sentences for recurrent lan-\\nguage models into bins of sentences that are approxi-\\nmately the same length, which can then be processed\\nmore efﬁciently.\\nIn addition to normal FIFO queues, we have also im-\\nplemented a shufﬂing queue, which randomly shufﬂes its\\nelements within a large in-memory buffer. This shufﬂing\\nfunctionality is useful for machine learning algorithms\\nthat want to randomize the order in which they process\\nexamples, for example.\\n4.7 Containers\\nAContainer is the mechanism within TensorFlow for\\nmanaging longer-lived mutable state. The backing store\\nfor a Variable lives in a container. The default con-\\ntainer is one that persists until the process terminates,\\nbut we also allow other named containers. A container\\n8\\ncan be reset by clearing it of its contents entirely. Us-\\ning containers, it is possible to share state even across\\ncompletely disjoint computation graphs associated with\\ndifferent Sessions.\\n5 Optimizations\\nIn this section, we describe some of the optimizations\\nin the TensorFlow implementation that improve perfor-\\nmance or resource usage of the system.\\n5.1 Common Subexpression Elimination\\nSince the construction of computation graphs is often\\ndone by many different layers of abstractions in the client\\ncode, computation graphs can easily end up with redun-\\ndant copies of the same computation. To handle this, we\\nhave implemented a common subexpression pass similar\\nto the algorithm described by Click [12] that runs over\\nthe computation graph and canonicalizes multiple copies\\nof operations with identical inputs and operation types\\nto just a single one of these nodes, and redirects graph\\nedges appropriately to reﬂect this canonicalization.\\n5.2 Controlling Data Communication and\\nMemory Usage\\nCareful scheduling of TensorFlow operations can result\\nin better performance of the system, in particular with\\nrespect to data transfers and memory usage. Speciﬁcally,\\nscheduling can reduce the time window during which\\nintermediate results need to be kept in', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1452: ('h and canonicalizes multiple copies\\nof operations with identical inputs and operation types\\nto just a single one of these nodes, and redirects graph\\nedges appropriately to reﬂect this canonicalization.\\n5.2 Controlling Data Communication and\\nMemory Usage\\nCareful scheduling of TensorFlow operations can result\\nin better performance of the system, in particular with\\nrespect to data transfers and memory usage. Speciﬁcally,\\nscheduling can reduce the time window during which\\nintermediate results need to be kept in memory in be-\\ntween operations and hence the peak memory consump-\\ntion. This reduction is particularly important for GPU\\ndevices where memory is scarce. Furthermore, orches-\\ntrating the communication of data across devices can re-\\nduce contention for network resources.\\nWhile there are many opportunities for scheduling op-\\ntimizations, here we focus on one that we found partic-\\nularly necessary and effective. It concerns the schedul-\\ning of Receive nodes for reading remote values. If no\\nprecautions are taken, these nodes may start much ear-\\nlier than necessary, possibly all at once when execution\\nstarts. By performing an as-soon-as-possible/as-late-as-\\npossible (ASAP/ALAP) calculation, of the kind common\\nin operations research, we analyze the critical paths of\\ngraphs, in order to estimate when to start the Receive\\nnodes. We then insert control edges with the aim of de-\\nlaying the start of these nodes until just before their re-\\nsults are needed.5.3 Asynchronous Kernels\\nIn addition to normal synchronous kernels that complete\\ntheir execution at the end of the Compute method, our\\nframework also supports non-blocking kernels. Such\\nnon-blocking kernels use a slightly different interface\\nwhereby the Compute method is passed a continuation\\nthat should be invoked when the kernel’s execution is\\ncomplete. This is an optimization for environments\\nwhere having many active threads is relatively expensive\\nin terms of memory usage or other resources, and allows\\nus to avoid tying up an execution thread for unbounded\\nperiods of', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1453: ('s that complete\\ntheir execution at the end of the Compute method, our\\nframework also supports non-blocking kernels. Such\\nnon-blocking kernels use a slightly different interface\\nwhereby the Compute method is passed a continuation\\nthat should be invoked when the kernel’s execution is\\ncomplete. This is an optimization for environments\\nwhere having many active threads is relatively expensive\\nin terms of memory usage or other resources, and allows\\nus to avoid tying up an execution thread for unbounded\\nperiods of time while waiting for I/O or other events to\\noccur. Examples of asynchronous kernels include the\\nReceive kernel, and the Enqueue andDequeue kernels\\n(which might need to block if queue space is not avail-\\nable or if no data is available to be read, respectively).\\n5.4 Optimized Libraries for Kernel Imple-\\nmentations\\nWe often make use of pre-existing highly-optimized nu-\\nmerical libraries to implement kernels for some opera-\\ntions. For example, there are a number of optimized li-\\nbraries for performing matrix multiplies on different de-\\nvices, including BLAS [15] and cuBLAS [39], or GPU\\nlibraries for convolutional kernels for deep neural nets\\nsuch as cuda-convnet [28] and cuDNN [9]. Many of\\nour kernel implementations are relatively thin wrappers\\naround such optimized libraries.\\nWe make fairly extensive use of the open-source Eigen\\nlinear algebra library [25] for many of the kernel imple-\\nmentations in the system. As one part of the develop-\\nment of TensorFlow, our team (primarily Benoit Steiner)\\nhas extended the open source Eigen library with support\\nfor arbitrary dimensionality tensor operations.\\n5.5 Lossy Compression\\nSome machine learning algorithms, including those typ-\\nically used for training neural networks, are tolerant of\\nnoise and reduced precision arithmetic. In a manner sim-\\nilar to the DistBelief system [14], we often use lossy\\ncompression of higher precision internal representations\\nwhen sending data between devices (sometimes within\\nthe same machine but especially across machine bound-\\naries). For ', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1454: ('he open source Eigen library with support\\nfor arbitrary dimensionality tensor operations.\\n5.5 Lossy Compression\\nSome machine learning algorithms, including those typ-\\nically used for training neural networks, are tolerant of\\nnoise and reduced precision arithmetic. In a manner sim-\\nilar to the DistBelief system [14], we often use lossy\\ncompression of higher precision internal representations\\nwhen sending data between devices (sometimes within\\nthe same machine but especially across machine bound-\\naries). For example, we often insert special conversion\\nnodes that convert 32-bit ﬂoating point representations\\ninto a 16-bit ﬂoating point representation (not the pro-\\nposed IEEE 16-bit ﬂoating point standard, but rather just\\na 32-bit IEEE 794 ﬂoat format, but with 16 bits less pre-\\ncision in the mantissa), and then convert back to a 32-\\nbit representation on the other side of the communica-\\ntion channel (by just ﬁlling in zeroes for the lost portion\\n9\\nof the mantissa, since that’s less computationally expen-\\nsive than doing the mathematically correct probabilistic\\nrounding when doing this 32!16!32-bit conver-\\nsion).\\n6 Status and Experience\\nThe TensorFlow interface and a reference implemen-\\ntation have been open sourced under an Apache 2.0\\nlicense, and the system is available for download at\\nwww.tensorﬂow.org. The system includes detailed docu-\\nmentation, a number of tutorials, and a number of exam-\\nples demonstrating how to use the system for a variety\\nof different machine learning tasks. The examples in-\\nclude models for classifying hand-written digits from the\\nMNIST dataset (the “hello world” of machine learning\\nalgorithms) [32], classifying images from the CIFAR-\\n10 dataset [30], doing language modeling using a recur-\\nrent LSTM [22] network, training word embedding vec-\\ntors [35] and more.\\nThe system includes front-ends for specifying Tensor-\\nFlow computations in Python and C++, and we expect\\nother front-ends to be added over time in response to\\nthe desires of both internal Google users and the broader\\nopen-source com', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1455: ('for classifying hand-written digits from the\\nMNIST dataset (the “hello world” of machine learning\\nalgorithms) [32], classifying images from the CIFAR-\\n10 dataset [30], doing language modeling using a recur-\\nrent LSTM [22] network, training word embedding vec-\\ntors [35] and more.\\nThe system includes front-ends for specifying Tensor-\\nFlow computations in Python and C++, and we expect\\nother front-ends to be added over time in response to\\nthe desires of both internal Google users and the broader\\nopen-source community.\\nWe have quite a few machine learning models in our\\nprevious DistBelief system [14] that we have migrated\\nover to TensorFlow. The rest of this section discusses\\nsome lessons we have learned that are generalizable for\\nany such migration of machine learning models from one\\nsystem to another, and therefore may be valuable to oth-\\ners.\\nIn particular, we focus on our lessons from porting a\\nstate-of-the-art convolutional neural network for image\\nrecognition termed Inception [23]. This image recogni-\\ntion system classiﬁes 224\\x02224pixel images into one\\nof 1000 labels (e.g., “cheetah”, “garbage truck”, etc.).\\nSuch a model comprises 13.6 million learnable parame-\\nters and 36,000 operations when expressed as a Tensor-\\nFlow graph. Running inference on a single image re-\\nquires 2 billion multiply-add operations.\\nAfter building all necessary mathematical operations\\nin TensorFlow, assembling and debugging all 36,000 op-\\nerations into the correct graph structure proved challeng-\\ning. Validating correctness is a difﬁcult enterprise be-\\ncause the system is inherently stochastic and only in-\\ntended to behave in a certain way in expectation — po-\\ntentially after hours of computation. Given these cir-\\ncumstances, we found the following strategies critical for\\nporting the Inception model to TensorFlow:\\n1.Build tools to gain insight into the exact number of\\nparameters in a given model. Such tools demon-strated subtle ﬂaws in a complex network architec-\\nture speciﬁcation. In particular we were able to\\nidentify operations and var', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1456: ('t enterprise be-\\ncause the system is inherently stochastic and only in-\\ntended to behave in a certain way in expectation — po-\\ntentially after hours of computation. Given these cir-\\ncumstances, we found the following strategies critical for\\nporting the Inception model to TensorFlow:\\n1.Build tools to gain insight into the exact number of\\nparameters in a given model. Such tools demon-strated subtle ﬂaws in a complex network architec-\\nture speciﬁcation. In particular we were able to\\nidentify operations and variables instantiated incor-\\nrectly due to automatic broadcasting in a mathemat-\\nical operation across a dimension.\\n2.Start small and scale up. The ﬁrst convolutional\\nneural network that we ported from our previ-\\nous system was a small network employed on the\\nCIFAR-10 data set [30]. Debugging such a network\\nelucidated subtle edge cases in individual opera-\\ntions (e.g., max-pooling) within the machine learn-\\ning system that would have been practically indeci-\\npherable in more complex models.\\n3.Always ensure that the objective (loss function)\\nmatches between machine learning systems when\\nlearning is turned off. Setting the learning rate to be\\nzero helped us identify unexpected behavior in how\\nwe had randomly initialized variables in a model.\\nSuch an error would have been difﬁcult to identify\\nin a dynamic, training network.\\n4.Make a single machine implementation match be-\\nfore debugging a distributed implementation. This\\nstrategy helped us delineate and debug discrep-\\nancies in training performance between machine\\nlearning system. In particular, we identiﬁed bugs\\ndue to race conditions and non-atomic operations\\nincorrectly assumed to be atomic.\\n5.Guard against numerical errors. Numerical li-\\nbraries are inconsistent in how they handle non-\\nﬁnite ﬂoating point values. Convolutional neu-\\nral networks are particularly susceptible to numer-\\nical instability and will tend to diverge quite regu-\\nlarly during experimentation and debugging phases.\\nGuarding against this behavior by checking for non-\\nﬁnite ﬂoating point value', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1457: ('\\nlearning system. In particular, we identiﬁed bugs\\ndue to race conditions and non-atomic operations\\nincorrectly assumed to be atomic.\\n5.Guard against numerical errors. Numerical li-\\nbraries are inconsistent in how they handle non-\\nﬁnite ﬂoating point values. Convolutional neu-\\nral networks are particularly susceptible to numer-\\nical instability and will tend to diverge quite regu-\\nlarly during experimentation and debugging phases.\\nGuarding against this behavior by checking for non-\\nﬁnite ﬂoating point values allows one to detect er-\\nrors in real time as opposed to identifying divergent\\nbehavior post-hoc.\\n6.Analyze pieces of a network and understand the\\nmagnitude of numerical error. Running subsec-\\ntions of a neural network in parallel on two machine\\nlearning systems provides a precise method to en-\\nsure that a numerical algorithm is identical across\\ntwo systems. Given that such algorithms run with\\nﬂoating point precision, it is important to predict\\nand understand the magnitude of expected numer-\\nical error in order to judge whether a given compo-\\nnent is correctly implemented (e.g., distinguishing\\nbetween “within 1e-2, great!” and“within 1e-2:\\nwhy is it so incorrect?!” ).\\n10\\ninputDevice B\\ninputDevice C\\ninputDevice AParameter Device(s)\\nPΔP\\nAdd\\nUpdate Client\\nSynchronous Data Parallelism\\nClient 1\\ninputDevice B\\ninputDevice C\\ninputDevice AParameter Device(s)\\nPUpdateΔP\\nUpdateUpdate\\nΔP\\nΔPClient 2Client 3\\nAsynchronous Data Parallelismmodel model modelmodel model modelFigure 7: Synchronous and asynchronous data parallel training\\nValidating complex mathematical operations in the\\npresence of an inherently stochastic system is quite chal-\\nlenging. The strategies outlined above proved invaluable\\nin gaining conﬁdence in the system and ultimately in in-\\nstantiating the Inception model in TensorFlow. The end\\nresult of these efforts resulted in a 6-fold speed improve-\\nment in training time versus our existing DistBelief im-\\nplementation of the model and such speed gains proved\\nindispensable in training a new class of larger-scale', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1458: (' training\\nValidating complex mathematical operations in the\\npresence of an inherently stochastic system is quite chal-\\nlenging. The strategies outlined above proved invaluable\\nin gaining conﬁdence in the system and ultimately in in-\\nstantiating the Inception model in TensorFlow. The end\\nresult of these efforts resulted in a 6-fold speed improve-\\nment in training time versus our existing DistBelief im-\\nplementation of the model and such speed gains proved\\nindispensable in training a new class of larger-scale im-\\nage recognition models.\\n7 Common Programming Idioms\\nTensorFlow’s basic dataﬂow graph model can be used in\\na variety of ways for machine learning applications. One\\ndomain we care about is speeding up training of com-\\nputationally intensive neural network models on large\\ndatasets. This section describes several techniques that\\nwe and others have developed in order to accomplish\\nthis, and illustrates how to use TensorFlow to realize\\nthese various approaches.\\nThe approaches in this subsection assume that the\\nmodel is being trained using stochastic gradient descent\\n(SGD) with relatively modest-sized mini-batches of 100\\nto 1000 examples.Data Parallel Training\\nOne simple technique for speeding up SGD is to paral-\\nlelize the computation of the gradient for a mini-batch\\nacross mini-batch elements. For example, if we are us-\\ning a mini-batch size of 1000 elements, we can use 10\\nreplicas of the model to each compute the gradient for\\n100 elements, and then combine the gradients and apply\\nupdates to the parameters synchronously, in order to be-\\nhave exactly as if we were running the sequential SGD\\nalgorithm with a batch size of 1000 elements. In this\\ncase, the TensorFlow graph simply has many replicas of\\nthe portion of the graph that does the bulk of the model\\ncomputation, and a single client thread drives the entire\\ntraining loop for this large graph. This is illustrated in\\nthe top portion of Figure 7.\\nThis approach can also be made asynchronous, where\\nthe TensorFlow graph has many replicas of the portion of\\nthe graph', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1459: ('nchronously, in order to be-\\nhave exactly as if we were running the sequential SGD\\nalgorithm with a batch size of 1000 elements. In this\\ncase, the TensorFlow graph simply has many replicas of\\nthe portion of the graph that does the bulk of the model\\ncomputation, and a single client thread drives the entire\\ntraining loop for this large graph. This is illustrated in\\nthe top portion of Figure 7.\\nThis approach can also be made asynchronous, where\\nthe TensorFlow graph has many replicas of the portion of\\nthe graph that does the bulk of the model computation,\\nand each one of these replicas also applies the parame-\\nter updates to the model parameters asynchronously. In\\nthis conﬁguration, there is one client thread for each of\\nthe graph replicas. This is illustrated in the bottom por-\\ntion of Figure 7. This asynchronous approach was also\\ndescribed in [14].\\n11\\nP1A A A A AP2B B B B BP3C C C C CClient\\nDevice 1Device 2Device 3Figure 8: Model parallel training\\nmodel\\ninputmodel\\ninputmodel\\ninputPUpdate Update UpdateClient\\nFigure 9: Concurrent steps\\nModel Parallel Training\\nModel parallel training, where different portions of the\\nmodel computation are done on different computational\\ndevices simultaneously for the same batch of examples,\\nis also easy to express in TensorFlow. Figure 8 shows\\nan example of a recurrent, deep LSTM model used for\\nsequence to sequence learning (see [47]), parallelized\\nacross three different devices.\\nConcurrent Steps for Model Computation Pipelining\\nAnother common way to get better utilization for train-\\ning deep neural networks is to pipeline the computation\\nof the model within the same devices, by running a small\\nnumber of concurrent steps within the same set of de-\\nvices. This is shown in Figure 9. It is somewhat similar\\nto asynchronous data parallelism, except that the paral-\\nlelism occurs within the same device(s), rather than repli-\\ncating the computation graph on different devices. This\\nallows “ﬁlling in the gaps” where computation of a sin-\\ngle batch of examples might not be able to fully utilize\\nt', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1460: ('\\ning deep neural networks is to pipeline the computation\\nof the model within the same devices, by running a small\\nnumber of concurrent steps within the same set of de-\\nvices. This is shown in Figure 9. It is somewhat similar\\nto asynchronous data parallelism, except that the paral-\\nlelism occurs within the same device(s), rather than repli-\\ncating the computation graph on different devices. This\\nallows “ﬁlling in the gaps” where computation of a sin-\\ngle batch of examples might not be able to fully utilize\\nthe full parallelism on all devices at all times during a\\nsingle step.8 Performance\\nA future version of this white paper will have a compre-\\nhensive performance evaluation section of both the sin-\\ngle machine and distributed implementations.\\n9 Tools\\nThis section describes some tools we have developed that\\nsit alongside the core TensorFlow graph execution en-\\ngine.\\n9.1 TensorBoard: Visualization of graph\\nstructures and summary statistics\\nIn order to help users understand the structure of their\\ncomputation graphs and also to understand the overall\\nbehavior of machine learning models, we have built Ten-\\nsorBoard, a companion visualization tool for TensorFlow\\nthat is included in the open source release.\\nVisualization of Computation Graphs\\nMany of the computation graphs for deep neural net-\\nworks can be quite complex. For example, the computa-\\ntion graph for training a model similar to Google’s Incep-\\ntion model [48], a deep convolutional neural net that had\\nthe best classiﬁcation performance in the ImageNet 2014\\ncontest, has over 36,000 nodes in its TensorFlow compu-\\ntation graph, and some deep recurrent LSTM models for\\nlanguage modeling have more than 15,000 nodes.\\nDue to the size and topology of these graphs, naive vi-\\nsualization techniques often produce cluttered and over-\\nwhelming diagrams. To help users see the underlying\\norganization of the graphs, the algorithms in Tensor-\\nBoard collapse nodes into high-level blocks, highlighting\\ngroups with identical structures. The system also sep-\\narates out high-degree n', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1461: ('ontest, has over 36,000 nodes in its TensorFlow compu-\\ntation graph, and some deep recurrent LSTM models for\\nlanguage modeling have more than 15,000 nodes.\\nDue to the size and topology of these graphs, naive vi-\\nsualization techniques often produce cluttered and over-\\nwhelming diagrams. To help users see the underlying\\norganization of the graphs, the algorithms in Tensor-\\nBoard collapse nodes into high-level blocks, highlighting\\ngroups with identical structures. The system also sep-\\narates out high-degree nodes, which often serve book-\\nkeeping functions, into a separate area of the screen. Do-\\ning so reduces visual clutter and focuses attention on the\\ncore sections of the computation graph.\\nThe entire visualization is interactive: users can pan,\\nzoom, and expand grouped nodes to drill down for de-\\ntails. An example of the visualization for the graph of a\\ndeep convolutional image model is shown in Figure 10.\\nVisualization of Summary Data\\nWhen training machine learning models, users often\\nwant to be able to examine the state of various aspects\\nof the model, and how this state changes over time. To\\nthis end, TensorFlow supports a collection of different\\nSummary operations that can be inserted into the graph,\\n12\\nFigure 10: TensorBoard graph visualization of a convolutional neural network model\\nFigure 11: TensorBoard graphical display of model summary statistics time series data\\nincluding scalar summaries (e.g., for examining overall\\nproperties of the model, such as the value of the loss\\nfunction averaged across a collection of examples, or the\\ntime taken to execute the computation graph), histogram-\\nbased summaries (e.g., the distribution of weight values\\nin a neural network layer), or image-based summaries\\n(e.g., a visualization of the ﬁlter weights learned in a\\nconvolutional neural network). Typically computation\\ngraphs are set up so that Summary nodes are included\\nto monitor various interesting values, and every so often\\nduring execution of the training graph, the set of sum-\\nmary nodes are also executed, in addit', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1462: ('ollection of examples, or the\\ntime taken to execute the computation graph), histogram-\\nbased summaries (e.g., the distribution of weight values\\nin a neural network layer), or image-based summaries\\n(e.g., a visualization of the ﬁlter weights learned in a\\nconvolutional neural network). Typically computation\\ngraphs are set up so that Summary nodes are included\\nto monitor various interesting values, and every so often\\nduring execution of the training graph, the set of sum-\\nmary nodes are also executed, in addition to the normal\\nset of nodes that are executed, and the client driver pro-\\ngram writes the summary data to a log ﬁle associated\\nwith the model training. The TensorBoard program is\\nthen conﬁgured to watch this log ﬁle for new summaryrecords, and can display this summary information and\\nhow it changes over time (with the ability to select the\\nmeasurement of “time” to be relative wall time since\\nthe beginning of the execution of the TensorFlow pro-\\ngram, absolute time, or “steps”, a numeric measure of\\nthe number of graph executions that have occurred since\\nthe beginning of execution of the TensorFlow program).\\nA screen shot of the visualization of summary values in\\nTensorBoard is shown in Figure 11.\\n9.2 Performance Tracing\\nWe also have an internal tool called EEG (not included\\nin the initial open source release in November, 2015) that\\nwe use to collect and visualize very ﬁne-grained informa-\\ntion about the exact ordering and performance character-\\n13\\nistics of the execution of TensorFlow graphs. This tool\\nworks in both our single machine and distributed imple-\\nmentations, and is very useful for understanding the bot-\\ntlenecks in the computation and communication patterns\\nof a TensorFlow program.\\nTraces are collected simultaneously on each machine\\nin the system from a variety of sources including Linux\\nkernel ftrace , our own lightweight thread tracing tools\\nand the CUDA Proﬁling Tools Interface (CUPTI). With\\nthese logs we can reconstruct the execution of a dis-\\ntributed training step with microsecond-level detai', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1463: ('s in both our single machine and distributed imple-\\nmentations, and is very useful for understanding the bot-\\ntlenecks in the computation and communication patterns\\nof a TensorFlow program.\\nTraces are collected simultaneously on each machine\\nin the system from a variety of sources including Linux\\nkernel ftrace , our own lightweight thread tracing tools\\nand the CUDA Proﬁling Tools Interface (CUPTI). With\\nthese logs we can reconstruct the execution of a dis-\\ntributed training step with microsecond-level details of\\nevery thread-switch, CUDA kernel launch and DMA op-\\neration.\\nTraces are combined in a visualization server which\\nis designed to rapidly extract events in a speciﬁed\\ntimerange and summarize at appropriate detail level for\\nthe user-interface resolution. Any signiﬁcant delays\\ndue to communication, synchronization or DMA-related\\nstalls are identiﬁed and highlighted using arrows in the\\nvisualization. Initially the UI provides an overview of the\\nentire trace, with only the most signiﬁcant performance\\nartifacts highlighted. As the user progressively zooms in,\\nincreasingly ﬁne resolution details are rendered.\\nFigure 12 shows an example EEG visualization of a\\nmodel being trained on a multi-core CPU platform. The\\ntop third of the screenshot shows TensorFlow operations\\nbeing dispatched in parallel, according to the dataﬂow\\nconstraints. The bottom section of the trace shows how\\nmost operations are decomposed into multiple work-\\nitems which are executed concurrently in a thread pool.\\nThe diagonal arrows on the right hand size show where\\nqueueing delay is building up in the thread pool. Fig-\\nure 13 shows another EEG visualization with compu-\\ntation mainly happening on the GPU. Host threads can\\nbe seen enqueuing TensorFlow GPU operations as they\\nbecome runnable (the light blue thread pool), and back-\\nground housekeeping threads can be seen in other col-\\nors being migrated across processor cores. Once again,\\narrows show where threads are stalled on GPU to CPU\\ntransfers, or where ops experience signiﬁcant queueing\\ndelay.\\n', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1464: (' hand size show where\\nqueueing delay is building up in the thread pool. Fig-\\nure 13 shows another EEG visualization with compu-\\ntation mainly happening on the GPU. Host threads can\\nbe seen enqueuing TensorFlow GPU operations as they\\nbecome runnable (the light blue thread pool), and back-\\nground housekeeping threads can be seen in other col-\\nors being migrated across processor cores. Once again,\\narrows show where threads are stalled on GPU to CPU\\ntransfers, or where ops experience signiﬁcant queueing\\ndelay.\\nFinally, Figure 14 shows a more detailed view which\\nallows us to examine how Tensorﬂow GPU operators\\nare assigned to multiple GPU streams. Whenever the\\ndataﬂow graph allows parallel execution or data trans-\\nfer we endeavour to expose the ordering constraints to\\nthe GPU device using streams and stream dependency\\nprimitives.\\n10 Future Work\\nWe have several different directions for future work. We\\nwill continue to use TensorFlow to develop new and in-teresting machine learning models for artiﬁcial intelli-\\ngence, and in the course of doing this, we may discover\\nways in which we will need to extend the basic Ten-\\nsorFlow system. The open source community may also\\ncome up with new and interesting directions for the Ten-\\nsorFlow implementation.\\nOne extension to the basic programming model that\\nwe are considering is a function mechanism, whereby\\na user can specify an entire subgraph of a TensorFlow\\ncomputation to be a reusable component. In the imple-\\nmentation we have designed, these functions can become\\nreusable components even across different front-end lan-\\nguages for TensorFlow, so that a user could deﬁne a func-\\ntion using the Python front end, but then use that func-\\ntion as a basic building block from within the C++ front-\\nend. We are hopeful that this cross-language reusability\\nwill bootstrap a vibrant community of machine learning\\nresearchers publishing not just whole examples of their\\nresearch, but also small reusable components from their\\nwork that can be reused in other contexts.\\nWe also have a number of c', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1465: ('mponents even across different front-end lan-\\nguages for TensorFlow, so that a user could deﬁne a func-\\ntion using the Python front end, but then use that func-\\ntion as a basic building block from within the C++ front-\\nend. We are hopeful that this cross-language reusability\\nwill bootstrap a vibrant community of machine learning\\nresearchers publishing not just whole examples of their\\nresearch, but also small reusable components from their\\nwork that can be reused in other contexts.\\nWe also have a number of concrete directions to im-\\nprove the performance of TensorFlow. One such direc-\\ntion is our initial work on a just-in-time compiler that\\ncan take a subgraph of a TensorFlow execution, perhaps\\nwith some runtime proﬁling information about the typi-\\ncal sizes and shapes of tensors, and can generate an op-\\ntimized routine for this subgraph. This compiler will un-\\nderstand the semantics of perform a number of optimiza-\\ntions such as loop fusion, blocking and tiling for locality,\\nspecialization for particular shapes and sizes, etc.\\nWe also imagine that a signiﬁcant area for future work\\nwill be in improving the placement and node scheduling\\nalgorithms used to decide where different nodes will exe-\\ncute, and when they should start executing. We have cur-\\nrently implemented a number of heuristics in these sub-\\nsystems, and we’d like to have the system instead learn\\nto make good placement decisions (perhaps using a deep\\nneural network, combined with a reinforcement learning\\nobjective function).\\n11 Related Work\\nThere are many other systems that are comparable in\\nvarious ways with TensorFlow. Theano [7], Torch [13],\\nCaffe [26], Chainer [49] and the Computational Network\\nToolkit [54] are a few systems designed primarily for the\\ntraining of neural networks. Each of these systems maps\\nthe computation onto a single machine, unlike the dis-\\ntributed TensorFlow implementation. Like Theano and\\nChainer, TensorFlow supports symbolic differentiation,\\nthus making it easier to deﬁne and work with gradient-\\nbased optimization algorithms', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1466: (' many other systems that are comparable in\\nvarious ways with TensorFlow. Theano [7], Torch [13],\\nCaffe [26], Chainer [49] and the Computational Network\\nToolkit [54] are a few systems designed primarily for the\\ntraining of neural networks. Each of these systems maps\\nthe computation onto a single machine, unlike the dis-\\ntributed TensorFlow implementation. Like Theano and\\nChainer, TensorFlow supports symbolic differentiation,\\nthus making it easier to deﬁne and work with gradient-\\nbased optimization algorithms. Like Caffe, TensorFlow\\nhas a core written in C++, simplifying the deployment\\n14\\nFigure 12: EEG visualization of multi-threaded CPU operations (x-axis is time in \\x16s).\\nFigure 13: EEG visualization of Inception training showing CPU and GPU activity.\\nof trained models in a wide variety of production set-\\ntings, including memory- and computation-constrained\\nenvironments such as mobile devices.\\nThe TensorFlow system shares some design charac-\\nteristics with its predecessor system, DistBelief [14],\\nand with later systems with similar designs like Project\\nAdam [10] and the Parameter Server project [33]. Like\\nDistBelief and Project Adam, TensorFlow allows com-\\nputations to be spread out across many computational de-\\nvices across many machines, and allows users to specifymachine learning models using relatively high-level de-\\nscriptions. Unlike DistBelief and Project Adam, though,\\nthe general-purpose dataﬂow graph model in TensorFlow\\nis more ﬂexible and more amenable to expressing a wider\\nvariety of machine learning models and optimization al-\\ngorithms. It also permits a signiﬁcant simpliﬁcation by\\nallowing the expression of stateful parameter nodes as\\nvariables, and variable update operations that are just\\nadditional nodes in the graph; in contrast, DistBelief,\\nProject Adam and the Parameter Server systems all have\\n15\\nFigure 14: Timeline of multi-stream GPU execution.\\nwhole separate parameter server subsystems devoted to\\ncommunicating and updating parameter values.\\nThe Halide system [40] for expressing image pro-\\ncess', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1467: ('models and optimization al-\\ngorithms. It also permits a signiﬁcant simpliﬁcation by\\nallowing the expression of stateful parameter nodes as\\nvariables, and variable update operations that are just\\nadditional nodes in the graph; in contrast, DistBelief,\\nProject Adam and the Parameter Server systems all have\\n15\\nFigure 14: Timeline of multi-stream GPU execution.\\nwhole separate parameter server subsystems devoted to\\ncommunicating and updating parameter values.\\nThe Halide system [40] for expressing image pro-\\ncessing pipelines uses a similar intermediate represen-\\ntation to the TensorFlow dataﬂow graph. Unlike Ten-\\nsorFlow, though, the Halide system actually has higher-\\nlevel knowledge of the semantics of its operations and\\nuses this knowledge to generate highly optimized pieces\\nof code that combine multiple operations, taking into ac-\\ncount parallelism and locality. Halide runs the resulting\\ncomputations only on a single machine, and not in a dis-\\ntributed setting. In future work we are hoping to extend\\nTensorFlow with a similar cross-operation dynamic com-\\npilation framework.\\nLike TensorFlow, several other distributed systems\\nhave been developed for executing dataﬂow graphs\\nacross a cluster. Dryad [24] and Flume [8] demon-\\nstrate how a complex workﬂow can be represented as\\na dataﬂow graph. CIEL [37] and Naiad [36] introduce\\ngeneric support for data-dependent control ﬂow: CIEL\\nrepresents iteration as a DAG that dynamically unfolds,\\nwhereas Naiad uses a static graph with cycles to support\\nlower-latency iteration. Spark [55] is optimized for com-\\nputations that access the same data repeatedly, using “re-\\nsilient distributed datasets” (RDDs), which are soft-state\\ncached outputs of earlier computations. Dandelion [44]\\nexecutes dataﬂow graphs across a cluster of heteroge-\\nneous devices, including GPUs. TensorFlow uses a hy-\\nbrid dataﬂow model that borrows elements from each\\nof these systems. Its dataﬂow scheduler, which is the\\ncomponent that chooses the next node to execute, uses\\nthe same basic algorithm as Dryad, Flume, CI', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1468: ('k [55] is optimized for com-\\nputations that access the same data repeatedly, using “re-\\nsilient distributed datasets” (RDDs), which are soft-state\\ncached outputs of earlier computations. Dandelion [44]\\nexecutes dataﬂow graphs across a cluster of heteroge-\\nneous devices, including GPUs. TensorFlow uses a hy-\\nbrid dataﬂow model that borrows elements from each\\nof these systems. Its dataﬂow scheduler, which is the\\ncomponent that chooses the next node to execute, uses\\nthe same basic algorithm as Dryad, Flume, CIEL, and\\nSpark. Its distributed architecture is closest to Naiad, inthat the system uses a single, optimized dataﬂow graph to\\nrepresent the entire computation, and caches information\\nabout that graph on each device to minimize coordination\\noverhead. Like Spark and Naiad, TensorFlow works best\\nwhen there is sufﬁcient RAM in the cluster to hold the\\nworking set of the computation. Iteration in TensorFlow\\nuses a hybrid approach: multiple replicas of the same\\ndataﬂow graph may be executing at once, while sharing\\nthe same set of variables. Replicas can share data asyn-\\nchronously through the variables, or use synchronization\\nmechanisms in the graph, such as queues, to operate syn-\\nchronously. TensorFlow also supports iteration within a\\ngraph, which is a hybrid of CIEL and Naiad: for simplic-\\nity, each node ﬁres only when all of its inputs are ready\\n(like CIEL); but for efﬁciency the graph is represented as\\na static, cyclic dataﬂow (like Naiad).\\n12 Conclusions\\nWe have described TensorFlow, a ﬂexible data ﬂow-\\nbased programming model, as well as single machine\\nand distributed implementations of this programming\\nmodel. The system is borne from real-world experience\\nin conducting research and deploying more than one hun-\\ndred machine learning projects throughout a wide range\\nof Google products and services. We have open sourced\\na version of TensorFlow, and hope that a vibrant shared\\ncommunity develops around the use of TensorFlow. We\\nare excited to see how others outside of Google make use\\nof TensorFlow in their own work.', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1469: ('rogramming model, as well as single machine\\nand distributed implementations of this programming\\nmodel. The system is borne from real-world experience\\nin conducting research and deploying more than one hun-\\ndred machine learning projects throughout a wide range\\nof Google products and services. We have open sourced\\na version of TensorFlow, and hope that a vibrant shared\\ncommunity develops around the use of TensorFlow. We\\nare excited to see how others outside of Google make use\\nof TensorFlow in their own work.\\n16\\nAcknowledgements\\nThe development of TensorFlow has beneﬁtted enor-\\nmously from the large and broad machine learning com-\\nmunity at Google, and in particular from the suggestions\\nand contributions from rest of the Google Brain team\\nand also from the hundreds of DistBelief and TensorFlow\\nusers within Google. Without a doubt, the usability and\\nfunctionality of TensorFlow has been greatly expanded\\nby listening to their feedback.\\nMany individuals have contributed to TensorFlow\\nand to its open source release, including John Gian-\\nnandrea (for creating a supportive research environ-\\nment), Irina Kofman and Phing Turner (project manage-\\nment), Bill Gruber and David Westbrook (technical writ-\\ning), Dave Andersen, Anelia Angelova, Yaroslav Bu-\\nlatov, Jianmin Chen, Jerjou Cheng, George Dahl, An-\\ndrew Dai, Lucy Gao, mig Gerard, Stephan Gouws,\\nNaveen Kumar, Geoffrey Hinton, Mrinal Kalarishnan,\\nAnjuli Kannan, Yutaka Leon-Suematsu, Frank Li, Pe-\\nter Liu, Xiaobing Liu, Nishant Patil, Pierre Sermanet,\\nNoam Shazeer, Jascha Sohl-dickstein, Philip Tucker,\\nYonghui Wu, Ke Yang, and Cliff Young (general con-\\ntributions), Doug Fritz, Patrick Hurst, Dilip Krish-\\nnan, Daniel Smilkov, James Wexler, Jimbo Wilson,\\nKanit Ham Wongsuphasawat, Cassandra Xia, and the\\nBig Picture team (graph visualization), Chris Leary,\\nRobert Springer and the Stream Executor team,\\nKayur Patel, Michael Piatek, and the coLab team, and\\nthe many others who have contributed to the TensorFlow\\ndesign and code base.\\nReferences\\n[1] Mart ´ın Abadi, Ashish Agarwal, Pa', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1470: (' Sohl-dickstein, Philip Tucker,\\nYonghui Wu, Ke Yang, and Cliff Young (general con-\\ntributions), Doug Fritz, Patrick Hurst, Dilip Krish-\\nnan, Daniel Smilkov, James Wexler, Jimbo Wilson,\\nKanit Ham Wongsuphasawat, Cassandra Xia, and the\\nBig Picture team (graph visualization), Chris Leary,\\nRobert Springer and the Stream Executor team,\\nKayur Patel, Michael Piatek, and the coLab team, and\\nthe many others who have contributed to the TensorFlow\\ndesign and code base.\\nReferences\\n[1] Mart ´ın Abadi, Ashish Agarwal, Paul Barham, Eugene\\nBrevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado,\\nAndy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghe-\\nmawat, Ian Goodfellow, Andrew Harp, Geoffrey Irv-\\ning, Michael Isard, Yangqing Jia, Rafal Jozefowicz,\\nLukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan\\nMan ´e, Rajat Monga, Sherry Moore, Derek Murray, Chris\\nOlah, Mike Schuster, Jonathon Shlens, Benoit Steiner,\\nIlya Sutskever, Kunal Talwar, Paul Tucker, Vincent\\nVanhoucke, Vijay Vasudevan, Fernanda Vi ´egas, Oriol\\nVinyals, Pete Warden, Martin Wattenberg, Martin Wicke,\\nYuan Yu, and Xiaoqiang Zheng. TensorFlow: Large-scale\\nmachine learning on heterogeneous systems, 2015. Soft-\\nware available from tensorﬂow.org.\\n[2] Anelia Angelova, Alex Krizhevsky, and Vincent Van-\\nhoucke. Pedestrian detection with a large-ﬁeld-of-view\\ndeep network. In Robotics and Automation (ICRA), 2015\\nIEEE International Conference on , pages 704–711. IEEE,\\n2015. CalTech PDF.\\n[3] Arvind and David E. Culler. Annual review\\nof computer science vol. 1, 1986. chapterDataﬂow Architectures, pages 225–253. 1986.\\nwww.dtic.mil/cgi-bin/GetTRDoc?Location=U2&\\ndoc=GetTRDoc.pdf&AD=ADA166235.\\n[4] Arvind and Rishiyur S. Nikhil. Executing a pro-\\ngram on the MIT tagged-token dataﬂow architec-\\nture. IEEE Trans. Comput. , 39(3):300–318, 1990.\\ndl.acm.org/citation.cfm?id=78583.\\n[5] Jimmy Ba, V olodymyr Mnih, and Koray Kavukcuoglu.\\nMultiple object recognition with visual atten-\\ntion. arXiv preprint arXiv:1412.7755 , 2014.\\narxiv.org/abs/1412.7755.\\n[6] Franc ¸oise Beaufays. The neural networks\\nbe', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1471: (' Architectures, pages 225–253. 1986.\\nwww.dtic.mil/cgi-bin/GetTRDoc?Location=U2&\\ndoc=GetTRDoc.pdf&AD=ADA166235.\\n[4] Arvind and Rishiyur S. Nikhil. Executing a pro-\\ngram on the MIT tagged-token dataﬂow architec-\\nture. IEEE Trans. Comput. , 39(3):300–318, 1990.\\ndl.acm.org/citation.cfm?id=78583.\\n[5] Jimmy Ba, V olodymyr Mnih, and Koray Kavukcuoglu.\\nMultiple object recognition with visual atten-\\ntion. arXiv preprint arXiv:1412.7755 , 2014.\\narxiv.org/abs/1412.7755.\\n[6] Franc ¸oise Beaufays. The neural networks\\nbehind Google Voice transcription, 2015.\\ngoogleresearch.blogspot.com/2015/08/the-neural-\\nnetworks-behind-google-voice.html.\\n[7] James Bergstra, Olivier Breuleux, Fr ´ed´eric Bastien, Pas-\\ncal Lamblin, Razvan Pascanu, Guillaume Desjardins,\\nJoseph Turian, David Warde-Farley, and Yoshua Bengio.\\nTheano: A CPU and GPU math expression compiler. In\\nProceedings of the Python for scientiﬁc computing con-\\nference (SciPy) , volume 4, page 3. Austin, TX, 2010.\\nUMontreal PDF.\\n[8] Craig Chambers, Ashish Raniwala, Frances Perry,\\nStephen Adams, Robert R Henry, Robert Bradshaw,\\nand Nathan Weizenbaum. FlumeJava: easy, efﬁ-\\ncient data-parallel pipelines. In ACM Sigplan No-\\ntices, volume 45, pages 363–375. ACM, 2010. re-\\nsearch.google.com/pubs/archive/35650.pdf.\\n[9] Sharan Chetlur, Cliff Woolley, Philippe Vandermer-\\nsch, Jonathan Cohen, John Tran, Bryan Catanzaro,\\nand Evan Shelhamer. cuDNN: Efﬁcient primitives for\\ndeep learning. arXiv preprint arXiv:1410.0759 , 2014.\\narxiv.org/abs/1410.0759.\\n[10] Trishul Chilimbi, Yutaka Suzue, Johnson Apacible, and\\nKarthik Kalyanaraman. Project Adam: Building an\\nefﬁcient and scalable deep learning training system. In\\n11th USENIX Symposium on Operating Systems Design\\nand Implementation (OSDI 14) , pages 571–582, 2014.\\nwww.usenix.org/system/ﬁles/conference/osdi14/osdi14-\\npaper-chilimbi.pdf.\\n[11] Jack Clark. Google turning its lucrative\\nweb search over to AI machines, 2015.\\nwww.bloomberg.com/news/articles/2015-10-26/google-\\nturning-its-lucrative-web-search-over-to-ai-machines.\\n[12] Cliff Click. Global', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1472: ('hnson Apacible, and\\nKarthik Kalyanaraman. Project Adam: Building an\\nefﬁcient and scalable deep learning training system. In\\n11th USENIX Symposium on Operating Systems Design\\nand Implementation (OSDI 14) , pages 571–582, 2014.\\nwww.usenix.org/system/ﬁles/conference/osdi14/osdi14-\\npaper-chilimbi.pdf.\\n[11] Jack Clark. Google turning its lucrative\\nweb search over to AI machines, 2015.\\nwww.bloomberg.com/news/articles/2015-10-26/google-\\nturning-its-lucrative-web-search-over-to-ai-machines.\\n[12] Cliff Click. Global code motion/global value number-\\ning. In ACM SIGPLAN Notices , volume 30, pages 246–\\n257. ACM, 1995. courses.cs.washington.edu/courses/\\ncse501/06wi/reading/click-pldi95.pdf.\\n[13] Ronan Collobert, Samy Bengio, and Johnny\\nMari ´ethoz. Torch: A modular machine learning\\nsoftware library. Technical report, IDIAP, 2002.\\ninfoscience.epﬂ.ch/record/82802/ﬁles/rr02-46.pdf.\\n[14] Jeffrey Dean, Gregory S. Corrado, Rajat Monga, Kai\\nChen, Matthieu Devin, Quoc V . Le, Mark Z. Mao,\\nMarc’Aurelio Ranzato, Andrew Senior, Paul Tucker,\\n17\\nKe Yang, and Andrew Y . Ng. Large scale distributed deep\\nnetworks. In NIPS , 2012. Google Research PDF.\\n[15] Jack J Dongarra, Jeremy Du Croz, Sven Hammar-\\nling, and Iain S Duff. A set of level 3 basic lin-\\near algebra subprograms. ACM Transactions on\\nMathematical Software (TOMS) , 16(1):1–17, 1990.\\nwww.maths.manchester.ac.uk/˜sven/pubs/Level3BLAS-\\n1-TOMS16-90.pdf.\\n[16] Andrea Frome, Greg S Corrado, Jonathon Shlens,\\nSamy Bengio, Jeff Dean, Tomas Mikolov, et al.\\nDeVISE: A deep visual-semantic embedding\\nmodel. In Advances in Neural Information Pro-\\ncessing Systems , pages 2121–2129, 2013. re-\\nsearch.google.com/pubs/archive/41473.pdf.\\n[17] Javier Gonzalez-Dominguez, Ignacio Lopez-Moreno, Pe-\\ndro J Moreno, and Joaquin Gonzalez-Rodriguez. Frame-\\nby-frame language identiﬁcation in short utterances using\\ndeep neural networks. Neural Networks , 64:49–58, 2015.\\n[18] Otavio Good. How Google Translate\\nsqueezes deep learning onto a phone, 2015.\\ngoogleresearch.blogspot.com/2015/07/how-google-\\ntranslate-squeezes', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1473: ('dding\\nmodel. In Advances in Neural Information Pro-\\ncessing Systems , pages 2121–2129, 2013. re-\\nsearch.google.com/pubs/archive/41473.pdf.\\n[17] Javier Gonzalez-Dominguez, Ignacio Lopez-Moreno, Pe-\\ndro J Moreno, and Joaquin Gonzalez-Rodriguez. Frame-\\nby-frame language identiﬁcation in short utterances using\\ndeep neural networks. Neural Networks , 64:49–58, 2015.\\n[18] Otavio Good. How Google Translate\\nsqueezes deep learning onto a phone, 2015.\\ngoogleresearch.blogspot.com/2015/07/how-google-\\ntranslate-squeezes-deep.html.\\n[19] Ian J. Goodfellow, Yaroslav Bulatov, Julian Ibarz, Sacha\\nArnoud, and Vinay Shet. Multi-digit number recognition\\nfrom Street View imagery using deep convolutional neu-\\nral networks. In International Conference on Learning\\nRepresentations , 2014. arxiv.org/pdf/1312.6082.\\n[20] Georg Heigold, Vincent Vanhoucke, Alan Senior, Patrick\\nNguyen, Marc’Aurelio Ranzato, Matthieu Devin, and\\nJeffrey Dean. Multilingual acoustic models using dis-\\ntributed deep neural networks. In Acoustics, Speech\\nand Signal Processing (ICASSP), 2013 IEEE Interna-\\ntional Conference on , pages 8619–8623. IEEE, 2013. re-\\nsearch.google.com/pubs/archive/40807.pdf.\\n[21] Geoffrey E. Hinton, Li Deng, Dong Yu, George E.\\nDahl, Abdel-rahman Mohamed, Navdeep Jaitly, An-\\ndrew Senior, Vincent Vanhoucke, Patrick Nguyen,\\nTara N. Sainath, and Brian Kingsbury. Deep\\nneural networks for acoustic modeling in speech\\nrecognition: The shared views of four research\\ngroups. IEEE Signal Process. Mag. , 29(6):82–\\n97, 2012. www.cs.toronto.edu/˜gdahl/papers/\\ndeepSpeechReviewSPM2012.pdf.\\n[22] Sepp Hochreiter and J ¨urgen Schmidhuber. Long short-\\nterm memory. Neural computation , 9(8):1735–1780,\\n1997. ftp.idsia.ch/pub/juergen/lstm.pdf.\\n[23] Sergey Ioffe and Christian Szegedy. Batch normaliza-\\ntion: Accelerating deep network training by reducing\\ninternal covariate shift. CoRR , abs/1502.03167, 2015.\\narxiv.org/abs/1502.03167.\\n[24] Michael Isard, Mihai Budiu, Yuan Yu, Andrew\\nBirrell, and Dennis Fetterly. Dryad: distributed\\ndata-parallel programs from sequential', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1474: ('ers/\\ndeepSpeechReviewSPM2012.pdf.\\n[22] Sepp Hochreiter and J ¨urgen Schmidhuber. Long short-\\nterm memory. Neural computation , 9(8):1735–1780,\\n1997. ftp.idsia.ch/pub/juergen/lstm.pdf.\\n[23] Sergey Ioffe and Christian Szegedy. Batch normaliza-\\ntion: Accelerating deep network training by reducing\\ninternal covariate shift. CoRR , abs/1502.03167, 2015.\\narxiv.org/abs/1502.03167.\\n[24] Michael Isard, Mihai Budiu, Yuan Yu, Andrew\\nBirrell, and Dennis Fetterly. Dryad: distributed\\ndata-parallel programs from sequential building\\nblocks. In ACM SIGOPS Operating Systems\\nReview , volume 41, pages 59–72. ACM, 2007.\\nwww.michaelisard.com/pubs/eurosys07.pdf.[25] Beno ˆıt Jacob, Ga ¨el Guennebaud, et al. Eigen library for\\nlinear algebra. eigen.tuxfamily.org.\\n[26] Yangqing Jia, Evan Shelhamer, Jeff Donahue, Sergey\\nKarayev, Jonathan Long, Ross Girshick, Sergio Guadar-\\nrama, and Trevor Darrell. Caffe: Convolutional archi-\\ntecture for fast feature embedding. In Proceedings of\\nthe ACM International Conference on Multimedia , pages\\n675–678. ACM, 2014. arxiv.org/pdf/1408.5093.\\n[27] Andrej Karpathy, George Toderici, Sachin Shetty,\\nTommy Leung, Rahul Sukthankar, and Li Fei-\\nFei. Large-scale video classiﬁcation with con-\\nvolutional neural networks. In Computer Vision\\nand Pattern Recognition (CVPR), 2014 IEEE Con-\\nference on , pages 1725–1732. IEEE, 2014. re-\\nsearch.google.com/pubs/archive/42455.pdf.\\n[28] A Krizhevsky. Cuda-convnet, 2014.\\ncode.google.com/p/cuda-convnet/.\\n[29] Alex Krizhevsky. One weird trick for paralleliz-\\ning convolutional neural networks. arXiv preprint\\narXiv:1404.5997 , 2014. arxiv.org/abs/1404.5997.\\n[30] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The\\nCIFAR-10 dataset. www.cs.toronto.edu/˜kriz/cifar.html.\\n[31] Quoc Le, Marc’Aurelio Ranzato, Rajat Monga, Matthieu\\nDevin, Greg Corrado, Kai Chen, Jeff Dean, and Andrew\\nNg. Building high-level features using large scale unsu-\\npervised learning. In ICML’2012 , 2012. Google Research\\nPDF.\\n[32] Yann LeCun, Corinna Cortes, and Christopher JC\\nBurges. The MNIST database of handwr', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1475: ('neural networks. arXiv preprint\\narXiv:1404.5997 , 2014. arxiv.org/abs/1404.5997.\\n[30] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. The\\nCIFAR-10 dataset. www.cs.toronto.edu/˜kriz/cifar.html.\\n[31] Quoc Le, Marc’Aurelio Ranzato, Rajat Monga, Matthieu\\nDevin, Greg Corrado, Kai Chen, Jeff Dean, and Andrew\\nNg. Building high-level features using large scale unsu-\\npervised learning. In ICML’2012 , 2012. Google Research\\nPDF.\\n[32] Yann LeCun, Corinna Cortes, and Christopher JC\\nBurges. The MNIST database of handwritten digits,\\n1998. yann.lecun.com/exdb/mnist/.\\n[33] Mu Li, Dave Andersen, and Alex Smola. Parameter\\nserver. parameterserver.org.\\n[34] Chris J Maddison, Aja Huang, Ilya Sutskever, and David\\nSilver. Move evaluation in Go using deep convolutional\\nneural networks. arXiv preprint arXiv:1412.6564 , 2014.\\narxiv.org/abs/1412.6564.\\n[35] Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-\\nfrey Dean. Efﬁcient estimation of word representa-\\ntions in vector space. In International Conference\\non Learning Representations: Workshops Track , 2013.\\narxiv.org/abs/1301.3781.\\n[36] Derek G Murray, Frank McSherry, Rebecca Isaacs,\\nMichael Isard, Paul Barham, and Mart ´ın Abadi. Naiad:\\na timely dataﬂow system. In Proceedings of the Twenty-\\nFourth ACM Symposium on Operating Systems Princi-\\nples, pages 439–455. ACM, 2013. Microsoft Research\\nPDF.\\n[37] Derek G. Murray, Malte Schwarzkopf, Christopher\\nSmowton, Steven Smit, Anil Madhavapeddy, and Steven\\nHand. Ciel: a universal execution engine for dis-\\ntributed data-ﬂow computing. In Proceedings of the Ninth\\nUSENIX Symposium on Networked Systems Design and\\nImplementation , 2011. Usenix PDF.\\n18\\n[38] Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas\\nAlcicek, Rory Fearon, Alessandro De Maria, Ve-\\ndavyas Panneershelvam, Mustafa Suleyman, Charles\\nBeattie, Stig Petersen, et al. Massively parallel meth-\\nods for deep reinforcement learning. arXiv preprint\\narXiv:1507.04296 , 2015. arxiv.org/abs/1507.04296.\\n[39] CUDA Nvidia. Cublas library. NVIDIA Corpo-\\nration, Santa Clara, California , 15, 2008. deve', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1476: ('gs of the Ninth\\nUSENIX Symposium on Networked Systems Design and\\nImplementation , 2011. Usenix PDF.\\n18\\n[38] Arun Nair, Praveen Srinivasan, Sam Blackwell, Cagdas\\nAlcicek, Rory Fearon, Alessandro De Maria, Ve-\\ndavyas Panneershelvam, Mustafa Suleyman, Charles\\nBeattie, Stig Petersen, et al. Massively parallel meth-\\nods for deep reinforcement learning. arXiv preprint\\narXiv:1507.04296 , 2015. arxiv.org/abs/1507.04296.\\n[39] CUDA Nvidia. Cublas library. NVIDIA Corpo-\\nration, Santa Clara, California , 15, 2008. devel-\\noper.nvidia.com/cublas.\\n[40] Jonathan Ragan-Kelley, Connelly Barnes, Andrew\\nAdams, Sylvain Paris, Fr ´edo Durand, and Saman Ama-\\nrasinghe. Halide: A language and compiler for optimiz-\\ning parallelism, locality, and recomputation in image pro-\\ncessing pipelines. ACM SIGPLAN Notices , 48(6):519–\\n530, 2013. people.csail.mit.edu/fredo/tmp/Halide-\\n5min.pdf.\\n[41] Bharath Ramsundar, Steven Kearnes, Patrick Riley, Dale\\nWebster, David Konerding, and Vijay Pande. Massively\\nmultitask networks for drug discovery. arXiv preprint\\narXiv:1502.02072 , 2015. arxiv.org/abs/1502.02072.\\n[42] Benjamin Recht, Christopher Re, Stephen Wright, and\\nFeng Niu. Hogwild: A lock-free approach to paral-\\nlelizing stochastic gradient descent. In Advances in\\nNeural Information Processing Systems , pages 693–701,\\n2011. papers.nips.cc/paper/4390-hogwild-a-lock-free-\\napproach-to-parallelizing-stochastic-gradient-descent.\\n[43] Chuck Rosenberg. Improving Photo Search:\\nA step across the semantic gap, 2013.\\ngoogleresearch.blogspot.com/2013/06/improving-\\nphoto-search-step-across.html.\\n[44] Christopher J Rossbach, Yuan Yu, Jon Currey, Jean-\\nPhilippe Martin, and Dennis Fetterly. Dandelion: a\\ncompiler and runtime for heterogeneous systems. In\\nProceedings of the Twenty-Fourth ACM Symposium\\non Operating Systems Principles , pages 49–68. ACM,\\n2013. research-srv.microsoft.com/pubs/201110/sosp13-\\ndandelion-ﬁnal.pdf.\\n[45] David E Rumelhart, Geoffrey E Hinton, and Ronald J\\nWilliams. Learning representations by back-\\npropagating errors. Cognitive modeling , 5:3,', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1477: ('ving-\\nphoto-search-step-across.html.\\n[44] Christopher J Rossbach, Yuan Yu, Jon Currey, Jean-\\nPhilippe Martin, and Dennis Fetterly. Dandelion: a\\ncompiler and runtime for heterogeneous systems. In\\nProceedings of the Twenty-Fourth ACM Symposium\\non Operating Systems Principles , pages 49–68. ACM,\\n2013. research-srv.microsoft.com/pubs/201110/sosp13-\\ndandelion-ﬁnal.pdf.\\n[45] David E Rumelhart, Geoffrey E Hinton, and Ronald J\\nWilliams. Learning representations by back-\\npropagating errors. Cognitive modeling , 5:3, 1988.\\nwww.cs.toronto.edu/ hinton/absps/naturebp.pdf.\\n[46] Has ¸im Sak, Andrew Senior, Kanishka Rao,\\nFranc ¸oise Beaufays, and Johan Schalkwyk. Google\\nVoice Search: faster and more accurate, 2015.\\ngoogleresearch.blogspot.com/2015/09/google-voice-\\nsearch-faster-and-more.html.\\n[47] Ilya Sutskever, Oriol Vinyals, and Quoc V . Le. Sequence\\nto sequence learning with neural networks. In NIPS ,\\n2014. papers.nips.cc/paper/5346-sequence-to-sequence-\\nlearning-with-neural.\\n[48] Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Ser-\\nmanet, Scott Reed, Dragomir Anguelov, Dumitru Er-\\nhan, Vincent Vanhoucke, and Andrew Rabinovich. Go-\\ning deeper with convolutions. In CVPR’2015 , 2015.\\narxiv.org/abs/1409.4842.[49] Seiya Tokui. Chainer: A powerful, ﬂexible and intuitive\\nframework of neural networks. chainer.org.\\n[50] Vincent Vanhoucke. Speech recognition and deep learn-\\ning, 2015. googleresearch.blogspot.com/2012/08/speech-\\nrecognition-and-deep-learning.html.\\n[51] Abhishek Verma, Luis Pedrosa, Madhukar Korupolu,\\nDavid Oppenheimer, Eric Tune, and John Wilkes.\\nLarge-scale cluster management at Google with Borg.\\nInProceedings of the Tenth European Conference\\non Computer Systems , page 18. ACM, 2015. re-\\nsearch.google.com/pubs/archive/43438.pdf.\\n[52] O. Vinyals, L. Kaiser, T. Koo, S. Petrov, I. Sutskever, and\\nG. Hinton. Grammar as a foreign language. Technical\\nreport, arXiv:1412.7449, 2014. arxiv.org/abs/1412.7449.\\n[53] Oriol Vinyals, Meire Fortunato, and Navdeep\\nJaitly. Pointer networks. In NIPS , 2015.\\narxiv.org/abs/1506.03134.\\n[5', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1478: ('mer, Eric Tune, and John Wilkes.\\nLarge-scale cluster management at Google with Borg.\\nInProceedings of the Tenth European Conference\\non Computer Systems , page 18. ACM, 2015. re-\\nsearch.google.com/pubs/archive/43438.pdf.\\n[52] O. Vinyals, L. Kaiser, T. Koo, S. Petrov, I. Sutskever, and\\nG. Hinton. Grammar as a foreign language. Technical\\nreport, arXiv:1412.7449, 2014. arxiv.org/abs/1412.7449.\\n[53] Oriol Vinyals, Meire Fortunato, and Navdeep\\nJaitly. Pointer networks. In NIPS , 2015.\\narxiv.org/abs/1506.03134.\\n[54] Dong Yu, Adam Eversole, Mike Seltzer, Kaisheng\\nYao, Zhiheng Huang, Brian Guenter, Oleksii Kuchaiev,\\nYu Zhang, Frank Seide, Huaming Wang, et al. An\\nintroduction to computational networks and the com-\\nputational network toolkit. Technical report, Tech.\\nRep. MSR, Microsoft Research, 2014, 2014. re-\\nsearch.microsoft.com/apps/pubs/?id=226641.\\n[55] Matei Zaharia, Mosharaf Chowdhury, Tathagata Das,\\nAnkur Dave, Justin Ma, Murphy McCauley, Michael J\\nFranklin, Scott Shenker, and Ion Stoica. Resilient\\ndistributed datasets: A fault-tolerant abstraction for\\nin-memory cluster computing. In Proceedings of the\\n9th USENIX conference on Networked Systems De-\\nsign and Implementation . USENIX Association, 2012.\\nwww.usenix.org/system/ﬁles/conference/nsdi12/nsdi12-\\nﬁnal138.pdf.\\n[56] Matthew D. Zeiler, Marc’Aurelio Ranzato, Rajat Monga,\\nMark Mao, Ke Yang, Quoc Le, Patrick Nguyen,\\nAndrew Senior, Vincent Vanhoucke, Jeff Dean, and\\nGeoffrey E. Hinton. On rectiﬁed linear units\\nfor speech processing. In ICASSP , 2013. re-\\nsearch.google.com/pubs/archive/40811.pdf.\\n19', 'TensorFlow Large Scale Machine Learning on Heterogenous Distributed system.pdf'), 1479: ('Noise Estimation Using Density Estimation\\nfor Self-Supervised Multimodal Learning\\nElad Amrani1,2, Rami Ben-Ari1, Daniel Rotman1, Alex Bronstein2\\n1IBM Research AI,2Technion\\nAbstract\\nOne of the key factors of enabling machine learning models\\nto comprehend and solve real-world tasks is to leverage mul-\\ntimodal data. Unfortunately, annotation of multimodal data\\nis challenging and expensive. Recently, self-supervised multi-\\nmodal methods that combine vision and language were pro-\\nposed to learn multimodal representations without annotation.\\nHowever, these methods often choose to ignore the presence of\\nhigh levels of noise and thus yield sub-optimal results. In this\\nwork, we show that the problem of noise estimation for multi-\\nmodal data can be reduced to a multimodal density estimation\\ntask. Using multimodal density estimation, we propose a noise\\nestimation building block for multimodal representation learn-\\ning that is based strictly on the inherent correlation between\\ndifferent modalities. We demonstrate how our noise estima-\\ntion can be broadly integrated and achieves comparable results\\nto state-of-the-art performance on ﬁve different benchmark\\ndatasets for two challenging multimodal tasks: Video Ques-\\ntion Answering and Text-To-Video Retrieval. Furthermore,\\nwe provide a theoretical probabilistic error bound substanti-\\nating our empirical results and analyze failure cases. Code:\\nhttps://github.com/elad-amrani/ssml.\\n1 Introduction\\nMultimodal learning is a well established methodology for\\ntackling complex and challenging artiﬁcial intelligence tasks\\nsuch as Visual Question Answering (Antol et al. 2015; Jang\\net al. 2017; Gao et al. 2018; Xu et al. 2017; Fan et al. 2019)\\nand Text-to-Video Retrieval (Liu et al. 2019; Mithun et al.\\n2018; Yu, Kim, and Kim 2018; Miech, Laptev, and Sivic\\n2018; Song and Soleymani 2019). The motivation for glean-\\ning information from multiple correlated data sources comes\\nfrom how we as humans perceive the world and learn from ex-\\nperience. Using the correlation between speech and vision, a\\np', 'Noise Estimation Using Density Estimation.pdf'), 1480: ('enging artiﬁcial intelligence tasks\\nsuch as Visual Question Answering (Antol et al. 2015; Jang\\net al. 2017; Gao et al. 2018; Xu et al. 2017; Fan et al. 2019)\\nand Text-to-Video Retrieval (Liu et al. 2019; Mithun et al.\\n2018; Yu, Kim, and Kim 2018; Miech, Laptev, and Sivic\\n2018; Song and Soleymani 2019). The motivation for glean-\\ning information from multiple correlated data sources comes\\nfrom how we as humans perceive the world and learn from ex-\\nperience. Using the correlation between speech and vision, a\\nperson is able to recognize objects by their names while learn-\\ning the visual characteristics. Additionally, concepts can be\\nlearned separately and a combination can be comprehended\\nautomatically, e.g., ‘running’ and ‘beach’ vs. ‘running on the\\nbeach’.\\nManual annotation of large-scale datasets and speciﬁcally\\nmultimodal datasets is challenging and expensive. This dif-\\nﬁculty results in a shortage which limits the progress of\\nCopyright ©2021, Association for the Advancement of Artiﬁcial\\nIntelligence (www.aaai.org). All rights reserved.supervised machine learning and has become the key devel-\\nopment bottleneck. Recently, to combat costs and effort of\\nannotation, self-supervised machine learning (Zhang, Isola,\\nand Efros 2016; Noroozi and Favaro 2016; Pathak et al. 2016;\\nMisra, Zitnick, and Hebert 2016; Wei et al. 2018; V ondrick,\\nPirsiavash, and Torralba 2016; Srivastava, Mansimov, and\\nSalakhudinov 2015) presents new ways to better utilize the\\nabundant unlabeled data on the web. However, most self-\\nsupervised systems aim to learn from a single data modality,\\nwhich limits their applicability.\\nIn contrast to the above, (Miech et al. 2019, 2020; Amrani\\net al. 2019; Moriya et al. 2019; Sun et al. 2019b,a) recently\\nshowed that unlabeled instructional videos could be used\\nas training data for a self-supervised multimodal learning\\nsystem due to the high correlation between the spoken word\\nand the ongoing visuals. Unfortunately, such systems are\\nforced to deal with high noise levels and thus yield sub-\\noptimal results as ', 'Noise Estimation Using Density Estimation.pdf'), 1481: ('stems aim to learn from a single data modality,\\nwhich limits their applicability.\\nIn contrast to the above, (Miech et al. 2019, 2020; Amrani\\net al. 2019; Moriya et al. 2019; Sun et al. 2019b,a) recently\\nshowed that unlabeled instructional videos could be used\\nas training data for a self-supervised multimodal learning\\nsystem due to the high correlation between the spoken word\\nand the ongoing visuals. Unfortunately, such systems are\\nforced to deal with high noise levels and thus yield sub-\\noptimal results as we show in this paper.\\nIn this paper, we propose a novel noise robust multimodal\\nrepresentation learning building block for self-supervised\\nlearning. We utilize the inherent correlation between different\\nmodalities for efﬁcient multimodal learning in the presence\\nof extreme levels of noise. Speciﬁcally, we show that noise\\nestimation can be reduced to a density estimation problem.\\nWe deﬁne a multimodal similarity function and show that\\nbased on this function, noise is correlated with sparsity and\\nvice versa.\\nUltimately, we integrate our proposed building block into\\nan embedding model and learn superior joint video-text rep-\\nresentations that achieve comparable state-of-the-art perfor-\\nmance on ﬁve datasets: MSRVTT (Xu et al. 2016), LSMDC\\n(Rohrbach et al. 2015), MSVD (Chen and Dolan 2011),\\nMSRVTT-QA (Xu et al. 2017) and MSVD-QA (Xu et al.\\n2017); for two different tasks: Video Question Answering\\nand Text to Video Retrieval. Additionally, we provide a theo-\\nretical probabilistic error bound substantiating our empirical\\nresults and analyze failure cases.\\nContributions. The key contributions of this paper are\\nfour fold:\\n1.We show that the problem of noise estimation for mul-\\ntimodal data can be efﬁciently reduced to a multimodal\\ndensity estimation task.\\n2.We propose a novel building block for noise-robust multi-\\nmodal representation learning and demonstrate its integra-arXiv:2003.03186v3  [cs.CV]  10 Dec 2020\\ntion into the max margin ranking loss function.\\n3.We demonstrate comparable state-of-the-art performance\\non ﬁ', 'Noise Estimation Using Density Estimation.pdf'), 1482: ('irical\\nresults and analyze failure cases.\\nContributions. The key contributions of this paper are\\nfour fold:\\n1.We show that the problem of noise estimation for mul-\\ntimodal data can be efﬁciently reduced to a multimodal\\ndensity estimation task.\\n2.We propose a novel building block for noise-robust multi-\\nmodal representation learning and demonstrate its integra-arXiv:2003.03186v3  [cs.CV]  10 Dec 2020\\ntion into the max margin ranking loss function.\\n3.We demonstrate comparable state-of-the-art performance\\non ﬁve datasets for two different challenging multimodal\\ntasks by utilizing our approach for self-supervised multi-\\nmodal learning with the HowTo100M dataset (Miech et al.\\n2019).\\n4.We substantiate our empirical results with a theoretical\\nanalysis of the proposed method that includes a proba-\\nbilistic error bound.\\n2 Related Work\\nSelf-Supervised Learning. Self-supervised learning meth-\\nods strive to learn informative data representations by deﬁn-\\ning and solving a pretext task. In these tasks, pseudo labels\\ncan be generated automatically and compact data representa-\\ntions must be learned in order to solve these tasks. Many pre-\\ntext tasks were proposed in recent years: colorizing grayscale\\nimages (Zhang, Isola, and Efros 2016), image jigsaw puzzle\\n(Noroozi and Favaro 2016), image inpainting (Pathak et al.\\n2016), video frame order veriﬁcation (Misra, Zitnick, and\\nHebert 2016), video future prediction (V ondrick, Pirsiavash,\\nand Torralba 2016; Srivastava, Mansimov, and Salakhudi-\\nnov 2015), audio-visual correspondence (Korbar, Tran, and\\nTorresani 2018; Arandjelovic and Zisserman 2017), speech-\\nvisual correspondence (Miech et al. 2019, 2020; Amrani et al.\\n2019; Moriya et al. 2019; Sun et al. 2019b,a), etc. In this\\nwork, we focus on speech-visual correspondence in unla-\\nbeled instructional videos, where speech is converted to text\\nusing an automatic speech recognition system. Speech-visual\\ncorrespondence is considered a difﬁcult pretext task due to\\nextremely noisy pseudo labels, yet it can be a highly advanta-\\ngeous task', 'Noise Estimation Using Density Estimation.pdf'), 1483: ('e (Korbar, Tran, and\\nTorresani 2018; Arandjelovic and Zisserman 2017), speech-\\nvisual correspondence (Miech et al. 2019, 2020; Amrani et al.\\n2019; Moriya et al. 2019; Sun et al. 2019b,a), etc. In this\\nwork, we focus on speech-visual correspondence in unla-\\nbeled instructional videos, where speech is converted to text\\nusing an automatic speech recognition system. Speech-visual\\ncorrespondence is considered a difﬁcult pretext task due to\\nextremely noisy pseudo labels, yet it can be a highly advanta-\\ngeous task since it provides semantic information of visual\\nfeatures in the form of natural text. Such valuable informa-\\ntion can be utilized to solve many challenging multimodal\\ndownstream tasks as we show in Section 6.\\nMultimodal Representation Learning. The word modal-\\nityrefers to a particular form of sensory perception, such as\\nthe visual and auditory modalities. A machine learning task or\\ndataset is said to be multimodal when it includes a number of\\nmodalities. Multimodal representation learning frameworks\\ncan be divided into three types: (a) joint representation which\\naims to learn a shared semantic subspace (Salakhutdinov\\nand Hinton 2009; Srivastava and Salakhutdinov 2012; Antol\\net al. 2015); (b) an encoder-decoder framework which aims\\nto translate from one modality into another and keep their\\nsemantics consistent (Mao et al. 2014; Rohrbach, Rohrbach,\\nand Schiele 2015; Venugopalan et al. 2015; Reed et al. 2016);\\nand (c) coordinated representation which aims to learn sepa-\\nrated yet coordinated representations for each modality under\\nsome constraints (Weston, Bengio, and Usunier 2010; Frome\\net al. 2013; Socher et al. 2014; Wang, Li, and Lazebnik 2016;\\nVendrov et al. 2016; Tian, Krishnan, and Isola 2019). In this\\nwork, we focus on coordinated representations that enforce\\nsimilarity among them. Our goal is to enforce the multimodal\\nrepresentations of similar ‘concepts’ to be close to each other.\\nE.g., a video of a man running on the beach should be close in\\nrepresentation to the textual representation of ‘a man runn', 'Noise Estimation Using Density Estimation.pdf'), 1484: ('or each modality under\\nsome constraints (Weston, Bengio, and Usunier 2010; Frome\\net al. 2013; Socher et al. 2014; Wang, Li, and Lazebnik 2016;\\nVendrov et al. 2016; Tian, Krishnan, and Isola 2019). In this\\nwork, we focus on coordinated representations that enforce\\nsimilarity among them. Our goal is to enforce the multimodal\\nrepresentations of similar ‘concepts’ to be close to each other.\\nE.g., a video of a man running on the beach should be close in\\nrepresentation to the textual representation of ‘a man runningon the beach’ as opposed to ‘a man cooking in the kitchen’.\\nThe multimodal representation described above is highly\\nvaluable for solving multimodal machine learning tasks. If\\na machine learning model learns to link between the visuals\\nand text of speciﬁc concepts it should be able, for example,\\nto answer natural language questions about visual content, or\\ndo cross-modal retrieval more easily (Section 5.2).\\nDensity Estimation. The aim of density estimation is to\\nestimate the probability density function underlying the data,\\nwhich is assumed to be i:i:d. Existing density estimation al-\\ngorithms can be divided into two categories: (a) parametric\\nor semi-parametric approaches such as Gaussian Mixture\\nmodels (McLachlan and Krishnan 2007; Wang and Wang\\n2015) and probabilistic graphical models (Koller and Fried-\\nman 2009); and (b) non-parametric approaches such as his-\\ntograms, Splines (Stone 1994), neural network-based density\\nestimation (Uria, Murray, and Larochelle 2014; Papamakar-\\nios, Pavlakou, and Murray 2017) and Kernel Density Es-\\ntimation (Silverman 2018; Terrell and Scott 1992). For an\\nextended review on density estimation for high-dimensional\\ndata see (Wang and Scott 2019). In this work, we utilize\\nmultimodal k-Nearest Neighbor density estimation, which\\nis a special case of Kernel Density Estimation. With it, we\\nform a novel noise-robust multimodal representation learning\\nmodel.\\nLearning with Noisy Data. Learning with noisy data can\\nbe divided into two approaches: (a) formulating explicit or\\nimplicit noi', 'Noise Estimation Using Density Estimation.pdf'), 1485: ('17) and Kernel Density Es-\\ntimation (Silverman 2018; Terrell and Scott 1992). For an\\nextended review on density estimation for high-dimensional\\ndata see (Wang and Scott 2019). In this work, we utilize\\nmultimodal k-Nearest Neighbor density estimation, which\\nis a special case of Kernel Density Estimation. With it, we\\nform a novel noise-robust multimodal representation learning\\nmodel.\\nLearning with Noisy Data. Learning with noisy data can\\nbe divided into two approaches: (a) formulating explicit or\\nimplicit noise models to characterize the distribution of noisy\\nand true labels using neural networks (Goldberger and Ben-\\nReuven 2017; Jiang et al. 2018; Sukhbaatar et al. 2015),\\ngraphical models (Xiao et al. 2015; Li et al. 2017), etc. and\\n(b) using correction methods. E.g., relabeling the data during\\ntraining (Reed et al. 2015), jointly optimizing the model’s\\nparameters and estimating true labels (Tanaka et al. 2018),\\nusing noise-tolerant loss function (Ghosh, Kumar, and Sastry\\n2017; Van Rooyen, Menon, and Williamson 2015) or noise\\ntolerant training algorithms (Li et al. 2019). However, these\\nmethods do not deal with multimodal association label (Def-\\ninition 1) and often require a small set of data with clean\\nlabels to be available. In this work, we propose a true label\\nestimation method for multimodal data that does not require\\navailability of clean labels. We base our estimation on the\\ncorrelation between modalities alone.\\n3 Method\\n3.1 Motivation\\nIn multimodal data, a sample is said to be noisy when two or\\nmore modalities do not share the same semantic meaning. For\\nexample, a video-text pair that is associated with each other,\\nyet the text is not related to the ongoing visuals. Existing\\nmultimodal embedding models are susceptible to such noisy\\ndata, i.e., the model is likely to adjust itself to the noise in\\nthe data and thus yield sub-optimal results. This scenario\\nis very common in the case of self-supervised multimodal\\nlearning and even when learning from unlabeled instructional\\nvideos. Although in these instructio', 'Noise Estimation Using Density Estimation.pdf'), 1486: ('alities do not share the same semantic meaning. For\\nexample, a video-text pair that is associated with each other,\\nyet the text is not related to the ongoing visuals. Existing\\nmultimodal embedding models are susceptible to such noisy\\ndata, i.e., the model is likely to adjust itself to the noise in\\nthe data and thus yield sub-optimal results. This scenario\\nis very common in the case of self-supervised multimodal\\nlearning and even when learning from unlabeled instructional\\nvideos. Although in these instructional videos there is some\\ncorrelation between caption (speech transcription) and vision,\\nunfortunately often a person is talking about something that\\nis not present visually. For example, in the HowTo100M\\ndataset (Miech et al. 2019), the authors manually inspected\\n400randomly sampled clip-caption pairs and found that in\\nabout half there was not a single object or action mentioned\\nin the caption that was also visually present in the video\\nclip. To deal with noise, we suggest to utilize the inherent\\ncorrelation between the different modalities that is based\\non the Deﬁnition and Assumption below. See Fig. 1 for a\\nvisualization and a detailed explanation.\\nDeﬁnition 1. A correctly (wrongly) associated pair is a clip-\\ncaption pair (v;c)that share (do not share) the same seman-\\ntic meaning or concept, i.e., the caption cdescribes (does not\\ndescribe) the ongoing visuals v.\\nAssumption 1 (Mixture Model) .The distributions of the\\nvideos and captions can be represented using a general mix-\\nture model of Tcomponents in the corresponding modality.\\nDenoting by a;b2f1;:::;Tg, respectively, the concept to\\nwhich the video vand the caption cbelong, we can write\\nvja\\x18pv(vja)andcjb\\x18pc(cjb).\\nIf Assumption 1 holds, then correctly associated pairs\\nform dense clusters in both modalities that contain pairs that\\nare also associated with each other (see Fig. 1a). Thus, by\\ndeﬁning a multimodal similarity function (i.e., a similarity\\nmeasure between pairs), we can formulate the task of ﬁnding\\ncorrectly associated pairs simply as a multimodal ', 'Noise Estimation Using Density Estimation.pdf'), 1487: (' corresponding modality.\\nDenoting by a;b2f1;:::;Tg, respectively, the concept to\\nwhich the video vand the caption cbelong, we can write\\nvja\\x18pv(vja)andcjb\\x18pc(cjb).\\nIf Assumption 1 holds, then correctly associated pairs\\nform dense clusters in both modalities that contain pairs that\\nare also associated with each other (see Fig. 1a). Thus, by\\ndeﬁning a multimodal similarity function (i.e., a similarity\\nmeasure between pairs), we can formulate the task of ﬁnding\\ncorrectly associated pairs simply as a multimodal density\\nestimation task. In this formulation, pairs in dense areas will\\nbe more likely to be correctly associated , while pairs in\\nsparse areas will be more likely to be wrongly associated (see\\nFig. 1b).\\n3.2 Notation and Problem Formulation\\nLetf(vi;ci)2Rdv\\x02RdcgM\\ni=1denote the set of clip-caption\\npairs, where for each i, the video clip viis associated with\\nthe caption sentence ci, andMdenotes the size of the dataset.\\nLetpi2f0;1gdenote a binary indicator for whether the pair\\n(vi;ci)iscorrectly associated (pi= 1) orwrongly associated\\n(pi= 0). Letfv:Rdv!Rdandfc:Rdc!Rddenote the\\nembedding functions of the videos and the captions, respec-\\ntively, into a common representation space. The task of noise\\nrobust multimodal representation learning aims to map all of\\nthe data modalities to a single embedding space such that for\\nallvithat is correctly associated withci,fv(vi)\\x19fc(ci)in\\nthe sense of some similarity function.\\n3.3 Noise Estimation Using Multimodal Density\\nEstimation\\nFor the ease of notation, we will denote the pair as zi=\\n(vi;ci). Let us deﬁne a similarity function between pairs,\\nS:Rdv+dc\\x02Rdv+dc!R.\\nS(zi;zj),min\\x1as(vi;vj)\\x00\\x16\\x16v\\n\\x16\\x1bv;s(ci;cj)\\x00\\x16\\x16c\\n\\x16\\x1bc\\x1b\\n;(1)\\nwherescan be, for example, the cosine similarity function\\ns(x;y) =x|y\\nkxkkyk;\\x16\\x16v;\\x16\\x16cand\\x16\\x1bv;\\x16\\x1bcare the sample means\\nand standard deviations of each modality, i.e., the similarityvalues of each modality are normalized before taking the\\nminimum. Using (1), a pairziis close tozjonly ifviis close\\ntovjandciis close tocjas well.\\nWe denote by ^pithe estimated probability of ', 'Noise Estimation Using Density Estimation.pdf'), 1488: ('pair as zi=\\n(vi;ci). Let us deﬁne a similarity function between pairs,\\nS:Rdv+dc\\x02Rdv+dc!R.\\nS(zi;zj),min\\x1as(vi;vj)\\x00\\x16\\x16v\\n\\x16\\x1bv;s(ci;cj)\\x00\\x16\\x16c\\n\\x16\\x1bc\\x1b\\n;(1)\\nwherescan be, for example, the cosine similarity function\\ns(x;y) =x|y\\nkxkkyk;\\x16\\x16v;\\x16\\x16cand\\x16\\x1bv;\\x16\\x1bcare the sample means\\nand standard deviations of each modality, i.e., the similarityvalues of each modality are normalized before taking the\\nminimum. Using (1), a pairziis close tozjonly ifviis close\\ntovjandciis close tocjas well.\\nWe denote by ^pithe estimated probability of zibeing\\ncorrectly associated , and compute it using its local k-NN\\ndensity estimation normalized such that ^pi2[0;1]:\\n^pi,\\x16Si\\x00min(f\\x16SigM\\ni=1)\\nmax(f\\x16SigM\\ni=1)\\x00min(f\\x16SigM\\ni=1); (2)\\nwhere,\\n\\x16Si=1\\nKKX\\nk=1S(zi;zik);i2[M]; (3)\\nzikis thek-th nearest neighbor of ziandSis the similarity\\nfunction deﬁned in (1).\\n3.4 Soft Max Margin Ranking Loss\\nIntegrating our noise estimation component from above into a\\nmax margin ranking loss function (Wang et al. 2014; Schroff,\\nKalenichenko, and Philbin 2015) is straightforward. We\\nweight each pair ziwith its ﬁxed estimated probability ^pi\\nof being correctly associated . We call it Soft Max Margin\\nRanking:\\nLsoft\\x00rank =X\\ni2P\\x12\\n^piX\\nj2Nimaxf0;sij\\x00sii+\\x0eg+\\nmaxf0;sji\\x00sii+\\x0eg\\x13\\n;(4)\\nwhere,Pis the set of noisy associated (positive) pairs, Ni\\nis the set of negative pairs for clip-caption pair (vi;ci),^pi\\nis deﬁned in (2),sijis the similarity score between the em-\\nbedding of the clip-caption pair (fv(vi);fc(cj)), and\\x0eis the\\nmargin. The ﬁrst term in the equation above is for matching\\na video with a negative caption and the second term is for\\nmatching a caption with a negative video.\\nWe note that a different integration approach is to dis-\\ncard samples with ^pibelow a certain threshold. However,\\nfor real-data experiments we found the performance to be\\nsubstantially worse.\\n4 Theoretical Analysis\\nWe present a theoretical probabilistic error upper bound of\\nour noise estimation approach. For simplicity we assume the\\ndata is distributed under a Gaussian Mixture model.\\n4.1 Probabilistic Error Upper Bound\\nT', 'Noise Estimation Using Density Estimation.pdf'), 1489: ('a negative caption and the second term is for\\nmatching a caption with a negative video.\\nWe note that a different integration approach is to dis-\\ncard samples with ^pibelow a certain threshold. However,\\nfor real-data experiments we found the performance to be\\nsubstantially worse.\\n4 Theoretical Analysis\\nWe present a theoretical probabilistic error upper bound of\\nour noise estimation approach. For simplicity we assume the\\ndata is distributed under a Gaussian Mixture model.\\n4.1 Probabilistic Error Upper Bound\\nTheorem 1. LetZ= (X;Y )2R\\x02Rbe a random\\npair of scalars satisfying Assumption 1 for a Gaussian\\nmixture ofT > 1equi-probable concepts. Denoting by\\n(A;B)2f1;:::;Tg2the concepts to which the pair Zbe-\\nlongs,XjA=a\\x18N(\\x16a;\\x1b2\\na)andYjB=b\\x18N(\\x160\\nb;\\x1b02\\nb).\\nWe further assume that each component of the mixture is 6\\x1b-\\nseparated, i.e.,j\\x16i\\x00\\x16jj>6\\x1bmaxandj\\x160\\ni\\x00\\x160\\njj>6\\x1b0\\nmax\\nfor everyi6=j, where\\x1bmax,maxtf\\x1btgand\\x1b0\\nmax,\\nmaxtf\\x1b0\\ntg.\\n(a)Multimodal data visualization . Each initial monomodal embedding space contains\\nsomewhat dense clusters of ‘concepts’, where a ‘concept’ could be a speciﬁc object or action\\n(e.g., ‘cutting’, ‘knife’, ‘check’, ‘tire’, ‘oven’, etc.). It is likely that correctly associated\\n(Deﬁnition 1) pairs form dense clusters in both modalities that contain pairs that are also\\nassociated with each other and of the same ‘concept’ (GREEN, z1-z6,z9-z11). In contrast,\\nawrongly associated (Deﬁnition 1) pair may still belong to dense clusters in both modalities\\nbut those clusters are not likely to contain pairs that are associated with each other (RED, z7\\nandz8). Best viewed in color.\\n(b)Multimodal space deﬁned by (1). Each\\npoint above (fzig11\\ni=1) represents a single pair\\nfrom the left sub-ﬁgure. The distance between\\npoints that is visualized is computed based on\\n(1). Given Assumption 1, in the multimodal\\nspace above, correctly associated pairs are cor-\\nrelated with high density and vice-versa. Best\\nviewed in color.\\nFigure 1: Noise estimation using multimodal density estimation\\nLetPr(A=a6=B=b) =\\x11\\nT(T\\x001)andPr(A=B=\\na) =1\\x00\\x11\\nTfor e', 'Noise Estimation Using Density Estimation.pdf'), 1490: ('ated with each other (RED, z7\\nandz8). Best viewed in color.\\n(b)Multimodal space deﬁned by (1). Each\\npoint above (fzig11\\ni=1) represents a single pair\\nfrom the left sub-ﬁgure. The distance between\\npoints that is visualized is computed based on\\n(1). Given Assumption 1, in the multimodal\\nspace above, correctly associated pairs are cor-\\nrelated with high density and vice-versa. Best\\nviewed in color.\\nFigure 1: Noise estimation using multimodal density estimation\\nLetPr(A=a6=B=b) =\\x11\\nT(T\\x001)andPr(A=B=\\na) =1\\x00\\x11\\nTfor everya;b2f1;:::;Tg. The binary indicator\\nPdenoting whether the pair (X;Y )is correctly associated\\nconsequently has Pr(P= 1) =Pr(A=B) = 1\\x00\\x11, where\\n\\x11is the noise ratio of the dataset.\\nLetfzi= (xi;yi)gM\\ni=1be a ﬁnite sample of pairs drawn\\nindependently from the described model, and let \\x16Sibe the\\naverage similarity between ziand itsKnearest neighbors\\nas deﬁned in (3), withS(zi;zj),s(xi;xj)+s(yi;yj)\\n2, and\\ns(x;x0),\\x00jx\\x00x0j. Then, the following bounds hold for\\nevery\\x1candt>0,\\nP(\\x16Si\\x15\\x1cjpi= 0)\\x14M\\x16Sijpi=0(t)\\net\\x1c; (5)\\nP(\\x16Si\\x14\\x1cjpi= 1)\\x14M\\x16Sijpi=1(\\x00t)\\ne\\x00t\\x1c; (6)\\nwhere,M\\x16Sijpi(t)is the moment generating function of \\x16Sijpi\\ndeﬁned in Appendix A, Eq. (8).\\nThe proof is provided in Appendix A. It is important to\\nremark that for the simplicity of analysis we assumed the\\npairs to be formed of scalars. While, from the ﬁrst glance, this\\nassumption might severely limit the possible conﬁgurations\\nof the concepts in each of the modalities, in our analysis we\\nmade no assumptions whatsoever on the way the concepts are\\ncollocated in space, except the 6\\x1b-separation that can hold\\nin any number of dimensions. The validity of the presented\\nanalysis in the multidimensional case is corroborated by the\\ntoy dataset example in Section 6.1.4.2 Numerical Simulations and Analysis\\nIn this section, we present numerical simulations of the prob-\\nabilistic error bounds in (5)and(6). Our goal is to gain\\ninsight into: (a) why the method works; (b) the effect of\\nthe design choice ( K) and dataset properties ( \\x11;M;T ) on\\nthe performance of the model; and (c) analyze po', 'Noise Estimation Using Density Estimation.pdf'), 1491: (' the 6\\x1b-separation that can hold\\nin any number of dimensions. The validity of the presented\\nanalysis in the multidimensional case is corroborated by the\\ntoy dataset example in Section 6.1.4.2 Numerical Simulations and Analysis\\nIn this section, we present numerical simulations of the prob-\\nabilistic error bounds in (5)and(6). Our goal is to gain\\ninsight into: (a) why the method works; (b) the effect of\\nthe design choice ( K) and dataset properties ( \\x11;M;T ) on\\nthe performance of the model; and (c) analyze possible\\nfailure cases. More speciﬁcally, we: (a) set \\x1c=\\x1c\\x03such\\nthatP(\\x16Si\\x15\\x1c\\x03jpi= 0) =P(\\x16Si\\x14\\x1c\\x03jpi= 1) , i.e.,\\n\\x1c\\x03=q\\nM\\x16Sijpi=0(t)\\x01M \\x16Sijpi=1(\\x00t); (b) sweep a single\\nparameter at a time, while the rest are ﬁxed; and (c) optimize\\nfortover[1;100].\\nDiscussion. In Fig. 2a we study the effect of K. As ex-\\npected, increasing Kdecreases the error bound initially and\\nfrom a certain value ( ,K0), the error bound increases. Not\\nsurprisingly, K0\\x19M\\nT\\x01(1\\x00\\x11), which is the average number\\nof correctly associated pairs per concept. Throughout Figures\\n2a, 2b, 2c, 2d we see the error bound is inﬂuenced greatly\\nby this equality, i.e., when K > K 0, the model performs\\nwell and when K\\x14K0, it starts to fail. Speciﬁcally, in Fig.\\n2c we show that the error bound goes to zero as the size\\nof the dataset ( M) increases (another point of view is that\\nK0is increased). For this reason we mark the point where\\nKT=M(1\\x00\\x11)by a red dashed line in Fig. 2. It is clear that\\nfor real-world data, concepts are usually not equi-probable\\nand thus assigning a global value for Kis sub-optimal. How-\\never, this ﬁnding allows us to better understand such failure\\ncases and thus choose a reasonable Kvalue. An additional\\ninstance where the method fails, gives us insight into why\\nusually the method succeeds. The method will fail for a small\\nnumber of concepts ( T) regardless of K0, because for a small\\nnumber of concepts there is a higher chance that two or more\\nFigure 2: Numerical simulations of our probabilistic error upper bound . From left to right: sweep over K;\\x11;M a', 'Noise Estimation Using Density Estimation.pdf'), 1492: ('lobal value for Kis sub-optimal. How-\\never, this ﬁnding allows us to better understand such failure\\ncases and thus choose a reasonable Kvalue. An additional\\ninstance where the method fails, gives us insight into why\\nusually the method succeeds. The method will fail for a small\\nnumber of concepts ( T) regardless of K0, because for a small\\nnumber of concepts there is a higher chance that two or more\\nFigure 2: Numerical simulations of our probabilistic error upper bound . From left to right: sweep over K;\\x11;M andT. We\\nmark with a red dashed vertical line where K=M\\nT\\x01(1\\x00\\x11)holds.\\nwrongly associated pairs belong to the same pair of concepts\\nin both modalities. Fortunately, in real-world data Tis almost\\nalways large, and additionally as Tincreases, this problem is\\nalleviated by a factor of O(T2)(see Appendix A, Eq. (10)).\\nA simulation of this case is presented in Appendix D.\\n5 Experimental Settings\\n5.1 Implementation Details\\nModel . For a fair comparison to the baseline model HTM\\n(Miech et al. 2019), we use the same class of non-linear em-\\nbedding functions: f(v) = (Wv\\n1v+bv\\n1)\\x0e\\x1b(Wv\\n2(Wv\\n1v+\\nbv\\n1) +bv\\n2),g(c) = (Wc\\n1c+bc\\n1)\\x0e\\x1b(Wc\\n2(Wc\\n1c+bc\\n1) +bc\\n2),\\nwhereWv\\n12Rd\\x02dv,Wc\\n12Rd\\x02dc,Wv\\n2;Wc\\n22Rd\\x02d,\\nbv\\n1;bv\\n2;bc\\n1;bc\\n22Rdare the learnable parameters, \\x1bis an\\nelement-wise sigmoid activation and \\x0eis the element-wise\\nmultiplication. We use dv= 4096 ,dc= 300 , andd= 6144 .\\nTraining dataset. We train our model using the\\nHowTo100M (Miech et al. 2019) narrated video dataset that\\nconsists of more than 1.2M videos accompanied with auto-\\nmatically generated speech transcription. Similarly to (Miech\\net al. 2019), we use the provided transcription to create pairs\\nof clip-caption deﬁned by each caption time stamp, where\\neach video clip shorter than 5 seconds is extended symmetri-\\ncally in time so that the duration is at least 5 seconds. Note\\nthat we only use 1.16M videos since some of the videos are\\nno longer available for download.\\nInput caption features. For the word representations, we\\nuse the standard GoogleNews pre-trained word2vec embe', 'Noise Estimation Using Density Estimation.pdf'), 1493: ('-\\nmatically generated speech transcription. Similarly to (Miech\\net al. 2019), we use the provided transcription to create pairs\\nof clip-caption deﬁned by each caption time stamp, where\\neach video clip shorter than 5 seconds is extended symmetri-\\ncally in time so that the duration is at least 5 seconds. Note\\nthat we only use 1.16M videos since some of the videos are\\nno longer available for download.\\nInput caption features. For the word representations, we\\nuse the standard GoogleNews pre-trained word2vec embed-\\nding model (Mikolov et al. 2013). For the input sentence\\nrepresentations used in Section 3.3 we simply average word\\nrepresentation over each sentence.\\nInput visual features. We extract 2D features using Im-\\nageNet pre-trained Resnet-152 (He et al. 2016) at a rate of\\n1 frame per second. We extract 3D features using Kinetics\\n(Carreira and Zisserman 2017) pre-trained ResNeXt-101 16-\\nframes (Hara, Kataoka, and Satoh 2018) at a rate of 24 frames\\nper second. After temporal max pooling we concatenate 2D\\nand 3D features to form a single feature vector per video clip.\\nLoss & Optimization. We train our model using the Soft\\nMax Margin loss function described in Section 3.4. We use\\nthe ADAM (Kingma and Ba 2015) optimizer with a ﬁxed\\nlearning rate of 10\\x003.\\nTime complexity. Using FAISS (Johnson, Douze, and\\nJ´egou 2019), computation of the Multimodal Density Esti-\\nmation described in Section 3.3 is done in less than 15 hoursover 10 CPUs. Training the model on the large HowTo100M\\ndataset is done on a single V100 GPU and takes less than 24\\nhours.\\nAdditional implementation details are included in Ap-\\npendix G.\\n5.2 Downstream Tasks\\nVideo Visual Question Answering (VQA). The Video\\nVQA task comprises answering questions about videos pre-\\nsented in natural language (Antol et al. 2015). Essentially, an\\ninstance of VQA includes an input video and a free-form tex-\\ntual query regarding the content in the video, and an expected\\ntextual answer. To accommodate this task we ﬁne-tune our\\nlearned multimodal representations and evaluate our', 'Noise Estimation Using Density Estimation.pdf'), 1494: ('akes less than 24\\nhours.\\nAdditional implementation details are included in Ap-\\npendix G.\\n5.2 Downstream Tasks\\nVideo Visual Question Answering (VQA). The Video\\nVQA task comprises answering questions about videos pre-\\nsented in natural language (Antol et al. 2015). Essentially, an\\ninstance of VQA includes an input video and a free-form tex-\\ntual query regarding the content in the video, and an expected\\ntextual answer. To accommodate this task we ﬁne-tune our\\nlearned multimodal representations and evaluate our model\\non two datasets: MSRVTT-QA and MSVD-QA (Xu et al.\\n2017). These datasets are based on existing video description\\ndatasets. See Table 5a in Appendix G for detailed statistics\\nof each dataset.\\nMost VQA models use a video and question as input,\\nand the answer is presented as the output of an LSTM unit\\n(Hochreiter and Schmidhuber 1997) or a softmax layer over\\na set of predetermined answers. However, these types of ar-\\nchitectures do not fully utilize the information which exists\\nin coordinated representations, i.e., the representation of the\\ncorrect answer might likely be closely embedded to the vi-\\nsual representation, given the question. To better utilize our\\nlearned multimodal representations speciﬁcally for the VQA\\ntask, we use a similar architecture to (Hu, Chao, and Sha\\n2018), but for video. We learn two more sets of embeddings\\non top of the pre-trained embeddings that were learned with\\nthe HowTo100M dataset: a question+video embedding, i.e.,\\nwe embed a concatenation of the question and video to a\\nsingle feature vector; and an answer embedding. We train the\\nmodel with a max margin ranking loss function to embed an\\nanswer close to its question+video. Inference is performed\\nsimply with a nearest neighbor search over the set of predeter-\\nmined answers in the joint video+question and answer space.\\nThis model is very simple compared to most VQA models,\\nyet as we show in Table 2 it is very powerful when built on\\neffective self-supervised pre-trained joint embeddings.\\nText-To-Video Retrieval. Text-To-Video Ret', 'Noise Estimation Using Density Estimation.pdf'), 1495: (\"gle feature vector; and an answer embedding. We train the\\nmodel with a max margin ranking loss function to embed an\\nanswer close to its question+video. Inference is performed\\nsimply with a nearest neighbor search over the set of predeter-\\nmined answers in the joint video+question and answer space.\\nThis model is very simple compared to most VQA models,\\nyet as we show in Table 2 it is very powerful when built on\\neffective self-supervised pre-trained joint embeddings.\\nText-To-Video Retrieval. Text-To-Video Retrieval in-\\ncludes retrieval of video clips based on textual description\\n(Liu et al. 2019; Mithun et al. 2018; Song and Soleymani\\n2019). With a learned joint representation space, retrieval\\nis performed with a nearest neighbor search over the joint\\nembedding space. To evaluate our model we use three differ-\\n40\\n 20\\n 0 20 4040\\n20\\n02040Input Caption T-SNE ({ci}M\\ni=1)\\npi=1\\npi=0(a) Caption T-SNE\\n0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\\npi\\n0.00.10.20.30.40.50.60.70.80.91.0CDFCumulative Distribution Function of pi\\npi | pi=1\\npi | pi=0 (Reversed)\\n (b) CDF of ^ p(Eq. (2))\\n40\\n 30\\n 20\\n 10\\n 0 10 20 30 4040\\n20\\n02040Input Video T-SNE ({vi}M\\ni=1)\\npi=1\\npi=0 (c) Video T-SNE\\nFigure 3: Toy dataset Visualizations. (a, c): T-SNE of input embeddings. As we can see, separating between samples with\\npi= 1and samples with pi= 0is non-trivial. (b): Cumulative Distribution Function of ^ piof toy dataset. The green solid line is\\nthe CDF of ^pijpi= 1, while the red dashed line is the inverse CDF of ^pijpi= 0. Assuming a binary prediction is made based on\\na hard threshold, it is possible to extract the precision and recall for each threshold from the ﬁgure above. For example, for the\\nthreshold 0:48, both precision and recall are '0:9. Best viewed in color.\\nent datasets: MSRVTT, MSVD and LSMDC (Xu et al. 2016;\\nChen and Dolan 2011; Rohrbach et al. 2015). We use the stan-\\ndard evaluation metrics: recall at K(R@K) forK= 1;5;10\\nand median recall (MR). See Table 5b in Appendix G for\\ndetailed statistics of each dataset.\\n6 Experiments and Analysis\\n\", 'Noise Estimation Using Density Estimation.pdf'), 1496: (\" is made based on\\na hard threshold, it is possible to extract the precision and recall for each threshold from the ﬁgure above. For example, for the\\nthreshold 0:48, both precision and recall are '0:9. Best viewed in color.\\nent datasets: MSRVTT, MSVD and LSMDC (Xu et al. 2016;\\nChen and Dolan 2011; Rohrbach et al. 2015). We use the stan-\\ndard evaluation metrics: recall at K(R@K) forK= 1;5;10\\nand median recall (MR). See Table 5b in Appendix G for\\ndetailed statistics of each dataset.\\n6 Experiments and Analysis\\nA toy dataset illustrative results are presented in Section 6.1.\\nComparison to ablative baselines and state-of-the-art models\\nis presented in Section 6.2. A design choice analysis is pre-\\nsented in Appendix F. Qualitative examples are presented in\\nAppendix C.\\n6.1 Multidimensional Toy Dataset\\nIn this section, we demonstrate the effectiveness of our\\nmethod visually using a toy (synthesized) dataset of mix-\\nture of Gaussians of Tcomponents in each modality,\\nfN(\\x16c\\nt;\\x06c\\nt)gT\\nt=1andfN(\\x16v\\nt;\\x06v\\nt)gT\\nk=1for caption and\\nvideo, respectively. Correctly associated pairs are repre-\\nsented byvi\\x18 N (\\x16v\\nt;\\x06v\\nt);ci\\x18 N (\\x16c\\nt;\\x06c\\nt), such that\\nt2[T];i2[M].Wrongly associated pairs are repre-\\nsented byvi\\x18N (\\x16v\\nm;\\x06v\\nm);ci\\x18N (\\x16c\\nn;\\x06c\\nn), such that\\nm6=n;fm;ng2[T];i2[M].\\x112[0;1]is the noise ratio,\\nsuch that a wrongly associated pair is sampled with prob-\\nability\\x11, and a correctly associated pair is sampled with\\nprobability 1\\x00\\x11.\\nIn our experiment, vi2Rdv;ci2Rdc,dv= 128;dc=\\n128;\\x16c\\nt2Rdc;\\x16v\\nt2Rdv;8t2[T]are sampled from a uni-\\nform multivariate distribution Udc(0;1);Udv(0;1), respec-\\ntively for caption and video; \\x06c\\nt2Rdc\\x02dc;\\x06v\\nt2Rdv\\x02dv\\nare diagonal matrices where the diagonals are sampled from\\na multivariate uniform distribution, Udc(0;0:3);Udv(0;0:3),\\nrespectively for caption and video; \\x11= 0:5;M= 1250;T=\\n50;k= 4(k-NN parameter).\\nIn Figures 3a and 3c we visualize T-SNE graphs for cap-\\ntion and video embedding spaces, respectively. In Fig. 3b we\\nvisualize the empirical cumulative distribution function of ^pi\\n(2), the estimated probability of \", 'Noise Estimation Using Density Estimation.pdf'), 1497: ('iate distribution Udc(0;1);Udv(0;1), respec-\\ntively for caption and video; \\x06c\\nt2Rdc\\x02dc;\\x06v\\nt2Rdv\\x02dv\\nare diagonal matrices where the diagonals are sampled from\\na multivariate uniform distribution, Udc(0;0:3);Udv(0;0:3),\\nrespectively for caption and video; \\x11= 0:5;M= 1250;T=\\n50;k= 4(k-NN parameter).\\nIn Figures 3a and 3c we visualize T-SNE graphs for cap-\\ntion and video embedding spaces, respectively. In Fig. 3b we\\nvisualize the empirical cumulative distribution function of ^pi\\n(2), the estimated probability of being correctly associated .\\nAdditionally, in Appendix B Fig. 4 we empirically reproducethe theoretical graphs in Fig. 2 and Fig. 8 using the multidi-\\nmensional toy dataset. These results corroborate the validity\\nof the analysis presented in Thm. 1 in the multidimensional\\ncase.\\n6.2 Ablative Baselines and SOTA Models\\nWe compare our proposed model against two ablative base-\\nlines and multiple task-speciﬁc state-of-the-art (SOTA) mod-\\nels:\\nHTM-PT (Miech et al. 2019) . The model (architecture\\nand loss function) used in (Miech et al. 2019). This baseline\\nis pre-trained (PT) on the HowTo100M dataset. It is the exact\\narchitecture described in Section 5.1 for our model. The\\nonly differentiating element is the loss function. (Miech et al.\\n2019) use the max margin ranking loss function, while we\\nuse our proposed Soft Max Margin ranking loss function.\\nSince the model is also trained identically to our own model\\nit is clear that any gain in performance over this baseline is\\ndue to our novel noise estimation based density estimation\\ncomponent.\\nHTM-no-PT (Miech et al. 2019) . The same model from\\nabove, but without pre-training (no-PT) on the HowTo100M\\ndataset. The (under) performance of this baseline on down-\\nstream tasks demonstrates the potential gain of utilizing self-\\nsupervised speech-visual correspondence training.\\nTask speciﬁc state-of-the-art models . After ﬁne-tuning\\nfor downstream tasks we compare our proposed model to\\nstate-of-the-art models for each task and each dataset. (Gao\\net al. 2018; Xu et al. 2017; Fan et ', 'Noise Estimation Using Density Estimation.pdf'), 1498: (' estimation\\ncomponent.\\nHTM-no-PT (Miech et al. 2019) . The same model from\\nabove, but without pre-training (no-PT) on the HowTo100M\\ndataset. The (under) performance of this baseline on down-\\nstream tasks demonstrates the potential gain of utilizing self-\\nsupervised speech-visual correspondence training.\\nTask speciﬁc state-of-the-art models . After ﬁne-tuning\\nfor downstream tasks we compare our proposed model to\\nstate-of-the-art models for each task and each dataset. (Gao\\net al. 2018; Xu et al. 2017; Fan et al. 2019; Jang et al. 2017)\\nfor VQA, and (Liu et al. 2019; Mithun et al. 2018; Yu, Kim,\\nand Kim 2018; Miech, Laptev, and Sivic 2018; Miech et al.\\n2019, 2020) for Text-To-Video Retrieval.\\nTables 1 and 2 show the result for Text-To-Video Retrieval\\nand Video Question Answering, respectively. Table 3 in Ap-\\npendix E shows the results for Zero-Shot Text-To-Video Re-\\ntrieval under ‘unfair’ settings. We summarize key insights\\nbelow:\\n–Our model consistently outperforms the baselines (HTM-\\nPT, HTM-no-PT (Miech et al. 2019)) in both Visual Ques-\\nMSRVTT LSMDC MSVD\\nMethod R@1 R@5 R@10 MR R@1 R@5 R@10 MR R@1 R@5 R@10 MR\\nZero-Shot\\nRandom 0.1 0.5 1.0 500.0 0.1 0.5 1.0 500.0 0.15 0.75 1.49 335\\nMIL-NCEy(Miech et al. 2020) 9.9 24.0 32.4 29.5 – – – – – – – –\\nHTM-PT\\x03(Miech et al. 2019) 7.5 21.2 29.6 38.0 4.0 9.8 14.0 137.0 12.86 33.06 45.83 13.0\\nOurs 8.0 21.3 29.3 33.0 4.2 11.6 17.1 119.0 13.66 35.7 47.74 12.0\\nFine-Tuned\\nCEz(Liu et al. 2019) 18.2 46.0 60.7 7.0 11.2 26.9 34.8 25.0 19.8 49.0 63.8 6.0\\nJEMC (Mithun et al. 2018) 7.0 20.9 29.7 38.0 – – – – 20.3 47.8 61.1 6.0\\nJSFusion (Yu, Kim, and Kim 2018) 10.2 31.2 43.2 13.0 9.1 21.2 34.1 36 – – – –\\nMoEE (Miech, Laptev, and Sivic 2018) 14.2 39.2 53.8 9 10.1 25.6 34.6 27 – – – –\\nHTM-no-PT (Miech et al. 2019) 12.4 36.0 52.0 10.0 5.8 18.8 28.4 45.0 13.0 37.43 52.41 10.0\\nHTM-PT\\x03(Miech et al. 2019) 14.9 40.2 52.8 9.0 7.1 19.6 27.9 40.0 15.52 40.93 55.7 8.0\\nOurs 17.4 41.6 53.6 8.0 6.4 19.8 28.4 39.0 20.3 48.97 63.26 6.0\\nTable 1: Text-To-Video retrieval. Zero-Shot: training was done only wit', 'Noise Estimation Using Density Estimation.pdf'), 1499: ('20.9 29.7 38.0 – – – – 20.3 47.8 61.1 6.0\\nJSFusion (Yu, Kim, and Kim 2018) 10.2 31.2 43.2 13.0 9.1 21.2 34.1 36 – – – –\\nMoEE (Miech, Laptev, and Sivic 2018) 14.2 39.2 53.8 9 10.1 25.6 34.6 27 – – – –\\nHTM-no-PT (Miech et al. 2019) 12.4 36.0 52.0 10.0 5.8 18.8 28.4 45.0 13.0 37.43 52.41 10.0\\nHTM-PT\\x03(Miech et al. 2019) 14.9 40.2 52.8 9.0 7.1 19.6 27.9 40.0 15.52 40.93 55.7 8.0\\nOurs 17.4 41.6 53.6 8.0 6.4 19.8 28.4 39.0 20.3 48.97 63.26 6.0\\nTable 1: Text-To-Video retrieval. Zero-Shot: training was done only with HowTo100M dataset. Fine-Tuned: model was ﬁne-tuned\\nwith the relevant benchmark dataset. For MR the lower the better. *: results for MSRVTT and LSMDC are from (Miech et al.\\n2019), while results for MSVD have been reproduced.y: MIL-NCE (Miech et al. 2020) use additional clip-caption pairs.z: CE\\n(Liu et al. 2019) use extra labeled data in the form of pre-trained semantic embeddings which include ‘general’ features such as\\nmotion, appearance, scene features and OCR.\\nMSRVTT-QA [%] MSVD-QA [%]\\nST-VQA (2017) 30.09 31.3\\nCo-Mem (2018) 32.0 31.7\\nAMU (2017) 32.5 32.0\\nHMEMA (2019) 33.0 33.7\\nHTM-no-PT (2019) 27.05 33.8\\nHTM-PT (2019) 34.38 34.83\\nOurs 35.06 35.13\\nTable 2: Video Question Answering. Results of ST-VQA and\\nCo-Mem taken from (Fan et al. 2019)\\ntion Answering and Text-To-Video Retrieval on ﬁve differ-\\nent datsets.\\n–We set a new state-of-the-art performance for two Visual\\nQuestion Answering datasets: MSRVTT-QA and MSVD-\\nQA.\\n–We set a new state-of-the-art performance for Zero-Shot\\nText-To-Video Retrieval on two datasets: LSMDC and\\nMSVD. For MSRVTT, we hypothesize that MIL-NCE\\n(Miech et al. 2020) performs better due to two reasons:\\ni) they train end-to-end, unlike our baseline model, which\\noperates on pre-proccessed embeddings; and ii) they utilize\\nadditional clip-caption pairs by associating a clip with its\\nadjacent (in time) captions. In fact, when those additional\\npairs are not used our model outperforms theirs.\\n–We set a new state-of-the-art performance for (ﬁne-tuned)\\nText-To-Video Retrieval on two datasets: MSR', 'Noise Estimation Using Density Estimation.pdf'), 1500: ('tasets: LSMDC and\\nMSVD. For MSRVTT, we hypothesize that MIL-NCE\\n(Miech et al. 2020) performs better due to two reasons:\\ni) they train end-to-end, unlike our baseline model, which\\noperates on pre-proccessed embeddings; and ii) they utilize\\nadditional clip-caption pairs by associating a clip with its\\nadjacent (in time) captions. In fact, when those additional\\npairs are not used our model outperforms theirs.\\n–We set a new state-of-the-art performance for (ﬁne-tuned)\\nText-To-Video Retrieval on two datasets: MSRVTT and\\nMSVD.\\n–We demonstrate that our model outperforms or is at least on\\npar with the performance of HTM-PT (Miech et al. 2019)even given a setting which is a clear disadvantage such as\\ntraining it without 3D features (i.e., only 2D). See Table 3\\nin Appendix E. This shows:\\n(i)The power of our noise estimation method and its poten-\\ntial.\\n(ii)Integrating our multimodal density estimation compo-\\nnent allows saving time and/or computation power by\\ntraining and running inference with only 2D features,\\nwithout (or with minor) performance degradation.\\n7 Summary\\nIn this work, we showed that the problem of noise estimation\\nin multimodal data can be effectively reduced to a multi-\\nmodal density estimation task. Based on this efﬁcient noise\\nestimation we proposed a novel building block for noise\\nrobust multimodal representation learning that can be inte-\\ngrated into many multimodal learning models and improve\\ntheir performance instantly. We demonstrated how to inte-\\ngrate our building block into the max margin ranking loss\\nfunction (Soft Max Margin) and it can similarly be inte-\\ngrated into various architectures and losses. We trained Soft\\nMax Margin on the self-supervised proxy task of speech-\\nvisual correspondence that is known to be highly noisy. We\\nfurther evaluated Soft Max Margin on two different down-\\nstream tasks: Visual Question Answering and Text-to-Video\\nRetrieval; and achieved comparable state-of-the-art perfor-\\nmance on ﬁve different datasets. For supporting the empirical\\nresults and analyzing failure cases', 'Noise Estimation Using Density Estimation.pdf'), 1501: (' loss\\nfunction (Soft Max Margin) and it can similarly be inte-\\ngrated into various architectures and losses. We trained Soft\\nMax Margin on the self-supervised proxy task of speech-\\nvisual correspondence that is known to be highly noisy. We\\nfurther evaluated Soft Max Margin on two different down-\\nstream tasks: Visual Question Answering and Text-to-Video\\nRetrieval; and achieved comparable state-of-the-art perfor-\\nmance on ﬁve different datasets. For supporting the empirical\\nresults and analyzing failure cases, we provided a theoretical\\nprobabilistic error bound. These results emphasize the impor-\\ntance of self-supervised multimodal representation learning\\nfor advancing the state of the art in challenging multimodal\\nartiﬁcial intelligence tasks.\\nReferences\\nAmrani, E.; Ben-Ari, R.; Hakim, T.; and Bronstein, A. 2019. Learn-\\ning to Detect and Retrieve Objects From Unlabeled Videos. In 2019\\nIEEE/CVF International Conference on Computer Vision Workshop\\n(ICCVW) , 3713–3717. IEEE.\\nAntol, S.; Agrawal, A.; Lu, J.; Mitchell, M.; Batra, D.; Lawrence Zit-\\nnick, C.; and Parikh, D. 2015. Vqa: Visual question answering. In\\nProceedings of the IEEE international conference on computer\\nvision , 2425–2433.\\nArandjelovic, R.; and Zisserman, A. 2017. Look, listen and learn.\\nInProceedings of the IEEE International Conference on Computer\\nVision , 609–617.\\nCarreira, J.; and Zisserman, A. 2017. Quo vadis, action recognition?\\na new model and the kinetics dataset. In proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition , 6299–\\n6308.\\nChen, D. L.; and Dolan, W. B. 2011. Collecting highly parallel\\ndata for paraphrase evaluation. In Proceedings of the 49th Annual\\nMeeting of the Association for Computational Linguistics: Human\\nLanguage Technologies-Volume 1 , 190–200. Association for Com-\\nputational Linguistics.\\nFan, C.; Zhang, X.; Zhang, S.; Wang, W.; Zhang, C.; and Huang,\\nH. 2019. Heterogeneous memory enhanced multimodal attention\\nmodel for video question answering. In Proceedings of the IEEE\\nConference on Computer Vision', 'Noise Estimation Using Density Estimation.pdf'), 1502: ('on , 6299–\\n6308.\\nChen, D. L.; and Dolan, W. B. 2011. Collecting highly parallel\\ndata for paraphrase evaluation. In Proceedings of the 49th Annual\\nMeeting of the Association for Computational Linguistics: Human\\nLanguage Technologies-Volume 1 , 190–200. Association for Com-\\nputational Linguistics.\\nFan, C.; Zhang, X.; Zhang, S.; Wang, W.; Zhang, C.; and Huang,\\nH. 2019. Heterogeneous memory enhanced multimodal attention\\nmodel for video question answering. In Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition , 1999–\\n2007.\\nFrome, A.; Corrado, G. S.; Shlens, J.; Bengio, S.; Dean, J.; Ranzato,\\nM.; and Mikolov, T. 2013. Devise: A deep visual-semantic embed-\\nding model. In Advances in neural information processing systems ,\\n2121–2129.\\nGao, J.; Ge, R.; Chen, K.; and Nevatia, R. 2018. Motion-appearance\\nco-memory networks for video question answering. In Proceedings\\nof the IEEE Conference on Computer Vision and Pattern Recogni-\\ntion, 6576–6585.\\nGhosh, A.; Kumar, H.; and Sastry, P. 2017. Robust loss functions\\nunder label noise for deep neural networks. In Thirty-First AAAI\\nConference on Artiﬁcial Intelligence .\\nGoldberger, J.; and Ben-Reuven, E. 2017. Training deep neural-\\nnetworks using a noise adaptation layer. In ICLR .\\nHara, K.; Kataoka, H.; and Satoh, Y . 2018. Can spatiotemporal 3d\\ncnns retrace the history of 2d cnns and imagenet? In Proceedings of\\nthe IEEE conference on Computer Vision and Pattern Recognition ,\\n6546–6555.\\nHe, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning\\nfor image recognition. In Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition , 770–778.\\nHochreiter, S.; and Schmidhuber, J. 1997. Long short-term memory.\\nNeural computation 9(8): 1735–1780.\\nHu, H.; Chao, W.-L.; and Sha, F. 2018. Learning answer embed-\\ndings for visual question answering. In Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition , 5428–\\n5436.\\nJang, Y .; Song, Y .; Yu, Y .; Kim, Y .; and Kim, G. 2017. Tgif-qa:\\nToward spatio-temporal reasoning ', 'Noise Estimation Using Density Estimation.pdf'), 1503: ('for image recognition. In Proceedings of the IEEE conference on\\ncomputer vision and pattern recognition , 770–778.\\nHochreiter, S.; and Schmidhuber, J. 1997. Long short-term memory.\\nNeural computation 9(8): 1735–1780.\\nHu, H.; Chao, W.-L.; and Sha, F. 2018. Learning answer embed-\\ndings for visual question answering. In Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition , 5428–\\n5436.\\nJang, Y .; Song, Y .; Yu, Y .; Kim, Y .; and Kim, G. 2017. Tgif-qa:\\nToward spatio-temporal reasoning in visual question answering.\\nInProceedings of the IEEE Conference on Computer Vision and\\nPattern Recognition , 2758–2766.\\nJiang, L.; Zhou, Z.; Leung, T.; Li, L.; and Fei-Fei, L. 2018. Mentor-\\nNet: Learning Data-Driven Curriculum for Very Deep Neural Net-\\nworks on Corrupted Labels. In Proceedings of the 35th InternationalConference on Machine Learning, ICML 2018, Stockholmsm ¨assan,\\nStockholm, Sweden, July 10-15, 2018 , volume 80 of Proceedings of\\nMachine Learning Research , 2309–2318. PMLR.\\nJohnson, J.; Douze, M.; and J ´egou, H. 2019. Billion-scale similarity\\nsearch with GPUs. IEEE Transactions on Big Data .\\nKingma, D. P.; and Ba, J. 2015. Adam: A method for stochastic\\noptimization. In ICLR 2015 .\\nKoller, D.; and Friedman, N. 2009. Probabilistic graphical models:\\nprinciples and techniques . MIT press.\\nKorbar, B.; Tran, D.; and Torresani, L. 2018. Cooperative learning\\nof audio and video models from self-supervised synchronization. In\\nAdvances in Neural Information Processing Systems , 7763–7774.\\nLi, J.; Wong, Y .; Zhao, Q.; and Kankanhalli, M. S. 2019. Learning\\nto learn from noisy labeled data. In Proceedings of the IEEE Con-\\nference on Computer Vision and Pattern Recognition , 5051–5059.\\nLi, Y .; Yang, J.; Song, Y .; Cao, L.; Luo, J.; and Li, L.-J. 2017.\\nLearning from noisy labels with distillation. In Proceedings of the\\nIEEE International Conference on Computer Vision , 1910–1918.\\nLiu, Y .; Albanie, S.; Nagrani, A.; and Zisserman, A. 2019. Use\\nWhat You Have: Video Retrieval Using Representations From Col-\\nla', 'Noise Estimation Using Density Estimation.pdf'), 1504: (', Y .; Zhao, Q.; and Kankanhalli, M. S. 2019. Learning\\nto learn from noisy labeled data. In Proceedings of the IEEE Con-\\nference on Computer Vision and Pattern Recognition , 5051–5059.\\nLi, Y .; Yang, J.; Song, Y .; Cao, L.; Luo, J.; and Li, L.-J. 2017.\\nLearning from noisy labels with distillation. In Proceedings of the\\nIEEE International Conference on Computer Vision , 1910–1918.\\nLiu, Y .; Albanie, S.; Nagrani, A.; and Zisserman, A. 2019. Use\\nWhat You Have: Video Retrieval Using Representations From Col-\\nlaborative Experts. In British Machine Vision Conference .\\nMao, J.; Xu, W.; Yang, Y .; Wang, J.; Huang, Z.; and Yuille, A. 2014.\\nDeep captioning with multimodal recurrent neural networks (m-rnn).\\narXiv preprint arXiv:1412.6632 .\\nMcLachlan, G. J.; and Krishnan, T. 2007. The EM algorithm and\\nextensions , volume 382. John Wiley & Sons.\\nMiech, A.; Alayrac, J.-B.; Smaira, L.; Laptev, I.; Sivic, J.; and Zis-\\nserman, A. 2020. End-to-end learning of visual representations from\\nuncurated instructional videos. In Proceedings of the IEEE/CVF\\nConference on Computer Vision and Pattern Recognition , 9879–\\n9889.\\nMiech, A.; Laptev, I.; and Sivic, J. 2018. Learning a text-video\\nembedding from incomplete and heterogeneous data. arXiv preprint\\narXiv:1804.02516 .\\nMiech, A.; Zhukov, D.; Alayrac, J.-B.; Tapaswi, M.; Laptev, I.; and\\nSivic, J. 2019. Howto100M: Learning a text-video embedding by\\nwatching hundred million narrated video clips. In Proceedings of the\\nIEEE International Conference on Computer Vision , 2630–2640.\\nMikolov, T.; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J.\\n2013. Distributed representations of words and phrases and their\\ncompositionality. In Advances in neural information processing\\nsystems , 3111–3119.\\nMisra, I.; Zitnick, C. L.; and Hebert, M. 2016. Shufﬂe and learn: un-\\nsupervised learning using temporal order veriﬁcation. In European\\nConference on Computer Vision , 527–544. Springer.\\nMithun, N. C.; Li, J.; Metze, F.; and Roy-Chowdhury, A. K. 2018.\\nLearning joint embedding with multimodal cues for cross', 'Noise Estimation Using Density Estimation.pdf'), 1505: ('; Sutskever, I.; Chen, K.; Corrado, G. S.; and Dean, J.\\n2013. Distributed representations of words and phrases and their\\ncompositionality. In Advances in neural information processing\\nsystems , 3111–3119.\\nMisra, I.; Zitnick, C. L.; and Hebert, M. 2016. Shufﬂe and learn: un-\\nsupervised learning using temporal order veriﬁcation. In European\\nConference on Computer Vision , 527–544. Springer.\\nMithun, N. C.; Li, J.; Metze, F.; and Roy-Chowdhury, A. K. 2018.\\nLearning joint embedding with multimodal cues for cross-modal\\nvideo-text retrieval. In Proceedings of the 2018 ACM on Interna-\\ntional Conference on Multimedia Retrieval , 19–27.\\nMoriya, Y .; Sanabria, R.; Metze, F.; and Jones, G. J. 2019. Ground-\\ning Object Detections With Transcriptions. In ICML Workshop\\n2019 .\\nNoroozi, M.; and Favaro, P. 2016. Unsupervised learning of visual\\nrepresentations by solving jigsaw puzzles. In European Conference\\non Computer Vision , 69–84. Springer.\\nPapamakarios, G.; Pavlakou, T.; and Murray, I. 2017. Masked\\nautoregressive ﬂow for density estimation. In Advances in Neural\\nInformation Processing Systems , 2338–2347.\\nPathak, D.; Krahenbuhl, P.; Donahue, J.; Darrell, T.; and Efros,\\nA. A. 2016. Context encoders: Feature learning by inpainting. In\\nProceedings of the IEEE conference on computer vision and pattern\\nrecognition , 2536–2544.\\nReed, S.; Akata, Z.; Yan, X.; Logeswaran, L.; Schiele, B.; and Lee,\\nH. 2016. Generative adversarial text to image synthesis. arXiv\\npreprint arXiv:1605.05396 .\\nReed, S.; Lee, H.; Anguelov, D.; Szegedy, C.; Erhan, D.; and Ra-\\nbinovich, A. 2015. Training deep neural networks on noisy labels\\nwith bootstrapping. In ICLR Workshop 2015 .\\nRohrbach, A.; Rohrbach, M.; and Schiele, B. 2015. The long-\\nshort story of movie description. In German conference on pattern\\nrecognition , 209–221. Springer.\\nRohrbach, A.; Rohrbach, M.; Tandon, N.; and Schiele, B. 2015. A\\ndataset for movie description. In Proceedings of the IEEE confer-\\nence on computer vision and pattern recognition , 3202–3212.\\nSalakhutdinov, R.; and Hinton, G. ', 'Noise Estimation Using Density Estimation.pdf'), 1506: ('Erhan, D.; and Ra-\\nbinovich, A. 2015. Training deep neural networks on noisy labels\\nwith bootstrapping. In ICLR Workshop 2015 .\\nRohrbach, A.; Rohrbach, M.; and Schiele, B. 2015. The long-\\nshort story of movie description. In German conference on pattern\\nrecognition , 209–221. Springer.\\nRohrbach, A.; Rohrbach, M.; Tandon, N.; and Schiele, B. 2015. A\\ndataset for movie description. In Proceedings of the IEEE confer-\\nence on computer vision and pattern recognition , 3202–3212.\\nSalakhutdinov, R.; and Hinton, G. 2009. Deep boltzmann machines.\\nInArtiﬁcial intelligence and statistics , 448–455.\\nSchroff, F.; Kalenichenko, D.; and Philbin, J. 2015. Facenet: A uni-\\nﬁed embedding for face recognition and clustering. In Proceedings\\nof the IEEE conference on computer vision and pattern recognition ,\\n815–823.\\nSilverman, B. W. 2018. Density estimation for statistics and data\\nanalysis . Routledge.\\nSocher, R.; Karpathy, A.; Le, Q. V .; Manning, C. D.; and Ng, A. Y .\\n2014. Grounded compositional semantics for ﬁnding and describ-\\ning images with sentences. Transactions of the Association for\\nComputational Linguistics 2: 207–218.\\nSong, Y .; and Soleymani, M. 2019. Polysemous visual-semantic\\nembedding for cross-modal retrieval. In Proceedings of the IEEE\\nConference on Computer Vision and Pattern Recognition , 1979–\\n1988.\\nSrivastava, N.; Mansimov, E.; and Salakhudinov, R. 2015. Unsuper-\\nvised learning of video representations using lstms. In International\\nconference on machine learning , 843–852.\\nSrivastava, N.; and Salakhutdinov, R. 2012. Learning representa-\\ntions for multimodal data with deep belief nets. In International\\nconference on machine learning workshop , volume 79.\\nStone, C. J. 1994. The use of polynomial splines and their tensor\\nproducts in multivariate function estimation. The Annals of Statistics\\n118–171.\\nSukhbaatar, S.; Estrach, J. B.; Paluri, M.; Bourdev, L.; and Fergus,\\nR. 2015. Training convolutional networks with noisy labels. In\\nICLR Workshop 2015 .\\nSun, C.; Baradel, F.; Murphy, K.; and Schmid, C. 2019a. Contrastiv', 'Noise Estimation Using Density Estimation.pdf'), 1507: (' 2012. Learning representa-\\ntions for multimodal data with deep belief nets. In International\\nconference on machine learning workshop , volume 79.\\nStone, C. J. 1994. The use of polynomial splines and their tensor\\nproducts in multivariate function estimation. The Annals of Statistics\\n118–171.\\nSukhbaatar, S.; Estrach, J. B.; Paluri, M.; Bourdev, L.; and Fergus,\\nR. 2015. Training convolutional networks with noisy labels. In\\nICLR Workshop 2015 .\\nSun, C.; Baradel, F.; Murphy, K.; and Schmid, C. 2019a. Contrastive\\nbidirectional transformer for temporal representation learning. arXiv\\npreprint arXiv:1906.05743 .\\nSun, C.; Myers, A.; V ondrick, C.; Murphy, K.; and Schmid, C.\\n2019b. Videobert: A joint model for video and language representa-\\ntion learning. In Proceedings of the IEEE International Conference\\non Computer Vision , 7464–7473.\\nTanaka, D.; Ikami, D.; Yamasaki, T.; and Aizawa, K. 2018. Joint\\noptimization framework for learning with noisy labels. In Pro-\\nceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition , 5552–5560.\\nTerrell, G. R.; and Scott, D. W. 1992. Variable kernel density\\nestimation. The Annals of Statistics 1236–1265.Tian, Y .; Krishnan, D.; and Isola, P. 2019. Contrastive multiview\\ncoding. arXiv preprint arXiv:1906.05849 .\\nUria, B.; Murray, I.; and Larochelle, H. 2014. A deep and tractable\\ndensity estimator. In International Conference on Machine Learn-\\ning, 467–475.\\nVan Rooyen, B.; Menon, A.; and Williamson, R. C. 2015. Learning\\nwith symmetric label noise: The importance of being unhinged. In\\nAdvances in Neural Information Processing Systems , 10–18.\\nVendrov, I.; Kiros, R.; Fidler, S.; and Urtasun, R. 2016. Order-\\nEmbeddings of Images and Language. In Bengio, Y .; and LeCun,\\nY ., eds., 4th International Conference on Learning Representations,\\nICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference\\nTrack Proceedings .\\nVenugopalan, S.; Xu, H.; Donahue, J.; Rohrbach, M.; Mooney, R.;\\nand Saenko, K. 2015. Translating Videos to Natural Language\\nUsing Deep Recurrent Neural Networks. I', 'Noise Estimation Using Density Estimation.pdf'), 1508: (' unhinged. In\\nAdvances in Neural Information Processing Systems , 10–18.\\nVendrov, I.; Kiros, R.; Fidler, S.; and Urtasun, R. 2016. Order-\\nEmbeddings of Images and Language. In Bengio, Y .; and LeCun,\\nY ., eds., 4th International Conference on Learning Representations,\\nICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference\\nTrack Proceedings .\\nVenugopalan, S.; Xu, H.; Donahue, J.; Rohrbach, M.; Mooney, R.;\\nand Saenko, K. 2015. Translating Videos to Natural Language\\nUsing Deep Recurrent Neural Networks. In Proceedings of the\\n2015 Conference of the North American Chapter of the Association\\nfor Computational Linguistics: Human Language Technologies ,\\n1494–1504.\\nV ondrick, C.; Pirsiavash, H.; and Torralba, A. 2016. Generating\\nvideos with scene dynamics. In Advances in neural information\\nprocessing systems , 613–621.\\nWang, J.; Song, Y .; Leung, T.; Rosenberg, C.; Wang, J.; Philbin, J.;\\nChen, B.; and Wu, Y . 2014. Learning ﬁne-grained image similarity\\nwith deep ranking. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition , 1386–1393.\\nWang, L.; Li, Y .; and Lazebnik, S. 2016. Learning deep structure-\\npreserving image-text embeddings. In Proceedings of the IEEE\\nconference on computer vision and pattern recognition , 5005–5013.\\nWang, X.; and Wang, Y . 2015. Nonparametric multivariate density\\nestimation using mixtures. Statistics and Computing 25(2): 349–\\n364.\\nWang, Z.; and Scott, D. W. 2019. Nonparametric density estimation\\nfor high-dimensional data—Algorithms and applications. Wiley\\nInterdisciplinary Reviews: Computational Statistics 11(4): e1461.\\nWei, D.; Lim, J. J.; Zisserman, A.; and Freeman, W. T. 2018. Learn-\\ning and using the arrow of time. In Proceedings of the IEEE Con-\\nference on Computer Vision and Pattern Recognition , 8052–8060.\\nWeston, J.; Bengio, S.; and Usunier, N. 2010. Large scale image\\nannotation: learning to rank with joint word-image embeddings.\\nMachine learning 81(1): 21–35.\\nXiao, T.; Xia, T.; Yang, Y .; Huang, C.; and Wang, X. 2015. Learn-\\ning from massive noisy label', 'Noise Estimation Using Density Estimation.pdf'), 1509: ('rdisciplinary Reviews: Computational Statistics 11(4): e1461.\\nWei, D.; Lim, J. J.; Zisserman, A.; and Freeman, W. T. 2018. Learn-\\ning and using the arrow of time. In Proceedings of the IEEE Con-\\nference on Computer Vision and Pattern Recognition , 8052–8060.\\nWeston, J.; Bengio, S.; and Usunier, N. 2010. Large scale image\\nannotation: learning to rank with joint word-image embeddings.\\nMachine learning 81(1): 21–35.\\nXiao, T.; Xia, T.; Yang, Y .; Huang, C.; and Wang, X. 2015. Learn-\\ning from massive noisy labeled data for image classiﬁcation. In\\nProceedings of the IEEE conference on computer vision and pattern\\nrecognition , 2691–2699.\\nXu, D.; Zhao, Z.; Xiao, J.; Wu, F.; Zhang, H.; He, X.; and Zhuang,\\nY . 2017. Video question answering via gradually reﬁned attention\\nover appearance and motion. In Proceedings of the 25th ACM\\ninternational conference on Multimedia , 1645–1653.\\nXu, J.; Mei, T.; Yao, T.; and Rui, Y . 2016. Msr-vtt: A large video\\ndescription dataset for bridging video and language. In Proceedings\\nof the IEEE conference on computer vision and pattern recognition ,\\n5288–5296.\\nYu, Y .; Kim, J.; and Kim, G. 2018. A joint sequence fusion model\\nfor video question answering and retrieval. In Proceedings of the\\nEuropean Conference on Computer Vision (ECCV) , 471–487.\\nZhang, R.; Isola, P.; and Efros, A. A. 2016. Colorful image col-\\norization. In European conference on computer vision , 649–666.\\nSpringer.\\nAppendix Overview\\nIn Appendix A we present the proof of theorem 1. In Appendix B we empirically reproduce the theoretical graphs in Section 4 using the\\nmultidimensional toy dataset described in Section 6.1 for corroborating the validity of the analysis presented in Thm. 1 in the multidimensional\\ncase. In Appendix C we present qualitative examples. In Appendix D we present a visualization of the ‘low Tfailure case’ mentioned in\\nSection 4.2. In Appendix E we compare the performance of our model trained without 3D features (i.e., only 2D) to the baseline model that is\\ntrained with 2D+3D features. In Appendix F we eval', 'Noise Estimation Using Density Estimation.pdf'), 1510: ('theoretical graphs in Section 4 using the\\nmultidimensional toy dataset described in Section 6.1 for corroborating the validity of the analysis presented in Thm. 1 in the multidimensional\\ncase. In Appendix C we present qualitative examples. In Appendix D we present a visualization of the ‘low Tfailure case’ mentioned in\\nSection 4.2. In Appendix E we compare the performance of our model trained without 3D features (i.e., only 2D) to the baseline model that is\\ntrained with 2D+3D features. In Appendix F we evaluate the effect of two important design choices. In Appendix G we provide additional\\nimplementation details.\\nA Proof of Theorem 1\\nProof. Given a pair zi= (xi;yi)with(ai;bi) = (a;b), we ﬁnd the moment generating function of \\x16Si. We ﬁrst start with the moment\\ngenerating functions of s(xik;xi)ands(yik;yi). We note that\\x00s(xik;xi)and\\x00s(yik;yi)are both distributed according to the folded normal\\ndistribution. For the general case, the moment generating function of \\x00jXj,X\\x18(\\x16;\\x1b), is\\nM(t;\\x16;\\x1b) =e\\x1b2t2\\n2+\\x16t\\x08\\x12\\x16\\n\\x1b+\\x1bt\\x13\\n+e\\x1b2t2\\n2\\x00\\x16t\\x08\\x12\\n\\x00\\x16\\n\\x1b+\\x1bt\\x13\\n; (7)\\nwhere \\x08(\\x01)is the normal cumulative distribution function.\\nDenote the cardinality of the set of pairs that originate from the components (a;b)ofzias~mi, i.e., ~mi,jfzj:aj=a;bj=b;j=\\n1;:::;Mgj. Recall the three sigma limit assumption between each pair of components. Thus, by using the law of total expectation, the moment\\ngenerating function of \\x16Sijpican be expressed as\\nM\\x16Sijpi(t) =MX\\nn=0Pr( ~mi=njpi)\\x01M \\x16Sijpi;~mi=n(t); (8)\\nwhere,\\nM\\x16Sij~mi=n(t) =\\x14\\nM\\x121\\n2Kt;\\x16a\\x00xi;\\x1ba\\x13\\n\\x01M\\x121\\n2Kt;\\x160\\nb\\x00yi;\\x1b0\\nb\\x13\\x15minfn;Kg\\n\\x01\\nmaxf0;K\\x00ngY\\nj=1M\\x121\\n2Kt;\\x16\\x0bj\\x00xi;\\x1b\\x0bj\\x13\\n\\x01M\\x121\\n2Kt;\\x160\\n\\x0cj\\x00yi;\\x1b0\\n\\x0cj\\x13\\n;(9)\\nwhere all (\\x0bj;\\x0cj)6= (a;b), and\\nPr( ~mi=njpi) =(\\x00M\\nn\\x01\\n\\x01\\x001\\x00\\x11\\nT\\x01n\\x01\\x00\\n1\\x001\\x00\\x11\\nT\\x01M\\x00npi= 1\\x00M\\nn\\x01\\n\\x01\\x00\\x11\\nT(T\\x001)\\x01n\\x01\\x00\\n1\\x00\\x11\\nT(T\\x001)\\x01M\\x00npi= 0:(10)\\nWe used the fact that the moment generating function of V=c1U1+\\x01\\x01\\x01+cnUnis given byMV(t) =MU1(c1t)\\x01\\x01\\x01MUn(cnt), when the\\nci’s are scalars and the Ui’s are independent random variables.\\nApplying the Chernoff bound concludes the proof.\\nTo make sense of this error bound we performed multiple numerical simulati', 'Noise Estimation Using Density Estimation.pdf'), 1511: ('b\\x13\\x15minfn;Kg\\n\\x01\\nmaxf0;K\\x00ngY\\nj=1M\\x121\\n2Kt;\\x16\\x0bj\\x00xi;\\x1b\\x0bj\\x13\\n\\x01M\\x121\\n2Kt;\\x160\\n\\x0cj\\x00yi;\\x1b0\\n\\x0cj\\x13\\n;(9)\\nwhere all (\\x0bj;\\x0cj)6= (a;b), and\\nPr( ~mi=njpi) =(\\x00M\\nn\\x01\\n\\x01\\x001\\x00\\x11\\nT\\x01n\\x01\\x00\\n1\\x001\\x00\\x11\\nT\\x01M\\x00npi= 1\\x00M\\nn\\x01\\n\\x01\\x00\\x11\\nT(T\\x001)\\x01n\\x01\\x00\\n1\\x00\\x11\\nT(T\\x001)\\x01M\\x00npi= 0:(10)\\nWe used the fact that the moment generating function of V=c1U1+\\x01\\x01\\x01+cnUnis given byMV(t) =MU1(c1t)\\x01\\x01\\x01MUn(cnt), when the\\nci’s are scalars and the Ui’s are independent random variables.\\nApplying the Chernoff bound concludes the proof.\\nTo make sense of this error bound we performed multiple numerical simulations (See Section 4.2), with the following set up:\\n1.f\\x16i;\\x160\\nigT\\ni=1are sampled uniformly from [0;100]\\n2.f\\x1bigT\\ni=1are sampled uniformly from (0;min\\ni;jj\\x16i\\x00\\x16jj=6], andf\\x1b0\\nigT\\ni=1are sampled uniformly from (0;min\\ni;jj\\x160\\ni\\x00\\x160\\njj=6], such that the\\nthree sigma limit assumption in Theorem 1 is met.\\n3. We set\\x1c=\\x1c\\x03such thatP(\\x16Si\\x15\\x1c\\x03jpi= 0) =P(\\x16Si\\x14\\x1c\\x03jpi= 1) , i.e.,\\x1c\\x03=q\\nM\\x16Sijpi=0(t)\\x01M \\x16Sijpi=1(\\x00t).\\n4. Optimization for tis done over [1;2;:::;100].\\n5. Each experiment is repeated 10 times and the average is presented.\\nB Reproducing Empirically the Theoretical Results\\nIn Fig. 4 we empirically reproduce the theoretical graphs in Section 4 Fig. 2 and Fig. 8 using the multidimensional toy dataset described in\\nSection 6.1. These results corroborate the validity of the analysis presented in Thm. 1 in the multidimensional case. We note that across all\\nsub-ﬁgures in Fig. 4, similar trends are observed in comparison to the theoretical graphs in Fig. 2 and Fig. 8. More speciﬁcally, across Fig. 4a,\\n4b, 4c, 4d we observe the inﬂuence of K0(mentioned in Section 4) on the performance of our suggested approach. Additionally, in Fig. 4e, we\\nobserve the same ‘low T failure case’ mentioned in Section 4.\\n0 10 20 30 40 50\\nK0.00.20.40.60.81.01 - precision\\nM=1250\\nT=50\\n=0.5\\nK=M\\nT(1 )\\n(a)K\\n0.0 0.2 0.4 0.6 0.8 1.0\\n0.00.20.40.60.81.01 - precision\\nM=1250\\nT=50\\nK=4=1KT\\nM\\n (b)\\x11\\n0 1000 2000\\nM0.00.20.40.60.81.01 - precision\\n=0.5\\nT=50\\nK=4M=KT\\n1\\n (c)M\\n0100 200 300 400 500\\nT0.00.20.40.60.81.01 - precision\\nM=1250\\n=0.5\\nK=4T=M\\nK(1 )\\n(d)T\\n0 20 40 60 80 100\\nT0.00.20.', 'Noise Estimation Using Density Estimation.pdf'), 1512: ('K0(mentioned in Section 4) on the performance of our suggested approach. Additionally, in Fig. 4e, we\\nobserve the same ‘low T failure case’ mentioned in Section 4.\\n0 10 20 30 40 50\\nK0.00.20.40.60.81.01 - precision\\nM=1250\\nT=50\\n=0.5\\nK=M\\nT(1 )\\n(a)K\\n0.0 0.2 0.4 0.6 0.8 1.0\\n0.00.20.40.60.81.01 - precision\\nM=1250\\nT=50\\nK=4=1KT\\nM\\n (b)\\x11\\n0 1000 2000\\nM0.00.20.40.60.81.01 - precision\\n=0.5\\nT=50\\nK=4M=KT\\n1\\n (c)M\\n0100 200 300 400 500\\nT0.00.20.40.60.81.01 - precision\\nM=1250\\n=0.5\\nK=4T=M\\nK(1 )\\n(d)T\\n0 20 40 60 80 100\\nT0.00.20.40.60.81.01 - precision\\nM=2500\\n=0.5\\nK=4 (e) LowTfailure case\\nFigure 4: Empirical error of multidimensional toy dataset . In the ﬁgures above we empirically reproduce the theoretical\\ngraphs in Fig. 2 and Fig. 8 using the multidimensional toy dataset mentioned above. The results help in validating that the analysis\\nthat was done in Thm. 1 for a single dimension, also holds for a multidimensional space. The vertical axis is (1\\x00precision) ,\\nwhere the threshold was chosen such that F1 Score is maximized. In each ﬁgure we mark with a red dashed vertical line the point\\nat which the equation K=M\\nT\\x01(1\\x00\\x11)holds. We note that across all ﬁgures, similar trends are observed in comparison to the\\ntheoretical graphs in Fig. 2 and Fig. 8.\\nC Qualitative Examples\\nC.1 High Score Examples and Their kNearest Neighbours\\nIn this section, we present two examples of clip-caption pairs with high ^p(see Eq. (2)) and their nearest neighbours in the multimodal space\\nthat contributed to their high score. One example includes in its caption the word ‘bye’ (Fig. 5) and the other the word ‘mix’ (Fig 6). The\\nﬁgures below include only one representative frame from each video clip. Thus, it is worth mentioning that all video clips in Fig. 5 and 6 in fact\\ncontain a ‘waiving goodbye’ action and a ‘mixing’ action, respectively. It is important to note that these examples were extracted only based on\\nour noise estimation component and are not based on the learned shared embedding space.\\nFigure 5: ‘Bye’ Cluster.\\nFigure 6: ‘Mix’ Cluster\\nC.2 High and Low ', 'Noise Estimation Using Density Estimation.pdf'), 1513: ('the word ‘bye’ (Fig. 5) and the other the word ‘mix’ (Fig 6). The\\nﬁgures below include only one representative frame from each video clip. Thus, it is worth mentioning that all video clips in Fig. 5 and 6 in fact\\ncontain a ‘waiving goodbye’ action and a ‘mixing’ action, respectively. It is important to note that these examples were extracted only based on\\nour noise estimation component and are not based on the learned shared embedding space.\\nFigure 5: ‘Bye’ Cluster.\\nFigure 6: ‘Mix’ Cluster\\nC.2 High and Low Score Examples for the Same Query\\nIn this section, we present ten examples of high and low ^pscore clip-caption pairs for the same query. These examples visually illustrate how\\nour noise estimation component is able to distinguish between wrongly associated pairs and correctly associated pairs successfully.\\nFigure 7: High and low ^pscore examples for the same query. Each row contains two video clips (represented by a single frame)\\nthat include in their caption the same query (right column). The left column (GREEN) contains clips with high ^p, while the\\nmiddle column (RED) contains clips with low ^p.\\nD LowTFailure Case Simulation\\nOne instance where the method fails, gives us insight into why usually the method succeeds. The method will fail for a small number of\\nconcepts (T) and regardless of K0, because for a small number of concepts there is a higher chance that two or more wrongly associated pairs\\nbelong to the same pair of concepts in both modalities. Fortunately, in real-world data Tis almost always large, and additionally as Tincreases\\nthis problem is alleviated by a factor of O(T2)(see Appendix A, Eq. (10)). A simulation of this case is presented in the ﬁgure below.\\n0 10 20 30 40 50 60 70 80 90 100\\nT0.20.30.40.50.60.70.80.91.0Error Bound\\nLow T Failure Case\\nM=2500\\n=0.5\\nK=4\\nFigure 8: Low Tfailure case.\\nE Zero-shot Text-To-Video retrieval in ‘unfair’ settings\\nWe demonstrate that our model outperforms or is at least on par with the performance of HTM-PT (Miech et al. 2019) even given a setting\\nwhich is a clea', 'Noise Estimation Using Density Estimation.pdf'), 1514: (', and additionally as Tincreases\\nthis problem is alleviated by a factor of O(T2)(see Appendix A, Eq. (10)). A simulation of this case is presented in the ﬁgure below.\\n0 10 20 30 40 50 60 70 80 90 100\\nT0.20.30.40.50.60.70.80.91.0Error Bound\\nLow T Failure Case\\nM=2500\\n=0.5\\nK=4\\nFigure 8: Low Tfailure case.\\nE Zero-shot Text-To-Video retrieval in ‘unfair’ settings\\nWe demonstrate that our model outperforms or is at least on par with the performance of HTM-PT (Miech et al. 2019) even given a setting\\nwhich is a clear disadvantage such as training it without 3D features (i.e., only 2D). See Table 3 in Appendix E. This shows:\\n(i) The power of our noise estimation method and its potential.\\n(ii)Integrating our multimodal density estimation component allows saving time and/or computation power by training and running inference\\nwith only 2D features, without (or with minor) performance degradation.\\nWe note that speciﬁcally for MSRVTT dataset our 2D-based model actually performs slightly better than our 2D+3D-based model. This result\\nrequires further investigation.\\nTable 3: Zero-shot Text-To-Video retrieval in ‘unfair’ settings. For MR the lower the better. We show below that our model\\noutperforms or is at least on par with the performance of HTM-PT (Miech et al. 2019) even given a setting which is a clear\\ndisadvantage such as training it without 3D features (no-3D), i.e., only 2D features\\nMSRVTT LSMDC MSVD\\nMethod R@1 R@5 R@10 MR R@1 R@5 R@10 MR R@1 R@5 R@10 MR\\nHTM-PT\\x03(Miech et al. 2019) 7.5 21.2 29.6 38.0 4.0 9.8 14.0 137.0 12.86 33.06 45.83 13.0\\nHTM-PT (Miech et al. 2019) no-3D 6.9 19.8 27.4 43.0 3.3 9.9 13.4 147.0 11.57 30.25 40.84 17.0\\nOurs (no 3D) 8.4 22.0 30.4 36.0 4.0 10.5 14.3 141.5 12.74 33.48 44.96 14.0\\nF Design-Choice Analysis\\nIn this section, we evaluate the effect of two important design choices on the Zero-Shot Text-To-Video Retrieval task: (a) k-NN parameter;\\nand (b)S(\\x01;\\x01), the multimodal similarity function. In Table 4a ( Kanalysis) we see a similar trend as in Section 4, Fig. 2a, i.e., increasing\\nKdecreases the ', 'Noise Estimation Using Density Estimation.pdf'), 1515: ('2.86 33.06 45.83 13.0\\nHTM-PT (Miech et al. 2019) no-3D 6.9 19.8 27.4 43.0 3.3 9.9 13.4 147.0 11.57 30.25 40.84 17.0\\nOurs (no 3D) 8.4 22.0 30.4 36.0 4.0 10.5 14.3 141.5 12.74 33.48 44.96 14.0\\nF Design-Choice Analysis\\nIn this section, we evaluate the effect of two important design choices on the Zero-Shot Text-To-Video Retrieval task: (a) k-NN parameter;\\nand (b)S(\\x01;\\x01), the multimodal similarity function. In Table 4a ( Kanalysis) we see a similar trend as in Section 4, Fig. 2a, i.e., increasing\\nKdecreases the error initially and from a certain value, the error increases. In Table 4b ( S(\\x01;\\x01)analysis), it is evident that there is a slight\\nadvantage of using the minimum function over the mean function, yet it is not conclusive, i.e., the mean function that is used in Thm. 1 for\\nsimplicity of analysis is a decent design choice as well.\\nk-NN MSRVTT LSMDC MSVD\\n1-NN 20.9 10.7 33.66\\n4-NN 21.3 11.6 35.7\\n16-NN 20.8 11.3 35.55\\n(a)k-NNS(zi;zj) MSRVTT LSMDC MSVD\\nmean (used in Thm. 1) 20.3 11.2 35.84\\nminimum (Eq. (1)) 21.3 11.6 35.7\\n(b) Multimodal similarity function\\nTable 4: Design-Choice Analysis. Recall@5 results for Zero-Shot Text-To-Video Retrieval.\\nG Additional Implementation Details\\nSampling strategy. For a fair comparison to the baseline model HTM (Miech et al. 2019), we follow the same sampling strategy. More\\nspeciﬁcally, half of the negative pairs, (vi;cj) :i6=jare sampled such that they belong to the same video clip, while the other half are\\nsampled such that they do not.\\nk-NN Computation. To compute k-NN efﬁciently over the entire dataset we use FAISS (Johnson, Douze, and J ´egou 2019). Due\\nto the high correlation between video segments of the same video, in practice we extract Knearest neighbors that originate from different\\nvideos, where K= 4.\\nDataset Length [s] #Clips Train/Val/Test Split\\nMSRVTT-QA (2017) 20 10,000 158,581/12,278/72,821\\nMSVD-QA (2017) 20 1970 30,933/6,415/13,157\\n(a) Video question answeringDataset Length [s] #Clips Train/Val/Test Split\\nMSRVTT (2016) 20 10,000 130,260/9940/1000\\nMSVD (2011) 20 1970 ', 'Noise Estimation Using Density Estimation.pdf'), 1516: (' over the entire dataset we use FAISS (Johnson, Douze, and J ´egou 2019). Due\\nto the high correlation between video segments of the same video, in practice we extract Knearest neighbors that originate from different\\nvideos, where K= 4.\\nDataset Length [s] #Clips Train/Val/Test Split\\nMSRVTT-QA (2017) 20 10,000 158,581/12,278/72,821\\nMSVD-QA (2017) 20 1970 30,933/6,415/13,157\\n(a) Video question answeringDataset Length [s] #Clips Train/Val/Test Split\\nMSRVTT (2016) 20 10,000 130,260/9940/1000\\nMSVD (2011) 20 1970 48,820/4401/3350\\nLSMDC (2015) 5 128,085 101,079/7408/1000\\n(b) Text-Video retrieval\\nTable 5: Statistics of datasets. For retrieval we use the same test set split as deﬁned by (Mithun et al. 2018; Yu, Kim, and Kim\\n2018; Miech, Laptev, and Sivic 2018) for a fair comparison.', 'Noise Estimation Using Density Estimation.pdf'), 1517: ('Adaptive Graph Convolutional Recurrent Network\\nfor Trafﬁc Forecasting\\nLei Bai\\nUNSW, Sydney\\nbaisanshi@gmail.comLina Yao\\nUNSW, Sydney\\nlina.yao@unsw.edu.auCan Li\\nUNSW, Sydney\\ncan.li4@student.unsw.edu.au\\nXianzhi Wang\\nUniversity of Technology Sydney\\nxianzhi.wang@uts.edu.auCan Wang\\nGrifﬁth University\\ncan.wang@griffith.edu.au\\nAbstract\\nModeling complex spatial and temporal correlations in the correlated time series\\ndata is indispensable for understanding the trafﬁc dynamics and predicting the\\nfuture status of an evolving trafﬁc system. Recent works focus on designing com-\\nplicated graph neural network architectures to capture shared patterns with the help\\nof pre-deﬁned graphs. In this paper, we argue that learning node-speciﬁc patterns\\nis essential for trafﬁc forecasting while the pre-deﬁned graph is avoidable. To\\nthis end, we propose two adaptive modules for enhancing Graph Convolutional\\nNetwork (GCN) with new capabilities: 1) a Node Adaptive Parameter Learning\\n(NAPL) module to capture node-speciﬁc patterns; 2) a Data Adaptive Graph Gen-\\neration (DAGG) module to infer the inter-dependencies among different trafﬁc\\nseries automatically. We further propose an Adaptive Graph Convolutional Recur-\\nrent Network (AGCRN) to capture ﬁne-grained spatial and temporal correlations\\nin trafﬁc series automatically based on the two modules and recurrent networks.\\nOur experiments1on two real-world trafﬁc datasets show AGCRN outperforms\\nstate-of-the-art by a signiﬁcant margin without pre-deﬁned graphs about spatial\\nconnections.\\n1 Introduction\\nThe fast urbanization introduces growing populations in cities and presents signiﬁcant mobility and\\nsustainability challenges. Among those challenges, Intelligent Transportation Systems (ITS) has\\nbecome an active research area [ 1], given its potential to promote system efﬁciency and decision-\\nmaking. As an essential step towards the ITS, trafﬁc forecasting aims at predicting the future status\\n(e.g., trafﬁc ﬂow and speed, and passenger demand) of urban trafﬁc systems. It plays a vital role in\\ntrafﬁc ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1518: ('uction\\nThe fast urbanization introduces growing populations in cities and presents signiﬁcant mobility and\\nsustainability challenges. Among those challenges, Intelligent Transportation Systems (ITS) has\\nbecome an active research area [ 1], given its potential to promote system efﬁciency and decision-\\nmaking. As an essential step towards the ITS, trafﬁc forecasting aims at predicting the future status\\n(e.g., trafﬁc ﬂow and speed, and passenger demand) of urban trafﬁc systems. It plays a vital role in\\ntrafﬁc scheduling and management and has attracted tremendous attention from the machine learning\\nresearch community in recent years [2, 3, 4, 5, 6].\\nTrafﬁc forecasting is challenging due to the complex intra-dependencies (i.e., temporal correlations\\nwithin one trafﬁc series) and inter-dependencies (i.e., spatial correlations among multitudinous corre-\\nlated trafﬁc series) [ 3] generated from different sources, e.g., different loop detectors/intersections\\nfor trafﬁc ﬂow & trafﬁc speed prediction, and various stations/regions for passenger demand pre-\\ndiction. Traditional methods simply deploy time series models, e.g., Auto-Regressive Integrated\\nMoving Average (ARIMA) and Vector Auto-Regression (V AR), for trafﬁc forecasting. They cannot\\ncapture the nonlinear correlations nor intricate spatial-temporal patterns among large scale trafﬁc\\n1Code available at: https://github.com/LeiBAI/AGCRN\\n34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.\\ndata. Recently, researchers shift to deep-learning-based methods and focus on designing new neural\\nnetwork architectures to capture prominent spatial-temporal patterns shared by all trafﬁc series. They\\ntypically model temporal dependencies with recurrent neural networks [ 7,8,9,10] (e.g., Long-Short\\nTerm Memory and Gated Recurrent Unit) or temporal convolution modules [ 3,4]. Regarding spatial\\ncorrelations, they commonly use GCN-based methods [ 2,4,3,6,11,5,12] to model unstructured\\ntrafﬁc series and their inter-dependencies.\\nFigure 1: Examples o', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1519: ('p-learning-based methods and focus on designing new neural\\nnetwork architectures to capture prominent spatial-temporal patterns shared by all trafﬁc series. They\\ntypically model temporal dependencies with recurrent neural networks [ 7,8,9,10] (e.g., Long-Short\\nTerm Memory and Gated Recurrent Unit) or temporal convolution modules [ 3,4]. Regarding spatial\\ncorrelations, they commonly use GCN-based methods [ 2,4,3,6,11,5,12] to model unstructured\\ntrafﬁc series and their inter-dependencies.\\nFigure 1: Examples of trafﬁc ﬂow with diverse\\npatterns. The trafﬁc ﬂow of road 3 is steady in the\\nday time. As a contrast, the trafﬁc ﬂows of road 1,\\n2 and 4 have obvious evening peak, morning peak,\\nand both peaks, respectively.While recent deep-learning-based methods\\nachieve promising results, they are biased to the\\nprominent and shared patterns among all trafﬁc\\nseries—the shared parameter space makes cur-\\nrent methods inferior in capturing ﬁne-grained\\ndata-source speciﬁc patterns accurately. In\\nfact, trafﬁc series exhibit diversiﬁed patterns (as\\nshown in Fig. 1), they may appear similar, dis-\\nsimilar, and even contradictory owning to the\\ndistinct attributes across a variety of data sources\\n[7,13]. Moreover, existing GCN-based methods\\nrequire pre-deﬁning an inter-connection graph\\nby similarity or distance measures [ 14] to cap-\\nture the spatial correlations. That further re-\\nquires substantial domain knowledge and is sen-\\nsitive to the graph quality. The graphs generated in this manner are normally intuitive, incomplete,\\nand not directly speciﬁc to the prediction tasks; they may contain biases and not adaptable to domains\\nwithout appropriate knowledge.\\nInstead of designing more complicated network architectures, we propose two concise yet effective\\nmechanisms by revising the basic building block of current methods (i.e., GCN) to solve the above\\nproblems separately. Speciﬁcally, we propose to enhance GCN with two adaptive modules for trafﬁc\\nforecasting tasks: 1) a Node Adaptive Parameter Learning (NAPL) module to learn node-speciﬁ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1520: ('t directly speciﬁc to the prediction tasks; they may contain biases and not adaptable to domains\\nwithout appropriate knowledge.\\nInstead of designing more complicated network architectures, we propose two concise yet effective\\nmechanisms by revising the basic building block of current methods (i.e., GCN) to solve the above\\nproblems separately. Speciﬁcally, we propose to enhance GCN with two adaptive modules for trafﬁc\\nforecasting tasks: 1) a Node Adaptive Parameter Learning (NAPL) module to learn node-speciﬁc\\npatterns for each trafﬁc series—NAPL factorizes the parameters in traditional GCN and generates\\nnode-speciﬁc parameters from a weights pool and bias pool shared by all nodes according to the node\\nembedding; 2) a Data Adaptive Graph Generation (DAGG) module to infer the node embedding\\n(attributes) from data and to generate the graph during training. NAPL and DAGG are independent and\\ncan be adapted to existing GCN-based trafﬁc forecasting models both separately and jointly. All the\\nparameters in the modules can be easily learned in an end-to-end manner. Furthermore, we combine\\nNAPL and DAGG with recurrent networks and propose a uniﬁed trafﬁc forecasting model - Adaptive\\nGraph Convolutional Recurrent Network (AGCRN). AGCRN can capture ﬁne-grained node-speciﬁc\\nspatial and temporal correlations in the trafﬁc series and unify the nodes embeddings in the revised\\nGCNs with the embedding in DAGG. As such, training AGCRN can result in a meaningful node\\nrepresentation vector for each trafﬁc series source (e.g., roads for trafﬁc speed/ﬂow, stations/regions\\nfor passenger demand). The learned node representation contains valuable information about the\\nroad/region and can be potentially applied to other tasks [15].\\nWe evaluate AGCRN on two real-world datasets for the multi-step trafﬁc prediction task and com-\\npare it with several representative trafﬁc forecasting models. The experimental results show that\\nAGCRN outperforms state-of-the-art with a signiﬁcant margin. We also conduct ablation studies and\\ndemonstrate the effect', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1521: ('for trafﬁc speed/ﬂow, stations/regions\\nfor passenger demand). The learned node representation contains valuable information about the\\nroad/region and can be potentially applied to other tasks [15].\\nWe evaluate AGCRN on two real-world datasets for the multi-step trafﬁc prediction task and com-\\npare it with several representative trafﬁc forecasting models. The experimental results show that\\nAGCRN outperforms state-of-the-art with a signiﬁcant margin. We also conduct ablation studies and\\ndemonstrate the effectiveness of both NAPL and DAGG.\\n2 Related Work\\nCorrelated time series prediction Trafﬁc forecasting belongs to correlated time series analysis\\n(or multivariate time series analysis) and has been studied for decades. In recent years, deep\\nlearning has dominated the correlated time series prediction due to its superior ability in modeling\\ncomplex functions and learning correlations from data automatically. A majority of such studies\\n[16,17,10,8,18,19,20,21] rely on LSTM or GRU to model the temporal dynamics in the time\\nseries data. Some efforts employ temporal convolutional networks [ 22,23,24] to enable the model\\nprocess very long sequence with fewer time. However, these studies do not explicitly model the\\ninter-dependencies among different time series. A very recent work [ 25] uses transformers for\\n2\\ncorrelated time series prediction. Such work normally requires massive training samples due to\\ntremendous trainable parameters [26].\\nGCN based Trafﬁc forecasting Different with general correlated time series prediction, trafﬁc\\nforecasting researches also pay more attention to spatial correlations among the trafﬁc series from\\ndifferent sources (spaces/regions/sensors) except for the temporal correlations. A part of these\\nstudies [ 27,28,7,9] utilize CNN to capture spatial correlations among near regions based on the\\nassumption that trafﬁc series are generated from grid-partitioned cities [ 28], which does not always\\nhold. To develop more general and widely-used trafﬁc forecasting methods, researchers are shifting\\nto ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1522: ('ction, trafﬁc\\nforecasting researches also pay more attention to spatial correlations among the trafﬁc series from\\ndifferent sources (spaces/regions/sensors) except for the temporal correlations. A part of these\\nstudies [ 27,28,7,9] utilize CNN to capture spatial correlations among near regions based on the\\nassumption that trafﬁc series are generated from grid-partitioned cities [ 28], which does not always\\nhold. To develop more general and widely-used trafﬁc forecasting methods, researchers are shifting\\nto GCN-based models in recent years. These efforts [ 4,3,29,5,6,11,14,30,31] formulate the\\ntrafﬁc forecasting problem on graph and utilize the spectral GCN developed in [ 32,33] for capturing\\nthe prominent spatial interactions among different trafﬁc series. DCRNN [ 2] re-formulates the spatial\\ndependency of trafﬁc as a diffusion process and extends the previous GCN [ 32,33] to a directed graph.\\nFollowing DCRNN, Graph Wavenet [ 5] combines GCN with dilated causal convolution networks for\\nsaving computation cost in handling long sequence and propose a self-adaptive adaptive adjacency\\nmatrix as a complement for the pre-deﬁned adjacent matrix to capture spatial correlations. More\\nrecent works such as ASTGCN [ 6], STSGCN [ 11] and GMAN [ 12] further add more complicated\\nspatial and temporal attention mechanisms with GCN to capture the dynamic spatial and temporal\\ncorrelations. However, these methods can only capture shared patterns among all trafﬁc series and\\nstill rely on the pre-deﬁned spatial connection graph.\\nGraph Convolutional Networks GCN [ 32,33] is a special kind of CNN generalized for graph-\\nstructured data, which is widely used in node classiﬁcation, link prediction, and graph classiﬁcation\\n[34]. Most of these works focus on graph representation, which learns node embedding by integrating\\nthe features from node’s local neighbours based on the given graph structure. To manipulate\\nneighbours’ information more accurately, GAT [ 35] learns to weight the information from different\\nneighbours with attention scores', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1523: ('ph Convolutional Networks GCN [ 32,33] is a special kind of CNN generalized for graph-\\nstructured data, which is widely used in node classiﬁcation, link prediction, and graph classiﬁcation\\n[34]. Most of these works focus on graph representation, which learns node embedding by integrating\\nthe features from node’s local neighbours based on the given graph structure. To manipulate\\nneighbours’ information more accurately, GAT [ 35] learns to weight the information from different\\nneighbours with attention scores learned by multi-head self-attention mechanism. DIFFPOOL [ 36]\\nenhances GCN with node clustering to generate hierarchical graph representations. Different from\\nthese works dealing with static features, our work deals with dynamically evolving streams and\\noperates on both spatial and temporal dimensions without the given graph structure.\\n3 Methodology\\n3.1 Problem Deﬁnition\\nWe target on the multi-step trafﬁc forecasting problem. Consider multitudinous trafﬁc series that\\ncontainsNcorrelated univariate time series represented as X=fX:;0;X:;1;:::;X:;t;:::g, where\\nX:;t=fx1;t;x2;t;:::;xi;t;:::xN;tgT2RN\\x021is the recording of Nsources at time step t, our target\\nis to predict the future values of the correlated trafﬁc series based on the observed historical values.\\nFollowing in the practice in the time series prediction, we formulate the problem as ﬁnding a function\\nFto forecast the next \\x1csteps data based on the past Tsteps historical data:\\nfX:;t+1;X:;t+2;:::;X:;t+\\x1cg=F\\x12(X:;t;X:;t\\x001;:::;X:;t\\x00T+1) (1)\\nwhere\\x12denotes all the learnable parameters in the model. In order to accurately manipulate the\\nspatial correlations between different trafﬁc series, the problem is further formulated on graph\\nG= (V;E;A), whereVis a set of nodes represent the sources of trafﬁc series and jVj=N,Eis a\\nset of edges, and A2RN\\x02Nis the adjacent matrix of the graph representing the proximity between\\nnodes or trafﬁc series (e.g., a function of trafﬁc network distance or trafﬁc series similarity). Thus,\\nthe problem is modiﬁed as:\\nfX:;t+1;X:;t+2;:::;X:;', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1524: ('he learnable parameters in the model. In order to accurately manipulate the\\nspatial correlations between different trafﬁc series, the problem is further formulated on graph\\nG= (V;E;A), whereVis a set of nodes represent the sources of trafﬁc series and jVj=N,Eis a\\nset of edges, and A2RN\\x02Nis the adjacent matrix of the graph representing the proximity between\\nnodes or trafﬁc series (e.g., a function of trafﬁc network distance or trafﬁc series similarity). Thus,\\nthe problem is modiﬁed as:\\nfX:;t+1;X:;t+2;:::;X:;t+\\x1cg=F\\x12(X:;t;X:;t\\x001;:::;X:;t\\x00T+1;G) (2)\\n3.2 Node Adaptive Parameter Learning\\nMost recent work in trafﬁc forecasting deploys GCN to capture the spatial correlations among trafﬁc\\nseries and follows the calculations proposed in the spectral domain [ 32,33]. According to [ 33], the\\ngraph convolution operation can be well-approximated by 1storder Chebyshev polynomial expansion\\nand generalized to high-dimensional GCN as:\\nZ= (IN+D\\x001\\n2AD\\x001\\n2)X\\x02+b (3)\\n3\\nwhereA2RN\\x02Nis the adjacent matrix of the graph, Dis the degree matrix, X2RN\\x02Cand\\nZ2RN\\x02Fare input and output of the GCN layer, \\x022RC\\x02Fandb2RFdenote the learnable\\nweights and bias, separately. From the view of one node (e.g., node i), the GCN operation can be\\nregarded as transforming the features of node Xi2R1\\x02CtoZi2R1\\x02Fwith the shared \\x02and\\nbamong all nodes. While sharing parameters may be useful to learn the most prominent patterns\\namong all nodes in many problems and can signiﬁcantly reduce the parameter numbers, we ﬁnd\\nits sub-optimal for trafﬁc forecasting problems. Except for the close spatial correlations between\\nclose related trafﬁc series, there also exist diverse patterns among different trafﬁc series due to the\\ndynamic propriety of time series data and various factors of the node that could inﬂuence trafﬁc. On\\nthe one hand, the trafﬁc streams from two adjacent nodes may also present dissimilar patterns at\\nsome particular period because of their speciﬁc attributes (e.g., PoI, weather). On the other hand, the\\ntrafﬁc series from two disjoint nodes may even show rever', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1525: ('xcept for the close spatial correlations between\\nclose related trafﬁc series, there also exist diverse patterns among different trafﬁc series due to the\\ndynamic propriety of time series data and various factors of the node that could inﬂuence trafﬁc. On\\nthe one hand, the trafﬁc streams from two adjacent nodes may also present dissimilar patterns at\\nsome particular period because of their speciﬁc attributes (e.g., PoI, weather). On the other hand, the\\ntrafﬁc series from two disjoint nodes may even show reverse patterns. As a result, only capturing\\nshared patterns among all nodes is not enough for accurate trafﬁc forecasting, and it is essential to\\nmaintain a unique parameter space for each node to learn node-speciﬁc patterns.\\nHowever, assigning parameters for each node will result in \\x022RN\\x02C\\x02F, which is too huge to\\noptimize and would lead to over-ﬁtting problem, especially when Nis big. To solve the issue,\\nwe propose to enhance traditional GCN with a Node Adaptive Parameter Learning module, which\\ndraws insights from the matrix factorization. Instead of directly learning \\x022RN\\x02C\\x02F, NAPL\\nlearns two smaller parameter matrix: 1) a node-embedding matrix EG2RN\\x02d, wheredis the\\nembedding dimension, and d<<N ; 2) a weight pool WG2Rd\\x02C\\x02F. Then, \\x02can be generated\\nby\\x02=EG\\x01WG. From the view of one node (e.g., node i), this process extracts parameters \\x02ifori\\nfrom a large shared weight pool WGaccording to the node embedding Ei\\nG, which can be interpreted\\nas learning node speciﬁc patterns from a set of candidate patterns discovered from all trafﬁc series.\\nThe same operation can also be used for b. Finally, the NAPL enhanced GCN (i.e., NAPL-GCN) can\\nbe formulaed as:\\nZ= (IN+D\\x001\\n2AD\\x001\\n2)XEGWG+EGbG (4)\\n3.3 Data Adaptive Graph Generation\\nAnother problem lies in existing GCN-based trafﬁc forecasting models, which require a pre-deﬁned\\nadjacent matrix Afor the graph convolution operation. Existing work mainly utilizes distance\\nfunction or similarity metrics to calculate the graph in advance. There are mainly two approaches\\nfor deﬁning A: 1)', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1526: ('d from all trafﬁc series.\\nThe same operation can also be used for b. Finally, the NAPL enhanced GCN (i.e., NAPL-GCN) can\\nbe formulaed as:\\nZ= (IN+D\\x001\\n2AD\\x001\\n2)XEGWG+EGbG (4)\\n3.3 Data Adaptive Graph Generation\\nAnother problem lies in existing GCN-based trafﬁc forecasting models, which require a pre-deﬁned\\nadjacent matrix Afor the graph convolution operation. Existing work mainly utilizes distance\\nfunction or similarity metrics to calculate the graph in advance. There are mainly two approaches\\nfor deﬁning A: 1) distance function, which deﬁnes the graph according to the geographic distance\\namong different nodes[ 2,4]; 2) similarity function, which deﬁnes the node proximity by measuring\\nthe similarity of the node attributes (e.g., PoI information) [ 7,14] or trafﬁc series itself [ 3]. However,\\nthese approaches are quite intuitive. The pre-deﬁned graph cannot contain complete information about\\nspatial dependency and is not directly related to prediction tasks, which may result in considerable\\nbiases. Besides, these approaches cannot be adapted to other domains without appropriate knowledge,\\nmaking existing GCN-based models ineffective.\\nTo solve the issue, we propose a Data Adaptive Graph Generation (DAGG) module to infer the hidden\\ninter-dependencies from data automatically. The DAGG module ﬁrst randomly initialize a learnable\\nnode embedding dictionaries EA2RN\\x02defor all nodes, where each row of EArepresents the\\nembedding of a node and dedenotes the dimension of node embedding. Then, similar as deﬁning\\nthe graph by nodes similarity, we can infer the spatial dependencies between each pair of nodes by\\nmultiplyingEAandET\\nA:\\nD\\x001\\n2AD\\x001\\n2=softmax (ReLU (EA\\x01ET\\nA)) (5)\\nwheresoftmax function is used to normalize the adaptive matrix. Here, instead of generating Aand\\ncalculating a Laplacian matrix, we directly generate D\\x001\\n2AD\\x001\\n2to avoid unnecessary and repeated\\ncalculations in the iterative training process. During training, EAwill be updated automatically to\\nlearn the hidden dependencies among different trafﬁc series and get the', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1527: ('es similarity, we can infer the spatial dependencies between each pair of nodes by\\nmultiplyingEAandET\\nA:\\nD\\x001\\n2AD\\x001\\n2=softmax (ReLU (EA\\x01ET\\nA)) (5)\\nwheresoftmax function is used to normalize the adaptive matrix. Here, instead of generating Aand\\ncalculating a Laplacian matrix, we directly generate D\\x001\\n2AD\\x001\\n2to avoid unnecessary and repeated\\ncalculations in the iterative training process. During training, EAwill be updated automatically to\\nlearn the hidden dependencies among different trafﬁc series and get the adaptive matrix for graph\\nconvolutions. Comparing with the self-adaptive adjacent matrix in [ 5], DAGG module is simpler and\\nthe learnedEAhas better interpret-ability. Finally, the DAGG enhanced GCN can be formulated as:\\nZ= (IN+softmax (ReLU (EA\\x01ET\\nA)))X\\x02 (6)\\nWhen dealing with extremely large graphs (i.e., Nis huge), DAGG may require heavy computation\\ncost. Graph partition and sub-graph training methods [ 12,37] could be applied to address the problem.\\n4\\n3.4 Adaptive Graph Convolutional Recurrent Network\\nExcept for the spatial correlations, trafﬁc forecasting also involves complex temporal correlations.\\nIn this part, we introduce an Adaptive Graph Convolutional Recurrent Network (AGCRN), which\\nintegrates NAPL-GCN, DAGG, and Gated Recurrent Units (GRU) to capture both node-speciﬁc\\nspatial and temporal correlations in trafﬁc series. AGCRN replaces the MLP layers in GRU with our\\nNAPL-GCN to learn node-speciﬁc patterns. Besides, it discoveries spatial dependencies automatically\\nwith the DAGG module. Formally:\\neA=softmax (ReLU (EET))\\nzt=\\x1b(eA[X:;t;ht\\x001]EWz+Ebz\\nrt=\\x1b(eA[X:;t;ht\\x001]EWr+Ebr\\n^ht=tanh(eA[X:;t;r\\x0cht\\x001]EW^h+Eb^h\\nht=z\\x0cht\\x001+ (1\\x00z)\\x0c^ht(7)\\nwhereX:;tandhtare input and output at time step t,[\\x01]denotes the concate operation, zandrare\\nreset gate and update gate, respectively. E,Wz,Wr,W^h,bz,br, andb^hare learnable parameters\\nin AGCRN. Similar to GRU, all the parameters in AGCRN can be trained end-to-end with back-\\npropagation through time. As can be observed from the equation, AGCRN uniﬁes all the embedding\\nmatrix to', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1528: ('=softmax (ReLU (EET))\\nzt=\\x1b(eA[X:;t;ht\\x001]EWz+Ebz\\nrt=\\x1b(eA[X:;t;ht\\x001]EWr+Ebr\\n^ht=tanh(eA[X:;t;r\\x0cht\\x001]EW^h+Eb^h\\nht=z\\x0cht\\x001+ (1\\x00z)\\x0c^ht(7)\\nwhereX:;tandhtare input and output at time step t,[\\x01]denotes the concate operation, zandrare\\nreset gate and update gate, respectively. E,Wz,Wr,W^h,bz,br, andb^hare learnable parameters\\nin AGCRN. Similar to GRU, all the parameters in AGCRN can be trained end-to-end with back-\\npropagation through time. As can be observed from the equation, AGCRN uniﬁes all the embedding\\nmatrix to beEinstead of learning separate node embedding matrix in different NAPL-GCN layers\\nand DAGG. This gives a strong regularizer to ensure the nodes embedding consistent among all GCN\\nblocks and gives our model better interpretability.\\n3.5 Multi-step trafﬁc prediction\\nTo achieve multi-step trafﬁc prediction, we stack several AGCRN layers as an encoder to capture the\\nnode-speciﬁc spatial-temporal patterns and represents the input (i.e., historical data) as H2RN\\x02do.\\nThen, we can directly obtain the trafﬁc prediction for the next \\x1csteps of all nodes by applying a linear\\ntransformation to project the representation from RN\\x02dotoRN\\x02\\x1c. Here, we do not generate the\\noutput in the sequential manner as it would increase the time consumption signiﬁcantly.\\nWe choose L1 loss as our training objective and optimize the loss for multi-step prediction together.\\nThus, the loss function of AGCRN for multi-step trafﬁc prediction can be formulated as:\\nL(W\\x12)=i=t+\\x1cX\\ni=t+1jX:;i\\x00X0\\n:;ij (8)\\nwhereW\\x12represents all the learnable parameters in the network, X:;iis the ground truth, and X0\\n:;i\\nis the prediction of all nodes at time step i. The problem can be solved via back-propagation and\\nAdam optimizer.\\n4 Experiments\\n4.1 Datasets\\nTo evaluate the performance of our work, we conduct experiments on two public real-world trafﬁc\\ndatasets: PeMSD4 and PeMSD8 [ 6,11]. PeMS means Caltrans Performance Measure System (PeMS)\\n[38], which measures the highway trafﬁc of California in real-time every 30 seconds.\\nPeMSD4 : The PeMSD4 dataset refers to the trafﬁ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1529: ('in the network, X:;iis the ground truth, and X0\\n:;i\\nis the prediction of all nodes at time step i. The problem can be solved via back-propagation and\\nAdam optimizer.\\n4 Experiments\\n4.1 Datasets\\nTo evaluate the performance of our work, we conduct experiments on two public real-world trafﬁc\\ndatasets: PeMSD4 and PeMSD8 [ 6,11]. PeMS means Caltrans Performance Measure System (PeMS)\\n[38], which measures the highway trafﬁc of California in real-time every 30 seconds.\\nPeMSD4 : The PeMSD4 dataset refers to the trafﬁc ﬂow data in the San Francisco Bay Area. There\\nare 307 loop detectors selected within the period from 1/Jan/2018 to 28/Feb/2018.\\nPeMSD8 : The PeMSD8 dataset contains trafﬁc ﬂow information collected from 170 loop detectors\\non the San Bernardino area from 1/Jul/2016 - 31/Aug/2016.\\nData Preprocess: The missing values in the datasets are ﬁlled by linear interpolation. Then, both\\ndatasets are aggregated into 5-minute windows, resulting in 288 data points per day. Besides, we\\nnormalize the dataset by standard normalization method to make the training process more stable.\\nFor multi-step trafﬁc forecasting, we use one-hour historical data to predict the next hour’s data, i.e.,\\n5\\nwe organize 12 steps’ historical data as input and the following 12 steps data as output. We split the\\ndatasets into training sets, validation sets, and test sets according to the chronological order. The split\\nratio is 6:2:2 for both datasets. Although our method does not need a pre-deﬁned graph, we use the\\npre-deﬁned graph for our baselines. Detailed dataset statistics are provided in the appendix.\\n4.2 Experimental Settings\\nTo evaluate the overall performance of our work, we compare AGCRN with widely used baselines\\nand state-of-the-art models, including 1) Historical Average (HA): which models the trafﬁc as a\\nseasonal process and uses the average of previous seasons (e.g., the same time slot of previous days)\\nas the prediction; 2) Vector Auto-Regression (V AR) [ 39]: a time series model that captures spatial\\ncorrelations among all trafﬁc se', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1530: ('es. Detailed dataset statistics are provided in the appendix.\\n4.2 Experimental Settings\\nTo evaluate the overall performance of our work, we compare AGCRN with widely used baselines\\nand state-of-the-art models, including 1) Historical Average (HA): which models the trafﬁc as a\\nseasonal process and uses the average of previous seasons (e.g., the same time slot of previous days)\\nas the prediction; 2) Vector Auto-Regression (V AR) [ 39]: a time series model that captures spatial\\ncorrelations among all trafﬁc series; 3) GRU-ED: an GRU-based baseline and utilize the encoder-\\ndecoder framework [ 40] for multi-step time series prediction; 4) DSANet [ 41]: a correlated time\\nseries prediction model using CNN networks for capturing temporal correlations with one time-series\\nand self-attention mechanism for spatial correlations; 5) DCRNN [ 2]: diffusion convolution recurrent\\nneural network, which formulates the graph convolution with the diffusion process and combines\\nGCN with recurrent models in an encoder-decoder manner for multi-step prediction; 6) STGCN [ 4]: a\\nspatio-temporal graph convolutional network that deploys GCN and temporal convolution to capture\\nspatial and temporal correlations, respectively; 7) ASTGCN [ 6]: attention-based spatio-temporal\\ngraph convolutional network, which further integrates spatial and temporal attention mechanisms to\\nSTGCN for capturing dynamic spatial and temporal patterns. We take its recent components to ensure\\nthe fairness of comparison; 8) STSGCN [ 11]: Spatial-Temporal Synchronous Graph Convolutional\\nNetwork that captures spatial-temporal correlations by stacking multiple localized GCN layers with\\nadjacent matrix over the time axis.\\nAll the deep-learning-based models, including our AGCRN, are implemented in Python with Pytorch\\n1.3.1 and executed on a server with one NVIDIA Titan X GPU card. We optimize all the models by\\nAdam optimizer for a maximum of 100 epochs and use an early stop strategy with the patience of 15.\\nThe best parameters for all deep learning models are chosen through', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1531: ('Graph Convolutional\\nNetwork that captures spatial-temporal correlations by stacking multiple localized GCN layers with\\nadjacent matrix over the time axis.\\nAll the deep-learning-based models, including our AGCRN, are implemented in Python with Pytorch\\n1.3.1 and executed on a server with one NVIDIA Titan X GPU card. We optimize all the models by\\nAdam optimizer for a maximum of 100 epochs and use an early stop strategy with the patience of 15.\\nThe best parameters for all deep learning models are chosen through a carefully parameter-tuning\\nprocess on the validation set.\\n4.3 Overall Comparison\\nWe deploy three widely used metrics - Mean Absolute Error (MAE), Root Mean Square Error\\n(RMSE), and Mean Absolute Percentage Error (MAPE) to measure the performance of predictive\\nmodels. Table 1 presents the overall prediction performances, which are the averaged MAE, RMSE\\nand MAPE over 12 prediction horizons, of our AGCRN and eight representative comparison methods.\\nWe can observe that: 1) GCN-based methods outperform baselines and self-attention-based DSANet,\\ndemonstrating the importance of modeling spatial correlations explicitly and the effectiveness of\\nGCN in trafﬁc forecasting; 2) our method further improves GCN-based methods with a signiﬁcant\\nmargin. AGCRN brings more than 5% relative improvements to the existing best results in MAE and\\nMAPE for both PeMSD4 and PeMSD8 dataset. Fig. 2 further shows the prediction performance at\\neach horizon in the PeMSD4 dataset. AGCRN balances short-term and long-term prediction well\\nand achieves the best performance for almost all horizons (except for the ﬁrst step). Besides, the\\nperformance of AGCRN deteriorate much slower than other GCN-based models (see appendix for\\nsimilar results in the PeMSD8 dataset).\\nOverall, the results demonstrate that AGCRN can accurately capture the spatial and temporal correla-\\ntions in the correlated trafﬁc series and achieve promising predictions.\\n4.4 Ablation Study\\nTo better evaluate the performance of NAPL and DAGG, we conduct a comprehensive ablation\\nst', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1532: ('d achieves the best performance for almost all horizons (except for the ﬁrst step). Besides, the\\nperformance of AGCRN deteriorate much slower than other GCN-based models (see appendix for\\nsimilar results in the PeMSD8 dataset).\\nOverall, the results demonstrate that AGCRN can accurately capture the spatial and temporal correla-\\ntions in the correlated trafﬁc series and achieve promising predictions.\\n4.4 Ablation Study\\nTo better evaluate the performance of NAPL and DAGG, we conduct a comprehensive ablation\\nstudy. The baseline for our ablation study is GCGRU, which integrates traditional GCN with GRU\\nto capture spatial and temporal correlations. We construct NAPL-GCGRU by replacing traditional\\nGCN with our NAPL-GCN and DAGG-GCGRU by replacing the pre-deﬁned graph with the DAGG\\nmodule. AGCCRN-I is the variant of our AGCRN, which does not unify the node embeddings but\\nemploys an independent node embedding matrix among different NAPL-GCN layers and DAGG. The\\nexperiments on the PeMSD4 dataset are illustrated in Fig. 3. We can observe that: 1) NAPL-GCGRU\\ngenerally outperforms GCGRU and AGCRN-I outperforms DAGG-GCGRU, demonstrating the\\n6\\nTable 1: Overall prediction performance of different methods on the PeMSD4 dataset and PeMSD8\\ndataset, results with * are reported performance in the paper used the same datasets and results with\\n__ are the best performance achieved by baselines. (smaller value means better performance)\\nModelDataset PeMSD4 PeMSD8\\nMetrics MAE RMSE MAPE MAE RMSE MAPE\\nHA 38.03 59.24 27.88% 34.86 52.04 24.07%\\nV AR 24.54 38.61 17.24% 19.19 29.81 13.10%\\nGRU-ED 23.68 39.27 16.44% 22.00 36.23 13.33%\\nDSANet [41] 22.79 35.77 16.03% 17.14 26.96 11.32%\\nDCRNN [2] 21.22 33.44 14.17% 16.82 26.36 10.92%\\nSTGCN [4] 21.16 34.89 13.83% 17.50 27.09 11.29%\\nASTGCN [6] 22.93 35.22 16.56% 18.25 28.06 11.64%\\nSTSGCN [11] 21.19* 33.65* 13.90%* 17.13* 26.86* 10.96%*\\nAGCRN (ours) 19.83 32.26 12.97% 15.95 25.22 10.09%\\nImprovements +6.29% +3.52% +6.22% +5.17% +4.32% +7.60%\\n(a) MAE\\n (b) RMSE\\n (c) MAPE\\nFigure 2: Prediction performance com', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1533: ('7%\\nV AR 24.54 38.61 17.24% 19.19 29.81 13.10%\\nGRU-ED 23.68 39.27 16.44% 22.00 36.23 13.33%\\nDSANet [41] 22.79 35.77 16.03% 17.14 26.96 11.32%\\nDCRNN [2] 21.22 33.44 14.17% 16.82 26.36 10.92%\\nSTGCN [4] 21.16 34.89 13.83% 17.50 27.09 11.29%\\nASTGCN [6] 22.93 35.22 16.56% 18.25 28.06 11.64%\\nSTSGCN [11] 21.19* 33.65* 13.90%* 17.13* 26.86* 10.96%*\\nAGCRN (ours) 19.83 32.26 12.97% 15.95 25.22 10.09%\\nImprovements +6.29% +3.52% +6.22% +5.17% +4.32% +7.60%\\n(a) MAE\\n (b) RMSE\\n (c) MAPE\\nFigure 2: Prediction performance comparison at each horizon on the PeMSD4 dataset.\\nnecessity of capturing node-speciﬁc patterns. Moreover, NAPL mainly enhances the long-term (e.g.,\\n30Min and 60 Min) prediction but slightly harms the short-term (e.g., 5Min and 15 Min) prediction.\\nWe conjecture the reason is that long-term prediction lacks enough useful information from historical\\nobservations and thus beneﬁts from the speciﬁc node embedding learned by the NAPL module to\\ndeduce future patters. At the same time, short-term prediction can obtain enough information from\\nhistorical observations. 2) DAGG-GCGRU improves GCGRU, and AGCRN-I beats NAPL-GCGRU.\\nBoth demonstrate the superiority of DAGG in inferring spatial correlations. The results also indicate\\nthat GCN-based methods can potentially be applied to more general correlated time series forecasting\\ntasks with the help of our DAGG module, and pre-deﬁning an adjacent matrix is not necessary; 3)\\nAGCRN achieves the best performance, demonstrating that we can share the node embedding among\\nall the modules and learn a uniﬁed node embedding for each node from the data.\\nOverall, our NAPL and DAGG modules can be deployed either separately and jointly, and they\\nconsistently boost the prediction performance.\\n4.5 Model Analysis\\nGraph Generation To further investigate DAGG, we compare it with two variants: 1) DAGG-r,\\nwhich removes the identity matrix in Eq. 6; 2) DAGG-2 which mimics the second-order Chebyshev\\npolynomial expansion in GCN [ 4,33] with our learned D\\x001\\n2AD\\x001\\n2. The backbone network is\\nAGCRN-I, whi', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1534: ('dules and learn a uniﬁed node embedding for each node from the data.\\nOverall, our NAPL and DAGG modules can be deployed either separately and jointly, and they\\nconsistently boost the prediction performance.\\n4.5 Model Analysis\\nGraph Generation To further investigate DAGG, we compare it with two variants: 1) DAGG-r,\\nwhich removes the identity matrix in Eq. 6; 2) DAGG-2 which mimics the second-order Chebyshev\\npolynomial expansion in GCN [ 4,33] with our learned D\\x001\\n2AD\\x001\\n2. The backbone network is\\nAGCRN-I, which does not share the embedding matrix among NAPL-GCN and DAGG to avoid the\\nconstraints from the NAPL module. As shown in Table 2 (where DAGG-1 follows Eq. 6), removing\\nthe identity matrix from DAGG signiﬁcantly harms the prediction performance, which presents the\\n7\\n(a) MAE\\n (b) MAPE\\nFigure 3: Ablation study on the PeMSD4 dataset.\\nFigure 4: Inﬂuence of the embed-\\nding dimension.\\nimportance of highlighting the self-information manually in prediction. Besides, DAGG-2 achieves\\nsimilar performance with DAGG-1, which is consistent with the existing works [ 33,4,2] using\\npre-deﬁned graphs. The results reveal that the generated graph Laplacian matrix D\\x001\\n2AD\\x001\\n2shares\\nsimilar property as the pre-deﬁned graph in Chebyshev polynomial expansion.\\nTable 2: Analysis of graph generation process on the PeMSD4 dataset.\\nModel15 Min 60 Min Average\\nMAE RMSE MAPE MAE RMSE MAPE MAE RMSE MAPE\\nDAGG-r 21.85 35.03 14.96% 26.54 41.07 17.91% 23.35 37.07 15.82%\\nDAGG-1 19.15 30.65 13.15% 21.98 34.91 14.82% 20.18 32.30 13.70%\\nDAGG-2 19.26 31.20 13.06% 21.58 34.73 14.49% 20.11 32.56 13.58%\\nEmbedding Dimension One key parameter in AGCRN is the dimensions of the node embedding,\\nwhich not only inﬂuences the quality of the learned graph but also decides the parameter diversity\\nin NAPL-GCN layers. Fig. 4 shows the effects of different embedding dimensions to AGCRN on\\nthe PeMSD4 dataset. AGCRN obtains relatively good performance for all the tested embedding\\ndimensions, which shows the robustness of our methods. Besides, AGCRN achieves the best\\nper', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1535: (' 31.20 13.06% 21.58 34.73 14.49% 20.11 32.56 13.58%\\nEmbedding Dimension One key parameter in AGCRN is the dimensions of the node embedding,\\nwhich not only inﬂuences the quality of the learned graph but also decides the parameter diversity\\nin NAPL-GCN layers. Fig. 4 shows the effects of different embedding dimensions to AGCRN on\\nthe PeMSD4 dataset. AGCRN obtains relatively good performance for all the tested embedding\\ndimensions, which shows the robustness of our methods. Besides, AGCRN achieves the best\\nperformance when the embedding dimension is set to 10. Both an excessively small and large\\nnode embedding dimension will lead to weaker performance. On the one hand, node embedding\\nwith a larger dimension can contain more information and thus help our DAGG module to deduce\\nmore accurate spatial correlations. On the other hand, a larger node embedding dimension will\\nsigniﬁcantly increase the parameter numbers in the NAPL module, making the model harder to\\noptimize and causing over-ﬁtting. Overall, it would be a good practice for AGCRN to ﬁnd a suitable\\nnode embedding dimension and balance the model’s performance and complexity.\\nComputation Cost To evaluate the computation cost, we compare the parameter numbers and training\\ntime of AGCRN with DCRNN, STGCN, and ASTGCN on the PeMSD4 dataset in Table 3. When he\\nnode embedding dimension is set to 10, AGCRN has ﬁve times more parameters than the DCRNN\\nmodel as a sacriﬁce for learning node-speciﬁc patterns. In terms of the training time, AGCRN runs\\nslightly faster than DCRNN as we generate all predictions directly instead of the iterative manner in\\nDCRNN. STGCN is the fastest thanks to the temporal convolution structure. However, it will require\\nmore parameters and training time to add spatial and temporal attention mechanisms to STGCN\\nfor learning more accurate spatial-temporal patterns (e.g., ASTGCN). Considering the signiﬁcant\\nperformance improvement (as shown in Table 1), the computation cost of AGCRN is moderate.\\n5 Discussion\\nMultivariate/correlated time series predi', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1536: ('DCRNN as we generate all predictions directly instead of the iterative manner in\\nDCRNN. STGCN is the fastest thanks to the temporal convolution structure. However, it will require\\nmore parameters and training time to add spatial and temporal attention mechanisms to STGCN\\nfor learning more accurate spatial-temporal patterns (e.g., ASTGCN). Considering the signiﬁcant\\nperformance improvement (as shown in Table 1), the computation cost of AGCRN is moderate.\\n5 Discussion\\nMultivariate/correlated time series prediction is a fundamental task for many applications, such as\\nepidemic transmission forecasting [ 42], meteorology (e.g., air quality, rainfall) prediction [ 43], stock\\nforecasting [ 44], and sale prediction [ 45]. While our work is motivated by the trafﬁc forecasting task,\\nthe proposed two adaptive modules and our AGCRN model may also be adapted to a wide variety of\\nmultivariate/correlated time series predictive tasks separately or jointly. It is possible to automatically\\n8\\nTable 3: The computation cost on the PeMSD4 dataset, \"dim\" means the dimension of E.\\nModel # Parameters Training Time (epoch)\\nDCRNN 149057 36.39 s\\nSTGCN 211596 16.36 s\\nASTGCN 450031 49.47 s\\nAGCRN (dim=2) 150386 33.88 s\\nAGCRN (dim=10) 748810 35.56 s\\ndiscover the inter-dependency among different correlated series from data, which bridges the gap\\nbetween graph-based prediction models and general correlated time series forecasting problems that\\ncannot pre-deﬁne the graph easily. Our future work will focus on examining the scale-ability of our\\nwork from two perspectives: 1) data perspective - validating the performance of AGCRN on more\\ntime series prediction tasks; 2) model perspective - adapting NAPL and DAGG to more GCN-based\\ntrafﬁc forecasting models.\\n6 Conclusion\\nIn this paper, we propose to enhance the traditional graph convolutional network with node adaptive\\nparameter learning and data-adaptive graph generation modules for learning node-speciﬁc patterns\\nand discovering spatial correlations from data, separately. Based on the two modules, we ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1537: ('rk from two perspectives: 1) data perspective - validating the performance of AGCRN on more\\ntime series prediction tasks; 2) model perspective - adapting NAPL and DAGG to more GCN-based\\ntrafﬁc forecasting models.\\n6 Conclusion\\nIn this paper, we propose to enhance the traditional graph convolutional network with node adaptive\\nparameter learning and data-adaptive graph generation modules for learning node-speciﬁc patterns\\nand discovering spatial correlations from data, separately. Based on the two modules, we further\\npropose the Adaptive Graph Convolutional Recurrent Network, which can capture node-speciﬁc\\nspatial and temporal correlations in time-series data automatically without a pre-deﬁned graph.\\nExtensive experiments on multi-step trafﬁc forecasting tasks demonstrate the effectiveness of both\\nAGCRN and the proposed adaptive modules. This work sheds light on applying GCN-based models\\nin correlated time series forecasting by inferring the inter-dependency from data and reveals that\\nlearning node-speciﬁc patterns is essential for understanding correlated time series data.\\nBroader Impact\\nIn general, this work enables more accurate trafﬁc forecasting, which facilities the higher-lever trafﬁc\\nscheduling such as taxi dispatch and route planing. In this way, our work can help save time for\\ntravelers, improve efﬁciency and income for transport operators, and save energy consumption. In a\\nbroad sense, adaptability is desirable in correlated time series analysis for broad social and business\\napplications in the era of big data. The proposed adaptive modules enable elevated robustness of data\\nanalysis and relevant applications based on dynamic, interdependent, time-series data. This research\\ngenerally supports better modeling and analysis of multiple channels of data based on graph structures\\nwith complex explicit and implicit correlations. It has implications and potentially accelerates the\\nresearch progress in address many world-scale economic and societal issues that rely on complex\\ntimes series data, such as prediction', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1538: ('ig data. The proposed adaptive modules enable elevated robustness of data\\nanalysis and relevant applications based on dynamic, interdependent, time-series data. This research\\ngenerally supports better modeling and analysis of multiple channels of data based on graph structures\\nwith complex explicit and implicit correlations. It has implications and potentially accelerates the\\nresearch progress in address many world-scale economic and societal issues that rely on complex\\ntimes series data, such as predictions of inﬂuenza outbreak, economic growth, and climate change. A\\npotential negative impact of this work is the fairness problem in the ride-sharing platforms. In the\\ncase that cabs supply cannot guarantee demand, platforms may emphasize the predicted high-demand\\nareas too much, which would increase the waiting time of travelers in the low-demand areas.\\nReferences\\n[1]Corey Snyder and Minh Do. Streets: A novel camera network dataset for trafﬁc ﬂow. In\\nAdvances in Neural Information Processing Systems , pages 10242–10253, 2019.\\n[2]Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. Diffusion convolutional recurrent neural\\nnetwork: Data-driven trafﬁc forecasting. In the Sixth International Conference on Learning\\nRepresentations (ICLR) , 2018.\\n[3]Lei Bai, Lina Yao, Salil S Kanhere, Xianzhi Wang, and Quan Z Sheng. Stg2seq: spatial-temporal\\ngraph to sequence model for multi-step passenger demand forecasting. In Proceedings of the\\n9\\n28th International Joint Conference on Artiﬁcial Intelligence , pages 1981–1987. AAAI Press,\\n2019.\\n[4]Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-temporal graph convolutional networks: a\\ndeep learning framework for trafﬁc forecasting. In Proceedings of the 27th International Joint\\nConference on Artiﬁcial Intelligence , pages 3634–3640, 2018.\\n[5]Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. Graph wavenet\\nfor deep spatial-temporal graph modeling. In Proceedings of the 28th International Joint\\nConference on Artiﬁcial Intelligence , pages 1907–1913. AAAI Press, 2019.\\n[6]She', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1539: ('s,\\n2019.\\n[4]Bing Yu, Haoteng Yin, and Zhanxing Zhu. Spatio-temporal graph convolutional networks: a\\ndeep learning framework for trafﬁc forecasting. In Proceedings of the 27th International Joint\\nConference on Artiﬁcial Intelligence , pages 3634–3640, 2018.\\n[5]Zonghan Wu, Shirui Pan, Guodong Long, Jing Jiang, and Chengqi Zhang. Graph wavenet\\nfor deep spatial-temporal graph modeling. In Proceedings of the 28th International Joint\\nConference on Artiﬁcial Intelligence , pages 1907–1913. AAAI Press, 2019.\\n[6]Shengnan Guo, Youfang Lin, Ning Feng, Chao Song, and Huaiyu Wan. Attention based spatial-\\ntemporal graph convolutional networks for trafﬁc ﬂow forecasting. In Proceedings of the AAAI\\nConference on Artiﬁcial Intelligence , volume 33, pages 922–929, 2019.\\n[7]Lei Bai, Lina Yao, Salil S Kanhere, Zheng Yang, Jing Chu, and Xianzhi Wang. Passenger\\ndemand forecasting with multi-task convolutional recurrent neural networks. In Paciﬁc-Asia\\nConference on Knowledge Discovery and Data Mining , pages 29–42. Springer, 2019.\\n[8]Xianfeng Tang, Huaxiu Yao, Yiwei Sun, Charu Aggarwal, Prasenjit Mitra, and Suhang Wang.\\nJoint modeling of local and global temporal dynamics for multivariate time series forecasting\\nwith missing values. arXiv preprint arXiv:1911.10273 , 2019.\\n[9]Huaxiu Yao, Fei Wu, Jintao Ke, Xianfeng Tang, Yitian Jia, Siyu Lu, Pinghua Gong, Jieping\\nYe, and Zhenhui Li. Deep multi-view spatial-temporal network for taxi demand prediction. In\\nThirty-Second AAAI Conference on Artiﬁcial Intelligence , 2018.\\n[10] David Salinas, Valentin Flunkert, Jan Gasthaus, and Tim Januschowski. Deepar: Probabilistic\\nforecasting with autoregressive recurrent networks. International Journal of Forecasting , 2019.\\n[11] Chao Song, Youfang Lin, Shengnan Guo, and Huaiyu Wan. Spatial-temporal sychronous graph\\nconvolutional networks: A new framework for spatial-temporal network data forecasting. In\\nProceedings of the AAAI Conference on Artiﬁcial Intelligence , 2020.\\n[12] Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. Gman: A graph mult', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1540: (', Valentin Flunkert, Jan Gasthaus, and Tim Januschowski. Deepar: Probabilistic\\nforecasting with autoregressive recurrent networks. International Journal of Forecasting , 2019.\\n[11] Chao Song, Youfang Lin, Shengnan Guo, and Huaiyu Wan. Spatial-temporal sychronous graph\\nconvolutional networks: A new framework for spatial-temporal network data forecasting. In\\nProceedings of the AAAI Conference on Artiﬁcial Intelligence , 2020.\\n[12] Chuanpan Zheng, Xiaoliang Fan, Cheng Wang, and Jianzhong Qi. Gman: A graph multi-\\nattention network for trafﬁc prediction. arXiv preprint arXiv:1911.08415 , 2019.\\n[13] Zheyi Pan, Yuxuan Liang, Weifeng Wang, Yong Yu, Yu Zheng, and Junbo Zhang. Urban trafﬁc\\nprediction from spatio-temporal data using deep meta learning. In Proceedings of the 25th ACM\\nSIGKDD International Conference on Knowledge Discovery & Data Mining , pages 1720–1730,\\n2019.\\n[14] Xu Geng, Yaguang Li, Leye Wang, Lingyu Zhang, Qiang Yang, Jieping Ye, and Yan Liu.\\nSpatiotemporal multi-graph convolution network for ride-hailing demand forecasting. In\\nProceedings of the AAAI Conference on Artiﬁcial Intelligence , volume 33, pages 3656–3663,\\n2019.\\n[15] Porter Jenkins, Ahmad Farag, Suhang Wang, and Zhenhui Li. Unsupervised representation learn-\\ning of spatial data via multimodal embedding. In Proceedings of the 28th ACM International\\nConference on Information and Knowledge Management , pages 1993–2002, 2019.\\n[16] Can Li, Lei Bai, Wei Liu, Lina Yao, and S Travis Waller. Knowledge adaption for demand\\nprediction based on multi-task memory neural network. In Proceedings of the 28th ACM\\nInternational Conference on Information and Knowledge Management , 2020.\\n[17] Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua\\nBengio. A recurrent latent variable model for sequential data. In Advances in neural information\\nprocessing systems , pages 2980–2988, 2015.\\n[18] Yonghong Luo, Xiangrui Cai, Ying Zhang, Jun Xu, et al. Multivariate time series imputation\\nwith generative adversarial networks. In Advances in ', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1541: (' memory neural network. In Proceedings of the 28th ACM\\nInternational Conference on Information and Knowledge Management , 2020.\\n[17] Junyoung Chung, Kyle Kastner, Laurent Dinh, Kratarth Goel, Aaron C Courville, and Yoshua\\nBengio. A recurrent latent variable model for sequential data. In Advances in neural information\\nprocessing systems , pages 2980–2988, 2015.\\n[18] Yonghong Luo, Xiangrui Cai, Ying Zhang, Jun Xu, et al. Multivariate time series imputation\\nwith generative adversarial networks. In Advances in Neural Information Processing Systems ,\\npages 1596–1607, 2018.\\n10\\n[19] Syama Sundar Rangapuram, Matthias W Seeger, Jan Gasthaus, Lorenzo Stella, Yuyang Wang,\\nand Tim Januschowski. Deep state space models for time series forecasting. In Advances in\\nneural information processing systems , pages 7785–7794, 2018.\\n[20] Wei Cao, Dong Wang, Jian Li, Hao Zhou, Lei Li, and Yitan Li. Brits: Bidirectional recurrent\\nimputation for time series. In Advances in Neural Information Processing Systems , pages\\n6775–6785, 2018.\\n[21] Guokun Lai, Wei-Cheng Chang, Yiming Yang, and Hanxiao Liu. Modeling long-and short-term\\ntemporal patterns with deep neural networks. In The 41st International ACM SIGIR Conference\\non Research & Development in Information Retrieval , pages 95–104, 2018.\\n[22] Anastasia Borovykh, Sander Bohte, and Cornelis W Oosterlee. Conditional time series forecast-\\ning with convolutional neural networks. arXiv preprint arXiv:1703.04691 , 2017.\\n[23] Shaojie Bai, J Zico Kolter, and Vladlen Koltun. An empirical evaluation of generic convolutional\\nand recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 , 2018.\\n[24] Rajat Sen, Hsiang-Fu Yu, and Inderjit S Dhillon. Think globally, act locally: A deep neural net-\\nwork approach to high-dimensional time series forecasting. In Advances in Neural Information\\nProcessing Systems , pages 4838–4847, 2019.\\n[25] Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing Gao, Weiyao Lin, Guo-Jun Qi, and Hongkai\\nXiong. Spatial-temporal transformer networks for trafﬁc ﬂow forecast', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1542: ('ion of generic convolutional\\nand recurrent networks for sequence modeling. arXiv preprint arXiv:1803.01271 , 2018.\\n[24] Rajat Sen, Hsiang-Fu Yu, and Inderjit S Dhillon. Think globally, act locally: A deep neural net-\\nwork approach to high-dimensional time series forecasting. In Advances in Neural Information\\nProcessing Systems , pages 4838–4847, 2019.\\n[25] Mingxing Xu, Wenrui Dai, Chunmiao Liu, Xing Gao, Weiyao Lin, Guo-Jun Qi, and Hongkai\\nXiong. Spatial-temporal transformer networks for trafﬁc ﬂow forecasting. arXiv preprint\\narXiv:2001.02908 , 2020.\\n[26] Yunkai Zhang, Qiao Jiang, Shurui Li, Xiaoyong Jin, Xueying Ma, and Xifeng Yan. You may\\nnot need order in time series forecasting. arXiv preprint arXiv:1910.09620 , 2019.\\n[27] Junbo Zhang, Yu Zheng, Dekang Qi, Ruiyuan Li, and Xiuwen Yi. Dnn-based prediction\\nmodel for spatio-temporal data. In Proceedings of the 24th ACM SIGSPATIAL International\\nConference on Advances in Geographic Information Systems , pages 1–4, 2016.\\n[28] Junbo Zhang, Yu Zheng, and Dekang Qi. Deep spatio-temporal residual networks for citywide\\ncrowd ﬂows prediction. In Thirty-First AAAI Conference on Artiﬁcial Intelligence , 2017.\\n[29] Lei Bai, Lina Yao, Salil S Kanhere, Xianzhi Wang, Wei Liu, and Zheng Yang. Spatio-temporal\\ngraph convolutional and recurrent networks for citywide passenger demand prediction. In\\nProceedings of the 28th ACM International Conference on Information and Knowledge Man-\\nagement , pages 2293–2296, 2019.\\n[30] Jiexia Ye, Juanjuan Zhao, Kejiang Ye, and Chengzhong Xu. How to build a graph-based deep\\nlearning architecture in trafﬁc domain: A survey. arXiv preprint arXiv:2005.11691 , 2020.\\n[31] Xueyan Yin, Genze Wu, Jinze Wei, Yanming Shen, Heng Qi, and Baocai Yin. A comprehensive\\nsurvey on trafﬁc prediction. arXiv preprint arXiv:2004.08555 , 2020.\\n[32] Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks\\non graphs with fast localized spectral ﬁltering. In Advances in neural information processing\\nsystems , pages 3844–3852, 2016.\\n[33] Th', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1543: (' to build a graph-based deep\\nlearning architecture in trafﬁc domain: A survey. arXiv preprint arXiv:2005.11691 , 2020.\\n[31] Xueyan Yin, Genze Wu, Jinze Wei, Yanming Shen, Heng Qi, and Baocai Yin. A comprehensive\\nsurvey on trafﬁc prediction. arXiv preprint arXiv:2004.08555 , 2020.\\n[32] Michaël Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks\\non graphs with fast localized spectral ﬁltering. In Advances in neural information processing\\nsystems , pages 3844–3852, 2016.\\n[33] Thomas N Kipf and Max Welling. Semi-supervised classiﬁcation with graph convolutional\\nnetworks. arXiv preprint arXiv:1609.02907 , 2016.\\n[34] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. A\\ncomprehensive survey on graph neural networks. IEEE Transactions on Neural Networks and\\nLearning Systems , 2020.\\n[35] Petar Veli ˇckovi ´c, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua\\nBengio. Graph attention networks. arXiv preprint arXiv:1710.10903 , 2017.\\n[36] Zhitao Ying, Jiaxuan You, Christopher Morris, Xiang Ren, Will Hamilton, and Jure Leskovec.\\nHierarchical graph representation learning with differentiable pooling. In Advances in neural\\ninformation processing systems , pages 4800–4810, 2018.\\n11\\n[37] Tanwi Mallick, Prasanna Balaprakash, Eric Rask, and Jane Macfarlane. Graph-partitioning-\\nbased diffusion convolution recurrent neural network for large-scale trafﬁc forecasting. arXiv\\npreprint arXiv:1909.11197 , 2019.\\n[38] Chao Chen, Karl Petty, Alexander Skabardonis, Pravin Varaiya, and Zhanfeng Jia. Freeway\\nperformance measurement system: mining loop detector data. Transportation Research Record ,\\n1748(1):96–102, 2001.\\n[39] Eric Zivot and Jiahui Wang. Vector autoregressive models for multivariate time series. Modeling\\nFinancial Time Series with S-Plus® , pages 385–429, 2006.\\n[40] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares,\\nHolger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-\\ndecod', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1544: ('Skabardonis, Pravin Varaiya, and Zhanfeng Jia. Freeway\\nperformance measurement system: mining loop detector data. Transportation Research Record ,\\n1748(1):96–102, 2001.\\n[39] Eric Zivot and Jiahui Wang. Vector autoregressive models for multivariate time series. Modeling\\nFinancial Time Series with S-Plus® , pages 385–429, 2006.\\n[40] Kyunghyun Cho, Bart Van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares,\\nHolger Schwenk, and Yoshua Bengio. Learning phrase representations using rnn encoder-\\ndecoder for statistical machine translation. arXiv preprint arXiv:1406.1078 , 2014.\\n[41] Siteng Huang, Donglin Wang, Xuehan Wu, and Ao Tang. Dsanet: Dual self-attention network for\\nmultivariate time series forecasting. In Proceedings of the 28th ACM International Conference\\non Information and Knowledge Management , pages 2129–2132, 2019.\\n[42] Bijaya Adhikari, Xinfeng Xu, Naren Ramakrishnan, and B Aditya Prakash. Epideep: Exploiting\\nembeddings for epidemic forecasting. In Proceedings of the 25th ACM SIGKDD International\\nConference on Knowledge Discovery & Data Mining , pages 577–586, 2019.\\n[43] Yawen Zhang, Qin Lv, Duanfeng Gao, Si Shen, Robert Dick, Michael Hannigan, and Qi Liu.\\nMulti-group encoder-decoder networks to fuse heterogeneous data for next-day air quality\\nprediction. In Proceedings of the 28th International Joint Conference on Artiﬁcial Intelligence ,\\npages 4341–4347. AAAI Press, 2019.\\n[44] Chang Li, Dongjin Song, and Dacheng Tao. Multi-task recurrent neural networks and higher-\\norder markov random ﬁelds for stock price movement prediction: Multi-task rnn and higer-order\\nmrfs for stock price classiﬁcation. In Proceedings of the 25th ACM SIGKDD International\\nConference on Knowledge Discovery & Data Mining , pages 1141–1151, 2019.\\n[45] Yan Qi, Chenliang Li, Han Deng, Min Cai, Yunwei Qi, and Yuming Deng. A deep neural\\nframework for sales forecasting in e-commerce. In Proceedings of the 28th ACM International\\nConference on Information and Knowledge Management , pages 299–308, 2019.\\n12', 'Adaptive Graph Convolutional Recurrent Network.pdf'), 1545: ('COGNITIVE SCIENCE 9, 147-169 (1985) \\nA Learning Algorithm for \\nBoltzmann Machines* \\nDAVID H. ACKLEY \\nGEOFFREY E. HINTON \\nComputer Science Department \\nCarnegie-Mellon University \\nTERRENCE J. SEJNOWSKI \\nBiophysics Department \\nThe Johns Hopkins University \\nThe computotionol power of massively parallel networks of simple processing \\nelements resides in the communication bandwidth provided by the hardware \\nconnections between elements. These connections con allow a significant \\nfraction of the knowledge of the system to be applied to an instance of a prob- \\nlem in o very short time. One kind of computation for which massively porollel \\nnetworks appear to be well suited is large constraint satisfaction searches, \\nbut to use the connections efficiently two conditions must be met: First, a \\nsearch technique that is suitable for parallel networks must be found. Second, \\nthere must be some way of choosing internal representations which allow the \\npreexisting hardware connections to be used efficiently for encoding the con- \\nstraints in the domain being searched. We describe a generol parallel search \\nmethod, based on statistical mechanics, and we show how it leads to a gen- \\neral learning rule for modifying the connection strengths so as to incorporate \\nknowledge obout o task domain in on efficient way. We describe some simple \\nexamples in which the learning algorithm creates internal representations \\nthot ore demonstrobly the most efficient way of using the preexisting connec- \\ntivity structure. \\n1. INTRODUCTION \\nEvidence about the architecture of the brain and the potential of the new \\nVLSI technology have led to a resurgence of interest in “connectionist” sys- \\nl The research reported here was supported by grants from the System Development \\nFoundation. We thank Peter Brown, Francis Crick, Mark Derthick, Scott Fahlman, Jerry \\nFeldman, Stuart Geman, Gail Gong, John Hopfield, Jay McClelland, Barak Pearlmutter, \\nHarry Printz, Dave Rumelhart, Tim Shallice, Paul Smolensky, Rick Szeliski, and Venkatara- \\nman Venkatasubramania', 'A Learning Algorithm for Boltzmann machines.pdf'), 1546: ('ce about the architecture of the brain and the potential of the new \\nVLSI technology have led to a resurgence of interest in “connectionist” sys- \\nl The research reported here was supported by grants from the System Development \\nFoundation. We thank Peter Brown, Francis Crick, Mark Derthick, Scott Fahlman, Jerry \\nFeldman, Stuart Geman, Gail Gong, John Hopfield, Jay McClelland, Barak Pearlmutter, \\nHarry Printz, Dave Rumelhart, Tim Shallice, Paul Smolensky, Rick Szeliski, and Venkatara- \\nman Venkatasubramanian for helpful discussions. \\nReprint requests should be addressed to David Ackley, Computer Science Department, \\nCarnegie-Mellon University, Pittsburgh, PA 15213. \\n147 \\n148 ACKLEY. HINTON. AND SEJNOWSKI \\nterns (Feldman & Ballard, 1982; Hinton & Anderson, 1981) that store their \\nlong-term knowledge as the strengths of the connections between simple \\nneuron-like processing elements. These networks are clearly suited to tasks \\nlike vision that can be performed efficiently in parallel networks which have \\nphysical connections in just the places where processes need to communicate. \\nFor problems like surface interpolation from sparse depth data (Crimson, \\n1981; Terzopoulos, 1984) where the necessary decision units and communi- \\ncation paths can be determined in advance, it is relatively easy to see how to \\nmake good use of massive parallelism. The more difficult problem is to dis- \\ncover parallel organizations that do not require so much problem-dependent \\ninformation to be built into the architecture of the network. Ideally, such a \\nsystem would adapt a given structure of processors and communication \\npaths to whatever problem it was faced with. \\nThis paper presents a type of parallel constraint satisfaction network \\nwhich we call a “Boltzmann Machine” that is capable of learning the under- \\nlying constraints that characterize a domain simply by being shown exam- \\nples from the domain. The network modifies the strengths of its connections \\nso as to construct an internal generarive model that produces examples with \\n', 'A Learning Algorithm for Boltzmann machines.pdf'), 1547: ('k. Ideally, such a \\nsystem would adapt a given structure of processors and communication \\npaths to whatever problem it was faced with. \\nThis paper presents a type of parallel constraint satisfaction network \\nwhich we call a “Boltzmann Machine” that is capable of learning the under- \\nlying constraints that characterize a domain simply by being shown exam- \\nples from the domain. The network modifies the strengths of its connections \\nso as to construct an internal generarive model that produces examples with \\nthe same probability distribution as the examples it is shown. Then, when \\nshown any particular example, the network can “interpret” it by finding \\nvalues of the variables in the internal model that would generate the exam- \\nple. When shown a partial example, the network can complete it by finding \\ninternal variable values that generate the partial example and using them to \\ngenerate the remainder. At present, we have an interesting mathematical \\nresult that guarantees that a certain learning procedure will build internal \\nrepresentations which allow the connection strengths to capture the under- \\nlying constraints that are implicit in a large ensemble of examples taken \\nfrom a domain. We also have simulations which show that the theory works \\nfor some simple cases, but the current version of the learning algorithm is \\nvery slow. \\nThe search for general principles that allow parallel networks to learn \\nthe structure of their environment has often begun with the assumption that \\nnetworks are randomly wired. This seems to us to be just as wrong as the \\nview that all knowledge is innate. If there are connectivity structures that \\nare good for particular tasks that the network will have to perform, it is \\nmuch more efficient to build these in at the start. However, not all tasks can \\nbe foreseen, and even for ones that can, fine-tuning may still be helpful. \\nAnother common belief is that a general connectionist learning rule \\nwould make sequential “rule-based” models unnecessary. We believe that \\nthis view stems fr', 'A Learning Algorithm for Boltzmann machines.pdf'), 1548: ('is seems to us to be just as wrong as the \\nview that all knowledge is innate. If there are connectivity structures that \\nare good for particular tasks that the network will have to perform, it is \\nmuch more efficient to build these in at the start. However, not all tasks can \\nbe foreseen, and even for ones that can, fine-tuning may still be helpful. \\nAnother common belief is that a general connectionist learning rule \\nwould make sequential “rule-based” models unnecessary. We believe that \\nthis view stems from a misunderstanding of the need for multiple levels of \\ndescription of large systems, which can be usefully viewed as either parallel \\nor serial depending on the grain of the analysis. ,Most of the key issues and \\nquestions that have been studied in the context of sequential models do not \\nmagically disappear in connectionist models. It is still necessary to perform \\nBOLTZMANN MACHINE LEARNING 149 \\nsearches for good solutions to problems or good interpretations of percep- \\ntual input, and to create complex internal representations. Ultimately it will \\nbe necessary to bridge the gap between hardware-oriented connectionist \\ndescriptions and the more abstract symbol manipulation models that have \\nproved to be an extremely powerful and pervasive way of describing human \\ninformation processing (Newell & Simon, 1972). \\n2. THE BOLTZMANN MACHINE \\nThe Boltzmann Machine is a parallel computational organization that is \\nwell suited to constraint satisfaction tasks involving large numbers of \\n“weak” constraints. Constraint-satisfaction searches (e.g., Waltz, 1975; \\nWinston, 1984) normally use “strong” constraints that tnusl be satisfied by \\nany solution. In problem domains such as games and puzzles, for example, \\nthe goal criteria often have this character, so strong constraints are the rule.’ \\nIn some problem domains, such as finding the most plausible interpretation \\nof an image, many of the criteria are not all-or-none, and frequently even \\nthe best possible solution violates some constraints (Hinton, 1977). A varia- ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1549: ('aint-satisfaction searches (e.g., Waltz, 1975; \\nWinston, 1984) normally use “strong” constraints that tnusl be satisfied by \\nany solution. In problem domains such as games and puzzles, for example, \\nthe goal criteria often have this character, so strong constraints are the rule.’ \\nIn some problem domains, such as finding the most plausible interpretation \\nof an image, many of the criteria are not all-or-none, and frequently even \\nthe best possible solution violates some constraints (Hinton, 1977). A varia- \\ntion that is more appropriate for such domains uses weak constraints that \\nincur a cost when violated. The quality of a solution is then determined by \\nthe total cost of all the constraints that it violates. In a perceptual interpre- \\ntation task, for example, this total cost should reflect the implausibility of \\nthe interpretation. \\nThe machine is composed of primitive computing elements called unifs \\nthat are connected to each other by bidirectional links. A unit is always in \\none of two states, on or off, and it adopts these states as a probabilistic \\nfunction of the states of its neighboring units and the weighfs on its links to \\nthem. The weights can take on real values of either sign. A unit being on or \\noff is taken to mean that the system currently accepts or rejects some ele- \\nmental hypothesis about the domain. The weight on a link represents a weak \\npairwise constraint between two hypotheses. A positive weight indicates \\nthat the two hypotheses tend to support one another; if one is currently ac- \\ncepted, accepting the other should be more likely. Conversely, a negative \\nweight suggests, other things being equal, that the two hypotheses should \\nnot both be accepted. Link weights are symmetric, having the same strength \\nin both directions (Hinton & Sejnowski, 1983).’ \\n’ But, see (Berliner & Ackley, 1982) for argument that, even in such domains, strong \\nconstraints must be used only where absolutely necessary for legal play, and in particular must \\nnot propagate into the determination of good play. \\n2', 'A Learning Algorithm for Boltzmann machines.pdf'), 1550: ('\\ncepted, accepting the other should be more likely. Conversely, a negative \\nweight suggests, other things being equal, that the two hypotheses should \\nnot both be accepted. Link weights are symmetric, having the same strength \\nin both directions (Hinton & Sejnowski, 1983).’ \\n’ But, see (Berliner & Ackley, 1982) for argument that, even in such domains, strong \\nconstraints must be used only where absolutely necessary for legal play, and in particular must \\nnot propagate into the determination of good play. \\n2 Requiring the weights to be symmetric may seem IO restrict the constraints that can be \\nrepresented. Although a constraint on boolean variables A and B such as “A = B with a penalty \\nof 2 points for violation” is obviously symmetric in A and B, “A =>f3 with a penalty of 2 \\npoints for violation” appears to be fundamentally asymmetric. Nevertheless, this constraint \\ncan be represented by the combination of a constraint on A alone and a symmetric pairwise \\nconstraint as follows: “Lose 2 points if A is true” and “Win 2 points if both A and E are true.” \\n150 ACKLEY. HINTON. AND SEJNOWSKI \\nThe resulting structure is related to a system described by Hopfield \\n(1982), and as in his system, each global state of the network can be assigned \\na single number called the “energy” of that state. With the right assump- \\ntions, the individual units can be made to act so as to minimize fhe global \\nenergy. If some of the units are externally forced or “clamped” into partic- \\nular states to represent a particular input, the system will then find the mini- \\nmum energy configuration that is compatible with that input. The energy of \\na configuration can be interpreted as the extent to which that combination \\nof hypotheses violates the constraints implicit in the problem domain, so in \\nminimizing energy the system evolves towards “interpretations” of that in- \\nput that increasingly satisfy the constraints of the problem domain. \\nThe energy of a global configuration is defined as \\nE= -,Z,w,s,s,+CB,s, (1) \\nwhere w,, is the strength of ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1551: ('tem will then find the mini- \\nmum energy configuration that is compatible with that input. The energy of \\na configuration can be interpreted as the extent to which that combination \\nof hypotheses violates the constraints implicit in the problem domain, so in \\nminimizing energy the system evolves towards “interpretations” of that in- \\nput that increasingly satisfy the constraints of the problem domain. \\nThe energy of a global configuration is defined as \\nE= -,Z,w,s,s,+CB,s, (1) \\nwhere w,, is the strength of connection between units i andj, S, is 1 if unit i is \\non and 0 otherwise, and Bi is a threshold. \\n2.1 Minimizing Energy \\nA simple algorithm for finding a combination of truth values that is a local \\nminimum is to switch each hypothesis into whichever of its two states yields \\nthe lower total energy given the current states of the other hypotheses. If \\nhardware units make their decisions asynchronously, and if transmission \\ntimes are negligible, then the system always settles into a local energy mini- \\nmum (Hopfield, 1982). Because the connections are symmetric, the differ- \\nence between the energy of the whole system with the krh hypothesis rejected \\nand its energy with the kfh hypothesis accepted can be determined locally by \\nthe k’h unit, and this “energy gap” is just \\nTherefore, the rule for minimizing the energy contributed by a unit is \\nto adopt the on state if its total input from the other units and from outside \\nthe system exceeds its threshold. This is the familiar rule for binary thresh- \\nold units. \\nThe threshold terms can be eliminated from Eqs. (1) and (2) by making \\nthe following observation: the effect of Bi on the global energy or on the \\nenergy gap of an individual unit is identical to the effect of a link with strength \\n- Bi between unit i and a special unit that is by definition always held in the \\non state. This “true unit” need have no physical reality, but it simplifies the \\ncomputations by allowing the threshold of a unit to be treated in the same \\nmanner as the links. The value - 0, is ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1552: ('. \\nThe threshold terms can be eliminated from Eqs. (1) and (2) by making \\nthe following observation: the effect of Bi on the global energy or on the \\nenergy gap of an individual unit is identical to the effect of a link with strength \\n- Bi between unit i and a special unit that is by definition always held in the \\non state. This “true unit” need have no physical reality, but it simplifies the \\ncomputations by allowing the threshold of a unit to be treated in the same \\nmanner as the links. The value - 0, is called the bias of unit i. If a perma- \\nBOLTZMANN MACHINE LEARNING 151 \\nnently active “true unit” is assumed to be part of every network, then Eqs. \\n(1) and (2) can be written as: \\nE = - i$j w;, si s, \\nAE~=cw~i.si \\n2.2 Using Noise to Escape from Local Minima \\nThe simple, deterministic algorithm suffers from the standard weakness of \\ngradient descent methods: It gets stuck in local minima that are not globally \\noptimal. This is not a problem in Hopfield’s system because the local energy \\nminima of his network are used to store “items”: If the system is started \\nnear some local minimum, the desired behavior is to fall into that minimum, \\nnot to find the global minimum. For constraint satisfaction tasks, however, \\nthe system must try to escape from local minima in order to find the con- \\nfiguration that is the global minimum given the current input. \\nA simple way to get out of local minima is to occasionally allow jumps \\nto configurations of higher energy. An algorithm with this property was in- \\ntroduced by Metropolis, Rosenbluth, Rosenbluth, Teller, & Teller (1953) to \\nstudy average properties of thermodynamic systems (Binder, 1978) and has \\nrecently been applied to problems of constraint satisfaction (Kirkpatrick, \\nGelatt, & Vecchi, 1983). We adopt a form of the Metroplis algorithm that is \\nsuitable for parallel computation: If the energy gap between the on and off \\nstates of the klh unit is AE, then regardless of the previous state sets* = 1 with \\nprobability \\n1 p*= (1 + PQ’r) (5) \\nwhere T is a parameter that ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1553: ('ropolis, Rosenbluth, Rosenbluth, Teller, & Teller (1953) to \\nstudy average properties of thermodynamic systems (Binder, 1978) and has \\nrecently been applied to problems of constraint satisfaction (Kirkpatrick, \\nGelatt, & Vecchi, 1983). We adopt a form of the Metroplis algorithm that is \\nsuitable for parallel computation: If the energy gap between the on and off \\nstates of the klh unit is AE, then regardless of the previous state sets* = 1 with \\nprobability \\n1 p*= (1 + PQ’r) (5) \\nwhere T is a parameter that acts like temperature (see Figure 1). \\nFigure 1. Eq. (5) at T= 1 .O (solid), T=4.0 (dashed), and T=0.25 (dotfed). \\n152 ACKLEY. HINTON. AND SEJNOWSKI \\nThe decision rule in Eq. (5) is the same as that for a particle which has \\ntwo energy states. A system of such particles in contact with a heat bath at a \\ngiven temperature will eventually reach thermal equilibrium and the proba- \\nbility of finding the system in any global state will then obey a Boltzmann \\ndistribution. Similarly, a network of units obeying this decision rule will \\neventually reach “thermal equilibrium” and the relative probability of two \\nglobal states will follow the Boltzman distribution: \\n(6) \\nwhere P, is the probability of being in the CI’~ global state, and E, is the \\nenergy of that state. \\nThe Boltzmann distribution has some beautiful mathematical proper- \\nties and it is intimately related to information theory. In particular, the dif- \\nference in the log probabilities of two global states is just their energy differ- \\nence (at a temperature of I). The simplicity of this relationship and the fact \\nthat the equilibrium distribution is independent of the path followed in \\nreaching equilibrium are what make Boltzmann machines interesting. \\nAt low temperatures there is a strong bias in favor of states with low \\nenergy, but the time required to reach equilibrium may be long. At higher \\ntemperatures the bias is not so favorable but equilibrium is reached faster. \\nA good way to beat this trade-off is to start at a high temperature and grad- \\nually', 'A Learning Algorithm for Boltzmann machines.pdf'), 1554: ('ure of I). The simplicity of this relationship and the fact \\nthat the equilibrium distribution is independent of the path followed in \\nreaching equilibrium are what make Boltzmann machines interesting. \\nAt low temperatures there is a strong bias in favor of states with low \\nenergy, but the time required to reach equilibrium may be long. At higher \\ntemperatures the bias is not so favorable but equilibrium is reached faster. \\nA good way to beat this trade-off is to start at a high temperature and grad- \\nually reduce it. This corresponds to annealing a physical system (Kirkpatrick, \\nGelatt, & Vecchi, 1983). At high temperatures, the network will ignore small \\nenergy differences and will rapidly approach equilibrium. In doing so, it will \\nperform a search of the coarse overall structure of the space of global states, \\nand will find a good minimum at that coarse level. As the temperature is \\nlowered, it will begin to respond to smaller energy differences and will find \\none of the better minima within the coarse-scale minimum it discovered at \\nhigh temperature. Kirkpatrick et al. have shown that this way of searching \\nthe coarse structure before the fine is very effective for combinatorial prob- \\nlems like graph partitioning, and we believe it will also prove useful when \\ntrying to satisfy multiple weak constraints, even though it will clearly fail in \\ncases where the best solution corresponds to a minimum that is deep, nar- \\nrow, and isolated. \\n3. A LEARNING ALGORITHM \\nPerhaps the most interesting aspect of the Boltzmann Machine formulation \\nis that it leads to a domain-independent learning algorithm that modifies the \\nBOLTZMANN MACHINE LEARNING 153 \\nconnection strengths between units in such a way that the whole network \\ndevelops an internal model which captures the underlying structure of its \\nenvironment. There has been a long history of failure in the search for such \\nalgorithms (Newell, 1982), and many people (particularly in Artificial In- \\ntelligence) now believe that no such algorithms exist. The major technic', 'A Learning Algorithm for Boltzmann machines.pdf'), 1555: ('zmann Machine formulation \\nis that it leads to a domain-independent learning algorithm that modifies the \\nBOLTZMANN MACHINE LEARNING 153 \\nconnection strengths between units in such a way that the whole network \\ndevelops an internal model which captures the underlying structure of its \\nenvironment. There has been a long history of failure in the search for such \\nalgorithms (Newell, 1982), and many people (particularly in Artificial In- \\ntelligence) now believe that no such algorithms exist. The major technical \\nstumbling block which prevented the generalization of simple learning \\nalgorithms to more complex networks was this: To be capable of interesting \\ncomputations, a network must contain nonlinear elements that are not \\ndirectly constrained by the input, and when such a network does the wrong \\nthing it appears to be impossible to decide which of the many connection \\nstrengths is at fault. This “credit-assignment” problem was what led to the \\ndemise of perceptrons (Minsky & Papert, 1968; Rosenblatt, 1961). The \\nperceptron convergence theorem guarantees that the weights of a single \\nlayer of decision units can be trained, but it could not be generalized to net- \\nworks of such units when the task did not directly specify how to use all the \\nunits in the network. \\nThis version of the credit-assignment problem can be solved within the \\nBoltzmann Machine formulation. By using the right stochastic decision \\nrule, and by running the network until it reaches “thermal equilibrium” at \\nsome finite temperature, we achieve a mathematically simple relationship \\nbetween the probability of a global state and its energy. For a network that \\nis running freely without any input from the environment, this relationship \\nis given by Eq. (6). Because the energy is a liueur function of the weights \\n(Eq. 1) this leads to a remarkably simple relationship between the log proba- \\nbilities of global states and the individual connection strengths: \\na In P,, \\na M’,, = +.m - PiI \\nwhere s: is the state of the ifh unit in the & global state (s', 'A Learning Algorithm for Boltzmann machines.pdf'), 1556: ('ve a mathematically simple relationship \\nbetween the probability of a global state and its energy. For a network that \\nis running freely without any input from the environment, this relationship \\nis given by Eq. (6). Because the energy is a liueur function of the weights \\n(Eq. 1) this leads to a remarkably simple relationship between the log proba- \\nbilities of global states and the individual connection strengths: \\na In P,, \\na M’,, = +.m - PiI \\nwhere s: is the state of the ifh unit in the & global state (so .c’:s;’ is 1 only if \\nunits i andj are both on in state CY), and p,; is just the probability of finding \\nthe two units i andj on at the same time when the system is at equilibrium. \\nGiven Eq. (7). it is possible to manipulate the log probabilities of global \\nstates. If the environment directly specifies the required probabilities P, for \\neach global state (Y, there is a straightforward way of converging on a set of \\nweights that achieve those probabilities, provided any such set exists (for \\ndetails, see Hinton & Sejnowski, 1983a). However, this is not a particularly \\ninteresting kind of learning because the system has to be given the required \\nprobabilities of co/up/e/e global states. This means that the central question \\nof what internal representation should be used has already been decided by \\nthe environment. The interesting problem arises when the environment im- \\nplicitly contains high-order constraints and the network must choose inter- \\nnal representations that allow these constraints to be expressed efficiently. \\n154 ACKLEY. HINTON, AND SEJNOWSKI \\n3.1 Modeling the Underlying Structure of an Environment \\nThe units of a Boltzmann Machine partition into two functional groups, a \\nnonempty set of visible units and a possibly empty set of hidden units. The \\nvisible units are the interface between the network and the environment; \\nduring training all the visible units are clamped into specific states by the \\nenvironment; when testing for completion ability, any subset of the visible \\nunits may be clamped. ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1557: ('ed efficiently. \\n154 ACKLEY. HINTON, AND SEJNOWSKI \\n3.1 Modeling the Underlying Structure of an Environment \\nThe units of a Boltzmann Machine partition into two functional groups, a \\nnonempty set of visible units and a possibly empty set of hidden units. The \\nvisible units are the interface between the network and the environment; \\nduring training all the visible units are clamped into specific states by the \\nenvironment; when testing for completion ability, any subset of the visible \\nunits may be clamped. The hidden units, if any, are never clamped by the \\nenvironment and can be used to “explain” underlying constraints in the en- \\nsemble of input vectors that cannot be represented by pairwise constraints \\namong the visible units. A hidden unit would be needed, for example, if the \\nenvironment demanded that the states of three visible units should have \\neven parity-a regularity that cannot be enforced by pairwise interactions \\nalone. Using hidden units to represent more complex hypotheses about the \\nstates of the visible units, such higher-order constraints among the visible \\nunits can be reduced to first and second-order constraints among the whole \\nset of units. \\nWe assume that each of the environmental input vectors persists for \\nlong enough to allow the network to approach thermal equilibrium, and we \\nignore any structure that may exist in the sequence of environmental vec- \\ntors. The structure of an environment can then be specified by giving the \\nprobability distribution over all 2” states of the v visible units. The network \\nwill be said to have a perfect model of the environment if it achieves exactly \\nthe same probability distribution over these 2” states when it is running freely \\nat thermal equilibrium with all units unclamped so there is no environmental \\ninput. \\nUnless the number of hidden units is exponentially large compared to \\nthe number of visible units, it will be impossible to achieve a perfecf model \\nbecause even if the network is totally connected the (v+ h - l)(v+h)/2 \\nweights and (v + h) b', 'A Learning Algorithm for Boltzmann machines.pdf'), 1558: ('e units. The network \\nwill be said to have a perfect model of the environment if it achieves exactly \\nthe same probability distribution over these 2” states when it is running freely \\nat thermal equilibrium with all units unclamped so there is no environmental \\ninput. \\nUnless the number of hidden units is exponentially large compared to \\nthe number of visible units, it will be impossible to achieve a perfecf model \\nbecause even if the network is totally connected the (v+ h - l)(v+h)/2 \\nweights and (v + h) biases among the v visible and h hidden units will be \\ninsufficient to model the 2” probabilities of the states of the visible units spe- \\ncified by the environment. However, if there are regularities in the environ- \\nment, and if the network uses its hidden units to capture these regularities, it \\nmay achieve a good match to the environmental probabilities. \\nAn information-theoretic measure of the discrepancy between the net- \\nwork’s internal model and the environment is \\nG=CP(V,) In 35L OI P’(K) \\nwhere P(V,) is the probability of the efh state of the visible units when their \\nstates are determined by the environment, andP’(V,) is the corresponding \\nprobability when the network is running freely with no environmental in- \\nput. The G metric, sometimes called the asymmetric divergence or informa- \\nBOLTZMANN MACHINE LEARNING 155 \\ntion gain (Kullback, 1959; Renyi, 1962), is a measure of the distance from \\nthe distribution given by the P’(V,) to the distribution given by the P(VJ. \\nG is zero if and only if the distributions are identical; otherwise it is positive. \\nThe term P’(VJ depends on the weights, and so G can be altered by \\nchanging them. To perform gradient descent in G, it is necessary to know \\nthe partial derivative of G with respect to each individual weight. In most \\ncross-coupled nonlinear networks it is very hard to derive this quantity, but \\nbecause of the simple relationships that hold at thermal equilibrium, the \\npartial derivative of G is straightforward to derive for our networks. The \\nprobabiliti', 'A Learning Algorithm for Boltzmann machines.pdf'), 1559: ('tributions are identical; otherwise it is positive. \\nThe term P’(VJ depends on the weights, and so G can be altered by \\nchanging them. To perform gradient descent in G, it is necessary to know \\nthe partial derivative of G with respect to each individual weight. In most \\ncross-coupled nonlinear networks it is very hard to derive this quantity, but \\nbecause of the simple relationships that hold at thermal equilibrium, the \\npartial derivative of G is straightforward to derive for our networks. The \\nprobabilities of global states are determined by their energies (Eq. 6) and the \\nenergies are determined by the weights (Eq. 1). Using these equations the \\npartial derivative of G (see the appendix) is: \\nac -= \\na wij - f@G, - PJ \\nwhere pij is the average probability of two units both being in the on state \\nwhen the environment is clamping the states of the visible units, and pi:, as \\nin Eq. (7), is the corresponding probability when the environmental input is \\nnot present and the network is running freely. (Both these probabilities must \\nbe measured at equilibrium.) Note the similarity between this equation and \\nEq. (7), which shows how changing a weight affects the log probability of a \\nsingle state. \\nTo minimize G, it is therefore sufficient to observe pi, and pi; when the \\nnetwork is at thermal equilibrium, and to change each weight by an amount \\nproportional to the difference between these two probabilities: \\nA W<j = c@<, - pi;) (10) \\nwhere e scales the size of each weight change. \\nA surprising feature of this rule is that it uses only local/y available \\ninformation. The change in a weight depends only on the behavior of the \\ntwo units it connects, even though the change optimizes a global measure, \\nand the best value for each weight depends on the values of all the other \\nweights. If there are no hidden units, it can be shown that G-space is con- \\ncave (when viewed from above) so that simple gradient descent will not get \\ntrapped at poor local minima. With hidden units, however, there can be \\nlocal minima that corres', 'A Learning Algorithm for Boltzmann machines.pdf'), 1560: ('is that it uses only local/y available \\ninformation. The change in a weight depends only on the behavior of the \\ntwo units it connects, even though the change optimizes a global measure, \\nand the best value for each weight depends on the values of all the other \\nweights. If there are no hidden units, it can be shown that G-space is con- \\ncave (when viewed from above) so that simple gradient descent will not get \\ntrapped at poor local minima. With hidden units, however, there can be \\nlocal minima that correspond to different ways of using the hidden units to \\nrepresent the higher-order constraints that are implicit in the probability \\ndistribution of environmental vectors. Some techniques for handling these \\nmore complex G-spaces are discussed in the next section. \\nOnce G has been minimized the network will have captured as well as \\npossible the regularities in the environment, and these regularities will be en- \\nforced when performing completion. An alternative view is that the net- \\n156 ACKLEY, HINTON. AND SEJNOWSKI \\nwork, in minimizing G, is finding the set of weights that is most likely to \\nhave generated the set of environmental vectors. It can be shown that maxi- \\nmizing this likelihood is mathematically equivalent to minimizing G (Peter \\nBrown, personal communication, 1983). \\n3.2 Controlling the Learning \\nThere are a number of free parameters and possible variations in the learn- \\ning algorithm presented above. As well as the size of e, which determines the \\nsize of each step taken for gradient descent, the lengths of time over which \\np,, and ,n,J are estimated have a significant impact on the learning process. \\nThe values employed for the simulations presented here were selected pri- \\nmarily on the basis of empirical observations. \\nA practical system which estimates p,, and p,; will necessarily have \\nsome noise in the estimates, leading to occasional “uphill steps” in the value \\nof G. Since hidden units in a network can create local minima in G, this is \\nnot necessarily a liability. The effect of the noise', 'A Learning Algorithm for Boltzmann machines.pdf'), 1561: ('he lengths of time over which \\np,, and ,n,J are estimated have a significant impact on the learning process. \\nThe values employed for the simulations presented here were selected pri- \\nmarily on the basis of empirical observations. \\nA practical system which estimates p,, and p,; will necessarily have \\nsome noise in the estimates, leading to occasional “uphill steps” in the value \\nof G. Since hidden units in a network can create local minima in G, this is \\nnot necessarily a liability. The effect of the noise in the estimates can be \\nreduced, if desired, by using a small value for E or by collecting statistics for \\na longer time, and so it is relatively easy to implement an annealing search \\nfor the minimum of G. \\nThe objective function G is a metric that specifies how well two proba- \\nbility distributions match. Problems arise if an environment specifies that \\nonly a small subset of the possible patterns over the visible units ever occur. \\nBy default, the unmentioned patterns must occur with probability zero, and \\nthe only way a Boltzmann Machine running at a non-zero temperature can \\nguarantee that certain configurations never occur is to give those configura- \\ntions infinitely high energy, which requires infinitely large weights. \\nOne way to avoid this implicit demand for infinite weights is to occa- \\nsionally provide “noisy ” input vectors. This can be done by filtering the \\n“correct” input vectors through a process that has a small probability of \\nreversing each of the bits. These noisy vectors are then clamped on the visi- \\nble units. If the noise is small, the correct vectors will dominate the \\nstatistics, but every vector will have some chance of occurring and so in- \\nfinite energies will not be needed. This “noisy clamping” technique was \\nused for all the examples presented here. It works quite well, but we are not \\nentirely satisfied with it and have been investigating other methods of pre- \\nventing the weights from growing too large when only a few of the possible \\ninput vectors ever occur. \\nThe simulati', 'A Learning Algorithm for Boltzmann machines.pdf'), 1562: ('ped on the visi- \\nble units. If the noise is small, the correct vectors will dominate the \\nstatistics, but every vector will have some chance of occurring and so in- \\nfinite energies will not be needed. This “noisy clamping” technique was \\nused for all the examples presented here. It works quite well, but we are not \\nentirely satisfied with it and have been investigating other methods of pre- \\nventing the weights from growing too large when only a few of the possible \\ninput vectors ever occur. \\nThe simulations presented in the next section employed a modification \\nof the obvious steepest descent method implied by Eq. (10). Instead of chang- \\ning w,, by an amount proportional to pij -pi;, it is simply incremented by a \\nfixed “weight-step” if pv>pi; and decremented by the same amount if pijc \\nPJ. The advantage of this method over steepest descent is that it can cope \\nBOLTZMANN MACHINE LEARNING 157 \\nwith wide variations in the first and second derivatives of G. It can make \\nsignificant progress on dimensions where G changes gently without taking \\nvery large divergent steps on dimensions where G falls rapidly and then rises \\nrapidly again. There is no suitable value for the E in Eq. (10) in such cases. \\nAny value large enough to allow progress along the gently sloping floor of a \\nravine will cause divergent oscillations up and down the steep sides of the \\nravine.’ \\n4. THE ENCODER PROBLEM \\nThe “encoder problem” (suggested to us by Sanjaya Addanki) is a simple \\nabstraction of the recurring task of communicating information among var- \\nious components of a parallel network. We have used this problem to test \\nout the learning algorithm because it is clear what the optimal solution is \\nlike and it is nontrivial to discover it. Two groups of visible units, desig- \\nnated V, and V-,, represent two systems that wish to communicate their \\nstates. Each group has v units. In the simple formulation we consider here, \\neach group has only one unit on at a time, so there are only v different states \\nof each group. I’, and VJ are not', 'A Learning Algorithm for Boltzmann machines.pdf'), 1563: ('mation among var- \\nious components of a parallel network. We have used this problem to test \\nout the learning algorithm because it is clear what the optimal solution is \\nlike and it is nontrivial to discover it. Two groups of visible units, desig- \\nnated V, and V-,, represent two systems that wish to communicate their \\nstates. Each group has v units. In the simple formulation we consider here, \\neach group has only one unit on at a time, so there are only v different states \\nof each group. I’, and VJ are not connected directly but both are connected \\nto a group of h hidden units H, with h < v so H may act as a limited capacity \\nbottleneck through which information about the states of V, and Vz must be \\nsqueezed. Since all simulations began with all weights set to zero, finding a \\nsolution to such a problem requires that the two visible groups come to \\nagree upon the meanings of a set of codes without any a priori conventions \\nfor communication through H. \\nTo permit perfect communication between the visible groups, it must \\nbe the case that h 1 /og,v. We investigated minimal cases in which h = log,v, \\nand cases when h was somewhat larger than log,v. In all cases, the environ- \\nment for the network consisted of v equiprobable vectors of length 2v which \\nspecified that one unit in V, and the corresponding unit in V, should be on \\ntogether with all other units off. Each visible group is completely connected \\ninternally and each is completely connected to H, but the units in Hare not \\nconnected to each other. \\nBecause of the severe speed limitation of simulation on a sequential \\nmachine, and because the learning requires many annealings, we have \\nprimarily experimented with small versions of the encoder problem. For ex- \\nample, Figure 2 shows a good solution to a “4-2-4” encoder problem in \\n’ The problem of finding a suitable value for t disappears if one performs a line search \\nfor the lowest value of G along the current direction of steepest descent, but line searches are \\ninapplicable in this case. Only the local gr', 'A Learning Algorithm for Boltzmann machines.pdf'), 1564: ('e of the severe speed limitation of simulation on a sequential \\nmachine, and because the learning requires many annealings, we have \\nprimarily experimented with small versions of the encoder problem. For ex- \\nample, Figure 2 shows a good solution to a “4-2-4” encoder problem in \\n’ The problem of finding a suitable value for t disappears if one performs a line search \\nfor the lowest value of G along the current direction of steepest descent, but line searches are \\ninapplicable in this case. Only the local gradient is available. There are bounds on the second \\nderivative that can be used to pick conservative values of e (Mark Derthick. personal communi- \\ncation, 1984), and methods of this kind are currently under investigation. \\n158 ACKLEY, HINTON. AND SEJNOWSKI \\nFigure 2. A solution to an encoder problem. The link weights are displayed using a recur- \\nsive notation. Each unit is represented by a shaded l-shaped box; from top to bottom the \\nrows of boxes represent groups V,, H. and V,. Each shaded box is o mop of the entire net- \\nwork, showing the strengths of that unit’s connections to other units. At each position in o \\nbox, the size of the white (positive) or block (negative) rectangle indicates the magnitude of \\nthe weight. In the position that would correspond to o unit connecting to itself (the second \\nposition in the top row of the second unit in the top row, for example). the bias is displayed. \\nAll connections between units appear twice in the diagram, once in the box for each of the \\ntwo units being connected. For example, the black square in the top right corner of the left- \\nmost unit of V, represents the same connection OS the block square in the top left corner of \\nthe rightmost unit of V,. This connection has a weight of -30. \\nwhich v = 4 and h = 2. The interconnections between the visible groups and \\nH have developed a binary coding-each visible unit causes a different pat- \\ntern of on and off states in the units of If, and corresponding units in V, \\nand V, support identical patterns in H. Note how ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1565: ('nected. For example, the black square in the top right corner of the left- \\nmost unit of V, represents the same connection OS the block square in the top left corner of \\nthe rightmost unit of V,. This connection has a weight of -30. \\nwhich v = 4 and h = 2. The interconnections between the visible groups and \\nH have developed a binary coding-each visible unit causes a different pat- \\ntern of on and off states in the units of If, and corresponding units in V, \\nand V, support identical patterns in H. Note how the bias of the second unit \\nof V, and VJ is positive to compensate for the fact that the code which repre- \\nsents that unit has all the H units turned off. \\n4.1. The 4-2-4 Encoder \\nThe experiments on networks with v = 4 and h = 2 were performed using the \\nfollowing learning cycle: \\n1. Esfimation of p,j: Each environmental vector in turn was clamped \\nover the visible units. For each environmental vector, the network \\nwas allowed to reach equilibrium twice. Statistics about how often \\npairs of units were both on together were gathered at equilibrium. \\nTo prevent the weights from growing too large we used the “noisy” \\nclamping technique described in Section 3.2. Each on bit of a \\nclamped vector was set to off with a probability of 0.15 and each \\noff bit was set to on with a probability of 0.05. \\n2. Estimation of p,;: The network was completely unclamped and \\nallowed to reach equilibrium at a temperature of 10. Statistics about \\n\\nBOLTZMANN MACHINE LEARNING 159 \\nco-occurrences were then gathered for as many annealings as were \\nused to estimate p,j. \\n3. Updaring the weigh&: All weights in the network were incremented \\nor decremented by a fixed weight-step of 2, with the sign of the in- \\ncrement being determined by the sign of p,, -p,,J. \\nWhen a settling to equilibrium was required, all the unclamped units were \\nrandomized with equal probability on or off (corresponding to raising the \\ntemperature to infinity), and then the network was allowed to run for the \\nfollowing times at the following temperatures: [2@20, 2@ 1', 'A Learning Algorithm for Boltzmann machines.pdf'), 1566: ('lings as were \\nused to estimate p,j. \\n3. Updaring the weigh&: All weights in the network were incremented \\nor decremented by a fixed weight-step of 2, with the sign of the in- \\ncrement being determined by the sign of p,, -p,,J. \\nWhen a settling to equilibrium was required, all the unclamped units were \\nrandomized with equal probability on or off (corresponding to raising the \\ntemperature to infinity), and then the network was allowed to run for the \\nfollowing times at the following temperatures: [2@20, 2@ 15,2@ 12,4@ lo].,’ \\nAfter this annealing schedule it was assumed that the network had reached \\nequilibrium, and statistics were collected at a temperature of 10 for 10 units \\nof time. \\nWe observed three main phases in the search for the global minimum of \\nG, and found that the occurrence of these phases was relatively insensitive to \\nthe precise parameters used. The first phase begins with all the weights set to \\nzero, and is characterized by the development of negative weights throughout \\nmost of the network, implementing two winner-take-all networks that model \\nthe simplest aspect of the environmental structure-only one unit in each visi- \\nble group is normally active at a time. In a 4-2-4 encoder, for example, the \\nnumber of possible patterns over the visible units is 28. By implementing a \\nwinner-take-all network among each group of four this can be reduced to 4 x 4 \\nlow energy patterns. Only the final reduction from 2’ to 2’ low energy pat- \\nterns requires the hidden units to be used for communicating between the two \\nvisible groups. Figure 3a shows a 4-2-4 encoder network after four learning \\ncycles. \\nAlthough the hidden units are exploited for inhibition in the first phase, \\nthe lateral inhibition task can be handled by the connections within the visible \\ngroups alone. In the second phase, the hidden units begin to develop positive \\nweights to some of the units in the visible groups, and they tend to maintain \\nsymmetry between the sign and approximate magnitude of a connection to a \\nunit in V, and the cor', 'A Learning Algorithm for Boltzmann machines.pdf'), 1567: ('ween the two \\nvisible groups. Figure 3a shows a 4-2-4 encoder network after four learning \\ncycles. \\nAlthough the hidden units are exploited for inhibition in the first phase, \\nthe lateral inhibition task can be handled by the connections within the visible \\ngroups alone. In the second phase, the hidden units begin to develop positive \\nweights to some of the units in the visible groups, and they tend to maintain \\nsymmetry between the sign and approximate magnitude of a connection to a \\nunit in V, and the corresponding unit in V2. The second phase finishes when \\nevery hidden unit has significant connection weights to each unit in V, and \\nanalogous weights to each unit in V,, and most of the different codes are \\nbeing used, but there are some codes that are used more than once and some \\nnot at all. Figure 3b shows the same network after 60 learning cycles. \\nOccasionally, all the codes are being used at the end of the second \\nphase in which case the problem is solved. Usually, however, there is a third \\nand longest phase during which the learning algorithm sorts out the remain- \\ning conflicts and finds a global minimum. There are two basic mechanisms \\n’ One unit of time is defined as the time required for each unit to be given, on average, one \\nchance to change its state. This means that if there are n unclamped units, a time period of I in- \\nvolves n random probes in which some unit is given a chance 10 change its stale. \\n160 ACKLEY. HINTON. AND SEJNOWSKI \\ninvolved in the sorting out process. Consider the conflict between the first \\nand fourth units in Figure 3b, which are both employing the code < -, + >. \\nWhen the system is running without environmental input, the two units will \\nbe on together quite frequently. Consequently, ,D,‘~ will be higher than P,,~ \\nbecause the environmental input tends to prevent the two units from being \\non together. Hence, the learning algorithm keeps decreasing the weight of \\nthe connection between the first and fourth units in each group, and they \\ncome to inhibit each other strongly.', 'A Learning Algorithm for Boltzmann machines.pdf'), 1568: (' between the first \\nand fourth units in Figure 3b, which are both employing the code < -, + >. \\nWhen the system is running without environmental input, the two units will \\nbe on together quite frequently. Consequently, ,D,‘~ will be higher than P,,~ \\nbecause the environmental input tends to prevent the two units from being \\non together. Hence, the learning algorithm keeps decreasing the weight of \\nthe connection between the first and fourth units in each group, and they \\ncome to inhibit each other strongly. (This effect explains the variations in \\ninhibitory weights in Figure 2. Visible units with similar codes are the ones \\nthat inhibit each other strongly.) Visible units thus compete for “territory” \\nin the space of possible codes, and this repulsion effect causes codes to \\nmigrate away from similar neighbors. In addition to the repulsion effect, we \\nobserved another process that tends to eventually bring the unused codes \\nadjacent (in terms of hamming distance) to codes that are involved in a con- \\nflict. The mechanics of this process are somewhat subtle and we do not take \\nthe time to expand on them here. \\nThe third phase finishes when all the codes are being used, and the \\nweights then tend to increase so that the solution locks in and remains stable \\nagainst the fluctuations caused by random variations in the co-occurrence \\nstatistics. (Figure 2 is the same network shown in Figure 3, after 120 learn- \\ning cycles.) \\nIn 250 different tests of the 4-2-4 encoder, it always found one of the \\nglobal minima, and once there it remained there. The median time required \\nto discover four different codes was I10 learning cycles. The longest time \\nwas 18 10 learning cycles. \\n4.2. The 4-3-4 Encoder \\nA variation on the binary encoder problem is to give H more units than are \\nabsolutely necessary for encoding the patterns in V, and V.. A simple exam- \\nple is the 4-3-4 encoder which was run with the same parameters as the 4-2-4 \\nencoder. In this case the learning algorithm quickly finds four different \\ncodes. Then it always', 'A Learning Algorithm for Boltzmann machines.pdf'), 1569: (' once there it remained there. The median time required \\nto discover four different codes was I10 learning cycles. The longest time \\nwas 18 10 learning cycles. \\n4.2. The 4-3-4 Encoder \\nA variation on the binary encoder problem is to give H more units than are \\nabsolutely necessary for encoding the patterns in V, and V.. A simple exam- \\nple is the 4-3-4 encoder which was run with the same parameters as the 4-2-4 \\nencoder. In this case the learning algorithm quickly finds four different \\ncodes. Then it always goes on to modify the codes so that they are optimally \\nspaced out and no pair differ by only a single bit, as shown in Figure 4. The \\nmedian time to find four well-spaced codes was 270 learning cycles and the \\nmaximum time in 200 trials was 1090. \\n4.3. The 8-3-8 Encoder \\nWith I’= 8 and /r = 3 it took many more learning cycles to find all 8 three-bit \\ncodes. We did 20 simulations, running each for 4000 learning cycles using \\nthe same parameters as for the 4-2-4 case (but with a probability of 0.02 of \\nreversing each ojy unit during noisy clamping). The algorithm found all 8 \\nBOLTZMANN MACHINE LEARNING 161 \\nFigure 3. Two phoses in the development of the perfect binory encoding shown in Figure 2. \\nThe weights ore shown (A) after 4 learning trials and (6) after 60 learning trials. \\nFigure 4. A 4-3.4 encoder thot has developed optimally spaced codes \\ncodes in 16 out of 20 simulations and found 7 codes in the rest. The median \\ntime to find 7 codes was 210 learning cycles and the median time to find all 8 \\nwas 1570 cycles. \\nThe di fficulty of finding all 8 codes is not surprising since the fraction \\nof the weight space that counts as a solution is much smaller than in the \\n4-2-4 case. Sets of weights that use 7 of the 8 different codes are found fairly \\n\\n162 ACKLEY, HINTON. AND SEJNOWSKI \\nrapidly and they constitute local minima which are far more numerous than \\nthe global minima and have almost as good a value of G. In this type of \\nG-space, the learning algorithm must be carefully tuned to achieve a global \\nminimu', 'A Learning Algorithm for Boltzmann machines.pdf'), 1570: ('0 cycles. \\nThe di fficulty of finding all 8 codes is not surprising since the fraction \\nof the weight space that counts as a solution is much smaller than in the \\n4-2-4 case. Sets of weights that use 7 of the 8 different codes are found fairly \\n\\n162 ACKLEY, HINTON. AND SEJNOWSKI \\nrapidly and they constitute local minima which are far more numerous than \\nthe global minima and have almost as good a value of G. In this type of \\nG-space, the learning algorithm must be carefully tuned to achieve a global \\nminimum, and even then it is very slow. We believe that the G-spaces for \\nwhich the algorithm is well-suited are ones where there are a great many \\npossible solutions and it is not essential to get the very best one. For large \\nnetworks to learn in a reasonable time, it may be necessary to have enough \\nunits and weights and a liberal enough specification of the task so that no \\nsingle unit or weight is essential. The next example illustrates the advantages \\nof having some spare capacity. \\n4.4. The 40-10-40 Encoder \\nA somewhat larger example is the 40-10-40 encoder. The 10 units in Hare \\nalmost twice the theoretical minimum, but Hstill acts as a limited bandwidth \\nbottleneck. The learning algorithm works well on this problem. Figure 5 \\nshows its performance when given a pattern in V, and required to settle to \\nthe corresponding pattern in Vz. Each learning cycle involved annealing once \\nwith each of the 40 environmental vectors clamped, and the same number of \\ntimes without clamping. The final performance asymptotes at 98.6% cor- \\nrect. \\nFigure 5. Completion accuracy of o 40-10-40 encoder during learning. The network was \\ntested by clomping the states of !he units in V, ond letting the remainder of the network \\nreach equilibrium. If iust the correct unit was on in V,, the test was successful. This was \\nrepeated 10 times for each of the 40 units in VI. For the first 300 learning cycles the network \\nwas run without connecting up the hidden units. This ensured that each group of 40 visible \\nunits developed enough loterol', 'A Learning Algorithm for Boltzmann machines.pdf'), 1571: (' at 98.6% cor- \\nrect. \\nFigure 5. Completion accuracy of o 40-10-40 encoder during learning. The network was \\ntested by clomping the states of !he units in V, ond letting the remainder of the network \\nreach equilibrium. If iust the correct unit was on in V,, the test was successful. This was \\nrepeated 10 times for each of the 40 units in VI. For the first 300 learning cycles the network \\nwas run without connecting up the hidden units. This ensured that each group of 40 visible \\nunits developed enough loterol inhibition to implement on effective winner-take-all net- \\nwork. The hidden units were then connected up and for the next 500 learning cycles we used \\n“noisy” clomping, switching on bits to off with o probobility of 0.1 and off bits to on with o \\nprobability of 0.0025. After this we removed the noise and this explains the sharp rise in \\nperformance after 800 cycles. The final performance asymptotes at 98.6% correct. \\nBOLTZMANN MACHINE LEARNING 163 \\nThe codes that the network selected to represent the patterns in V, and \\nV, were all separated by a hamming distance of at least 2, which is very un- \\nlikely to happen by chance. As a test, we compared the weights of the con- \\nnections between visible and hidden units. Each visible unit has 10 weights \\nconnecting it to the hidden units, and to avoid errors, the 10 dimensional \\nweight vectors for two different visible units should not be too similar. The \\ncosine of the angle between two vectors was used as a measure of similarity, \\nand no two codes had a similarity greater than 0.73, whereas many pairs had \\nsimilarities of 0.8 or higher when the same weights were randomly rearranged \\nto provide a control group for comparison. \\nTo achieve good performance on the completion tests, it was neces- \\nsary to use a very gentle annealing schedule during testing. The schedule \\nspent twice as long at each temperature and went down to half the final tem- \\nperature of the schedule used during learning. As the annealing was made \\nfaster, the error rate increased, thus giving a ver', 'A Learning Algorithm for Boltzmann machines.pdf'), 1572: (' greater than 0.73, whereas many pairs had \\nsimilarities of 0.8 or higher when the same weights were randomly rearranged \\nto provide a control group for comparison. \\nTo achieve good performance on the completion tests, it was neces- \\nsary to use a very gentle annealing schedule during testing. The schedule \\nspent twice as long at each temperature and went down to half the final tem- \\nperature of the schedule used during learning. As the annealing was made \\nfaster, the error rate increased, thus giving a very natural speed/accuracy \\ntrade-off. We have not pursued this issue any further, but it may prove \\nfruitful because some of the better current models of the speed/accuracy \\ntrade-off in human reaction time experiments involve the idea of a biased \\nrandom walk (Ratcliff, 1978), and the annealing search gives rise to similar \\nunderlying mathematics. \\n5. REPRESENTATION IN PARALLEL NETWORKS \\nSo far, we have avoided the issue of how complex concepts would be repre- \\nsented in a Boltzmann machine. The individual units stand for “hypothe- \\nses,” but what is the relationship between these hypotheses and the kinds of \\nconcepts for which we have words? Some workers suggest that a concept \\nshould be represented in an essentially “local” fashion: The activation of \\none or a few computing units is the representation for a concept (Feldman & \\nBallard, 1982); while others view concepts as “distributed” entities: A par- \\nticular pattern of activity over a large group of units represents a concept, \\nand different concepts corresponds to alternative patterns of activity over \\nthe same group of units (Hinton, 1981). \\nOne of the better arguments in favor of local representations is their \\ninherent modularity. Knowledge about relationships between concepts is \\nlocalized in specific connections and is therefore easy to add, remove, and \\nmodify, if some reasonable scheme for forming hardware connections can \\nbe found (Fahlman, 1980; Feldman, 1982). With distributed representa- \\ntions, however, the knowledge is diffuse. This is good f', 'A Learning Algorithm for Boltzmann machines.pdf'), 1573: ('responds to alternative patterns of activity over \\nthe same group of units (Hinton, 1981). \\nOne of the better arguments in favor of local representations is their \\ninherent modularity. Knowledge about relationships between concepts is \\nlocalized in specific connections and is therefore easy to add, remove, and \\nmodify, if some reasonable scheme for forming hardware connections can \\nbe found (Fahlman, 1980; Feldman, 1982). With distributed representa- \\ntions, however, the knowledge is diffuse. This is good for tolerance to local \\nhardware damage, but it appears to make the design of modules to perform \\nspecific functions much harder. It is particularly difficult to see how new \\ndistributed representations of concepts could originate spontaneously. \\n164 ACKLEY, HINTON, AND SEJNOWSKI \\nIn a Boltzmann machine, a distributed representation corresponds to \\nan energy minimum, and so the problem of creating a good collection of \\ndistributed representations is equivalent to the problem of creating a good \\n“energy landscape.” The learning algorithm we have presented is capable \\nof solving this problem, and it therefore makes distributed representations \\nconsiderably more plausible. The diffuseness of any one piece of knowledge \\nis no longer a serious objection, because the mathematical simplicity of the \\nBoltzmann distribution makes it possible to manipulate all the diffuse local \\nweights in a coherent way on the basis of purely local information. The for- \\nmation of a simple set of distributed representations is illustrated by the en- \\ncoder problems. \\n5.1. Communicating Information between Modules \\nThe encoder problem examples also suggest a method for communicating \\nsymbols between various components of a parallel computational network. \\nFeldman and Ballard (1982) present sketches of two implementations for this \\ntask; using the example of the transmission of the concept “wormy apple” \\nfrom where it is recognized in the perceptual system to where the phrase \\n“wormy apple” can be generated by the speech system. They argue', 'A Learning Algorithm for Boltzmann machines.pdf'), 1574: ('ted by the en- \\ncoder problems. \\n5.1. Communicating Information between Modules \\nThe encoder problem examples also suggest a method for communicating \\nsymbols between various components of a parallel computational network. \\nFeldman and Ballard (1982) present sketches of two implementations for this \\ntask; using the example of the transmission of the concept “wormy apple” \\nfrom where it is recognized in the perceptual system to where the phrase \\n“wormy apple” can be generated by the speech system. They argue that \\nthere appears to be only two ways that this could be accomplished. In the \\nfirst method, the perceptual information is encoded into a set of symbols \\nthat are then transmitted as messages to the speech system, where they are \\ndecoded into a form suitable for utterance. In this case, there would be a set \\nof general-purpose communciation lines, analogous to a bus in a conven- \\ntional computer, that would be used as the medium for all such messages \\nfrom the visual system to the speech system. Feldman and Ballard describe \\nthe problems with such a system as: \\nl Complex messages would presumably have to be transmitted se- \\nquentially over the communication lines. \\nl Both sender and receiver would have to learn the common code for \\neach new concept. \\nl The method seems biologically implausible as a mechanism for the \\nbrain. \\nThe alternative implementation they suggest requires an individual, \\ndedicated hardware pathway for each concept that is communicated from \\nthe perceptual system to the speech system. The idea is that the simulta- \\nneous activation of “apple” and “worm” in the perceptual system can be \\ntransmitted over private links to their counterparts in the speech system. \\nThe critical issues for such an implementation are having the necessary con- \\nnections available between concepts, and being able to establish new con- \\nBOLTZMANN MACHINE LEARNING 165 \\nnection pathways as new concepts are learned in the two systems. The main \\npoint of this approach is that the links between the computing units carr', 'A Learning Algorithm for Boltzmann machines.pdf'), 1575: ('The idea is that the simulta- \\nneous activation of “apple” and “worm” in the perceptual system can be \\ntransmitted over private links to their counterparts in the speech system. \\nThe critical issues for such an implementation are having the necessary con- \\nnections available between concepts, and being able to establish new con- \\nBOLTZMANN MACHINE LEARNING 165 \\nnection pathways as new concepts are learned in the two systems. The main \\npoint of this approach is that the links between the computing units carry \\nsimple, nonsymbolic information such as a single activation level. \\nThe behavior of the Boltzmann machine when presented with an en- \\ncoder problem demonstrates a way of communicating concepts that largely \\ncombines the best of the two implementations mentioned. Like the second \\napproach, the computing units are small, the links carry a simple numeric \\nvalue, and the computational and connection requirements are within the \\nrange of biological plausibility. Like the first approach, the architecture is \\nsuch that many different concepts can be transmitted over the same commu- \\nnication lines, allowing for effective use of limited connections. The learning \\nof new codes to represent new concepts emerges automatically as a coopera- \\ntive process from the G-minimization learning algorithm. \\n6. CONCLUSION \\nThe application of statistical mechanics to constraint satisfaction searches \\nin parallel networks is a promising new area that has been discovered inde- \\npendently by several other groups (Geman & Geman, 1983; Smolensky, \\n1983). There are many interesting issues that we have only mentioned in \\npassing. Some of these issues are discussed in greater detail elsewhere: Hin- \\nton and Sejnowski (1983b) and Geman and Geman (1983) describe the rela- \\ntion to Bayesian inference and to more conventional relaxation techniques; \\nFahlman, Hinton, and Sejnowski (1983) compare Boltzmann machines with \\nsome alternative parallel schemes, and discuss some knowledge representa- \\ntion issues. An expanded version of this paper (Hi', 'A Learning Algorithm for Boltzmann machines.pdf'), 1576: ('3; Smolensky, \\n1983). There are many interesting issues that we have only mentioned in \\npassing. Some of these issues are discussed in greater detail elsewhere: Hin- \\nton and Sejnowski (1983b) and Geman and Geman (1983) describe the rela- \\ntion to Bayesian inference and to more conventional relaxation techniques; \\nFahlman, Hinton, and Sejnowski (1983) compare Boltzmann machines with \\nsome alternative parallel schemes, and discuss some knowledge representa- \\ntion issues. An expanded version of this paper (Hinton, Sejnowski, & Ack- \\nley, 1984) presents this material in greater depth and discusses a number of \\nrelated issues such as the relationship to the brain and the problem of se- \\nquential behavior. It also shows how the probabilistic decision function \\ncould be realized using gaussian noise, how the assumptions of symmetry in \\nthe physical connections and of no time delay in transmission can be relaxed, \\nand describes results of simulations on some other tasks. \\nSystems with symmetric weights form an interesting class of computa- \\ntional device because their dynamics is governed by an energy function.’ \\nThis is what makes it possible to analyze their behavior and to use them for \\niterative constraint satisfaction. In their influential exploration of percep- \\ntrons, Minsky and Papert (1968, p. 231) concluded that: “Multilayer ma- \\nchines with loops clearly open up all the questions of the general theory of \\nautomata.” Although this statement is very plausible, recent developments \\n’ One can easily write down a similar energy function for asymmetric networks, but this \\nenergy function does not govern the behavior of the network when the links are given their nor- \\nmal causal interpretation. \\n166 ACKLEY, HINTON. AND SEJNOWSKI \\nsuggest that it may be misleading because it ignores the symmetric case, and \\nit seems to have led to the general belief that it would be impossible to find \\npowerful learning algorithms for networks of perceptron-like elements. \\nWe believe that the Boltzmann Machine is a simple example of ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1577: ('a similar energy function for asymmetric networks, but this \\nenergy function does not govern the behavior of the network when the links are given their nor- \\nmal causal interpretation. \\n166 ACKLEY, HINTON. AND SEJNOWSKI \\nsuggest that it may be misleading because it ignores the symmetric case, and \\nit seems to have led to the general belief that it would be impossible to find \\npowerful learning algorithms for networks of perceptron-like elements. \\nWe believe that the Boltzmann Machine is a simple example of a class \\nof interesting stochastic models that exploit the close relationship between \\nBoltzmann distributions and information theory. \\nAll of this will lead to theories [of computation] which are much less \\nrigidly of an all-or-none nature than past and present formal logic. They \\nwill be of a much less combinatorial, and much more analytical, charac- \\nter. In fact, there are numerous indications to make us believe that this \\nnew system of formal logic will move closer to another discipline which \\nhas been little linked in the past with logic. This is thermodynamics, \\nprimarily in the form it was received from Boitzmann, and is that part \\nof theoretical physics which comes nearest in some of its aspects to ma- \\nnipulating and measuring information. \\n(John Von Neumann, Collected Works Vol. 5, p. 304) \\nAPPENDIX: DERIVATION OF THE LEARNING ALGORITHM \\nWhen a network is free-running at equilibrium the probability distribution \\nover the visible units is given by \\nP’(V,)=CP’(V,AH,)= I:;: 8 (11) \\nAn \\nwhere V, is a vector of states of the visible units, HB is a vector of states of \\nthe hidden units, and E,, is the energy of the system in state V,AH@ \\nEp6= - C w..~@J+ \\ni<j 1, I , . \\nHence, \\nDifferentiating (11) then yields \\nBOLTZMANN MACHINE LEARNING 167 \\n1 =- T [ gp ‘( ~mr\\\\%Wq~ - P ‘( V,).$lP ‘( V,AH,).5y+ \\n1 . \\nThis derivative is used to compute the gradient of the G-measure \\nG=CP(V,) ins P P \\nwhere P( V,) is the clamped probability distribution over the visible units \\nand is independent of wu. So \\naG _ c p(k) apw,) -', 'A Learning Algorithm for Boltzmann machines.pdf'), 1578: ('ector of states of the visible units, HB is a vector of states of \\nthe hidden units, and E,, is the energy of the system in state V,AH@ \\nEp6= - C w..~@J+ \\ni<j 1, I , . \\nHence, \\nDifferentiating (11) then yields \\nBOLTZMANN MACHINE LEARNING 167 \\n1 =- T [ gp ‘( ~mr\\\\%Wq~ - P ‘( V,).$lP ‘( V,AH,).5y+ \\n1 . \\nThis derivative is used to compute the gradient of the G-measure \\nG=CP(V,) ins P P \\nwhere P( V,) is the clamped probability distribution over the visible units \\nand is independent of wu. So \\naG _ c p(k) apw,) -= ___ \\naWij c( P’(V,) aw, \\nNow, \\nand \\n(12) \\nEquation (12) holds because the probability of a hidden state given some \\nvisible state must be the same in equilibrium whether the visible units were \\nclamped in that state or arrived there by free-running. Hence, \\nAlso, \\nTherefore, CP(V*)= 1. P \\naG -= \\naw, -+bij-P;] \\n168 \\nwhere ACKLEY. HINTON. AND SEJNOWSKI \\nand \\nas given in (9). \\nThe Boltzmann Machine learning algorithm can also be formulated as \\nan input-output model. The visible units are divided into an input set / and \\nan output set 0, and an environment specifies a set of conditional probabili- \\nties of the form P(O,II,). During the “training” phase the environment \\nclamps both the input and output units, and p,,s are estimated. During the \\n“testing” phase the input units are clamped and the output units and hidden \\nunits free-run, and p,$ are estimated. The appropriate G measure in this \\ncase is \\nSimilar mathematics apply in this formulation and aG/aw,, is the same as \\nbefore. \\nREFERENCES \\nBerliner, H. J.. & Ackley. D. H. (1982, August). The QBKG system: Generating explanations \\nfrom a non-discrete knowledge representation. Proc’eedin,qs 0.1 rhe No~ionul Con.ference \\n~7 .-1r/!/lc/u/ /rr/e//;eence .4,4.4 I-82. Pittsburgh, PA, 213-216. \\nBinder, K. (Ed.) (1978). The Mm/e-Cur/o /?re//rod /,I .s~o~is/ictr/ phmks. New York: Springer- \\nVerlag. \\nFahlman. S. E. (1980, June). The Hashnet Interconnection Scheme. (Tech. Rep. No. CMU- \\nCS-80-125). Carnegie-Mellon University, Pittsburgh, PA. \\nFahlman, S. E.. Hinton, G. E.,', 'A Learning Algorithm for Boltzmann machines.pdf'), 1579: ('& Ackley. D. H. (1982, August). The QBKG system: Generating explanations \\nfrom a non-discrete knowledge representation. Proc’eedin,qs 0.1 rhe No~ionul Con.ference \\n~7 .-1r/!/lc/u/ /rr/e//;eence .4,4.4 I-82. Pittsburgh, PA, 213-216. \\nBinder, K. (Ed.) (1978). The Mm/e-Cur/o /?re//rod /,I .s~o~is/ictr/ phmks. New York: Springer- \\nVerlag. \\nFahlman. S. E. (1980, June). The Hashnet Interconnection Scheme. (Tech. Rep. No. CMU- \\nCS-80-125). Carnegie-Mellon University, Pittsburgh, PA. \\nFahlman, S. E.. Hinton, G. E., & Sejnowski, T. J. (1983. August). Massively parallel architec- \\ntures for Al: NETL, Thistle, and Boltzmann Machines. Proceedings o./ rhe No~ionul \\nCoft.lerence (,!I .Ar/(ficiu/ /nre//i,cence AAA 1-83. Washington, DC, 109-I 13. \\nFeldman. J. A. (1982). Dynamic connections in neural networks. Bio/o~icu/ C)berne/icr. 46. \\n27-39. \\nFeldman, J. A., & Ballard, D. H. (1982). Connectionist models and their properties. Cogni/ive \\nScience. 6. 205-254. \\nGeman. S., & Geman, D. (1983). Stochastic relaxation, Gibbs distributions, and the Bayesian \\nrestoration of images. Unpublished manuscript. \\nCrimson. W. E. L. (1981). Frorrr imuges /o .FII~/UC~S. Cambridge, MA: MIT Press. \\nHinton, G. E. (1977). Re/u.uario~t und its role in vision. Unpublished doctoral dissertation, \\nUniversity of Edinburgh. Described in D. H. Ballard & C. M. Brown (Eds.), Co/vptr/er \\nt’/.s/on. Englewood Cliffs, NJ: Prentice-Hall, 408-430. \\nBOLTZMANN MACHINE LEARNING 169 \\nHinton. G. E. (1981). Implementing semantic networks in parallel hardware. In G. E. Hinton \\n& .I. A. Anderson (Eds.), furu//e/ Models oj Associative Memory. Hillsdale. NJ: Erl- \\nbaum. \\nHinton, G. E.. & Anderson, J. A. (1981). Pam//e/ models oJassociulive rne/nor.v. Hillsdale, \\nNJ: Erlbaum. \\nHinton, G. E., & Sejnowski, T. J. (1983a. May). Analyzing cooperative computation. fro- \\nceedings of ihe Fijlh Annuul Conference of /he Cognirive Science Sociefy. Rochester, \\nNY. \\nHinton. G. E., & Sejnowski, T. J. (1983b, June). Optimal perceptual inference. Proceedings \\nof (he IEEE Cornprrrer Socie(v C', 'A Learning Algorithm for Boltzmann machines.pdf'), 1580: ('Hinton \\n& .I. A. Anderson (Eds.), furu//e/ Models oj Associative Memory. Hillsdale. NJ: Erl- \\nbaum. \\nHinton, G. E.. & Anderson, J. A. (1981). Pam//e/ models oJassociulive rne/nor.v. Hillsdale, \\nNJ: Erlbaum. \\nHinton, G. E., & Sejnowski, T. J. (1983a. May). Analyzing cooperative computation. fro- \\nceedings of ihe Fijlh Annuul Conference of /he Cognirive Science Sociefy. Rochester, \\nNY. \\nHinton. G. E., & Sejnowski, T. J. (1983b, June). Optimal perceptual inference. Proceedings \\nof (he IEEE Cornprrrer Socie(v Con.ference on Compurer Vision und Puftem Recogni- \\n/ion. Washington, DC, pp. 448-453. \\nHinton, G. E., Sejnowski, T. J.. & Ackley, D. H. (1984. May). Eo//munn Machines: Con- \\ns/ruin/ m/is//c/ion nerworks /ho/ /em?. (Tech. Rep. No. CMU-CS-84-I 19). Pittsburgh, \\nPA: Carnegie-Mellon University. \\nHopfield, J. J. (1982). Neural networks and physical systems with emergent collective compu- \\ntational abilities. Proceedings o/‘ the Nurionul Academy of’ Sciencer USA, 79. 2554- \\n2558. \\nKirkpatrick, S., Gelatt, C. D., & Vecchi, M. P. (1983). Optimization by simulated annealing. \\nSciewe, 220. 61 I-680. \\nKullback, S. (1959). Injormu/ion /heor!, und r/a/isrics. New York: Wiley. \\nMetropolis, N., Rosenbluth, A., Rosenbluth, M., Teller, A.. & Teller, E. (1953). Equation of \\nstate calculations for fast computing machines. Journul oJ ChemiwI P/r~sic.c. 6. 1087. \\nMinsky, M.. & Papert, S. (1968). Percepplrons. Cambridge, MA: MIT Press. \\nNewell, A. (1982). /nte//ecruu/ issues in rhe hi.rrory o/ ur/i/cro/ inrelligence. (Tech. Rep. NO. \\nCMU-CS-82-142). Pittsburgh, PA: Carnegie-Mellon University. \\nNewell, A.. & Simon, H. A. (1972). H~rnru!t problem so/vr~r~. Englewood Cliffs, NJ: Prentice- \\nHall, 1972. \\nRatcliff. R. (1978). A theory of memory retrieval. Ps.vcho/ogictr/ Review. X_C. 59-108. \\nRenyi, A. (1962). Probubi/i/J /hew,‘. Amsterdam: North-Holland. \\nRosenblatt , F. ( I96 I). Principles o/‘ tlelrrorl.vnu,,licJ: Perceprrom ontl /he fheo~:v o/’ brurn \\nrtrechuniw~s. Washington, DC: Spartan. \\nSmolensky, P. (1983. August). Schema selecti', 'A Learning Algorithm for Boltzmann machines.pdf'), 1581: ('O. \\nCMU-CS-82-142). Pittsburgh, PA: Carnegie-Mellon University. \\nNewell, A.. & Simon, H. A. (1972). H~rnru!t problem so/vr~r~. Englewood Cliffs, NJ: Prentice- \\nHall, 1972. \\nRatcliff. R. (1978). A theory of memory retrieval. Ps.vcho/ogictr/ Review. X_C. 59-108. \\nRenyi, A. (1962). Probubi/i/J /hew,‘. Amsterdam: North-Holland. \\nRosenblatt , F. ( I96 I). Principles o/‘ tlelrrorl.vnu,,licJ: Perceprrom ontl /he fheo~:v o/’ brurn \\nrtrechuniw~s. Washington, DC: Spartan. \\nSmolensky, P. (1983. August). Schema selection and stochastic inference in modular environ- \\nments. Proceedings of /he Nu/ionu/ Con.ference O/I .A ri!fic,iol Itilelli,~ence .,I A A 1-S). \\nWashington, DC. 109-I 13. \\nTerzopoulos, D. ( 1984). M~t/iireco/r~/ion cwrrpic~u/ion oJ ~,i.rih/e-c1rt:lirc.e re/~r)T(~.\\\\etft~I/iot~.~. Un- \\npublished doctoral dissertation, MIT, Cambridge, MA. \\nWaltz, D. L. (1975). Understanding line drawings of scenes with shadows. In P. Winston \\n(Ed.), The Pxycho/og.t q/ Compu/er Vision. New York: McGraw-Hill. \\nWinston, P. H. (1984). Ar/iji’ciu/ /n/e//igerrce. (2nd ed.) Reading, MA: Addison-Wesley. ', 'A Learning Algorithm for Boltzmann machines.pdf'), 1582: ('Investigating the Potential of GPT-3 in Providing Feedback for\\nProgramming Assessments\\nRishabh Balse\\nBS Programme in Data Science and\\nApplications\\nIndian Institute of Technology Madras\\nChennai, Tamil Nadu, India\\nrish.workspace@gmail.comBharath Valaboju∗\\nBS Programme in Data Science and\\nApplications\\nIndian Institute of Technology Madras\\nChennai, Tamil Nadu, India\\nvalabojubharath@yahoo.comShreya Singhal∗\\nBS Programme in Data Science and\\nApplications\\nIndian Institute of Technology Madras\\nChennai, Tamil Nadu, India\\nsinghalshreya201@gmail.com\\nJayakrishnan Madathil\\nWarriem\\nNational Programme on Technology\\nEnhanced Learning (NPTEL)\\nBS Programme in Data Science and\\nApplications\\nIndian Institute of Technology Madras\\nChennai, Tamil Nadu, India\\njkm@nptel.iitm.ac.inPrajish Prasad\\nSchool of Computing and Data\\nSciences\\nFLAME University\\nPune, Maharashtra, India\\nprajish.prasad@gmail.com\\nABSTRACT\\nRecent advances in artificial intelligence have led to the develop-\\nment of large language models (LLMs), which are able to generate\\ntext, images, and source code based on prompts provided by humans.\\nIn this paper, we explore the capabilities of an LLM - OpenAI’s GPT-\\n3 model to provide feedback for student written code. Specifically,\\nwe examine the feasibility of GPT-3 to check, critique and suggest\\nchanges to code written by learners in an online programming\\nexam of an undergraduate Python programming course.\\nWe collected 1211 student code submissions from 7 questions\\nasked in a programming exam, and provided the GPT-3 model with\\nseparate prompts to check, critique and provide suggestions on\\nthese submissions. We found that there was a high variability in the\\naccuracy of the model’s feedback for student submissions. Across\\nquestions, the range for accurately checking the correctness of the\\ncode was between 57% to 79%, between 41% to 77% for accurately\\ncritiquing code, and between 32% and 93% for suggesting appropri-\\nate changes to the code. We also found instances where the model\\ngenerated incorrect and inconsistent feedback. These fin', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1583: ('arate prompts to check, critique and provide suggestions on\\nthese submissions. We found that there was a high variability in the\\naccuracy of the model’s feedback for student submissions. Across\\nquestions, the range for accurately checking the correctness of the\\ncode was between 57% to 79%, between 41% to 77% for accurately\\ncritiquing code, and between 32% and 93% for suggesting appropri-\\nate changes to the code. We also found instances where the model\\ngenerated incorrect and inconsistent feedback. These findings sug-\\ngest that models like GPT-3 currently cannot be ‘directly’ used to\\nprovide feedback to students for programming assessments.\\n∗Both authors contributed equally to this research.\\nPermission to make digital or hard copies of all or part of this work for personal or\\nclassroom use is granted without fee provided that copies are not made or distributed\\nfor profit or commercial advantage and that copies bear this notice and the full citation\\non the first page. Copyrights for components of this work owned by others than the\\nauthor(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or\\nrepublish, to post on servers or to redistribute to lists, requires prior specific permission\\nand/or a fee. Request permissions from permissions@acm.org.\\nITiCSE 2023, July 8–12, 2023, Turku, Finland\\n©2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.\\nACM ISBN 979-8-4007-0138-2/23/07. . . $15.00\\nhttps://doi.org/10.1145/3587102.3588852CCS CONCEPTS\\n•Applied computing →Computer-assisted instruction; •So-\\ncial and professional topics →CS1; •Computing methodolo-\\ngies→Natural language generation.\\nKEYWORDS\\nLarge language models (LLM), GPT-3, Evaluation, Feedback, Python\\nprogramming\\nACM Reference Format:\\nRishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil\\nWarriem, and Prajish Prasad. 2023. Investigating the Potential of GPT-3 in\\nProviding Feedback for Programming Assessments. In Proceedings of the\\n2023 Conference on Innovation and Technology in Computer Science Edu', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1584: ('r-assisted instruction; •So-\\ncial and professional topics →CS1; •Computing methodolo-\\ngies→Natural language generation.\\nKEYWORDS\\nLarge language models (LLM), GPT-3, Evaluation, Feedback, Python\\nprogramming\\nACM Reference Format:\\nRishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil\\nWarriem, and Prajish Prasad. 2023. Investigating the Potential of GPT-3 in\\nProviding Feedback for Programming Assessments. In Proceedings of the\\n2023 Conference on Innovation and Technology in Computer Science Education\\nV. 1 (ITiCSE 2023), July 8–12, 2023, Turku, Finland. ACM, New York, NY,\\nUSA, 7 pages. https://doi.org/10.1145/3587102.3588852\\n1 INTRODUCTION\\nRapid progress in the field of artificial intelligence has led to the\\ndevelopment of large language models (LLMs), which are able to\\ngenerate text (e.g. ChatGPT1), images (e.g. DALL-E2), and source\\ncode (e.g. CoPilot3), based on prompts provided by humans. One\\nsuch LLM is OpenAI’s GPT-3 model [ 5], which initially released in\\nJune 2020. GPT-3 has been used by several applications for features\\nsuch as search, conversation and text completion4.\\nConsidering the ready availability of such LLMs to the public,\\nthere has been a growing interest in the CS education community\\nabout the benefits, opportunities and challenges that LLMs pose\\nto programming education [ 2,15]. Instructors and CS education\\nresearchers have been urged to act quickly and explore possible\\nopportunities, as well as determine possible use cases of misuse.\\n1https://chat.openai.com/chat\\n2https://openai.com/dall-e-2/\\n3https://github.com/features/copilot\\n4https://openai.com/blog/gpt-3-apps/\\n292\\n\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil Warriem, & Prajish Prasad\\nThere are several use cases which have already been explored\\nby CS education researchers. Previous work has examined the fea-\\nsibility of large language models in generating solutions [ 7,10] and\\ncode explanations [ 18]. In this paper, we examine a use case which\\nhas not been', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1585: ('.com/dall-e-2/\\n3https://github.com/features/copilot\\n4https://openai.com/blog/gpt-3-apps/\\n292\\n\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil Warriem, & Prajish Prasad\\nThere are several use cases which have already been explored\\nby CS education researchers. Previous work has examined the fea-\\nsibility of large language models in generating solutions [ 7,10] and\\ncode explanations [ 18]. In this paper, we examine a use case which\\nhas not been sufficiently explored - how models like GPT-3 can\\nbe used by instructors as a mechanism for providing feedback for\\nprogramming assessments.\\nProviding specific feedback in programming assessments is in-\\nherently difficult, especially in MOOCs and large classrooms. Using\\ntest cases is widely used to provide feedback to students in program-\\nming assignments [12]. Usually, feedback from test cases involves\\nspecifying how many test cases passed or failed, and students have\\nto infer issues in their code from this information. There can also\\nbe issues in designing test cases, such is missing, incorrect, and\\nredundant test cases. Hence, the number of correct test cases may\\nnot accurately reflect the grade which students receive in their\\nsubmission [20].\\nA potential solution is to use LLMs like GPT-3 to check and\\ngenerate specific feedback for student programming assessments.\\nIn this paper, we examine the accuracy of GPT-3’s feedback, and also\\nexamine specific ways in which GPT-3 critiques a given student’s\\ncode. We examine the capabilities of the GPT-3 model in checking\\nthe correctness of the code, in critiquing what was wrong with the\\ncode, and in suggesting proper changes to improve the code.\\nWe explore the following research questions in this paper.\\n•To what extent does GPT-3 accurately check, critique and\\nprovide suggestions to students’ code?\\n•In what ways does GPT-3 correctly or incorrectly critique\\nstudents’ code?\\n2 RELATED WORK\\n2.1 LLMs in Programming Education\\nThere has been a growing interest in how LLMs can', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1586: ('examine the capabilities of the GPT-3 model in checking\\nthe correctness of the code, in critiquing what was wrong with the\\ncode, and in suggesting proper changes to improve the code.\\nWe explore the following research questions in this paper.\\n•To what extent does GPT-3 accurately check, critique and\\nprovide suggestions to students’ code?\\n•In what ways does GPT-3 correctly or incorrectly critique\\nstudents’ code?\\n2 RELATED WORK\\n2.1 LLMs in Programming Education\\nThere has been a growing interest in how LLMs can be used in pro-\\ngramming education [ 2,10,14,15,17–19]. LLMs like Codex have\\nbeen shown to perform reasonably well in solving introductory\\nprogramming problems [ 7,10,19]. Codex’s response has been com-\\npared with student responses, and has been shown to outperform\\nmost students, and has also shown to provide sufficient range of\\nresponses for a given problem [ 10]. Denny et al. investigated CoPi-\\nlot’s performance when provided with problems from a publicly\\navailable dataset of programming problems. Around 47.6% of the\\nproblems were solved by Codex in the first attempt, and around\\n61% of the remaining problems were solved after modifying the\\nproblem description prompts given to Codex [7].\\nLLMs have also been used to generate programming exercises\\nand code explanations [ 16,18]. MacNeil et al. used Codex in a\\nsoftware development course to generate explanations for code\\nexamples in an online e-book [ 16]. Students perceived these code\\nexplanations as being useful for learning. Sarsa et al. used LLMs\\nto create programming exercises and code explanations [ 18], and\\nmany of the automatically generated content was reasonable and\\nnovel. However, the authors also argue that instructors need to be\\ncareful to inspect the content before releasing it to students.\\nThese findings provide evidence that LLMs are reasonably good\\nin generating solutions and explanations for introductory program-\\nming problems. Hence, in this paper, we investigate another contextwhere LLMs can be used - in providing feedback for student written', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1587: (' programming exercises and code explanations [ 18], and\\nmany of the automatically generated content was reasonable and\\nnovel. However, the authors also argue that instructors need to be\\ncareful to inspect the content before releasing it to students.\\nThese findings provide evidence that LLMs are reasonably good\\nin generating solutions and explanations for introductory program-\\nming problems. Hence, in this paper, we investigate another contextwhere LLMs can be used - in providing feedback for student written\\ncode in programming assessments.\\n2.2 Providing Feedback in Programming\\nAssessments\\nUsing test cases is a widely used method to provide feedback to\\nstudents in programming assignments [ 12]. Automatic assessment\\ntools like ASSYST [ 13] and Web-CAT [ 8] use test cases fed by in-\\nstructors or TAs to evaluate student programs. Instead of manually\\nproviding test cases, tools such as Klee can automatically gener-\\nate test cases from formal specifications of program’s expected\\nbehaviour [ 4,6]. Instructors have used student-written tests for\\ntesting other students’ implementations [ 9,11], and tools like Leg-\\nent also use student submissions to generate personalised test cases\\n[1].\\nEvaluating student code using test cases is common, and by\\nproviding information of how many test cases passed or failed,\\nstudents are able to check the correctness of their code to a certain\\ndegree. However, test cases fail in critiquing issues in students’\\ncode, as well as in providing suggestions for what can be improved.\\nIn this paper, we investigate how feedback from LLMs can augment\\nfeedback from test cases.\\n3 RESEARCH CONTEXT\\nIn this section, we describe the context in which this research\\nwas conducted. We used student code responses from an online\\nprogramming exam conducted in a Python programming course\\noffered by a Tier-1 research university in our country. The exam\\nwas conducted online, and human proctors monitored students’\\nactivity remotely using Google Meet.\\nIn the programming exam, each student had to attempt 4 pro-\\ngramming', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1588: ('r, we investigate how feedback from LLMs can augment\\nfeedback from test cases.\\n3 RESEARCH CONTEXT\\nIn this section, we describe the context in which this research\\nwas conducted. We used student code responses from an online\\nprogramming exam conducted in a Python programming course\\noffered by a Tier-1 research university in our country. The exam\\nwas conducted online, and human proctors monitored students’\\nactivity remotely using Google Meet.\\nIn the programming exam, each student had to attempt 4 pro-\\ngramming questions which where allotted to them at random from\\na pool of 40 questions. The exam duration was 2 hours. Students\\nused the course’s programming portal to write code for a given\\nproblem statement. Students could “run” their code on the portal\\nand check for code correctness using public and private test cases.\\nStudents were allowed to run and submit their code any number\\nof times. The percentage of private test cases passed in the last\\nsubmission made by the student was the score awarded to them for\\nthat particular question. Not submitting for a particular question\\nresulted in the student getting a zero score for that question.\\nThe programming exam was taken by 3399 students in total. Out\\nof the pool of 40 questions, we chose 7 questions for our research.\\nWe used the latest code submissions of all students who submitted\\ntheir codes for the 7 questions as the code corpus for our analysis.\\nThis resulted in 1211 student code responses from the 7 chosen\\nprogramming questions. The questions were chosen such that they\\nincluded a variety of concepts, and varying levels of difficulty. Ques-\\ntions included content from the first six weeks of the course, which\\ncovered basic concepts such as conditional statements, loops, lists,\\nmatrices, strings, functions, and dictionaries. We estimated the dif-\\nficulty level on the basis of average student score in the exam and\\ninputs from the teaching assistants of the Python course.\\n293\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1589: ('t they\\nincluded a variety of concepts, and varying levels of difficulty. Ques-\\ntions included content from the first six weeks of the course, which\\ncovered basic concepts such as conditional statements, loops, lists,\\nmatrices, strings, functions, and dictionaries. We estimated the dif-\\nficulty level on the basis of average student score in the exam and\\ninputs from the teaching assistants of the Python course.\\n293\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2023, July 8–12, 2023, Turku, Finland\\nTable 1: Statistics of the selected questions for which student\\nresponses were given as prompts to GPT-3 for feedback\\nQuestion Concepts No. of Mean Perceived\\nID Submissions Score Difficulty\\nQ_Hamm string,function 213 71.83 easy\\nQ_DOB math,string 176 69.83 easy\\nQ_Ngrm dictionary 180 61.94 medium\\nstring,\\nloops,function\\nQ_AntiDia matrix, math, 159 47.83 medium\\nloops,function\\nQ_Arrw patterns, loops 163 54.17 medium\\nQ_Div maths,loops 174 32.87 hard\\nQ_Hstl string, loops 146 31.19 hard\\nfunction\\n4 METHOD\\n4.1 Research Questions\\nThe research questions guiding this study are as follows:\\n•RQ 1: To what extent does GPT-3 accurately check, critique\\nand provide suggestions to students’ code?\\n•RQ 2: In what ways does GPT-3 correctly or incorrectly\\ncritique students’ code?\\nThe goal of RQ 1 is to examine the accuracy of GPT-3’s feedback.\\nRQ 2 focuses on specific ways in which GPT-3 critiques a given\\nstudent’s code. Answers to this RQ can help us determine if there\\nare specific issues in the code GPT-3 can critique well, and others\\nwhich it handles poorly.\\n4.2 Programming questions and prompts for\\nGPT-3\\nThe data provided to GPT-3 consisted of 1211 student code re-\\nsponses from 7 programming questions asked in the online pro-\\ngramming exam. Consent for analyzing the code responses were\\nobtained from students in two forms:\\n•The use of students data for academic research and pro-\\ngramme improvement is made part of the \"Privacy Policy\"\\nof the programme website\\n•Students agree to the \"Code of Condu', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1590: (' code GPT-3 can critique well, and others\\nwhich it handles poorly.\\n4.2 Programming questions and prompts for\\nGPT-3\\nThe data provided to GPT-3 consisted of 1211 student code re-\\nsponses from 7 programming questions asked in the online pro-\\ngramming exam. Consent for analyzing the code responses were\\nobtained from students in two forms:\\n•The use of students data for academic research and pro-\\ngramme improvement is made part of the \"Privacy Policy\"\\nof the programme website\\n•Students agree to the \"Code of Conduct\" and \"Examination\\nInstructions\" where we specify that the data will be used for\\nlater analysis\\nThe questions were chosen based on different student difficulty\\nlevels and different concepts used (see Section 3 for details). A\\ncondensed version of the questions are shown in Table 2. The\\nnumber of student submissions, concepts covered, mean score and\\nperceived difficulty of each question is shown in Table 1.\\nFor each student response, we provided the following three\\nprompts to the GPT-3 model\\n(1)Check - “Respond with incorrect if the code is incorrect. Re-\\nspond with correct if the code is correct. ”\\nThe purpose of this prompt is to check if GPT-3 is able to\\ncheck whether the code is correct or not.Table 2: Selected questions for which student code submis-\\nsions were given to GPT-3 for providing feedback (the ques-\\ntion statements have been condensed to save space)\\nQuestion Question\\nID\\nQ_Hamm Calculate the hamming distance between two\\nstrings. The Hamming distance between two strings\\nof equal lengths is the number of positions at\\nwhich the corresponding characters are different.\\nFor example, the Hamming distance between ‘great’\\nand ‘green’ is 2, as there are two positions where\\nthe characters differ. If the strings are of unequal\\nlengths, the function should return -1.\\nQ_DOB Find the younger of two persons, given their dates\\nof birth. If both of them share the same date of\\nbirth, then the younger of the two is assumed to be\\nthat person whose name comes first in alphabetical\\norder.\\nQ_Angrm Accept two words as in', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1591: ('umber of positions at\\nwhich the corresponding characters are different.\\nFor example, the Hamming distance between ‘great’\\nand ‘green’ is 2, as there are two positions where\\nthe characters differ. If the strings are of unequal\\nlengths, the function should return -1.\\nQ_DOB Find the younger of two persons, given their dates\\nof birth. If both of them share the same date of\\nbirth, then the younger of the two is assumed to be\\nthat person whose name comes first in alphabetical\\norder.\\nQ_Angrm Accept two words as inputs from the user and print\\nTrue if one word is the anagram of the other and\\nFalse otherwise. All the words will be in lower case.\\nQ_AntiDia Write a function named anti_diagonal that accepts\\na positive integer 𝑛as argument and returns an anti-\\ndiagonal identity matrix of size 𝑛x𝑛.\\nQ_Arrw Accept a positive integer 𝑛as input and print a\\n\"number arrow\" of size 𝑛. For example, 𝑛=3 should\\nproduce the following output:\\n1\\n1,2\\n1,2,3\\n1,2\\n1\\nQ_Div Accept a positive integer 𝑛as input and print the\\nsmallest integer that is divisible by all the integers\\nin the range [1, 𝑛], endpoints inclusive.\\nQ_Hstl Two positive integers are called hostile if they have\\nno digit in common. For example, 1234 and9876 are\\nhostile, whereas 1234 and 38706 are not hostile as\\nthe digit 3is in common. Write a function named\\nhostile_pairs that accepts a list of positive integers\\nas argument and return the number of pairs of hos-\\ntile numbers. ( 𝑎,𝑏) and ( 𝑏,𝑎) represent the same pair\\nand should be counted just once.\\n(2)Critique - “If the code is incorrect, explain what is wrong. If\\nthe code is correct, respond with correct. ”\\nThe desired output from GPT-3 was feedback detailing what\\nwas wrong in the code.\\n(3)Suggest - “If the code is incorrect, provide suggestions to make\\nit right. If the code is correct, suggest improvements. ”\\nThe purpose of this prompt was to understand how GPT-3\\ncan make corrections to incorrect code and suggest improve-\\nments if the code is partially or even fully correct.\\n294\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Risha', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1592: ('incorrect, explain what is wrong. If\\nthe code is correct, respond with correct. ”\\nThe desired output from GPT-3 was feedback detailing what\\nwas wrong in the code.\\n(3)Suggest - “If the code is incorrect, provide suggestions to make\\nit right. If the code is correct, suggest improvements. ”\\nThe purpose of this prompt was to understand how GPT-3\\ncan make corrections to incorrect code and suggest improve-\\nments if the code is partially or even fully correct.\\n294\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil Warriem, & Prajish Prasad\\nWe automated the process of gathering OpenAI’s feedback using\\nthe𝑜𝑝𝑒𝑛𝑎𝑖5library. We generated an API request to the \"text-davnci-\\n003\" model and fed student’s codes for each question as an input\\nprompt to the API request in the following format: question state-\\nment + student’s code + prompt. Hence, for one student submission\\nfor a particular question, we made 3 API requests, with the question\\nstatement and student code remaining the same and only changing\\nthe prompt (either ‘Check’, ‘Critique’ or ‘Suggest’) for each request.\\nStudents’ code submissions were saved in a Google Cloud Bucket\\nand were extracted and converted into a string format before feed-\\ning it as a combined input to the API. Student-ids, their codes and\\nscores along with GPT-3’s response for each prompt was stored in\\na CSV for each question. The above process was repeated for other\\nquestions as well.\\n4.3 Data Analysis\\nTo answer RQ 1 (To what extent does GPT-3 accurately check,\\ncritique, and provide suggestions to students’ code?), we examined\\nGPT-3’s responses to the “Check”, “Critique” and “Suggest” prompts.\\nWe categorized GPT-3’s response to the “Check”, “Critique” and\\n“Suggest” prompts as either accurate or inaccurate. For example, if\\nGPT-3’s response to the “Critique” prompt is “Incorrect”, to a code\\nwhich did not pass any test case (i.e. with a score of 0), the response\\nis categorized as “Accurate”, since GPT-3 correctly identified that\\nthe code is ', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1593: ('s GPT-3 accurately check,\\ncritique, and provide suggestions to students’ code?), we examined\\nGPT-3’s responses to the “Check”, “Critique” and “Suggest” prompts.\\nWe categorized GPT-3’s response to the “Check”, “Critique” and\\n“Suggest” prompts as either accurate or inaccurate. For example, if\\nGPT-3’s response to the “Critique” prompt is “Incorrect”, to a code\\nwhich did not pass any test case (i.e. with a score of 0), the response\\nis categorized as “Accurate”, since GPT-3 correctly identified that\\nthe code is incorrect. Whereas if GPT-3’s response is “Incorrect”\\nto a student’s code that passes all test-cases (i.e. with a score of\\n100), then this response is categorized as “Inaccurate”. For some\\n“Critique” and “Suggest” prompts, GPT-3’s correctly responded that\\nthe code was correct/incorrect, but provided inaccurate critique or\\nsuggestions. We categorized these responses as “Inaccurate” since\\nthe explanations were incorrect. We then aggregated the correct\\nand incorrect responses for all three prompts for each question.\\nTo answer RQ 2 (In what ways does GPT-3 correctly or incor-\\nrectly critique students’ code?), we used GPT-3’s responses to the\\n“Critique” prompts as data. We used a thematic analysis approach\\nto analyse these responses. Thematic analysis is the process of iden-\\ntifying patterns or themes within qualitative data [ 3]. Two authors\\nindependently coded for the same 40 GPT-3 “Critique” responses\\n(20 GPT-3 responses from 2 questions) and came up with the ini-\\ntial codes. The responses were chosen in a manner such that the\\nsample had a diverse range of student scores. After independently\\ncoming up with the codes, both authors discussed between them-\\nselves, and came to an agreement on the codes. After that, both\\nauthors independently coded a total of 100 GPT-3 “Critique” re-\\nsponses (20 responses each from the remaining 5 questions). After\\nindependently coming up with themes, both researchers discussed\\nbetween themselves, reviewed and defined the themes and came to\\nan agreement on the final themes.\\n5https://o', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1594: ('er such that the\\nsample had a diverse range of student scores. After independently\\ncoming up with the codes, both authors discussed between them-\\nselves, and came to an agreement on the codes. After that, both\\nauthors independently coded a total of 100 GPT-3 “Critique” re-\\nsponses (20 responses each from the remaining 5 questions). After\\nindependently coming up with themes, both researchers discussed\\nbetween themselves, reviewed and defined the themes and came to\\nan agreement on the final themes.\\n5https://openai.com/api/Table 3: Accuracy of GPT-3’s responses for the check, critique\\nand suggest prompts\\nQuestion Difficulty Check Critique Suggest\\nID % % %\\nQ_Hamm easy 79.34 76.53 92.96\\nQ_DOB easy 61.37 58.52 36.93\\nQ_Angrm medium 65 41.11 70\\nQ_AntiDia medium 77.35 74.22 80.5\\nQ_Arrw medium 78.53 58.9 49.08\\nQ_Div hard 56.9 66.09 31.6\\nQ_Hstl hard 79.45 63.01 72.6\\nAverage 71.13 62.63 61.95\\n5 FINDINGS\\n5.1 Accuracy of GPT-3’s feedback to students’\\ncode\\nWe first examine how accurately GPT-3 can check, critique, and\\nprovide suggestions to students’ code. Table 3 summarizes the accu-\\nracy of GPT-3’s feedback for the “Check”, “Critique” and “Suggest”\\nprompts on students’ code responses. Aggregating across all ques-\\ntions, GPT-3 was able to accurately check for code correctness for\\n71.13% of the total submissions, critique student’s code for 62.63%\\nof the total submissions, and suggest improvements for 61.95% of\\nthe total submissions. Across questions, the range of accurately pro-\\nviding feedback was between 57% to 79% for the “Check” prompt,\\nbetween 41% to 77% for the “Critique” prompt, and between 32%\\nand 93% for the “Suggest” prompt.\\nWhen we compared the accuracy of GPT-3’s feedback across\\nquestions for each type of prompt, we were unable to detect obvious\\npatterns (see Table 3). We assumed that the accuracy of checking, cri-\\ntiquing, and suggesting changes in students’ code would be higher\\nfor ‘easy’ questions, compared to ‘hard’ ones. However, this has not\\nbeen the case. For example, the accuracy of GPT-3’s responses for\\nQ_', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1595: (' “Check” prompt,\\nbetween 41% to 77% for the “Critique” prompt, and between 32%\\nand 93% for the “Suggest” prompt.\\nWhen we compared the accuracy of GPT-3’s feedback across\\nquestions for each type of prompt, we were unable to detect obvious\\npatterns (see Table 3). We assumed that the accuracy of checking, cri-\\ntiquing, and suggesting changes in students’ code would be higher\\nfor ‘easy’ questions, compared to ‘hard’ ones. However, this has not\\nbeen the case. For example, the accuracy of GPT-3’s responses for\\nQ_DOB (which has been classified as an ‘easy’ question) is lower\\nthan Q_Hstl (a ‘hard’ question).\\nComparing the accuracy of GPT-3’s feedback across different\\nprompts for the same question, we see that the accuracy of “Check”\\nprompts’ feedback was higher than that of “Critique“ prompts’\\nfeedback. This seems intuitive, as checking if a code response is\\ncorrect is easier than explaining what is wrong in the code. However,\\nin some cases, the accuracy of “Suggest” prompts feedback was\\nhigher than that of “Check” and “Critique”. This seems to indicate\\nthat generating code for a given problem is easier for the GPT-3\\nmodel to do rather than check or critique a given code.\\nThe variability in accuracy of the feedback (between 32% to 93%)\\nas well as low accuracy percentages across questions gives a clear\\nindicator that the current GPT-3 model cannot be ‘directly’ used to\\nprovide feedback for programming assessments.\\n5.2 Categories of critiquing students’ code\\nWe answer the second research question by examining the broad\\nthemes which emerged from the thematic analysis of GPT-3 model’s\\n“Critique” responses for students’ code submissions. We found that\\n295\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2023, July 8–12, 2023, Turku, Finland\\nthe GPT-3 model generated accurate as well as inaccurate expla-\\nnations for it’s critique of students’ code. The feedback provided\\nwas sometimes generic, and sometimes specific to the students’\\ncode. Specific feedback involves both correct and i', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1596: ('hemes which emerged from the thematic analysis of GPT-3 model’s\\n“Critique” responses for students’ code submissions. We found that\\n295\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2023, July 8–12, 2023, Turku, Finland\\nthe GPT-3 model generated accurate as well as inaccurate expla-\\nnations for it’s critique of students’ code. The feedback provided\\nwas sometimes generic, and sometimes specific to the students’\\ncode. Specific feedback involves both correct and incorrect expla-\\nnations regarding variable initialization and updates, conditionals,\\nand iteration.\\n5.2.1 Generic Feedback. This feedback involved explanations re-\\ngarding the broad steps and logic that the program can follow. This\\nincludes the GPT-3 model\\n•Identifying the use case for which the code will work, and\\nnot work\\n•Identifying what the code is doing incorrectly\\n•Identifying how the code is different from what the code is\\nsupposed to do\\n•Identifying what is missing in the code\\nFor example, consider the following incorrect student code for\\nthe Q_Angrm question shown in Figure 1\\nFigure 1: Incorrect student code for the Q_Angrm question\\nThe critique response provided by the GPT-3 model is “Incorrect.\\nThis code only checks if the two words are the same by comparing the\\ntwo words letter by letter, without looking at all possible arrangements\\nof the letters in each word. ”.\\nThis response shows that the model is able to understand the code,\\nand is correctly able to identify the issue with student code.\\nOn the other hand, the GPT-3 model makes generic incorrect\\nsuggestions. For example, the model\\n•Incorrectly states what the output of the student’s program\\nwill be\\n•Incorrectly states that user is not returning what is intended\\n•Incorrectly recognizes that one of the conditions of the task\\nis not being satisfied\\n•Incorrectly suggests that the code is not doing a step when\\nin fact it is doing it\\n•Identifies that the function does not consider a particular\\nuse case (although it is not required to consider it)\\n•Is', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1597: ('he other hand, the GPT-3 model makes generic incorrect\\nsuggestions. For example, the model\\n•Incorrectly states what the output of the student’s program\\nwill be\\n•Incorrectly states that user is not returning what is intended\\n•Incorrectly recognizes that one of the conditions of the task\\nis not being satisfied\\n•Incorrectly suggests that the code is not doing a step when\\nin fact it is doing it\\n•Identifies that the function does not consider a particular\\nuse case (although it is not required to consider it)\\n•Is unable to capture the logic of the entire code and hence\\nprovides corrections based on a part of the code\\nConsider the student code shown in Figure 2 for question Q_Hamm,\\nwhich is correct and passed all test cases. The “Critique” feedback\\ngiven by the GPT-3 model is as follows - “Incorrect. Your code should\\ninclude an if-else statement to return -1 if the lengths of the two strings\\ndiffer. Additionally, you should be returning the value of c instead of\\njust the boolean expression. ”\\nWe see that the model incorrectly recognizes that a conditional and\\nreturn statement is missing.\\nFigure 2: Correct student code for the Q_Hamm question\\n5.2.2 Variable initialization and updates. The GPT-3 model is able\\nto provide appropriate feedback regarding what variables have to\\nbe initialized and updated. Similar to generic feedback, we see that\\nthe GPT-3 model provides both correct and incorrect feedback. Our\\nanalysis shows that the model\\n•Identifies missing variables and where it has to be updated\\n•Recognizes incorrect updates/changes made to variables\\n•Incorrectly identifies that a variable is undefined, when it\\nhas in fact been defined\\n•Incorrectly identifies that a variable is not updated\\n5.2.3 Conditionals. The GPT-3 model is correctly able to\\n•Recognize the need of an if-else construct\\n•Recognize what the conditionals are checking\\n•Recognize that the conditional statement is incorrect\\nHowever, the model incorrectly recognizes that a conditional is\\nmissing, although it is present in the code.\\n5.2.4 Iteration. The model i', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1598: ('ates/changes made to variables\\n•Incorrectly identifies that a variable is undefined, when it\\nhas in fact been defined\\n•Incorrectly identifies that a variable is not updated\\n5.2.3 Conditionals. The GPT-3 model is correctly able to\\n•Recognize the need of an if-else construct\\n•Recognize what the conditionals are checking\\n•Recognize that the conditional statement is incorrect\\nHowever, the model incorrectly recognizes that a conditional is\\nmissing, although it is present in the code.\\n5.2.4 Iteration. The model is able to correctly recognize errors\\nrelated to loop syntax, loop initialization, and the range of loop.\\nHowever, similar to previous cases, it provides incorrect reasons as\\nwell. Our analysis shows that the model\\n•Correctly recognizes the need for iteration (so that code can\\nbe generalized for different inputs)\\n•Correctly recognizes that iteration is missing\\n•Correctly identifies that only one loop is needed\\n•Correctly recognizes that the loop is initialized incorrectly\\n•Correctly recognizes incorrect loop syntax\\n•Correctly identifies that the range is incorrect\\n•Correctly identifies that the index can go out of bounds\\n•Does not recognize that an additional loop has been added\\nwhich is not needed\\n•Incorrectly identifies that a loop will not terminate\\n•Incorrectly determines what the range of the loop should be\\nWe highlight some of above mentioned response categories using\\nthe following example. Consider the following incorrect student\\nsolution for question Q_Hamm as shown in Figure 3. The response\\nprovided by the GPT-3 model is as follows - “Incorrect. The variable\\nd should be initialized to 0 before the loop, and should be incremented\\nby 1 inside the loop if there is a difference between the characters. ”\\nWe see that the model is correctly able to suggest what variables\\nare missing and what it should be initialized to. However, it failed\\nto recognize that student used 2 loops, where only 1 was needed in\\nthis case.\\n296\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Rishabh Balse, Bharath Valaboju, Shreya Singhal', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1599: ('y the GPT-3 model is as follows - “Incorrect. The variable\\nd should be initialized to 0 before the loop, and should be incremented\\nby 1 inside the loop if there is a difference between the characters. ”\\nWe see that the model is correctly able to suggest what variables\\nare missing and what it should be initialized to. However, it failed\\nto recognize that student used 2 loops, where only 1 was needed in\\nthis case.\\n296\\nITiCSE 2023, July 8–12, 2023, Turku, Finland Rishabh Balse, Bharath Valaboju, Shreya Singhal, Jayakrishnan Madathil Warriem, & Prajish Prasad\\nFigure 3: Incorrect student code for the Q_Hamm question\\n6 DISCUSSION\\n6.1 Accuracy of the GPT-3 model responses\\n(RQ1)\\nThe key finding from RQ 1 (accuracy of GPT-3 model’s responses)\\nis that there is high variability in the accuracy of the model’s re-\\nsponses. The model does seem to perform reasonably well in check-\\ning, critiquing, and suggesting changes in students’ code for some\\nquestions (e.g. Q_Hamm - Suggest - 92.96%), and poorly for others\\n(e,g, Q_Div - Suggest - 31.6%, Q_DOB - Suggest - 36.93%) (see Table\\n3). Aggregating across all questions, GPT-3 was able to accurately\\ncheck for code correctness for 71.13% of the total submissions, cri-\\ntique student’s code for 62.63% of the total submissions, and suggest\\nimprovements for 61.95% of the total submissions. These average ac-\\ncuracy numbers have been similar to previous work examining the\\ncorrectness of code automatically generated by LLMs like CoPilot\\nand Codex [ 7,10]. However, in the context of providing feedback to\\nstudents, the accuracy percentage is low. Taking averages across all\\nquestions and all prompts, we find that the model was not able to ac-\\ncurately identify the correctness state of the students’ submission\\nfor roughly one-third of the submissions. Hence, a key implica-\\ntion is that instructors cannot rely on such a model for automated\\nfeedback for all students.\\n6.2 Categories of GPT-3 model’s feedback (RQ 2)\\nIn RQ 2, we explored the different kinds of critique the GPT-3 model\\nprovided for st', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1600: ('ng feedback to\\nstudents, the accuracy percentage is low. Taking averages across all\\nquestions and all prompts, we find that the model was not able to ac-\\ncurately identify the correctness state of the students’ submission\\nfor roughly one-third of the submissions. Hence, a key implica-\\ntion is that instructors cannot rely on such a model for automated\\nfeedback for all students.\\n6.2 Categories of GPT-3 model’s feedback (RQ 2)\\nIn RQ 2, we explored the different kinds of critique the GPT-3 model\\nprovided for student code responses. The categories that emerged\\nfrom the thematic analysis shows that there are both correct as\\nwell as incorrect feedback provided by the GPT-3 model to stu-\\ndent responses. The model provided generic, broad-level feedback\\nregarding what the code is doing incorrectly, what is missing in\\nthe code, and what the code is doing incorrectly. The model also\\ngave specific feedback regarding student code - such as variables,\\nconditionals and loops.\\nAlthough there were instances where the model provided correct\\nfeedback and explanations, we also found incorrect instances, where\\nthe feedback directly contradicted what was present in the code\\n(see examples in Section 5.2.1). Based on our analysis, we could not\\ncome up with a definitive answer to specific issues the model can\\nor cannot critique in the code. For example, for some submissions,\\nthe model is able to identify uninitialized variables and number of\\nloops required, but fails to identify these issues in other submissions.\\nHence, this makes it difficult to predict for what type of code issueswe can expect LLM models like GPT-3 to provide accurate and\\nsuitable feedback.\\nWe also found that most of the incorrect responses and expla-\\nnations were provided in an authoritative and confident manner.\\nThese instances provide indications that current versions of an\\nLLM like GPT-3 cannot be “directly” used to provide feedback to\\nstudents. Explanations that contradict or falsify the code written\\nby students does not serve the intended purpose of feedback, and\\n', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1601: ('fficult to predict for what type of code issueswe can expect LLM models like GPT-3 to provide accurate and\\nsuitable feedback.\\nWe also found that most of the incorrect responses and expla-\\nnations were provided in an authoritative and confident manner.\\nThese instances provide indications that current versions of an\\nLLM like GPT-3 cannot be “directly” used to provide feedback to\\nstudents. Explanations that contradict or falsify the code written\\nby students does not serve the intended purpose of feedback, and\\nwould naturally confuse students. The confident manner of the\\nGPT-3 model’s incorrect responses can also mislead students and\\neven instructors on the correctness of their own solutions.\\n6.3 Limitations\\nThe above findings should be considered in light of certain limi-\\ntations in the study. First, models like GPT-3 are probabilistic and\\nnon-deterministic [ 5], and hence the model might generate differ-\\nent responses for the same student code when we run it each time.\\nHowever, we have tried to mitigate this by choosing a large data set.\\nSecond, for the “Suggest” prompts, we checked only for the correct-\\nness of the suggestions, and not other aspects like efficiency of the\\nprovided code. We intend to examine this in future studies. Third,\\nthe problem set we have chosen considers only Python programs,\\nand specific programming concepts, and hence the findings may\\nnot be generalizable to other programming languages and concepts.\\nThis can also be explored in future studies.\\n7 CONCLUSION AND FUTURE WORK\\nIn this paper, we examined the capability of a large language model\\nlike GPT-3 to provide feedback for students’ programming assess-\\nments. Our findings show that there is a high variability in the\\naccuracy of the GPT-3 model in checking the correctness of the\\ncode, critiquing what was wrong with the code, and in suggesting\\nproper changes to improve the code. We also observed instances\\nof incorrect, inconsistent feedback provided in a confident tone.\\nThese findings imply that models like GPT-3 currently cannot be\\n‘direct', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1602: (' we examined the capability of a large language model\\nlike GPT-3 to provide feedback for students’ programming assess-\\nments. Our findings show that there is a high variability in the\\naccuracy of the GPT-3 model in checking the correctness of the\\ncode, critiquing what was wrong with the code, and in suggesting\\nproper changes to improve the code. We also observed instances\\nof incorrect, inconsistent feedback provided in a confident tone.\\nThese findings imply that models like GPT-3 currently cannot be\\n‘directly’ used to provide feedback to students.\\nThese findings provide several directions for future research.\\nWe intend to compare the feedback which GPT-3 generated with\\nmore recent models like GPT-4. This can give indicators of how\\nrecent models are performing compared to previous models. We\\nalso plan to explore how such feedback can be used by instructors\\nand TAs. LLMs like GPT-3 can aid instructors in crafting feedback\\nresponses for students’ code. Instead of going through students’\\ncode and trying to decipher the logic behind the code, LLMs can\\nassist instructors by providing critique and suggestions to students’\\nwritten code. Ultimately, the feedback provided by LLMs like GPT-3\\nshould be useful to students. Hence, an important next step is to\\nunderstand perceptions of students on the feedback generated by\\nsuch models. This can help us gain a more nuanced understand-\\ning of the potential of LLMs like GPT-3 in providing feedback for\\nprogramming assessments.\\n8 ACKNOWLEDGMENTS\\nThe authors acknowledge the support provided by the administra-\\ntors and instructors of BS Programme in Data Science and Applica-\\ntions at IIT Madras in carrying out the study.\\n297\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2023, July 8–12, 2023, Turku, Finland\\nREFERENCES\\n[1]Nimisha Agarwal and Amey Karkare. 2022. LEGenT: Localizing Errors and\\nGenerating Testcases for CS1. In Proceedings of the Ninth ACM Conference on\\nLearning@ Scale. 102–112.\\n[2]Brett A Becker, Paul Denny, James Finnie-Ansl', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1603: (' provided by the administra-\\ntors and instructors of BS Programme in Data Science and Applica-\\ntions at IIT Madras in carrying out the study.\\n297\\nInvestigating the Potential of GPT-3 in Providing Feedback for Programming Assessments ITiCSE 2023, July 8–12, 2023, Turku, Finland\\nREFERENCES\\n[1]Nimisha Agarwal and Amey Karkare. 2022. LEGenT: Localizing Errors and\\nGenerating Testcases for CS1. In Proceedings of the Ninth ACM Conference on\\nLearning@ Scale. 102–112.\\n[2]Brett A Becker, Paul Denny, James Finnie-Ansley, Andrew Luxton-Reilly, James\\nPrather, and Eddie Antonio Santos. 2023. Programming Is Hard-Or at Least It\\nUsed to Be: Educational Opportunities and Challenges of AI Code Generation. In\\nProceedings of the 54th ACM Technical Symposium on Computer Science Education\\nV. 1. 500–506. https://doi.org/10.1145/3545945.3569759\\n[3]Virginia Braun and Victoria Clarke. 2012. Thematic analysis. American Psycho-\\nlogical Association.\\n[4]Cristian Cadar, Daniel Dunbar, Dawson R Engler, et al .2008. Klee: unassisted\\nand automatic generation of high-coverage tests for complex systems programs..\\nInOSDI, Vol. 8. 209–224.\\n[5]Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira\\nPinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman,\\net al.2021. Evaluating large language models trained on code. arXiv preprint\\narXiv:2107.03374 (2021).\\n[6]Koen Claessen and John Hughes. 2000. QuickCheck: a lightweight tool for\\nrandom testing of Haskell programs. In Proceedings of the fifth ACM SIGPLAN\\ninternational conference on Functional programming. 268–279.\\n[7]Paul Denny, Viraj Kumar, and Nasser Giacaman. 2023. Conversing with Copilot:\\nExploring prompt engineering for solving CS1 problems using natural language.\\nInProceedings of the 54th ACM Technical Symposium on Computer Science Educa-\\ntion V. 1. 1136–1142.\\n[8]Stephen H Edwards. 2003. Improving student performance by evaluating how\\nwell students test their own programs. Journal on Educational Resources in\\nComputing (JERIC) 3, 3 (2003), 1–es.\\n[9]Stephen', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1604: ('rnational conference on Functional programming. 268–279.\\n[7]Paul Denny, Viraj Kumar, and Nasser Giacaman. 2023. Conversing with Copilot:\\nExploring prompt engineering for solving CS1 problems using natural language.\\nInProceedings of the 54th ACM Technical Symposium on Computer Science Educa-\\ntion V. 1. 1136–1142.\\n[8]Stephen H Edwards. 2003. Improving student performance by evaluating how\\nwell students test their own programs. Journal on Educational Resources in\\nComputing (JERIC) 3, 3 (2003), 1–es.\\n[9]Stephen H Edwards, Zalia Shams, Michael Cogswell, and Robert C Senkbeil.\\n2012. Running students’ software tests against each others’ code: new life for an\\nold\" gimmick\". In Proceedings of the 43rd ACM technical symposium on Computer\\nScience Education. 221–226.\\n[10] James Finnie-Ansley, Paul Denny, Brett A Becker, Andrew Luxton-Reilly, and\\nJames Prather. 2022. The Robots Are Coming: Exploring the Implications of Ope-\\nnAI Codex on Introductory Programming. In Australasian Computing EducationConference. 10–19.\\n[11] Michael H Goldwasser. 2002. A gimmick to integrate software testing throughout\\nthe curriculum. ACM SIGCSE Bulletin 34, 1 (2002), 271–275.\\n[12] Petri Ihantola, Tuukka Ahoniemi, Ville Karavirta, and Otto Seppälä. 2010. Review\\nof recent systems for automatic assessment of programming assignments. In\\nProceedings of the 10th Koli calling international conference on computing education\\nresearch. 86–93.\\n[13] David Jackson and Michelle Usher. 1997. Grading student programs using ASSYST.\\nInProceedings of the twenty-eighth SIGCSE technical symposium on Computer\\nscience education. 335–339.\\n[14] Juho Leinonen, Arto Hellas, Sami Sarsa, Brent Reeves, Paul Denny, James Prather,\\nand Brett A Becker. 2023. Using Large Language Models to Enhance Programming\\nError Messages. In Proceedings of the 54th ACM Technical Symposium on Computer\\nScience Education V. 1. 563–569.\\n[15] Stephen Macneil, Joanne Kim, Juho Leinonen, Paul Denny, Seth Bernstein, Brett\\nBecker, Michel Wermelinger, Arto Hellas, Andrew Tran, Sami Sarsa, James\\nPrather, ', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1605: ('ighth SIGCSE technical symposium on Computer\\nscience education. 335–339.\\n[14] Juho Leinonen, Arto Hellas, Sami Sarsa, Brent Reeves, Paul Denny, James Prather,\\nand Brett A Becker. 2023. Using Large Language Models to Enhance Programming\\nError Messages. In Proceedings of the 54th ACM Technical Symposium on Computer\\nScience Education V. 1. 563–569.\\n[15] Stephen Macneil, Joanne Kim, Juho Leinonen, Paul Denny, Seth Bernstein, Brett\\nBecker, Michel Wermelinger, Arto Hellas, Andrew Tran, Sami Sarsa, James\\nPrather, and Viraj Kumar. 2023. The Implications of Large Language Models for\\nCS Teachers and Students. https://doi.org/10.1145/3545947.3573358\\n[16] Stephen MacNeil, Andrew Tran, Arto Hellas, Joanne Kim, Sami Sarsa, Paul\\nDenny, Seth Bernstein, and Juho Leinonen. 2023. Experiences from using code\\nexplanations generated by large language models in a web software development\\ne-book. In Proceedings of the 54th ACM Technical Symposium on Computer Science\\nEducation V. 1. 931–937.\\n[17] Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bernstein, Erin Ross, and Ziheng\\nHuang. 2022. Generating diverse code explanations using the gpt-3 large language\\nmodel. In Proceedings of the 2022 ACM Conference on International Computing\\nEducation Research-Volume 2. 37–39.\\n[18] Sami Sarsa, Paul Denny, Arto Hellas, and Juho Leinonen. 2022. Automatic\\ngeneration of programming exercises and code explanations using large language\\nmodels. In Proceedings of the 2022 ACM Conference on International Computing\\nEducation Research-Volume 1. 27–43.\\n[19] Michel Wermelinger. 2023. Using GitHub Copilot to Solve Simple Programming\\nProblems. (2023).\\n[20] John Wrenn, Shriram Krishnamurthi, and Kathi Fisler. 2018. Who tests the\\ntesters?. In Proceedings of the 2018 ACM Conference on International Computing\\nEducation Research. 51–59.\\n298', 'Investigating the Potential of GPT-3 in Providing Feedback for Programming Assessments.pdf'), 1606: ('See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/337876790\\nAN ANALYSIS OF EVALUATION METRICS OF GANS\\nConf erence Paper  · July 2019\\nCITATIONS\\n25READS\\n6,486\\n3 author s:\\nHamed Alqaht ani\\nMac quarie Univ ersity\\n35 PUBLICA TIONS \\xa0\\xa0\\xa01,575  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nManoly a Kav akli\\nMac quarie Univ ersity\\n144 PUBLICA TIONS \\xa0\\xa0\\xa02,273  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nGulshan K umar\\nShaheed Bhag at Singh St ate Univ ersity, Ferozepur\\n77 PUBLICA TIONS \\xa0\\xa0\\xa03,060  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Hamed Alqaht ani on 11 Dec ember 2019.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.\\nANANALYSIS OF EVALUATION METRICS OF GAN S\\nA P REPRINT\\nHamed Alqahtani\\nPostgraduate Student\\nMacquarie University\\nhsqahtani@kku.edu.saManolya Kavakli-Thorne\\nAssociate Professor\\nMacquarie University\\nmanolya.kavakli@mq.edu.auGulshan Kumar\\nAssistant Professoor\\nSBSSTC, Ferozepur\\ngulshanahuja@gmail.com\\nDecember 11, 2019\\nABSTRACT\\nGenerative adversarial networks (GANs) have gained signiﬁcant attention in recent years. A number\\nof GAN variants have been proposed and have been utilized in many applications. Despite a large\\nnumber of applications and developments in GANs, few works have studied the metrics that evaluate\\nGANs’ performance.\\nIn this paper, we present a comprehensive analysis of the most commonly used evaluation metrics\\nfor measuring the performance of GANs. We discuss their deﬁnitions of by explaining them\\nmathematically and analyzed their pros and cons in the context of GANs. Based on our analysis,\\nwe observe that deﬁning an appropriate metric for evaluating GAN’s performance is still an open\\nproblem, not only for fair model comparison but also for understanding, improving, and developing\\ngenerative models. Overall, this study suggests that the choice of feature space in which to compute\\nvarious metrics is crucial. In addition, it is suggested to create a code repository of evaluation metrics\\nthat enable the conduct of a ', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1607: (' and analyzed their pros and cons in the context of GANs. Based on our analysis,\\nwe observe that deﬁning an appropriate metric for evaluating GAN’s performance is still an open\\nproblem, not only for fair model comparison but also for understanding, improving, and developing\\ngenerative models. Overall, this study suggests that the choice of feature space in which to compute\\nvarious metrics is crucial. In addition, it is suggested to create a code repository of evaluation metrics\\nthat enable the conduct of a comparative empirical and analytical studies of available measures for\\nbenchmarking models under the same conditions using more than one metrics in the future.\\n1 Introduction\\nGenerative adversarial networks (GANs) are a recently developed technique for learning in both semi-supervised and\\nunsupervised mode. These networks obtain it through modelling high-dimensional distributions of data implicitly.\\nFirstly, Goodfellow et al. [ 1] introduced the adversarial process to learn generative models. The fundamental aspect\\nof GAN is the min-max two-person zero-sum game. In this game, one player takes the advantages at the equivalent\\nloss of the other player. Here, the players correspond to different networks of GAN called discriminator and generator.\\nThe main objective of the discriminator consists of determining whether a sample belongs to a fake distribution or real\\ndistribution. Whereas, generator aims to deceive the discriminator by generating fake sample distribution. Discriminator\\nproduces the chances or probability of a given sample to be a real sample. A higher value of probability shows that the\\nsample is likely to be a real sample. The value close to zero indicates that the sample is a fake sample. The probability\\nvalue near 0.5 indicates the generation of an optimal solution, such that discriminator is unable to differentiate fake and\\nreal sample.\\nGAN models can be divided into two categories, namely, explicit and implicit. The explicit GAN models assume access\\nto the model likelihood function, whereas the i', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1608: ('ility of a given sample to be a real sample. A higher value of probability shows that the\\nsample is likely to be a real sample. The value close to zero indicates that the sample is a fake sample. The probability\\nvalue near 0.5 indicates the generation of an optimal solution, such that discriminator is unable to differentiate fake and\\nreal sample.\\nGAN models can be divided into two categories, namely, explicit and implicit. The explicit GAN models assume access\\nto the model likelihood function, whereas the implicit models utilizes a sampling mechanism to generate data. Explicit\\nmodels includes variational auto-encoders (V AEs) [2] and PixelCNN [3]. Implicit models includes GANs.\\nGenerative adversarial networks (GANs) [ 1] have been studied extensively in recent years. Besides producing\\nsurprisingly plausible images of faces [ 4][5] and bedrooms [ 6][7], they have also been innovatively applied in, for\\nexample, semi-supervised learning [ 3][8], image-to-image translation [ 9], and simulated image reﬁnement [ 10]. But,\\ndespite the availability of a plethora of GAN models, these models are evaluated is still qualitative, very often resorting\\nto manual inspection of the visual ﬁdelity of generated images. The manual inspection is time-consuming, subjective\\nand probably misleading.\\nAPREPRINT - DECEMBER 11, 2019\\nSeveral evaluation metrics have been deﬁned for measuring the performance of GAN models. In GANs, the objective\\nfunction for the generator and the discriminator usually measures how well they are doing relative to the opponent.\\nFor example, we measure how well the generator is fooling the discriminator. It is not a good metric in measuring the\\nimage quality or its diversity.\\nNowadays, researchers focused on quantitative evaluation of GAN models along with qualitative metrics. Both,\\nqualitative and quantitative metrics have their own pros and cons. Quantitative metrics less subjective, and not directly\\nmap to how humans perceive and judge generated images. These along with other problems like the variety of proba', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1609: ('e to the opponent.\\nFor example, we measure how well the generator is fooling the discriminator. It is not a good metric in measuring the\\nimage quality or its diversity.\\nNowadays, researchers focused on quantitative evaluation of GAN models along with qualitative metrics. Both,\\nqualitative and quantitative metrics have their own pros and cons. Quantitative metrics less subjective, and not directly\\nmap to how humans perceive and judge generated images. These along with other problems like the variety of probability\\ncriteria and the lack of a perceptually meaningful image similarity measures, have made evaluating generative models\\ndifﬁcult and challenging [11].\\nHowever, there is no globally accepted agreement regarding the best GAN evolution metrics. Some researchers\\nproposed to benchmark GANs [ 12]. These research efforts are beneﬁcial for extending research for understanding GAN\\nevaluation metrics to analyze their pros and cons.\\n2 GAN and its Variants\\nFirstly, Goodfellow et al. [ 1] introduced the adversarial process to learn generative models. The fundamental aspect\\nof GAN is the min-max two-person zero-sum game. In this game, one player takes the advantages at the equivalent\\nloss of the other player. Here, the players correspond to different networks of GAN called discriminator and generator.\\nThe main objective of the discriminator consists of determining whether a sample belongs to a fake distribution or real\\ndistribution. Whereas, generator aims to deceive the discriminator by generating fake sample distribution. The general\\narchitecture of GAN is shown in Figure 1.\\nFigure 1: The general architecture of GAN.\\nIn general architecture, a generative adversarial network has two types of networks called discriminator and generator\\ndenoted as D and G respectively.\\n1.The Generator (G): The G is a network that is used to generate the images using random noise Z. The\\ngenerated images using noise are recorded as G(z). The input that is commonly a Gaussian noise that is a\\nrandom point in latent space. Parameters of both t', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1610: ('tion. The general\\narchitecture of GAN is shown in Figure 1.\\nFigure 1: The general architecture of GAN.\\nIn general architecture, a generative adversarial network has two types of networks called discriminator and generator\\ndenoted as D and G respectively.\\n1.The Generator (G): The G is a network that is used to generate the images using random noise Z. The\\ngenerated images using noise are recorded as G(z). The input that is commonly a Gaussian noise that is a\\nrandom point in latent space. Parameters of both the G and D networks are updated iteratively during the\\ntraining process of GAN. Infected the parameters of D remain static while training the G network. The output\\nof G network is labelled as fake distribution and given to D network as an input for determining its class. The\\nerror is computed between the output of the discriminator and the label of the sample image. The error is\\npropagated back to update the weights of G network. A few constraints have been imposed on input parameters\\nof G network that can be added in the last layer of this network. In addition, noise can also be added to the\\nhidden layers. There is no limit on the dimensions of input Z of G networks.\\n2.The Discriminator (D): The D is considered as a discriminant network to determine whether a given image\\nbelongs to a real distribution or not. It receives an input image X and produces the output D (x), representing\\nthe probability that X belongs to a real distribution. If the output is 1, then it indicates a real image distribution.\\nThe output value of D as 0 indicates that it belongs to a fake image distribution. During the training process of\\nthe network, G network remains static. D network takes a real image as well as the fake image generated by g\\nnetwork as input to compute the error in its label prediction. The weights of the discriminator D network are\\nupdated on the basis of back-propagated error.\\n2\\nAPREPRINT - DECEMBER 11, 2019\\nThe objective function of a two-player minimax game would be as Eq. 1.\\nGMinDMaxV (D;G ) =Ex\\x18pdata (x)[log(d(x', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1611: ('t value of D as 0 indicates that it belongs to a fake image distribution. During the training process of\\nthe network, G network remains static. D network takes a real image as well as the fake image generated by g\\nnetwork as input to compute the error in its label prediction. The weights of the discriminator D network are\\nupdated on the basis of back-propagated error.\\n2\\nAPREPRINT - DECEMBER 11, 2019\\nThe objective function of a two-player minimax game would be as Eq. 1.\\nGMinDMaxV (D;G ) =Ex\\x18pdata (x)[log(d(x))] (1)\\n+Ez\\x18pg(z)[log(1\\x00D(G(z)))]\\nThe major difference between discriminative and generative algorithms is that discriminative networks learn the\\nboundaries between classes (as the Discriminator does) while generative networks learn the distribution of classes (as\\nthe Generator does) [13].\\nWith the passage of time, several GAN models have been developed. Some important developments are as follows.\\n\\x0fConditional GAN (CGAN) [14]: GANs can be extended to a conditional model if both the G and D networks\\nare conditioned on some extra information y to address the limitation of dependence only on random variables\\nin original model [ 14]. y could be any kind of auxiliary information, such as class labels or data from other\\nmodalities. The conditional information can be added by feeding y into the both the D and G network as an\\nadditional input layer.\\nIn the G network, the prior input noise pz(z), and y are combined in joint hidden representation, and the\\nadversarial training framework allows for considerable ﬂexibility in how this hidden representation is composed\\n[14]. In the D network, x and y are presented as inputs and to a D function. The objective function of a\\ntwo-player minimax game would be as Eq. 2.\\nGMinDMaxV (D;G ) =Ey;x\\x18pdata (y;x)[log(d(y;x))] (2)\\n+Ex\\x18px;z\\x18pz(z)[log(1\\x00D(G(z;x);x))]\\n\\x0fDeep Convolutional Generative Adversarial Networks (DCGAN): Radford et al. [ 4] proposed a new class\\nof CNNs called Deep Convolutional Generative Adversarial Networks (DCGANs) having certain architectural\\nconstraints. These cons', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1612: ('y in how this hidden representation is composed\\n[14]. In the D network, x and y are presented as inputs and to a D function. The objective function of a\\ntwo-player minimax game would be as Eq. 2.\\nGMinDMaxV (D;G ) =Ey;x\\x18pdata (y;x)[log(d(y;x))] (2)\\n+Ex\\x18px;z\\x18pz(z)[log(1\\x00D(G(z;x);x))]\\n\\x0fDeep Convolutional Generative Adversarial Networks (DCGAN): Radford et al. [ 4] proposed a new class\\nof CNNs called Deep Convolutional Generative Adversarial Networks (DCGANs) having certain architectural\\nconstraints. These constraints involved adopting and modifying three changes to the CNN architectures.\\n–Removing fully-connected hidden layers and replacing the pooling layers with strided convolutions on\\nthe discriminator and fractional-strided convolutions on the generator\\n–Using batch normalization on both the generative and discriminative models\\n–Using ReLU activations in every layer of the generative model except the last layer and LeakyReLU\\nactivations in all layers of the discriminative model\\n\\x0fAdversarial Autoencoders (AAE): Makhzani et al. [ 8] proposed adversarial autoencoder which is a proba-\\nbilistic autoencoder which makes use of GAN to perform variational inference by matching the aggregated\\nposterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. In adversarial\\nautoencoder, the autoencoder is trained with dual objectives - a traditional reconstruction error criteria, and an\\nadversarial training criterion that matches the aggregated posterior distribution of the latent representation\\nto an arbitrary prior distribution. After training, the encoder learns to convert the data distribution to the\\nprior distribution, while the decoder learns a deep generative model that maps the imposed prior to the data\\ndistribution.\\n\\x0fGenerative Recurrent Adversarial Networks (GRAN): Im et al. [ 15] proposed recurrent generative model\\nshowing that unrolling the gradient based optimization yields a recurrent computation that creates images\\nby incrementally adding to a visual “canvas”. Here, the “encoder” co', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1613: ('\\nto an arbitrary prior distribution. After training, the encoder learns to convert the data distribution to the\\nprior distribution, while the decoder learns a deep generative model that maps the imposed prior to the data\\ndistribution.\\n\\x0fGenerative Recurrent Adversarial Networks (GRAN): Im et al. [ 15] proposed recurrent generative model\\nshowing that unrolling the gradient based optimization yields a recurrent computation that creates images\\nby incrementally adding to a visual “canvas”. Here, the “encoder” convolutional network extracts images\\nof current “canvas”. The resulting code and the code for the reference image get fed to a “decoder” which\\ndecides on an update to the “canvas”.\\n\\x0fInformation Maximizing Generative Adversarial Networks (InfoGAN): Information maximizing GANs\\n(InfoGANs) [ 16] are an information-theoretic extension of GANs that are able to learn disentangled features\\nin a completely unsupervised manner. A disentangled representation is one which explicitly represents the\\nsalient features of a data instance and can be useful for tasks such as face recognition and object recognition.\\nHere, InfoGANs modify the objective of GANs to learn meaningful representations by maximizing the mutual\\ninformation between a ﬁxed small subset of GAN’s noise variables and observations.\\n3 Desirable Characteristics of GANs Evaluation Metrics\\nWith the development of GAN architectures and their increasing use of numerous real-life applications, several\\nqualitative and quantitative metrics have been proposed for evaluating the performance of GANs. However, still there\\nexists no globally accepted benchmark metrics for evaluating the performance of a GAN architecture in all aspects. But,\\n3\\nAPREPRINT - DECEMBER 11, 2019\\nthere are some essential and desirable characteristics of GAN evaluation metrics as deﬁned below. These characteristics\\nenable its meta measurement for evaluating and comparing the GAN performance. An effective GAN evaluation metric\\nshould possess the following characteristics.\\n1. It should favour models that', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1614: ('ing the performance of GANs. However, still there\\nexists no globally accepted benchmark metrics for evaluating the performance of a GAN architecture in all aspects. But,\\n3\\nAPREPRINT - DECEMBER 11, 2019\\nthere are some essential and desirable characteristics of GAN evaluation metrics as deﬁned below. These characteristics\\nenable its meta measurement for evaluating and comparing the GAN performance. An effective GAN evaluation metric\\nshould possess the following characteristics.\\n1. It should favour models that create highly distinguishable generated samples from real ones.\\n2. It should be sensitive over-ﬁtting of the model.\\n3. It should be able to control with disentangled latent spaces as well as space continuity.\\n4. It should have well-deﬁned boundary values.\\n5. It must be sensitive to image distortions and transformations.\\n6. It must agree with human perceptual judgments and human rankings of models, and\\n7. It must have a low sample and computational complexity.\\n4 GAN Evaluation Metrics\\nThis section provides the GAN evaluation metrics along with their deﬁnitions, advantages and disadvantages. The GAN\\nevaluation metrics can be categorized as quantitative and qualitative metrics. A detailed description of these metrics is\\nprovided below.\\n4.1 Qualitative metrics\\nVisual investigation of images by humans is the common and most intuitive ways to evaluate GANs [ 17]. But, it lacks\\nin many ways. Firstly, it is very costlier and biased to examine the quality of generated images with human vision.\\nEven it is difﬁcult to reproduce and does not fully reﬂect the capacity of models. Secondly, human inspections have a\\nvariance that makes it necessary to average over a large number of subjects. Thirdly, an evaluation based on samples\\ncould be biased towards models that overﬁt and therefore a poor indicator of a good density model in a log-likelihood\\nsense [18]. Following methods have been used for measuring the performance of GAN qualitatively.\\n1.Nearest Neighbors: In order to detect over-ﬁtting, traditionally some samples are a', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1615: ('reproduce and does not fully reﬂect the capacity of models. Secondly, human inspections have a\\nvariance that makes it necessary to average over a large number of subjects. Thirdly, an evaluation based on samples\\ncould be biased towards models that overﬁt and therefore a poor indicator of a good density model in a log-likelihood\\nsense [18]. Following methods have been used for measuring the performance of GAN qualitatively.\\n1.Nearest Neighbors: In order to detect over-ﬁtting, traditionally some samples are against their nearest\\nneighbours in the training set. There exist two concerns for such examination.\\nFirstly, Nearest neighbours are typically determined on the basis of Euclidean distance. This distance is\\nsensitive to minor perceptual perturbations. This is a well-known phenomenon in psychophysics literature. It\\nis trivial to generate samples that are visually almost identical to a training image but have large Euclidean\\ndistances with its [18].\\nA model that stores (transformed) training images can trivially pass the Nearest-Neighbor over-ﬁtting test.\\nThis problem can be alleviated by choosing the nearest neighbours based on perceptual measures, and by\\nshowing more than one nearest neighbour.\\n2.Rating and Preference Judgment: These types of experiments invite subjects to rate models in terms\\nof the ﬁdelity of their generated images. For example, Snell et al., [ 19] studied whether observers prefer\\nreconstructions produced by perceptually-optimized networks or by the pixelwise-loss optimized networks.\\nParticipants were shown image triplets with the original (reference) image in the centre and the SSIM and\\nMSE optimized reconstructions on either side with the locations counterbalanced.\\n3.Rapid Scene Categorization: This type of metrics are based upon the fact that human beings are able to\\nreporting certain characteristics of scenes in a short glance [ 20]. For obtaining a quantitative metric of quality\\nof the image, Denton et al. [ 17] invited volunteers to differentiate their generated images from real images.\\n', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1616: ('pants were shown image triplets with the original (reference) image in the centre and the SSIM and\\nMSE optimized reconstructions on either side with the locations counterbalanced.\\n3.Rapid Scene Categorization: This type of metrics are based upon the fact that human beings are able to\\nreporting certain characteristics of scenes in a short glance [ 20]. For obtaining a quantitative metric of quality\\nof the image, Denton et al. [ 17] invited volunteers to differentiate their generated images from real images.\\nThey varied the viewing time from 50ms to 2000ms. They concluded that their model was better than the\\noriginal GAN [ 1] since it did better in fooling the subjects (lower bound here is 0% and the upper bound is\\n100%).\\n4.2 Quantitative metrics\\nSeveral quantitative metrics have been proposed for measuring performance of GANs described below.\\n1.Parzen Window Density: Parzen window estimation or Kernel density estimation (KDE) is a well-known\\nmethod for estimating the density function of a distribution from samples. For a probability kernel K\\n(most often an isotropic Gaussian) and i.i.d samples X1;X2::::Xn, a density function at x is deﬁned as\\np(x)\\x191\\nzPn\\ni=1K(x\\x00xi). Here. z is normalizing constant.\\n4\\nAPREPRINT - DECEMBER 11, 2019\\nThe Parzen window approach to density estimation takes a ﬁnite set of images generated by a model and then\\nusing those as the centroids of a Gaussian mixture. The constructed Parzen windows mix is then used for\\ncomputing a log-likelihood score on a set of test examples.\\nWu et al. [ 21] suggested to utilize annealed importance sampling (AIS) [ 22] for estimating log-likelihoods\\nusing a Gaussian observation model with a ﬁxed variance. The key drawback of this approach is the assumption\\nof the Gaussian observation model that may not work quite well in high dimensional spaces. They observed\\nthat AIS is two orders of magnitude more accurate than KDE, and is accurate enough for comparing generative\\nmodels.\\nDue to limitations of this metric, it becomes difﬁcult to address the simple issue like wh', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1617: ('uggested to utilize annealed importance sampling (AIS) [ 22] for estimating log-likelihoods\\nusing a Gaussian observation model with a ﬁxed variance. The key drawback of this approach is the assumption\\nof the Gaussian observation model that may not work quite well in high dimensional spaces. They observed\\nthat AIS is two orders of magnitude more accurate than KDE, and is accurate enough for comparing generative\\nmodels.\\nDue to limitations of this metric, it becomes difﬁcult to address the simple issue like whether GANs are simply\\nmemorizing training examples, or whether they are missing important modes of the data distribution.\\n2.Inception Score (IS): This metric was proposed by Salimans et al. [ 23], it is widely used score for GAN\\nevaluation. It employs a pre-trained neural network for capturing the desirable properties of generated samples\\nlike highly classiﬁable and diverse with respect to class labels. It measures the average KL divergence between\\nthe conditional label distribution p(yjx)of samples and the marginal distribution p(y) obtained from all the\\nsamples. It favors low entropy of p(yjx)but a large entropy of p(y).\\nexp(Ex[KL(p(yjx)kp(y))]) =exp(Hy)\\x00Ex[H(yjx)]) (3)\\nwhere,p(yjx)is the conditional label distribution for image x estimated using a pre-trained Inception model,\\nand p (y) is the marginal distribution. The IS shows a reasonable correlation with the quality and diversity of\\ngenerated images [23]. IS over real images can serve as the upper bound.\\nBut, IS has several limitations as follows. It also favors a “memory GAN” that stores all training samples, thus\\nis unable to detect over-ﬁtting [ 24]. It fails in detecting a model that has been trapped into one bad mode. since\\nIS uses Inception model that has been trained on ImageNet with many object classes, it may favor models\\nthat generate good objects rather realistic images. It only considers Pgand ignoresPr. Manipulations such as\\nmixing in natural images from an entirely different distribution could deceive this score. As a result, it may\\nfavor mo', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1618: ('so favors a “memory GAN” that stores all training samples, thus\\nis unable to detect over-ﬁtting [ 24]. It fails in detecting a model that has been trapped into one bad mode. since\\nIS uses Inception model that has been trained on ImageNet with many object classes, it may favor models\\nthat generate good objects rather realistic images. It only considers Pgand ignoresPr. Manipulations such as\\nmixing in natural images from an entirely different distribution could deceive this score. As a result, it may\\nfavor models that simply learn sharp and diversiﬁed images, instead of Pr.\\n3.Mode score: Che et al. [ 25] suggested this metric that addresses an important drawback of the IS ignoring the\\nthe prior distribution of the ground truth labels.\\nexp(Ex[KL(p(yjx)kp(ytrain))])\\x00KL(p(y)kp(ytrain)) (4)\\nwhere,p(ytrain)is the empirical distribution of labels computed from training data. Mode score adequately\\nreﬂects the variety and visual quality of generated images .\\n4.AM score: Zhou et al. [ 26] argued that the entropy term on y in the IS is not suitable when the data is\\nnot evenly distributed over classes. To take ytraininto account, they proposed to replace H(y) with the KL\\ndivergence between ytrainand y. The AM score is then deﬁned as per following equation.\\nKL(p(ytrain)kp(y)) +Ex[Hy(yjx)] (5)\\nThe AM score contains two factors. The ﬁrst factor is minimized when ytrainis close to y. The second factor\\nis minimized when the predicted class label for sample x (i.e. yjx) has low entropy. Thus, the smaller the\\nAM score, the better.\\n5.Frechet Inception Distance(FID): Heusel et al. [ 27] deﬁned FID that embeds a set of generated images into\\na feature space given by a speciﬁc layer of Inception Net (or any CNN). Viewing the embedding layer as a\\ncontinuous multivariate Gaussian, the mean and covariance are estimated for both the generated data and the\\nreal data. The Frechet distance between these two Gaussians (a.k.a Wasserstein-2 distance) is then used to\\nquantify the quality of generated samples as per following equation.\\nFID (r;g) =k\\x16', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1619: ('\\n5.Frechet Inception Distance(FID): Heusel et al. [ 27] deﬁned FID that embeds a set of generated images into\\na feature space given by a speciﬁc layer of Inception Net (or any CNN). Viewing the embedding layer as a\\ncontinuous multivariate Gaussian, the mean and covariance are estimated for both the generated data and the\\nreal data. The Frechet distance between these two Gaussians (a.k.a Wasserstein-2 distance) is then used to\\nquantify the quality of generated samples as per following equation.\\nFID (r;g) =k\\x16r\\x00\\x16gk2\\n2+Tr(X\\nr+X\\ng+2(X\\nrX\\ng)1\\n2) (6)\\nwhere (\\x16r;P\\nr)and(\\x16g;P\\ng)are the mean and covariance of the real data and model distributions, respectively.\\nLower FID means smaller distances between synthetic and real data distributions. FID performs well in terms\\nof discriminability, robustness and computational efﬁciency. It appears to be a good measure, even though\\nit only takes into consideration the ﬁrst two order moments of the distributions. However, it assumes that\\nfeatures are of Gaussian distribution which is often not guaranteed.\\n6.Maximum Mean Discrepancy (MMD): Fortet et al. [ 28] deﬁned MMD that measures the dissimilarity\\nbetween two probability distributions PrandPgusing samples drawn independently from each. A lower\\nMMD hence means that Pgis closer toPr. MMD can be regarded as two-sample testing since, as in classiﬁer\\n5\\nAPREPRINT - DECEMBER 11, 2019\\ntwo samples test, it tests whether one model or another is closer to the true data distribution [ 29]. Such\\nhypothesis tests allow choosing one evaluation measure over another. The kernel MMD [ 30] measures (square)\\nMMD between Pr and Pg for some ﬁxed characteristic kernel function k.\\n7.Image Retrieval Performance:\\nWang et al. [ 31] proposed an image retrieval metrics to evaluate GANs. The main idea is to investigate images\\nin the dataset that are badly modeled by a network. Images from a held-out test set as well as generated images\\nare represented using a discriminatively trained CNN [ 32]. The nearest neighbors of generated images in the\\ntest dataset are th', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1620: ('easure over another. The kernel MMD [ 30] measures (square)\\nMMD between Pr and Pg for some ﬁxed characteristic kernel function k.\\n7.Image Retrieval Performance:\\nWang et al. [ 31] proposed an image retrieval metrics to evaluate GANs. The main idea is to investigate images\\nin the dataset that are badly modeled by a network. Images from a held-out test set as well as generated images\\nare represented using a discriminatively trained CNN [ 32]. The nearest neighbors of generated images in the\\ntest dataset are then retrieved. To evaluate the quality of the retrieval results, following metrics have been\\nproposed. The ﬁrst metric considers dk\\ni;jto be the distance of the jthnearest image generated by method k to\\ntest image i, and dk\\nj=dk\\n1;j;::::;dk\\nn;j,the set ofjth-nearest distances to all n test images (j is often set to 1).\\nThe Wilcoxon signed-rank test is then used to test the hypothesis that the median of the difference between\\ntwo nearest distance distributions by two generators is zero, in which case they are equally good . If they are\\nnot equal, the test can be used to assess which method is statistically better. The second metric considers dt\\njto\\nbe the distribution of the jthnearest distance of the train images to the test dataset. Since train and test sets are\\ndrawn from the same dataset, the distribution dt\\njcan be considered the optimal distribution that a generator\\ncould attain.\\n8.Generative Adversarial Metric (GAM): Im et al. [ 15] proposed to compare two GANs by having them\\nengaged in a battle against each other by swapping discriminators or generators across the two models. GAM\\nmeasures the relative performance of two GANs by measuring the likelihood ratio of the two models. The\\nlikelihood-ratio is deﬁned as per following equation.\\np(xjy= 1; \\x13M1)\\np(xjy= 1; \\x13M2)=p(y= 1jx;D1)p(x;G2)\\np(y= 1jx;D1)p(x;G2)(7)\\nwhere, \\x13M1and \\x13M1are the swapped pairs (D1;G2)and(D2;G1),p(xjy= 1;M)is the likelihood of x\\ngenerated from the data distribution p(x) by model M, and p(y= 1jx;D)indicates that discriminator D\\nthinks x is ', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1621: ('each other by swapping discriminators or generators across the two models. GAM\\nmeasures the relative performance of two GANs by measuring the likelihood ratio of the two models. The\\nlikelihood-ratio is deﬁned as per following equation.\\np(xjy= 1; \\x13M1)\\np(xjy= 1; \\x13M2)=p(y= 1jx;D1)p(x;G2)\\np(y= 1jx;D1)p(x;G2)(7)\\nwhere, \\x13M1and \\x13M1are the swapped pairs (D1;G2)and(D2;G1),p(xjy= 1;M)is the likelihood of x\\ngenerated from the data distribution p(x) by model M, and p(y= 1jx;D)indicates that discriminator D\\nthinks x is a real sample.\\nGAM suffers from two main caveats: a) it has a constraint where the two discriminators must have an\\napproximately similar performance on a calibration dataset, which can be difﬁcult to satisfy in practice, and b)\\nit is expensive to compute because it has to be computed for all pairs of models.\\n9.Image Quality Measures: Some researchers have proposed to use measures from the image quality assess-\\nment literature for training and evaluating GANs as described below.\\n\\x0fSSIM: Wang et al. [ 33] proposed a single-scale SSIM metric that is a well-characterized perceptual\\nsimilarity measure that aims to discount aspects of an image that are not important for human perception.\\nIt compares corresponding pixels and their neighborhoods in two images, denoted by x and y, using three\\nquantities—luminance (I), contrast (C), and structure (S):\\nI(x;y) =2\\x16x\\x16y+C1\\n\\x162x\\x162y+C1(8)\\nC(x;y) =2\\x1bx\\x1by+C2\\n\\x1b2x\\x1b2y+C2(9)\\nS(x;y) =\\x1bxy+C3\\n\\x1bx\\x1by+C3(10)\\nThe variables \\x16x,\\x16y,\\x1bx, and\\x1bydenote mean and standard deviations of pixel intensity in a local image\\npatch centered at either x or y The variable \\x1bxydenotes the sample correlation coefﬁcient between\\ncorresponding pixels in the patches centered at x and y. The constants C1,C2, andC3are small values\\nadded for numerical stability. The three quantities are combined to form the SSIM score as per following\\nequation.\\nSSIM (x;y) =I(x;y)\\x0bC(x;y)\\x0cS(x;y)\\r(11)\\n\\x0fPSNR: It measures the peak signal-to-noise ratio between two monochrome images I and K to assess the\\nquality of a generated image compared to i', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1622: ('in a local image\\npatch centered at either x or y The variable \\x1bxydenotes the sample correlation coefﬁcient between\\ncorresponding pixels in the patches centered at x and y. The constants C1,C2, andC3are small values\\nadded for numerical stability. The three quantities are combined to form the SSIM score as per following\\nequation.\\nSSIM (x;y) =I(x;y)\\x0bC(x;y)\\x0cS(x;y)\\r(11)\\n\\x0fPSNR: It measures the peak signal-to-noise ratio between two monochrome images I and K to assess the\\nquality of a generated image compared to its corresponding real image. The higher the PSNR (in db), the\\nbetter quality of the generated image. It is computed as per following equation.\\nPSNR (I;K) = 10Log 10(Max2\\nI\\nMSE) (12)\\n6\\nAPREPRINT - DECEMBER 11, 2019\\n= 20Log 10(Max2\\nI)\\x0020Log 10(MSEI;K) (13)\\nWhere,\\nMSEI;K=1\\nmnm\\x001X\\ni=0n\\x001X\\ni=0(I(m;n)\\x00K(m;n))2(14)\\nand,MAXIis the maximum possible pixel value of the image. This score can be used when a reference\\nimage is available for example in training conditional GANs using paired data.\\n\\x0fSharpness Difference (SD): It measures the loss of sharpness during image generation. It is compute as\\nper following equation.\\nSD(I;K) = 10Log 10(Max2\\nI\\nGRADSI;K) (15)\\nOdena et al. [ 3] used 9 MS-SSIM to evaluate the diversity of generated images. The intuition is that\\nimage pairs with higher MS-SSIM seem more similar than pairs with lower MS-SSIM. They measured\\nthe MS-SSIM scores of 100 randomly chosen pairs of images within a given class. The higher (lower)\\ndiversity within a class, the lower (the higher) mean MSSSIM score.\\n10.Precision and recall and F score:\\nLucic et al. [ 34] proposed to compute precision, recall and F-1 score to quantify the degree of overﬁtting\\nin GANs. Intuitively precision measures the quality of the generated samples, whereas recall measures the\\nproportion of the reference distribution covered by the learned distribution. They argue that IS only captures\\nprecision as it does not penalize a model for not producing all modes of the data distribution. Rather, it only\\npenalizes the model for not producing all ', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1623: ('recision and recall and F score:\\nLucic et al. [ 34] proposed to compute precision, recall and F-1 score to quantify the degree of overﬁtting\\nin GANs. Intuitively precision measures the quality of the generated samples, whereas recall measures the\\nproportion of the reference distribution covered by the learned distribution. They argue that IS only captures\\nprecision as it does not penalize a model for not producing all modes of the data distribution. Rather, it only\\npenalizes the model for not producing all classes. FID score, on the other hand, captures both precision and\\nrecall.\\nTo approximate these scores for a model, Lucic et al. [ 34] proposed to use toy datasets for which the data\\nmanifold is known and distances of generated samples to the manifold can be computed. An example of such\\ndataset is the manifold of convex shapes.\\nPrecision is deﬁned as the fraction of the generated samples whose distance to the manifold is below a certain\\nthreshold. Recall, on the other hand, is given by the fraction of test samples whose L2distance to G(z) is\\nbelow the threshold. If the samples from the model distribution Pgare (on average) close to the manifold, its\\nprecision is high. Similarly, high recall implies that the generator can recover (i.e. generate something close\\nto) any sample from the manifold, thus capturing most of the manifold.\\nThe major drawback of these scores is that they are impractical for real images where the data manifold is\\nunknown, and their use is limited to evaluations on synthetic data.\\n5 Pros and Cons\\nBased on the above analysis, the advantages and inherent limitations of the most signiﬁcant evaluation metrics can\\nbe summarized, and conditions under which they produce meaningful results. Some metrics enable us to study the\\nproblem of over-ﬁtting, perform model selection on GAN models and compare GAN models without resorting to\\nhuman evaluation based on selected samples.\\nThere is no consensus regarding the best score. Different scores assess various aspects of the image generation process,\\nand it ', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1624: ('nd Cons\\nBased on the above analysis, the advantages and inherent limitations of the most signiﬁcant evaluation metrics can\\nbe summarized, and conditions under which they produce meaningful results. Some metrics enable us to study the\\nproblem of over-ﬁtting, perform model selection on GAN models and compare GAN models without resorting to\\nhuman evaluation based on selected samples.\\nThere is no consensus regarding the best score. Different scores assess various aspects of the image generation process,\\nand it is unlikely that a single score can cover all aspects. Nevertheless, some measures seem more plausible than others.\\nQuality metrics such as nearest neighbor visualizations or rapid categorization tasks may favor models that over-\\nﬁt. Overall, it seems that the main challenge is to have a measure that evaluates both diversity and visual ﬁdelity\\nsimultaneously. The former implies that all modes are covered while the latter implies that the generated samples\\nshould have high likelihood.\\nParzen windows estimation of likelihood favors trivial models and is irrelevant to visual ﬁdelity of samples. Further, it\\nfails to approximate the true likelihood in high dimensional spaces or to rank models.\\nTwo widely accepted scores, IS and FID, rely on pre-trained deep networks to represent and statistically compare\\noriginal and generated samples. The IS does show a reasonable correlation with the quality and diversity of generated\\nimages, which explains the wide usage in practice. However, it is ill-posed mostly because it only evaluates Pgas\\nan image generation model rather than its similarity to Pr. Blunt violations like mixing in natural images from an\\nentirely different distribution completely deceives IS. As a result, it may encourage the models to simply learn sharp\\nand diversiﬁed images, instead of Pr.\\n7\\nAPREPRINT - DECEMBER 11, 2019\\nSome evaluation methods like MS-SSIM aim to assess the diversity of the generated samples, regardless of the data\\ndistribution. While being able to detect severe cases of mode collapse, the', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1625: ('nly evaluates Pgas\\nan image generation model rather than its similarity to Pr. Blunt violations like mixing in natural images from an\\nentirely different distribution completely deceives IS. As a result, it may encourage the models to simply learn sharp\\nand diversiﬁed images, instead of Pr.\\n7\\nAPREPRINT - DECEMBER 11, 2019\\nSome evaluation methods like MS-SSIM aim to assess the diversity of the generated samples, regardless of the data\\ndistribution. While being able to detect severe cases of mode collapse, these methods fall short in measuring how well a\\ngenerator captures the true data distribution.\\nKernel MMD works surprising well when it operates in the feature space of a pre-trained ResNet. It is always able to\\nidentify generative/noise images from real images, and both its sample complexity and computational complexity are\\nlow. Given these advantages, even though MMD is biased, still it is recommended.\\n6 Summary and Future Research Directions\\nThis paper presented an analysis of signiﬁcant and most commonly used GAN evaluation metrics by highlighting their\\npros and cons. It can be observed that deﬁning an appropriate metric for evaluating GANs performance is still an open\\nproblem, not only for fair model comparison but also for understanding, improving, and developing generative models.\\nRecently, Lucic et al. [ 34] found no empirical evidence in favour of GAN models who claimed superiority over the\\noriginal GAN. In this regard, borrowing from other ﬁelds such as natural scene statistics and cognitive vision can be\\nrewarding.\\nOverall, this study suggests that the choice of feature space in which to compute various metrics is crucial. In addition,\\nit is suggested to create a code repository of evaluation metrics that enables the conduct of a comparative empirical\\nand analytical studies of available measures for benchmarking models under the same conditions using more than one\\nmetrics in the future.\\nReferences\\n[1]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Cour', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1626: ('n be\\nrewarding.\\nOverall, this study suggests that the choice of feature space in which to compute various metrics is crucial. In addition,\\nit is suggested to create a code repository of evaluation metrics that enables the conduct of a comparative empirical\\nand analytical studies of available measures for benchmarking models under the same conditions using more than one\\nmetrics in the future.\\nReferences\\n[1]Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville,\\nand Yoshua Bengio. Generative adversarial nets. In Advances in neural information processing systems , pages\\n2672–2680, 2014.\\n[2] Diederik P Kingma and Max Welling. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 , 2013.\\n[3]Augustus Odena, Christopher Olah, and Jonathon Shlens. Conditional image synthesis with auxiliary classiﬁer\\ngans. In Proceedings of the 34th International Conference on Machine Learning-Volume 70 , pages 2642–2651.\\nJMLR. org, 2017.\\n[4]Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with deep convolutional\\ngenerative adversarial networks. arXiv preprint arXiv:1511.06434 , 2015.\\n[5]Anders Boesen Lindbo Larsen, Søren Kaae Sønderby, Hugo Larochelle, and Ole Winther. Autoencoding beyond\\npixels using a learned similarity metric. arXiv preprint arXiv:1512.09300 , 2015.\\n[6]Martin Arjovsky, Soumith Chintala, and Léon Bottou. Wasserstein gan. arXiv preprint arXiv:1701.07875 , 2017.\\n[7]Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville. Improved training\\nof wasserstein gans. In Advances in Neural Information Processing Systems , pages 5767–5777, 2017.\\n[8]Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders.\\narXiv preprint arXiv:1511.05644 , 2015.\\n[9]Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional\\nadversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recogniti', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1627: ('umoulin, and Aaron C Courville. Improved training\\nof wasserstein gans. In Advances in Neural Information Processing Systems , pages 5767–5777, 2017.\\n[8]Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, and Brendan Frey. Adversarial autoencoders.\\narXiv preprint arXiv:1511.05644 , 2015.\\n[9]Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation with conditional\\nadversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition , pages\\n1125–1134, 2017.\\n[10] Ashish Shrivastava, Tomas Pﬁster, Oncel Tuzel, Joshua Susskind, Wenda Wang, and Russell Webb. Learning\\nfrom simulated and unsupervised images through adversarial training. In Proceedings of the IEEE Conference on\\nComputer Vision and Pattern Recognition , pages 2107–2116, 2017.\\n[11] Leon A Gatys, Alexander S Ecker, and Matthias Bethge. Image style transfer using convolutional neural networks.\\nInProceedings of the IEEE conference on computer vision and pattern recognition , pages 2414–2423, 2016.\\n[12] Karol Kurach, Mario Lucic, Xiaohua Zhai, Marcin Michalski, and Sylvain Gelly. The gan landscape: Losses,\\narchitectures, regularization, and normalization. arXiv preprint arXiv:1807.04720 , 2018.\\n[13] A Karazeev. Generative adversarial networks (gans): Engine and applications, 2017.\\n[14] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint arXiv:1411.1784 ,\\n2014.\\n8\\nAPREPRINT - DECEMBER 11, 2019\\n[15] Daniel Jiwoong Im, Chris Dongjoo Kim, Hui Jiang, and Roland Memisevic. Generating images with recurrent\\nadversarial networks. arXiv preprint arXiv:1602.05110 , 2016.\\n[16] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable\\nrepresentation learning by information maximizing generative adversarial nets. In Advances in neural information\\nprocessing systems , pages 2172–2180, 2016.\\n[17] Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative image models using a laplacian pyramid\\nof adversari', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1628: ('and Roland Memisevic. Generating images with recurrent\\nadversarial networks. arXiv preprint arXiv:1602.05110 , 2016.\\n[16] Xi Chen, Yan Duan, Rein Houthooft, John Schulman, Ilya Sutskever, and Pieter Abbeel. Infogan: Interpretable\\nrepresentation learning by information maximizing generative adversarial nets. In Advances in neural information\\nprocessing systems , pages 2172–2180, 2016.\\n[17] Emily L Denton, Soumith Chintala, Rob Fergus, et al. Deep generative image models using a laplacian pyramid\\nof adversarial networks. In Advances in neural information processing systems , pages 1486–1494, 2015.\\n[18] Lucas Theis, Aäron van den Oord, and Matthias Bethge. A note on the evaluation of generative models. arXiv\\npreprint arXiv:1511.01844 , 2015.\\n[19] Jake Snell, Karl Ridgeway, Renjie Liao, Brett D Roads, Michael C Mozer, and Richard S Zemel. Learning to\\ngenerate images with perceptual similarity metrics. In 2017 IEEE International Conference on Image Processing\\n(ICIP) , pages 4277–4281. IEEE, 2017.\\n[20] Aude Oliva. Gist of the scene. In Neurobiology of attention , pages 251–256. Elsevier, 2005.\\n[21] Yuhuai Wu, Yuri Burda, Ruslan Salakhutdinov, and Roger Grosse. On the quantitative analysis of decoder-based\\ngenerative models. arXiv preprint arXiv:1611.04273 , 2016.\\n[22] Radford M Neal. Annealed importance sampling. Statistics and computing , 11(2):125–139, 2001.\\n[23] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved\\ntechniques for training gans. In Advances in neural information processing systems , pages 2234–2242, 2016.\\n[24] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. Attribute2image: Conditional image generation from\\nvisual attributes. In European Conference on Computer Vision , pages 776–791. Springer, 2016.\\n[25] Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative adversarial\\nnetworks. arXiv preprint arXiv:1612.02136 , 2016.\\n[26] Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang, Yong Yu, and Jun ', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1629: ('rmation processing systems , pages 2234–2242, 2016.\\n[24] Xinchen Yan, Jimei Yang, Kihyuk Sohn, and Honglak Lee. Attribute2image: Conditional image generation from\\nvisual attributes. In European Conference on Computer Vision , pages 776–791. Springer, 2016.\\n[25] Tong Che, Yanran Li, Athul Paul Jacob, Yoshua Bengio, and Wenjie Li. Mode regularized generative adversarial\\nnetworks. arXiv preprint arXiv:1612.02136 , 2016.\\n[26] Zhiming Zhou, Han Cai, Shu Rong, Yuxuan Song, Kan Ren, Weinan Zhang, Yong Yu, and Jun Wang. Activation\\nmaximization generative adversarial nets. arXiv preprint arXiv:1703.02000 , 2017.\\n[27] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a\\ntwo time-scale update rule converge to a local nash equilibrium. In Advances in Neural Information Processing\\nSystems , pages 6626–6637, 2017.\\n[28] Robert Fortet and Edith Mourier. Convergence de la repartition empirique vers la repartition theorique. In Annales\\nscientiﬁques de Ecole Normale Superieure , volume 70, pages 267–285, 1953.\\n[29] Krikamol Muandet, Kenji Fukumizu, Bharath Sriperumbudur, Bernhard Scholkopf, et al. Kernel mean embedding\\nof distributions: A review and beyond. Foundations and Trends R\\rin Machine Learning , 10(1-2):1–141, 2017.\\n[30] Arthur Gretton, Karsten M Borgwardt, Malte J Rasch, Bernhard Scholkopf, and Alexander Smola. A kernel\\ntwo-sample test. Journal of Machine Learning Research , 13(Mar):723–773, 2012.\\n[31] Yaxing Wang, Lichao Zhang, and Joost van de Weijer. Ensembles of generative adversarial networks. arXiv\\npreprint arXiv:1612.00991 , 2016.\\n[32] Yann LeCun, Leon Bottou, Yoshua Bengio, Patrick Haffner, et al. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE , 86(11):2278–2324, 1998.\\n[33] Zhou Wang, Alan C Bovik, Hamid R Sheikh, Eero P Simoncelli, et al. Image quality assessment: from error\\nvisibility to structural similarity. IEEE transactions on image processing , 13(4):600–612, 2004.\\n[34] Mario Lucic, Karol Kurach, Marcin Michalski, Sylva', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1630: (' generative adversarial networks. arXiv\\npreprint arXiv:1612.00991 , 2016.\\n[32] Yann LeCun, Leon Bottou, Yoshua Bengio, Patrick Haffner, et al. Gradient-based learning applied to document\\nrecognition. Proceedings of the IEEE , 86(11):2278–2324, 1998.\\n[33] Zhou Wang, Alan C Bovik, Hamid R Sheikh, Eero P Simoncelli, et al. Image quality assessment: from error\\nvisibility to structural similarity. IEEE transactions on image processing , 13(4):600–612, 2004.\\n[34] Mario Lucic, Karol Kurach, Marcin Michalski, Sylvain Gelly, and Olivier Bousquet. Are gans created equal? a\\nlarge-scale study. In Advances in neural information processing systems , pages 700–709, 2018.\\n9\\nView publication stats', 'An_Analysis_of_Evaluation_Metrics_of_GANs__Arxiv_format___Copy_.pdf'), 1631: ('Addressing Failure Prediction\\nby Learning Model Conﬁdence\\nCharles Corbière1,2\\ncharles.corbiere@valeo.comNicolas Thome1\\nnicolas.thome@cnam.fr\\nAvner Bar-Hen1\\navner@cnam.frMatthieu Cord2,3\\nmatthieu.cord@lip6.frPatrick Pérez2\\npatrick.perez@valeo.com\\n1CEDRIC, Conservatoire National des Arts et Métiers, Paris, France\\n2valeo.ai, Paris, France\\n3Sorbonne University, Paris, France\\nAbstract\\nAssessing reliably the conﬁdence of a deep neural network and predicting its fail-\\nures is of primary importance for the practical deployment of these models. In this\\npaper, we propose a new target criterion for model conﬁdence, corresponding to\\ntheTrue Class Probability (TCP). We show how using the TCP is more suited than\\nrelying on the classic Maximum Class Probability (MCP). We provide in addition\\ntheoretical guarantees for TCP in the context of failure prediction. Since the true\\nclass is by essence unknown at test time, we propose to learn TCP criterion on\\nthe training set, introducing a speciﬁc learning scheme adapted to this context.\\nExtensive experiments are conducted for validating the relevance of the proposed\\napproach. We study various network architectures, small and large scale datasets for\\nimage classiﬁcation and semantic segmentation. We show that our approach con-\\nsistently outperforms several strong methods, from MCP to Bayesian uncertainty,\\nas well as recent approaches speciﬁcally designed for failure prediction.\\n1 Introduction\\nDeep neural networks have seen a wide adoption, driven by their impressive performance in various\\ntasks including image classiﬁcation [ 25], object recognition [ 43,33,37], natural language processing\\n[34,35], and speech recognition [ 18,15]. Despite their growing success, safety remains a great\\nconcern when it comes to implement these models in real-world conditions [ 1,19]. Estimating when a\\nmodel makes an error is even more crucial in applications where failing carries serious repercussions,\\nsuch as in autonomous driving, medical diagnosis or nuclear power plant monitoring [32].\\nThis paper addr', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1632: ('rious\\ntasks including image classiﬁcation [ 25], object recognition [ 43,33,37], natural language processing\\n[34,35], and speech recognition [ 18,15]. Despite their growing success, safety remains a great\\nconcern when it comes to implement these models in real-world conditions [ 1,19]. Estimating when a\\nmodel makes an error is even more crucial in applications where failing carries serious repercussions,\\nsuch as in autonomous driving, medical diagnosis or nuclear power plant monitoring [32].\\nThis paper addresses the challenge of failure prediction with deep neural networks [ 17,20,16].\\nThe objective is to provide conﬁdence measures for model’s predictions that are reliable and whose\\nranking among samples enables to distinguish correct from incorrect predictions. Equipped with such\\na conﬁdence measure, a system could decide to stick to the prediction or, on the contrary, to hand\\nover to a human or a back-up system with, e.g.other sensors, or simply to trigger an alarm.\\nIn the context of classiﬁcation, a widely used baseline for conﬁdence estimation with neural networks\\nis to take the value of the predicted class’ probability, namely the Maximum Class Probability (MCP),\\ngiven by the softmax layer output. Although recent evaluations of MCP for failure prediction with\\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\\nFigure 1: When ranking test samples according to Maximum Class Probability (a), output by a\\nconvolutional model trained on CIFAR-10 dataset, we observe that correct predictions (in green) and\\nincorrect ones (in red) overlap considerably, making it difﬁcult to distinguish them. On the other\\nhand, ranking samples according to True Class Probability (b) alleviates this issue and allows a better\\nseparation for failure prediction. (Distributions of both correct and incorrect samples are plotted in\\nrelative density for visualization purpose).\\nmodern deep models reveal reasonable performances [ 17], they still suffer from several conceptual\\ndrawbacks. Softmax probabilit', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1633: ('rrect predictions (in green) and\\nincorrect ones (in red) overlap considerably, making it difﬁcult to distinguish them. On the other\\nhand, ranking samples according to True Class Probability (b) alleviates this issue and allows a better\\nseparation for failure prediction. (Distributions of both correct and incorrect samples are plotted in\\nrelative density for visualization purpose).\\nmodern deep models reveal reasonable performances [ 17], they still suffer from several conceptual\\ndrawbacks. Softmax probabilities are indeed known to be non-calibrated [ 13,40], sensitive to\\nadversarial attacks [ 12,44], and inadequate for detecting in- from out-of-distribution examples [ 17,\\n30, 26].\\nAnother important issue related to MCP, which we speciﬁcally address in this work, relates to ranking\\nof conﬁdence scores: this ranking is unreliable for the task of failure prediction [ 41,20]. As illustrated\\nin Figure 1(a) for a small convolutional network trained on CIFAR-10 dataset, MCP conﬁdence\\nvalues for erroneous and correct predictions overlap. It is worth mentioning that this problem comes\\nfrom the fact that MCP leads by design to high conﬁdence values, even for erroneous ones, since the\\nlargest softmax output is used. On the other hand, the probability of the model with respect to the true\\nclass naturally reﬂects a better behaved model conﬁdence, as illustrated in Figure 1(b). This leads to\\nerrors’ conﬁdence distributions shifted to smaller values, while correct predictions are still associated\\nwith high values, allowing a much better separability between these two types of prediction.\\nBased on this observation, we propose a novel approach for failure prediction with deep neural\\nnetworks. We introduce a new conﬁdence criteria based on the idea of using the TCP (section 2.1),\\nfor which we provide theoretical guarantees in the context of failure prediction. Since the true class\\nis obviously unknown at test time, we introduce a method to learn a given target conﬁdence criterion\\nfrom data (section 2.2). We also discuss connections', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1634: ('uch better separability between these two types of prediction.\\nBased on this observation, we propose a novel approach for failure prediction with deep neural\\nnetworks. We introduce a new conﬁdence criteria based on the idea of using the TCP (section 2.1),\\nfor which we provide theoretical guarantees in the context of failure prediction. Since the true class\\nis obviously unknown at test time, we introduce a method to learn a given target conﬁdence criterion\\nfrom data (section 2.2). We also discuss connections and differences between related works for\\nfailure prediction, in particular Bayesian deep learning and ensemble approaches, as well as recent\\napproaches designing alternative criteria for failure prediction (section 2.3). We conduct extensive\\ncomparative experiments across various tasks, datasets and network architectures to validate the\\nrelevance of our proposed approach (section 3.2). Finally, a thorough analysis of our approach\\nregarding the choice of loss function, criterion and learning scheme is presented in section 3.3.\\n2 Failure prediction by learning model conﬁdence\\nWe are interested in the problem of deﬁning relevant conﬁdence criteria for failure prediction with\\ndeep neural networks, in the context of classiﬁcation. We also address semantic image segmentation,\\nwhich can be seen as a pixel-wise classiﬁcation problem, where a model outputs a dense segmentation\\nmask with a predicted class assigned to each pixel. As such, all the following material is formulated\\nfor classiﬁcation, and implementation details for segmentation are speciﬁed when necessary.\\nLet us consider a dataset Dwhich consists of Ni.i.d. training samplesD=f(xi;y\\x03\\ni)gN\\ni=1where\\nxi2Rdis ad-dimensional feature and y\\x03\\ni2Y=f1;:::;Kgis its true class. We view a classiﬁcation\\nneural network as a probabilistic model: given an input x, the network assigns a probabilistic\\npredictive distribution P(Yjw;x)by computing the softmax output for each class kand where w\\n2\\nare the parameters of the network. From this predictive distribution, one can infer', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1635: ('etails for segmentation are speciﬁed when necessary.\\nLet us consider a dataset Dwhich consists of Ni.i.d. training samplesD=f(xi;y\\x03\\ni)gN\\ni=1where\\nxi2Rdis ad-dimensional feature and y\\x03\\ni2Y=f1;:::;Kgis its true class. We view a classiﬁcation\\nneural network as a probabilistic model: given an input x, the network assigns a probabilistic\\npredictive distribution P(Yjw;x)by computing the softmax output for each class kand where w\\n2\\nare the parameters of the network. From this predictive distribution, one can infer the class predicted\\nby the model as ^y= argmax\\nk2YP(Y=kjw;x).\\nDuring training, network parameters ware learned following a maximum likelihood estimation\\nframework where one minimizes the Kullback-Leibler (KL) divergence between the predictive\\ndistribution and the true distribution. In classiﬁcation, this is equivalent to minimizing the cross-\\nentropy loss w.r.t. w, which is the negative sum of the log-probabilities over positive labels:\\nLCE(w;D) =\\x001\\nNNX\\ni=1y\\x03\\nilogP(Y=y\\x03\\nijw;xi): (1)\\n2.1 Conﬁdence criterion for failure prediction\\nInstead of trying to improve the accuracy of a given trained model, we are interested in knowing if\\nit can be endowed with the ability to recognize when its prediction may be wrong. A conﬁdence\\ncriterion is a quantitative measure to estimate the conﬁdence of the model prediction. The higher the\\nvalue, the more certain the model about its prediction. As such, a suitable conﬁdence criterion should\\ncorrelate erroneous predictions with low values and successful predictions with high values. Here,\\nwe speciﬁcally focus on the ability of the conﬁdence criterion to separate successful and erroneous\\npredictions in order to distinguish them.\\nFor a given input x, a standard approach is to compute the softmax probability of the predicted class\\n^y, that is the Maximum Class Probability: MCP( x) = max\\nk2YP(Y=kjw;x) =P(Y= ^yjw;x).\\nBy taking the largest softmax probability, MCP leads to high conﬁdence values both for errors and\\ncorrect predictions, making it hard to distinguish them, as shown in Figur', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1636: ('es. Here,\\nwe speciﬁcally focus on the ability of the conﬁdence criterion to separate successful and erroneous\\npredictions in order to distinguish them.\\nFor a given input x, a standard approach is to compute the softmax probability of the predicted class\\n^y, that is the Maximum Class Probability: MCP( x) = max\\nk2YP(Y=kjw;x) =P(Y= ^yjw;x).\\nBy taking the largest softmax probability, MCP leads to high conﬁdence values both for errors and\\ncorrect predictions, making it hard to distinguish them, as shown in Figure 1(a). On the other hand,\\nwhen the model is misclassifying an example, the probability associated to the true class y\\x03would be\\nmore likely close to a low value, reﬂecting the fact that the model made an error. Thus, we propose to\\nconsider the True Class Probability as a suitable conﬁdence criterion for failure prediction:\\nTCP : Rd\\x02Y ! R\\n(x; y\\x03)!P(Y=y\\x03jw;x) (2)\\nTheoretical guarantees. With TCP, the following properties hold (see derivation in supplementary\\n1.1). Given an example (x;y\\x03),\\n\\x0fTCP(x;y\\x03)>1=2)^y=y\\x03,i.e.the example is properly classiﬁed by the model,\\n\\x0fTCP(x;y\\x03)<1=K)^y6=y\\x03,i.e.the example is wrongly classiﬁed by the model.\\nWithin the range [1=K;1=2], there is no theoretical guarantee that correct and incorrect predictions\\nwill not overlap in terms of TCP. However, when using deep neural networks, we observe that the\\nactual overlap area is extremely small in practice, as illustrated in Figure 1(b) on the CIFAR-10\\ndataset. One possible explanation comes from the fact that modern deep neural networks output\\noverconﬁdent predictions and therefore non-calibrated probabilities [ 13]. We provide consolidated\\nresults and analysis on this aspect in Section 3 and in the supplementary 1.2.\\nWe also introduce a normalized variant of the TCP conﬁdence criterion, which consists in computing\\ntheratio between TCP and MCP:\\nTCPr(x;y\\x03) =P(Y=y\\x03jw;x)\\nP(Y= ^yjw;x): (3)\\nTheTCPrcriterion presents stronger theoretical guarantees than TCP, since correct predictions will\\nbe, by design, assigned the value of 1, whereas errors will r', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1637: ('ut\\noverconﬁdent predictions and therefore non-calibrated probabilities [ 13]. We provide consolidated\\nresults and analysis on this aspect in Section 3 and in the supplementary 1.2.\\nWe also introduce a normalized variant of the TCP conﬁdence criterion, which consists in computing\\ntheratio between TCP and MCP:\\nTCPr(x;y\\x03) =P(Y=y\\x03jw;x)\\nP(Y= ^yjw;x): (3)\\nTheTCPrcriterion presents stronger theoretical guarantees than TCP, since correct predictions will\\nbe, by design, assigned the value of 1, whereas errors will range in [0;1[. On the other hand, learning\\nthis criterion may be more challenging since all correct predictions must match a single scalar value.\\n2.2 Learning TCP conﬁdence with deep neural networks\\nUsing TCP as conﬁdence criterion on a model’s output would be of great help when it comes\\nto predicting failures. However, the true class y\\x03of an output is obviously not available when\\n3\\nFigure 2: Our approach is based on two sub-networks. The classiﬁcation model with parameters\\nwis composed of a succession of convolutional and dense layers (‘ConvNet’) followed by a ﬁnal\\ndense layer with softmax activation. The conﬁdence network, ‘ConﬁdNet’, builds upon features maps\\nextracted by ConvNet, and is composed of a succession of layers which output a conﬁdence score\\n^c(x;\\x12)2[0;1].\\nestimating conﬁdence on test samples. Thus, we propose to learn TCP conﬁdence c\\x03(x;y\\x03) =\\nP(Y=y\\x03jw;x)1, our target conﬁdence value. We introduce a conﬁdence neural network, termed\\nConﬁdNet , with parameters \\x12, which outputs a conﬁdence prediction ^c(x;\\x12). During training, we\\nseek\\x12such that ^c(x;\\x12)is close toc\\x03(x;y\\x03)on training samples (see Figure 2).\\nConﬁdNet builds upon a classiﬁcation neural network M, whose parameters ware preliminary\\nlearned using cross-entropy loss LCEin (1). We are not concerned with improving model M’s\\naccuracy. As a consequence, its classiﬁcation layers (last fully connected layer and subsequent\\noperations) will be ﬁxed from now on.\\nConﬁdence network design. During initial classiﬁcation training, model Mlearns to extract\\n', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1638: ('on ^c(x;\\x12). During training, we\\nseek\\x12such that ^c(x;\\x12)is close toc\\x03(x;y\\x03)on training samples (see Figure 2).\\nConﬁdNet builds upon a classiﬁcation neural network M, whose parameters ware preliminary\\nlearned using cross-entropy loss LCEin (1). We are not concerned with improving model M’s\\naccuracy. As a consequence, its classiﬁcation layers (last fully connected layer and subsequent\\noperations) will be ﬁxed from now on.\\nConﬁdence network design. During initial classiﬁcation training, model Mlearns to extract\\nincreasingly complex features that are fed to the classiﬁcation layers. To beneﬁt from these rich\\nrepresentations, we build ConﬁdNet on top of them: ConﬁdNet passes these features through a\\nsuccession of dense layers with a ﬁnal sigmoid activation that outputs a scalar ^c(x;\\x12)2[0;1].\\nNote that in semantic segmentation, models consist of fully convolutional networks where hidden\\nrepresentations are 2D feature maps. ConﬁdNet can beneﬁt from this spatial information by replacing\\ndense layers by 1\\x021convolutions with adequate number of channels.\\nLoss function. Since we want to regress a score between 0and1, we use the `2loss to train\\nConﬁdNet:\\nLconf(\\x12;D) =1\\nNNX\\ni=1(^c(xi;\\x12)\\x00c\\x03(xi;y\\x03\\ni))2: (4)\\nIn the experimental part, we also tried more direct approaches for failure prediction such as a binary\\ncross entropy loss (BCE) between the conﬁdence network score and a incorrect/correct prediction\\ntarget. We also tried implementing Focal loss [ 31], a BCE variant which focuses on hard examples.\\nFinally, one can also see failure detection as a ranking problem where good predictions must be\\nranked before erroneous ones according to a conﬁdence criterion. To this end, we also implemented a\\nranking loss [36, 7] applied locally on training batch inputs.\\nLearning scheme. Our complete conﬁdence model, from input image to conﬁdence score, shares\\nits ﬁrst encoding part (‘ConvNet’ in Fig.2) with the classiﬁcation model M. The training of ConﬁdNet\\n1or its normalized variant TCPr(x; y\\x03).\\n4\\nstarts by ﬁxing entirely M(freezing w) and learn', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1639: ('lure detection as a ranking problem where good predictions must be\\nranked before erroneous ones according to a conﬁdence criterion. To this end, we also implemented a\\nranking loss [36, 7] applied locally on training batch inputs.\\nLearning scheme. Our complete conﬁdence model, from input image to conﬁdence score, shares\\nits ﬁrst encoding part (‘ConvNet’ in Fig.2) with the classiﬁcation model M. The training of ConﬁdNet\\n1or its normalized variant TCPr(x; y\\x03).\\n4\\nstarts by ﬁxing entirely M(freezing w) and learning \\x12using loss (4). In a next step, we can then\\nﬁne-tune the ConvNet encoder. However, as model Mhas to remain ﬁxed to compute similar\\nclassiﬁcation predictions, we have now to decouple the feature encoders used for classiﬁcation and\\nconﬁdence prediction respectively. We also deactivate dropout layers in this last training phase and\\nreduce learning rate to mitigate stochastic effects that may lead the new encoder to deviate too much\\nfrom the original one used for classiﬁcation. Data augmentation can thus still be used.\\n2.3 Related works\\nConﬁdence estimation has already raised interest in the machine learning community over the past\\ndecade. Blatz et al. [3] introduce a method similar to our BCE baseline for conﬁdence estimation in\\nmachine translation but their approach is not dedicated to training deep neural networks. Similarly,\\n[42,29] mention the use of bi-directional lattice RNN speciﬁcally designed for conﬁdence estimation\\nin speech recognition, whereas ConﬁdNet offers a model- and task-agnostic approach which can\\nbe plugged into any deep neural network. Post-hoc selective classiﬁcation methods [ 11] identify a\\nthreshold over a conﬁdence-rate function (e.g., MCP ) to satisfy a user-speciﬁed risk level, whereas\\nwe focus here on relative metrics. Recently, Hendricks et al. [17] established a standard baseline for\\ndeep neural networks which relies on MCP retrieved from softmax distribution. As stated before,\\nMCP presents several limits regarding both failure prediction and out-of-distribution detection as\\nit ', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1640: (' which can\\nbe plugged into any deep neural network. Post-hoc selective classiﬁcation methods [ 11] identify a\\nthreshold over a conﬁdence-rate function (e.g., MCP ) to satisfy a user-speciﬁed risk level, whereas\\nwe focus here on relative metrics. Recently, Hendricks et al. [17] established a standard baseline for\\ndeep neural networks which relies on MCP retrieved from softmax distribution. As stated before,\\nMCP presents several limits regarding both failure prediction and out-of-distribution detection as\\nit outputs high conﬁdence values. This limit is alleviated in our TCP criterion which also provides\\nsome interesting theoretical guarantees regarding conﬁdence threshold.\\nIn [20], Jiang et al. propose a new conﬁdence measure, ‘Trust Score’, which measures the agreement\\nbetween the classiﬁer and a modiﬁed nearest-neighbor classiﬁer on the test examples. More precisely,\\nthe conﬁdence criterion used in Trust Score [ 20] is the ratio between the distance from the sample\\nto the nearest class different from the predicted class and the distance to the predicted class. One\\nclear drawback of this approach is its lack of scalability, since computing nearest neighbors in large\\ndatasets is extremely costly in both computation and memory. Another more fundamental limitation\\nrelated to the Trust Score itself is that local distance computation becomes less meaningful in high\\ndimensional spaces [ 2], which is likely to negatively affect performances of this method. In contrast,\\nConﬁdNet is based on a training approach which learns a sub-manifold in the error/success space,\\nwhich is arguably less prone to the curse of dimensionality and, therefore, facilitate discrimination\\nbetween these classes.\\nBayesian approaches for uncertainty estimation in neural networks gained a lot of attention recently,\\nespecially due to the elegant connection between efﬁcient stochastic regularization techniques,\\ne.g.dropout [ 10], and variational inference in Bayesian neural networks [ 10,9,4,21,22]. Gal and\\nGhahramani proposed in [ 10] using Monte Car', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1641: ('rns a sub-manifold in the error/success space,\\nwhich is arguably less prone to the curse of dimensionality and, therefore, facilitate discrimination\\nbetween these classes.\\nBayesian approaches for uncertainty estimation in neural networks gained a lot of attention recently,\\nespecially due to the elegant connection between efﬁcient stochastic regularization techniques,\\ne.g.dropout [ 10], and variational inference in Bayesian neural networks [ 10,9,4,21,22]. Gal and\\nGhahramani proposed in [ 10] using Monte Carlo Dropout (MCDropout) to estimate the posterior\\npredictive network distribution by sampling several stochastic network predictions. When applied\\nto regression, the predictive distribution uncertainty can be summarized by computing statistics,\\ne.g.variance. When using MCDropout for uncertainty estimation in classiﬁcation tasks, however,\\nthe predictive distribution is averaged to a point-wise softmax estimate before computing standard\\nuncertainty criteria, e.g.entropy or variants such as mutual information. It is worth mentioning that\\nthese entropy-based criteria measure the softmax output dispersion, where the uniform distribution has\\nmaximum entropy. It is not clear how well these dispersion measures are adapted for distinguishing\\nfailures from correct predictions, especially with deep neural networks which output overconﬁdent\\npredictions [ 13]: for example, it might be very challenging to discriminate a peaky prediction\\ncorresponding to a correct prediction from an incorrect overconﬁdent one. We illustrate this issue in\\nsection 3.2.\\nIn tasks closely related to failure prediction, other approaches also identiﬁed the issue of MCP\\nregarding high conﬁdence predictions [ 17,30,26,28,13,40]. Guo et al. [13], for conﬁdence\\ncalibration, and Liang et al. [30], for out-of-distribution detection, proposed to use temperature\\nscaling to mitigate conﬁdence values. However, this doesn’t affect the ranking of the conﬁdence\\nscore and therefore the separability between errors and correct predictions. DeVries et al. [6] share\\nw', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1642: ('this issue in\\nsection 3.2.\\nIn tasks closely related to failure prediction, other approaches also identiﬁed the issue of MCP\\nregarding high conﬁdence predictions [ 17,30,26,28,13,40]. Guo et al. [13], for conﬁdence\\ncalibration, and Liang et al. [30], for out-of-distribution detection, proposed to use temperature\\nscaling to mitigate conﬁdence values. However, this doesn’t affect the ranking of the conﬁdence\\nscore and therefore the separability between errors and correct predictions. DeVries et al. [6] share\\nwith us the same purpose of learning conﬁdence in neural networks. Their work differs by focusing\\non out-of-distribution detection and learning jointly a distribution conﬁdence score and classiﬁcation\\nprobabilities. In addition, they use predicted conﬁdence score to interpolate output probabilities and\\ntarget whereas we speciﬁcally deﬁne TCP, a criterion suited for failure prediction.\\n5\\nLakshminarayanan et al. [26] propose an alternative to Bayesian neural networks by leveraging\\nensemble of neural networks to produce well-calibrated uncertainty estimates. Part of their approach\\nrelies on using a proper scoring rule as training criterion. It is interesting to note that our TCP criterion\\ncorresponds actually to the exponential cross-entropy loss value of a model prediction, which is a\\nproper scoring rule in the case of multi-class classiﬁcation.\\n3 Experiments\\nIn this section, we evaluate our approach to predict failure in both classiﬁcation and segmentation\\nsettings. First, we run comparative experiments against state-of-the-art conﬁdence estimation and\\nBayesian uncertainty estimation methods on various datasets. These results are then completed by\\na thorough analysis of the inﬂuence of the conﬁdence criterion, the training loss and the learning\\nscheme in our approach. Finally, we provide a few visualizations to get additional insight into the\\nbehavior of our approach. Our code is available at https://github.com/valeoai/ConﬁdNet.\\n3.1 Experimental setup\\nDatasets. We run experiments on image datasets of varying scal', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1643: (' state-of-the-art conﬁdence estimation and\\nBayesian uncertainty estimation methods on various datasets. These results are then completed by\\na thorough analysis of the inﬂuence of the conﬁdence criterion, the training loss and the learning\\nscheme in our approach. Finally, we provide a few visualizations to get additional insight into the\\nbehavior of our approach. Our code is available at https://github.com/valeoai/ConﬁdNet.\\n3.1 Experimental setup\\nDatasets. We run experiments on image datasets of varying scale and complexity: MNIST [ 27]\\nand SVHN [ 39] datasets provide relatively simple and small ( 28\\x0228) images of digits (10 classes).\\nCIFAR-10 and CIFAR-100 [ 24] propose more complex object recognition tasks on low resolution\\nimages. We also report experiments for semantic segmentation on CamVid [ 5], a standard road scene\\ndataset. Further details about these datasets, as well as on architectures, training and metrics can be\\nfound in supplementary 2.1.\\nNetwork architectures. The classiﬁcation deep architectures follow those proposed in [ 20] for fair\\ncomparison. They range from small convolutional networks for MNIST and SVHN to larger VGG-16\\narchitecture for the CIFAR datasets. We also added a multi-layer perceptron (MLP) with 1 hidden\\nlayer for MNIST to investigate performances on small models. For CamVid, we implemented a\\nSegNet semantic segmentation model, following [21].\\nOur conﬁdence prediction network, ConﬁdNet, is attached to the penultimate layer of the classiﬁcation\\nnetwork. It is composed of a succession of 5 dense layers. Variants of this architecture have been\\ntested, leading to similar performances (see supplementary 2.2 for more details). Following our\\nspeciﬁc learning scheme, we ﬁrst train ConﬁdNet layers before ﬁne-tuning the duplicate ConvNet\\nencoder dedicated to conﬁdence estimation. In the context of semantic segmentation, we adapt\\nConﬁdNet by making it fully convolutional.\\nEvaluation metrics. We measure the quality of failure prediction following the standard metrics\\nused in the literature [ 17', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1644: ('on of 5 dense layers. Variants of this architecture have been\\ntested, leading to similar performances (see supplementary 2.2 for more details). Following our\\nspeciﬁc learning scheme, we ﬁrst train ConﬁdNet layers before ﬁne-tuning the duplicate ConvNet\\nencoder dedicated to conﬁdence estimation. In the context of semantic segmentation, we adapt\\nConﬁdNet by making it fully convolutional.\\nEvaluation metrics. We measure the quality of failure prediction following the standard metrics\\nused in the literature [ 17]:AUPR-Error ,AUPR-Success ,FPR at 95% TPR andAUROC . We will\\nmainly focus on AUPR-Error, which computes the area under the Precision-Recall curve using errors\\nas the positive class.\\n3.2 Comparative results on failure prediction\\nTo demonstrate the effectiveness of our method, we implemented competitive conﬁdence and un-\\ncertainty estimation approaches including Maximum Class Probability (MCP) as a baseline [ 17],\\nTrust Score [ 20], and Monte-Carlo Dropout (MCDropout) [ 10]. For Trust Score, we used the code\\nprovided by the authors2. Further implementation details and parameter settings are available in the\\nsupplementary 2.1.\\nComparative results are summarized in Table 1. First of all, we observe that our approach outperforms\\nbaseline methods in every setting, with a signiﬁcant gap on small models/datasets. This conﬁrms both\\nthat TCP is an adequate conﬁdence criterion for failure prediction and that our approach ConﬁdNet\\nis able to learn it. TrustScore method also presents good results on small datasets/models such as\\nMNIST where it improved baseline. While ConﬁdNet still performs well on more complex datasets,\\nTrust Score’s performance drops, which might be explained by high dimensionality issues with\\ndistances as mentioned in section 2.3. For its application to semantic segmentation where each\\ntraining pixel is a ‘neighbor’, computational complexity forced us to reduce drastically the number\\nof training neighbors and of test samples. We sampled randomly in each train and test image a\\n2https://github.com/google', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1645: (' such as\\nMNIST where it improved baseline. While ConﬁdNet still performs well on more complex datasets,\\nTrust Score’s performance drops, which might be explained by high dimensionality issues with\\ndistances as mentioned in section 2.3. For its application to semantic segmentation where each\\ntraining pixel is a ‘neighbor’, computational complexity forced us to reduce drastically the number\\nof training neighbors and of test samples. We sampled randomly in each train and test image a\\n2https://github.com/google/TrustScore\\n6\\nTable 1: Comparison of failure prediction methods on various datasets. All methods share the same\\nclassiﬁcation network. Note that for MCDropout, test accuracy is averaged over random sampling.\\nAll values are percentages.\\nDataset Model FPR-95%-TPR AUPR-Error AUPR-Success AUC\\nMNIST\\nMLPBaseline (MCP) [17] 14.87 37.70 99.94 97.13\\nMCDropout [10] 15.15 38.22 99.94 97.15\\nTrustScore [20] 12.31 52.18 99.95 97.52\\nConﬁdNet (Ours) 11.79 57.37 99.95 97.83\\nMNIST\\nSmall ConvNetBaseline (MCP) [17] 5.56 35.05 99.99 98.63\\nMCDropout [10] 5.26 38.50 99.99 98.65\\nTrustScore [20] 10.00 35.88 99.98 98.20\\nConﬁdNet (Ours) 3.33 45.89 99.99 98.82\\nSVHN\\nSmall ConvNetBaseline (MCP) [17] 31.28 48.18 99.54 93.20\\nMCDropout [10] 36.60 43.87 99.52 92.85\\nTrustScore [20] 34.74 43.32 99.48 92.16\\nConﬁdNet (Ours) 28.58 50.72 99.55 93.44\\nCIFAR-10\\nVGG16Baseline (MCP) [17] 47.50 45.36 99.19 91.53\\nMCDropout [10] 49.02 46.40 99.27 92.08\\nTrustScore [20] 55.70 38.10 98.76 88.47\\nConﬁdNet (Ours) 44.94 49.94 99.24 92.12\\nCIFAR-100\\nVGG16Baseline (MCP) [17] 67.86 71.99 92.49 85.67\\nMCDropout [10] 64.68 72.59 92.96 86.09\\nTrustScore [20] 71.74 66.82 91.58 84.17\\nConﬁdNet (Ours) 62.96 73.68 92.68 86.28\\nCamVid\\nSegNetBaseline (MCP) [17] 63.87 48.53 96.37 84.42\\nMCDropout [10] 62.95 49.35 96.40 84.58\\nTrustScore [20] 20.42 92.72 68.33\\nConﬁdNet (Ours) 61.52 50.51 96.58 85.02\\n(a) CIFAR-10\\n (b) SVHN\\nFigure 3: Risk-coverage curves. ‘Selective risk’ ( y-axis) represents the percentage of errors in the\\nremaining test set for a given coverage percentage.\\nsmall percen', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1646: ('MCP) [17] 67.86 71.99 92.49 85.67\\nMCDropout [10] 64.68 72.59 92.96 86.09\\nTrustScore [20] 71.74 66.82 91.58 84.17\\nConﬁdNet (Ours) 62.96 73.68 92.68 86.28\\nCamVid\\nSegNetBaseline (MCP) [17] 63.87 48.53 96.37 84.42\\nMCDropout [10] 62.95 49.35 96.40 84.58\\nTrustScore [20] 20.42 92.72 68.33\\nConﬁdNet (Ours) 61.52 50.51 96.58 85.02\\n(a) CIFAR-10\\n (b) SVHN\\nFigure 3: Risk-coverage curves. ‘Selective risk’ ( y-axis) represents the percentage of errors in the\\nremaining test set for a given coverage percentage.\\nsmall percentage of pixels to compute TrustScore. ConﬁdNet, in contrast, is as fast as the original\\nsegmentation network.\\nWe also improve state-of-art performances from MCDropout. While MCDropout leverages ensem-\\nbling based on dropout layers, taking as conﬁdence measure the entropy on the average softmax\\ndistribution may not be always adequate. In Figure 4, we show side-by-side two samples with a\\nsimilar distribution entropy. Left image is misclassiﬁed while right one enjoys a correct prediction.\\nEntropy is a symmetric measure in regards to class probabilities: a correct prediction with [0:65;0:35]\\ndistribution is evaluated as conﬁdent as an incorrect one with [0:35;0:65]distribution. In contrast,\\nour approach can discriminate an incorrect from a correct prediction despite both having similarly\\nspread distributions.\\n7\\nFigure 4: Illustrating the limits of MCDropout with entropy as conﬁdence estimation on SVHN test\\nsamples. Red-border image (a) is misclassiﬁed by the classiﬁcation model; green-border image (b)\\nis correctly classiﬁed. Prediction exhibit similar high entropy in both cases. For each sample, we\\nprovide a plot of their softmax predictive distribution.\\nRisk-coverage curves [ 8,11] depicting the performance of ConﬁdNet and other baselines for CIFAR-\\n10 and SVHN datasets appear in Figure 3. ‘Coverage’ corresponds to the probability mass of the\\nnon-rejected region after using a threshold as selection function [ 11]. For both datasets, ConﬁdNet\\npresents a better coverage potential for each selective risk that a user ', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1647: ('y classiﬁed. Prediction exhibit similar high entropy in both cases. For each sample, we\\nprovide a plot of their softmax predictive distribution.\\nRisk-coverage curves [ 8,11] depicting the performance of ConﬁdNet and other baselines for CIFAR-\\n10 and SVHN datasets appear in Figure 3. ‘Coverage’ corresponds to the probability mass of the\\nnon-rejected region after using a threshold as selection function [ 11]. For both datasets, ConﬁdNet\\npresents a better coverage potential for each selective risk that a user can choose beforehand. In\\naddition, we can see that the improvement is more pronounced at high coverage rates - e.g. in\\n[0:8; 0:95]for CIFAR-10 (Fig. 3a) and in [0:86; 0:96]for SVHN (Fig. 3b) - which highlights the\\ncapacity of ConﬁdNet to identify successfully critical failures.\\n3.3 Effect of learning variants\\nTable 2: Effect of learning scheme on AUPR-Error\\nMNIST CIFAR-100\\nSmallConvNet VGG-16\\nConﬁdence training 43.94% 72.68%\\n+ Fine-tuning ConvNet 45.89% 73.68%We ﬁrst evaluate the effect\\nof ﬁne-tuning ConvNet in\\nour approach. Without\\nﬁne-tuning, ConﬁdNet al-\\nready achieves signiﬁcant\\nimprovements w.r.t. base-\\nline, as shown in Table 2.\\nBy allowing subsequent\\nﬁne-tuning as described in\\nsection 2.2, ConﬁdNet performance is further boosted in every setting, around 1-2%. Note that using\\na vanilla ﬁne-tuning without deactivating dropout layers did not bring any improvement.\\nGiven the small number of errors available due to deep neural network over-ﬁtting, we also experi-\\nmented with training ConﬁdNet on a hold-out dataset. We report results on all datasets in Table 3 for\\nvalidation sets with 10% of samples. We observe a general performance drop when using a validation\\nset for training TCP conﬁdence. The drop is especially pronounced for small datasets (MNIST),\\nwhere models reach >97% train and val accuracies. Consequently, with a high accuracy and a small\\nvalidation set, we do not get a larger absolute number of errors using val set compared to train set.\\nOne solution would be to increase validation set size but thi', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1648: (' dataset. We report results on all datasets in Table 3 for\\nvalidation sets with 10% of samples. We observe a general performance drop when using a validation\\nset for training TCP conﬁdence. The drop is especially pronounced for small datasets (MNIST),\\nwhere models reach >97% train and val accuracies. Consequently, with a high accuracy and a small\\nvalidation set, we do not get a larger absolute number of errors using val set compared to train set.\\nOne solution would be to increase validation set size but this would damage model’s prediction per-\\nformance. By contrast, we take care with our approach to base our conﬁdence estimation on models\\nwith levels of test predictive performance that are similar to those of baselines. On CIFAR-100, the\\ngap between train accuracy and val accuracy is substantial (95.56% vs. 65.96%), which may explain\\nthe slight improvement for conﬁdence estimation using val set (+0.17%). We think that training\\nConﬁdNet on val set with models reporting low/middle test accuracies could improve the approach.\\nTable 3: Comparison between training ConﬁdNet on train set or on validation set\\nAUPR-Error (%) MNIST MNIST SVHN CIFAR-10 CIFAR-100 CamVid\\nMLP SmallConvNet SmallConvNet VGG-16 VGG-16 SegNet\\nConﬁdNet (using train set) 57.34% 43.94% 50.72% 49.94% 73.68% 50.28%\\nConﬁdNet (using val set) 33.41% 34.22% 47.96% 48.93% 73.85% 50.15%\\nOn Table 4, we compare training ConﬁdNet with MSE loss to binary classiﬁcation cross-\\nentropy loss (BCE). Even though BCE speciﬁcally addresses the failure prediction task, we\\n8\\nobserve that it achieves lower performances on CIFAR-10 and CamVid datasets. Focal\\nloss and ranking loss were also tested and presented similar results (see supplementary 2.3).\\nTable 4: Effect of loss and normalized criterion on AUPR-Error\\nDataset Loss Criterion\\nTCP BCE TCPr\\nCIFAR-10 49.94% 47.95% 48.78%\\nCamVid 50.51% 48.96% 51.35%We intuitively think that\\nTCP regularizes training\\nby providing more ﬁne-\\ngrained information about\\nthe quality of the classiﬁer\\nregarding a sample’s pre-\\ndiction. This is e', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1649: (' we\\n8\\nobserve that it achieves lower performances on CIFAR-10 and CamVid datasets. Focal\\nloss and ranking loss were also tested and presented similar results (see supplementary 2.3).\\nTable 4: Effect of loss and normalized criterion on AUPR-Error\\nDataset Loss Criterion\\nTCP BCE TCPr\\nCIFAR-10 49.94% 47.95% 48.78%\\nCamVid 50.51% 48.96% 51.35%We intuitively think that\\nTCP regularizes training\\nby providing more ﬁne-\\ngrained information about\\nthe quality of the classiﬁer\\nregarding a sample’s pre-\\ndiction. This is especially\\nimportant in the difﬁcult\\nlearning conﬁguration where only very few error samples are available due to the good performance\\nof the classiﬁer. We also evaluate the impact of regression to the normalized criterion TCPr: per-\\nformance is lower than the one of TCP on small datasets such as CIFAR-10 where few errors are\\npresent, but higher on larger datasets such as CamVid where each pixel is a sample. This emphasizes\\nonce again the complexity of incorrect/correct classiﬁcation training.\\n3.4 Qualitative assessments\\nIn this last subsection, we provide an illustration on CamVid (Figure 5) to better understand our\\napproach for failure prediction. Compared to MCP baseline, our approach produces higher conﬁdence\\nscores for correct pixel predictions and lower ones on erroneously predicted pixels, which allow an\\nuser to better detect errors area in semantic segmentation.\\nFigure 5: Comparison of inverse conﬁdence (uncertainty) map between ConﬁdNet (e) and MCP (f) on\\none CamVid scene. The top row shows the input image (a) with its ground-truth (b) and the semantic\\nsegmentation mask (c) predicted by the original classiﬁcation model. The error map associated to\\nthe predicted segmentation is shown in (d), with erroneous predictions ﬂagged in white. ConﬁdNet\\n(55.53% AP-Error) allows a better prediction of these errors than MCP (54.69% AP-Error).\\n4 Conclusion\\nIn this paper, we deﬁned a new conﬁdence criterion, TCP, which provides both theoretical guarantees\\nand empirical evidences to address failure prediction. We propo', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1650: ('image (a) with its ground-truth (b) and the semantic\\nsegmentation mask (c) predicted by the original classiﬁcation model. The error map associated to\\nthe predicted segmentation is shown in (d), with erroneous predictions ﬂagged in white. ConﬁdNet\\n(55.53% AP-Error) allows a better prediction of these errors than MCP (54.69% AP-Error).\\n4 Conclusion\\nIn this paper, we deﬁned a new conﬁdence criterion, TCP, which provides both theoretical guarantees\\nand empirical evidences to address failure prediction. We proposed a speciﬁc method to learn this\\ncriterion with a conﬁdence neural network built upon a classiﬁcation model. Results showed a\\nsigniﬁcant improvement from strong baselines on various classiﬁcation and semantic segmentation\\ndatasets, which validate the effectiveness of our approach. Further works involve exploring methods\\nto artiﬁcially generate errors, such as in adversarial training. ConﬁdNet could also be applied for\\nuncertainty estimation in domain adaptation [45, 14] or in multi-task learning [23, 38].\\n9\\nReferences\\n[1]Dario Amodei, Chris Olah, Jacob Steinhardt, Paul F. Christiano, John Schulman, and Dan Mané.\\nConcrete problems in AI safety. arXiv preprint arXiv:1606.06565 , 2016. 1\\n[2]Kevin Beyer, Jonathan Goldstein, Raghu Ramakrishnan, and Uri Shaft. When is “nearest\\nneighbor” meaningful? In ICDT , 1999. 5\\n[3]John Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza,\\nAlberto Sanchis, and Nicola Uefﬁng. Conﬁdence estimation for machine translation. In\\nCOLING , 2004. 5\\n[4]Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty\\nin neural networks. In ICML , 2015. 5\\n[5]Gabriel J. Brostow, Julien Fauqueur, and Roberto Cipolla. Semantic object classes in video: A\\nhigh-deﬁnition ground truth database. Pattern Recogn. Lett. , 30(2):88–97, 2009. 6\\n[6]Terrance DeVries and Graham W Taylor. Learning conﬁdence for out-of-distribution detection\\nin neural networks. arXiv preprint arXiv:1802.04865 , 2018. 5\\n[7]Thibaut Durand, Nicolas Thome, and Matthieu ', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1651: ('arles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. Weight uncertainty\\nin neural networks. In ICML , 2015. 5\\n[5]Gabriel J. Brostow, Julien Fauqueur, and Roberto Cipolla. Semantic object classes in video: A\\nhigh-deﬁnition ground truth database. Pattern Recogn. Lett. , 30(2):88–97, 2009. 6\\n[6]Terrance DeVries and Graham W Taylor. Learning conﬁdence for out-of-distribution detection\\nin neural networks. arXiv preprint arXiv:1802.04865 , 2018. 5\\n[7]Thibaut Durand, Nicolas Thome, and Matthieu Cord. Mantra: Minimum maximum latent\\nstructural SVM for image classiﬁcation and ranking. In ICCV , 2015. 4\\n[8]Ran El-Yaniv and Yair Wiener. On the foundations of noise-free selective classiﬁcation. J.\\nMach. Learn. Res. , 11:1605–1641, 2010. 8\\n[9] Yarin Gal. Uncertainty in Deep Learning . PhD thesis, University of Cambridge, 2016. 5\\n[10] Yarin Gal and Zoubin Ghahramani. Dropout as a bayesian approximation: Representing model\\nuncertainty in deep learning. In ICML , 2016. 5, 6, 7\\n[11] Yonatan Geifman and Ran El-Yaniv. Selective classiﬁcation for deep neural networks. In NIPS ,\\n2017. 5, 8\\n[12] Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversar-\\nial examples. arXiv preprint arXiv:1412.6572 , 2014. 2\\n[13] Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q. Weinberger. On calibration of modern neural\\nnetworks. In ICML , 2017. 2, 3, 5\\n[14] Ligong Han, Yang Zou, Ruijiang Gao, Lezi Wang, and Dimitris Metaxas. Unsupervised domain\\nadaptation via calibrating uncertainties. In CVPR Workshops , 2019. 9\\n[15] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan\\nPrenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and Andrew Y . Ng. Deep speech:\\nScaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567 , 2014. 1\\n[16] Simon Hecker, Dengxin Dai, and Luc Van Gool. Failure prediction for autonomous driving. In\\nIV, 2018. 1\\n[17] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassiﬁed and out-of-distribution\\nexamples in neural network', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1652: ('shops , 2019. 9\\n[15] Awni Hannun, Carl Case, Jared Casper, Bryan Catanzaro, Greg Diamos, Erich Elsen, Ryan\\nPrenger, Sanjeev Satheesh, Shubho Sengupta, Adam Coates, and Andrew Y . Ng. Deep speech:\\nScaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567 , 2014. 1\\n[16] Simon Hecker, Dengxin Dai, and Luc Van Gool. Failure prediction for autonomous driving. In\\nIV, 2018. 1\\n[17] Dan Hendrycks and Kevin Gimpel. A baseline for detecting misclassiﬁed and out-of-distribution\\nexamples in neural networks. In ICLR , 2017. 1, 2, 5, 6, 7\\n[18] Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed, Navdeep\\nJaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath, et al. Deep neural\\nnetworks for acoustic modeling in speech recognition: The shared views of four research groups.\\nIEEE Signal Processing Magazine , 29(6):82–97, 2012. 1\\n[19] Joel Janai, Fatma Güney, Aseem Behl, and Andreas Geiger. Computer vision for au-\\ntonomous vehicles: Problems, datasets and state-of-the-art. arXiv preprint arXiv:1704.05519 ,\\nabs/1704.05519, 2017. 1\\n[20] Heinrich Jiang, Been Kim, Melody Guan, and Maya Gupta. To trust or not to trust a classiﬁer.\\nInNIPS , 2018. 1, 2, 5, 6, 7\\n10\\n[21] Alex Kendall, Vijay Badrinarayanan, , and Roberto Cipolla. Bayesian SegNet: Model un-\\ncertainty in deep convolutional encoder-decoder architectures for scene understanding. arXiv\\npreprint arXiv:1511.02680 , 2015. 5, 6\\n[22] Alex Kendall and Yarin Gal. What uncertainties do we need in Bayesian deep learning for\\ncomputer vision? In NIPS , 2017. 5\\n[23] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh\\nlosses for scene geometry and semantics. In CVPR , June 2018. 9\\n[24] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s\\nthesis, Department of Computer Science, University of Toronto , 2009. 6\\n[25] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep\\nconvolutional neural networks. In NIPS , 2012. 1\\n[26] Balaji La', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1653: ('ion? In NIPS , 2017. 5\\n[23] Alex Kendall, Yarin Gal, and Roberto Cipolla. Multi-task learning using uncertainty to weigh\\nlosses for scene geometry and semantics. In CVPR , June 2018. 9\\n[24] A. Krizhevsky and G. Hinton. Learning multiple layers of features from tiny images. Master’s\\nthesis, Department of Computer Science, University of Toronto , 2009. 6\\n[25] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep\\nconvolutional neural networks. In NIPS , 2012. 1\\n[26] Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable\\npredictive uncertainty estimation using deep ensembles. In Advances in Neural Information\\nProcessing Systems 30 , 2017. 2, 5, 6\\n[27] Yann LeCun and Corinna Cortes. The MNIST database of handwritten digits.\\nhttp://yann.lecun.com/exdb/mnist , 1998. 6\\n[28] Kimin Lee, Honglak Lee, Kibok Lee, and Jinwoo Shin. Training conﬁdence-calibrated classiﬁers\\nfor detecting out-of-distribution samples. In ICLR , 2018. 5\\n[29] Qiujia Li, Preben Ness, Anton Ragni, and M.J.F. Gales. Bi-directional lattice recurrent neural\\nnetworks for conﬁdence estimation. In IEEE International Conference on Acoustics, Speech\\nand Signal Processing , 10 2018. 5\\n[30] Shiyu Liang, Yixuan Li, and R. Srikant. Enhancing the reliability of out-of-distribution image\\ndetection in neural networks. In ICLR , 2018. 2, 5\\n[31] T. Lin, P. Goyal, R. Girshick, K. He, and P. Dollár. Focal loss for dense object detection. In\\nICCV , 2017. 4\\n[32] Ondrej Linda, Todd V ollmer, and Milos Manic. Neural network based intrusion detection\\nsystem for critical infrastructures. In IJCNN , 2009. 1\\n[33] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu,\\nand Alexander C. Berg. SSD: Single shot multibox detector. In ECCV , 2016. 1\\n[34] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word\\nrepresentations in vector space. arXiv preprint arXiv:1301.3781 , abs/1301.3781, 2013. 1\\n[35] Tomas Mikolov, Martin Karaﬁát, Lukás Burget, Jan Cernocký,', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1654: ('. Neural network based intrusion detection\\nsystem for critical infrastructures. In IJCNN , 2009. 1\\n[33] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu,\\nand Alexander C. Berg. SSD: Single shot multibox detector. In ECCV , 2016. 1\\n[34] Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. Efﬁcient estimation of word\\nrepresentations in vector space. arXiv preprint arXiv:1301.3781 , abs/1301.3781, 2013. 1\\n[35] Tomas Mikolov, Martin Karaﬁát, Lukás Burget, Jan Cernocký, and Sanjeev Khudanpur. Recur-\\nrent neural network based language model. In Takao Kobayashi, Keikichi Hirose, and Satoshi\\nNakamura, editors, INTERSPEECH , 2010. 1\\n[36] Pritish Mohapatra, Michal Rolínek, C.V . Jawahar, Vladimir Kolmogorov, and M. Pawan Kumar.\\nEfﬁcient optimization for rank-based loss functions. In CVPR , June 2018. 4\\n[37] Taylor Mordan, Nicolas Thome, Gilles Henaff, and Matthieu Cord. End-to-end learning of\\nlatent deformable part-based representations for object detection. International Journal of\\nComputer Vision , pages 1–21, 07 2018. 1\\n[38] Taylor Mordan, Nicolas Thome, Gilles Henaff, and Matthieu Cord. Revisiting multi-task\\nlearning with ROCK: a deep residual auxiliary block for visual detection. In NIPS , 2018. 9\\n[39] Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y . Ng.\\nReading digits in natural images with unsupervised feature learning. In NIPS Workshop , 2011.\\n6\\n[40] L. Neumann, A. Zisserman, and A. Vedaldi. Relaxed softmax: Efﬁcient conﬁdence auto-\\ncalibration for safe pedestrian detection. In NIPS Workshops , 2018. 2, 5\\n11\\n[41] Anh Mai Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High\\nconﬁdence predictions for unrecognizable images. In CVPR , 2015. 2\\n[42] A. Ragni, Q. Li, M. J. F. Gales, and Y . Wang. Conﬁdence estimation and deletion prediction\\nusing bidirectional recurrent neural networks. In SLT Workshop , 2018. 5\\n[43] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time\\nobject detectio', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1655: ('tion for safe pedestrian detection. In NIPS Workshops , 2018. 2, 5\\n11\\n[41] Anh Mai Nguyen, Jason Yosinski, and Jeff Clune. Deep neural networks are easily fooled: High\\nconﬁdence predictions for unrecognizable images. In CVPR , 2015. 2\\n[42] A. Ragni, Q. Li, M. J. F. Gales, and Y . Wang. Conﬁdence estimation and deletion prediction\\nusing bidirectional recurrent neural networks. In SLT Workshop , 2018. 5\\n[43] Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster R-CNN: Towards real-time\\nobject detection with region proposal networks. In NIPS , 2015. 1\\n[44] Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian J.\\nGoodfellow, and Rob Fergus. Intriguing properties of neural networks. In ICLR , 2014. 2\\n[45] Tuan-Hung Vu, Himalaya Jain, Maxime Bucher, Matthieu Cord, and Patrick Pérez. ADVENT:\\nAdversarial entropy minimization for domain adaptation in semantic segmentation. In CVPR ,\\n2019. 9\\n12', 'Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf'), 1656: ('The Generalization-Stability Tradeoff In Neural\\nNetwork Pruning\\nBrian R. Bartoldson\\x03\\nLawrence Livermore\\nNational Laboratory\\nbartoldson@llnl.govAri S. Morcos\\nFacebook AI Research\\narimorcos@fb.com\\nAdrian Barbu\\nFlorida State University\\nabarbu@stat.fsu.eduGordon Erlebacher\\nFlorida State University\\ngerlebacher@fsu.edu\\nAbstract\\nPruning neural network parameters is often viewed as a means to compress models,\\nbut pruning has also been motivated by the desire to prevent overﬁtting. This\\nmotivation is particularly relevant given the perhaps surprising observation that\\na wide variety of pruning approaches increase test accuracy despite sometimes\\nmassive reductions in parameter counts. To better understand this phenomenon,\\nwe analyze the behavior of pruning over the course of training, ﬁnding that prun-\\ning’s beneﬁt to generalization increases with pruning’s instability (deﬁned as the\\ndrop in test accuracy immediately following pruning). We demonstrate that this\\n“generalization-stability tradeoff” is present across a wide variety of pruning settings\\nand propose a mechanism for its cause: pruning regularizes similarly to noise in-\\njection. Supporting this, we ﬁnd less pruning stability leads to more model ﬂatness\\nand the beneﬁts of pruning do not depend on permanent parameter removal. These\\nresults explain the compatibility of pruning-based generalization improvements\\nand the high generalization recently observed in overparameterized networks.\\n1 Introduction\\nStudies of generalization in deep neural networks (DNNs) have increasingly focused on the observa-\\ntion that adding parameters improves generalization (as measured by model accuracy on previously\\nunobserved inputs), even when the DNN already has enough parameters to ﬁt large datasets of\\nrandomized data [ 1,2]. This surprising phenomenon has been addressed by an array of empirical and\\ntheoretical analyses [ 3–13], all of which study generalization measures other than parameter counts.\\nReducing memory-footprint and inference-FLOPs requirements of such well-generalizing but ', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1657: ('easingly focused on the observa-\\ntion that adding parameters improves generalization (as measured by model accuracy on previously\\nunobserved inputs), even when the DNN already has enough parameters to ﬁt large datasets of\\nrandomized data [ 1,2]. This surprising phenomenon has been addressed by an array of empirical and\\ntheoretical analyses [ 3–13], all of which study generalization measures other than parameter counts.\\nReducing memory-footprint and inference-FLOPs requirements of such well-generalizing but overpa-\\nrameterized DNNs is necessary to make them broadly applicable [ 14], and it is achievable through\\nneural network pruning, which can substantially shrink parameter counts without harming accuracy\\n[15–21]. Moreover, many pruning methods actually improve generalization [15–17, 22–30].\\nAt the interface of pruning and generalization research, then, there’s an apparent contradiction. If\\nlarger parameter counts don’t increase overﬁtting in overparameterized DNNs, why would pruning\\nDNN parameters throughout training improve generalization?\\nWe provide an answer to this question by illuminating a regularization mechanism in pruning separate\\nfrom its effect on parameter counts. Speciﬁcally, we show that simple magnitude pruning [ 17,18]\\nproduces an effect similar to noise-injection regularization [ 31–37]. We explore this view of pruning\\n\\x03Corresponding author. Majority of work completed as a student at Florida State University.\\n34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.\\nPruning\\nIterationsi\\x001 i i+ 1TrainTest\\n(tpre;i\\x001)PruneTest\\n(tpost;i\\x001)TrainTest\\n(tpre;i)PruneTest\\n(tpost;i)\\nFigure 1: A pruning algorithm’s instability on pruning iteration iisinstabilityi=tpre;i\\x00tpost;i\\ntpre;i, where\\ntpre;iandtpost;iare the pruned DNN’s test accuracies measured immediately before and immediately after\\n(respectively) pruning iteration i. Pruning algorithm stability on iteration iisstabilityi= 1\\x00instabilityi, the\\nfraction of accuracy remaining immediately after a pruning event.\\nas nois', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1658: ('anada.\\nPruning\\nIterationsi\\x001 i i+ 1TrainTest\\n(tpre;i\\x001)PruneTest\\n(tpost;i\\x001)TrainTest\\n(tpre;i)PruneTest\\n(tpost;i)\\nFigure 1: A pruning algorithm’s instability on pruning iteration iisinstabilityi=tpre;i\\x00tpost;i\\ntpre;i, where\\ntpre;iandtpost;iare the pruned DNN’s test accuracies measured immediately before and immediately after\\n(respectively) pruning iteration i. Pruning algorithm stability on iteration iisstabilityi= 1\\x00instabilityi, the\\nfraction of accuracy remaining immediately after a pruning event.\\nas noise injection through a proxy for the level of representation “noise” or corruption pruning injects:\\nthe drop in accuracy immediately after a pruning event, which we call the pruning instability (Figure\\n1 illustrates the computation of instability). While stability (stability = 1\\x00instability ) is often the\\ngoal of neural network pruning because it preserves the function computed [ 15], stable pruning could\\nbe suboptimal to the extent that pruning regularizes by noising representations during learning.\\nSupporting the framing of pruning as noise-injection, we ﬁnd that pruning stability is negatively corre-\\nlated with the ﬁnal level of generalization attained by the pruned model . Further, this generalization-\\nstability tradeoff appears when making changes to any of several pruning algorithm hyperparameters.\\nFor example, pruning algorithms typically prune the smallest magnitude weights to minimize their\\nimpact on network activation patterns (i.e., maximize stability). However, we observe that while\\npruning the largest magnitude weights does indeed cause greater harm to stability, it also increases\\ngeneralization performance. In addition to suggesting a way to understand the repercussions of\\npruning algorithm design and hyperparameter choices, then, these results reinforce the idea that\\npruning’s positive effect on DNN generalization is more about stability than ﬁnal parameter count.\\nWhile the generalization-stability tradeoff suggests that pruning’s generalization beneﬁts may be\\npresent even without the permanent pa', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1659: ('gest magnitude weights does indeed cause greater harm to stability, it also increases\\ngeneralization performance. In addition to suggesting a way to understand the repercussions of\\npruning algorithm design and hyperparameter choices, then, these results reinforce the idea that\\npruning’s positive effect on DNN generalization is more about stability than ﬁnal parameter count.\\nWhile the generalization-stability tradeoff suggests that pruning’s generalization beneﬁts may be\\npresent even without the permanent parameter count reduction associated with pruning, a more\\ntraditional interpretation suggests that permanent removal of parameters is critical to how pruning\\nimproves generalization. To test this, we allow pruned connections back into the network after it has\\nadapted to pruning, and we ﬁnd that the generalization beneﬁt of permanent pruning is still obtained.\\nThis independence of pruning-based generalization improvements from permanent parameter count\\nreduction resolves the aforementioned contradiction between pruning and generalization.\\nWe hypothesize that lowering pruning stability (and thus adding more representation noise) helps\\ngeneralization by encouraging more ﬂatness in the ﬁnal DNN. Our experiments support this hypoth-\\nesis. We ﬁnd that pruning stability is negatively correlated with multiple measures of ﬂatness that\\nare associated with better generalization. Thus, pruning and overparameterizing may improve DNN\\ngeneralization for the same reason, as ﬂatness is also a suspected source of the unintuitively high\\ngeneralization levels in overparameterized DNNs [3, 4, 9, 11, 12, 38–40].\\n2 Approach\\nOur primary aim in this work is to better understand the relationship between pruning and general-\\nization performance, rather than the development of a new pruning method. We study this topic by\\nvarying the hyperparameters of magnitude pruning algorithms [ 17,18] to generate a broad array of\\ngeneralization improvements and stability levels.2The generalization levels reported also reﬂect the\\ngeneralization gap (trai', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1660: ('ly high\\ngeneralization levels in overparameterized DNNs [3, 4, 9, 11, 12, 38–40].\\n2 Approach\\nOur primary aim in this work is to better understand the relationship between pruning and general-\\nization performance, rather than the development of a new pruning method. We study this topic by\\nvarying the hyperparameters of magnitude pruning algorithms [ 17,18] to generate a broad array of\\ngeneralization improvements and stability levels.2The generalization levels reported also reﬂect the\\ngeneralization gap (train minus test accuracy) behavior because all training accuracies at the time of\\nevaluation are 100% (Section 3.2 has exceptions that we address by plotting generalization gaps).\\nIn each experiment, every hyperparameter conﬁguration was run ten times, and plots display all ten\\nruns or a mean with 95% conﬁdence intervals estimated from bootstrapping. Here, we discuss our\\nhyperparameter choices and methodological approach. Please see Appendix A for more details.\\nModels, data, and optimization We use VGG11 [ 41] with batch normalization and its dense\\nlayers replaced by a single dense layer, ResNet18, ResNet20, and ResNet56 [ 42]. Except where noted\\nin Section 3.2, we train models with Adam [ 43], which was more helpful than SGD for recovering\\naccuracy after pruning (perhaps related to the observation that recovery from pruning is harder when\\n2Our code is available at https://github.com/bbartoldson/GeneralizationStabilityTradeoff .\\n2\\nlearning rates are low [ 44]). We use CIFAR10 data [ 45] without data augmentation, except in Section\\n3.2 where we note use of data augmentation (random crops and horizontal ﬂips) and Appendix F\\nwhere we use CIFAR100 with data augmentation to mimic the setup in [ 10]. We set batch size to 128.\\nUse of`1- and`2-norm regularization Pruning algorithms often add additional regularization via\\na sparsifying penalty [ 22,24–26,28,30,46], which obfuscates the intrinsic effect of pruning on\\ngeneralization. Even with a simple magnitude pruning algorithm, the choice between `1- and`2-norm\\nregulariza', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1661: (', except in Section\\n3.2 where we note use of data augmentation (random crops and horizontal ﬂips) and Appendix F\\nwhere we use CIFAR100 with data augmentation to mimic the setup in [ 10]. We set batch size to 128.\\nUse of`1- and`2-norm regularization Pruning algorithms often add additional regularization via\\na sparsifying penalty [ 22,24–26,28,30,46], which obfuscates the intrinsic effect of pruning on\\ngeneralization. Even with a simple magnitude pruning algorithm, the choice between `1- and`2-norm\\nregularization affects the size of the generalization beneﬁt of pruning [ 17], making it difﬁcult to\\ndetermine whether changes in generalization performance are due to changes in the pruning approach\\nor the regularization. To avoid this confound, we study variants of simple magnitude pruning in\\nunpenalized models, except when we note our use of the training setup of [42] in Section 3.2.\\nEschewing such regularizers may have another beneﬁt: in a less regularized model, the size of the\\ngeneralization improvement caused by pruning may be ampliﬁed. Larger effect sizes are desirable, as\\nthey help facilitate the identiﬁcation of pruning algorithm facets that improve generalization. To this\\nend, we also restrict pruning to the removal of an intermediate number of weights, which prevents\\npruning from harming accuracy, even when removing random or large weights [18].\\nPruning schedule and rates For each layer of a model, the pruning schedule speciﬁes epochs on\\nwhich pruning iterations occur (for example, two conﬁgurations in Figure 2 prune the last VGG11\\nconvolutional layer every 40 epochs between epochs 7 and 247). On a pruning iteration, the amount\\nof the layer pruned is the layer’s iterative pruning rate (given as a fraction of the layer’s original\\nsize), and a layer’s total pruning percentage is its iterative pruning rate multiplied by the number\\nof scheduled pruning iterations. With the aforementioned schedule, there are seven pruning events,\\nand a layer with total pruning percentage 90% would have an iterative pruning rate of', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1662: ('re 2 prune the last VGG11\\nconvolutional layer every 40 epochs between epochs 7 and 247). On a pruning iteration, the amount\\nof the layer pruned is the layer’s iterative pruning rate (given as a fraction of the layer’s original\\nsize), and a layer’s total pruning percentage is its iterative pruning rate multiplied by the number\\nof scheduled pruning iterations. With the aforementioned schedule, there are seven pruning events,\\nand a layer with total pruning percentage 90% would have an iterative pruning rate of90\\n7%\\x1913%.\\nExcept where we note otherwise, our VGG11 and ResNet18 experiments prune just the last four\\nconvolutional layers with total pruning percentages {30%, 30%, 30%, 90%} and {25%, 40%, 25%,\\n95%}, respectively. This leads to parameter reductions of 42% for VGG11 and 46% for ResNet18.\\nOur experiments and earlier work [47] indicated that focusing pruning on later layers was sufﬁcient\\nto create generalization and stability differences while also facilitating recovery from various kinds\\nof pruning instability (lower total pruning percentages in earlier layers also helped recovery in\\n[18,30]). As iterative pruning rate and schedule vary by layer to accommodate differing total pruning\\npercentages, we note the largest iterative pruning rate used by a conﬁguration in the plot legend. In\\nSection 3.2, we test the dependence of our results on having layer-speciﬁc hyperparameter settings by\\npruning 10% of every layer in every block of ResNet18, ResNet20, and ResNet56.\\nParameter scoring and pruning target We remove entire ﬁlters (structured pruning), and we\\ntypically score ﬁlters of VGG11 using their `2-norm and ﬁlters of ResNet18—which has feature\\nmap shortcuts not accounted for by ﬁlters—using their resulting feature map activations’ `1-norms\\n[18,48], which we compute with a moving average. Experiments in Section 3.2, Appendix B, and\\nAppendix F use other scoring approaches, including `1-norm scoring of ResNet ﬁlters in Section 3.2.\\nWe denote pruning algorithms that target /remove the smallest-magnitude (lowest-scored', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1663: ('ntire ﬁlters (structured pruning), and we\\ntypically score ﬁlters of VGG11 using their `2-norm and ﬁlters of ResNet18—which has feature\\nmap shortcuts not accounted for by ﬁlters—using their resulting feature map activations’ `1-norms\\n[18,48], which we compute with a moving average. Experiments in Section 3.2, Appendix B, and\\nAppendix F use other scoring approaches, including `1-norm scoring of ResNet ﬁlters in Section 3.2.\\nWe denote pruning algorithms that target /remove the smallest-magnitude (lowest-scored) parameters\\nwith an \"S\" subscript (e.g. Prune Sor Prune_S), random parameters with an \"R\" subscript, and the\\nlargest-magnitude parameters with an \"L\" subscript. Please see Appendix A for more pruning details.\\nFraming pruning as noise injection Pruning is typically a deterministic procedure, with the\\nweights that are targeted for pruning being deﬁned by a criterion (e.g., the bottom 1% of weights in\\nmagnitude). Given weights meeting such a criterion, pruning can be effected through their multiplica-\\ntion by a Bernoulli(p)distributed random variable, where p= 0. Settingp>0would correspond\\nto DropConnect, a DNN noise injection approach and generalization of dropout [ 33–35]. Thus, for\\nweights meeting the pruning criterion, pruning is a limiting case of a noise injection technique. Since\\nnot all weights matter equally to a DNN’s computations, we measure the amount/salience of the\\n“noise” injected by pruning via the drop in accuracy immediately following pruning (see Figure 1).\\nIn Section 3.3, we show that pruning’s generalization beneﬁt can be obtained without permanently\\nremoving parameters. Primarily, we achieve this by multiplying by zero—for a denoted number of\\ntraining batches—the parameters we would normally prune, then returning them to the model (we run\\nvariants where they return initialized at the values they trained to prior to zeroing, and at zero as in\\n[49]). In a separate experiment, we replace the multiplication by zero with the addition of Gaussian\\n3\\n50 100 150 200 250 300\\nEpoch83.0 83.083.5 83.584.', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1664: ('g’s generalization beneﬁt can be obtained without permanently\\nremoving parameters. Primarily, we achieve this by multiplying by zero—for a denoted number of\\ntraining batches—the parameters we would normally prune, then returning them to the model (we run\\nvariants where they return initialized at the values they trained to prior to zeroing, and at zero as in\\n[49]). In a separate experiment, we replace the multiplication by zero with the addition of Gaussian\\n3\\n50 100 150 200 250 300\\nEpoch83.0 83.083.5 83.584.0 84.084.5 84.585.0 85.085.5 85.586.0 86.086.5 86.5Test Accuracy (%)\\n7%\\nStability (Method)\\n100% Stable (No Pruning)\\n99.96% Stable (Prune_S 1%)\\n99.59% Stable (Prune_S 13%)\\n99.19% Stable (Prune_L 13%)\\n98.75 99.00 99.25 99.50 99.75 100.00\\nMean Stability (%)85.285.485.685.886.086.286.486.6Test Accuracy (%)\\npearsonr = -0.73; p = 4.4e-06\\nkendalltau = -0.55; p = 2.3e-05\\n50 100 150 200 250 300\\nEpoch84 8485 8586 8687 8788 88Test Accuracy (%)7%\\n9%\\nStability (Method)\\n100% Stable (No Pruning)\\n99.96% Stable (Prune_S 1%)\\n99.47% Stable (Prune_S 14%)\\n98.9% Stable (Prune_L 14%)\\n98.50 98.75 99.00 99.25 99.50 99.75 100.00\\nMean Stability (%)87.287.487.687.888.088.288.4Test Accuracy (%)\\npearsonr = -0.43; p = 0.015\\nkendalltau = -0.25; p = 0.048Figure 2: Less stable pruning leads to higher generalization in VGG11 (top) and ResNet18 (bottom) when\\ntraining on CIFAR-10 (10 runs per conﬁguration). (Left) Test accuracy during training of several models\\nillustrates how adaptation to less stable pruning leads to better generalization. (Right) Means reduce along the\\nepoch dimension (creating one point per run-conﬁguration combination).\\nnoise, which has a variance equal to the variance of the unperturbed parameters on each training\\nbatch and a larger variance on the ﬁrst batch of a new epoch. Please see Appendix D for more details.\\nComputing ﬂatness In Section 3.4, we use test data [ 12] to compute approximations to the traces\\nof the Hessian of the loss H(curvature) and the gradient covariance matrix C(noise).3Hindicates\\nthe gradient’s sensit', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1665: ('ght) Means reduce along the\\nepoch dimension (creating one point per run-conﬁguration combination).\\nnoise, which has a variance equal to the variance of the unperturbed parameters on each training\\nbatch and a larger variance on the ﬁrst batch of a new epoch. Please see Appendix D for more details.\\nComputing ﬂatness In Section 3.4, we use test data [ 12] to compute approximations to the traces\\nof the Hessian of the loss H(curvature) and the gradient covariance matrix C(noise).3Hindicates\\nthe gradient’s sensitivity to parameter changes at a point, while Cshows the sensitivity of the gradient\\nto changes in the sampled input (see Figure 6) [ 12]. The combination of these two matrices via the\\nTakeuchi information criterion (TIC) [ 50] is particularly predictive of generalization [ 12]. Thus, in\\naddition to looking at Hand/orCindividually, as has been done in [ 11,40], we also consider a rough\\nTIC proxy Tr(C)=Tr(H)inspired by [ 12]. Finally, similar to analyses in [ 3,11,40], we compute\\nthe size\"of the parameter perturbation (in the directions of the Hessian’s dominant eigenvectors)\\nthat can be withstood before the loss increases by 0.1.\\n3 Experiments\\n3.1 The generalization-stability tradeoff\\nCan improved generalization in pruned DNNs simply be explained by the reduced parameter count, or\\nrather, do the properties of the pruning algorithm play an important role in the resultant generalization?\\nAs removing parameters from a DNN via pruning may make the DNN less capable of ﬁtting to the\\nnoise in the training data [ 15,16,21], we might expect that the generalization improvements observed\\nin pruned DNNs are entirely explained by the number of parameters removed at each layer. In which\\ncase, methods that prune equal amounts of parameters per layer would generalize similarly.\\nAlternatively, the nature of the particular pruning algorithm might determine generalization im-\\nprovements. While all common pruning approaches seek to preserve important components of the\\nfunction computed by the overparameterized DNN, they do this wit', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1666: ('6,21], we might expect that the generalization improvements observed\\nin pruned DNNs are entirely explained by the number of parameters removed at each layer. In which\\ncase, methods that prune equal amounts of parameters per layer would generalize similarly.\\nAlternatively, the nature of the particular pruning algorithm might determine generalization im-\\nprovements. While all common pruning approaches seek to preserve important components of the\\nfunction computed by the overparameterized DNN, they do this with varying degrees of success,\\ncreating different levels of stability. More stable approaches include those that compute a very\\nclose approximation to the way the loss changes with respect to each parameter and prune a single\\nparameter at a time [ 16], while less stable approaches include those that assume parameter magnitude\\nand importance are roughly similar and prune many weights all at once [ 17]. Therefore, to the extent\\nthat differences in the noise injected by pruning explain differences in pruning-based generalization\\nimprovements, we might expect to observe a relationship between generalization and pruning stability.\\n3We use “ﬂatness” loosely when discussing the trace of the gradient covariance, which is large/“sharp” when\\nthe model’s gradient is very sensitive to changes in the data sample and small/“ﬂat” otherwise.\\n4\\n2 4 8 16 32 64\\nIterative Pruning Rate (% and Log Scale)7580859095100Mean Stability (%)\\n2 4 81699.099.5100.0\\n2 4 8 16 32 64\\nIterative Pruning Rate (% and Log Scale)85.485.685.886.086.2Test Accuracy (%)\\nPruning Style\\nPrune_S\\nPrune_R\\nPrune_L\\n2 4 8 16 32 64\\nIterative Pruning Rate (% and Log Scale)0.8\\n0.6\\n0.4\\n0.2\\n0.00.20.4Correlation between\\nGeneralization and StabilityFigure 3: Increasing the iterative pruning rate (and decreasing the number of pruning events to hold total pruning\\nconstant) leads to less stability (left), and can allow methods that target less important parameters to generalize\\nbetter (center). At a particular iterative rate, the Pearson correlation between generalization and', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1667: ('st Accuracy (%)\\nPruning Style\\nPrune_S\\nPrune_R\\nPrune_L\\n2 4 8 16 32 64\\nIterative Pruning Rate (% and Log Scale)0.8\\n0.6\\n0.4\\n0.2\\n0.00.20.4Correlation between\\nGeneralization and StabilityFigure 3: Increasing the iterative pruning rate (and decreasing the number of pruning events to hold total pruning\\nconstant) leads to less stability (left), and can allow methods that target less important parameters to generalize\\nbetter (center). At a particular iterative rate, the Pearson correlation between generalization and stability is\\nalways negative (right), a similar pattern holds with Kendall’s rank correlation. A baseline has 85.2% accuracy.\\nTo determine whether pruning algorithm stability affects generalization, we compared the stability\\nand ﬁnal test accuracy of several pruning algorithms with varying pruning targets and iterative pruning\\nrates (Figure 2). Consistent with the nature of the pruning algorithm playing a role in generalization,\\nwe observed that less stable pruning algorithms created higher ﬁnal test accuracies than those which\\nwere stable (Figure 2, right; VGG11: Pearson’s correlation r=\\x00:73, p-value = 4:4e\\x006; ResNet18:\\nr=\\x00:43, p-value =:015). While many pruning approaches have aimed to be as stable as possible,\\nthese results suggest that pruning techniques may actually facilitate better generalization when they\\ninduce lessstability. In other words there is a tradeoff between the stability during training and the\\nresultant generalization of the model. Furthermore, these results show that parameter-count- and\\narchitecture-based [ 21] arguments are not sufﬁcient to explain generalization levels in pruned DNNs,\\nas the precise pruning method plays a critical role in this process.\\nFigure 2 also demonstrates that pruning events for Prune Lwith a high iterative pruning rate (red\\ncurve, pruning as much as 14% of a given convolutional layer per pruning iteration) are substantially\\nmore destabilizing than other pruning events, but despite the dramatic pruning-induced drops in\\nperformance, the network recovers to higher', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1668: ('d\\narchitecture-based [ 21] arguments are not sufﬁcient to explain generalization levels in pruned DNNs,\\nas the precise pruning method plays a critical role in this process.\\nFigure 2 also demonstrates that pruning events for Prune Lwith a high iterative pruning rate (red\\ncurve, pruning as much as 14% of a given convolutional layer per pruning iteration) are substantially\\nmore destabilizing than other pruning events, but despite the dramatic pruning-induced drops in\\nperformance, the network recovers to higher performance within a few epochs. Several of these\\npruning events are highlighted with red arrows. Please see Appendix B for more details.\\nAppendix B also shows results with a novel scoring method that led to a wider range of stabilities and\\ngeneralization levels, which improved the correlations between generalization and stability in both\\nDNNs. Thus, the visibility of the generalization-stability tradeoff is affected by pruning algorithm\\nhyperparameter settings, accenting the beneﬁt of designing experiments to allow large pruning-based\\ngeneralization gains. In addition, these results suggest that the regularization levels associated with\\nvarious pruning hyperparameter choices may be predicted by their effects on stability during training.\\n3.2 Towards understanding the bounds of the generalization-stability tradeoff\\nIn Figure 2, decreasing pruning algorithm stability led to higher ﬁnal generalization. Will decreasing\\nstability always help generalization? Is the beneﬁt of instability present in smaller DNNs and when\\ntraining with SGD? Here, we address these and similar questions and ultimately ﬁnd that the tradeoff\\nhas predictable limits but is nonetheless present across a wide range of experimental hyperparameters.\\nImpact of iterative pruning rate on the generalization-stability tradeoff For a particular prun-\\ning target and total pruning percentage, pruning stability in VGG11 monotonically decreases as we\\nraise the iterative pruning rate up to the maximal, one-shot-pruning level (Figure 3 left). Thus, if\\nless ', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1669: ('d when\\ntraining with SGD? Here, we address these and similar questions and ultimately ﬁnd that the tradeoff\\nhas predictable limits but is nonetheless present across a wide range of experimental hyperparameters.\\nImpact of iterative pruning rate on the generalization-stability tradeoff For a particular prun-\\ning target and total pruning percentage, pruning stability in VGG11 monotonically decreases as we\\nraise the iterative pruning rate up to the maximal, one-shot-pruning level (Figure 3 left). Thus, if\\nless stability is always better, we would expect to see monotonically increasing generalization as we\\nraise iterative pruning rate. Alternatively, it’s possible that we will observe a generalization-stability\\ntradeoff over a particular range of iterative rates, but that there will be a point at which lowering\\nstability further will not be helpful to generalization. To test this, we compare iterative pruning rate\\nand test accuracy for each of three pruning targets (Figure 3 center).\\nFor pruning targets that are initially highly stable (Prune Sand Prune R), raising the iterative pruning\\nrate and decreasing stability produces higher generalization up until the one-shot pruning case\\n(Figure 3 center). When the pruning target lacks stability at the initial iterative rate (Prune L), further\\ndecreasing stability is harmful to generalization. These results suggest that the generalization stability\\ntradeoff is present across a wide range of iterative pruning rates, but, critically, that there are limits to\\nthe beneﬁts of further decreasing stability once it is already at a low level.\\n5\\nResNet20\\n75 80 85 90 95\\nMean Stability (%)91.091.291.491.6Test Accuracy (%)\\npearsonr = -0.51; p = 0.0037\\nkendalltau = -0.38; p = 0.0032 ResNet56\\n70 80 90 100\\nMean Stability (%)91.592.092.593.0Test Accuracy (%)\\npearsonr = -0.42; p = 0.03\\nkendalltau = -0.3; p = 0.026 ResNet18\\n94 96 98 100\\nMean Stability (%)94.194.294.394.494.594.694.7Test Accuracy (%)\\npearsonr = -0.46; p = 0.013\\nkendalltau = -0.37; p = 0.006\\n75 80 85 90 95\\nMean Stability (%)7.27', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1670: ('urther decreasing stability once it is already at a low level.\\n5\\nResNet20\\n75 80 85 90 95\\nMean Stability (%)91.091.291.491.6Test Accuracy (%)\\npearsonr = -0.51; p = 0.0037\\nkendalltau = -0.38; p = 0.0032 ResNet56\\n70 80 90 100\\nMean Stability (%)91.592.092.593.0Test Accuracy (%)\\npearsonr = -0.42; p = 0.03\\nkendalltau = -0.3; p = 0.026 ResNet18\\n94 96 98 100\\nMean Stability (%)94.194.294.394.494.594.694.7Test Accuracy (%)\\npearsonr = -0.46; p = 0.013\\nkendalltau = -0.37; p = 0.006\\n75 80 85 90 95\\nMean Stability (%)7.27.47.67.8Generalization Gap (%)\\n pearsonr = 0.69; p = 2.3e-05\\nkendalltau = 0.48; p = 0.00021\\n70 80 90 100\\nMean Stability (%)6.757.007.257.507.758.008.258.50Generalization Gap (%)\\npearsonr = 0.41; p = 0.036\\nkendalltau = 0.29; p = 0.036\\n94 96 98 100\\nMean Stability (%)5.35.45.55.65.75.85.9Generalization Gap (%)\\npearsonr = 0.47; p = 0.013\\nkendalltau = 0.38; p = 0.0046\\nFigure 4: Among pruned models, lower pruning stability is associated with higher generalization and lower\\ngeneralization gaps (overﬁtting) in ResNet18, ResNet20, and ResNet56 when training with weight decay and\\ndata augmentation. Blue and orange dots represent models pruned with 3% and 5% iterative rates, respectively.\\nInterestingly, we found that the generalization-stability tradeoff grew weaker as the iterative pruning\\nrate increased as well (Figure 3 right). Notably, however, the tradeoff was present for all iterative\\npruning rates studied (though at the highest iterative rates, the correlation is no longer signiﬁcant). This\\nresult suggests that not only does the generalization improvement decrease as stability decreases past\\nsome threshold, the strength of the tradeoff itself also decreases as stability decreases, highlighting\\nthat there is a “sweet spot” at which decreased stability is most helpful.\\nImpact of traditional training and pruning on the generalization-stability tradeoff Our exper-\\niments thus far (e.g. those shown in Figure 2) pruned only a subset of layers of large models trained\\nwith Adam, without weight decay or data augmentation. I', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1671: ('ot only does the generalization improvement decrease as stability decreases past\\nsome threshold, the strength of the tradeoff itself also decreases as stability decreases, highlighting\\nthat there is a “sweet spot” at which decreased stability is most helpful.\\nImpact of traditional training and pruning on the generalization-stability tradeoff Our exper-\\niments thus far (e.g. those shown in Figure 2) pruned only a subset of layers of large models trained\\nwith Adam, without weight decay or data augmentation. It’s possible that reductions in stability only\\nimprove generalization in such a regime. Alternatively, the tradeoff may be present when making\\nchanges to these factors.\\nWe investigate this important matter by evaluating the relationship between generalization and\\nstability in ResNet18, ResNet20, and ResNet56 when training using the hyperparameters described\\nin [42] (e.g., we employ SGD with weight decay and data augmentation). Further, we simplify our\\npruning approach by removing 10% of the ﬁlters of each convolutional layer of each block, scoring\\nﬁlters with their `1-norms. Parameters are removed either three times during training (epochs {41,\\n71, 101}) or twice during training (epochs {41, 101}), creating iterative rates of roughly 3% and 5%.\\nConsistent with the generalization-stability tradeoff explaining generalization levels across various\\ntraining and pruning scenarios, Figure 4 shows that reductions in stability improve both generalization\\nand the generalization gap in pruned models. In Appendix C.4, we build on these results and show a\\nstability regime where lower stability leads to generalization levels higher than the baseline model’s.\\nImpact of total pruning percentage on the generalization-stability tradeoff We raised the total\\npruning percentage in the Figure 2 ResNet18 experiments from 46% to 59% and found that the\\ngeneralization-stability tradeoff was still present. Interestingly, however, Prune Lseemingly induced\\ntoo much instability and ceased to outperform Prune Sat this higher total pruning p', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1672: ('e build on these results and show a\\nstability regime where lower stability leads to generalization levels higher than the baseline model’s.\\nImpact of total pruning percentage on the generalization-stability tradeoff We raised the total\\npruning percentage in the Figure 2 ResNet18 experiments from 46% to 59% and found that the\\ngeneralization-stability tradeoff was still present. Interestingly, however, Prune Lseemingly induced\\ntoo much instability and ceased to outperform Prune Sat this higher total pruning percentage, consis-\\ntent with prior work [ 18] which found that pruning large weights was harmful. Please see Appendix\\nC for these additional results and more details of the experiments in this section.\\nTaken together, these results demonstrate that while the generalization-stability tradeoff was present\\nacross a wide range of pruning hyperparameters, it consistently broke down once pruning stability\\ndropped below some threshold, at which point further reducing stability did not lead to generalization\\nimprovements. This failure mode highlights the need to frame the beneﬁts of lower stability as a part\\nof a tradeoff rather than a free lunch. Further, it is consistent with the comparison to noise-injection,\\nwherein the noise is moderate (e.g., increasing the dropout rate past 0.8 harms generalization) [ 31–37].\\n6\\n3.3 Iterative magnitude pruning as noise injection\\nWe have alluded to the idea that simple magnitude pruning performs a kind of noise injection, with\\nthe peculiarity that the noise is applied permanently or not at all. Removing the permanence of\\npruning by allowing weight reentry can mitigate the parameter reduction of pruning, making it more\\nsimilar to a traditional noise-injection regularizer, and allowing us to test whether the permanent\\nreduction in parameters caused by pruning is critical to its effect on generalization.\\nAs a baseline, we consider Prune Lapplied to VGG11, judging ﬁlter magnitude via the `2-norm. We\\nthen modify this algorithm to, rather than permanently prune ﬁlters, simply set the ﬁl', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1673: ('y or not at all. Removing the permanence of\\npruning by allowing weight reentry can mitigate the parameter reduction of pruning, making it more\\nsimilar to a traditional noise-injection regularizer, and allowing us to test whether the permanent\\nreduction in parameters caused by pruning is critical to its effect on generalization.\\nAs a baseline, we consider Prune Lapplied to VGG11, judging ﬁlter magnitude via the `2-norm. We\\nthen modify this algorithm to, rather than permanently prune ﬁlters, simply set the ﬁlter weights to\\nzero, then allow the zeroed weights to immediately resume training in the network (\"Zeroing 1\" in\\nFigure 5 top). However, by allowing pruned weights to immediately recover, Zeroing 1 differs from\\npruning noise, which causes the unpruned features to be trained in the absence of the pruned feature\\nmaps.\\n50 100 150 200 250 300\\nEpoch83848586Test Accuracy (%)Noise Type\\nNo Noise\\nPrune_L\\nZeroing 1\\nZeroing 50\\nZeroing 1105\\n50 100 150 200 250 300\\nEpoch83848586Test Accuracy (%)Noise Type\\nNo Noise\\nPrune_L\\nGaussian 1\\nGaussian 50\\nGaussian 1105\\nFigure 5: Generalization improvements from prun-\\ning bear resemblance to those obtained by using\\ntemporary multiplicative zeroing (top) and additive\\nGaussian noise (bottom), as long as the noise is\\napplied for enough batches/steps.To retain this potentially regularizing aspect of prun-\\ning noise, we held weights to zero for 50 and 1105\\nconsecutive batches, as well. As a related experi-\\nment, we measured the impact of adding Gaussian\\nnoise to the weights either once (Gaussian 1) or re-\\npeatedly over a series of training batches (Gaussian\\n50/1105 in Figure 5 bottom).\\nIf the capacity reduction associated with having\\nfewer parameters is not necessary to explain prun-\\ning’s effect on generalization, then we would ex-\\npect that the generalization behavior of temporary\\npruning noise injection algorithms could mimic the\\ngeneralization behavior of Prune L. Alternatively, if\\nhaving fewer weights is a necessary component of\\npruning-based generalization improvements, then\\nwe would n', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1674: ('ussian 1) or re-\\npeatedly over a series of training batches (Gaussian\\n50/1105 in Figure 5 bottom).\\nIf the capacity reduction associated with having\\nfewer parameters is not necessary to explain prun-\\ning’s effect on generalization, then we would ex-\\npect that the generalization behavior of temporary\\npruning noise injection algorithms could mimic the\\ngeneralization behavior of Prune L. Alternatively, if\\nhaving fewer weights is a necessary component of\\npruning-based generalization improvements, then\\nwe would not expect close similarities between the\\ngeneralization phenomena of Prune Land temporary\\npruning noise injection.\\nConsistent with the idea that the noise injected by\\npruning leads to the generalization beneﬁts observed\\nin pruned DNNs, applying zeroing noise for 50\\nbatches to ﬁlters (rather than pruning them com-\\npletely) generates strikingly similar ﬁnal general-\\nization performance to Prune L(Figure 5 top). In\\nfact, throughout training, both methods have similar\\nlevels of instability and test accuracy. This result\\nsuggests that pruning-based generalization improvements in overparameterized DNNs do not require\\nthe model’s parameter count to be reduced.\\nFinally, we evaluated the impact of adding Gaussian noise to parameters at various points throughout\\ntraining. Consistent with the generalization-stability tradeoff, we found that when Gaussian noise\\nwas added for a long enough duration (Gaussian 1105; purple line in Figure 5 bottom), performance\\nincreased substantially. This result demonstrates that the generalization-stability tradeoff is not\\nspeciﬁc to pruning, and that noise injected by pruning is simply a special case of noise more broadly.\\nAdditional results and experimental details are in Appendix D. For example, an alternative version of\\nthis analysis zeros weights for N batches, then allows them back in at their pre-zeroing values. This\\nmethod creates instability similar to regular pruning’s, and produces a similar generalization beneﬁt.\\nAlso, we provide a visualization of the weight noising methods tha', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1675: ('alization-stability tradeoff is not\\nspeciﬁc to pruning, and that noise injected by pruning is simply a special case of noise more broadly.\\nAdditional results and experimental details are in Appendix D. For example, an alternative version of\\nthis analysis zeros weights for N batches, then allows them back in at their pre-zeroing values. This\\nmethod creates instability similar to regular pruning’s, and produces a similar generalization beneﬁt.\\nAlso, we provide a visualization of the weight noising methods that we use here.\\n3.4 Flatness: a mechanism for pruning-based generalization improvements?\\nOur results thus far suggest that noise injection is the mechanism through which pruning improves\\ngeneralization. Can the noise pruning adds to representations translate to ﬂatness in the ﬁnal model\\nthat improves generalization? Here, we address this question.\\n7\\n98.75 99.00 99.25 99.50 99.75 100.00\\nMean Stability (%)250300350400450500Curvature,\\nSensitivity of Lw to w\\nFlatterSharper\\npearsonr = 0.55; p = 7.3e-06\\nkendalltau = 0.53; p = 1.1e-08\\n250 300 350 400 450 500\\nCurvature,\\n Sensitivity of Lw to w\\n85.0085.2585.5085.7586.0086.2586.50Test Accuracy (%)\\nFlatter Sharperpearsonr = -0.59; p = 7.3e-07\\nkendalltau = -0.46; p = 2.7e-07\\n98.75 99.00 99.25 99.50 99.75 100.00\\nMean Stability (%)2000300040005000Noise,\\nSensitivity of Lw to Sample\\nFlatterSharper\\npearsonr = 0.57; p = 2.8e-06\\nkendalltau = 0.59; p = 1.4e-10\\n2000 3000 4000 5000\\nNoise,\\n Sensitivity of Lw to Sample\\n85.0085.2585.5085.7586.0086.2586.50Test Accuracy (%)\\nFlatter Sharperpearsonr = -0.71; p = 2.2e-10\\nkendalltau = -0.56; p = 3.7e-10\\n300 400 500\\nhessian_first_100_eigen_sum85.085.586.086.5Best Test Accuracy in Run\\n100% Stable (No Pruning) 100% Stable (Scratch Pruning) 99.96% Stable (Prune_S 1%) 99.59% Stable (Prune_S 13%) 99.68% Stable (Prune_R 13%) 99.19% Stable (Prune_L 13%)Figure 6: Less pruning stability improves measures of model robustness to noise in the parameters and change in\\nthe inputs. These two types of model “ﬂatness” are in turn correlated with generalization', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1676: ('perpearsonr = -0.71; p = 2.2e-10\\nkendalltau = -0.56; p = 3.7e-10\\n300 400 500\\nhessian_first_100_eigen_sum85.085.586.086.5Best Test Accuracy in Run\\n100% Stable (No Pruning) 100% Stable (Scratch Pruning) 99.96% Stable (Prune_S 1%) 99.59% Stable (Prune_S 13%) 99.68% Stable (Prune_R 13%) 99.19% Stable (Prune_L 13%)Figure 6: Less pruning stability improves measures of model robustness to noise in the parameters and change in\\nthe inputs. These two types of model “ﬂatness” are in turn correlated with generalization. “Scratch” pruning\\n[18, 21] trains the pruned architecture from the outset and is thus 100% stable.\\nGiven the many successful versions of noise injection [ 31–37], and pruning’s relationship to dropout\\n[51,52], we hypothesize that pruning noise can produce ﬂatness in the resulting model that’s helpful\\nto generalization. Speciﬁcally, we expect that less stable pruning, which introduces more signiﬁcant\\nnoise by deﬁnition, will translate to heightened model robustness to changes in data sample and\\nparameters (ﬂatness). Furthermore, we expect that the heightened ﬂatness will translate to higher\\ngeneralization, consistent with empirical evidence and theory suggesting that ﬂatness is helpful to\\ngeneralization in overparameterized DNNs [3, 4, 11, 12, 38–40, 53].\\nAlternatively, it’s possible that the observed relationship between pruning stability and generalization\\nis merely correlation, that pruning noise helps in a way unrelated to ﬂatness, or that ﬂatness differences\\ndon’t explain the generalization beneﬁts created by pruning. If we observed a positive or no correlation\\nbetween stability and ﬂatness, or a negative correlation between ﬂatness and generalization, then our\\nexperiments would support one of these alternative hypotheses.\\nTo test these hypotheses, we compute several measures of ﬂatness, and examine their relationships to\\npruning stability and ﬁnal generalization in VGG11. We ﬁnd that there is also a tradeoff between\\nﬂatness and stability, as decreasing stability led to ﬂatter minima for all ﬂatness measu', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1677: ('ted by pruning. If we observed a positive or no correlation\\nbetween stability and ﬂatness, or a negative correlation between ﬂatness and generalization, then our\\nexperiments would support one of these alternative hypotheses.\\nTo test these hypotheses, we compute several measures of ﬂatness, and examine their relationships to\\npruning stability and ﬁnal generalization in VGG11. We ﬁnd that there is also a tradeoff between\\nﬂatness and stability, as decreasing stability led to ﬂatter minima for all ﬂatness measures (Figure 6\\nand Appendix E). Furthermore, increased ﬂatness statistically signiﬁcantly improved generalization.\\nThus, we ﬁnd evidence supporting the hypothesis that less pruning stability leads to greater ﬂatness\\nof a kind that is helpful to generalization.\\nThis result also suggests that the generalization-stability tradeoff we observe may be mediated\\nby increases to the ﬂatness of the converged solution. Speciﬁcally, after DNNs recover from the\\ncorruption of representations issued by pruning, they not only generalize better but also are less\\nsensitive to data sample and parameter changes. Supporting treatment of pruning as noise injection,\\nthis ﬂattening effect is enhanced by representation corruption that is more salient (less stable pruning).\\nMore broadly, these ﬁndings add to the recent empirical evidence showing that ﬂatness can explain\\ngeneralization levels in DNNs when parameter counts cannot [ 3,40]. We also corroborate the\\nrecent observation that there is utility in moving beyond parameter ﬂatness and also looking at the\\ngradient covariance to understand generalization performance [ 11,12]. Finally, these ﬁndings resolve\\nthe contradiction between the observation that pruning improves generalization and the emerging\\ngeneralization theory that de-emphasizes or removes the role of parameter counts [ 1,6,54]. Appendix\\nE contains all of our ﬂatness results and details on our measurements of ﬂatness.\\n8\\n4 Related work\\nMany pruning studies have shown that the pruned DNN has heightened generalization [ 17,22–', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1678: ('and also looking at the\\ngradient covariance to understand generalization performance [ 11,12]. Finally, these ﬁndings resolve\\nthe contradiction between the observation that pruning improves generalization and the emerging\\ngeneralization theory that de-emphasizes or removes the role of parameter counts [ 1,6,54]. Appendix\\nE contains all of our ﬂatness results and details on our measurements of ﬂatness.\\n8\\n4 Related work\\nMany pruning studies have shown that the pruned DNN has heightened generalization [ 17,22–30],\\nand this is consistent with the fact that pruning may be framed as a regularization (rather than\\ncompression) approach. For example, variational Bayesian approaches to pruning via sparsity-\\ninducing priors [ 20,26] frame weight removal as a means to reduce model description length, which\\nmay improve the likelihood of the model obtaining good generalization [ 55]. However, the relevance\\nof the Bayesian/MDL explanation to the regularization done by variational pruning strategies depends\\non the choice of prior [ 56]. More importantly, non-Bayesian pruning can improve generalization and\\neven outperform variational approaches [ 57], showing that pruning regularizes in non-Bayesian ways.\\nPruning to improve generalization has also been inspired by analyses of VC dimension, a measure of\\nmodel capacity [ 15,16]. Overﬁtting can be bounded above by an increasing function of VC dimension,\\nwhich itself often increases with parameter counts, so fewer parameters can lead to a guarantee of less\\noverﬁtting [ 58]. While generalization in some learning environments can be eloquently explained\\nby parameter-count-based bounds, such bounds can be so loose in practice that tightening them by\\nreducing parameter counts does not imply better generalization [ 39]. In fact, generalization in deep\\nneural networks tends to improve as model size increases [ 1,2,6,7,10], suggesting that model-size\\nreduction inadequately describes pruning’s DNN regularization mechanism (see Appendix F).\\nMore recent generalization bounds consider how the D', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1679: ('eneralization in some learning environments can be eloquently explained\\nby parameter-count-based bounds, such bounds can be so loose in practice that tightening them by\\nreducing parameter counts does not imply better generalization [ 39]. In fact, generalization in deep\\nneural networks tends to improve as model size increases [ 1,2,6,7,10], suggesting that model-size\\nreduction inadequately describes pruning’s DNN regularization mechanism (see Appendix F).\\nMore recent generalization bounds consider how the DNN responds to parameter noise [ 4,9,38,39],\\nwhich (along with the gradient covariance) is predictive of generalization in practice [ 11,12]. Our\\nresults provide empirical support for such theory, as we ﬁnd that iterative DNN pruning may improve\\nboth generalization and ﬂatness by creating various noisy versions of the internal representation of\\nthe data, which unpruned parameters try to ﬁt to, as in noise-injection regularization [33–36].\\nFlatness and neural network pruning were previously linked by an algorithm that removed weights\\nwhen doing so led to a ﬂatter loss surface [ 59]. We show that a ﬂat-minimum-search algorithm is not\\nrequired to ﬂatten models via pruning: simple magnitude pruning injects noise that ﬂattens DNNs.\\nDropout creates particularly similar noise to pruning, as it temporarily sets random subsets of layer\\noutputs to zero (likely changing an input’s internal representation every epoch). Indeed, applying\\ndropout-like zeroing noise to a subset of features during training can encourage robustness to a post-\\nhoc pruning of that subset [ 51,52]. The iterative DNN pruning noise analyzed in our experiments\\ndiffers, however, as it is: applied less frequently, permanent, not random, and less well studied.\\nWhen pruning noise is strong enough to alter DNN predictions, accuracy will likely move closer\\nto chance-level, in which case we say the pruning stability (deﬁned in Figure 1) falls. The pruning\\nliterature has other measures of pruning’s impact on the network, including how much pruning\\naffects the', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1680: ('tness to a post-\\nhoc pruning of that subset [ 51,52]. The iterative DNN pruning noise analyzed in our experiments\\ndiffers, however, as it is: applied less frequently, permanent, not random, and less well studied.\\nWhen pruning noise is strong enough to alter DNN predictions, accuracy will likely move closer\\nto chance-level, in which case we say the pruning stability (deﬁned in Figure 1) falls. The pruning\\nliterature has other measures of pruning’s impact on the network, including how much pruning\\naffects the values of the weights in the resulting subnetwork (the unpruned weights) via the Euclidean\\ndistance between two subnetwork copies trained with and without the removal of the weights targeted\\nby pruning [ 60]. Our stability measure characterizes an immediate change in accuracy caused by\\npruning, allowing us to study how noise injection relates to pruning’s effect on generalization.\\nPermanent removal of parameters is not required to obtain generalization beneﬁts of pruning with\\nDSD (dense-sparse-dense training), retraining a model after pruning then returning the pruned weights\\nto the model for a ﬁnal training phase [ 49]. Relative to DSD, we demonstrate the effects of multiple\\ndifferent pruning schemes and argue that a scheme with less stability produces better generalization.\\n5 Discussion\\nWe demonstrated the presence of a generalization-stability tradeoff in neural network pruning that\\nstems from the generalization beneﬁts of pruning less stably, which heightens ﬂatness by intensifying\\na noise-injection-like effect that does not require permanent parameter removal to be effective.\\nThus, our results show how pruning-based generalization improvements can be consistent with\\ngeneralization bounds that do not depend on parameter counts [ 6,54], and they provide empirical\\nsupport for generalization theory based on ﬂatness/noise-robustness [4, 38, 39].\\nOur results suggest that the generalization-stability tradeoff is a useful framework for analyzing the\\neffect of pruning hyperparameters on pruned-model generalization', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1681: (' effect that does not require permanent parameter removal to be effective.\\nThus, our results show how pruning-based generalization improvements can be consistent with\\ngeneralization bounds that do not depend on parameter counts [ 6,54], and they provide empirical\\nsupport for generalization theory based on ﬂatness/noise-robustness [4, 38, 39].\\nOur results suggest that the generalization-stability tradeoff is a useful framework for analyzing the\\neffect of pruning hyperparameters on pruned-model generalization. For example, the fact that iterative\\npruning outperforms one-shot pruning [ 17] can be seen through this framework as an observation\\nabout repeated noise injections being preferable to one (perhaps unhelpfully large) injection of noise.\\n9\\nBroader Impact\\nThis work focuses on resolving an apparent contradiction in the scientiﬁc understanding of the\\nrelationship between pruning and generalization performance. As such, we believe its primary\\nimpact will be on other researchers and it is unlikely to have substantial broader impacts. That said,\\nunderstanding the mechanisms underlying our models is important for the safe deployment of such\\nmodels in application domains. Our work takes a step in that direction, and we hope may help pave\\nthe way for further understanding.\\nAcknowledgments and Disclosure of Funding\\nWe thank Juan Guillermo Llanos, Margaret Scheiner, Valentin Thomas, Jacob Pettit, and our reviewers\\nfor helpful conversations and feedback. We have no funding or competing interests to disclose.\\nReferences\\n[1]Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. In search of the real inductive bias:\\nOn the role of implicit regularization in deep learning. arXiv preprint arXiv:1412.6614 , 2014.\\n[2]Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding\\ndeep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530 , 2016.\\n[3]Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping\\nTak Peter Tang. On large-batch training for deep', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1682: ('[1]Behnam Neyshabur, Ryota Tomioka, and Nathan Srebro. In search of the real inductive bias:\\nOn the role of implicit regularization in deep learning. arXiv preprint arXiv:1412.6614 , 2014.\\n[2]Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding\\ndeep learning requires rethinking generalization. arXiv preprint arXiv:1611.03530 , 2016.\\n[3]Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping\\nTak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima.\\narXiv preprint arXiv:1609.04836 , 2016.\\n[4]Sanjeev Arora, Rong Ge, Behnam Neyshabur, and Yi Zhang. Stronger generalization bounds\\nfor deep nets via a compression approach. arXiv preprint arXiv:1802.05296 , 2018.\\n[5]Ari Morcos, David GT Barrett, Neil C Rabinowitz, and Matthew Botvinick. On the importance\\nof single directions for generalization. In Proceeding of the International Conference on\\nLearning Representations , 2018.\\n[6]Behnam Neyshabur, Zhiyuan Li, Srinadh Bhojanapalli, Yann LeCun, and Nathan Srebro.\\nTowards understanding the role of over-parametrization in generalization of neural networks.\\narXiv preprint arXiv:1805.12076 , 2018.\\n[7]Mikhail Belkin, Daniel Hsu, Siyuan Ma, and Soumik Mandal. Reconciling modern machine\\nlearning and the bias-variance trade-off. arXiv preprint arXiv:1812.11118 , 2018.\\n[8]Vaishnavh Nagarajan and J Zico Kolter. Generalization in deep networks: The role of distance\\nfrom initialization. arXiv preprint arXiv:1901.01672 , 2019.\\n[9]Vaishnavh Nagarajan and J Zico Kolter. Deterministic pac-bayesian generalization bounds for\\ndeep networks via generalizing noise-resilience. arXiv preprint arXiv:1905.13344 , 2019.\\n[10] Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya\\nSutskever. Deep double descent: Where bigger models and more data hurt. arXiv preprint\\narXiv:1912.02292 , 2019.\\n[11] Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, and Samy Bengio. Fantastic\\ngeneralization measures and where to ', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1683: (']Vaishnavh Nagarajan and J Zico Kolter. Deterministic pac-bayesian generalization bounds for\\ndeep networks via generalizing noise-resilience. arXiv preprint arXiv:1905.13344 , 2019.\\n[10] Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya\\nSutskever. Deep double descent: Where bigger models and more data hurt. arXiv preprint\\narXiv:1912.02292 , 2019.\\n[11] Yiding Jiang, Behnam Neyshabur, Hossein Mobahi, Dilip Krishnan, and Samy Bengio. Fantastic\\ngeneralization measures and where to ﬁnd them. arXiv preprint arXiv:1912.02178 , 2019.\\n[12] Valentin Thomas, Fabian Pedregosa, Bart van Merriënboer, Pierre-Antoine Mangazol, Yoshua\\nBengio, and Nicolas Le Roux. On the interplay between noise and curvature and its effect on\\noptimization and generalization, 2019.\\n[13] Zeyuan Allen-Zhu, Yuanzhi Li, and Yingyu Liang. Learning and generalization in overparame-\\nterized neural networks, going beyond two layers. In Advances in neural information processing\\nsystems , pages 6155–6166, 2019.\\n10\\n[14] Song Han, Huizi Mao, and William J Dally. Deep compression: Compressing deep neural net-\\nworks with pruning, trained quantization and huffman coding. arXiv preprint arXiv:1510.00149 ,\\n2015.\\n[15] Yann LeCun, John S Denker, and Sara A Solla. Optimal brain damage. In Advances in neural\\ninformation processing systems , pages 598–605, 1990.\\n[16] Babak Hassibi and David G Stork. Second order derivatives for network pruning: Optimal brain\\nsurgeon. In Advances in neural information processing systems , pages 164–171, 1993.\\n[17] Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections\\nfor efﬁcient neural network. In Advances in neural information processing systems , pages\\n1135–1143, 2015.\\n[18] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning ﬁlters for\\nefﬁcient convnets. arXiv preprint arXiv:1608.08710 , 2016.\\n[19] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural\\nnetworks. In International Conference on Computer Vision (I', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1684: ('93.\\n[17] Song Han, Jeff Pool, John Tran, and William Dally. Learning both weights and connections\\nfor efﬁcient neural network. In Advances in neural information processing systems , pages\\n1135–1143, 2015.\\n[18] Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning ﬁlters for\\nefﬁcient convnets. arXiv preprint arXiv:1608.08710 , 2016.\\n[19] Yihui He, Xiangyu Zhang, and Jian Sun. Channel pruning for accelerating very deep neural\\nnetworks. In International Conference on Computer Vision (ICCV) , volume 2, 2017.\\n[20] Christos Louizos, Karen Ullrich, and Max Welling. Bayesian compression for deep learning. In\\nAdvances in Neural Information Processing Systems , pages 3290–3300, 2017.\\n[21] Zhuang Liu, Mingjie Sun, Tinghui Zhou, Gao Huang, and Trevor Darrell. Rethinking the value\\nof network pruning. arXiv preprint arXiv:1810.05270 , 2018.\\n[22] Wei Wen, Chunpeng Wu, Yandan Wang, Yiran Chen, and Hai Li. Learning structured sparsity in\\ndeep neural networks. In Advances in Neural Information Processing Systems , pages 2074–2082,\\n2016.\\n[23] Sharan Narang, Gregory Diamos, Shubho Sengupta, and Erich Elsen. Exploring sparsity in\\nrecurrent neural networks. arXiv preprint arXiv:1704.05119 , 2017.\\n[24] Zhuang Liu, Jianguo Li, Zhiqiang Shen, Gao Huang, Shoumeng Yan, and Changshui Zhang.\\nLearning efﬁcient convolutional networks through network slimming. In Computer Vision\\n(ICCV), 2017 IEEE International Conference on , pages 2755–2763. IEEE, 2017.\\n[25] Christos Louizos, Max Welling, and Diederik P Kingma. Learning sparse neural networks\\nthroughl_0regularization. arXiv preprint arXiv:1712.01312 , 2017.\\n[26] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsiﬁes deep\\nneural networks. arXiv preprint arXiv:1701.05369 , 2017.\\n[27] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable\\nneural networks. arXiv preprint arXiv:1803.03635 , 2018.\\n[28] Bin Dai, Chen Zhu, and David Wipf. Compressing neural networks using the variational\\ninformation bottleneck', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1685: ('ing sparse neural networks\\nthroughl_0regularization. arXiv preprint arXiv:1712.01312 , 2017.\\n[26] Dmitry Molchanov, Arsenii Ashukha, and Dmitry Vetrov. Variational dropout sparsiﬁes deep\\nneural networks. arXiv preprint arXiv:1701.05369 , 2017.\\n[27] Jonathan Frankle and Michael Carbin. The lottery ticket hypothesis: Finding sparse, trainable\\nneural networks. arXiv preprint arXiv:1803.03635 , 2018.\\n[28] Bin Dai, Chen Zhu, and David Wipf. Compressing neural networks using the variational\\ninformation bottleneck. arXiv preprint arXiv:1802.10399 , 2018.\\n[29] Jianbo Ye, Xin Lu, Zhe Lin, and James Z Wang. Rethinking the smaller-norm-less-informative\\nassumption in channel pruning of convolution layers. arXiv preprint arXiv:1802.00124 , 2018.\\n[30] Zhonghui You, Jinmian Yan, Kun; Ye, Meng Ma, and Ping Wang. Gate decorator: Global ﬁlter\\npruning method for accelerating deep convolutional neural networks. In Advances in Neural\\nInformation Processing Systems , 2019.\\n[31] Geoffrey E Hinton and Drew Van Camp. Keeping the neural networks simple by minimizing\\nthe description length of the weights. In Proceedings of the sixth annual conference on\\nComputational learning theory , pages 5–13. ACM, 1993.\\n[32] Yulei Jiang, Richard M Zur, Lorenzo L Pesce, and Karen Drukker. A study of the effect of noise\\ninjection on the training of artiﬁcial neural networks. In 2009 International Joint Conference on\\nNeural Networks , pages 1428–1432. IEEE, 2009.\\n11\\n[33] Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhut-\\ndinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv\\npreprint arXiv:1207.0580 , 2012.\\n[34] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus. Regularization of\\nneural networks using dropconnect. In International Conference on Machine Learning , pages\\n1058–1066, 2013.\\n[35] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\\nDropout: A simple way to prevent neural networks from overﬁtting. The Journal of M', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1686: (' Salakhut-\\ndinov. Improving neural networks by preventing co-adaptation of feature detectors. arXiv\\npreprint arXiv:1207.0580 , 2012.\\n[34] Li Wan, Matthew Zeiler, Sixin Zhang, Yann Le Cun, and Rob Fergus. Regularization of\\nneural networks using dropconnect. In International Conference on Machine Learning , pages\\n1058–1066, 2013.\\n[35] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov.\\nDropout: A simple way to prevent neural networks from overﬁtting. The Journal of Machine\\nLearning Research , 15(1):1929–1958, 2014.\\n[36] Ben Poole, Jascha Sohl-Dickstein, and Surya Ganguli. Analyzing noise in autoencoders and\\ndeep networks. arXiv preprint arXiv:1406.1831 , 2014.\\n[37] Arvind Neelakantan, Luke Vilnis, Quoc V Le, Ilya Sutskever, Lukasz Kaiser, Karol Kurach,\\nand James Martens. Adding gradient noise improves learning for very deep networks. arXiv\\npreprint arXiv:1511.06807 , 2015.\\n[38] Behnam Neyshabur, Srinadh Bhojanapalli, David McAllester, and Nati Srebro. Exploring\\ngeneralization in deep learning. In Advances in Neural Information Processing Systems , pages\\n5949–5958, 2017.\\n[39] Gintare Karolina Dziugaite and Daniel M Roy. Computing nonvacuous generalization bounds\\nfor deep (stochastic) neural networks with many more parameters than training data. arXiv\\npreprint arXiv:1703.11008 , 2017.\\n[40] Zhewei Yao, Amir Gholami, Qi Lei, Kurt Keutzer, and Michael W Mahoney. Hessian-based\\nanalysis of large batch training and robustness to adversaries. In Advances in Neural Information\\nProcessing Systems , pages 4949–4959, 2018.\\n[41] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale\\nimage recognition. arXiv preprint arXiv:1409.1556 , 2014.\\n[42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image\\nrecognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,\\npages 770–778, 2016.\\n[43] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\\narXiv:1412.6980 ', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1687: ('cessing Systems , pages 4949–4959, 2018.\\n[41] Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale\\nimage recognition. arXiv preprint arXiv:1409.1556 , 2014.\\n[42] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image\\nrecognition. In Proceedings of the IEEE conference on computer vision and pattern recognition ,\\npages 770–778, 2016.\\n[43] Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint\\narXiv:1412.6980 , 2014.\\n[44] Michael Zhu and Suyog Gupta. To prune, or not to prune: exploring the efﬁcacy of pruning for\\nmodel compression. arXiv preprint arXiv:1710.01878 , 2017.\\n[45] Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced\\nresearch). URL http://www.cs.toronto.edu/~kriz/cifar.html .\\n[46] Andreas S Weigend, David E Rumelhart, and Bernardo A Huberman. Generalization by weight-\\nelimination with application to forecasting. In Advances in neural information processing\\nsystems , pages 875–882, 1991.\\n[47] Brian Bartoldson, Adrian Barbu, and Gordon Erlebacher. Enhancing the regularization effect of\\nweight pruning in artiﬁcial neural networks. arXiv preprint arXiv:1805.01930 , 2018.\\n[48] Adam Polyak and Lior Wolf. Channel-level acceleration of deep face representations. IEEE\\nAccess , 3:2163–2175, 2015.\\n[49] Song Han, Jeff Pool, Sharan Narang, Huizi Mao, Enhao Gong, Shijian Tang, Erich Elsen, Peter\\nVajda, Manohar Paluri, John Tran, et al. Dsd: Dense-sparse-dense training for deep neural\\nnetworks. arXiv preprint arXiv:1607.04381 , 2016.\\n[50] Kei Takeuchi. The distribution of information statistics and the criterion of goodness of ﬁt of\\nmodels. Mathematical Science , 153:12–18, 1976.\\n12\\n[51] Guillaume Leclerc, Manasi Vartak, Raul Castro Fernandez, Tim Kraska, and Samuel Madden.\\nSmallify: Learning network size while training. arXiv preprint arXiv:1806.03723 , 2018.\\n[52] Aidan N Gomez, Ivan Zhang, Kevin Swersky, Yarin Gal, and Geoffrey E Hinton. Targeted\\ndropout. 2018.\\n[53] Pratik Chaudh', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1688: ('eural\\nnetworks. arXiv preprint arXiv:1607.04381 , 2016.\\n[50] Kei Takeuchi. The distribution of information statistics and the criterion of goodness of ﬁt of\\nmodels. Mathematical Science , 153:12–18, 1976.\\n12\\n[51] Guillaume Leclerc, Manasi Vartak, Raul Castro Fernandez, Tim Kraska, and Samuel Madden.\\nSmallify: Learning network size while training. arXiv preprint arXiv:1806.03723 , 2018.\\n[52] Aidan N Gomez, Ivan Zhang, Kevin Swersky, Yarin Gal, and Geoffrey E Hinton. Targeted\\ndropout. 2018.\\n[53] Pratik Chaudhari, Anna Choromanska, Stefano Soatto, Yann LeCun, Carlo Baldassi, Christian\\nBorgs, Jennifer Chayes, Levent Sagun, and Riccardo Zecchina. Entropy-sgd: Biasing gradient\\ndescent into wide valleys. arXiv preprint arXiv:1611.01838 , 2016.\\n[54] Noah Golowich, Alexander Rakhlin, and Ohad Shamir. Size-independent sample complexity of\\nneural networks. arXiv preprint arXiv:1712.06541 , 2017.\\n[55] Jorma Rissanen. Modeling by shortest data description. Automatica , 14(5):465–471, 1978.\\n[56] Jiri Hron, Alexander G de G Matthews, and Zoubin Ghahramani. Variational gaussian dropout\\nis not bayesian. arXiv preprint arXiv:1711.02989 , 2017.\\n[57] Trevor Gale, Erich Elsen, and Sara Hooker. The state of sparsity in deep neural networks. CoRR ,\\nabs/1902.09574, 2019. URL http://arxiv.org/abs/1902.09574 .\\n[58] Shai Shalev-Shwartz and Shai Ben-David. Understanding machine learning: From theory to\\nalgorithms . Cambridge university press, 2014.\\n[59] Sepp Hochreiter and Jürgen Schmidhuber. Flat minima. Neural Computation , 9(1):1–42, 1997.\\n[60] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. The lottery\\nticket hypothesis at scale. arXiv preprint arXiv:1903.01611 , 2019.\\n[61] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,\\nZeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in\\npytorch. 2017.\\n[62] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.\\nTechnical report, Citeseer, 2009.\\n[63] Shuzhi Yu an', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1689: ('997.\\n[60] Jonathan Frankle, Gintare Karolina Dziugaite, Daniel M Roy, and Michael Carbin. The lottery\\nticket hypothesis at scale. arXiv preprint arXiv:1903.01611 , 2019.\\n[61] Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito,\\nZeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in\\npytorch. 2017.\\n[62] Alex Krizhevsky and Geoffrey Hinton. Learning multiple layers of features from tiny images.\\nTechnical report, Citeseer, 2009.\\n[63] Shuzhi Yu and Carlo Tomasi. Identity connections in residual nets improve noise stability. arXiv\\npreprint arXiv:1905.10944 , 2019.\\n[64] Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training\\nby reducing internal covariate shift. arXiv preprint arXiv:1502.03167 , 2015.\\n[65] Noah Golmant, Zhewei Yao, Amir Gholami, Michael Mahoney, and Joseph Gonzalez. pytorch-\\nhessian-eigentings: efﬁcient pytorch hessian eigendecomposition, October 2018. URL https:\\n//github.com/noahgolmant/pytorch-hessian-eigenthings .\\n13', 'The Generalization-Stability Tradeoff In Neural Network Pruning.pdf'), 1690: ('IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY SECTION\\nReceived 8 October 2023, accepted 4 December 2023, date of publication 12 December 2023,\\ndate of current version 21 December 2023.\\nDigital Object Identifier 10.1 109/ACCESS.2023.3341419\\nEEG Signal Processing for Medical Diagnosis,\\nHealthcare, and Monitoring: A Comprehensive\\nReview\\nNISREEN SAID AMER\\n , (Member, IEEE),\\nAND SAMIR BRAHIM BELHAOUARI\\n , (Senior Member, IEEE)\\nCollege of Science and Engineering, Hamad Bin Khalifa University, Qatar Foundation, Doha, Qatar\\nCorresponding author: Nisreen Said Amer (niam27832@hbku.edu.qa)\\nThis work was supported by the Open Access funding provided by the Qatar National Library.\\nABSTRACT EEG is a common and safe test that uses small electrodes to record electrical signals from\\nthe brain. It has a broad range of applications in medical diagnosis, including diagnosis of epileptic seizure,\\nAlzheimer’s, brain tumors, head injury, sleep disorders, stroke, and other seizure and neurological disorders.\\nEEG can also be used to help diagnose death in people who are in a persistent coma. The use of digital signal\\nprocessing and machine learning to improve EEG analysis for medical diagnosis has gained traction in recent\\nyears. This is because EEG visual analysis can be complex and time-consuming, as it mostly involves high\\ndimensions and consists of large datasets. The development of novel sensors for EEG recording, digital\\nsignal processing algorithms, feature engineering, and detection algorithms increases the need for efficient\\ndiagnostic systems. An extensive review of the recent approaches for EEG preprocessing, extraction of\\nfeatures, and diagnosis of brain disorders is provided. In this paper, the main focus is to identify reliable\\nalgorithms for preprocessing, feature engineering, and classification of EEG, applied to medical healthcare\\nand diagnosis, providing practitioners with insights into the most effective strategies, as well as potential\\nfuture directions for improving accuracy of the automatic diagnostic systems. Th', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1691: ('t\\ndiagnostic systems. An extensive review of the recent approaches for EEG preprocessing, extraction of\\nfeatures, and diagnosis of brain disorders is provided. In this paper, the main focus is to identify reliable\\nalgorithms for preprocessing, feature engineering, and classification of EEG, applied to medical healthcare\\nand diagnosis, providing practitioners with insights into the most effective strategies, as well as potential\\nfuture directions for improving accuracy of the automatic diagnostic systems. The study of reliable feature\\nextraction and classification algorithms is crucial for a more accurate analysis of EEG signals. This paper\\ncan provide valuable information to researchers and practitioners working in the fields of EEG analysis\\nand machine learning, as it provides a summary of recent developments and highlights key areas for future\\nresearch. This paper can help researchers and clinicians to stay up-to-date on the latest developments in this\\nfield.\\nINDEX TERMS Classification, electroencephalogram (EEG), feature extraction, machine learning,\\npreprocessing.\\nI. INTRODUCTION\\nAccording to the World Health Organization (WHO), of the\\none billion people affected by neurological disorders world-\\nwide, 50 million are affected by epilepsy and 24 million by\\nother brain diseases and dementias [1]. These Neurological\\nand brain disorders can affect individuals of all ages, genders,\\neducational backgrounds, and income levels regardless of\\nwhere they live in the world. Figure 1depicts a report of\\nthe main causes of death globally, as published by WHO on\\nThe associate editor coordinating the review of this manuscript and\\napproving it for publication was Sung-Min Park\\n .December 9, 2020. Women are disproportionately affected by\\nAlzheimer’s disease and other forms of dementia, accounting\\nfor two-thirds of the cases Globally. The neurological and\\nbrain disorders and other non-communicable diseases claim\\nabout 43.5% of deaths globally.\\nThe main brain disorder epilepsy is characterized by\\nrecurrent seizures, which can affe', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1692: (' death globally, as published by WHO on\\nThe associate editor coordinating the review of this manuscript and\\napproving it for publication was Sung-Min Park\\n .December 9, 2020. Women are disproportionately affected by\\nAlzheimer’s disease and other forms of dementia, accounting\\nfor two-thirds of the cases Globally. The neurological and\\nbrain disorders and other non-communicable diseases claim\\nabout 43.5% of deaths globally.\\nThe main brain disorder epilepsy is characterized by\\nrecurrent seizures, which can affect people of all ages.\\nAbout 4-10 people per 1000 individuals experience active\\nepilepsy at any given time [1]. In addition to epilepsy and\\nAlzheimer’s, the WHO estimates that 1 in 100 children has\\nautism, which is a disorder that affects the development of\\nthe nervous system and brain and can cause problems with\\n143116\\n2023 The Authors. This work is licensed under a Creative Commons Attribution 4.0 License.\\nFor more information, see https://creativecommons.org/licenses/by/4.0/ VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nbehavior, sociability, and intercommunication [2]. Mental\\ndisorders are also prevalent worldwide, with approximately\\n1 in 8 individuals, or 970 million people, living with\\na form of mental disorder. Anxiety and depression are\\nthe most common disorders, and the COVID-19 pandemic\\nhas led to an increase in persons living with these\\nconditions [3].\\nFIGURE 1. Summary of the statistical report of WHO regarding leading\\ncauses of deaths globally for the year 2000 and up to 2023.\\nPsychiatric disorders, including bipolar disorder, schizophre-\\nnia, eating disorders, ADHD, and autism spectrum disorder\\n(ASD), are characterized by significant difficulties in\\nthinking, emotional regulation, and behavior.\\nVarious projects have been conducted globally to manage\\nthese disorders and identify potential prevention strategies\\nby diagnosing brain activity. However, the brain consists of\\nbillions of cells, with neurons and non-neuron cells calle', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1693: ('of deaths globally for the year 2000 and up to 2023.\\nPsychiatric disorders, including bipolar disorder, schizophre-\\nnia, eating disorders, ADHD, and autism spectrum disorder\\n(ASD), are characterized by significant difficulties in\\nthinking, emotional regulation, and behavior.\\nVarious projects have been conducted globally to manage\\nthese disorders and identify potential prevention strategies\\nby diagnosing brain activity. However, the brain consists of\\nbillions of cells, with neurons and non-neuron cells called\\nglia being the most common types of cells [4]. Neurons in\\nthe brain are closely linked, with synapses as entryways for\\neither inhibitory or excitatory activity. Activity at a synaptic\\njunction generates tiny voltages known as a postsynaptic\\npotential [1]. While it is impossible to detect the burst\\nof a single neuron without direct contact due to its small\\nsize, the synchronous activity of hundreds of millions of\\nneurons with similar spatial orientations can be recognized\\non the scalp’s surface. During volume conduction, many\\nneurons simultaneously push ions, and the energies of the\\nions push and pull electrons onto the electrodes. Voltmeters\\ncan measure the difference between any two electrodes’\\npush and pull voltages because metals conduct electrons\\nefficiently. The differences in voltage between electrodes in\\nthe brain create EEG signals, which are used to analyze brain\\nactivity [2].\\nEEG signals are vital in biomedical healthcare because\\nthese represent brain activity mainly utilized for the iden-\\ntification of epilepsy, Alzheimer’s, mental stress, autism,\\nADHD, and other brain and neurological disorders. Early\\ndetection and precise identification of these brain conditions\\ncan help save lives across the globe. We were motivated to\\nconduct a comprehensive assessment of EEG signals by the\\ndesire to save lives and reduce the symptoms and disabilities\\nassociated with brain disorders.The EEG signal is very low amplitude and is commonly\\nenhanced with amplifiers during acquisition. Due to low\\namplitude, noise sour', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1694: ('ion of epilepsy, Alzheimer’s, mental stress, autism,\\nADHD, and other brain and neurological disorders. Early\\ndetection and precise identification of these brain conditions\\ncan help save lives across the globe. We were motivated to\\nconduct a comprehensive assessment of EEG signals by the\\ndesire to save lives and reduce the symptoms and disabilities\\nassociated with brain disorders.The EEG signal is very low amplitude and is commonly\\nenhanced with amplifiers during acquisition. Due to low\\namplitude, noise sources usually contaminate the signal; thus,\\ndenoising is applied to get a clean signal. Sometimes, if the\\nnoise is dominant and deficient, the signal is discarded and\\nrecorded by experimenting again. Further, depending on the\\napplication, filtering and processing are applied to EEG. EEG\\nsignals are then analyzed by extracting features that consider\\nthe complexity of brain dynamics. EEG signals are currently\\nbeing studied to improve preprocessing and feature extraction\\nmethods, which can be applied to EEG processing, enabling\\nthe extraction of reliable features [3].\\nIn this study, we aim to develop a comprehensive reference\\ntool for EEG researchers by covering various topics related to\\nEEG signal processing, feature extraction, and classification.\\nThe paper’s contents are organized as follows: Section II\\nbegins with a brief history of EEG, its techniques and\\napplications, and a description of the mechanisms and\\nmethods involved. This section also provides an overview\\nof the current challenges associated with EEG processing.\\nSection IIIpresents the available datasets, Section IVreviews\\nEEG artifacts and their types, and Section Vdiscusses the\\npreprocessing techniques used to remove these artifacts. Sec-\\ntionVIfocuses on the features of EEG and the methods used\\nfor their extraction. Section VIIdiscusses the most commonly\\nused classification techniques, and Section VIII presents\\nan overview of existing review papers. Finally, Section IX\\ndiscusses future research directions and concludes the paper.\\nOverall, this study', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1695: (' processing.\\nSection IIIpresents the available datasets, Section IVreviews\\nEEG artifacts and their types, and Section Vdiscusses the\\npreprocessing techniques used to remove these artifacts. Sec-\\ntionVIfocuses on the features of EEG and the methods used\\nfor their extraction. Section VIIdiscusses the most commonly\\nused classification techniques, and Section VIII presents\\nan overview of existing review papers. Finally, Section IX\\ndiscusses future research directions and concludes the paper.\\nOverall, this study provides up-to-date and comprehensive\\nreferences based on influential articles published in scholarly\\njournals and prime academic conferences after 2017 while\\nhighlighting open challenges and possibilities that should be\\naddressed to enhance the accuracy of the models.\\nA. MAIN CONTRIBUTIONS OF THIS STUDY\\nThis study provides new insights into the potential of EEG\\nsignals for diagnosing, monitoring, and managing brain\\ndisorders. While many survey articles have been published on\\nEEG signal processing, these articles often focus on general\\naspects of the field and do not provide a comprehensive\\noverview of EEG for medical diagnosis. In 2022, Orban et al.\\n[5]provided a comprehensive review of EEG; however, it also\\ndiscusses the development of natural interaction strategies,\\nwith a specific emphasis on EEG recording, preprocessing,\\nclassification of diseases, and control strategies. It does not\\nprovide insight into EEG in medical healthcare and diagnosis.\\nIn[6], the researchers presented an extensive review of EEG\\nsignaling but mainly focused on the general applications of\\nEEG-controlling devices. Reference [7]provides a review of\\nusing DL models for EEG signal processing; however, it only\\nfocuses on signal denoising and processing. The literature\\nreview reveals a lack of an extensive review of EEG signals\\nfor medical diagnosis, healthcare, and monitoring; this study\\npresents a comprehensive review with the following main\\ncontributions.\\nVOLUME 11, 2023 143117\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for M', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1696: ('\\nsignaling but mainly focused on the general applications of\\nEEG-controlling devices. Reference [7]provides a review of\\nusing DL models for EEG signal processing; however, it only\\nfocuses on signal denoising and processing. The literature\\nreview reveals a lack of an extensive review of EEG signals\\nfor medical diagnosis, healthcare, and monitoring; this study\\npresents a comprehensive review with the following main\\ncontributions.\\nVOLUME 11, 2023 143117\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n1) Ascribe a detailed review of all the stages of the EEG\\nAnalysis for medical diagnosis,\\n2) Describes the types of common artifacts that contam-\\ninate EEG signals and the techniques for attenuating\\nthem.\\n3) Outlines the preprocessing techniques applied to EEG,\\n4) Discusses the EEG filtering and feature extraction\\ntechniques for medical diagnosis.\\n5) Provides a comprehensive examination of EEG-based\\ntraditional ML/DL approaches for medical diagnosis\\nand healthcare, 6) Additionally, we furnish a synopsis\\nof the common datasets employed in EEG signal pro-\\ncessing and the existing challenges within EEG signal\\nprocessing methods are underscored, accompanied by\\nproposed remedies and promising avenues for future\\nresearch.\\nII. EEG BACKGROUND\\nThe invention of the electroencephalogram (EEG) is\\nattributed to Hans Berger, a German scientist, who acquired\\nthe EEG from human subjects for the first time, marking\\nthe beginning of clinical electroencephalography. Gibbs,\\nDavis, and Lennox further characterized interictal signals\\nand patterns of clinical seizures, contributing to the growth\\nof EEG’s clinical and scientific use. The development of\\nmachine learning in the 1960s [8]led to increased usage\\nof EEGs in research and medical practice, culminating\\nin the invention of the recurrent neural network in 1982\\n[9]. Since then, mathematical frequency analysis [10],\\nfrequency reduction [11], and classification techniques [9],\\n[12] have advanced EEG analysis, alongside technical\\nimprovem', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1697: (' Lennox further characterized interictal signals\\nand patterns of clinical seizures, contributing to the growth\\nof EEG’s clinical and scientific use. The development of\\nmachine learning in the 1960s [8]led to increased usage\\nof EEGs in research and medical practice, culminating\\nin the invention of the recurrent neural network in 1982\\n[9]. Since then, mathematical frequency analysis [10],\\nfrequency reduction [11], and classification techniques [9],\\n[12] have advanced EEG analysis, alongside technical\\nimprovements such as videotape recording and remote\\nreal-time reading in the 1990s. Complex algorithms such\\nas multi-class support vector machines and probabilistic\\nneural networks were introduced in the 2000s, aimed\\nat reducing artifacts and improving classification [13],\\ncomplementing the feature extraction techniques described in\\nSection II.\\nA. OVERVIEW OF EEG\\nEEG is a painless procedure that uses electrodes placed on the\\nscalp to measure the electric current by neurons in the brain\\nto study its operation [14]. Each electrode is connected to a\\nsingle wire to detect voltage fluctuations or electric potential\\ndifferences resulting from the flow of ionic currents inside the\\nneurons of the brain [15], [16].\\nEEG signals show oscillations at various frequencies,\\nwhich can be classified into five main bands as shown in\\nTable 1 [17]. Different frequency bands of EEG are linked\\nto various brain activities and functions, and their amplitudes\\nand relative power can help detect neurological and brain\\ndisorders.\\nTo measure EEG signals, electrodes are placed on specific\\nscalp locations following a 10-20 international system,\\nas shown in Figure 2, which maintains consistency inlaboratory procedures worldwide [18]. The EEG from the\\nelectrodes is fed into amplifiers that filter and amplify the\\nsignal before being displayed. EEG is typically used to detect\\nbrain activity in a bandwidth from 0.1 Hz to 100 Hz, as shown\\nin Figure 3.\\nHowever, EEG processing faces various challenges,\\nincluding artifact removal, signal processing and analy', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1698: (' signals, electrodes are placed on specific\\nscalp locations following a 10-20 international system,\\nas shown in Figure 2, which maintains consistency inlaboratory procedures worldwide [18]. The EEG from the\\nelectrodes is fed into amplifiers that filter and amplify the\\nsignal before being displayed. EEG is typically used to detect\\nbrain activity in a bandwidth from 0.1 Hz to 100 Hz, as shown\\nin Figure 3.\\nHowever, EEG processing faces various challenges,\\nincluding artifact removal, signal processing and analysis,\\nindividual differences, and interpretation and validation.\\nDespite these challenges, EEG has multiple applications in\\nclinical practice, such as diagnosing and monitoring epilepsy,\\nsleep disorders, and other neurological and psychiatric\\nconditions. EEG also studies brain function and connectivity,\\nincluding memory, attention, and language. Therefore, EEG\\nhas become a vital tool in neuroscience and clinical practice.\\nFIGURE 2. The actiCAP: a 32-electrode EEG cap that uses the\\ninternational 10–20 system for electrode placement [18].\\nB. EEG APPLICATIONS\\nEEG applications are diverse and range from clinical to\\nnon-clinical settings. Clinical applications of EEG include\\nstudying sleep patterns, seizures, comas, brain death, atten-\\ntion deficit hyperactivity disorder (ADHD), disorders of\\nconsciousness, and the depth of anesthesia [17], [19] [20],\\n[21], [22]. EEG is also used to diagnose and monitor various\\nneurological and psychiatric conditions alongside these brain\\ndisorders.\\nIn addition to clinical applications, EEG is used in\\nneuromarketing and psychological studies to evaluate a\\npatient’s cognitive state, such as mood and anxiety. For\\nexample, brain-computer interface (BCI) involves moving\\nthe cursor on the screen using the brain, wheelchairs, and\\nmilitary scenarios [21]. EEG is recognized as one of the most\\nefficient imaging methods for detecting brain electric currents\\n143118 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 3. EEG ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1699: ('ons, EEG is used in\\nneuromarketing and psychological studies to evaluate a\\npatient’s cognitive state, such as mood and anxiety. For\\nexample, brain-computer interface (BCI) involves moving\\nthe cursor on the screen using the brain, wheelchairs, and\\nmilitary scenarios [21]. EEG is recognized as one of the most\\nefficient imaging methods for detecting brain electric currents\\n143118 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 3. EEG of a healthy subject recorded for 200 seconds, broken\\ndown into the five main frequency bands of cerebral oscillations, also\\ncalled brainwaves.\\nTABLE 1. The five bands of EEG signals.\\ndue to the coordinated actions of hundreds of neurons.\\nThis approach offers high temporal resolution, which may\\nbe viewed on the screen as a digital representation of\\na continuous voltage flow. This technique can determine\\ncortical activity even at the lowest time intervals. EEG\\nis an essential tool for clinical and non-clinical settings,\\nand ongoing research continues to explore its potential\\napplications.\\nC. CURRENT CHALLENGES IN EEG PROCESSING\\nProcessing EEG signals poses several challenges that must be\\naddressed for accurate analysis. One of the most significant\\nchallenges is the Signal to Noise Ratio (SNR), and the\\npresence of different noise sources, such as artifacts or\\ninterference, which makes signal preprocessing difficult [23],\\n[24]. The SNR of the EEG is sensitive to external factors,\\nincluding light, smells, blinking, movement, temperature,\\nand controlled lab environments. These inherited noise\\nsources complicate their analysis as the EEG processingalgorithms work on an adequate quality of the signals.\\nVarious techniques can be utilized to overcome the challenge\\nof low SNR and external noise sources in EEG processing.\\nThese techniques include using high-quality electrodes,\\noptimal electrode placement, advanced signal filtering and\\ndenoising algorithms, and improved experimental setups and\\nstimulation techniques [22].\\n', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1700: ('g, movement, temperature,\\nand controlled lab environments. These inherited noise\\nsources complicate their analysis as the EEG processingalgorithms work on an adequate quality of the signals.\\nVarious techniques can be utilized to overcome the challenge\\nof low SNR and external noise sources in EEG processing.\\nThese techniques include using high-quality electrodes,\\noptimal electrode placement, advanced signal filtering and\\ndenoising algorithms, and improved experimental setups and\\nstimulation techniques [22].\\nAdditionally, EEG signals are unique in nature, making\\ntheir processing complex due to non-stationarity, non-\\nlinearity, and the higher likelihood of artifacts, which makes\\nit challenging to study their internal relationships directly.\\nTherefore, preprocessing steps are required to remove\\nartifacts from the signal before post-processing, commonly\\ncalled artifact subtraction (AS) [25].\\nAnother challenge is the data dimensionality that arises\\nfrom collecting numerous electrodes. Thus, fusion and\\nmerging of data are critical for reducing dimensionality and\\nimproving classification results. Noise reduction algorithms\\nand methods like multiple-source Electrooculography (EOG)\\n[26], non-linear recursive least squares [27], Fisher scores,\\nand principal component analysis (PCA) are commonly\\napplied to remove noise and decrease data dimensions, with\\nPCA being the most widely used method for separating the\\ndata into independent components.\\nThe lack of data is another challenge as statistics\\nchange over time for the same patient, and physiological\\ndifferences between patients can lead to high inter-subject\\nvariability [28], negatively affecting the generalization of\\nmodels. Various processing pipelines, such as adaptive and\\nRiemannian-geometry-based classifiers [29], are applied to\\nEEG for denoising, feature engineering, and classification,\\nalthough this area of research remains active. The stages of\\nEEG data analysis as shown in Figure 4, are discussed in the\\nfollowing sections.\\nFIGURE 4. Various steps used in EEG digital', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1701: (' patient, and physiological\\ndifferences between patients can lead to high inter-subject\\nvariability [28], negatively affecting the generalization of\\nmodels. Various processing pipelines, such as adaptive and\\nRiemannian-geometry-based classifiers [29], are applied to\\nEEG for denoising, feature engineering, and classification,\\nalthough this area of research remains active. The stages of\\nEEG data analysis as shown in Figure 4, are discussed in the\\nfollowing sections.\\nFIGURE 4. Various steps used in EEG digital signal processing and\\nclassification for medical diagnosis.\\nIII. DATASETS\\nFreely downloadable EEG datasets make them more accessi-\\nble to researchers, medical doctors, and clinicians for medical\\ndiagnosis and research. Numerous well-known EEG datasets\\nhave been made available for research purposes and have\\nbeen utilized by researchers. These datasets are publicly\\navailable and have been used in many research studies.\\nSome of these datasets include Melbourne, CHB-MIT, Bonn,\\nVOLUME 11, 2023 143119\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nEuropean Epilepsy datasets, EEG dataset for Alzheimer,\\nAmerican Epilepsy Society dataset, and other datasets as\\nlisted in Table 2. The details of these datasets are summarized\\nin the following subsections.\\nA. CHB-MIT DATASET\\nEEGs of children were acquired at the Boston Children’s\\nHospital and Massachusetts Institute of Technology (MIT)\\n[30]. The data are publicly accessible and are available on\\nthe website Physionet.org. EEG is recorded for 916 hours\\nfrom 22 pediatric participants with intractable seizures for a\\ntotal of one hour or four hours. Five males and 17 females\\nparticipated in this research, ranging in age from 3-22 years\\nand 1.5-19 years, respectively. The number of electrodes\\nvaried between 23 to 28 electrodes for different patients. The\\nsampling rate for EEG was set to 256 samples per second,\\nwith 23 EEG signals per file, and 198 seizures were annotated\\nwith their beginning and end times. There are 23 chann', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1702: ('org. EEG is recorded for 916 hours\\nfrom 22 pediatric participants with intractable seizures for a\\ntotal of one hour or four hours. Five males and 17 females\\nparticipated in this research, ranging in age from 3-22 years\\nand 1.5-19 years, respectively. The number of electrodes\\nvaried between 23 to 28 electrodes for different patients. The\\nsampling rate for EEG was set to 256 samples per second,\\nwith 23 EEG signals per file, and 198 seizures were annotated\\nwith their beginning and end times. There are 23 channels\\nin most records, with a few having 24 and 26; Figure 5\\nshows seizures and non-seizures records. The files can be\\ndownloaded as ZIP files (42.6 GB) using European Data\\nFormat (.edf) [31], which can be accessed via a terminal or\\nGoogle Cloud Storage Browser. Preictal and interictal labels\\nwere not included in this dataset, but could be extracted\\nfrom the meta-data files for each patient [32]. It is a widely\\nused dataset for epilepsy research. However, there are several\\nchallenges associated with this dataset. One of the main\\nchallenges is the presence of artifacts, including motion\\nartifacts, electrode artifacts, and muscle artifacts, which can\\naffect the accuracy of the analysis. Another challenge is\\nthe interictal and ictal classification of EEG signals, which\\nrequires domain knowledge and can be time-consuming.\\nAdditionally, the dataset only contains a limited number of\\npatients, which can limit the generalizability of the findings\\nto a larger population.\\nB. UNIVERSITY OF BONN DATASET\\nBonn dataset has five sub-datasets (A-E) for healthy people\\nand patients with epilepsy. The data can be downloaded\\nfor free from http://epileptologie-bonn.de/. 100 EEG signal\\nrecordings last for 23.6 seconds per channel in each dataset.\\nFour phases are measured: surface EEG with open and closed\\neyes and intracranial EEG with interictal and seizure phases.\\nEach channel contains 4097 samples, sampled at a rate of\\n173.61 samples per second. The zip files of the datasets are\\navailable with labels. The Bonn dataset is not chosen f', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1703: ('ve sub-datasets (A-E) for healthy people\\nand patients with epilepsy. The data can be downloaded\\nfor free from http://epileptologie-bonn.de/. 100 EEG signal\\nrecordings last for 23.6 seconds per channel in each dataset.\\nFour phases are measured: surface EEG with open and closed\\neyes and intracranial EEG with interictal and seizure phases.\\nEach channel contains 4097 samples, sampled at a rate of\\n173.61 samples per second. The zip files of the datasets are\\navailable with labels. The Bonn dataset is not chosen for the\\ndevelopment of epilepsy prediction algorithms as it is only\\none channel and recorded for a shorter duration.\\nC. AMERICAN EPILEPSY SOCIETY DATASET\\nThis dataset [33] consists of EEG recordings of seven\\nparticipants for 1300 hours. The subjects are two humans and\\nfive canines with channels from 15 to 24 per subject. The\\nEEG recordings include a line noise of 60 Hz that could be\\nfixed using a notch filter [34].\\nFIGURE 5. Two records for EEG tracing of CHB12_23: (a) no seizure,\\n(b) seizure [31].\\nD. EUROPEAN EPILEPTIC DATASET\\nThe European Epileptic Dataset, part of the EU-funded\\nproject ‘‘EPILESIAE’’ [35], is one of the most comprehen-\\nsive data sources currently available. This dataset contains\\nEEG signals recorded for 300 subjects aged 13 to 67 years,\\nrepresenting a wide spectrum of epilepsy symptoms. A total\\nof 6488 hours of EEG recordings with more than 250 seizures\\nwere included in the dataset, of which 50 included intracra-\\nnial recordings with up to 122 channels. Datasets are\\navailable on http://epilepsy-database.eu/, but they must be\\npaid for. They are saved in.edf format. Moreover, the\\ndataset is not labeled as preictal, ictal, or interictal but\\ncan be analyzed based on the timing information of the\\nseizures.\\nE. EEG DATASET FOR ALZHEIMER\\nAlzheimer’s disease (AD) is a neurodegenerative disorder\\nthat causes memory loss, changes in behavior, and other\\ncognitive problems. They are most common in people over\\n65 but can occur at younger ages. Recently a new dataset\\nof EEG signals for Alzheimer’s has been de', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1704: ('psy-database.eu/, but they must be\\npaid for. They are saved in.edf format. Moreover, the\\ndataset is not labeled as preictal, ictal, or interictal but\\ncan be analyzed based on the timing information of the\\nseizures.\\nE. EEG DATASET FOR ALZHEIMER\\nAlzheimer’s disease (AD) is a neurodegenerative disorder\\nthat causes memory loss, changes in behavior, and other\\ncognitive problems. They are most common in people over\\n65 but can occur at younger ages. Recently a new dataset\\nof EEG signals for Alzheimer’s has been developed by\\nMiltiadous et al. [36]. The EEG dataset has signal acquired\\nfor 88 subjects resting with closed eyes. Of these, 36 were\\nAD patients, 23 with frontotemporal dementia (FTD), and\\n29 with cognitive normal. The neurological state of each\\nparticipant was evaluated using a test called Mini-Mental\\nState Examination (MMSE)—this standardized test scores\\ncognitive decline from 0 to 30, where 0 is for more severe\\ncases.\\n143120 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nF. EEG DATASETS FOR PARKINSON’S DISEASE\\nThe open-source and publically available dataset of EEG for\\nParkinson’s disease is the San Diego dataset (31 subjects,\\n93 min) [37]. EEG is recorded from subjects sitting in a\\ncomfortable state with their eye relaxed while focused on\\na screen. The dataset has two sub-datasets: the first subset\\nhas EEGs from 16 healthy individuals, and the second group\\ncontains EEGs from 15 Parkinson’s disease (PD) persons,\\nwhich were similar to the healthy subjects in terms of\\ngender, right-handedness, cognition, and age, as recognized\\nby MMSE.\\nG. EDPMSC DATASET\\nAnother dataset analyzed in this study is the Perceived Mental\\nStress Classification (EDPMSC) dataset [38]. The data is\\navailable for anyone to use and contains EEG signals labeled\\nwith one of two categories: stress or not stress. The data is\\ncollected from 28 subjects aged between 18 and 40 years,\\ncomprising 13 men and 15 women, using a Muse headband\\nwith only four channels (AF7, AF8, TP9, TP', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1705: ('healthy subjects in terms of\\ngender, right-handedness, cognition, and age, as recognized\\nby MMSE.\\nG. EDPMSC DATASET\\nAnother dataset analyzed in this study is the Perceived Mental\\nStress Classification (EDPMSC) dataset [38]. The data is\\navailable for anyone to use and contains EEG signals labeled\\nwith one of two categories: stress or not stress. The data is\\ncollected from 28 subjects aged between 18 and 40 years,\\ncomprising 13 men and 15 women, using a Muse headband\\nwith only four channels (AF7, AF8, TP9, TP10). Signals were\\nacquired using a sampling frequency of 256 samples/s for\\nthree minutes across three experiments: a pre-active phase\\nconsisting of three minutes of recording in a quiet room\\nwith a relaxed position and open eyes, an activity phase\\nduring a presentation in front of people, and a post-activity\\nphase involving three minutes of recording in the same room.\\nTo categorize the groups as stressed or not stressed, the\\nPerceived Stress Scale (PSS) was employed. The groups\\nwere classified as either stressed (PSS>=20) or not stressed\\n(PSS20) based on their PSS scores.\\nIV. EEG ARTIFACTS\\nSeveral physiological and non-physiological sources of noise\\nattenuate EEG. These artifacts refer to signal records that\\nare not of neural origin. Detecting and removing artifacts is\\ncrucial to ensure adequate quality of EEG signals, as they can\\noften mimic actual brain abnormalities or seizures. Artifacts\\ncan be classified into two types: physiological, which are\\nfrom the body of the subject, and non-physiological, due\\nto the surroundings [51]. Figure 6illustrates the most\\ncommon types of EEG artifacts. The details are in the next\\nsubsections.\\nA. PHYSIOLOGIC ARTIFACTS\\n1) ELECTROMYOGRAM (EMG)\\nEMG refers to the electrical noise produced by muscle\\nmovements. Myogenic potentials are the most common\\nartifacts generated by the muscles near the scalp, like the\\nfrontalis, orbicularis, and temporalis muscles surrounding\\nthe eyebrows, eyelids, and jaw [53]. Muscle artifacts\\nthat mimic cerebral activity are due to different disorders\\nl', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1706: ('the surroundings [51]. Figure 6illustrates the most\\ncommon types of EEG artifacts. The details are in the next\\nsubsections.\\nA. PHYSIOLOGIC ARTIFACTS\\n1) ELECTROMYOGRAM (EMG)\\nEMG refers to the electrical noise produced by muscle\\nmovements. Myogenic potentials are the most common\\nartifacts generated by the muscles near the scalp, like the\\nfrontalis, orbicularis, and temporalis muscles surrounding\\nthe eyebrows, eyelids, and jaw [53]. Muscle artifacts\\nthat mimic cerebral activity are due to different disorders\\nlike essential tremor, PD, and hemifacial spasm and can\\nbe identified based on their duration, morphology, and\\nfrequency [54]. An example of such artifacts is depicted in\\nFigure 7.\\nFIGURE 6. Common EEG Artifacts: (A) Superposition of 50Hz main waves\\nof EEG appears as thickened signal, (B) Movement Artifact causes sudden\\ndeviation from the EEG background, (C) The EEG could be cut short by\\nsudden movement, (D) When the ECG’s pulses are overlapped on the EEG,\\na pulsed EEG is the visible result, (E) Sweat artifacts show up on EEGs as\\na little shift in the baseline [52].\\n2) ELECTROOCULOGRAPHY (EOG)\\nElectrical impulses called electrooculograms (EOGs) are\\ngenerated by eye movements and blinking. These artifacts are\\nonly helpful in determining sleep modes [55]. Otherwise, the\\nEEG is affected by these artifacts, leading to inaccurate inter-\\npretations [56]. EOG and EEG contaminated by movement\\nartifacts from an infant are shown in Figure 7 [57].\\nFIGURE 7. Panel: (A) Eye movement, (B) Eye Blink, (C) Head Movement,\\n(D) Comforter/nursing Movement [57].\\n3) GLOSSOKINETIC ARTIFACTS\\nThese artifacts are caused by tongue movement during the\\nacquisition of EEG while talking, chewing, or sucking,\\nas depicted in Figure 7. These artifacts are commonly seen\\nin young patients and those with dementia [53].\\n4) ELECTROCARDIOGRAM (ECG OR EKG) ARTIFACT\\nElectrocardiogram artifacts refer to the heart activity that may\\nbe detected on the scalp during EEG recordings [58]. Sharp\\nwaves or spikes characterize them and are most prominent\\nin individ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1707: ('omforter/nursing Movement [57].\\n3) GLOSSOKINETIC ARTIFACTS\\nThese artifacts are caused by tongue movement during the\\nacquisition of EEG while talking, chewing, or sucking,\\nas depicted in Figure 7. These artifacts are commonly seen\\nin young patients and those with dementia [53].\\n4) ELECTROCARDIOGRAM (ECG OR EKG) ARTIFACT\\nElectrocardiogram artifacts refer to the heart activity that may\\nbe detected on the scalp during EEG recordings [58]. Sharp\\nwaves or spikes characterize them and are most prominent\\nin individuals with short and wide necks. These artifacts can\\nVOLUME 11, 2023 143121\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 2. A list of EEG public datasets for various brain and neurological disorders.\\nbe distinguished based on duration and morphology unless\\nthe EEG signal coincides with abnormal cerebral activity,\\nmaking it difficult to differentiate the two [59].\\n5) EEG PULSE ARTIFACT\\nThe placement of an electrode over a pulsating blood vessel\\ncan cause an EEG pulse artifact, resulting in the appearance\\nof slow waves on the EEG graph. The main QRS spike\\nin the ECG represents the heart’s electrical component,\\nwhich appears between 200 and 300 ms before the pulse\\nartifact [59]. To address this issue, the electrode can be\\nrepositioned to a different location.\\n6) SKIN ARTIFACTS\\nThe large baseline is a skin artifact observed in EEG and is\\nprimarily due to sweating. Other potential causes may include\\nskull defects and subgaleal hematomas [58].\\nB. NON-PHYSIOLOGIC ARTIFACTS\\nThese types of artifacts are often referred to as non-biological\\nor technological artifacts. Powerline interference, electrode\\npop, cable movement, improper reference positioning, and\\nerroneous placement of electrodes are all potential causes\\nof such artifacts that degrade the quality of EEG and thus\\nlimit its applications. An example of EEG signals with these\\nartifacts is depicted in Figure 8.1) ELECTRODE ARTIFACTS\\nThe sudden disconnection or movement of the electrode\\nis one of the most ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1708: ('SIOLOGIC ARTIFACTS\\nThese types of artifacts are often referred to as non-biological\\nor technological artifacts. Powerline interference, electrode\\npop, cable movement, improper reference positioning, and\\nerroneous placement of electrodes are all potential causes\\nof such artifacts that degrade the quality of EEG and thus\\nlimit its applications. An example of EEG signals with these\\nartifacts is depicted in Figure 8.1) ELECTRODE ARTIFACTS\\nThe sudden disconnection or movement of the electrode\\nis one of the most common electrode artifacts. This can\\nresult in either incorrect acquisition of the EEG signal or\\na transient vertical path associated with a single electrode\\ndue to an abrupt change in impedance and can be visually\\nidentified [59].\\n2) MOVEMENTS IN THE ENVIRONMENT\\nMovements in the environment, such as the movement of a\\nperson around the patient, electrostatic effects on the drops,\\nrespirators, radio, and television radiation, or interference of\\nother equipment, such as electromagnetic sources like infu-\\nsion pumps that use electricity, can affect EEG signals [61].\\nThis can result in the deflection of the pens and make it\\ndifficult to record EEG signals unless the interfering devices\\nare turned off [62].\\n3) ALTERNATING CURRENT ARTIFACT\\nAn alternate current artifact refers to a specific type of\\nartifact that arises from technical complications, such as\\nunintentionally high impedance [63]. These complications\\ncan lead to the emergence of a 50 Hz or 60 Hz artifact,\\ndepending on the frequency standards followed. Notably,\\ncountries like the USA operate on a frequency of 60 Hz.\\nTherefore, any technical issues resulting in artifacts within\\n143122 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 8. (a) Electrode Pop with a distortion in F3 produced by touching\\nthe sensor, (b) Cable Movement producing distortion in Cz or Pz that are\\nnot eeg-related, (c) Reference Incorrect Placement producing a high\\namplitude abrupt, (d) Powerline Interference wit', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1709: ('tably,\\ncountries like the USA operate on a frequency of 60 Hz.\\nTherefore, any technical issues resulting in artifacts within\\n143122 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 8. (a) Electrode Pop with a distortion in F3 produced by touching\\nthe sensor, (b) Cable Movement producing distortion in Cz or Pz that are\\nnot eeg-related, (c) Reference Incorrect Placement producing a high\\namplitude abrupt, (d) Powerline Interference with a peak at 50Hz\\noverlapping the EEG data, (e) Head Movement effect overlaps low\\nfrequencies of eeg in all channels [60].\\nthe USA would typically produce a 60 Hz artifact. It is\\nessential to recognize that this frequency disparity stems from\\nvariations in electrical systems and standards across different\\ncountries.\\nV. EEG PREPROCESSING AND FILTERING\\nTo prepare raw EEG signals for feature extraction and\\nclassification, it is crucial to clean them from noise and\\nartifacts through preprocessing and proper filtering to\\nenhance the extraction of relevant information. EEG signals\\nare biomedical signals that reflect brain activity and are\\nsusceptible to external interference during collection because\\nof their high time-varying nature and low amplitude. This\\ninterference can come from eye movement, blinking, ECG,\\nand EMG sources. These interferences are often called\\nartifacts.\\nEEG analysis is complex in the presence of these artifacts.\\nThey can also affect EEG features, detection, and classifi-\\ncation if not attenuated. Due to the low amplitude and the\\ncomplex nature of EEG signals, attenuating them is also more\\ncomplex. Thus, it is expected to perform some preprocessing\\nand filtering on the signal before using it to classify diseases.\\nTo make it convenient, first, the frequency contents of the\\nEEG are visualized to check for the existence of noises.\\nAs depicted in Figure 9, the 3D plot shows the contents\\nof the signals with respect to time and frequency. At this\\nstage, the spatiotemporal characteristics of EEG signals', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1710: ('ed. Due to the low amplitude and the\\ncomplex nature of EEG signals, attenuating them is also more\\ncomplex. Thus, it is expected to perform some preprocessing\\nand filtering on the signal before using it to classify diseases.\\nTo make it convenient, first, the frequency contents of the\\nEEG are visualized to check for the existence of noises.\\nAs depicted in Figure 9, the 3D plot shows the contents\\nof the signals with respect to time and frequency. At this\\nstage, the spatiotemporal characteristics of EEG signals [64]\\nplay a significant role since they can help select a suitable\\npreprocessing and filter technique [23], [65], [66], [67] [68],[69]. Artifacts originate from external sources, including\\nphysiologic and non-physiologic sources,\\nFilters are systems that attenuate unwanted frequencies from\\nEEG signals, amplify desired frequencies, or do both. A high-\\npass filter passes high frequencies of EEG while attenuating\\nlower frequencies (noises), while a notch filter stops power\\nline interference. Low-pass filters smooth the input signals\\nby removing high-frequency noises. Thus, filtering provides\\na tool for improving the signal SNR, which measures how\\nmuch of the signal is to noise. By removing noise from a\\nsignal, the SNR can be improved.\\nFilters work by taking advantage of the difference between\\nthe frequency spectrum of the noise and that of the target\\nsignal. Frequency spectra is a graphical representation of the\\nfrequencies that are present in a signal. Filters attenuate those\\nfrequencies in the spectrum that are dominated by noise more\\nthan those frequencies that are dominated by the target signal.\\nThis can significantly improve the SNR of the signal. Some\\nof the filter and preprocessing techniques used for EEG are\\ndiscussed in detail in the next sections and are summarized in\\nTable 3.\\nFIGURE 9. Time-frequency 3D plot of EEG: (a) Not filtered,\\n(b) Filtered [92].\\nA. POWER LINE INTERFERENCE REMOVAL\\nThe frequency of line noise artifact is typically found in\\nthe gamma band of the EEG at 50 Hz or 60 Hz, as shown\\nin F', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1711: ('re dominated by noise more\\nthan those frequencies that are dominated by the target signal.\\nThis can significantly improve the SNR of the signal. Some\\nof the filter and preprocessing techniques used for EEG are\\ndiscussed in detail in the next sections and are summarized in\\nTable 3.\\nFIGURE 9. Time-frequency 3D plot of EEG: (a) Not filtered,\\n(b) Filtered [92].\\nA. POWER LINE INTERFERENCE REMOVAL\\nThe frequency of line noise artifact is typically found in\\nthe gamma band of the EEG at 50 Hz or 60 Hz, as shown\\nin Figure 10. A notch filter, which blocks off a specific\\nfrequency range, is commonly used to eliminate this artifact.\\nHowever, the use of a notch filter can introduce spurious\\noscillations with parasitic frequencies and potentially distort\\nthe signal [70], [71], [93]. Spectral interpolation [70] is\\nalso a good option however, it also sometimes introduces\\nextra frequencies in the signal while performing the phase\\ninterpolation.\\nA smoothing filter of cut-off frequency less than 50 Hz\\nor 60 Hz can be a solution. However, it can lead to an\\nincorrectly denoised signal with missed causalities [95]and\\nalteration of the signal’s temporal structure [96]. To overcome\\nthis issue, a multi-taper decomposition can be utilized\\nto estimate the spectral energy, which helps to minimize\\nbroadband variations [97], as depicted in Figure 11. The\\nentire process is carried out in three key stages: Firstly,\\na short-time window is slid over the data using discrete\\nprolate spheroidal sequences (DPSS) tapers, and multiple\\nindependent projections of the data are extracted [98].\\nVOLUME 11, 2023 143123\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 3. A Summary of the preprocessing, Artifacts Removal, and digital filtering techniques applied to EEG signals.\\nSecondly, the single-taper spectra for each projection are\\ncomputed, representing the spectral energy within each band.\\nFinally, a regression-based model is utilized to calculate the\\ncomponent’s mean and approximate phase and ampl', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1712: ('ections of the data are extracted [98].\\nVOLUME 11, 2023 143123\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 3. A Summary of the preprocessing, Artifacts Removal, and digital filtering techniques applied to EEG signals.\\nSecondly, the single-taper spectra for each projection are\\ncomputed, representing the spectral energy within each band.\\nFinally, a regression-based model is utilized to calculate the\\ncomponent’s mean and approximate phase and amplitude (50\\nHz or 60 Hz).\\nThe following equation describes multi-taper analysis:\\n˜xk(f)=N/summationdisplay\\n1wt(k)xie(−2π ift)(1)\\nwhere:\\nwt(k): k orthogonal taper functions N: length of taper w:\\nfrequency brandwidth parameter\\nThe third step involves using the Thompson F-test to deter-\\nmine the statistical significance of the non-zero regressioncoefficient since the precise frequency and phase of the\\nsinusoidal component (50 Hz or 60 Hz) could slightly vary\\nover time in the second step. This method can identify\\nfrequencies with maximum F-statistics above a defined\\nsignificance threshold (> 0.05), and the sinusoid can be\\nremoved from the affected time series, as shown in Figure 12\\n[23].\\nB. REFERENCING\\nReferencing is a crucial step in EEG preprocessing since it\\naffects the amplitude measurement of the signal. When one\\nelectrode is used as a reference for another electrode, it can\\nintroduce a mixture of brain activity and noise. To address\\nthis issue, different referencing methods can be used, such\\nas the Average Reference (A V) and the Common Average\\n143124 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 10. Electromagnetic interference at 50 Hz (Take into account that\\ncertain nations, such as the USA, operate on a 60Hz frequency.). To get rid\\nof them, a notch filter can be applied to the raw signal with MNE to cut\\noff frequencies at or around 50 Hz and their multiples [94].\\nFIGURE 11. The difference in the frequency spectra of the F3 (left)', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1713: ('ference (A V) and the Common Average\\n143124 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 10. Electromagnetic interference at 50 Hz (Take into account that\\ncertain nations, such as the USA, operate on a 60Hz frequency.). To get rid\\nof them, a notch filter can be applied to the raw signal with MNE to cut\\noff frequencies at or around 50 Hz and their multiples [94].\\nFIGURE 11. The difference in the frequency spectra of the F3 (left) and Cz\\n(right) electrodes before (blue) and after (green) multi-taper line\\nnoise-cleaning [99].\\nReference (CAR), which are commonly used in BCI design,\\nwhere a single reference point is positioned distantly from\\nthe other electrodes. However, this can lead to a single-point\\nfailure, so detecting and removing outlier channels should\\nbe done first. The AR method subtracts the average brain\\nactivity across all EEG electrodes, with the assumption that\\nthe sum of the overall brain activity is zero at a particular time.\\nAnother referencing method is the current source density\\n(CSD) estimation, which uses Laplacian to calculate the\\nchanging rate of current in the scalp. However, this method is\\nonly valid if the electrodes are positioned at equal distances\\nin a 2-D plane. Selection of the referencing method can\\nchange the interpretation of EEG, thus should be selected\\ncarefully [98], [100], [101], [102].\\nC. BAD CHANNELS DETECTION\\nAn electrode popping up from its location on the scalp or\\nmovement artifacts can cause bad channels [103]. Noise\\ninformation is propagated to all channels, thereby making\\nit difficult to detect and remove artifacts. To eliminate\\nbad channels, statistical characteristics, including power\\nspectral density(PSD), kurtosis, and variance, must be\\nconsidered. A bad channel can also be detected by using\\nthe robust z-score, correlation, soft F1 score, and binary\\ncross-entropy to calculate the loss function for a given\\nchannel. A series of interpolation schemes are then employed\\nto replace high-frequen', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1714: ('bad channels [103]. Noise\\ninformation is propagated to all channels, thereby making\\nit difficult to detect and remove artifacts. To eliminate\\nbad channels, statistical characteristics, including power\\nspectral density(PSD), kurtosis, and variance, must be\\nconsidered. A bad channel can also be detected by using\\nthe robust z-score, correlation, soft F1 score, and binary\\ncross-entropy to calculate the loss function for a given\\nchannel. A series of interpolation schemes are then employed\\nto replace high-frequency components above the threshold,including radial basis functions [104], nearest neighbor\\naveraging [105], and spherical spline interpolation [106].\\nFIGURE 12. The original time series is fitted with the major line\\ncomponent (identified by the F-test). From the original, noisy time series,\\nthis signal will be removed [99].\\nD. ARTIFACT REMOVAL\\nSeveral factors must be considered while eliminating artifacts\\nfrom EEG data, which necessitates a significant amount\\nof processing power and computing time, which becomes\\nproblematic when employed in ‘‘real-world applications.’’\\n[91]. As an area of investigation within the field of artifact\\nremoval, there is still no optimal approach that can be used\\nfor the effective removal of artifacts. In terms of the methods\\nthat are currently in place can be categorized as follows:\\n1) REGRESSION ANALYSIS\\nRegression analysis can be applied to EEG in any domain\\nand is based on estimating the artifacts from the EEG data\\nand subtracting them from the data [72]. This method has\\nsome limitations, including the need for a channel to serve\\nas a reference and the in-feasibility of its use for applications\\ninvolving EEG-like signals that are non-stationary. It is\\nlimited to certain artifacts rather than all categories of\\nartifacts.\\n2) DIGITAL FILTERING\\n1) Time domain filters: attenuate either very high- or\\nlow-frequency bands while leaving behind the required\\nfrequencies [107]. Temporal filters de-noise the EEG\\nand improve its quality by avoiding artifacts caused by\\ninterference from power l', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1715: ('imitations, including the need for a channel to serve\\nas a reference and the in-feasibility of its use for applications\\ninvolving EEG-like signals that are non-stationary. It is\\nlimited to certain artifacts rather than all categories of\\nartifacts.\\n2) DIGITAL FILTERING\\n1) Time domain filters: attenuate either very high- or\\nlow-frequency bands while leaving behind the required\\nfrequencies [107]. Temporal filters de-noise the EEG\\nand improve its quality by avoiding artifacts caused by\\ninterference from power lines and improper polariza-\\ntion of scalp electrodes [108].\\nLong-duration brain signals are filtered using DFT\\nor FFT by eliminating all coefficients that do not\\ncorrespond to the frequency band of EEG signals.\\nSubsequently, a backward DFT is used to convert it\\nback into a time domain signal.\\nTo generate a filtered EEG signal s(n) FIR, FIR filters\\nuse last Minput samples from a recorded EEG signal\\ns(n) as follows:\\n˜\\ns(n) FIR=M−1/summationdisplay\\nk=0aks(n−k) (2)\\nVOLUME 11, 2023 143125\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nwhere:\\n{ak}represents the filter coefficients and M represents\\nthe total number of coefficients of the FIR filter.\\nSimilarly, recursive IIR filters use the most recent N\\noutput samples and the most recent M input samples\\nfrom a raw EEG signal, requiring fewer coefficients\\nthan FIR filters [109].\\n˜\\ns(n) IIR=M−1/summationdisplay\\nk=0aks(n−k)+N−1/summationdisplay\\nk=1bks(n−k)IIR (3)\\nwhere\\n{ak}and{bk}are filter coefficients and M and N\\nrespectively represent the recent input samples and the\\nmost recent recursive, i.e., feedback output samples.\\nA review of the state-of-the-art digital filtering applied\\nto EEG is summarized in Table 3.\\n2) Spatial Filters: Utilize CAR and the surface Laplacian\\n(SL) filters to eliminate the noise from the background\\nbrain activity for pattern recognition, especially imag-\\nined motor activities [110]. A spacial filter is used\\nfor space reduction, signal filtering, and original brain\\nsignal recovery [62]. This', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1716: ('\\nrespectively represent the recent input samples and the\\nmost recent recursive, i.e., feedback output samples.\\nA review of the state-of-the-art digital filtering applied\\nto EEG is summarized in Table 3.\\n2) Spatial Filters: Utilize CAR and the surface Laplacian\\n(SL) filters to eliminate the noise from the background\\nbrain activity for pattern recognition, especially imag-\\nined motor activities [110]. A spacial filter is used\\nfor space reduction, signal filtering, and original brain\\nsignal recovery [62]. This is defined as follows:\\n˜x=/summationdisplay\\niwixi=wX (4)\\nwhere:\\n˜x: spatial filtered signal xi: Signal from EEG channel i\\nwi: channel weight in a spatial filter and w is a vector\\nrepresenting all channel weights X: original EEG\\nbrain signal matrix from all channels\\n3) Surface Laplacian Filtering: uses topographical power\\nspectral distributions with respect to frequency [111]\\nto differentiate between the brain and muscle signals.\\nThese techniques approximate the localized current\\ndensity passing perpendicularly into the scalp [111].\\nThe surface Laplacian can also be used to estimate\\nthe cortical surface potential and source identification.\\nLaplacian methods are all reference-independent [112].\\n4) Adaptive filtering: a self-modifying system that uses an\\noptimization algorithm to adjust filter parameters while\\ncomparing the reference and output signals [91]. As a\\nresult, it estimates noise and subtracts it from the raw\\nEEG signals through feedback.\\n3) BLIND SOURCE SEPARATION (BSS)\\nThe BSS is a commonly used method for ocular artifact sup-\\npression. Reference [113] from statistically independent [73]\\nsignals, incorporates the following:\\n1) Independent component analysis (ICA): A method\\nof analyzing data that involves first centering and\\nwhitening the data. This is followed by optimization,\\nwhich aims to minimize the nongaussianity of the\\nindependent sources. The advantages of ICA include\\nits independence from reference channels [114]. One ofthe major drawbacks of ICA is that it is computationally\\ncomplex and must ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1717: ('hod for ocular artifact sup-\\npression. Reference [113] from statistically independent [73]\\nsignals, incorporates the following:\\n1) Independent component analysis (ICA): A method\\nof analyzing data that involves first centering and\\nwhitening the data. This is followed by optimization,\\nwhich aims to minimize the nongaussianity of the\\nindependent sources. The advantages of ICA include\\nits independence from reference channels [114]. One ofthe major drawbacks of ICA is that it is computationally\\ncomplex and must be manually selected in terms of its\\nartifacts. This can be fixed by the use of kurtosis, along\\nwith spatial, spectral, and temporal features to detect\\nICs automatically [73].\\n2) Canonical Correlation Analysis (CCA): utilizes corre-\\nlation; it splits the contaminated signals while utilizing\\nstatistics of the second order (SOS) [75] to calculate\\nthe maximized correlation by canonical variables.\\nIt is efficient in detecting muscle artifacts but still\\nhas automation with fewer complexity problems than\\nICA[115].\\n3) Morphological component analysis (MCA): depends\\non the artifact database that has been decomposed\\naccording to its morphological properties, thus mak-\\ning it insufficient as an individual technique on its\\nown[76].\\n4) Principle Component Analysis (PCA): transforms a\\ncorrelated signal in the time domain into uncorrelated\\nprincipal components via orthogonal transformation\\n(PCs) [74]. Artifacts can be removed only if they are\\nuncorrelated with the EEG [75].\\n4) FREQUENCY DECOMPOSITION\\nWavelet transform decomposition is a time-frequency anal-\\nysis method that decomposes a signal into a series of\\nwavelets localized in both time and frequency. This allows for\\nseparating highly correlated wavelets from artifacts that are\\nnot correlated with the basis mother wavelet [116]. Several\\nwavelet transforms exist, including continuous wavelet trans-\\nform (CWT), wavelet packet transform (WPT), stationary\\nwavelet transform (SWT), and discrete wavelet transform\\n(DWT). DWT with statistical threshold (ST) functions is\\nsuitable', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1718: ('mposition is a time-frequency anal-\\nysis method that decomposes a signal into a series of\\nwavelets localized in both time and frequency. This allows for\\nseparating highly correlated wavelets from artifacts that are\\nnot correlated with the basis mother wavelet [116]. Several\\nwavelet transforms exist, including continuous wavelet trans-\\nform (CWT), wavelet packet transform (WPT), stationary\\nwavelet transform (SWT), and discrete wavelet transform\\n(DWT). DWT with statistical threshold (ST) functions is\\nsuitable for ocular artifacts removal [77], with a fast execution\\ntime when working on single-channel applications.\\n5) EMPIRICAL MODE DECOMPOSITION\\nA method that can adapt to different datasets and tasks [78].\\nTo remove the noisy intrinsic mode functions (IMFs) from\\nthe signals, these are divided into IMFs and use complex\\ncomputations. This method is most suitable for highly\\ncontaminated data [79]. However, the model overlap is one\\nof its significant drawbacks. An ensemble-EMD approach\\n(EEMD) is used to overcome this issue in which the IMF\\ncomponent is determined by averaging the ensembles of\\ntrials [80]in one channel, while a multivariate empirical mode\\ndecomposition (MEMD) is based on identifying muscle\\nartifacts over a small number of channels.\\n6) HYBRID METHODS\\nA combination of multiple methods is often used to obtain\\nsuperior outcomes. For instance, BSS-AF, and (BBS-WT)\\n[85], [117], [118] have been found to be more effective than\\nusing the BSS technique alone, particularly when combined\\nwith EMD or SVM [86], [119], [120]. Additionally, the\\n143126 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\ncombined use of wavelet and adaptive filters can miti-\\ngate certain limitations and eliminate ocular artifacts [82].\\nMoreover, VMD-CCA [90]has shown superior performance\\nover EEMD and ICA and EEMD and CCA across various\\nSNRs and channels, while AWCCR has demonstrated higher\\nefficacy than CCR [121].\\nVI. EEG FEATURES AND FEATURE EXTRACTION\\nMETHODS\\nEEG data o', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1719: ('9], [120]. Additionally, the\\n143126 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\ncombined use of wavelet and adaptive filters can miti-\\ngate certain limitations and eliminate ocular artifacts [82].\\nMoreover, VMD-CCA [90]has shown superior performance\\nover EEMD and ICA and EEMD and CCA across various\\nSNRs and channels, while AWCCR has demonstrated higher\\nefficacy than CCR [121].\\nVI. EEG FEATURES AND FEATURE EXTRACTION\\nMETHODS\\nEEG data often has long recordings of multiple channels, thus\\ngenerating massive data. The use of feature extraction helps\\nsimplify this dataset by identifying attributes. This approach\\nhas the advantage of reducing burdens and minimizing over-\\nfitting risks. When studying brain activity, EEG recordings\\nare typically collected from individuals with brain function\\nand those with conditions, resulting in a large amount of data\\nfor analysis. EEG signal features represent values that capture\\nsignal characteristics observed at sampling frequencies\\nranging from 100 to 1000 Hz. The individual features are\\nthen aggregated into a feature vector. Extraction of features\\nfrom either an EEG signal or a collection of signals requires\\nthe application of diverse methodologies. Feature engineering\\nmethods prepare the data for classification stages, enabling\\nthe identification of synchronization instances, recognition\\nof prominent low-frequency bands during peak periods,\\nand identification of frequencies indicative of specific\\npathologies, like epilepsy, tumors, and injuries. Figure 13)\\ndepicts time-frequency and non-linear features. A summary\\nof the features used for automatic diagnosis of various brain\\ndisorders is summarized in Table 4.\\nA. TIME-DOMAIN FEATURES\\nVariable features of time-domain parameters [122] include\\nmean, median, variance, RMS, peak-to-peak, standard devia-\\ntion, auto-correlation, absolute value, and zero-crossing (ZC)\\n[147]. Below are a few more time domain features:\\n1) EEG histogram: It demonstrates the typical spre', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1720: ('es, like epilepsy, tumors, and injuries. Figure 13)\\ndepicts time-frequency and non-linear features. A summary\\nof the features used for automatic diagnosis of various brain\\ndisorders is summarized in Table 4.\\nA. TIME-DOMAIN FEATURES\\nVariable features of time-domain parameters [122] include\\nmean, median, variance, RMS, peak-to-peak, standard devia-\\ntion, auto-correlation, absolute value, and zero-crossing (ZC)\\n[147]. Below are a few more time domain features:\\n1) EEG histogram: It demonstrates the typical spread of\\nEEG.\\n2) The kurtosis of a frequency distribution curve repre-\\nsents the peak’s sharpness compared with that of a\\nGaussian curve.\\n3) Skewness: The degree to which the distribution curve\\ndeviates from what would be expected if the data were\\ndistributed according to a Gaussian distribution.\\n4) Fractal dimensions: This term is also known by its other\\nname, the Hurst exponent, and it refers to the capacity\\nof a time series to store information for a longer time.\\n5) Entropy characterizes the degree of randomness in the\\ntime series. It simultaneously specifies the uniformity\\nof the waves and the uncertainty of the alterations.\\n6) The Hjorth parameter measures the variability of\\nEEG derivatives, such as mobility coefficient and\\ncomplexity coefficient [148].\\n7) K-complexes [136] are standard waveforms in\\nnon-rapid eye phase two.\\nFIGURE 13. Representation of Signals (a) with respect to time and\\n(b) with respect to frequency [146].\\nB. FREQUENCY-DOMAIN FEATURES\\nThe frequency domain is where signals are analyzed\\nbased on frequency rather than time. A frequency-domain\\nrepresentation has amplitude and phase of the signal’s\\nfrequency components. Specifically, this representation can\\ninclude information on the phase shift required to recombine\\nthe frequency components and obtain the original time\\nsignal [137].\\nThe power spectral density (PSD) [129] can also be used\\nto get the features of the signal in the frequency domain.\\nFourier transforms [149], convert signals into sinusoidal\\ncomponents, where wavelet decomposition, a', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1721: ('ed on frequency rather than time. A frequency-domain\\nrepresentation has amplitude and phase of the signal’s\\nfrequency components. Specifically, this representation can\\ninclude information on the phase shift required to recombine\\nthe frequency components and obtain the original time\\nsignal [137].\\nThe power spectral density (PSD) [129] can also be used\\nto get the features of the signal in the frequency domain.\\nFourier transforms [149], convert signals into sinusoidal\\ncomponents, where wavelet decomposition, as explained in\\nSection Cincorporates a mother wavelet function into the\\ndecomposition process [134].\\nFourier Transform It involves decomposing the signal into\\nsub-spectral components covering the frequency spectrum.\\nThese subspectral components represent peaks with respect\\nto frequency. The peaks in this domain are then collected\\nand computed using the FFT algorithm, as given in Figure 14\\n[130].\\nC. TIME FREQUENCY FEATURES\\nAnalyzing a two-dimensional signal in both time and\\nfrequency domains is powerful because it can exhibit\\nnon-stationary characteristics [131], [148]. The spectral\\ncharacteristics of a signal can change over time, and it\\nis essential to observe frequency changes over time to\\nunderstand the signal better.\\nTime-frequency analysis provides a way to analyze signals\\nin time-frequency domains. One of the most straightfor-\\nward techniques for observing a signal and calculating its\\nfrequency components is the short-time Fourier transform\\nVOLUME 11, 2023 143127\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 4. A review of the features and feature extraction methods used for classification of brain disorders from EEG.\\n(STFT), which uses uniform separation and obtains a\\nspectrogram [131]. More sophisticated methods have also\\nbeen developed for data with uneven spacing, such as\\nwavelet transform [134], which uses variable window\\nsizes based on spectral frequencies and least-squares spec-\\ntral analysis. These techniques provide valuable insight\\nin', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1722: (' Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 4. A review of the features and feature extraction methods used for classification of brain disorders from EEG.\\n(STFT), which uses uniform separation and obtains a\\nspectrogram [131]. More sophisticated methods have also\\nbeen developed for data with uneven spacing, such as\\nwavelet transform [134], which uses variable window\\nsizes based on spectral frequencies and least-squares spec-\\ntral analysis. These techniques provide valuable insight\\ninto the spectral characteristics of a signal with respect\\nto time.1) SHORT TIME FOURIER TRANSFORM\\nSTFT, as illustrated in Figure 15, enables the description of\\nthe frequency information of a signal with respect to time,\\nthereby improving classification accuracy [132]. Unlike the\\nstandard FT, which evaluates the whole signal at once, STFT\\nuses time-shifting window frames [146] to divide the data\\ninto several short signals and then find its frequency contents\\nindividually.\\n143128 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 14. An EEG signal with its Fourier Transform [150].\\nFIGURE 15. (a) EEG signal, (b) STFT of the signal [151].\\n2) PROGRESSIVE FOURIER TRANSFORM (PFT)\\nThe Progressive Fourier Transform (PFT) [152], as depicted\\nin Figure 16, is an innovative technique in time-frequency\\nanalysis based on the concept of the Short-Time Fourier\\nTransform (STFT). It efficiently converts time-domain sig-\\nnals into the frequency domain by adaptively considering\\na specific window of values. PFT gradually computes the\\nSTFT by sliding a predetermined window size across the\\nsignal, focusing solely on the values within the window.\\nThe rest of the signal values outside the window are\\neffectively disregarded. PFT is a valuable tool for analyzing\\ntime-frequency characteristics in signals using the following\\nequation:\\nX(f,u)=/integraldisplayu\\n−∞e−j2π ftx(t)1{t<u}dt (5)\\nwhere fandurepresent the signal frequency and time; eis a\\nmathematical constant that', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1723: ('aptively considering\\na specific window of values. PFT gradually computes the\\nSTFT by sliding a predetermined window size across the\\nsignal, focusing solely on the values within the window.\\nThe rest of the signal values outside the window are\\neffectively disregarded. PFT is a valuable tool for analyzing\\ntime-frequency characteristics in signals using the following\\nequation:\\nX(f,u)=/integraldisplayu\\n−∞e−j2π ftx(t)1{t<u}dt (5)\\nwhere fandurepresent the signal frequency and time; eis a\\nmathematical constant that represents the base of the natural\\nlogarithm; jis an imaginary unit; and 1 t∈I(t) is equal to one\\niftbelongs to the interval Iand is zero otherwise [152]\\n3) WAVELET TRANSFORM (WT)\\nThe WT is an extension of the Fourier transform that\\novercomes the limitations of STFT by providing multi-\\nscale analysis, as shown in Figure 17. In WT, the signal is\\ndivided into a family of basis functions known as wavelets,\\nwhich are then used to reconstruct the original signal. This\\ndecomposition process allows for identifying low-frequency\\nFIGURE 16. PFT [152].\\nand high-frequency components of the signal at different\\nscales.\\nWavelets can be created from an existing wavelet by\\nstretching, compressing, and reshaping the mother wavelet,\\nwhich makes it possible to customize wavelets to fit specific\\nsignal characteristics [133]. This flexibility, combined with\\nthe ability to analyze signals at different scales, makes\\nwavelet analysis a powerful tool for signal processing and\\nanalysis.\\na: MOTHER WAVELET\\nψa,b=1√aψ/parenleftbigt−b\\na/parenrightbig\\n;a>0,−∞<b<∞\\nwhere ais the scale parameter and bdetermines the location\\nof the wavelet [153].\\nThe WT delivers precise frequency information at low\\nfrequencies and accurate time information at high frequencies\\nusing 3D representations. Numerous mother wavelets are\\nused in a wide variety of WT types used in practice. Below\\nare some types used with EEG signals.\\nb: CONTINUOUS WAVELET TRANSFORM (CWT)\\nThe Continuous Wavelet Transform (CWT) technique ana-\\nlyzes non-stationary signals by examining signa', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1724: ('arenrightbig\\n;a>0,−∞<b<∞\\nwhere ais the scale parameter and bdetermines the location\\nof the wavelet [153].\\nThe WT delivers precise frequency information at low\\nfrequencies and accurate time information at high frequencies\\nusing 3D representations. Numerous mother wavelets are\\nused in a wide variety of WT types used in practice. Below\\nare some types used with EEG signals.\\nb: CONTINUOUS WAVELET TRANSFORM (CWT)\\nThe Continuous Wavelet Transform (CWT) technique ana-\\nlyzes non-stationary signals by examining signal portions at\\ndifferent scales and positions. Unlike the traditional Fourier\\nTransform, which focuses on frequency components, the\\nCWT captures the frequency content of the signal at varying\\nresolutions by convolving it with a scaled and translated\\nversion of a mother wavelet function, often the ‘‘Morlet’’\\nfunction [154]. This adaptability enables the CWT to\\naccommodate the dynamic characteristics of non-stationary\\nsignals, making it a valuable tool in signal processing, image\\nanalysis, time-series analysis, and biomedical signal analysis.\\nThe resulting scalogram provides a visual representation of\\nthe signal’s energy distribution across different scales and\\ntimes [134] as seen in Figure 18, aiding in the identification of\\nlocalized frequency variations and time-frequency patterns.\\nBy continuously varying the location and scale parameters,\\nthe CWT allows for selecting and examining different signal\\nparts for different scale variations. Overall, the CWT and\\nscalograms offer valuable insights into the complex dynamics\\nof time-varying signals.\\nWf(a,b)=/integraltext∞\\n−∞f(t)ψ∗\\na,b(t)dt=1√a/integraltext∞\\n−∞ψ∗\\na,b/parenleftbigt−b\\na/parenrightbig\\nf(t)dt\\nVOLUME 11, 2023 143129\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 17. (a) EEG signal- awake, (b) Wavelet Transform [155].\\nFIGURE 18. Scalograms for Alzheimer and Parkinson.\\nc: DWT\\nDifferent mother wavelets can be used with DWT, and\\nwavelet scales and translations can be customized dependingon the sampled ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1725: ('ynamics\\nof time-varying signals.\\nWf(a,b)=/integraltext∞\\n−∞f(t)ψ∗\\na,b(t)dt=1√a/integraltext∞\\n−∞ψ∗\\na,b/parenleftbigt−b\\na/parenrightbig\\nf(t)dt\\nVOLUME 11, 2023 143129\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 17. (a) EEG signal- awake, (b) Wavelet Transform [155].\\nFIGURE 18. Scalograms for Alzheimer and Parkinson.\\nc: DWT\\nDifferent mother wavelets can be used with DWT, and\\nwavelet scales and translations can be customized dependingon the sampled value for an efficient signal decomposi-\\ntion [153]. An important difference between the DWT and\\nCWT is that the signal is broken up into a collection of\\nwavelets that are orthogonal to one another across all discrete\\nscales by using the DWT transform. This is expressed as\\nfollows:\\nψi,k(u)=2−i/2ψ/parenleftbig\\n2−iu−k/parenrightbig\\nThe coefficients are obtained using the following expression:\\nWi,k=W/parenleftbig\\n2i,k2i/parenrightbig\\n=2−i/2/integraltext∞\\n−∞f(u)ψ/parenleftbig\\n2−iu−k/parenrightbig\\ndu\\nd: WAVELET PACKET DECOMPOSITION (WPD)\\nWPD is a general form of the wavelet decomposition, Fig-\\nure 19, it gives a richer signal analysis and a higher frequency\\nresolution [156], decomposing both the approximation and\\ndetail components of the signal at every level using two-scale\\nequations [157].\\nψ2i\\nj,k(t)=1√\\n2ψ2i/parenleftbigg2jk−t\\n2j/parenrightbigg\\n=/summationdisplay\\nnh(n)ψi\\nj−1,2k −n(t)\\nψ2i+1\\nj,k(t)=1√\\n2ψ2i+1/parenleftbigg2jk−t\\n2j/parenrightbigg\\n=/summationdisplay\\nng(n)ψi\\nj−1,2k −n(t)\\nwhere iis the node’s counter, jis the level of decomposition;\\nhandgrepresent filters used as quadrature mirrors. The\\ncoefficients are computed using recursion equations [157].\\nFIGURE 19. Wavelet packet decomposition of an electroencephalogram\\n(up to level 3) [135].\\nD. NON-LINEAR FEATURES\\nThe complex nature of the brain’s electrical activity and\\nits non-linear dynamic characteristics result in diverse EEG\\npatterns. Breaking down the signal into smaller subsystems\\ncan potentially modify the irregular patterns and dynamic\\nattributes of the', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1726: ('jis the level of decomposition;\\nhandgrepresent filters used as quadrature mirrors. The\\ncoefficients are computed using recursion equations [157].\\nFIGURE 19. Wavelet packet decomposition of an electroencephalogram\\n(up to level 3) [135].\\nD. NON-LINEAR FEATURES\\nThe complex nature of the brain’s electrical activity and\\nits non-linear dynamic characteristics result in diverse EEG\\npatterns. Breaking down the signal into smaller subsystems\\ncan potentially modify the irregular patterns and dynamic\\nattributes of the signal. Thus, different non-linear statistical\\nfeatures are extracted from EEG [215]. Fractal geometry\\nprovides a perspective for studying EEG signals due to\\nthe property of self-similarity or scaling invariance. Several\\nfractal dimensions can be estimated in EEG signal analysis\\nusing multifractal time-series analysis, such as the Hurst\\nexponent [158], [159], Renyi scaling exponent [148], [160],\\n[161], Katz fractal dimension (KFD) [162], Petrosian fractal\\n143130 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\ndimension (PFD) [163], and Higuchi fractal dimension\\n(HFD) [164]. Similarly, Hjorth’s parameters can discriminate\\nEEG based on their slope, amplitude, and complexity [165].\\nThese features are helpful in EEG analysis for medical\\ndiagnosis and achieve high accuracy in classifying diseases.\\nThe Lyapunov exponent (LE) [166] is a number that\\nmeasures the linearity, complexity, and stability of a dynamic\\nsystem by evaluating the exponential divergence between\\ntwo trajectories over time [119]. Non-linear features of the\\nLyapunov exponent can be extracted using WT [167], EMD,\\nand multivariate EMD [168]. These features can then be fed\\ninto the Hilbert transform [169] for classification. Similarly,\\nthe divergence (Div) follows a similar trend [170]. Another\\nmeasure is the entropy of the recurrence plot.\\nE. ENTROPIES\\nThe entropy, first introduced by Shannon [171] in 1948,\\nmeasures the randomness or uncertainty of the data using\\nthe equations −sum ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1727: (' divergence between\\ntwo trajectories over time [119]. Non-linear features of the\\nLyapunov exponent can be extracted using WT [167], EMD,\\nand multivariate EMD [168]. These features can then be fed\\ninto the Hilbert transform [169] for classification. Similarly,\\nthe divergence (Div) follows a similar trend [170]. Another\\nmeasure is the entropy of the recurrence plot.\\nE. ENTROPIES\\nThe entropy, first introduced by Shannon [171] in 1948,\\nmeasures the randomness or uncertainty of the data using\\nthe equations −sum jpjlog/parenleftbig\\npj/parenrightbig\\n, where pjis the pdf of the\\nsignals. Different forms of information entropy are utilized\\nin EEG analysis to isolate relevant data from the background\\nnoise [172]. Several entropies can be used to analyze\\nEEG data. These include Renyi’s entropy [173] given as\\n−α\\n1−α/summationtextlogpα\\nk, with α > 0 and α̸=1 and Tsallis’\\nentropy [174] given byk\\nq−1/parenleftbig\\n1−/summationtext\\nipq\\ni/parenrightbig\\n, with kas a positive\\nconstant and qis the nonextensity parameter. Later entropies\\nserve as a basis for calculating other entropies such as\\nKraskov’s entropy [50], spectral entropy [175], and Renyi’s\\nspectral entropy [176]. Log energy entropy (LogEn) and\\nwavelet entropy (WE) are similar to spectral entropy but\\ndiffer in a few important aspects. Meanwhile, Kolmogorov’s\\nentropy [177] is calculated by adding the positive Lyapunov\\nexponents, which makes it computationally difficult. Entropy\\nis the rate at which information is lost, as well as the regularity\\nof the attractor. There are several methods to estimate Kol-\\nmogorov’s entropy [178] with less computational expense,\\nincluding non-linear forecasting entropy [179], maximum-\\nlikelihood entropy [180], and approximate entropy (ApEn)\\n[181].\\nVII. CLASSIFICATION OF BRAIN DISORDERS USING\\nTRADITIONAL ML AND DL APPROACHES\\nML techniques can be applied to classify EEG for various\\nbrain disorders. This can be done using supervised or\\nunsupervised learning methods. Supervised learning (SL)\\nmethods use input and output data to train models that c', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1728: ('several methods to estimate Kol-\\nmogorov’s entropy [178] with less computational expense,\\nincluding non-linear forecasting entropy [179], maximum-\\nlikelihood entropy [180], and approximate entropy (ApEn)\\n[181].\\nVII. CLASSIFICATION OF BRAIN DISORDERS USING\\nTRADITIONAL ML AND DL APPROACHES\\nML techniques can be applied to classify EEG for various\\nbrain disorders. This can be done using supervised or\\nunsupervised learning methods. Supervised learning (SL)\\nmethods use input and output data to train models that can\\nestimate the outcome of unseen data. Unsupervised learning\\nuses data to find patterns or clusters in it.\\nSL methods are typically more accurate than unsupervised\\nfor diagnosing brain disorders from EEG signals. However,\\nthe accuracy of a single classification method can be limited\\nto specific use cases. Multimodal integration algorithms that\\ncombine multiple classification methods can also be used to\\nimprove accuracy.ML algorithms can lead to bias, which can affect accuracy.\\nML methods have been used to classify EEG signals for\\ndiagnosing diseases (e.g., epilepsy, Alzheimer’s, Parkinson’s,\\ndepression, stroke) and rehabilitation interventions.\\nReliable classification techniques are pivotal in enhancing\\nour comprehension of real-world signal analysis applications\\nin medical diagnosis. Various supervised machine learn-\\ning classifiers are frequently employed for this purpose,\\nencompassing linear/non-linear classifiers, non-linear Bayes\\nclassifiers, neural networks, nearest-neighbor classifiers, and\\nhybrid classifiers such as Support Vector Machines (SVM)\\ncombined with nearest-neighbor methods [8]. SVM and\\nnearest neighbors are used in almost 40 percent of the studies.\\nA detailed list of the classification methods used for\\nclassifying various brain disorders is listed in Table 5.\\nA. LINEAR CLASSIFIERS\\nLinear classifiers employ algorithms based on linear discrim-\\ninants to classify a collection of data points by combining\\nthe predictor variables linearly to distinguish between various\\nclasses. Examples of such li', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1729: ('ssifiers such as Support Vector Machines (SVM)\\ncombined with nearest-neighbor methods [8]. SVM and\\nnearest neighbors are used in almost 40 percent of the studies.\\nA detailed list of the classification methods used for\\nclassifying various brain disorders is listed in Table 5.\\nA. LINEAR CLASSIFIERS\\nLinear classifiers employ algorithms based on linear discrim-\\ninants to classify a collection of data points by combining\\nthe predictor variables linearly to distinguish between various\\nclasses. Examples of such linear classifiers include SVM and\\nLDA.\\n1) LINEAR DISCRIMINANT ANALYSIS (LDA)\\nIt is an approach that employs hyperplanes to classify EEG\\ndata, as illustrated in Figure 20. This method involves seg-\\nregating classes by leveraging their respective mean values\\nwhile maximizing their separation distance. Nevertheless,\\nLDA’s effectiveness diminishes when dealing with intricate\\nnon-linear EEG signals, and it can also be susceptible to\\noverfitting issues [182].\\nFIGURE 20. Feature separation using LDA [183].\\n2) SUPPORT VECTOR MACHINE(SVM)\\nSVMs use a discriminant hyperplane to determine classes\\nwith higher speed, better performance, and better generaliza-\\ntion abilities while maximizing the margin and varying the\\nkernel value, as shown in Figure 21.\\nWhen the hyperplane dimension changes from 1D to the nth\\ndimension, differentiation becomes challenging. However,\\nVOLUME 11, 2023 143131\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 21. SVM classification of ictal and non-ictal EEG data [184].\\nwith the kernel trick, SVM can be used for non-linear data\\nclassifications [103]. The Kernel function G(x,y) provides\\na mapping to a higher dimension. Generally, three types\\nof kernels are selected for data: linear kernels, polynomial\\nkernels, Gaussian kernels, and radial basis functions.\\nK(x,y)=exp/parenleft\\uf8ecig\\n−∥x−y∥2\\n2σ2/parenright\\uf8ecig\\nB. NON-LINEAR BAYESIAN CLASSIFIERS\\nThese are classifiers based on Bayes’ theorem and involve\\nprobabilistic reasoning. They are employed for', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1730: ('al and non-ictal EEG data [184].\\nwith the kernel trick, SVM can be used for non-linear data\\nclassifications [103]. The Kernel function G(x,y) provides\\na mapping to a higher dimension. Generally, three types\\nof kernels are selected for data: linear kernels, polynomial\\nkernels, Gaussian kernels, and radial basis functions.\\nK(x,y)=exp/parenleft\\uf8ecig\\n−∥x−y∥2\\n2σ2/parenright\\uf8ecig\\nB. NON-LINEAR BAYESIAN CLASSIFIERS\\nThese are classifiers based on Bayes’ theorem and involve\\nprobabilistic reasoning. They are employed for predict-\\ning probabilities of class membership, thereby facilitating\\nclass classification. However, their computational demands\\nbecome significant when dealing with numerous items and\\nsituations involving zero probabilities, which represents\\ntheir main limitation. The two prevalent forms of Bayesian\\nclassifiers are Bayesian quadratics and Markov models, also\\nknown as Hidden Markov Models (HMM) [182]. These\\nclassifiers are used for EEG classification for various brain\\ndisorders, including epilepsy and Alzheimer’s.\\n1) BAYES QUADRATIC\\nThe Bayes Quadratic algorithm is used to determine the most\\nlikely class for the feature vector [182]. It is mostly used in\\nmental task classification.\\n2) HIDDEN MARKOV MODEL (HMM)\\nIt is an intelligent classifier for social network sequence clas-\\nsification, speech recognition, and analysis [185]. It predicts\\nunknown data points from given input data points.\\nC. NEAREST NEIGHBOR CLASSIFIERS\\nNearest-neighbor classifiers are successful for a large number\\nof classification problems. It uses uniform weights, which\\nmeans looking at the samples closest in the distance to the\\nnew point to predict its label.\\nK-Nearest Neighbor (KNN) is a straightforward method to\\ngauge the probability of a data point’s association with aparticular group. This determination is based on the nearest\\nneighbor principle, as depicted in Figure 22. However,\\nKNN’s efficacy diminishes when confronted with datasets\\nthat possess high dimensions or are substantial in size, owing\\nto the considerable prediction expenses i', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1731: ('t uses uniform weights, which\\nmeans looking at the samples closest in the distance to the\\nnew point to predict its label.\\nK-Nearest Neighbor (KNN) is a straightforward method to\\ngauge the probability of a data point’s association with aparticular group. This determination is based on the nearest\\nneighbor principle, as depicted in Figure 22. However,\\nKNN’s efficacy diminishes when confronted with datasets\\nthat possess high dimensions or are substantial in size, owing\\nto the considerable prediction expenses involved. Primarily,\\nKNN finds its utility in pattern recognition and statistical\\nestimation [8].\\nFIGURE 22. K-nearest neighbor [186].\\nThese classifiers are utilized by the researchers to automat-\\nically diagnose brain disorders, including ADHD, epilepsy,\\nAlzheimer’s, Parkinson’s, sleep apnea, etc. The use of these\\nstate-of-the-art classifiers for automatically detecting these\\ndiseases is discussed in the next section.\\nD. DEEP LEARNING-BASED CLASSIFICATION OF BRAIN\\nDISORDERS FROM EEG\\nDue to the non-stationary nature of EEG, a classifier trained\\non a smaller dataset from one particular individual may\\nnot be able to generalize well to data collected from the\\nsame subject at a different time. This is a challenge for\\ntraditional machine learning classifiers to classify brain\\ndisorders from EEG, which may have to work with a limited\\nnumber of data. Another problem with EEG signals is the\\nhigh degree of inter-subject variability, which degrades the\\nperformance of traditional ML algorithms discussed in the\\nabove subsections. The reason for this phenomenon is that\\nthere are physiological differences between individuals. The\\nvariability of EEG signals across subjects can be challenging\\nfor models trained to generalize to new subjects [187].\\nTraditional machine learning methods for processing EEG\\ndata have limitations, such as limited generalization capabil-\\nities and flexibility. Deep learning (DL) could significantly\\nimprove the processing of EEG data by automatically learn-\\ning end-to-end pipelines that include automat', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1732: ('ections. The reason for this phenomenon is that\\nthere are physiological differences between individuals. The\\nvariability of EEG signals across subjects can be challenging\\nfor models trained to generalize to new subjects [187].\\nTraditional machine learning methods for processing EEG\\ndata have limitations, such as limited generalization capabil-\\nities and flexibility. Deep learning (DL) could significantly\\nimprove the processing of EEG data by automatically learn-\\ning end-to-end pipelines that include automatic extraction\\nof features and diagnosis of diseases directly from EEG.\\nThis could lead to better performance in diagnosis of various\\ndiseases. DL models are very effective in dealing with\\ncomplex data, such as text, audio images, and biomedical\\nsignals/images. DL models have high performance on\\nmultiple public benchmark challenges [188], Deep Learning\\ndelves into the exploration of computational models that\\n143132 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nacquire layered representations of input data. These repre-\\nsentations are constructed by means of sequential non-linear\\nconversions [188]. Deep neural networks are frameworks\\nin which (1) successive tiers of artificial ‘neurons’ employ\\nlinear transformations on incoming data, and (2)the output of\\neach tier is channeled across non-linear activation functions.\\nSignificantly, the parameters steering the transformations are\\nfine-tuned by minimizing a defined cost function. Figure 23\\ndepicts the architecture of a deep learning model having\\nEEG signals as input, with deep layers and the output\\nclassification layer, which give the classification probabilities\\nfor each class, i.e., the brain disease. Different DL models like\\nauto-encoders (AE), Generative adversarial networks (GAN),\\nTransformers, Recurrent Neural Networks, etc., are different\\nvariants of the DL that are used for EEG analysis. Some of\\nthe DL model diagnoses of brain disorders like Alzheimer’s,\\nParkinson’s, epilepsy, etc. are l', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1733: ('icts the architecture of a deep learning model having\\nEEG signals as input, with deep layers and the output\\nclassification layer, which give the classification probabilities\\nfor each class, i.e., the brain disease. Different DL models like\\nauto-encoders (AE), Generative adversarial networks (GAN),\\nTransformers, Recurrent Neural Networks, etc., are different\\nvariants of the DL that are used for EEG analysis. Some of\\nthe DL model diagnoses of brain disorders like Alzheimer’s,\\nParkinson’s, epilepsy, etc. are listed at the bottom of\\nTables 4and5. Graph neural networks (GNN), auto-encoders\\n(AE), Recurrent neural networks (RNN), Deep belief net-\\nworks (DBN), Convolutional neural networks (CNN), Long\\nshort term memory (LSTM), and optimized deep neural\\nnetworks are used for diagnosis of epilepsy and other brain\\ndisorders. These are discussed in the next subsections.\\n1) CONVOLUTIONAL NEURAL NETWORKS (CNNS)\\nCNNs have four primary feature layers, with the first layer\\nbeing a convolutional layer that comprises multiple feature\\nmaps [189] and a ReLU layer that trains several times faster\\nby changing all negative activation values to zero using the\\nformula f(x) = max(x,0) [190]. Pooling layers reduce the\\ndimensionality of feature maps, which makes the feature\\nextraction more robust to noise and distortions. The fully\\nconnected layer is the final output layer, which incorporates\\nall neurons from previous layers. An example of CNN is\\nshown in, Figure 23.\\nFIGURE 23. Architecture of CNN for automatic diagnosis of brain\\ndisorders using EEG.\\n2) GRAPH NEURAL NETWORKS (GNNS)\\nGNNs are ANNs that can learn from data hat is organized\\nas a graph. In recent years, GNNs have been applied to\\ndetect brain disorders from EEG signals. In [191], the author\\nused GNN to classify Alzheimer’s Disease from EEG. They\\nused Functional-Connectivity-Based Brain Graph Inference\\nas input to GNNs. The EEG is used to represent the brain as\\na graph network, with the electrode as a node, and the time\\nsamples recorded for each electrode are the features of thatno', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1734: (' using EEG.\\n2) GRAPH NEURAL NETWORKS (GNNS)\\nGNNs are ANNs that can learn from data hat is organized\\nas a graph. In recent years, GNNs have been applied to\\ndetect brain disorders from EEG signals. In [191], the author\\nused GNN to classify Alzheimer’s Disease from EEG. They\\nused Functional-Connectivity-Based Brain Graph Inference\\nas input to GNNs. The EEG is used to represent the brain as\\na graph network, with the electrode as a node, and the time\\nsamples recorded for each electrode are the features of thatnode. They achieved an accuracy of 98.4% for Alzheimer’s\\ndetection.\\n3) RECURRENT NEURAL NETWORKS (RNNS)\\nRNNs are deep-learning models that have been around for\\ndecades. However, their full potential was not realized until\\nthe 1990s when long short-term memory (LSTMs) were\\nadvanced. LSTMs are able to learn longer dependencies,\\nwhich is essential for time series classification like EEG and\\nother biomedical signals. RNNs are similar to the human\\nbrain in their behavior because they can process sequential\\ndata, which is something that the human brain is very good\\nat. An example of RNN models is shown in Figure 24.\\nFIGURE 24. Structure of RNNS.\\nVIII. CURRENT STATE-OF-THE-ART\\nThis section provides an extensive review of the current\\nstate of the art in EEG analysis for seizure and other\\nbrain disorders detection from 2017 to 2023, focusing on\\nthe studies published in Science Direct, Web of Science,\\nPubMed, and IEEE Xplore databases, summarized in Table 5.\\nThe studies were screened and filtered in three iterations to\\nexclude duplicates and articles outside the scope according\\nto their titles, abstracts, and domain.\\nSharma and Pachori [192] proposed a tunable Q-wavelet-\\ntransform (TQWT) method based on a single-channel dataset\\nfrom the University of Bonn. This method decomposes the\\nEEG signals into subbands, and the fractal dimensions (FDs)\\nare computed for each subband. The features are then fed to\\nthe least squares SVM. The authors achieved 100% accuracy\\nfor automatic detection of epilepsy, but the method was not\\ntested', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1735: ('xclude duplicates and articles outside the scope according\\nto their titles, abstracts, and domain.\\nSharma and Pachori [192] proposed a tunable Q-wavelet-\\ntransform (TQWT) method based on a single-channel dataset\\nfrom the University of Bonn. This method decomposes the\\nEEG signals into subbands, and the fractal dimensions (FDs)\\nare computed for each subband. The features are then fed to\\nthe least squares SVM. The authors achieved 100% accuracy\\nfor automatic detection of epilepsy, but the method was not\\ntested on multi-channel EEG datasets.\\nGupta et al. [193] developed an automated system based on\\ndifference and flexible analytic wavelet transform for the\\nBern Barcelona database. After decomposing the signal into\\nsub-bands, cross correntropy, SURE entropy, and Log Energy\\nEntropy are entered into an SVM. The accuracy was 94.4%\\nfor this method. Similarly, the authors proposed a sparse\\ndiscriminative ensemble learning paradigm for emotion\\nrecognition from EEG [194], where kernel-based represen-\\ntations were calculated from training EEG recordings and\\nlinear discriminant objective functions for ensemble learning.\\nSVM showed better accuracy of 77.27% and 74.53% in the\\n2-class classification setting using the DEAP dataset.\\nFurthermore, Chen et al. [119] developed a new model that\\nidentifies the optimized DWT to improve the performance on\\nVOLUME 11, 2023 143133\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nTABLE 5. Summary of Machine and Deep Learning based methods for classification of brain disorder from EEG signals.\\nthe test data. To create an optimal setting for DWT, the authors\\ncombined factors: the mother wavelet, the frequency band,\\nthe decomposition level, and the features. The CHB-MIT\\ndatasets and UBonn were tested using this method. They\\nachieved 92.3% and 99.33% accuracy, respectively on these\\ndatasets.\\nHarender and Sharma [195] tested a wavelet-based tech-\\nnique over the University of Bonn single channel, where\\nthree statistical features were determined af', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1736: ('for classification of brain disorder from EEG signals.\\nthe test data. To create an optimal setting for DWT, the authors\\ncombined factors: the mother wavelet, the frequency band,\\nthe decomposition level, and the features. The CHB-MIT\\ndatasets and UBonn were tested using this method. They\\nachieved 92.3% and 99.33% accuracy, respectively on these\\ndatasets.\\nHarender and Sharma [195] tested a wavelet-based tech-\\nnique over the University of Bonn single channel, where\\nthree statistical features were determined after the wavelet\\ndecomposition. The authors claimed that KNN got an average\\naccuracy of 97.50%, but they did not test their approach\\non CHB-MIT or any other multi-channel dataset. Madan\\net al. [196] employed a DWT to extract features from the\\nBonn dataset based on the Hurst exponent (HE). As a result\\nof their approach, the SVM produced a higher accuracy\\nof 99% compared to the KNN. Similarly, Lahmiri and\\nShmuel [197] presented a new automated detection system\\n(computer-aided diagnostic-CAD system) based on the Hurst\\nexponent to differentiate intracranial EEG with non-seizure\\nand seizure periods. Using KNN with tenfold cross-validationand testing on the Bonn dataset, they achieved 100%\\naccuracy. Tuncer [198] developed a novel biomedical EEG\\nclassification method called Hamsi-Pat that uses a non-linear\\nfeature extractor based on the Hamshi hash function of the\\nsubstitution box. A Hamsi-Pat feature generator, TQWT\\ndecomposition method, iterative neighborhood component\\nanalysis (INCA), and a kNN classifier were used in the\\nproposed method. The authors claimed 99.20% accuracy\\nfor five class cases and 100% accuracy for others on the\\nBonn dataset. Selvathi and Meera [210] achieved 95.6%\\naccuracy over the CHB MIT dataset by decomposing the EEG\\nsignal into seven levels using DWT and extracting statistical\\ncharacteristics of the alpha band for SVM classification.\\nWithin the same context, Omidvar and colleagues [199]\\nused DWT to divide the Bonn University dataset into\\nfive sub-bands and achieved 100% accuracy in two-class\\np', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1737: ('d in the\\nproposed method. The authors claimed 99.20% accuracy\\nfor five class cases and 100% accuracy for others on the\\nBonn dataset. Selvathi and Meera [210] achieved 95.6%\\naccuracy over the CHB MIT dataset by decomposing the EEG\\nsignal into seven levels using DWT and extracting statistical\\ncharacteristics of the alpha band for SVM classification.\\nWithin the same context, Omidvar and colleagues [199]\\nused DWT to divide the Bonn University dataset into\\nfive sub-bands and achieved 100% accuracy in two-class\\nproblems and 98.7% accuracy in three-class problems\\nby combining SVM and ANN. Similarly, using wavelet\\npacket decomposition (WPD) to extract statistical features,\\nAlbaqami et al. [200] utilized WPD to decrease the feature’s\\n143134 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\ndimension and demonstrated that GBDT could achieve an\\naccuracy of 87.68% on the TUH EEG Corpus dataset. EMD\\nand its derivatives were used in many studies as a baseline\\nmethod to divide EEG signals into intrinsic mode functions\\n(IMFs) and extract relevant features from those derivatives\\nto classify the signal. According to Cura et al. [201], using\\nEMD analysis, they achieved, 95.63%, 96.25%, 94.56% and\\n96.8%for KNN, logistic regression SVM and Naive Bayes\\nrespectively. Meanwhile, 96.06%, 97%, 97%, and 96.25% of\\nthe classifications were achieved using the EEMD and the\\nsame classifiers, respectively. Kaleem et al. [202] used a new\\nmodel on the CHB-MIT scalp EEG dataset, with accuracy,\\nsensitivity, and specificity values to achieve accuracy values\\nof 99.6%, 99.8%, and 99.6%, respectively. Wijayanto et\\nal.[203] claimed to achieve 99.7% accuracy using the\\nBonn University dataset with five IMFs, FD, and SVM in\\ncombination with EMD. Belhadj et al. [204] used the EMD\\ntool and the rapid potential-based hierarchical agglomerative\\n(PHA) clustering technique. The Euclidian, Batacharay, and\\nKolmogorov distances between the IMFs were calculated and\\nfed into the PHA cluster to achieve ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1738: ('with accuracy,\\nsensitivity, and specificity values to achieve accuracy values\\nof 99.6%, 99.8%, and 99.6%, respectively. Wijayanto et\\nal.[203] claimed to achieve 99.7% accuracy using the\\nBonn University dataset with five IMFs, FD, and SVM in\\ncombination with EMD. Belhadj et al. [204] used the EMD\\ntool and the rapid potential-based hierarchical agglomerative\\n(PHA) clustering technique. The Euclidian, Batacharay, and\\nKolmogorov distances between the IMFs were calculated and\\nfed into the PHA cluster to achieve an accuracy of 98.84%\\nover the CHB-MIT datasets. In their study, Wang et al. [205]\\nused a directed transfer function-based method for detecting\\nepilepsy. They used the sliding window technique and the\\nDFT method to determine cerebral function connectivity\\nand calculate the brain’s information outflow. The SVM\\nclassifier was later utilized to differentiate between ictal and\\ninterictal EEG signals with 98.45% accuracy. Multi-channel\\nEEG datasets such as those from Bonn.\\nGeorge et al. [206] proposed a tunable Q-wavelet transform-\\nbased method that divides a signal into sub-bands, entropies\\nbased on the non-linear features are calculated, optimal\\nfeatures are then selected using particle swarm optimization,\\nand ANN is then used to classify the signals. Over the Temple\\nUniversity Hospital (TUH) dataset, the method achieved\\n95.1% accuracy, 97.4% accuracy, and 88.8% accuracy.\\nShoeibi et al. [207] also proposed a novel procedure on\\nthe basis of deep learning and fuzzy logic. A tunable-Q-\\nwavelet transform is proposed to decompose the EEG into\\nsub-bands, and 13 different entropies are calculated and\\ntheir computational complexity is considered for the purpose\\nof choosing the best one. The dimensionality was reduced\\nusing a six-layer autoencoder (AE). Finally, for classification,\\nthe classic adaptive neuro-fuzzy inference system (ANFIS)\\ntechniques of the grasshopper optimization (ANFIS-GOA),\\nparticle swarm optimization (PSO), and breeding swarm\\noptimization (BSO) were utilized to achieve an accuracy\\nof 99.46% for the Bon', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1739: (' to decompose the EEG into\\nsub-bands, and 13 different entropies are calculated and\\ntheir computational complexity is considered for the purpose\\nof choosing the best one. The dimensionality was reduced\\nusing a six-layer autoencoder (AE). Finally, for classification,\\nthe classic adaptive neuro-fuzzy inference system (ANFIS)\\ntechniques of the grasshopper optimization (ANFIS-GOA),\\nparticle swarm optimization (PSO), and breeding swarm\\noptimization (BSO) were utilized to achieve an accuracy\\nof 99.46% for the Bonn EEG dataset and 99.28% for the\\nFreiburg EEG dataset.\\nThe classification technique NeuCube on the basis of spiking\\nANN was put forward by Luo et al. [208]. The authors\\nintegrated Ben’s spiker rule with other rules. The EEG data\\nwere processed using DWT and FFT for feature extraction.\\nAn SNN classifier was then used, with accuracies of 96.76%\\nfor the SEED dataset and 86.27% for the DEAP dataset.\\nIn their study, Mehla et al. [130] proposed the Fourierdecomposition method (FDM) for EEG classification. FDM\\nwas used to divide EEG data into Fourier intrinsic band\\nfunctions (FIBFs), and the Kruskal-Wallis test was applied\\nfor feature extraction. SVM was trained with the features and\\n99.96% and 99.94% accuracies were obtained for BONN and\\nCHB-MIT datasets.\\nIn[123], the authors proposed a model for epileptic EEG\\nclassification. The method combines random RF and CNN\\nfor the classification of epileptic seizures. The model was\\nvalidated using EEG signals of the Bonn dataset and Indian\\nNew Delhi dataset. The accuracy, specificity, and sensitivity\\nwere 99.9%, 99.80%, and 100%, respectively for the C-E\\ncase.\\nMany studies have used EEG signals and machine learning\\ntechniques to detect Parkinson’s disease (PD). 5, also summa-\\nrizes these studies, the models, and the results they obtained.\\nMost of these studies in used DL methods [124], [125], [209].\\nKhare [126] got higher accuracy using a smoothed pseudo-\\nWigner-Ville distribution of EEG combined with CNN with\\nan accuracy of 100%.\\nSeveral studies have demonstrated encouraging ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1740: ('ecificity, and sensitivity\\nwere 99.9%, 99.80%, and 100%, respectively for the C-E\\ncase.\\nMany studies have used EEG signals and machine learning\\ntechniques to detect Parkinson’s disease (PD). 5, also summa-\\nrizes these studies, the models, and the results they obtained.\\nMost of these studies in used DL methods [124], [125], [209].\\nKhare [126] got higher accuracy using a smoothed pseudo-\\nWigner-Ville distribution of EEG combined with CNN with\\nan accuracy of 100%.\\nSeveral studies have demonstrated encouraging outcomes in\\nthe identification of neurological disorders like Alzheimer’s\\ndisease. Although there is no specific cure for AD, the\\ntimely identification of the condition may help enhance the\\nquality of life for those affected. Fiscon and Weitschek\\nimplemented a methodology that leverages techniques for\\nextracting distinctive attributes and categorizing EEG [128].\\nThey differentiate between patients afflicted with AD, those\\nexperiencing mild AD, and individuals in a healthy group.\\nA total of 109 samples spanning AD, MCI, and HC categories\\nare converted to scalograms using both Fourier and Wavelet\\nTransforms. Through the utilization of Wavelet-based feature\\nextraction, they attained classification accuracies of 83% for\\nAD and normal cases,92% for health and mild AD cases, and\\n79% for Mild and AD classification scenarios.\\nIn[127], authors employed six computational techniques for\\nanalyzing time-series data i.e. EEG of 160 subjects with AD\\nand 24 with HC. Findings derived from both the original and\\nwavelet-filtered EEG signals to sub-bands indicate that some\\nvalidated methods, such as wavelet-coherence and quantile\\ngraphs, exhibit a robust capacity to differentiate between AD\\npatients and healthy elderly participants with high accuracy.\\nThe authors of [211] proposed graph theoretical approaches\\nto analyze brain functional or cortical connectivity from\\nEEG signals. Brain networks were modeled as graphs\\nbased on super edges [212], which take all possible paths\\nbetween a pair of nodes, allowing the characterization of\\n', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1741: ('d EEG signals to sub-bands indicate that some\\nvalidated methods, such as wavelet-coherence and quantile\\ngraphs, exhibit a robust capacity to differentiate between AD\\npatients and healthy elderly participants with high accuracy.\\nThe authors of [211] proposed graph theoretical approaches\\nto analyze brain functional or cortical connectivity from\\nEEG signals. Brain networks were modeled as graphs\\nbased on super edges [212], which take all possible paths\\nbetween a pair of nodes, allowing the characterization of\\nthe properties of the networks within the graphs. In the\\nproposed method, current densities of various dipoles were\\naveraged using linear inverse problems (distributed inverse\\nmethods) and Brodmann’s mapping criterion based on MRI\\nimages and EEG recordings. In the later stages, multivariate\\nautoregressive models (MV AR) were used to estimate the\\nfrequency domain, which was then modeled by a graph. After\\nusing PCA for dimensionality reduction and decorrelation\\nof heavily correlated measurements, each frequency band\\nVOLUME 11, 2023 143135\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nwas projected into a three-dimensional space, allowing for\\nfurther analysis and interpretation of the data. According to\\nthe results obtained for the dataset [213], [214], the p-value\\nyielded a value of 0.066.\\nIn the study titled ‘‘PFT: A Novel Time-Frequency Decompo-\\nsition of BOLD fMRI Signals for Autism Spectrum Disorder\\nDetection,’’ the authors of [152] proposed a new approach\\ncalled Progressive Fourier Transform (PFT) for detecting\\nAutism Spectrum Disorder (ASD) using fMRI signals. They\\nutilized the temporal dynamics of the BOLD (blood oxygen\\nlevel-dependent) data from specific brain areas for ASD\\ncategorization. The PFT was employed to derive the temporal\\ndynamic features of the BOLD signals. This approach aimed\\nto address the limitations of existing ASD detection systems\\nby incorporating time-frequency components and improving\\nfeature extraction and classification. The st', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1742: ('oach\\ncalled Progressive Fourier Transform (PFT) for detecting\\nAutism Spectrum Disorder (ASD) using fMRI signals. They\\nutilized the temporal dynamics of the BOLD (blood oxygen\\nlevel-dependent) data from specific brain areas for ASD\\ncategorization. The PFT was employed to derive the temporal\\ndynamic features of the BOLD signals. This approach aimed\\nto address the limitations of existing ASD detection systems\\nby incorporating time-frequency components and improving\\nfeature extraction and classification. The study used the\\nAutism Brain Imaging Data Exchange dataset for model\\nvalidation, demonstrating better results with the proposed\\nPFT model compared to existing models, including an\\nincrease in accuracy to 96.7%. This research highlights the\\npotential of the PFT technique for analyzing rs-fMRI data\\nfrom various brain diseases of the same type.\\nIn summary, various methods have been proposed for EEG\\nsignal processing and classification for various brain disor-\\nders, including time-frequency analysis, wavelet transforms,\\nempirical mode decomposition, spiking neural networks, and\\ngraph theoretical approaches. These methods are robust i and\\nhave the potential to be used for various applications, such as\\ndetecting epileptic seizures and analyzing brain connectivity.\\nFurther research and experimentation are necessary to\\nincrease the accuracy of these methods and to explore their\\napplicability for diagnosing other brain and neurological\\ndisorders.\\nIX. PROBLEMS, CHALLENGES AND WAY FORWARD\\nEEG of individuals or selected from a dataset can have a lot\\nof noise. This is because EEG signals are often multi-channel\\nand of longer duration. As a result, signal denoising,\\npreprocessing, and analysis can be challenging. Accurate\\ncomputer-based processing of EEG is also challenging due\\nto its low amplitude and susceptibility to high frequency and\\nother noises. In this work, we highlighted the main problems\\nand complexities caused by various common artifacts, their\\nautomatic detection, and attenuation methods in detail.\\nWe also discusse', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1743: ('m a dataset can have a lot\\nof noise. This is because EEG signals are often multi-channel\\nand of longer duration. As a result, signal denoising,\\npreprocessing, and analysis can be challenging. Accurate\\ncomputer-based processing of EEG is also challenging due\\nto its low amplitude and susceptibility to high frequency and\\nother noises. In this work, we highlighted the main problems\\nand complexities caused by various common artifacts, their\\nautomatic detection, and attenuation methods in detail.\\nWe also discussed the limitations of current signal processing\\nmethods and how they can be improved.\\nWe are of the opinion that a single model may not be able to\\nremove all possible artifacts from EEG. Thus the selection\\nof a proper filter and preprocessing technique for removal\\nof each possible noise is required. ML/DL-based techniques\\nmay be used in the future first to classify the type of noise\\ncontaminating EEG signals, and then in run time, a proper\\nfilter may be applied to attenuate the noise to get a better\\nquality signal. In some cases, the noise may only be present\\nin one portion of the EEG, which needs to be identified first,and then filtering may be applied to that portion of the EEG\\nonly.\\nThe second main challenge is the feature engineering step.\\nTraditional handcrafted feature engineering methods struggle\\nto detect reliable features from EEG signals due to low EEG\\namplitude and SNR. Another challenge is the selection of the\\nnumber of features, which increases the computational cost.\\nThus, the main challenges in EEG are computational cost,\\nhigh dimensionality, and classification accuracy for brain\\ndisorders. The best approach to overcome these challenges\\nis to select features depending on the specific application and\\nthe desired trade-off between processing time and accuracy.\\nWe propose that new optimization techniques may be applied\\nto EEG signals to select the most relevant features rather\\nthan using traditional EEG signal processing systems. This\\nincludes developing new feature selection and transformation\\nmetho', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1744: ('EEG are computational cost,\\nhigh dimensionality, and classification accuracy for brain\\ndisorders. The best approach to overcome these challenges\\nis to select features depending on the specific application and\\nthe desired trade-off between processing time and accuracy.\\nWe propose that new optimization techniques may be applied\\nto EEG signals to select the most relevant features rather\\nthan using traditional EEG signal processing systems. This\\nincludes developing new feature selection and transformation\\nmethods and improving the efficiency of existing methods.\\nRecently, ML/DL has proven to be immensely worthwhile\\nfor interpreting EEG signals. Nevertheless, the incorporation\\nof ML/DL techniques into clinical practices presents a range\\nof technical challenges. A primary hurdle involves achieving\\ndata standardization. The broad compatibility of EEG data is\\ninevitably hindered by variations in the types of EEG input\\ndata available, storage formats employed, and interpretation\\nprotocols applied. These variations stem from differences in\\ndata collection sources, whether from ambulatory devices,\\nbedside apparatus, or mobile devices, resulting in potential\\ndiscrepancies and divergences during data analysis. A sig-\\nnificant constraint faced by AI algorithms is their reliance\\non substantial amounts of high SNR data to yield correct\\noutcomes, especially when proposing models for managing\\nbrain disorders having limited datasets. Occasionally, the\\nSNR of the signals can be compromised by factors like\\nincompleteness, heterogeneity, or noise, thereby introducing\\nmissing values, redundancies, or data sparsity. Furthermore,\\nAI models typically demand advanced processors to function\\neffectively, leading to increased computational complexities.\\nAs a consequence, there exists a trade-off in the design of a\\nsystem.\\nEEG datasets are often small, which can make it difficult\\nto train machine learning algorithms. This is because EEG\\nsignals are typically recorded from a small number of\\nsubjects, and each subject may only have a limited amo', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1745: ('eity, or noise, thereby introducing\\nmissing values, redundancies, or data sparsity. Furthermore,\\nAI models typically demand advanced processors to function\\neffectively, leading to increased computational complexities.\\nAs a consequence, there exists a trade-off in the design of a\\nsystem.\\nEEG datasets are often small, which can make it difficult\\nto train machine learning algorithms. This is because EEG\\nsignals are typically recorded from a small number of\\nsubjects, and each subject may only have a limited amount\\nof data. This problem can be overcome by recording data for\\na relatively longer time but it is also sometimes not possible\\nif the subject has severe epilepsy episodes or other chronic\\nbrain disorders. Another challenge is high dimensionality:\\nEEG signals have a high dimensionality, i.e., signals are\\nrecorded with an electrode grid, with longer recordings. This\\ncan make it difficult to find the most important features\\nfor classification, and it can also make the training of\\nmachine learning algorithms computationally expensive. The\\nnon-stationary nature of EEG makes it difficult to classify\\nEEG signals, as the classifier needs to adapt to the unexpected\\nchanges in the data with respect to time. Inter-subject\\nvariability is also a big challenge which can make it difficult\\n143136 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nto develop a classifier that works for everyone. This is because\\nthe features important for classifying EEG signals in one\\nperson may not be important in another person. Even though\\nthese challenges exist there has been significant progress in\\nEEG processing in recent years. ML and DL algorithms, such\\nas SVM, RF, LSTM, and Hybrid CNN-LSTM, have been\\nshown to be helpful in classifying EEG signals for a variety of\\ndisorders. Recently developed transformer models may also\\nbe used to overcome these challenges.\\nX. CONCLUSION AND FUTURE WORK\\nThis paper provides an extensive overview of the most pop-\\nular datasets, feature do', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1746: ('s in one\\nperson may not be important in another person. Even though\\nthese challenges exist there has been significant progress in\\nEEG processing in recent years. ML and DL algorithms, such\\nas SVM, RF, LSTM, and Hybrid CNN-LSTM, have been\\nshown to be helpful in classifying EEG signals for a variety of\\ndisorders. Recently developed transformer models may also\\nbe used to overcome these challenges.\\nX. CONCLUSION AND FUTURE WORK\\nThis paper provides an extensive overview of the most pop-\\nular datasets, feature domains, artifacts, and preprocessing\\nmethods used to perform more accurate analyses of EEG\\nfor the automatic detection of brain disorders, especially\\nepilepsy. An examination of EEG characteristics and the\\nprocedures utilized to extract those characteristics, along\\nwith a discussion of the benefits and drawbacks of each\\nmethod, are presented in this article. In addition, this study\\nexamines the current trends regarding feature engineering\\nand classification techniques. Several academic papers have\\nprovided the source material for these methodologies and the\\nfindings associated with them. The time-frequency methods\\nof the EEG do not provide as much detail as the frequency\\ndomain methods, while the frequency domain approaches do\\nnot provide satisfactory performance for a number of signals.\\nTime-frequency is one of the most frequently utilized feature\\ndomains, and its analysis can be performed using either the\\nSTFT or CWT. It is important to choose accurate features and\\nmethods for analysis in accordance with the various mental\\ntasks that are being carried out to improve the results.\\nAs a future work, We believe that in the era of the medical\\ninternet of things, ML, and DL, EEG signal processing is\\npoised to undergo significant advances and transformative\\nchanges. IoT allows for seamless connectivity of EEG\\ndevices, enabling real-time monitoring of brain activity. This\\nis particularly valuable for remote patient monitoring, where\\nEEG data can be transmitted to healthcare professionals\\nfor timely diagnosis and inter', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1747: (' various mental\\ntasks that are being carried out to improve the results.\\nAs a future work, We believe that in the era of the medical\\ninternet of things, ML, and DL, EEG signal processing is\\npoised to undergo significant advances and transformative\\nchanges. IoT allows for seamless connectivity of EEG\\ndevices, enabling real-time monitoring of brain activity. This\\nis particularly valuable for remote patient monitoring, where\\nEEG data can be transmitted to healthcare professionals\\nfor timely diagnosis and intervention. Similarly, With the\\nincreasing processing capabilities of edge devices, it becomes\\nfeasible to perform initial preprocessing and feature extrac-\\ntion directly on EEG devices. This will reduce the need to\\ntransmit huge raw data, minimizing bandwidth requirements\\nand latency. In summary, the convergence of IoT, ML, and\\nDL technologies has the potential to revolutionize EEG signal\\nprocessing. This convergence opens up new opportunities\\nfor personalized healthcare, real-time monitoring, improved\\ndiagnostic accuracy, and a deeper understanding of brain\\nactivity and neurological conditions.\\nThis paper provides a holistic evaluation of the existing\\nEEG processing for medical diagnosis. It discusses several\\nimportant research works in detail and Serves as a resource\\nfor researchers in this field of EEG processing for the\\ndiagnosis of health conditions. It also provides insight for\\nfuture research on EEG analysis for healthcare. In con-\\nclusion, while there have been significant advancementsin EEG analysis techniques, there are still challenges\\nthat need to be addressed, such as artifact and noise\\nremoval. As machine learning and deep learning continue\\nto evolve, new approaches for robust artifact removal may\\nbecome available. Developing a noise-reduction method\\nand creating a custom metric for deep learning are also\\nproposed as future directions. Additionally, attention should\\nbe given to other neurological disorders beyond epilepsy\\nto find the best methods for EEG analysis. The use of\\ngraph neural networks an', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1748: ('chniques, there are still challenges\\nthat need to be addressed, such as artifact and noise\\nremoval. As machine learning and deep learning continue\\nto evolve, new approaches for robust artifact removal may\\nbecome available. Developing a noise-reduction method\\nand creating a custom metric for deep learning are also\\nproposed as future directions. Additionally, attention should\\nbe given to other neurological disorders beyond epilepsy\\nto find the best methods for EEG analysis. The use of\\ngraph neural networks and exploring new transformations\\nlike time-frequency decomposition are also suggested for\\nimproving EEG analysis. Overall, there is still much to be\\nexplored and developed in EEG analysis, and future research\\nshould continue to advance the field.\\nXI. CONFLICTS OF INTEREST\\nThe authors declare that they have no conflicts of interest.\\nREFERENCES\\n[1] W. O. Tatum, G. Rubboli, P. W. Kaplan, S. M. Mirsatari,\\nK. Radhakrishnan, D. Gloss, L. O. Caboclo, F. W. Drislane,\\nM. Koutroumanidis, D. L. Schomer, D. K.-N. Trenite, M. Cook,\\nand S. Beniczky, ‘‘Clinical utility of EEG in diagnosing and monitoring\\nepilepsy in adults,’’ Clin. Neurophysiol., vol. 129, no. 5, pp. 1056–1082,\\nMay 2018.\\n[2] M. Elsabbagh, A. Yusuf, J. Zeidan, J. Scorah, E. Fombonne, M. S. Durkin,\\nS. Saxena, and A. Shih, ‘‘The time has come for living systematic reviews\\nin autism research,’’ Autism Res., vol. 15, no. 7, pp. 1187–1188, Jul. 2022.\\n[3] T. Wang, Y. Ma, R. Li, J. Sun, L. Huang, S. Wang, and C. Yu, ‘‘Trends\\nof ischemic heart disease mortality attributable to household air pollution\\nduring 1990–2019 in China and India: An age-period-cohort analysis,’’\\nEnviron. Sci. Pollut. Res., vol. 29, pp. 87478–87489, Dec. 2022.\\n[4] C. J. Stam, ‘‘Nonlinear dynamical analysis of EEG and MEG: Review of\\nan emerging field,’’ Clin. Neurophysiol., vol. 116, no. 10, pp. 2266–2301,\\nOct. 2005.\\n[5] M. Orban, M. Elsamanty, K. Guo, S. Zhang, and H. Yang, ‘‘A review of\\nbrain activity and EEG-based brain–computer interfaces for rehabilitation\\napplication,’’ Bioengineering, vol. ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1749: ('butable to household air pollution\\nduring 1990–2019 in China and India: An age-period-cohort analysis,’’\\nEnviron. Sci. Pollut. Res., vol. 29, pp. 87478–87489, Dec. 2022.\\n[4] C. J. Stam, ‘‘Nonlinear dynamical analysis of EEG and MEG: Review of\\nan emerging field,’’ Clin. Neurophysiol., vol. 116, no. 10, pp. 2266–2301,\\nOct. 2005.\\n[5] M. Orban, M. Elsamanty, K. Guo, S. Zhang, and H. Yang, ‘‘A review of\\nbrain activity and EEG-based brain–computer interfaces for rehabilitation\\napplication,’’ Bioengineering, vol. 9, no. 12, p. 768, Dec. 2022. [Online].\\nAvailable: https://www.mdpi.com/2306-5354/9/12/768\\n[6] P. Wang, X. Cao, Y. Zhou, P. Gong, M. Yousefnezhad, W. Shao,\\nand D. Zhang, ‘‘A comprehensive review on motion trajectory\\nreconstruction for EEG-based brain-computer interface,’’ Frontiers\\nNeurosci., vol. 17, Jun. 2023, Art. no. 1086472. [Online]. Available:\\nhttps://www.frontiersin.org/articles/10.3389/fnins.2023.1086472\\n[7] H. Altaheri, G. Muhammad, M. Alsulaiman, S. U. Amin, G. A.\\nAltuwaijri, W. Abdul, M. A. Bencherif, and M. Faisal, ‘‘Deep learning\\ntechniques for classification of electroencephalogram (EEG) motor\\nimagery (MI) signals: A review,’’ Neural Comput. Appl., vol. 35, no. 20,\\npp. 14681–14722, Jul. 2023.\\n[8] S. Pahuja and K. Veer, ‘‘Recent approaches on classification and feature\\nextraction of EEG signal: A review,’’ Robotica, vol. 40, no. 1, pp. 77–101,\\nJan. 2022.\\n[9] J. D. Bronzino, ‘‘Quantitative analysis of the EEG-general concepts\\nand animal studies,’’ IEEE Trans. Biomed. Eng., vol. BME-31, no. 12,\\npp. 850–856, Dec. 1984.\\n[10] M. C. Houston, ‘‘Some aspects of a college health service,’’ Amer. J.\\nNursing, vol. 42, no. 10, pp. 1183–1189, Oct. 1942.\\n[11] P. L. Nunez, ‘‘Representation of evoked potentials by Fourier-\\nBessel expansions,’’ IEEE Trans. Biomed. Eng., vol. BME-20, no. 5,\\npp. 372–374, Sep. 1973.\\n[12] A. C. Sanderson, J. Segen, and E. Richey, ‘‘Hierarchical modeling of EEG\\nsignals,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. PAMI-2, no. 5,\\npp. 405–415, Sep. 1980.\\n[13] P. Herman, G. Prasad, T. ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1750: ('. 850–856, Dec. 1984.\\n[10] M. C. Houston, ‘‘Some aspects of a college health service,’’ Amer. J.\\nNursing, vol. 42, no. 10, pp. 1183–1189, Oct. 1942.\\n[11] P. L. Nunez, ‘‘Representation of evoked potentials by Fourier-\\nBessel expansions,’’ IEEE Trans. Biomed. Eng., vol. BME-20, no. 5,\\npp. 372–374, Sep. 1973.\\n[12] A. C. Sanderson, J. Segen, and E. Richey, ‘‘Hierarchical modeling of EEG\\nsignals,’’ IEEE Trans. Pattern Anal. Mach. Intell., vol. PAMI-2, no. 5,\\npp. 405–415, Sep. 1980.\\n[13] P. Herman, G. Prasad, T. M. McGinnity, and D. Coyle, ‘‘Comparative\\nanalysis of spectral approaches to feature extraction for EEG-based motor\\nimagery classification,’’ IEEE Trans. Neural Syst. Rehabil. Eng., vol. 16,\\nno. 4, pp. 317–326, Aug. 2008.\\nVOLUME 11, 2023 143137\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n[14] S. Biswal, J. Kulas, H. Sun, B. Goparaju, M. B. Westover, M. T. Bianchi,\\nand J. Sun, ‘‘SLEEPNET: Automated sleep staging system via deep\\nlearning,’’ 2017, arXiv:1707.08262.\\n[15] R. Hari and A. Puce, MEG-EEG Primer. Oxford, U.K.: Oxford Univ.\\nPress, 2017.\\n[16] D. L. Schomer and F. L. Da Silva, Niedermeyer’s Electroencephalog-\\nraphy: Basic Principles, Clinical Applications, and Related Fields.\\nPhiladelphia, PA, USA: Lippincott Williams & Wilkins, 2012.\\n[17] D. A. Engemann, F. Raimondo, J.-R. King, B. Rohaut, G. Louppe,\\nF. Faugeras, J. Annen, H. Cassol, O. Gosseries, D. Fernandez-Slezak,\\nS. Laureys, L. Naccache, S. Dehaene, and J. D. Sitt, ‘‘Robust EEG-based\\ncross-site and cross-protocol classification of states of consciousness,’’\\nBrain, vol. 141, no. 11, pp. 3179–3192, Nov. 2018.\\n[18] N. S. Bastos, B. P. Marques, D. F. Adamatti, and C. Z. Billa, ‘‘Analyzing\\nEEG signals using decision trees: A study of modulation of amplitude,’’\\nComput. Intell. Neurosci., vol. 2020, pp. 1–11, Jul. 2020.\\n[19] J. T. Giacino, J. J. Fins, S. Laureys, and N. D. Schiff, ‘‘Disorders of\\nconsciousness after acquired brain injury: The state of the science,’’\\nNature Rev. Neurol., vol. 10, no. 2,', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1751: ('te and cross-protocol classification of states of consciousness,’’\\nBrain, vol. 141, no. 11, pp. 3179–3192, Nov. 2018.\\n[18] N. S. Bastos, B. P. Marques, D. F. Adamatti, and C. Z. Billa, ‘‘Analyzing\\nEEG signals using decision trees: A study of modulation of amplitude,’’\\nComput. Intell. Neurosci., vol. 2020, pp. 1–11, Jul. 2020.\\n[19] J. T. Giacino, J. J. Fins, S. Laureys, and N. D. Schiff, ‘‘Disorders of\\nconsciousness after acquired brain injury: The state of the science,’’\\nNature Rev. Neurol., vol. 10, no. 2, pp. 99–114, Feb. 2014.\\n[20] S. Hagihira, ‘‘Changes in the electroencephalogram during anaesthesia\\nand their physiological basis,’’ Brit. J. Anaesthesia, vol. 115, pp. 27–31,\\nJul. 2015.\\n[21] F. Lotte, L. Bougrain, A. Cichocki, M. Clerc, M. Congedo,\\nA. Rakotomamonjy, and F. Yger, ‘‘A review of classification algorithms\\nfor EEG-based brain–computer interfaces: A 10 year update,’’ J. Neural\\nEng., vol. 15, no. 3, Jun. 2018, Art. no. 031005.\\n[22] M. Rashid, N. Sulaiman, A. P. P. Abdul Majeed, R. M. Musa,\\nA. F. A. Nasir, B. S. Bari, and S. Khatun, ‘‘Current status, challenges,\\nand possible solutions of EEG-based brain-computer interface: A com-\\nprehensive review,’’ Frontiers Neurorobotics, vol. 14, p. 25, Jun. 2020.\\n[23] N. Bigdely-Shamlo, T. Mullen, C. Kothe, K.-M. Su, and K. A. Robbins,\\n‘‘The PREP pipeline: Standardized preprocessing for large-scale EEG\\nanalysis,’’ Frontiers Neuroinform., vol. 9, p. 16, Jun. 2015.\\n[24] M. Jas, D. A. Engemann, Y. Bekhti, F. Raimondo, and A. Gramfort,\\n‘‘Autoreject: Automated artifact rejection for MEG and EEG data,’’\\nNeuroImage, vol. 159, pp. 417–429, Oct. 2017.\\n[25] D. Steyrl and G. R. Müller-Putz, ‘‘Artifacts in EEG of simultaneous EEG-\\nfMRI: Pulse artifact remainders in the gradient artifact template are a\\nsource of artifact residuals after average artifact subtraction,’’ J. Neural\\nEng., vol. 16, no. 1, Feb. 2019, Art. no. 016011.\\n[26] H. Zamanian and H. Farsi, ‘‘A new feature extraction method to improve\\nemotion detection using EEG signals,’’ ELCVIA Electron. Lett. Comput.\\nVis. I', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1752: ('ct rejection for MEG and EEG data,’’\\nNeuroImage, vol. 159, pp. 417–429, Oct. 2017.\\n[25] D. Steyrl and G. R. Müller-Putz, ‘‘Artifacts in EEG of simultaneous EEG-\\nfMRI: Pulse artifact remainders in the gradient artifact template are a\\nsource of artifact residuals after average artifact subtraction,’’ J. Neural\\nEng., vol. 16, no. 1, Feb. 2019, Art. no. 016011.\\n[26] H. Zamanian and H. Farsi, ‘‘A new feature extraction method to improve\\nemotion detection using EEG signals,’’ ELCVIA Electron. Lett. Comput.\\nVis. Image Anal., vol. 17, no. 1, pp. 29–44, Nov. 2018.\\n[27] K. D. Rao and D. C. Reddy, ‘‘On-line method for enhancement of\\nelectroencephalogram signals in presence of electro-oculogram artefacts\\nusing nonlinear recursive least squares technique,’’ Med. Biol. Eng.\\nComput., vol. 33, no. 3, pp. 488–491, May 1995.\\n[28] L. Cao, J. Li, Y. Sun, H. Zhu, and C. Yan, ‘‘EEG-based vigilance analysis\\nby using Fisher score and PCA algorithm,’’ in Proc. IEEE Int. Conf. Prog.\\nInformat. Comput., vol. 1, Dec. 2010, pp. 175–179.\\n[29] F. Lotte, L. Bougrain, and M. Clerc, ‘‘Electroencephalography (EEG)-\\nbased brain-computer interfaces,’’ in Wiley Encyclopedia of Elec-\\ntrical and Electronics Engineering. Wiley, 2015, p. 44. [Online].\\nAvailable: https://hal.archives-ouvertes.fr/hal-01167515, doi: 10.1002/\\n047134608X.W8278.\\n[30] A. Shoeb, CHB-MIT Scalp EEG Database. Accessed: Aug. 11, 2023.\\n[Online]. Available: http://physionet.org/pn6/chbmit/\\n[31] A. H. Shoeb, ‘‘Application of machine learning to epileptic seizure\\nonset detection and treatment,’’ Ph.D. dissertation, Massachusetts Inst.\\nTechnol., Cambridge, MA, USA, 2009.\\n[32] R. Hussein, S. Lee, R. Ward, and M. J. McKeown, ‘‘Epileptic seizure\\nprediction: A semi-dilated convolutional neural network architecture,’’ in\\nProc. 25th Int. Conf. Pattern Recognit. (ICPR), Jan. 2021, pp. 5436–5443.\\n[33] B. Hegermiller-Smith, P. Miller, A. Husain, and V. Neurodiagnostic,\\n‘‘American epilepsy society,’’ Epilepsia, vol. 50, no. 11, pp. 1–502, 2009.\\n[34] R. Rahman, S. M. Varnosfaderani, O. Makke, N. J. ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1753: ('eatment,’’ Ph.D. dissertation, Massachusetts Inst.\\nTechnol., Cambridge, MA, USA, 2009.\\n[32] R. Hussein, S. Lee, R. Ward, and M. J. McKeown, ‘‘Epileptic seizure\\nprediction: A semi-dilated convolutional neural network architecture,’’ in\\nProc. 25th Int. Conf. Pattern Recognit. (ICPR), Jan. 2021, pp. 5436–5443.\\n[33] B. Hegermiller-Smith, P. Miller, A. Husain, and V. Neurodiagnostic,\\n‘‘American epilepsy society,’’ Epilepsia, vol. 50, no. 11, pp. 1–502, 2009.\\n[34] R. Rahman, S. M. Varnosfaderani, O. Makke, N. J. Sarhan, E. Asano,\\nA. Luat, and M. Alhawari, ‘‘Comprehensive analysis of EEG datasets\\nfor epileptic seizure prediction,’’ in Proc. IEEE Int. Symp. Circuits Syst.\\n(ISCAS), May 2021, pp. 1–5.\\n[35] M. Ihle, H. Feldwisch-Drentrup, C. A. Teixeira, A. Witon, B. Schelter,\\nJ. Timmer, and A. Schulze-Bonhage, ‘‘Epilepsiae—A European epilepsy\\ndatabase,’’ Comput. Methods Programs Biomed., vol. 106, no. 3,\\npp. 127–138, 2012.[36] A. Miltiadous, K. D. Tzimourta, T. Afrantou, P. Ioannidis, N. Grigoriadis,\\nD. G. Tsalikakis, P. Angelidis, M. G. Tsipouras, E. Glavas,\\nN. Giannakeas, and A. T. Tzallas, ‘‘A dataset of scalp EEG recordings\\nof Alzheimer’s disease, frontotemporal dementia and healthy subjects\\nfrom routine EEG,’’ Data, vol. 8, no. 6, p. 95, 2023. [Online]. Available:\\nhttps://www.mdpi.com/2306-5729/8/6/95\\n[37] N. G. J. A. A. Rockhill, A. P. Jackson, and N. C. Swann, ‘‘UC San\\nDiego resting state EEG data from patients with Parkinson’s disease,’’\\nTech. Rep., 2021.\\n[38] A. Arsalan, M. Majid, A. R. Butt, and S. M. Anwar, ‘‘Classification of\\nperceived mental stress using a commercially available EEG headband,’’\\nIEEE J. Biomed. Health Informat., vol. 23, no. 6, pp. 2257–2264,\\nNov. 2019.\\n[39] G. Schalk, D. J. McFarland, T. Hinterberger, N. Birbaumer, and\\nJ. R. Wolpaw, ‘‘BCI2000: A general-purpose brain-computer interface\\n(BCI) system,’’ IEEE Trans. Biomed. Eng., vol. 51, no. 6, pp. 1034–1043,\\nJun. 2004.\\n[40] S. Koelstra, C. Muhl, M. Soleymani, J.-S. Lee, A. Yazdani, T. Ebrahimi,\\nT. Pun, A. Nijholt, and I. Patras, ‘‘DEAP: A datab', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1754: ('Classification of\\nperceived mental stress using a commercially available EEG headband,’’\\nIEEE J. Biomed. Health Informat., vol. 23, no. 6, pp. 2257–2264,\\nNov. 2019.\\n[39] G. Schalk, D. J. McFarland, T. Hinterberger, N. Birbaumer, and\\nJ. R. Wolpaw, ‘‘BCI2000: A general-purpose brain-computer interface\\n(BCI) system,’’ IEEE Trans. Biomed. Eng., vol. 51, no. 6, pp. 1034–1043,\\nJun. 2004.\\n[40] S. Koelstra, C. Muhl, M. Soleymani, J.-S. Lee, A. Yazdani, T. Ebrahimi,\\nT. Pun, A. Nijholt, and I. Patras, ‘‘DEAP: A database for emotion\\nanalysis; Using physiological signals,’’ IEEE Trans. Affect. Comput.,\\nvol. 3, no. 1, pp. 18–31, Jan. 2012.\\n[41] K. T. Sweeney, H. Ayaz, T. E. Ward, M. Izzetoglu, S. F. McLoone, and\\nB. Onaral, ‘‘A methodology for validating artifact removal techniques for\\nphysiological signals,’’ IEEE Trans. Inf. Technol. Biomed., vol. 16, no. 5,\\npp. 918–926, Sep. 2012.\\n[42] W.-L. Zheng and B.-L. Lu, ‘‘Investigating critical frequency bands and\\nchannels for EEG-based emotion recognition with deep neural networks,’’\\nIEEE Trans. Auto. Mental Develop., vol. 7, no. 3, pp. 162–175, Sep. 2015.\\n[43] M. Simoes, D. Borra, E. Santamaría-Vázquez,\\nM. Bittencourt-Villalpando, D. Krzeminski, and A. Miladinovic,\\n‘‘BCIAUT-P300: A multi-session and multi-subject benchmark dataset\\non autism for P300-based brain-computer-interfaces,’’ Frontiers\\nNeurosci., vol. 14, Sep. 2020, Art. no. 568104.\\n[44] A. Guillot, F. Sauvet, E. H. During, and V. Thorey, ‘‘Dreem open\\ndatasets: Multi-scored sleep datasets to compare human and automated\\nsleep staging,’’ IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 9,\\npp. 1955–1965, Sep. 2020.\\n[45] A. Delorme, S. Makeig, M. Fabre-Thorpe, and T. Sejnowski,\\n‘‘From single-trial EEG to brain area dynamics,’’ Neurocomputing,\\nvols. 44–46, pp. 1057–1064, Jun. 2002.\\n[46] T. B. Alakus, M. Gonen, and I. Turkoglu, ‘‘Database for an emotion\\nrecognition system based on EEG signals and various computer games—\\nGAMEEMO,’’ Biomed. Signal Process. Control, vol. 60, Jul. 2020,\\nArt. no. 101951.\\n[47] A. Raheel, M. Majid,', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1755: ('leep staging,’’ IEEE Trans. Neural Syst. Rehabil. Eng., vol. 28, no. 9,\\npp. 1955–1965, Sep. 2020.\\n[45] A. Delorme, S. Makeig, M. Fabre-Thorpe, and T. Sejnowski,\\n‘‘From single-trial EEG to brain area dynamics,’’ Neurocomputing,\\nvols. 44–46, pp. 1057–1064, Jun. 2002.\\n[46] T. B. Alakus, M. Gonen, and I. Turkoglu, ‘‘Database for an emotion\\nrecognition system based on EEG signals and various computer games—\\nGAMEEMO,’’ Biomed. Signal Process. Control, vol. 60, Jul. 2020,\\nArt. no. 101951.\\n[47] A. Raheel, M. Majid, and S. M. Anwar, ‘‘DEAR-MULSEMEDIA:\\nDataset for emotion analysis and recognition in response to multiple\\nsensorial media,’’ Inf. Fusion, vol. 65, pp. 37–49, Jan. 2021.\\n[48] W. Liu, J.-L. Qiu, W.-L. Zheng, and B.-L. Lu, ‘‘Comparing recognition\\nperformance and robustness of multimodal deep learning models for\\nmultimodal emotion recognition,’’ IEEE Trans. Cognit. Develop. Syst.,\\nvol. 14, no. 2, pp. 715–729, Jun. 2022.\\n[49] Y. Wang, W. Duan, D. Dong, L. Ding, and X. Lei, ‘‘A test-retest resting,\\nand cognitive state EEG dataset during multiple subject-driven states,’’\\nSci. Data, vol. 9, no. 1, pp. 1–11, Sep. 2022.\\n[50] M. J. Alhaddad, M. I. Kamel, and H. M. Malibary, ‘‘Diagnosis autism\\nby Fisher linear discriminant analysis FLDA via EEG,’’ Int. J. Bio-Sci.\\nBio-Technol., vol. 4, no. 2, pp. 45–54, 2012.\\n[51] M. Sazgar and M. G. Young, Absolute Epilepsy and EEG Rotation\\nReview: Essentials for Trainees. Berlin, Germany: Springer, 2019.\\n[52] S. Motamedi-Fakhr, M. Moshrefi-Torbati, M. Hill, C. M. Hill, and\\nP. R. White, ‘‘Signal processing techniques applied to human sleep EEG\\nsignals—A review,’’ Biomed. Signal Process. Control, vol. 10, pp. 21–33,\\nMar. 2014.\\n[53] D. Moretti, ‘‘Computerized processing of EEG–EOG–EMG artifacts for\\nmulti-centric studies in EEG oscillations and event-related potentials,’’\\nInt. J. Psychophysiol., vol. 47, no. 3, pp. 199–216, Mar. 2003.\\n[54] K. Venkatachalam, A. Devipriya, J. Maniraj, M. Sivaram, A. Ambikapa-\\nthy, and S. A. Iraj, ‘‘A novel method of motor imagery classification using\\nEEG signa', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1756: (' ‘‘Signal processing techniques applied to human sleep EEG\\nsignals—A review,’’ Biomed. Signal Process. Control, vol. 10, pp. 21–33,\\nMar. 2014.\\n[53] D. Moretti, ‘‘Computerized processing of EEG–EOG–EMG artifacts for\\nmulti-centric studies in EEG oscillations and event-related potentials,’’\\nInt. J. Psychophysiol., vol. 47, no. 3, pp. 199–216, Mar. 2003.\\n[54] K. Venkatachalam, A. Devipriya, J. Maniraj, M. Sivaram, A. Ambikapa-\\nthy, and S. A. Iraj, ‘‘A novel method of motor imagery classification using\\nEEG signal,’’ Artif. Intell. Med., vol. 103, Mar. 2020, Art. no. 101787.\\n[55] S. Sen Gupta, S. Soman, P. Govind Raj, R. Prakash, S. Sailaja,\\nand R. Borgohain, ‘‘Detecting eye movements in EEG for controlling\\ndevices,’’ in Proc. IEEE Int. Conf. Comput. Intell. Cybern. (Cybernet-\\nicsCom), Jul. 2012, pp. 69–73.\\n143138 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n[56] T. W. Picton, P. van Roon, M. L. Armilio, P. Berg, N. Ille, and M. Scherg,\\n‘‘The correction of ocular artifacts: A topographic perspective,’’ Clin.\\nNeurophysiol., vol. 111, no. 1, pp. 53–65, Jan. 2000.\\n[57] S. Hoehl and S. Wahl, ‘‘Recording infant ERP data for cogni-\\ntive research,’’ Develop. Neuropsychol., vol. 37, no. 3, pp. 187–209,\\nApr. 2012.\\n[58] D. Craven, B. McGinley, L. Kilmartin, M. Glavin, and E. Jones,\\n‘‘Adaptive dictionary reconstruction for compressed sensing of ECG\\nsignals,’’ IEEE J. Biomed. Health Informat., vol. 21, no. 3, pp. 645–654,\\nMay 2017.\\n[59] S. R. Benbadis and K. Lin, ‘‘Errors in EEG interpretation and\\nmisdiagnosis of epilepsy,’’ Eur. Neurol., vol. 59, no. 5, pp. 267–271, 2008.\\n[60] (Mar. 2021). All About EEG Artifacts and Filtering Tools. [Online].\\nAvailable: https://www.bitbrain.com/blog/eeg-artifacts\\n[61] A. W. Lininger, M. R. Volow, and D. T. Gianturco, ‘‘Intravenous infusion\\nmotor artifact,’’ Amer. J. EEG Technol., vol. 21, no. 4, pp. 167–173,\\nDec. 1981.\\n[62] N. Elsayed, Z. Saad, and M. Bayoumi, ‘‘Brain computer interface: EEG\\nsignal preprocessing issues and ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1757: ('. Lin, ‘‘Errors in EEG interpretation and\\nmisdiagnosis of epilepsy,’’ Eur. Neurol., vol. 59, no. 5, pp. 267–271, 2008.\\n[60] (Mar. 2021). All About EEG Artifacts and Filtering Tools. [Online].\\nAvailable: https://www.bitbrain.com/blog/eeg-artifacts\\n[61] A. W. Lininger, M. R. Volow, and D. T. Gianturco, ‘‘Intravenous infusion\\nmotor artifact,’’ Amer. J. EEG Technol., vol. 21, no. 4, pp. 167–173,\\nDec. 1981.\\n[62] N. Elsayed, Z. Saad, and M. Bayoumi, ‘‘Brain computer interface: EEG\\nsignal preprocessing issues and solutions,’’ Int. J. Comput. Appl., vol. 169,\\nno. 3, pp. 12–16, Jul. 2017.\\n[63] K. Majumdar, A Brief Survey of Quantitative EEG. Boca Raton, FL, USA:\\nCRC Press, 2017.\\n[64] D. J. Krusienski, D. J. McFarland, J. C. Principe, and E. Wolpaw, ‘‘BCI\\nsignal processing: Feature extraction,’’ in Brain-Computer Interfaces:\\nPrinciples and Practice, J. R. Wolpaw and E. W. Wolpaw, Eds. New York,\\nNY, USA: Oxford Univ. Press, 2012, pp. 123–146.\\n[65] H. Jäger, H. Witte, M. Galicki, C. Schelenz, M. Specht, K. Reinhart,\\nM. Eiselt, and A. Doering, ‘‘Adaptable preprocessing units and neural\\nclassification for the segmentation of EEG signals,’’ Methods Inf. Med.,\\nvol. 38, no. 3, pp. 214–224, 1999.\\n[66] I. Rejer and P. Górski, ‘‘Independent component analysis for EEG data\\npreprocessing-algorithms comparison,’’ in Proc. IFIP Int. Conf. Comput.\\nInf. Syst. Ind. Manag. Cham, Switzerland: Springer, 2013, pp. 108–119.\\n[67] I. Winkler, S. Debener, K.-R. Müller, and M. Tangermann, ‘‘On the\\ninfluence of high-pass filtering on ICA-based artifact reduction in EEG-\\nERP,’’ in Proc. 37th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC),\\nAug. 2015, pp. 4101–4105.\\n[68] D. Wu, J.-T. King, C.-H. Chuang, C.-T. Lin, and T.-P. Jung, ‘‘Spatial\\nfiltering for EEG-based regression problems in brain–computer interface\\n(BCI),’’ IEEE Trans. Fuzzy Syst., vol. 26, no. 2, pp. 771–781, Apr. 2018.\\n[69] L. Eeckhout, ‘‘Hot chips: Industry and academia cutting-edge micropro-\\ncessors,’’ IEEE Micro, vol. 37, no. 2, p. 4, Mar. 2017.\\n[70] S. Leske and S. S. Dalal, ‘‘Redu', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1758: ('ifact reduction in EEG-\\nERP,’’ in Proc. 37th Annu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC),\\nAug. 2015, pp. 4101–4105.\\n[68] D. Wu, J.-T. King, C.-H. Chuang, C.-T. Lin, and T.-P. Jung, ‘‘Spatial\\nfiltering for EEG-based regression problems in brain–computer interface\\n(BCI),’’ IEEE Trans. Fuzzy Syst., vol. 26, no. 2, pp. 771–781, Apr. 2018.\\n[69] L. Eeckhout, ‘‘Hot chips: Industry and academia cutting-edge micropro-\\ncessors,’’ IEEE Micro, vol. 37, no. 2, p. 4, Mar. 2017.\\n[70] S. Leske and S. S. Dalal, ‘‘Reducing power line noise in EEG and MEG\\ndata via spectrum interpolation,’’ NeuroImage, vol. 189, pp. 763–776,\\nApr. 2019. [Online]. Available: https://www.sciencedirect.com/\\nscience/article/pii/S1053811919300266\\n[71] J. Strobl, M. Piorecky, V. Koudelka, T. Nagy, and V. Krajca, ‘‘Methods\\nfor removing of line noise artifact from EEG records with minimization of\\nneural information loss,’’ in Proc. Medit. Conf. Med. Biol. Eng. Comput.\\nCham, Switzerland: Springer, 2019, pp. 184–192.\\n[72] M. A. Klados, C. Papadelis, C. Braun, and P. D. Bamidis, ‘‘REG-ICA:\\nA hybrid methodology combining blind source separation and regression\\ntechniques for the rejection of ocular artifacts,’’ Biomed. Signal Process.\\nControl, vol. 6, no. 3, pp. 291–300, Jul. 2011.\\n[73] A. Zachariah, J. Jai, and G. Titus, ‘‘Automatic EEG artifact removal by\\nindependent component analysis using critical EEG rhythms,’’ in Proc.\\nInt. Conf. Control Commun. Comput. (ICCC), Dec. 2013, pp. 364–367.\\n[74] T. Zikov, S. Bibian, G. A. Dumont, M. Huzmezan, and C. R. Ries,\\n‘‘A wavelet based de-noising technique for ocular artifact correction of\\nthe electroencephalogram,’’ in Proc. 2nd Joint 24th Annu. Conf. Annu.\\nFall Meeting Biomed. Eng. Society, vol. 1, 2002, pp. 98–105.\\n[75] V. Krishnaveni, S. Jayaraman, N. Malmurugan, A. Kandasamy, and\\nD. Ramadoss, ‘‘Non adaptive thresholding methods for correcting ocular\\nartifacts in EEG,’’ Academic Open Internet J., vol. 13, pp. 2–3, Mar. 2004.\\n[76] X. Yong, R. K. Ward, and G. E. Birch, ‘‘Artifact removal in EEG using\\nmorphological', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1759: ('ies,\\n‘‘A wavelet based de-noising technique for ocular artifact correction of\\nthe electroencephalogram,’’ in Proc. 2nd Joint 24th Annu. Conf. Annu.\\nFall Meeting Biomed. Eng. Society, vol. 1, 2002, pp. 98–105.\\n[75] V. Krishnaveni, S. Jayaraman, N. Malmurugan, A. Kandasamy, and\\nD. Ramadoss, ‘‘Non adaptive thresholding methods for correcting ocular\\nartifacts in EEG,’’ Academic Open Internet J., vol. 13, pp. 2–3, Mar. 2004.\\n[76] X. Yong, R. K. Ward, and G. E. Birch, ‘‘Artifact removal in EEG using\\nmorphological component analysis,’’ in Proc. IEEE Int. Conf. Acoust.,\\nSpeech Signal Process., Apr. 2009, pp. 345–348.\\n[77] S. Khatun, R. Mahajan, and B. I. Morshed, ‘‘Comparative analysis of\\nwavelet based approaches for reliable removal of ocular artifacts from\\nsingle channel EEG,’’ in Proc. IEEE Int. Conf. Electro/Inf. Technol. (EIT),\\nMay 2015, pp. 335–340.[78] R. B. Pachori, ‘‘Discrimination between ictal and seizure-free EEG\\nsignals using empirical mode decomposition,’’ Res. Lett. Signal Process.,\\nvol. 2008, pp. 1–5, Dec. 2008.\\n[79] D. Safieddine, A. Kachenoura, L. Albera, G. Birot, A. Karfoul,\\nA. Pasnicu, A. Biraben, F. Wendling, L. Senhadji, and I. Merlet,\\n‘‘Removal of muscle artifact from EEG data: Comparison between\\nstochastic (ICA and CCA) and deterministic (EMD and wavelet-based)\\napproaches,’’ EURASIP J. Adv. Signal Process., vol. 2012, no. 1,\\npp. 1–15, Dec. 2012.\\n[80] K. T. Sweeney, S. F. McLoone, and T. E. Ward, ‘‘The use of ensemble\\nempirical mode decomposition with canonical correlation analysis as a\\nnovel artifact removal technique,’’ IEEE Trans. Biomed. Eng., vol. 60,\\nno. 1, pp. 97–105, Jan. 2013.\\n[81] X. Chen, X. Xu, A. Liu, M. J. McKeown, and Z. J. Wang, ‘‘The use\\nof multivariate EMD and CCA for denoising muscle artifacts from few-\\nchannel EEG recordings,’’ IEEE Trans. Instrum. Meas., vol. 67, no. 2,\\npp. 359–370, Feb. 2018.\\n[82] B. Widrow and S. D. Stearns, Adaptive Signal Processing. Englewood\\nCliffs, NJ, USA: Prentice-Hall, 1985.\\n[83] B. Kovavevic, Z. Banjac, and M. Milosavljevic, Adaptive Digital Filters', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1760: ('tifact removal technique,’’ IEEE Trans. Biomed. Eng., vol. 60,\\nno. 1, pp. 97–105, Jan. 2013.\\n[81] X. Chen, X. Xu, A. Liu, M. J. McKeown, and Z. J. Wang, ‘‘The use\\nof multivariate EMD and CCA for denoising muscle artifacts from few-\\nchannel EEG recordings,’’ IEEE Trans. Instrum. Meas., vol. 67, no. 2,\\npp. 359–370, Feb. 2018.\\n[82] B. Widrow and S. D. Stearns, Adaptive Signal Processing. Englewood\\nCliffs, NJ, USA: Prentice-Hall, 1985.\\n[83] B. Kovavevic, Z. Banjac, and M. Milosavljevic, Adaptive Digital Filters.\\nBerlin, Germany: Springer, 2013.\\n[84] G. Benmouyal, ‘‘Removal of DC-offset in current waveforms using\\ndigital mimic filtering,’’ IEEE Trans. Power Del., vol. 10, no. 2,\\npp. 621–630, Apr. 1995.\\n[85] M. Rakibul Mowla, S.-C. Ng, M. S. A. Zilany, and R. Paramesran,\\n‘‘Artifacts-matched blind source separation and wavelet transform for\\nmultichannel EEG denoising,’’ Biomed. Signal Process. Control, vol. 22,\\npp. 111–118, Sep. 2015.\\n[86] J. P. Lindsen and J. Bhattacharya, ‘‘Correction of blink artifacts using\\nindependent component analysis and empirical mode decomposition,’’\\nPsychophysiology, vol. 47, no. 5, pp. 955–960, 2010.\\n[87] V. Kamath, Y.-C. Lai, L. Zhu, and S. Urval, ‘‘Empirical mode\\ndecomposition and blind source separation methods for antijamming\\nwith GPS signals,’’ in Proc. IEEE/ION Position, Location, Navigat.\\nSymp., 2006, pp. 335–341.\\n[88] X. Navarro, F. Porée, and G. Carrault, ‘‘ECG removal in preterm\\nEEG combining empirical mode decomposition and adaptive filtering,’’\\ninProc. IEEE Int. Conf. Acoust., Speech Signal Process. (ICASSP),\\nMar. 2012, pp. 661–664.\\n[89] Y. Chen, Q. Zhao, B. Hu, J. Li, H. Jiang, W. Lin, Y. Li, S. Zhou, and\\nH. Peng, ‘‘A method of removing ocular artifacts from EEG using discrete\\nwavelet transform and Kalman filtering,’’ in Proc. IEEE Int. Conf. Bioinf.\\nBiomed. (BIBM), Dec. 2016, pp. 1485–1492.\\n[90] Q. Chen, Y. Li, and X. Yuan, ‘‘A hybrid method for muscle artifact\\nremoval from EEG signals,’’ J. Neurosci. Methods, vol. 353, Apr. 2021,\\nArt. no. 109104.\\n[91] W. Mumtaz, S. Rasheed, an', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1761: ('Speech Signal Process. (ICASSP),\\nMar. 2012, pp. 661–664.\\n[89] Y. Chen, Q. Zhao, B. Hu, J. Li, H. Jiang, W. Lin, Y. Li, S. Zhou, and\\nH. Peng, ‘‘A method of removing ocular artifacts from EEG using discrete\\nwavelet transform and Kalman filtering,’’ in Proc. IEEE Int. Conf. Bioinf.\\nBiomed. (BIBM), Dec. 2016, pp. 1485–1492.\\n[90] Q. Chen, Y. Li, and X. Yuan, ‘‘A hybrid method for muscle artifact\\nremoval from EEG signals,’’ J. Neurosci. Methods, vol. 353, Apr. 2021,\\nArt. no. 109104.\\n[91] W. Mumtaz, S. Rasheed, and A. Irfan, ‘‘Review of challenges associated\\nwith the EEG artifact removal methods,’’ Biomed. Signal Process.\\nControl, vol. 68, Jul. 2021, Art. no. 102741.\\n[92] M.-T. Shih, F. Doctor, S.-Z. Fan, K.-K. Jen, and J.-S. Shieh, ‘‘Instanta-\\nneous 3D EEG signal analysis based on empirical mode decomposition\\nand the Hilbert–Huang transform applied to depth of anaesthesia,’’\\nEntropy, vol. 17, no. 3, pp. 928–949, Feb. 2015.\\n[93] J. A. DeLisa, B. M. Gans, and N. E. Walsh, Physical Medicine and\\nRehabilitation: Principles and Practice, vol. 1. Philadelphia, PA, USA:\\nLippincott Williams & Wilkins, 2005.\\n[94] ‘‘Pre-processing for ERP analysis,’’ CREx, Feb. 2015. Accessed:\\nJul. 12, 2023. [Online]. Available: http://blricrex.hypotheses.org/\\nressources/eeg/pre-processing-for-erps\\n[95] E. Florin, J. Gross, J. Pfeifer, G. R. Fink, and L. Timmermann, ‘‘The effect\\nof filtering on Granger causality based multivariate causality measures,’’\\nNeuroImage, vol. 50, no. 2, pp. 577–588, Apr. 2010.\\n[96] R. VanRullen, ‘‘Four common conceptual fallacies in mapping the time\\ncourse of recognition,’’ Frontiers Psychol., vol. 2, p. 365, Dec. 2011.\\n[97] B. Babadi and E. N. Brown, ‘‘A review of multitaper spectral analysis,’’\\nIEEE Trans. Biomed. Eng., vol. 61, no. 5, pp. 1555–1564, May 2014.\\n[98] S.-P. Kim, ‘‘Preprocessing of EEG,’’ in Computational EEG Analysis.\\nBerlin, Germany: Springer, 2018, pp. 15–33.\\n[99] A. Turnip and E. Junaidi, ‘‘Removal artifacts from EEG signal using\\nindependent component analysis and principal component analysis,’’\\ninPro', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1762: ('al fallacies in mapping the time\\ncourse of recognition,’’ Frontiers Psychol., vol. 2, p. 365, Dec. 2011.\\n[97] B. Babadi and E. N. Brown, ‘‘A review of multitaper spectral analysis,’’\\nIEEE Trans. Biomed. Eng., vol. 61, no. 5, pp. 1555–1564, May 2014.\\n[98] S.-P. Kim, ‘‘Preprocessing of EEG,’’ in Computational EEG Analysis.\\nBerlin, Germany: Springer, 2018, pp. 15–33.\\n[99] A. Turnip and E. Junaidi, ‘‘Removal artifacts from EEG signal using\\nindependent component analysis and principal component analysis,’’\\ninProc. 2nd Int. Conf. Technol., Informat., Manag., Eng. Environ.,\\nAug. 2014, pp. 296–302.\\nVOLUME 11, 2023 143139\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n[100] D. Hagemann, E. Naumann, and J. F. Thayer, ‘‘The quest for the\\nEEG reference revisited: A glance from brain asymmetry research,’’\\nPsychophysiology, vol. 38, no. 5, pp. 847–857, Sep. 2001.\\n[101] T. Al-Ani, D. Trad, and V. S. Somerset, ‘‘Signal processing and\\nclassification approaches for brain-computer interface,’’ in Intelligent and\\nBiosensors. Rijeka, Croatia: Intech, 2010, pp. 25–66.\\n[102] J. Dien, ‘‘Issues in the application of the average reference: Review, cri-\\ntiques, and recommendations,’’ Behav. Res. Methods, Instrum., Comput.,\\nvol. 30, no. 1, pp. 34–43, Mar. 1998.\\n[103] P. N. Kumar and H. Kareemullah, ‘‘EEG signal with feature extraction\\nusing SVM and ICA classifiers,’’ in Proc. Int. Conf. Inf. Commun.\\nEmbedded Syst. (ICICES), Feb. 2014, pp. 1–7.\\n[104] J. Jäger, A. Klein, M. Buhmann, and W. Skrandies, ‘‘Reconstruction\\nof electroencephalographic data using radial basis functions,’’ Clin.\\nNeurophysiol., vol. 127, no. 4, pp. 1978–1983, Apr. 2016.\\n[105] N. Chauveau, J. P. Morucci, X. Franceries, P. Celsis, and B. Rigaud,\\n‘‘Resistor mesh model of a spherical head: Part 1: Applications to\\nscalp potential interpolation,’’ Med. Biol. Eng. Comput., vol. 43, no. 6,\\npp. 694–702, Nov. 2005.\\n[106] F. Perrin, J. Pernier, O. Bertnard, M. H. Giard, and J. F. Echallier,\\n‘‘Mapping of scalp potentials by sur', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1763: (' W. Skrandies, ‘‘Reconstruction\\nof electroencephalographic data using radial basis functions,’’ Clin.\\nNeurophysiol., vol. 127, no. 4, pp. 1978–1983, Apr. 2016.\\n[105] N. Chauveau, J. P. Morucci, X. Franceries, P. Celsis, and B. Rigaud,\\n‘‘Resistor mesh model of a spherical head: Part 1: Applications to\\nscalp potential interpolation,’’ Med. Biol. Eng. Comput., vol. 43, no. 6,\\npp. 694–702, Nov. 2005.\\n[106] F. Perrin, J. Pernier, O. Bertnard, M. H. Giard, and J. F. Echallier,\\n‘‘Mapping of scalp potentials by surface spline interpolation,’’ Electroen-\\ncephalogr. Clin. Neurophysiol., vol. 66, no. 1, pp. 75–81, Jan. 1987.\\n[107] F. Lotte, ‘‘Study of electroencephalographic signal processing and\\nclassification techniques towards the use of brain-computer interfaces in\\nvirtual reality applications,’’ Nat. Inst. Appl. Sci. (INSA), Rennes, France,\\n2008.\\n[108] D. Bansal and R. Mahajan, EEG-Based Brain-Computer Interfaces:\\nCognitive Analysis and Control Applications . Cambridge, MA, USA:\\nAcademic Press, 2019.\\n[109] S.-I. Park, M. J. T. Smith, and R. M. Mersereau, ‘‘A new directional\\nfilter bank for image analysis and classification,’’ in Proc. IEEE Int. Conf.\\nAcoust., Speech, Signal Process., May 1999, pp. 1417–1420.\\n[110] J. Müller-Gerking, G. Pfurtscheller, and H. Flyvbjerg, ‘‘Designing\\noptimal spatial filters for single-trial EEG classification in a movement\\ntask,’’ Clin. Neurophysiol., vol. 110, no. 5, pp. 787–798, May 1999.\\n[111] D. J. McFarland, L. M. McCane, S. V. David, and J. R. Wolpaw, ‘‘Spatial\\nfilter selection for EEG-based communication,’’ Electroencephalogr.\\nClin. Neurophysiol., vol. 103, no. 3, pp. 386–394, Sep. 1997.\\n[112] P. L. Nunez, R. B. Silberstein, P. J. Cadusch, R. S. Wijesinghe,\\nA. F. Westdorp, and R. Srinivasan, ‘‘A theoretical and experimental\\nstudy of high resolution EEG based on surface Laplacians and cortical\\nimaging,’’ Electroencephalogr. Clin. Neurophysiol., vol. 90, no. 1,\\npp. 40–57, Jan. 1994.\\n[113] W. De Clercq, A. Vergult, B. Vanrumste, W. Van Paesschen, and\\nS. Van Huffel, ‘‘Canonical correlat', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1764: (' EEG-based communication,’’ Electroencephalogr.\\nClin. Neurophysiol., vol. 103, no. 3, pp. 386–394, Sep. 1997.\\n[112] P. L. Nunez, R. B. Silberstein, P. J. Cadusch, R. S. Wijesinghe,\\nA. F. Westdorp, and R. Srinivasan, ‘‘A theoretical and experimental\\nstudy of high resolution EEG based on surface Laplacians and cortical\\nimaging,’’ Electroencephalogr. Clin. Neurophysiol., vol. 90, no. 1,\\npp. 40–57, Jan. 1994.\\n[113] W. De Clercq, A. Vergult, B. Vanrumste, W. Van Paesschen, and\\nS. Van Huffel, ‘‘Canonical correlation analysis applied to remove muscle\\nartifacts from the electroencephalogram,’’ IEEE Trans. Biomed. Eng. ,\\nvol. 53, no. 12, pp. 2583–2587, Nov. 2006.\\n[114] S. Makeig, T.-P. Jung, D. Ghahremani, and T. J. Sejnowski, ‘‘Independent\\ncomponent analysis of simulated ERP data,’’ Inst. Neural Comput., Univ.\\nCalifornia, Long Beach, CA, USA, Tech. Rep. INC-9606, 1996.\\n[115] V. Kumaravel, F. Paissan, and E. Farella, ‘‘Towards a domain-specific\\nneural network approach for EEG bad channel detection,’’ in Proc. IEEE\\nSignal Process. Med. Biol. Symp. (SPMB), Dec. 2021, pp. 1–4.\\n[116] P. A. Bizopoulos, T. Al-Ani, D. G. Tsalikakis, A. T. Tzallas,\\nD. D. Koutsouris, and D. I. Fotiadis, ‘‘An automatic electroencephalog-\\nraphy blinking artefact detection and removal method based on template\\nmatching and ensemble empirical mode decomposition,’’ in Proc. 35th\\nAnnu. Int. Conf. IEEE Eng. Med. Biol. Soc. (EMBC), Jul. 2013,\\npp. 5853–5856.\\n[117] M. B. Hamaneh, N. Chitravas, K. Kaiboriboon, S. D. Lhatoo, and\\nK. A. Loparo, ‘‘Automated removal of EKG artifact from EEG data\\nusing independent component analysis and continuous wavelet trans-\\nformation,’’ IEEE Trans. Biomed. Eng., vol. 61, no. 6, pp. 1634–1641,\\nJun. 2014.\\n[118] C. Zhao and T. Qiu, ‘‘An automatic ocular artifacts removal method based\\non wavelet-enhanced canonical correlation analysis,’’ in Proc. Annu. Int.\\nConf. IEEE Eng. Med. Biol. Soc., Aug. 2011, pp. 4191–4194.\\n[119] X. Chen, C. He, and H. Peng, ‘‘Removal of muscle artifacts from\\nsingle-channel EEG based on ensemble empirical ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1765: ('oval of EKG artifact from EEG data\\nusing independent component analysis and continuous wavelet trans-\\nformation,’’ IEEE Trans. Biomed. Eng., vol. 61, no. 6, pp. 1634–1641,\\nJun. 2014.\\n[118] C. Zhao and T. Qiu, ‘‘An automatic ocular artifacts removal method based\\non wavelet-enhanced canonical correlation analysis,’’ in Proc. Annu. Int.\\nConf. IEEE Eng. Med. Biol. Soc., Aug. 2011, pp. 4191–4194.\\n[119] X. Chen, C. He, and H. Peng, ‘‘Removal of muscle artifacts from\\nsingle-channel EEG based on ensemble empirical mode decomposition\\nand multiset canonical correlation analysis,’’ J. Appl. Math., vol. 2014,\\npp. 1–10, Jun. 2014.\\n[120] L. Shoker, S. Sanei, and J. Chambers, ‘‘Artifact removal from elec-\\ntroencephalograms using a hybrid BSS-SVM algorithm,’’ IEEE Signal\\nProcess. Lett., vol. 12, no. 10, pp. 721–724, Oct. 2005.[121] B. Abdi-Sargezeh, R. Foodeh, V. Shalchyan, and M. R. Daliri, ‘‘EEG\\nartifact rejection by extracting spatial and spatio-spectral common\\ncomponents,’’ J. Neurosci. Methods, vol. 358, Jul. 2021, Art. no. 109182.\\n[122] D. Jiang, Y.-N. Lu, Y. Ma, and Y. Wang, ‘‘Robust sleep stage classification\\nwith single-channel EEG signals using multimodal decomposition and\\nHMM-based refinement,’’ Exp. Syst. Appl., vol. 121, pp. 188–203,\\nMay 2019.\\n[123] W. Chen, Y. Wang, Y. Ren, H. Jiang, G. Du, J. Zhang, and J. Li,\\n‘‘An automated detection of epileptic seizures EEG using CNN classifier\\nbased on feature fusion with high accuracy,’’ BMC Med. Informat. Decis.\\nMaking, vol. 23, no. 1, p. 96, May 2023.\\n[124] S. Lee, R. Hussein, R. Ward, Z. J. Wang, and M. J. McKeown,\\n‘‘A convolutional-recurrent neural network approach to resting-state EEG\\nclassification in Parkinson’s disease,’’ J. Neurosci. Methods, vol. 361,\\nSep. 2021, Art. no. 109282.\\n[125] H. W. Loh, C. P. Ooi, E. Palmer, P. D. Barua, S. Dogan, T. Tuncer,\\nM. Baygin, and U. R. Acharya, ‘‘GaborPDNet: Gabor transformation\\nand deep neural network for Parkinson’s disease detection using EEG\\nsignals,’’ Electronics, vol. 10, no. 14, p. 1740, Jul. 2021.\\n[126] S. K. Khare, V. Baj', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1766: ('sein, R. Ward, Z. J. Wang, and M. J. McKeown,\\n‘‘A convolutional-recurrent neural network approach to resting-state EEG\\nclassification in Parkinson’s disease,’’ J. Neurosci. Methods, vol. 361,\\nSep. 2021, Art. no. 109282.\\n[125] H. W. Loh, C. P. Ooi, E. Palmer, P. D. Barua, S. Dogan, T. Tuncer,\\nM. Baygin, and U. R. Acharya, ‘‘GaborPDNet: Gabor transformation\\nand deep neural network for Parkinson’s disease detection using EEG\\nsignals,’’ Electronics, vol. 10, no. 14, p. 1740, Jul. 2021.\\n[126] S. K. Khare, V. Bajaj, and U. R. Acharya, ‘‘Detection of Parkinson’s\\ndisease using automated tunable Q wavelet transform technique with\\nEEG signals,’’ Biocybernetics Biomed. Eng., vol. 41, no. 2, pp. 679–689,\\nApr. 2021.\\n[127] M. L. Vicchietti, F. M. Ramos, L. E. Betting, and A. S. Campanharo,\\n‘‘Computational methods of EEG signals analysis for Alzheimer’s disease\\nclassification,’’ Sci Rep., vol. 13, no. 1, p. 8184, 2023.\\n[128] G. Fiscon, E. Weitschek, A. Cialini, G. Felici, P. Bertolazzi, S. De\\nSalvo, A. Bramanti, P. Bramanti, and M. C. De Cola, ‘‘Combining\\nEEG signal processing with supervised methods for Alzheimer’s patients\\nclassification,’’ BMC Med. Informat. Decis. Making, vol. 18, no. 1,\\npp. 1–10, Dec. 2018.\\n[129] A. S. Al-Fahoum and A. A. Al-Fraihat, ‘‘Methods of EEG signal\\nfeatures extraction using linear analysis in frequency and time-frequency\\ndomains,’’ ISRN Neurosci., vol. 2014, pp. 1–7, Feb. 2014.\\n[130] V. K. Mehla, A. Singhal, P. Singh, and R. B. Pachori, ‘‘An efficient method\\nfor identification of epileptic seizures from EEG signals using Fourier\\nanalysis,’’ Phys. Eng. Sci. Med., vol. 44, no. 2, pp. 443–456, Jun. 2021.\\n[131] R. Alazrai, A. Al-Saqqaf, F. Al-Hawari, H. Alwanni, and M. I. Daoud,\\n‘‘A time-frequency distribution-based approach for decoding visu-\\nally imagined objects using EEG signals,’’ IEEE Access, vol. 8,\\npp. 138955–138972, 2020.\\n[132] K. Samiee, P. Kovács, and M. Gabbouj, ‘‘Epileptic seizure classification\\nof EEG time-series using rational discrete short-time Fourier transform,’’\\nIEEE Trans. Biomed.', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1767: ('res from EEG signals using Fourier\\nanalysis,’’ Phys. Eng. Sci. Med., vol. 44, no. 2, pp. 443–456, Jun. 2021.\\n[131] R. Alazrai, A. Al-Saqqaf, F. Al-Hawari, H. Alwanni, and M. I. Daoud,\\n‘‘A time-frequency distribution-based approach for decoding visu-\\nally imagined objects using EEG signals,’’ IEEE Access, vol. 8,\\npp. 138955–138972, 2020.\\n[132] K. Samiee, P. Kovács, and M. Gabbouj, ‘‘Epileptic seizure classification\\nof EEG time-series using rational discrete short-time Fourier transform,’’\\nIEEE Trans. Biomed. Eng., vol. 62, no. 2, pp. 541–552, Feb. 2015.\\n[133] N. Hazarika, J. Z. Chen, A. C. Tsoi, and A. Sergejew, ‘‘Classification of\\nEEG signals using the wavelet transform,’’ Signal Process., vol. 59, no. 1,\\npp. 61–72, May 1997.\\n[134] M. Rhif, A. Ben Abbes, I. Farah, B. Martínez, and Y. Sang,\\n‘‘Wavelet transform application for/in non-stationary time-series analy-\\nsis: A review,’’ Appl. Sci., vol. 9, no. 7, p. 1345, Mar. 2019.\\n[135] M. A. Rahman, F. Khanam, M. Ahmad, and M. S. Uddin, ‘‘Multiclass\\nEEG signal classification utilizing Rényi min-entropy-based feature\\nselection from wavelet packet transformation,’’ Brain Informat., vol. 7,\\nno. 1, pp. 1–11, Dec. 2020.\\n[136] G. H. B. S. Oliveira, L. R. Coutinho, J. C. D. Silva, I. J. P. Pinto,\\nJ. M. S. Ferreira, F. J. S. Silva, D. V. Santos, and A. S. Teles, ‘‘Multitaper-\\nbased method for automatic K-complex detection in human sleep EEG,’’\\nExp. Syst. Appl., vol. 151, Aug. 2020, Art. no. 113331.\\n[137] M. Akin, M. Kiymik, M. Arserim, and I. Turkoglu, ‘‘Separation of\\nbrain signals using FFT and neural networks,’’ in Proc. Biyomut, 2000,\\npp. 161–164.\\n[138] J. Zhao, J. Song, X. Li, and J. Kang, ‘‘A study on EEG feature extraction\\nand classification in autistic children based on singular spectrum analysis\\nmethod,’’ Brain Behav., vol. 10, no. 12, pp. 2651–2660, Dec. 2020.\\n[139] M. Baygin, S. Dogan, T. Tuncer, P. Datta Barua, O. Faust, N. Arunkumar,\\nE. W. Abdulhay, E. Emma Palmer, and U. Rajendra Acharya, ‘‘Automated\\nASD detection using hybrid deep lightweight features extracted f', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1768: ('signals using FFT and neural networks,’’ in Proc. Biyomut, 2000,\\npp. 161–164.\\n[138] J. Zhao, J. Song, X. Li, and J. Kang, ‘‘A study on EEG feature extraction\\nand classification in autistic children based on singular spectrum analysis\\nmethod,’’ Brain Behav., vol. 10, no. 12, pp. 2651–2660, Dec. 2020.\\n[139] M. Baygin, S. Dogan, T. Tuncer, P. Datta Barua, O. Faust, N. Arunkumar,\\nE. W. Abdulhay, E. Emma Palmer, and U. Rajendra Acharya, ‘‘Automated\\nASD detection using hybrid deep lightweight features extracted from\\nEEG signals,’’ Comput. Biol. Med., vol. 134, Jul. 2021, Art. no. 104548.\\n[140] J. Kang, T. Zhou, J. Han, and X. Li, ‘‘EEG-based multi-feature\\nfusion assessment for autism,’’ J. Clin. Neurosci., vol. 56, pp. 101–107,\\nOct. 2018.\\n[141] X. Zhao, X. Wang, T. Yang, S. Ji, H. Wang, J. Wang, Y. Wang, and\\nQ. Wu, ‘‘Classification of sleep apnea based on EEG sub-band signal\\ncharacteristics,’’ Sci. Rep., vol. 11, no. 1, p. 5824, Mar. 2021.\\n143140 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n[142] R. Behzad and A. Behzad, ‘‘The role of EEG in the diagnosis and\\nmanagement of patients with sleep disorders,’’ J. Behav. Brain Sci.,\\nvol. 11, no. 10, pp. 257–266, 2021.\\n[143] M. M. Siddiqui, G. Srivastava, and S. H. Saeed, ‘‘Diagnosis of insomnia\\nsleep disorder using short time frequency analysis of PSD approach\\napplied on EEG signal using channel ROC-LOC,’’ Sleep Sci., vol. 9, no. 3,\\npp. 186–191, Jul. 2016.\\n[144] F. A. Alturki, K. AlSharabi, A. M. Abdurraqeeb, and M. Aljalal, ‘‘EEG\\nsignal analysis for diagnosing neurological disorders using discrete\\nwavelet transform and intelligent techniques,’’ Sensors, vol. 20, no. 9,\\np. 2505, Apr. 2020.\\n[145] C. L. Alves, A. M. Pineda, K. Roster, C. Thielemann, and F. A. Rodrigues,\\n‘‘EEG functional connectivity and deep learning for automatic diagnosis\\nof brain disorders: Alzheimer’s disease and schizophrenia,’’ J. Phys.,\\nComplex., vol. 3, no. 2, Apr. 2022, Art. no. 025001, doi: 10.1088/2632-\\n072x/ac5f8d.\\n[146] L. Hu', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1769: ('rraqeeb, and M. Aljalal, ‘‘EEG\\nsignal analysis for diagnosing neurological disorders using discrete\\nwavelet transform and intelligent techniques,’’ Sensors, vol. 20, no. 9,\\np. 2505, Apr. 2020.\\n[145] C. L. Alves, A. M. Pineda, K. Roster, C. Thielemann, and F. A. Rodrigues,\\n‘‘EEG functional connectivity and deep learning for automatic diagnosis\\nof brain disorders: Alzheimer’s disease and schizophrenia,’’ J. Phys.,\\nComplex., vol. 3, no. 2, Apr. 2022, Art. no. 025001, doi: 10.1088/2632-\\n072x/ac5f8d.\\n[146] L. Hu and Z. Zhang, EEG Signal Processing and Feature Extraction.\\nBerlin, Germany: Springer, 2019.\\n[147] N. Michielli, U. R. Acharya, and F. Molinari, ‘‘Cascaded LSTM\\nrecurrent neural network for automated sleep stage classification using\\nsingle-channel EEG signals,’’ Comput. Biol. Med., vol. 106, pp. 71–81,\\nMar. 2019.\\n[148] I. Stancin, M. Cifrek, and A. Jovic, ‘‘A review of EEG signal features\\nand their application in driver drowsiness detection systems,’’ Sensors,\\nvol. 21, no. 11, p. 3786, May 2021.\\n[149] M. Akin, ‘‘Comparison of wavelet transform and FFT methods in the\\nanalysis of EEG signals,’’ J. Med. Syst., vol. 26, no. 3, pp. 241–247, 2002.\\n[150] K. Nathan and J. L. Contreras-Vidal, ‘‘Negligible motion artifacts in scalp\\nelectroencephalography (EEG) during treadmill walking,’’ Frontiers\\nHum. Neurosci., vol. 9, p. 708, Jan. 2016.\\n[151] B. R. Joy, A. Amara, and A. Nakhmani, ‘‘Transform with no parameters\\nbased on extrema points for non-stationary signal analysis,’’ Circuits,\\nSyst., Signal Process., vol. 37, no. 6, pp. 2535–2547, Jun. 2018.\\n[152] S. B. Belhaouari, A. Talbi, S. Hassan, D. Al-Thani, and M. Qaraqe,\\n‘‘PFT: A novel time-frequency decomposition of BOLD fMRI signals\\nfor autism spectrum disorder detection,’’ Sustainability, vol. 15, no. 5,\\np. 4094, Feb. 2023.\\n[153] I. Daubechies, Ten Lectures on Wavelets. Philadelphia, PA, USA: SIAM,\\n1992.\\n[154] S. Mallat and C. Mallat, ‘‘7.2 classes of wavelet bases,’’ in A Wavelet\\nTour of Signal Processing. Amsterdam, The Netherlands: Elsevier, 1999,\\npp. 241–254.\\n[155', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1770: ('o. 6, pp. 2535–2547, Jun. 2018.\\n[152] S. B. Belhaouari, A. Talbi, S. Hassan, D. Al-Thani, and M. Qaraqe,\\n‘‘PFT: A novel time-frequency decomposition of BOLD fMRI signals\\nfor autism spectrum disorder detection,’’ Sustainability, vol. 15, no. 5,\\np. 4094, Feb. 2023.\\n[153] I. Daubechies, Ten Lectures on Wavelets. Philadelphia, PA, USA: SIAM,\\n1992.\\n[154] S. Mallat and C. Mallat, ‘‘7.2 classes of wavelet bases,’’ in A Wavelet\\nTour of Signal Processing. Amsterdam, The Netherlands: Elsevier, 1999,\\npp. 241–254.\\n[155] A. C. Hale, T. Hansard, L. W. Sheppard, P. V. E. McClintock,\\nand A. Stefanovska, ‘‘The Kuramoto model subject to a fluctuating\\nenvironment: Application to brainwave dynamics,’’ Fluctuation Noise\\nLett., vol. 11, no. 1, Mar. 2012, Art. no. 1240011.\\n[156] M. Unser and A. Aldroubi, ‘‘A review of wavelets in biomedical\\napplications,’’ Proc. IEEE, vol. 84, no. 4, pp. 626–638, Apr. 1996.\\n[157] J.-Z. Xue, H. Zhang, C.-X. Zheng, and X.-G. Yan, ‘‘Wavelet packet\\ntransform for feature extraction of EEG during mental tasks,’’ in Proc.\\nInt. Conf. Mach. Learn. Cybern., 2003, pp. 360–363.\\n[158] H. E. Hurst, ‘‘Methods of using long-term storage in reservoirs,’’ Proc.\\nInst. Civil Engineers, vol. 5, no. 5, pp. 519–543, Oct. 1956.\\n[159] E. Lloyd, ‘‘Review of long-term storage: An experimental study,’’ J.\\nRoyal Stat. Soc. A Gen., vol. 129, no. 4, pp. 591–593, 1996. [Online].\\nAvailable: https://doi.org/10.2307/2982267\\n[160] H. Salat, R. Murcio, and E. Arcaute, ‘‘Multifractal methodology,’’ Phys.\\nA, Stat. Mech. Appl., vol. 473, pp. 467–487, May 2017.\\n[161] H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, vol. 7.\\nCambridge, U.K.: Cambridge Univ. Press, 2004.\\n[162] D. P. Dash, M. H. Kolekar, and K. Jha, ‘‘Multi-channel EEG based auto-\\nmatic epileptic seizure detection using iterative filtering decomposition\\nand hidden Markov model,’’ Comput. Biol. Med., vol. 116, Jan. 2020,\\nArt. no. 103571.\\n[163] C.-T. Shi, ‘‘Signal pattern recognition based on fractal features and\\nmachine learning,’’ Appl. Sci., vol. 8, no. 8, p. 1327, Aug', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1771: ('p. 467–487, May 2017.\\n[161] H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, vol. 7.\\nCambridge, U.K.: Cambridge Univ. Press, 2004.\\n[162] D. P. Dash, M. H. Kolekar, and K. Jha, ‘‘Multi-channel EEG based auto-\\nmatic epileptic seizure detection using iterative filtering decomposition\\nand hidden Markov model,’’ Comput. Biol. Med., vol. 116, Jan. 2020,\\nArt. no. 103571.\\n[163] C.-T. Shi, ‘‘Signal pattern recognition based on fractal features and\\nmachine learning,’’ Appl. Sci., vol. 8, no. 8, p. 1327, Aug. 2018.\\n[164] R. Ferenets, T. Lipping, A. Anier, V. Jantti, S. Melto, and S. Hovilehto,\\n‘‘Comparison of entropy and complexity measures for the assessment\\nof depth of sedation,’’ IEEE Trans. Biomed. Eng., vol. 53, no. 6,\\npp. 1067–1077, Jun. 2006.\\n[165] R. Damasevicius, R. Maskeliunas, M. Wozniak, and D. Polap, ‘‘Visual-\\nization of physiologic signals based on Hjorth parameters and Gramian\\nangular fields,’’ in Proc. IEEE 16th World Symp. Appl. Mach. Intell.\\nInformat. (SAMI), Feb. 2018, pp. 91–96.[166] I. I. Shevchenko, ‘‘Lyapunov exponents in resonance multiplets,’’ Phys.\\nLett. A, vol. 378, nos. 1–2, pp. 34–42, Jan. 2014.\\n[167] A. Prochazka, J. Kukal, and O. Vysata, ‘‘Wavelet transform use for feature\\nextraction and EEG signal segments classification,’’ in Proc. 3rd Int.\\nSymp. Commun., Control Signal Process., Mar. 2008, pp. 719–722.\\n[168] S. Zou, T. Qiu, P. Huang, X. Bai, and C. Liu, ‘‘Constructing multi-\\nscale entropy based on the empirical mode decomposition (EMD) and\\nits application in recognizing driving fatigue,’’ J. Neurosci. Methods,\\nvol. 341, Jul. 2020, Art. no. 108691.\\n[169] M. Johansson, ‘‘The Hilbert transform,’’ M.S. thesis. Växjö Univ., Suecia.\\nDisponible en internet, Växjö, Sweden, 1999. Accessed: Aug. 31, 2023.\\n[Online]. Available: http://yumpu.com/en/document/read/6683719/m-\\njohansson-the-hilbert-transformpdf\\n[170] D. P. Subha, P. K. Joseph, R. U. Acharya, and C. M. Lim, ‘‘EEG\\nsignal analysis: A survey,’’ J. Med. Syst., vol. 34, no. 2, pp. 195–212,\\nApr. 2010.\\n[171] B. J. Strait and T. G. Dewey, ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1772: ('fatigue,’’ J. Neurosci. Methods,\\nvol. 341, Jul. 2020, Art. no. 108691.\\n[169] M. Johansson, ‘‘The Hilbert transform,’’ M.S. thesis. Växjö Univ., Suecia.\\nDisponible en internet, Växjö, Sweden, 1999. Accessed: Aug. 31, 2023.\\n[Online]. Available: http://yumpu.com/en/document/read/6683719/m-\\njohansson-the-hilbert-transformpdf\\n[170] D. P. Subha, P. K. Joseph, R. U. Acharya, and C. M. Lim, ‘‘EEG\\nsignal analysis: A survey,’’ J. Med. Syst., vol. 34, no. 2, pp. 195–212,\\nApr. 2010.\\n[171] B. J. Strait and T. G. Dewey, ‘‘The Shannon information entropy\\nof protein sequences,’’ Biophysical J., vol. 71, no. 1, pp. 148–155,\\nJul. 1996.\\n[172] U. R. Acharya, H. Fujita, V. K. Sudarshan, S. Bhat, and J. E. W. Koh,\\n‘‘Application of entropies for automated diagnosis of epilepsy using EEG\\nsignals: A review,’’ Knowl.-Based Syst., vol. 88, pp. 85–96, Nov. 2015.\\n[173] A. Rényi, ‘‘On measures of entropy and information,’’ in Proc. 4th\\nBerkeley Symp. Math. Statist. Probab., Contrib. Theory Statist., vol. 4.\\nUniv. of California Press, 1961, pp. 547–562.\\n[174] C. Tsallis, R. Mendes, and A. R. Plastino, ‘‘The role of constraints within\\ngeneralized nonextensive statistics,’’ Phys. A, Stat. Mech. Appl., vol. 261,\\nnos. 3–4, pp. 534–554, Dec. 1998.\\n[175] J. Fell, J. Röschke, K. Mann, and C. Schäffner, ‘‘Discrimination of sleep\\nstages: A comparison between spectral and nonlinear EEG measures,’’\\nElectroencephalogr. Clin. Neurophysiol., vol. 98, no. 5, pp. 401–410,\\nMay 1996.\\n[176] N. Kannathal, M. L. Choo, U. R. Acharya, and P. K. Sadasivan,\\n‘‘Entropies for detection of epilepsy in EEG,’’ Comput. Methods\\nPrograms Biomed., vol. 80, no. 3, pp. 187–194, Dec. 2005.\\n[177] E. Guariglia, ‘‘Entropy and fractal antennas,’’ Entropy, vol. 18, no. 3,\\np. 84, Mar. 2016.\\n[178] P. Grassberger and I. Procaccia, ‘‘Estimation of the Kolmogorov entropy\\nfrom a chaotic signal,’’ Phys. Rev. A, Gen. Phys., vol. 28, no. 4,\\npp. 2591–2593, Oct. 1983.\\n[179] D. J. Wales, ‘‘Calculating the rate of loss of information from chaotic\\ntime series by forecasting,’’ Nature, vol. 350, no. ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1773: ('ies for detection of epilepsy in EEG,’’ Comput. Methods\\nPrograms Biomed., vol. 80, no. 3, pp. 187–194, Dec. 2005.\\n[177] E. Guariglia, ‘‘Entropy and fractal antennas,’’ Entropy, vol. 18, no. 3,\\np. 84, Mar. 2016.\\n[178] P. Grassberger and I. Procaccia, ‘‘Estimation of the Kolmogorov entropy\\nfrom a chaotic signal,’’ Phys. Rev. A, Gen. Phys., vol. 28, no. 4,\\npp. 2591–2593, Oct. 1983.\\n[179] D. J. Wales, ‘‘Calculating the rate of loss of information from chaotic\\ntime series by forecasting,’’ Nature, vol. 350, no. 6318, pp. 485–488,\\nApr. 1991.\\n[180] J. C. Schouten, F. Takens, and C. M. van den Bleek, ‘‘Maximum-\\nlikelihood estimation of the entropy of an attractor,’’ Phys. Rev. E, Stat.\\nPhys. Plasmas Fluids Relat. Interdiscip. Top., vol. 49, no. 1, pp. 126–129,\\nJan. 1994.\\n[181] S. M. Pincus, I. M. Gladstone, and R. A. Ehrenkranz, ‘‘A regularity\\nstatistic for medical data analysis,’’ J. Clin. Monitor., vol. 7, no. 4,\\npp. 335–345, Oct. 1991.\\n[182] A. Subasi and M. I. Gursoy, ‘‘EEG signal classification using PCA, ICA,\\nLDA and support vector machines,’’ Exp. Syst. Appl., vol. 37, no. 12,\\npp. 8659–8666, Dec. 2010.\\n[183] M. Chaudhary, S. Mukhopadhyay, M. Litoiu, L. E. Sergio, and\\nM. S. Adams, ‘‘Understanding brain dynamics for color perception using\\nwearable EEG headband,’’ 2020, arXiv:2008.07092.\\n[184] M. Sharma, R. B. Pachori, and U. Rajendra Acharya, ‘‘A new approach\\nto characterize epileptic seizures using analytic time-frequency flexible\\nwavelet transform and fractal dimension,’’ Pattern Recognit. Lett., vol. 94,\\npp. 172–179, Jul. 2017.\\n[185] F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, and B. Arnaldi,\\n‘‘A review of classification algorithms for EEG-based brain–computer\\ninterfaces,’’ J. Neural Eng., vol. 4, no. 2, pp. R1–R13, 2007.\\n[186] A. Bablani, D. R. Edla, and S. Dodia, ‘‘Classification of EEG data\\nusing k-nearest neighbor approach for concealed information test,’’ Proc.\\nComput. Sci., vol. 143, pp. 242–249, Jan. 2018.\\n[187] M. Congedo, A. Barachant, and R. Bhatia, ‘‘Riemannian geometry for\\nEEG-based brain-computer ', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1774: ('2–179, Jul. 2017.\\n[185] F. Lotte, M. Congedo, A. Lécuyer, F. Lamarche, and B. Arnaldi,\\n‘‘A review of classification algorithms for EEG-based brain–computer\\ninterfaces,’’ J. Neural Eng., vol. 4, no. 2, pp. R1–R13, 2007.\\n[186] A. Bablani, D. R. Edla, and S. Dodia, ‘‘Classification of EEG data\\nusing k-nearest neighbor approach for concealed information test,’’ Proc.\\nComput. Sci., vol. 143, pp. 242–249, Jan. 2018.\\n[187] M. Congedo, A. Barachant, and R. Bhatia, ‘‘Riemannian geometry for\\nEEG-based brain-computer interfaces; a primer and a review,’’ Brain-\\nComput. Interfaces, vol. 4, no. 3, pp. 155–174, Jul. 2017.\\n[188] Y. LeCun, Y. Bengio, and G. Hinton, ‘‘Deep learning,’’ Nature, vol. 521,\\npp. 436–444, May 2015.\\n[189] W.-L. Mao, H. I. K. Fathurrahman, Y. Lee, and T. W. Chang, ‘‘EEG\\ndataset classification using CNN method,’’ J. Phys., Conf., vol. 1456,\\nno. 1, Jan. 2020, Art. no. 012017.\\nVOLUME 11, 2023 143141\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\n[190] D. Bardou, K. Zhang, and S. M. Ahmad, ‘‘Classification of breast cancer\\nbased on histology images using convolutional neural networks,’’ IEEE\\nAccess, vol. 6, pp. 24680–24693, 2018.\\n[191] D. Klepl, F. He, M. Wu, D. J. Blackburn, and P. Sarrigiannis, ‘‘EEG-based\\ngraph neural network classification of Alzheimer’s disease: An empirical\\nevaluation of functional connectivity methods,’’ IEEE Trans. Neural Syst.\\nRehabil. Eng., vol. 30, pp. 2651–2660, 2022.\\n[192] M. Sharma and R. B. Pachori, ‘‘A novel approach to detect epileptic\\nseizures using a combination of tunable-Q wavelet transform and\\nfractal dimension,’’ J. Mech. Med. Biol., vol. 17, no. 7, Nov. 2017,\\nArt. no. 1740003.\\n[193] V. Gupta, T. Priya, A. K. Yadav, R. B. Pachori, and U. R. Acharya,\\n‘‘Automated detection of focal EEG signals using features extracted from\\nflexible analytic wavelet transform,’’ Pattern Recognit. Lett., vol. 94,\\npp. 180–188, Jul. 2017.\\n[194] H. Ullah, M. Uzair, A. Mahmood, M. Ullah, S. D. Khan, and F. A. Cheikh,\\n‘‘Internal emotion class', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1775: ('etect epileptic\\nseizures using a combination of tunable-Q wavelet transform and\\nfractal dimension,’’ J. Mech. Med. Biol., vol. 17, no. 7, Nov. 2017,\\nArt. no. 1740003.\\n[193] V. Gupta, T. Priya, A. K. Yadav, R. B. Pachori, and U. R. Acharya,\\n‘‘Automated detection of focal EEG signals using features extracted from\\nflexible analytic wavelet transform,’’ Pattern Recognit. Lett., vol. 94,\\npp. 180–188, Jul. 2017.\\n[194] H. Ullah, M. Uzair, A. Mahmood, M. Ullah, S. D. Khan, and F. A. Cheikh,\\n‘‘Internal emotion classification using EEG signal with sparse discrimi-\\nnative ensemble,’’ IEEE Access, vol. 7, pp. 40144–40153, 2019.\\n[195] B. Harender and R. K. Sharma, ‘‘DWT based epileptic seizure detection\\nfrom EEG signal using k-NN classifier,’’ in Proc. Int. Conf. Trends\\nElectron. Informat. (ICEI), May 2017, pp. 762–765.\\n[196] S. Madan, K. Srivastava, A. Sharmila, and P. Mahalakshmi, ‘‘A case\\nstudy on discrete wavelet transform based Hurst exponent for epilepsy\\ndetection,’’ J. Med. Eng. Technol., vol. 42, no. 1, pp. 9–17, Jan. 2018.\\n[197] S. Lahmiri and A. Shmuel, ‘‘Accurate classification of seizure and\\nseizure-free intervals of intracranial EEG signals from epileptic patients,’’\\nIEEE Trans. Instrum. Meas., vol. 68, no. 3, pp. 791–796, Mar. 2019.\\n[198] T. Tuncer, ‘‘A new stable nonlinear textural feature extraction method\\nbased EEG signal classification method using substitution box of the\\nHamsi hash function: Hamsi pattern,’’ Appl. Acoust., vol. 172, Jan. 2021,\\nArt. no. 107607.\\n[199] M. Omidvar, A. Zahedi, and H. Bakhshi, ‘‘EEG signal processing for\\nepilepsy seizure detection using 5-level Db4 discrete wavelet transform,\\nGA-based feature selection and ANN/SVM classifiers,’’ J. Ambient Intell.\\nHumanized Comput., vol. 12, no. 11, pp. 10395–10403, Nov. 2021.\\n[200] H. Albaqami, G. M. Hassan, A. Subasi, and A. Datta, ‘‘Automatic\\ndetection of abnormal EEG signals using wavelet feature extraction\\nand gradient boosting decision tree,’’ Biomed. Signal Process. Control,\\nvol. 70, Sep. 2021, Art. no. 102957.\\n[201] O. K. Cura, S. K. Atli', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1776: ('‘‘EEG signal processing for\\nepilepsy seizure detection using 5-level Db4 discrete wavelet transform,\\nGA-based feature selection and ANN/SVM classifiers,’’ J. Ambient Intell.\\nHumanized Comput., vol. 12, no. 11, pp. 10395–10403, Nov. 2021.\\n[200] H. Albaqami, G. M. Hassan, A. Subasi, and A. Datta, ‘‘Automatic\\ndetection of abnormal EEG signals using wavelet feature extraction\\nand gradient boosting decision tree,’’ Biomed. Signal Process. Control,\\nvol. 70, Sep. 2021, Art. no. 102957.\\n[201] O. K. Cura, S. K. Atli, H. S. Türe, and A. Akan, ‘‘Epileptic seizure\\nclassifications using empirical mode decomposition and its derivative,’’\\nBiomed. Eng. OnLine, vol. 19, no. 1, pp. 1–22, Dec. 2020.\\n[202] M. Kaleem, A. Guergachi, and S. Krishnan, ‘‘Patient-specific seizure\\ndetection in long-term EEG using wavelet decomposition,’’ Biomed.\\nSignal Process. Control, vol. 46, pp. 157–165, Sep. 2018.\\n[203] I. Wijayanto, R. Hartanto, and H. A. Nugroho, ‘‘Comparison of empirical\\nmode decomposition and coarse-grained procedure for detecting pre-ictal\\nand ictal condition in electroencephalography signal,’’ Informat. Med.\\nUnlocked, vol. 19, Jan. 2020, Art. no. 100325.\\n[204] S. Belhadj, A. Attia, A. B. Adnane, Z. Ahmed-Foitih, and A. A. Taleb,\\n‘‘Whole brain epileptic seizure detection using unsupervised classifi-\\ncation,’’ in Proc. 8th Int. Conf. Model., Identificat. Control (ICMIC),\\nNov. 2016, pp. 977–982.\\n[205] G. Wang, D. Ren, K. Li, D. Wang, M. Wang, and X. Yan, ‘‘EEG-based\\ndetection of epileptic seizures through the use of a directed transfer\\nfunction method,’’ IEEE Access, vol. 6, pp. 47189–47198, 2018.\\n[206] S. T. George, M. S. P. Subathra, N. J. Sairamya, L. Susmitha, and\\nM. J. Premkumar, ‘‘Classification of epileptic EEG signals using PSO\\nbased artificial neural network and tunable-Q wavelet transform,’’\\nBiocybernetics Biomed. Eng., vol. 40, no. 2, pp. 709–728, Apr. 2020.\\n[207] A. Shoeibi, N. Ghassemi, M. Khodatars, P. Moridian, R. Alizadehsani,\\nA. Zare, A. Khosravi, A. Subasi, U. R. Acharya, and J. M. Gorriz,\\n‘‘Detection of epileptic', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1777: ('ansfer\\nfunction method,’’ IEEE Access, vol. 6, pp. 47189–47198, 2018.\\n[206] S. T. George, M. S. P. Subathra, N. J. Sairamya, L. Susmitha, and\\nM. J. Premkumar, ‘‘Classification of epileptic EEG signals using PSO\\nbased artificial neural network and tunable-Q wavelet transform,’’\\nBiocybernetics Biomed. Eng., vol. 40, no. 2, pp. 709–728, Apr. 2020.\\n[207] A. Shoeibi, N. Ghassemi, M. Khodatars, P. Moridian, R. Alizadehsani,\\nA. Zare, A. Khosravi, A. Subasi, U. R. Acharya, and J. M. Gorriz,\\n‘‘Detection of epileptic seizures on EEG signals using ANFIS classifier,\\nautoencoders and fuzzy entropies,’’ Biomed. Signal Process. Control,\\nvol. 73, Mar. 2022, Art. no. 103417.\\n[208] Y. Luo, Q. Fu, J. Xie, Y. Qin, G. Wu, J. Liu, F. Jiang, Y. Cao, and X. Ding,\\n‘‘EEG-based emotion classification using spiking neural networks,’’\\nIEEE Access, vol. 8, pp. 46007–46016, 2020.[209] S. A. A. Shah, L. Zhang, and A. Bais, ‘‘Dynamical system based compact\\ndeep hybrid network for classification of Parkinson disease related EEG\\nsignals,’’ Neural Netw., vol. 130, pp. 75–84, Oct. 2020.\\n[210] D. Selvathi and V. K. Meera, ‘‘Realization of epileptic seizure detection\\nin EEG signal using wavelet transform and SVM classifier,’’ in Proc. Int.\\nConf. Signal Process. Commun. (ICSPC), Jul. 2017, pp. 18–22.\\n[211] F. D. V. Fallani, L. d. F. Costa, F. A. Rodriguez, L. Astolfi, G. Vecchiato,\\nJ. Toppi, G. Borghini, F. Cincotti, D. Mattia, and S. Salinari, ‘‘A graph-\\ntheoretical approach in brain functional networks. possible implications\\nin EEG studies,’’ in Nonlinear Biomedical Physics, vol. 4, no. 1. Berlin,\\nGermany: Springer, 2010, pp. 1–13.\\n[212] L. D. F. Costa and F. A. Rodrigues, ‘‘What is there between any two nodes\\nin a complex network?’’ 2008, arXiv:0801.4068.\\n[213] F. D. V. Fallani, L. Astolfi, F. Cincotti, D. Mattia, M. G. Marciani,\\nS. Salinari, J. Kurths, S. Gao, A. Cichocki, A. Colosimo, and F. Babiloni,\\n‘‘Cortical functional connectivity networks in normal and spinal cord\\ninjured patients: Evaluation by graph analysis,’’ Hum. Brain Mapping,\\nvol. 28,', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1778: ('nlinear Biomedical Physics, vol. 4, no. 1. Berlin,\\nGermany: Springer, 2010, pp. 1–13.\\n[212] L. D. F. Costa and F. A. Rodrigues, ‘‘What is there between any two nodes\\nin a complex network?’’ 2008, arXiv:0801.4068.\\n[213] F. D. V. Fallani, L. Astolfi, F. Cincotti, D. Mattia, M. G. Marciani,\\nS. Salinari, J. Kurths, S. Gao, A. Cichocki, A. Colosimo, and F. Babiloni,\\n‘‘Cortical functional connectivity networks in normal and spinal cord\\ninjured patients: Evaluation by graph analysis,’’ Hum. Brain Mapping,\\nvol. 28, no. 12, pp. 1334–1346, Dec. 2007.\\n[214] R. Sinatra, F. De Vico Fallani, L. Astolfi, F. Babiloni, F. Cincotti,\\nD. Mattia, and V. Latora, ‘‘Cluster structure of functional networks\\nestimated from high-resolution EEG data,’’ Int. J. Bifurcation Chaos,\\nvol. 19, no. 2, pp. 665–676, Feb. 2009.\\n[215] I. Stancin, N. Frid, M. Cifrek, and A. Jovic, ‘‘EEG signal multichannel\\nfrequency-domain ratio indices for drowsiness detection based on\\nmulticriteria optimization,’’ Sensors, vol. 21, no. 20, p. 6932, 2021.\\nNISREEN SAID AMER (Member, IEEE) received\\nthe B.Sc. degree in computer science (CS) from\\nthe American University of Culture and Education\\n(AUCE), Lebanon, in 2006, the M.A. degree\\nin international education mathematics from the\\nUniversity of Nottingham, U.K., in 2017, and\\nthe M.A. degree in science from SUNY Buffalo\\nState University, USA, in 2020. She is currently\\npursuing the Ph.D. degree in computer science\\nand engineering (CSE) with Hamad Bin Khalifa\\nUniversity (HBKU), Qatar Foundation, Qatar. She has been a Mathematics\\nInstructor at the University of Doha for Science and Technology, since 2021.\\nShe has also been works as a Teacher Assistant (TA) at the ICT Department,\\nHBKU, since 2022. Her research interests include machine learning, data\\nanalytics, and biomedical signal processing for the detection and prediction\\nof neurological disorders.\\nSAMIR BRAHIM BELHAOUARI (Senior Mem-\\nber, IEEE) received the master’s degree in\\ntelecommunications and network from Institut\\nNational Polytechnique de Toulouse, France,\\nin 200', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1779: ('hematics\\nInstructor at the University of Doha for Science and Technology, since 2021.\\nShe has also been works as a Teacher Assistant (TA) at the ICT Department,\\nHBKU, since 2022. Her research interests include machine learning, data\\nanalytics, and biomedical signal processing for the detection and prediction\\nof neurological disorders.\\nSAMIR BRAHIM BELHAOUARI (Senior Mem-\\nber, IEEE) received the master’s degree in\\ntelecommunications and network from Institut\\nNational Polytechnique de Toulouse, France,\\nin 2000, and the Ph.D. degree in mathematics\\nfrom the Federal Polytechnic School of Lausanne,\\nSwitzerland, in 2006. Currently, he serves as an\\nAssociate Professor with the University of Hamad\\nBin Khalifa, Qatar Foundation, within the Division\\nof Information and Communication Technologies,\\nCollege of Science and Engineering, HBKU. Over the years, he has held\\nvarious Research and Teaching Positions at institutions including Innopolis\\nUniversity-Russia, Alfaisal University-KSA, University of Sharjah-UAE,\\nUniversity Technology PETRONAS-Malaysia, and EPFL Federal Swiss\\nSchool-Switzerland. His research interests include span a wide range of\\nareas, applied mathematics, statistics, data analysis, artificial intelligence,\\nimage and signal processing (with a focus on biomedical, bioinformatics, and\\nforecasting applications), his interdisciplinary background in mathematics\\nand computer science informs his contributions to these diverse fields.\\nOpen Access funding provided by ‘Qatar National Library’ within the CRUI CARE Agreement\\n143142 VOLUME 11, 2023', 'EEG_Signal_Processing_for_Medical_Diagnosis_Healthcare_and_Monitoring_A_Comprehensive_Review.pdf'), 1780: ('Towards High Resolution Video\\nGeneration with Progressive Growing of\\nSliced Wasserstein GANs\\nDinesh Acharya\\nDepartment of Mathematics\\nAdvisor: Dr. Zhiwu Huang, Dr. Danda Paudel\\nSupervisor: Prof. Dr. Luc van Gool\\nComputer Vision Laboratory\\nDepartment of Information Technology and Electrical Engineering\\nMay 22, 2018arXiv:1810.02419v2  [cs.CV]  6 Dec 2018\\nAbstract\\nThe extension of image generation to video generation turns out to be a very difﬁcult task, since\\nthe temporal dimension of videos introduces an extra challenge during the generation process. Be-\\nsides, due to the limitation of memory and training stability, the generation becomes increasingly\\nchallenging with the increase of the resolution/duration of videos. In this work, we exploit the\\nidea of progressive growing of Generative Adversarial Networks (GANs) for higher resolution\\nvideo generation. In particular, we begin to produce video samples of low-resolution and short-\\nduration, and then progressively increase both resolution and duration alone (or jointly) by adding\\nnew spatiotemporal convolutional layers to the current networks. Starting from the learning on a\\nvery raw-level spatial appearance and temporal movement of the video distribution, the proposed\\nprogressive method learns spatiotemporal information incrementally to generate higher resolution\\nvideos. Furthermore, we introduce a sliced version of Wasserstein GAN (SWGAN) loss to improve\\nthe distribution learning on the video data of high-dimension and mixed-spatiotemporal distribu-\\ntion. SWGAN loss replaces the distance between joint distributions by that of one-dimensional\\nmarginal distributions, making the loss easier to compute.\\nAs suitable larger resolution video datasets are scarce, we collected 10,900 videos capturing\\nface dynamics from Hollywood movie trailers. We used our new dataset to generate face videos of\\n256x256x32 resolution, while beneﬁting from sliced Wasserstein GAN loss within the progressive\\nframework. Up to our knowledge, this is the ﬁrst work that generates videos larger th', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1781: (' loss replaces the distance between joint distributions by that of one-dimensional\\nmarginal distributions, making the loss easier to compute.\\nAs suitable larger resolution video datasets are scarce, we collected 10,900 videos capturing\\nface dynamics from Hollywood movie trailers. We used our new dataset to generate face videos of\\n256x256x32 resolution, while beneﬁting from sliced Wasserstein GAN loss within the progressive\\nframework. Up to our knowledge, this is the ﬁrst work that generates videos larger than 64x64x32\\nresolution. In addition to the gain on resolution, our model performs better than the existing meth-\\nods in terms of both appearance and dynamics. The proposed model reaches a record inception\\nscore of 14.57 in unsupervised action recognition dataset UCF-101. Additionally, our method ob-\\ntains a better FID score than the state-of-the-art methods, on two challenging datasets captured in\\nthe wild.\\nAcknowledgements\\nI am highly indebted to Dr. Zhiwu Huang and Dr. Danda Paudel for their supervision and support\\nduring the thesis. Content related to Sliced Wasserstein Gan in section 5 was taken from manuscript\\nprepared by Dr. Zhiwu Huang. I would also like to thank Jiqing Wu for his code related to Sliced\\nWasserstein GAN. Prof. Dr. Luc Van Gool and his Computer Vision Lab also deserve special\\nacknowledgement for the resources. I would also like to thank Bernhard Kratzwald whose models\\nfor TGAN and VideoGAN I used for some experiments.\\nI would also like to thank NVIDIA team for releasing their work on Progressive Growing of GANs\\nand donating GPUs to the lab.\\nMy parents and siblings deserve special acknowledgement for their help and support throughout\\nall my endeavors.\\nContents\\n1 Introduction 1\\n1.1 Focus of this Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.2 Thesis Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n2 Background 5\\n2.1 GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Wasserstein GAN . .', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1782: ('gressive Growing of GANs\\nand donating GPUs to the lab.\\nMy parents and siblings deserve special acknowledgement for their help and support throughout\\nall my endeavors.\\nContents\\n1 Introduction 1\\n1.1 Focus of this Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2\\n1.2 Thesis Organization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\\n2 Background 5\\n2.1 GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5\\n2.2 Wasserstein GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7\\n2.3 Conditional GANs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8\\n3 Related Works 9\\n3.1 Progressive Growing of GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10\\n3.2 Video GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.3 Temporal GAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n3.4 MoCoGAN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n3.5 Other Related Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13\\n4 Progressive Video Generation 15\\n4.1 Transition Phase . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.2 Minibatch Standard Deviation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n4.3 Pixel Normalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17\\n5 Sliced Wasserstein GAN Loss 19\\n6 Evaluation Metrices 21\\n6.1 Inception Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n6.2 Fr ´echet Inception Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nI\\nCONTENTS\\n7 Evaluation Datasets 23\\n7.1 Trailer Face Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n7.2 UCF101 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n7.3 Golf and Aeroplane Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n8 Experiment', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1783: ('ion Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\\n6.2 Fr ´echet Inception Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\\nI\\nCONTENTS\\n7 Evaluation Datasets 23\\n7.1 Trailer Face Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n7.2 UCF101 Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n7.3 Golf and Aeroplane Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25\\n8 Experiments and Results 27\\n8.1 Qualitative Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\\n8.2 Inception score on UCF101 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\\n8.3 FID . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n9 Conclusion and Discussion 33\\nA Network Architecture 35\\nB Latent Space Interpolations 39\\nII\\nList of Figures\\n2.1 Standard GAN Architecture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\\n3.1 Transition phase during growing of generator and discriminator networks under the\\nprogressive growing scheme. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\\n3.2 Two stream architecture of the generator of Video GAN. Video GAN assumes sta-\\nble background in the video clips. . . . . . . . . . . . . . . . . . . . . . . . . . . 12\\n3.3 Temporal GAN uses a cascade architecture to generate videos. Temporal generator\\nuses 1-D deconvolutions and spatial generator uses 2-D deconvolutions. . . . . . . 13\\n4.1 Progressive video generation. Initially low resolution and short videos are gener-\\nated. Gradually, higher resolution and longer videos are generated. . . . . . . . . . 15\\n4.2 Transition phase during which new layers are introduced to both generator and\\ndiscriminator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.3 Illustration of different steps of minibatch standard deviation layer: (a) feature\\nvectors at each pixel across the minibatch, (b) standard deviation computation of\\n', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1784: ('gressive video generation. Initially low resolution and short videos are gener-\\nated. Gradually, higher resolution and longer videos are generated. . . . . . . . . . 15\\n4.2 Transition phase during which new layers are introduced to both generator and\\ndiscriminator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\\n4.3 Illustration of different steps of minibatch standard deviation layer: (a) feature\\nvectors at each pixel across the minibatch, (b) standard deviation computation of\\neach feature vector, (c) average operation, (d) replication and (e) concatenation. . . 17\\n5.1 Intuition behind Sliced Wasserstein Distance. After projection, the Wasserstein\\nDistance of 1-D marginals is integrated over all possible values of \\x12. . . . . . . . . 19\\n7.1 Pipeline for Construction of Dataset. . . . . . . . . . . . . . . . . . . . . . . . . . 23\\n7.2 Samples from TrailerFaces Dataset. Random frames were chosen for visualization. 25\\n7.3 Samples from UCF101 dataset. Random frames were selected for visualization. . . 26\\n7.4 Samples from Golf (right) and Aeroplane (left) datasets. Random frame was se-\\nlected for visualization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26\\nIII\\nLIST OF FIGURES\\n8.1 Improvement in resolution of generated videos over time on TrailerFaces dataset.\\nSingle frames from each video clips were selected . . . . . . . . . . . . . . . . . . 27\\n8.2 Qualitative comparision of samples from Aeroplane dataset generated by our method\\nwith that generated by Video GAN and Temporal GAN. . . . . . . . . . . . . . . . 28\\n8.3 Qualitative comparision of samples from Golf dataset generated by our method\\nwith that generated by Video GAN and Temporal GAN. . . . . . . . . . . . . . . . 29\\n8.4 Qualitative comparision of clips generated with progressive approach (top), Tem-\\nporal GAN (bottom left) and Video GAN (bottom right) on aeroplane (left) and\\ngolf datasets (right). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n8.5 Comparison of our models on UCF101 data', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1785: (' Temporal GAN. . . . . . . . . . . . . . . . 28\\n8.3 Qualitative comparision of samples from Golf dataset generated by our method\\nwith that generated by Video GAN and Temporal GAN. . . . . . . . . . . . . . . . 29\\n8.4 Qualitative comparision of clips generated with progressive approach (top), Tem-\\nporal GAN (bottom left) and Video GAN (bottom right) on aeroplane (left) and\\ngolf datasets (right). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29\\n8.5 Comparison of our models on UCF101 dataset based on FID Score (left) and In-\\nception Score (right). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31\\n8.6 Comparison of our model with TGAN and VideoGAN based on Golf and Aero-\\nplane Datasets as measured by FID score. . . . . . . . . . . . . . . . . . . . . . . 31\\nB.1 Linear interpolation in latent space to generate samples from Golf dataset - 1. . . . 39\\nB.2 Linear interpolation in latent space to generate samples from Golf dataset - 2 . . . 40\\nB.3 Linear interpolation in latent space to generate samples from Aeroplane dataset - 1 40\\nB.4 Linear interpolation in latent space to generate samples from Aeroplane dataset - 2 41\\nB.5 Linear interpolation in latent space to generate samples from TrailerFaces dataset - 1 41\\nB.6 Linear interpolation in latent space to generate samples from TrailerFaces dataset - 2 42\\nIV\\nList of Tables\\n7.1 Comparision of our TrailerFaces dataset with existing datasets containing facial\\ndynamics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\\n7.2 Total number of clips with given number of frames. . . . . . . . . . . . . . . . . . 24\\n8.1 Inception scores of Progressive Video GAN compared with other models on UCF101\\ndataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n8.2 Quantitative comparision of Progressive Video GAN with TGAN and VideoGAN\\nbased on FID score on Golf and Aeroplane datasets. . . . . . . . . . . . . . . . . . 31\\nA.1 Generator architecture for generation of 256x256x32 videos', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1786: (' . . . . . . . 24\\n7.2 Total number of clips with given number of frames. . . . . . . . . . . . . . . . . . 24\\n8.1 Inception scores of Progressive Video GAN compared with other models on UCF101\\ndataset. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30\\n8.2 Quantitative comparision of Progressive Video GAN with TGAN and VideoGAN\\nbased on FID score on Golf and Aeroplane datasets. . . . . . . . . . . . . . . . . . 31\\nA.1 Generator architecture for generation of 256x256x32 videos. . . . . . . . . . . . . 36\\nA.2 Discriminator architecture for generation of 256x256x32 videos. . . . . . . . . . . 37\\nV\\nLIST OF TABLES\\nVI\\nChapter 1\\nIntroduction\\nCompared to images, videos contain additional temporal dynamics. Hence, richer information\\nabout the scene can be extracted. Furthermore, images are also restricted to a single perspective\\nand are prone to ambiguity. Despite this, most of the focus of computer vision community has been\\non static image based techniques. This can be attributed to computational and storage overhead of\\nvideo based algorithms as well as complexity of modeling videos. As seen from action recogni-\\ntion problems, static images are not sufﬁcient to correctly predict the event. This holds true even\\nwhen best possible frame is chosen [14]. This motivates the work on video based computer vision\\nalgorithms.\\nThe main motivation behind generative models for both images and videos lies in the notion\\nthat how well we understand a given object is directly related to how well we can generate that\\nobject. As such, neural network based unsupervised methods such as Autoencoders [11][27], Au-\\ntoregressive models [32][41][18] and Generative Adversarial Networks (GAN) [10][12][34] have\\nbeen widely used to design generative models. Several of such techniques have also been applied\\nto video generative models. These generative models provide mechanism for unsupervised repre-\\nsentation learning and have been widely employed for semi-supervised methods. Semi-supervised\\nand unsupervised techniques ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1787: ('enerate that\\nobject. As such, neural network based unsupervised methods such as Autoencoders [11][27], Au-\\ntoregressive models [32][41][18] and Generative Adversarial Networks (GAN) [10][12][34] have\\nbeen widely used to design generative models. Several of such techniques have also been applied\\nto video generative models. These generative models provide mechanism for unsupervised repre-\\nsentation learning and have been widely employed for semi-supervised methods. Semi-supervised\\nand unsupervised techniques are particularly useful when collecting data is relatively easy but la-\\nbelling is very expensive. Such scenarios arise in several problems such as semantic segmentation,\\nmedical image analysis and facial action unit encoding.\\nGANs are one of most widely used generative models. In last couple of years, research in\\nGAN has made signiﬁcant progress in terms of stability of training and quantitative evaluation\\nframeworks [35][13]. These improvements can primarily be attributed to improved loss func-\\ntion [28][2][12][48][7], robust network architectures [33][19] and robust training schemes [19]\\n1\\nCHAPTER 1. I NTRODUCTION\\nthat guarantee convergence. However as in the case of other computer vision works, most of the\\nGANs have focused on image based problems. The research into GANs that focus on video gen-\\neration is relatively scarce. Due to computational limitation and network instability, all existing\\nworks generate 64\\x0264tiny clips [40][34][43][31].\\nWhile designing models for video generation, it is natural to assume that temporal variations\\nin videos behave differently than spatial variations. Spatial variations can be used to infer various\\nobjects present in the scene, where as the dynamics of these objects can be inferred from temporal\\nvariations. The relationship between and interaction of these objects may depend on both temporal\\nand spatial variations. So, while modeling videos, it is natural to model temporal and spatial\\ndomains separately. This has been explored by using 1-D convolutions for temporal genera', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1788: ('sume that temporal variations\\nin videos behave differently than spatial variations. Spatial variations can be used to infer various\\nobjects present in the scene, where as the dynamics of these objects can be inferred from temporal\\nvariations. The relationship between and interaction of these objects may depend on both temporal\\nand spatial variations. So, while modeling videos, it is natural to model temporal and spatial\\ndomains separately. This has been explored by using 1-D convolutions for temporal generator [34]\\nor Recurrent Neural Networks (RNN) to generate latent code for image based generators [40].\\nUsing 1-D convolutions also reduces the model size[49][39]. However, 3-D convolutions have\\nsurvived the test of time and are widely used for problems ranging from object recognition, shot\\ndetection to video stabilization.\\nIn this work, we explore whether the robust measures introduced for training GANs on im-\\nage based problems [19][48] generalize to video based frameworks. In particular, we generalize\\nthe scheme of Progressive Growing of GANs[19] to video based problems. As discussed earlier,\\nthough 1-D convolutions [34] or Recurrent Neural Networks [40] have been experimented in the\\ncontext of generative models to model the temporal domain, we use simple 3-D convolutions to\\nkeep the model simple. This is particularly important in light of the complexity of the model\\nintroduced by progressive growing approach.\\nRealistic video generation has been accomplished in works such as [20][37][50][42][29]. How-\\never these works are restricted to very speciﬁc problems and domains. As such, they are not useful\\nfor general unsupervised representation learning or for use in semi-supervised techniques. Fur-\\nthermore, the network architectures in such scenarios are highly specialized. In this work, we\\nexplore the more general problem of unsupervised video generation using Generative Adversarial\\nNetworks. In particular, we apply the idea of Progressively Growing GANs for video generation.\\n1.1 Focus of this Work\\nThe main focus o', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1789: ('ese works are restricted to very speciﬁc problems and domains. As such, they are not useful\\nfor general unsupervised representation learning or for use in semi-supervised techniques. Fur-\\nthermore, the network architectures in such scenarios are highly specialized. In this work, we\\nexplore the more general problem of unsupervised video generation using Generative Adversarial\\nNetworks. In particular, we apply the idea of Progressively Growing GANs for video generation.\\n1.1 Focus of this Work\\nThe main focus of the work is on unsupervised generation of higher resolution videos. Such an\\nendeavour has several challenges. First, there is lack of sufﬁcient large resolution video datasets.\\nNext, generating larger videos incurs severe memory and computational constraints. Network train-\\ning and convergence is also highly unstable. We address these issue with following contributions:\\n2\\nCHAPTER 1. I NTRODUCTION\\n\\x0fProgressive growing of video generative adversarial networks\\n\\x0fImproved loss function for better stability\\n\\x0fNovel 300\\x02300facial dynamics dataset with 10;910video clips\\n1.2 Thesis Organization\\nIn chapter 2, readers will be introduced to basic ideas behind GANs and recent advances for\\nstable training of GANs. In chapter 3, relevant literature will be reviewed and important models\\nwill be discussed in details. In chapter 4, proposed techniques for spatio-temporal growing of gans\\nwill be discussed. Sliced Wasserstein GAN loss for stable training will be presented in chapter 5.\\nIn chapter 6, various metrices used in this work for evaluating and comparing our model against\\nother models will be presented. In chapter 7, we will discuss about novel dataset collected for this\\nwork. Additional datasets used for evaluating our model will be also be mentioned. Qualitative\\nand quantitative comparision of our model with existing models will be presented in chapter 8. In\\nchapter 9, we will discuss our ﬁndings and conclusions.\\n3\\nCHAPTER 1. I NTRODUCTION\\n4\\nChapter 2\\nBackground\\nFor limited number of computer vision problems such as obj', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1790: ('s work for evaluating and comparing our model against\\nother models will be presented. In chapter 7, we will discuss about novel dataset collected for this\\nwork. Additional datasets used for evaluating our model will be also be mentioned. Qualitative\\nand quantitative comparision of our model with existing models will be presented in chapter 8. In\\nchapter 9, we will discuss our ﬁndings and conclusions.\\n3\\nCHAPTER 1. I NTRODUCTION\\n4\\nChapter 2\\nBackground\\nFor limited number of computer vision problems such as object recognition, collection of la-\\nbelled data is relatively easy. Supervised machine learning techniques have already reached super\\nhuman performance on such tasks. However, for several other problems such as segmentation,\\ncollection of labelled data is not as easy and the performance of purely supervised techniques is\\nstill at sub-human level. Semi-supervised and unsupervised techniques are promising avenue for\\nsuch problems with information bottleneck. There have been numerous works in the direction of\\nunsupervised representation learning. In particular, in computer vision community, various tech-\\nniques such as Variational Autoencoders (V AE), Autoregressive models and Generative Adversar-\\nial Networks (GAN) have been utilized before for unsupervised image generation. Out of these\\ntechniques, GANs in particular have been main focus of the community for last couple of years.\\nThough GANs suffered from stability of training and failure to converge in early years, these issues\\nhave largely been addressed with improved loss function [2][12][48][7], robust network architec-\\nture [19][51] and improved training algorithms [13][2].\\nIn following sections, we will brieﬂy introduce GANs and discuss different techniques pro-\\nposed so far for stable training of GANs.\\n2.1 GAN\\nGenerative Adversarial Networks (GANs)[10] are unsupervised generative models that learn\\nto generate samples from a given distribution in adversarial manner. The network architecture\\nconsists of generator Gand discriminatorD(in some cases also called', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1791: (' improved loss function [2][12][48][7], robust network architec-\\nture [19][51] and improved training algorithms [13][2].\\nIn following sections, we will brieﬂy introduce GANs and discuss different techniques pro-\\nposed so far for stable training of GANs.\\n2.1 GAN\\nGenerative Adversarial Networks (GANs)[10] are unsupervised generative models that learn\\nto generate samples from a given distribution in adversarial manner. The network architecture\\nconsists of generator Gand discriminatorD(in some cases also called critic). Given a random\\nnoise as input, the generator G:Rk!Rm, wherekis latent space dimension, tries to generate\\n5\\nCHAPTER 2. B ACKGROUND\\nFigure 2.1: Standard GAN Architecture.\\nsamples from a given distribution. The discriminator Dtries to distinguish whether the generated\\nsample is from a given distribution or not. The loss function is designed so that generator’s goal is\\nto generate samples that fool the discriminator. Similarly, the discriminator’s goal is designed to\\navoid being fooled by the generator. As such, GANs can be interpreted as non-cooperative games.\\nLetG:z2Rk!x2Rmbe generator andD:x2Rm!f0;1gbe discriminator. Then the\\nloss function proposed in [10] is given by:\\nF(D;G) =Ex\\x18px[\\x00logD(x)] +Ez\\x18pz[\\x00log(1\\x00D(G(z)))]; (2.1)\\nwhere zis latent code, xis data sample, pzis probability distribution over latent space and pxis\\nprobability distribution over data samples. The two-player minimax game is then given by:\\nmin\\nGmax\\nDF(D;G): (2.2)\\nIn early years, discriminators were trained with sigmoid cross entropy loss as they were trained\\nas classiﬁers for real and generated data. However, it was argued in [28], that such GANs suffer\\nfrom vanishing gradient problem. Instead, in [28], least squares GANs were proposed that used\\nleast squares loss to train discriminators instead of sigmoid cross entropy loss.\\nDespite some improvements from least squares loss[28], GANs still suffered from several is-\\nsues such as instability in training, mode collapse and lack of convergence. In [35], authors pro-\\nposed various techniqu', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1792: ('loss as they were trained\\nas classiﬁers for real and generated data. However, it was argued in [28], that such GANs suffer\\nfrom vanishing gradient problem. Instead, in [28], least squares GANs were proposed that used\\nleast squares loss to train discriminators instead of sigmoid cross entropy loss.\\nDespite some improvements from least squares loss[28], GANs still suffered from several is-\\nsues such as instability in training, mode collapse and lack of convergence. In [35], authors pro-\\nposed various techniques such as feature matching and minibatch discrimination. In feature match-\\ning, activations of intermediate layers of discriminator are used to guide the generator. Formally,\\n6\\nCHAPTER 2. B ACKGROUND\\nthe new generator loss is given by:\\njjEx\\x18pxf(x)\\x00Ez\\x18pzf(G(z))jj2\\n2; (2.3)\\nwhere freplaces the traditional Din the form of a feature extractor rather than a discriminator. The\\ndiscriminator is trained as usual. Minibatch discrimination technique was proposed to address the\\nissue of mode collapse. To accomplish this, additional statistics that models afﬁnity of samples in a\\nminibatch is concatenated to features in the discriminator. it is important to note that the summary\\nstatistics is learned during training through large projection matrices.\\n2.2 Wasserstein GAN\\nIn [2], authors argue that optimization of GAN loss given in Eq. 2.1 is same as minimization\\nof Jensen-Shannon (JS) divergence between distribution of generated and real samples. In case\\nthe two distributions have non-overlapping support, JS-divergence can have jumps. This leads to\\naforementioned optimization issues. For stable training of GANs, authors propose to minimize\\nWasserstein Distance (WD) between the distributions which behaves smoothly even in case of\\nnon-overlapping support. Formally, the primal form of WD is given by:\\nW(pr;pg) = inf\\n\\r2Q(pr;pg)E(x;y)\\x18\\r[jjx\\x00yjj]; (2.4)\\nwherepr;pgare distributions of real and generated samples andQ(pr;pg)is the space of all pos-\\nsible joint probability distributions of prandpg. It is not feasible to explore all po', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1793: ('n have jumps. This leads to\\naforementioned optimization issues. For stable training of GANs, authors propose to minimize\\nWasserstein Distance (WD) between the distributions which behaves smoothly even in case of\\nnon-overlapping support. Formally, the primal form of WD is given by:\\nW(pr;pg) = inf\\n\\r2Q(pr;pg)E(x;y)\\x18\\r[jjx\\x00yjj]; (2.4)\\nwherepr;pgare distributions of real and generated samples andQ(pr;pg)is the space of all pos-\\nsible joint probability distributions of prandpg. It is not feasible to explore all possible values\\nof\\r2Q(pr;pg). So, authors propose to use the dual formulation which is better suited for\\napproximation. Formally, the dual formulation of Eq. 2.4 is given by:\\nW(pr;pg) =1\\nKsup\\njjfjjL\\x14KEx\\x18pr[f(x)]\\x00Ex\\x18pg[f(x)]; (2.5)\\nwherejjfjjL\\x14KisK\\x00Lipschitz constraint. The GAN loss is then given by:\\nF(G;D) =W(pr;pg) = max\\nw2WEx\\x18pr[fw(x)]\\x00Ez2pr(z)[fw(G(z))]: (2.6)\\nHere, the discriminator takes the form of feature extractor and is parametrized by w.fis further\\nrequired to be K-Lipschitz. In order to enforce the K-Lipschitz constraint, authors proposed weight\\nclipping. However, as argued in the same paper, gradient clipping is a very rudimentary technique\\n7\\nCHAPTER 2. B ACKGROUND\\nto enforce the Lipschitz constraint. In [12], authors propose to penalize the norm of the gradient in\\norder to enforce Lipschitz constraint. In particular, the new loss is deﬁned as:\\nF(D;G) =Ex\\x18px[D(x)]\\x00Ez\\x18pz[D(G(z))] +\\x15E^x\\x18p^x[(jjr^xD(^x)jj2\\x001)2]; (2.7)\\nwhere\\x15is regularization parameter and ^xis sampled uniformly from a straight line connecting\\nreal sample and generated sample.\\n2.3 Conditional GANs\\nIt is relevant to brieﬂy review Conditional GANs[30]. They provide a framework to enforce\\nconditions on the generator in order to generate samples with desired property. Such conditions\\ncould be class labels or some portion of original data as in case of future prediction. Under the new\\nsetting, the GAN loss deﬁned in Eq. 2.1 becomes\\nF(D;G) =Ex\\x18px[\\x00logD(x)] +Ez\\x18pz[\\x00log(1\\x00D(G(z)))] (2.8)\\nConcrete applications of Conditional GANs include generatio', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1794: ('necting\\nreal sample and generated sample.\\n2.3 Conditional GANs\\nIt is relevant to brieﬂy review Conditional GANs[30]. They provide a framework to enforce\\nconditions on the generator in order to generate samples with desired property. Such conditions\\ncould be class labels or some portion of original data as in case of future prediction. Under the new\\nsetting, the GAN loss deﬁned in Eq. 2.1 becomes\\nF(D;G) =Ex\\x18px[\\x00logD(x)] +Ez\\x18pz[\\x00log(1\\x00D(G(z)))] (2.8)\\nConcrete applications of Conditional GANs include generation of speciﬁc digits of MNIST dataset\\n[30] or a face with speciﬁc facial expression, age or complexion in the context of images [6], or\\nfuture prediction[23] in context of videos to name a few.\\nOver the years, GANs have found applications in numerous areas. To name a few, such ap-\\nplications include image-to-image translation[52][17][53][6], 3D object generation[46][47], super\\nresolution[25] , image inpainting[44] etc.\\n8\\nChapter 3\\nRelated Works\\nAs outlined in the title, our focus on this work is on higher resolution video generation with\\nprogressive growing of Sliced Wasserstein GANs (SWGAN). As such, we will brieﬂy discuss\\nexisting works related to progressive growing technique, video generation and Sliced Wasserstein\\nGANs in the following sections. Later, we will also discuss the details of the selected works\\nrelevant to this work.\\nAs the complexity of the problem grows, it becomes more and more difﬁcult to learn an ap-\\npropriate model. To address this, the idea of curriculum learning was proposed in [3]. The idea\\nbehind curriculum learning is to gradually increase the complexity of the problem during training.\\nThe idea to use multiple generators has been explored in [9] to address the issue of mode collapse.\\nIn [15], authors proposed to use multiple discriminators for stable training. Similarly, [51] in-\\ntroduces multi-stage GANs where consecutive GANs take input from GANs from previous stage.\\nThe details and complexity of features of the generated samples increases with increasing stages\\nof GANs. This was on', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1795: ('e idea\\nbehind curriculum learning is to gradually increase the complexity of the problem during training.\\nThe idea to use multiple generators has been explored in [9] to address the issue of mode collapse.\\nIn [15], authors proposed to use multiple discriminators for stable training. Similarly, [51] in-\\ntroduces multi-stage GANs where consecutive GANs take input from GANs from previous stage.\\nThe details and complexity of features of the generated samples increases with increasing stages\\nof GANs. This was one of the early GANs to generate reasonable images of size 256x256. In-\\nspired by these concepts of using multiple generators and discriminators, and curriculum learning,\\nauthors of [19] proposed the technique of progressively growing the network for stable generation\\nof 1024x1024 images.\\nThere have been numerous works that aim to improve the original objective function for GANs\\nEq. 2.1. This has already been reviewed in detail in earlier chapter. LS-GAN[28], WGAN[2],\\nI-WGAN[12] are one of the most important works that aim to improve the original GAN loss\\nfunction. Recently, Sliced Wasserstein GANs (SWGANs) that propose to use Sliced Wasserstein\\nDistance (SWD) were proposed in [48][7]. As stated in [4], SWD is equivalent to WD. However,\\nSWD is relatively easier to approximate compared to original WD[21][4]. SWGANs are motivated\\n9\\nCHAPTER 3. R ELATED WORKS\\nby the fact that WD is ideal to measure distance between two distributions with non-overlapping\\nsupport and enforcing the Lipschitz constraint on the dual formulation in non trivial.\\nIn the direction of video generation, there are very limited works that try to model videos in un-\\nsupervised setting. One of the earliest works [43] tried to separate background and foreground for\\nvideo generation. In [18], Video Pixel Network (VPN) was proposed building on the work of Pixel\\nCNNs. Temporal GAN [34] used temporal and image generators to generate temporal encoding\\nand images separately. MoCoGAN [40] also use temporal and spatial generators. However, they\\nclaim to se', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1796: ('rmulation in non trivial.\\nIn the direction of video generation, there are very limited works that try to model videos in un-\\nsupervised setting. One of the earliest works [43] tried to separate background and foreground for\\nvideo generation. In [18], Video Pixel Network (VPN) was proposed building on the work of Pixel\\nCNNs. Temporal GAN [34] used temporal and image generators to generate temporal encoding\\nand images separately. MoCoGAN [40] also use temporal and spatial generators. However, they\\nclaim to separate motion and content of video using different techniques to encode latent space.\\nOne recent work [31] tries to model videos by separating texture and optical ﬂow. All of these\\nworks generate videos of 64x64 resolution. In this work we generate videos of up to 256x256\\nresolution. It is important to note that most of the above mentioned works design their model to do\\nsome sort of separation on the space of videos with different names such as foreground and back-\\nground separation or texture and ﬂow separation or motion and content separation. In this work,\\nwe do not carry any such separation entirely for model simplicity in light of model complexity\\nintroduced by progressively growing scheme. However, advantage of single stream models while\\ngenerating unstabilized videos has been highlighted in [23].\\nAs the ideas behind progressive growing techniques[19] and video generative networks[34][43]\\nare relevant to this work, these works will be discussed in detail in following section.\\n3.1 Progressive Growing of GAN\\nAs mentioned earlier, the basic idea behind progressive growing of GANs is to gradually in-\\ncrease the complexity of the problem [19]. To accomplish this, authors propose to ﬁrst train the\\ngenerators and discriminators on lower resolution samples. During training they propose to pro-\\ngressively introduce new layers to increasingly learn on more complex problem of generating\\nhigher resolution images. As illustrated in Fig. 3.1, successively new networks layers are intro-\\nduced to generators and discrimin', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1797: ('GAN\\nAs mentioned earlier, the basic idea behind progressive growing of GANs is to gradually in-\\ncrease the complexity of the problem [19]. To accomplish this, authors propose to ﬁrst train the\\ngenerators and discriminators on lower resolution samples. During training they propose to pro-\\ngressively introduce new layers to increasingly learn on more complex problem of generating\\nhigher resolution images. As illustrated in Fig. 3.1, successively new networks layers are intro-\\nduced to generators and discriminators. The transition from one stage of training to another stage\\nof training is made smooth by using linear interpolation during transition phase. The interpolation\\nfactor is then smoothly changed during training. At every stage, the output layer of the generator\\nconsists of a 1x1 convolutions that map feature channels to RGB image. Similarly, the ﬁrst layer\\nof discriminator consists of 1x1 convolutions that map RGB image to feature channels. During the\\ntransition step, a linear interpolation of output of 1x1 convolutions from lower resolution feature\\nchannels and 1x1 convolutions from higher resolution feature channels is taken as output of gener-\\nator. The scalar factor \\x0bcorresponding to output of higher resolution feature channels is smoothly\\n10\\nCHAPTER 3. R ELATED WORKS\\nFigure 3.1: Transition phase during growing of generator and discriminator networks under the\\nprogressive growing scheme.\\nincreased from 0to1. Similarly, during transition, both higher resolution and downscaled images\\nare provided as input to different input layers of discriminator. Learning on simpler problem and\\ngradually increasing complexity of the problem for both discriminator and generator can be ex-\\npected to lead to faster convergence and stability. Authors claim in the paper that the improvement\\nwith proposed training scheme is orthogonal to improvements arising from loss functions. The\\nidea of progressive growing has not yet been applied to video generation. In this work, we explore\\nprogressively growing of video generative netwo', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1798: ('t to different input layers of discriminator. Learning on simpler problem and\\ngradually increasing complexity of the problem for both discriminator and generator can be ex-\\npected to lead to faster convergence and stability. Authors claim in the paper that the improvement\\nwith proposed training scheme is orthogonal to improvements arising from loss functions. The\\nidea of progressive growing has not yet been applied to video generation. In this work, we explore\\nprogressively growing of video generative networks.\\n3.2 Video GAN\\nIn [43], authors propose a parallel architecture for unsupervised video generation. The ar-\\nchitecture consists of two parallel streams consisting of 2D and 3D convolution layers for the\\ngenerator and single stream 3D convolution layers for discriminator. As illustrated in Figure 3.2,\\nthe two stream architecture was designed to untangle foreground and background in videos. If\\n0\\x14m(z)\\x141be the mask that selectes either foreground or background, the output of generator,\\nG, at pixelzis given by:\\nG(z) =m(z)\\x0cf(z) + (1\\x00m(z))\\x0cb(z); (3.1)\\n11\\nCHAPTER 3. R ELATED WORKS\\nFigure 3.2: Two stream architecture of the generator of Video GAN. Video GAN assumes stable\\nbackground in the video clips.\\nwhereb(z)is output of background stream and f(z)is output of foreground stream. In case of\\nbackground stream, the same value of b(z)is replicated over all time frames. Experimental results\\npresented by authors supports the use of two stream architecture. However, one of the strong\\nassumptions of the model is that of static background.\\n3.3 Temporal GAN\\nIn [34], authors propose a cascade architecture for unsupervised video generation. As illus-\\ntrated in Fig. 3.3, the proposed architecture consisting of temporal and image generator. Temporal\\ngenerator, which consists of 1-D deconvolution layers, maps input latent code to a set of new latent\\ncodes corresponding to frames in the video. Each new latent code and the original latent code to-\\ngether are then fed to a new image generator. The resulting frames are then concatena', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1799: ('static background.\\n3.3 Temporal GAN\\nIn [34], authors propose a cascade architecture for unsupervised video generation. As illus-\\ntrated in Fig. 3.3, the proposed architecture consisting of temporal and image generator. Temporal\\ngenerator, which consists of 1-D deconvolution layers, maps input latent code to a set of new latent\\ncodes corresponding to frames in the video. Each new latent code and the original latent code to-\\ngether are then fed to a new image generator. The resulting frames are then concatenated together\\nto obtain a video. For the discriminator, TGAN uses single stream 3D convolution layers.\\nUnlike in the case of Video GAN, this model makes no assumption about separation of back-\\nground and foreground stream. As such, no requirement on background stabilization of videos is\\nassumed.\\n12\\nCHAPTER 3. R ELATED WORKS\\nFigure 3.3: Temporal GAN uses a cascade architecture to generate videos. Temporal generator\\nuses 1-D deconvolutions and spatial generator uses 2-D deconvolutions.\\n3.4 MoCoGAN\\nMotion Content GAN (MoCoGAN) network architecture is similar to TemporalGAN (TGAN)\\n[34] in the sense it also has cascade architecture. Furthermore, it also uses temporal and image gen-\\nerators and 3D convolution layers based discriminator. However, unlike TGAN, temporal generator\\non MoCoGAN is based on Recurrent Neural Network (RNN) and the input to temporal generator\\nis a set of latent variables. Furthermore, the outputs of temporal generator, motion codes, are con-\\ncatenated with newly sampled content code to feed image generators. In discriminator, there is\\nan additional image based discriminator. The authors claim that using such architecture helps to\\nseparate motion and content from videos.\\n3.5 Other Related Works\\nVideo Pixel Networks (VPN) [18] build on the work of PixelCNNs [41] for future prediction.\\nIn particular, they estimate probability distribution of raw pixel values in video using resolution\\npreserving CNN encoders and PixelCNN decoders. Other works for future prediction include [29].\\nRecently, optical ﬂow', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1800: ('age generators. In discriminator, there is\\nan additional image based discriminator. The authors claim that using such architecture helps to\\nseparate motion and content from videos.\\n3.5 Other Related Works\\nVideo Pixel Networks (VPN) [18] build on the work of PixelCNNs [41] for future prediction.\\nIn particular, they estimate probability distribution of raw pixel values in video using resolution\\npreserving CNN encoders and PixelCNN decoders. Other works for future prediction include [29].\\nRecently, optical ﬂow based models have produced more realistic results. In particular, in [31]\\nauthors use ﬂow and texture GAN to model optical ﬂow and texture in videos. Several of the works\\nhave also focused on future prediction which is a slightly different problem than unsupervised\\nvideo generation[23][29].\\n13\\nCHAPTER 3. R ELATED WORKS\\n14\\nChapter 4\\nProgressive Video Generation\\nGANs typically suffer from instability and failure to converge. Such issues are even more\\nprominent for higher resolution images or video generation as the generator and discriminator con-\\ntain too many parameters. In such cases improved loss function itself may not sufﬁce to generate\\nhigh resolution videos.\\nFigure 4.1: Progressive video generation. Initially low resolution and short videos are generated.\\nGradually, higher resolution and longer videos are generated.\\nTo address this issue, the idea behind curriculum learning [3] can be utilized. In the beginning,\\nsmaller network with less parameters can be used to learn the lower resolution samples [19]. Gen-\\nerator and discriminator can be trained to generate and discriminate downscaled videos. Learning\\n15\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\na coarser model is relatively easier and turns out to be more stable. First learning simpler models\\nand gradually increasing model complexity also leads to faster convergence. To increase model\\ncomplexity during training, gradually new layers can be introduced both to the generator and the\\ndiscriminator to generate larger resolution videos. Doing so helps the mo', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1801: ('. Gen-\\nerator and discriminator can be trained to generate and discriminate downscaled videos. Learning\\n15\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\na coarser model is relatively easier and turns out to be more stable. First learning simpler models\\nand gradually increasing model complexity also leads to faster convergence. To increase model\\ncomplexity during training, gradually new layers can be introduced both to the generator and the\\ndiscriminator to generate larger resolution videos. Doing so helps the model to learn a ﬁner dis-\\ntribution of samples. Progressively growing the network during training, helps to ﬁrst estimate a\\ncoarser PDF and gradually reﬁne it during training.\\nIn order to progressively grow the network for video generation, the real 32\\x02256\\x02256video\\nsamples are downscaled to 4\\x024\\x024by applying 3-D average pooling ﬁlter. The generator then\\ngenerates 4\\x024\\x024videos. New layers added during training gradually introduce more spatial and\\ntemporal details.\\n4.1 Transition Phase\\nFigure 4.2: Transition phase during which new layers are introduced to both generator and discrim-\\ninator.\\nDuring each phase, the ﬁnal layer of generator consists of 1\\x021\\x021convolution ﬁlters that\\nmap input feature channels to RGB videos. The discriminator in the similar fashion consists of\\n1\\x021\\x021convolution ﬁlters that map input RGB videos to feature channels. While transitioning\\nfrom one resolution to another resolution, new convolution layers are introduced to both discrimi-\\nnator and generator symmetrically to generate larger resolution videos. During transition from one\\nlevel of detail to another level of detail, generator outputs videos of two different resolutions. The\\n16\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\nlower resolution videos are upscaled with nearest-neighbor upscaling. The linear combination of\\nthe upscaled video and higher resolution video is then fed to discriminator. The weight correspond-\\ning to higher resolution video generated by generator is smoothly increased from 0 to 1 and that\\ncorresponding to upscaled video', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1802: ('ution videos. During transition from one\\nlevel of detail to another level of detail, generator outputs videos of two different resolutions. The\\n16\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\nlower resolution videos are upscaled with nearest-neighbor upscaling. The linear combination of\\nthe upscaled video and higher resolution video is then fed to discriminator. The weight correspond-\\ning to higher resolution video generated by generator is smoothly increased from 0 to 1 and that\\ncorresponding to upscaled video is gradually decreased from 1 to 0. New layers are introduced in\\ndiscriminator in similar manner.\\n4.2 Minibatch Standard Deviation\\nOne way to avoid mode collapse is to use feature statistics of different samples within the mini-\\nbatch and penalize the closeness of those features [12]. In this approach, the feature statistics are\\nlearned through parameters of projection matrices that summarize input activations [19][2]. In-\\nstead, following [19], standard deviation of individual features from each spatio-temporal location\\nacross the minibatch is computed and then averaged. Thus obtained single summary statistics is\\nconcatenated to all spatio-temporal location and features of the minibatch.\\nFigure 4.3: Illustration of different steps of minibatch standard deviation layer: (a) feature vectors\\nat each pixel across the minibatch, (b) standard deviation computation of each feature vector, (c)\\naverage operation, (d) replication and (e) concatenation.\\nSince there are no additional learnable parameters, this approach is computationally cheaper\\nand yet as argued in [19], efﬁcient.\\n4.3 Pixel Normalization\\nFollowing [19] and in the direction of local response normalization proposed in [24], normal-\\nization of feature vector at each pixel avoids explosion of parameters in generator and discrimina-\\n17\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\ntor. The pixel feature vector normalization proposed in [19] can be naturally extended to spatio-\\ntemporal case. In particular, if ax;y;t andbx;y;t be original and normalized feature ve', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1803: (' is computationally cheaper\\nand yet as argued in [19], efﬁcient.\\n4.3 Pixel Normalization\\nFollowing [19] and in the direction of local response normalization proposed in [24], normal-\\nization of feature vector at each pixel avoids explosion of parameters in generator and discrimina-\\n17\\nCHAPTER 4. P ROGRESSIVE VIDEO GENERATION\\ntor. The pixel feature vector normalization proposed in [19] can be naturally extended to spatio-\\ntemporal case. In particular, if ax;y;t andbx;y;t be original and normalized feature vector at pixel\\n(x;y;t )corresponding to spatial and temporal position,\\nbx;y;t=ax;y;tq\\n1\\nNPN\\x001\\nj=0(aj\\nx;y;t)2+\\x0f; (4.1)\\nwhere\\x0f= 10\\x008andNis number of feature maps. Though pixel vector normalization may not\\nnecessarily improve performance, it does avoid explosion of parameters in the network.\\n18\\nChapter 5\\nSliced Wasserstein GAN Loss\\nAs discussed earlier chapters, in [2], authors proposed to approximate Wasserstein Distance\\n(WD) using it’s dual formulation. The dual formulation was obtained using Kantorovich-Rubinstein\\nduality. Thus obtained formulation has form of a saddle-point problem and is usually difﬁcult to\\noptimize [8]. Instead of the above discussed formulation, Sliced Wasserstein Distance (SWD) can\\nbe used to measure the distance between two distributions. It was proven in [4] that SWD is equiv-\\nalent to WD. To compute the SWD, the plane is sliced using lines passing through the origin and\\nhigher dimensional marginal distributions are projected onto these lines using Radon transform.\\nThe Radon transform is performed using orthogonal projection matrices. The required metric is\\nFigure 5.1: Intuition behind Sliced Wasserstein Distance. After projection, the Wasserstein Dis-\\ntance of 1-D marginals is integrated over all possible values of \\x12.\\nthen given by integral of the projections along all such lines. As the projected marginal distribu-\\n19\\nCHAPTER 5. S LICED WASSERSTEIN GAN L OSS\\ntions are one dimensional, the SWD takes the form of functional of 1-D WD. Since closed form\\nsolution of 1-D WD exists, approximat', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1804: ('s performed using orthogonal projection matrices. The required metric is\\nFigure 5.1: Intuition behind Sliced Wasserstein Distance. After projection, the Wasserstein Dis-\\ntance of 1-D marginals is integrated over all possible values of \\x12.\\nthen given by integral of the projections along all such lines. As the projected marginal distribu-\\n19\\nCHAPTER 5. S LICED WASSERSTEIN GAN L OSS\\ntions are one dimensional, the SWD takes the form of functional of 1-D WD. Since closed form\\nsolution of 1-D WD exists, approximating SWD becomes easier. Mathematically, the SWD as a\\nfunctional of 1-D WD is given by\\nZ\\nSN\\x001 \\nsup\\nf2L1EX\\x12\\x18PX\\x12[f(X\\x12)]\\x00EY\\x12\\x18PY\\x12[f(Y\\x12)]!\\nd\\x12; (5.1)\\nwhereL1is the function space of all 1\\x00Lipschitz functions, PX\\x12;PY\\x12are the projected marginal\\ndistributions discussed earlier. As the latent space is usually low-dimensional in GANs, it is im-\\nplicitly assumed that the distribution of real samples lies on low-dimensional manifold. Hence,\\nifx= [x1;x2;:::;xn]2RN\\x02nbeNdimensional ninput samples, using standard discrimina-\\ntor setting, input data is encoded to Kdimensional latent code y= [y1;y2;:::;yn]2RK\\x02n.\\nThen orthogonal transform matrices \\x12= [\\x121;\\x122;:::;\\x12K]2RK\\x02Kare applied to project the\\nK\\x00dimensional encodings into Kone dimensional marginal distributions. The k\\x00Lipschitz map-\\nping function fis given by:\\nf(y) =0\\nBB@\\x1e(\\x151(\\x12T\\n1y) +b1)\\n...\\n\\x1e(\\x15K(\\x12T\\nKy) +bK)1\\nCCA; (5.2)\\nwhere\\x12iare projection matrices deﬁned earlier. \\x1eis an activation function, \\x15iandbiare scalars. In\\npractice, we compute f(y) =1\\nKPK\\ni=1(\\x1e(\\x15i(\\x12T\\n1y)+bi))to approximate the integral of Eq. 5.1, and\\nthe mapping function of the discriminator is D=f\\x0eE. To avoid gradient explosion and vanishing\\nforE, we additionally imposing the gradient regularizer on it. The ﬁnal objective function is given\\nby:\\nmin\\nGmax\\nDEX\\x18PX[D(X)]\\x00EZ\\x18PZ[D(G(Z))]\\n+\\x151E^X\\x18P^X[kr^XE(^X)k2\\n2]\\n+\\x152E^Y\\x18P^Y[(kr^Yf(^Y))k2\\x00k)2];(5.3)\\nwhere we sample the ^X;^Ybased on [12], where \\x151;\\x152are the coefﬁcients to balance the penalty\\nterms.\\x152is also used to absorb the scale kcaused by the k-Lipschitz constraint.\\n20\\nCha', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1805: ('imate the integral of Eq. 5.1, and\\nthe mapping function of the discriminator is D=f\\x0eE. To avoid gradient explosion and vanishing\\nforE, we additionally imposing the gradient regularizer on it. The ﬁnal objective function is given\\nby:\\nmin\\nGmax\\nDEX\\x18PX[D(X)]\\x00EZ\\x18PZ[D(G(Z))]\\n+\\x151E^X\\x18P^X[kr^XE(^X)k2\\n2]\\n+\\x152E^Y\\x18P^Y[(kr^Yf(^Y))k2\\x00k)2];(5.3)\\nwhere we sample the ^X;^Ybased on [12], where \\x151;\\x152are the coefﬁcients to balance the penalty\\nterms.\\x152is also used to absorb the scale kcaused by the k-Lipschitz constraint.\\n20\\nChapter 6\\nEvaluation Metrices\\nEvaluation of GANs is a non trivial problem. Some of the early works relied on evaluation\\nbased on surveys such as Amazon Mechanical Turk [35][43][23]. More quantitative metrics such\\nas Inception Score [35] and Frechet Inception Distance (FID) [13] have been proposed for image\\nbased GAN evaluation. These metrices were shown to correlate well with human perception. We\\nwill brieﬂy review these metrices in following sections.\\n6.1 Inception Score\\nInception score was originally proposed in [35] for evaluation of GANs. In the paper, the\\nauthors argued that Inception Score correlated well with the visual quality of generated samples.\\nLetx\\x18G be samples generated by the generator G.p(yjx)be the distribution of classes for\\ngenerated samples and p(y)be the marginal class distribution:\\np(y) =Z\\nxp(yjx)pg(x): (6.1)\\nThe Inception score is deﬁned as:\\nIS(G) = exp( Ex\\x18pgDKL(p(yjx)jjp(y))); (6.2)\\nwhereDKLis the Kullback-Leibler divergence between p(yjx)andp(y).\\n21\\nCHAPTER 6. E VALUATION METRICES\\nIn practice, the marginal class distribution is approximated with:\\n^p(y) =1\\nNNX\\ni=1p(yjx(i)); (6.3)\\nwhereNis number of samples generated.\\nIntuitively, maximum Inception Score is obtained when generated samples can be clearly clas-\\nsiﬁed as belonging to one of the classes in training set and the distribution of samples belonging to\\ndifferent classes is as uniform as possible. This encourages realistic samples and discourages mode\\ncollapse. The idea behind Inception score has been generalized to the context of vid', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1806: ('actice, the marginal class distribution is approximated with:\\n^p(y) =1\\nNNX\\ni=1p(yjx(i)); (6.3)\\nwhereNis number of samples generated.\\nIntuitively, maximum Inception Score is obtained when generated samples can be clearly clas-\\nsiﬁed as belonging to one of the classes in training set and the distribution of samples belonging to\\ndifferent classes is as uniform as possible. This encourages realistic samples and discourages mode\\ncollapse. The idea behind Inception score has been generalized to the context of video generation.\\nIn [34] authors propose to use C3D model trained on Sports-1M dataset and ﬁnetuned on UCF101\\ndataset. It is important to point out that Inception score computation requires a model trained\\non speciﬁc classiﬁcation problem and corresponding data. Furthermore Inception score does not\\ncompare the statistics of generated samples directly with statistics of real samples [13].\\n6.2 Fr ´echet Inception Distance\\nAlternative measure to access the quality of generated samples was proposed in [13]. In the\\npaper, authors propose to use pre-trained networks as feature extractors to extract low level features\\nfrom both real and generated samples. If Dbe the CNN used to extract features, (mr;\\x06r)be mean\\nand covariance of features extracted from real samples and (mf;\\x06f)be mean and covariance of\\nfeatures extracted from fake samples with D, then the Fr ´echet distance is deﬁned as\\nd2((mr;\\x06r);(mf;\\x06f)) =jjmr\\x00mfjj2\\n2+Tr(\\x06r+ \\x06f\\x002(\\x06r\\x06f)1=2): (6.4)\\nFID was shown to correlate well to visual perception quality [13]. Since FID directly compares the\\nsummary statistics of generated samples and real samples, it can be considered to be more accurate\\nthan Inception score. Furthermore, as lower level features are used to compute FID score, it can be\\nused to evaluate generative models for any dataset.\\nSimilar to Inception score, FID can be generalized to compare video generative models. In\\nparticular, as C3D is standard model widely used in video recognition tasks, a C3D model trained\\non action recognition dataset can be used as fe', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1807: (' FID directly compares the\\nsummary statistics of generated samples and real samples, it can be considered to be more accurate\\nthan Inception score. Furthermore, as lower level features are used to compute FID score, it can be\\nused to evaluate generative models for any dataset.\\nSimilar to Inception score, FID can be generalized to compare video generative models. In\\nparticular, as C3D is standard model widely used in video recognition tasks, a C3D model trained\\non action recognition dataset can be used as feature extractor. Since output of ﬁnal pooling layer is\\nvery high dimensional in case of C3D, output of ﬁrst fully connected layer can be used to resonably\\ncompare the quality of generated samples.\\n22\\nChapter 7\\nEvaluation Datasets\\nTo evaluate our video generative mode, we collected our own TrailerFaces dataset. Further-\\nmore, we also evaluated our model on existing Golf [43], Aeroplane [23] and UCF101 datasets [36].\\nIn following sections, we will review these datasets brieﬂy.\\n7.1 Trailer Face Dataset\\nFigure 7.1: Pipeline for Construction of Dataset.\\nLarge chunk of GAN papers evaluate and compare the generative models on facial datasets\\n[19][13][10] such as CelebA[26] in case of images and MUG dataset[1] or YouTube Faces[45]\\nin case of videos [40][16]. However, there is lack of publicly available high resolution datasets\\ncontaining facial dynamics. In terms of resolution too, widely used datasets for video generation\\n23\\nCHAPTER 7. E VALUATION DATASETS\\nDataset Resolution (Aligned) Sequences Wild Labels Diverse Dynamics\\nTrailerFaces 300x300 10,911 3 7 3\\nYoutubeFaces 100x100 3,425 3 Identity 7\\nAFEW - 1,426 3 Expressions 3\\nMUG 896x896 1,462 7 Expressions 7\\nTable 7.1: Comparision of our TrailerFaces dataset with existing datasets containing facial dynam-\\nics.\\nsuch as Golf and Aeroplane datasets too are only 128x128 resolution. UCF101 is widely used for\\nevaluation of generative models. Though it contains 240x320 resolution samples, due to relatively\\nsmall number of samples per class, learning meaningful features is not', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1808: ('ynamics\\nTrailerFaces 300x300 10,911 3 7 3\\nYoutubeFaces 100x100 3,425 3 Identity 7\\nAFEW - 1,426 3 Expressions 3\\nMUG 896x896 1,462 7 Expressions 7\\nTable 7.1: Comparision of our TrailerFaces dataset with existing datasets containing facial dynam-\\nics.\\nsuch as Golf and Aeroplane datasets too are only 128x128 resolution. UCF101 is widely used for\\nevaluation of generative models. Though it contains 240x320 resolution samples, due to relatively\\nsmall number of samples per class, learning meaningful features is not possible. Aeroplane and\\nGolf datasets contain too diverse videos. Learning meaningful representation from such videos\\ncan be difﬁcult for networks. Hence a novel dataset of human facial dynamics was collected from\\nmovie trailers.\\nNumber of Frames 30-33 34-39 40-47 48-57 58-69 70-423\\nTotal clips 1781 3106 2291 1591 940 1201\\nTable 7.2: Total number of clips with given number of frames.\\nOur motivation to use movie trailers for dataset collection was motivated by the fact movie\\ntrailers highlight dramatic and emotionally charged scenes. Unlike whole movies, interviews or TV\\nseries, trailers contain scenes where stronger emotional response of actors are highlighted. Further-\\nmore using trailers of thousands of movies increases the gender, racial and age-wise diversity of\\nthe faces in the clips. Approximately 6000 complete Hollywood movie trailers were downloaded\\nfrom YouTube. Number of SIFT feature matches between corresponding frames was used for shot\\nboundary detection. Approximately 200;000shots were detected in those trailers. After splitting\\ntrailers into individual shots, those with too few or too many frames were removed. Face-detection\\nwas carried out to ﬁlter-out clips where at least 31 consecutive frames do not contain any faces. For\\nface detection Haar-cascade based face detection tool from Open-CV was used. After detection of\\nfaces, Deep Alignment Network[22] was used for extraction of 68-point facial landmark. Thus\\nobtained facial landmarks were used for alignment using similarity transform. This was o', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1809: ('in those trailers. After splitting\\ntrailers into individual shots, those with too few or too many frames were removed. Face-detection\\nwas carried out to ﬁlter-out clips where at least 31 consecutive frames do not contain any faces. For\\nface detection Haar-cascade based face detection tool from Open-CV was used. After detection of\\nfaces, Deep Alignment Network[22] was used for extraction of 68-point facial landmark. Thus\\nobtained facial landmarks were used for alignment using similarity transform. This was observed\\nto be more stable across temporal dimension compared to state-of-art techniques like MTCNN.\\n24\\nCHAPTER 7. E VALUATION DATASETS\\nFinally, consecutive frames from those shots on which face detection was successful were selected.\\nSIFT feature matching was again used to remove clips containing different personalities across\\nframes.\\nFigure 7.2: Samples from TrailerFaces Dataset. Random frames were chosen for visualization.\\n7.2 UCF101 Dataset\\nUCF101 dataset [36] was originally collected for action recognition tasks. It contains 13320\\nvideos from 101 different action categories. Some of the action categories in the videos include\\nSky Diving, Knitting and Baseball Pitch. In [34] video based inception score was proposed for\\nevaluation of quality of video generative models. As argued in [34], Inception score computation\\nrequires a dataset with class labels and a standard model trained for classiﬁcation. For training,\\nﬁrst training split of UCF101 dataset with 9,537 video samples was used.\\n7.3 Golf and Aeroplane Datasets\\nGolf and Aeroplane datasets contain 128x128 resolution datasets that can be used for evaluating\\nvideo generative adversarial networks. Golf dataset in particular was used in [34][43][23]. Both of\\nthese datasets contain videos in the wild. Golf dataset contains more than half a million clips. We\\nused the background stabilized clips for training our model. Aeroplane dataset contains more than\\n300,000 clips that are not background stabilized.\\n25\\nCHAPTER 7. E VALUATION DATASETS\\nFigure 7.3: Samples from', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1810: ('Datasets\\nGolf and Aeroplane datasets contain 128x128 resolution datasets that can be used for evaluating\\nvideo generative adversarial networks. Golf dataset in particular was used in [34][43][23]. Both of\\nthese datasets contain videos in the wild. Golf dataset contains more than half a million clips. We\\nused the background stabilized clips for training our model. Aeroplane dataset contains more than\\n300,000 clips that are not background stabilized.\\n25\\nCHAPTER 7. E VALUATION DATASETS\\nFigure 7.3: Samples from UCF101 dataset. Random frames were selected for visualization.\\nFigure 7.4: Samples from Golf (right) and Aeroplane (left) datasets. Random frame was selected\\nfor visualization.\\n26\\nChapter 8\\nExperiments and Results\\nTo compare the performance of our model with state of art models, we present qualitative and\\nquantitative results below. Since UCF101 has class labels and as it was used for evaluation in prior\\nworks, we evaluate our models by comparing Inception score on UCF101 dataset with compare\\nGolf and Aeroplane datasets with FID score. For TrailerFaces dataset, we present qualitative results\\nbelow.\\n8.1 Qualitative Results\\nFigure 8.1: Improvement in resolution of generated videos over time on TrailerFaces dataset. Sin-\\ngle frames from each video clips were selected\\nAs discussed earlier, progressive growing scheme was utilized for training the video generative\\nnetworks. The improvement in quality and level of details over the course of training is illustrated\\nin Fig. 8.1. As seen from the ﬁgure, more detailed structures appear in the images over the course\\n27\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFigure 8.2: Qualitative comparision of samples from Aeroplane dataset generated by our method\\nwith that generated by Video GAN and Temporal GAN.\\nof training. Furthermore, the generated images look reasonable on TrailerFaces dataset. However,\\nthe quality is still not comparable to the quality of generated samples in the case of images [19]. As\\nillustrated in Fig. 8.2, Fig. 8.3 and Fig. 8.4, the structure of moving objects ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1811: ('structures appear in the images over the course\\n27\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFigure 8.2: Qualitative comparision of samples from Aeroplane dataset generated by our method\\nwith that generated by Video GAN and Temporal GAN.\\nof training. Furthermore, the generated images look reasonable on TrailerFaces dataset. However,\\nthe quality is still not comparable to the quality of generated samples in the case of images [19]. As\\nillustrated in Fig. 8.2, Fig. 8.3 and Fig. 8.4, the structure of moving objects such aeroplanes, humans\\nand animals is not distinct and they appear as blobs. Though appearance of dynamic objects is not\\nwell captured by the network, it can be inferred from Fig. 8.2 and Fig. 8.3 that temporal dynamics\\nseems more reasonable.\\nTo analyze if the network has overﬁtted the dataset, we carried out linear interpolation in latent\\nspace and generated samples. As seen from Fig. B.1,B.2,B.3,B.4,B.5,B.6, samples from all datasets\\nshow that our network has good generalization ability and does not overﬁt the model.\\nIt can be observed that progressive growing technique can generate higher resolution videos\\nwithout mode collapse or instability issues traditionally suffered by GANs. However, the issue that\\nmoving objects appear as blobs in generated samples as reported in [43], is still not completely\\nsolved.\\n8.2 Inception score on UCF101\\nSame protocol and C3D model proposed in [34] was used for computation of inception scores.\\nAll scores except our own were taken from [34] and [40]. To train our model, central 32 frames\\nfrom UCF101 were selected and then each frame was resized and cropped to 128\\x02128. In our\\nexperiments, best Inception score of 13:59was obtained with a single, though progressive model.\\n28\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFigure 8.3: Qualitative comparision of samples from Golf dataset generated by our method with\\nthat generated by Video GAN and Temporal GAN.\\nFigure 8.4: Qualitative comparision of clips generated with progressive approach (top), Temporal\\nGAN (bottom left) and Video GAN (bot', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1812: ('tral 32 frames\\nfrom UCF101 were selected and then each frame was resized and cropped to 128\\x02128. In our\\nexperiments, best Inception score of 13:59was obtained with a single, though progressive model.\\n28\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFigure 8.3: Qualitative comparision of samples from Golf dataset generated by our method with\\nthat generated by Video GAN and Temporal GAN.\\nFigure 8.4: Qualitative comparision of clips generated with progressive approach (top), Temporal\\nGAN (bottom left) and Video GAN (bottom right) on aeroplane (left) and golf datasets (right).\\n29\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFurthermore, with SWGAN loss, we were able to obtain inception score of 14:56. Both of these\\nscores are the best result we are aware of.\\nModel Inception Score\\nVGAN[43] 8:18\\nTGAN[34] 11:85\\nMoCoGAN[40] 12:42\\nProgressive Video GAN 13:59\\nProgressive Video GAN +SWGAN 14.56\\nMaximum Possible 83:18\\nTable 8.1: Inception scores of Progressive Video GAN compared with other models on UCF101\\ndataset.\\nIn all cases, ﬁrst training split of UCF101 dataset was used. However, in [34] and [40], authors\\nrandomly sampled 16or32consecutive frames during training. In our case, we restricted to central\\n32frames of video during training.\\nSurprisingly, inception score started decreasing on training the network further. One possible\\ncause could be smaller minibatch size used at higher resolution. However, further experiment is\\nnecessary to make decisive conclusion about the behaviour.\\n8.3 FID\\nIn this section, we compare FID score of samples generated with our model and one generated\\nwith models from VideoGAN and TGAN papers. In C3D model, output of fc-6 layer is 4096-d\\nwhere as output of pool-5 layer is 8192-d. The output of fc-6 layer of C3D model was used to\\ncompute FID score for computational reasons. In order to compute FID score, 10,000 samples\\nwere generated with each model. Since VideoGAN and TGAN models were trained to generate on\\n64x64 resolution videos, we upscaled the videos to 128\\x02128in order to compute FID score.\\nTo report FID, TG', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1813: ('generated with our model and one generated\\nwith models from VideoGAN and TGAN papers. In C3D model, output of fc-6 layer is 4096-d\\nwhere as output of pool-5 layer is 8192-d. The output of fc-6 layer of C3D model was used to\\ncompute FID score for computational reasons. In order to compute FID score, 10,000 samples\\nwere generated with each model. Since VideoGAN and TGAN models were trained to generate on\\n64x64 resolution videos, we upscaled the videos to 128\\x02128in order to compute FID score.\\nTo report FID, TGAN and VideoGAN were trained on our own using code available on the\\ninternet. It is clear from both datasets that progressive video GAN performs signiﬁcantly better than\\nTGAN and VideoGAN. The difference is even more prominent in case of Aeroplane dataset where\\nTGAN and Progressive Video GAN perform signiﬁcantly better than VideoGAN. As mentioned\\nearlier, Golf dataset was stabilized whereas Aeroplane dataset was not. This is easily explained by\\n30\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nFigure 8.5: Comparison of our models on UCF101 dataset based on FID Score (left) and Inception\\nScore (right).\\nFigure 8.6: Comparison of our model with TGAN and VideoGAN based on Golf and Aeroplane\\nDatasets as measured by FID score.\\nModel FID Score on Golf Dataset FID Score on Aeroplane Dataset\\nVGAN[43] 113007 149094\\nTGAN[34] 112029 120417\\nProgressive Video GAN 95544 102049\\nTable 8.2: Quantitative comparision of Progressive Video GAN with TGAN and VideoGAN based\\non FID score on Golf and Aeroplane datasets.\\n31\\nCHAPTER 8. E XPERIMENTS AND RESULTS\\nthe fact that VideoGAN assumes stable background whereas TGAN and Progressive Video GAN\\nmake no such assumptions.\\n32\\nChapter 9\\nConclusion and Discussion\\nIn this work, we explored the use of progressive growing of GANs for video generation. By\\nprogressively growing the network, we were able to generate videos of up to 256x256 resolution\\nand 32 frames. Our model performed better than existing state-of-art models on UCF101 dataset\\nas measured by Inception Score and FID Score. We obtained state of', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1814: ('S AND RESULTS\\nthe fact that VideoGAN assumes stable background whereas TGAN and Progressive Video GAN\\nmake no such assumptions.\\n32\\nChapter 9\\nConclusion and Discussion\\nIn this work, we explored the use of progressive growing of GANs for video generation. By\\nprogressively growing the network, we were able to generate videos of up to 256x256 resolution\\nand 32 frames. Our model performed better than existing state-of-art models on UCF101 dataset\\nas measured by Inception Score and FID Score. We obtained state of art inception score of 14.56\\non UCF101 dataset. This is signiﬁcant improvement over state-of-art score reported in [40]. This\\nshows that the idea of ﬁrst training on simpler problem and progressively increasing the complexity\\nof the problem is also effective for video generative models. Though we observed that use of Sliced\\nWasserstein metric as loss for training GANs improves performance of the model as measured by\\ninception score in some cases, more experiment is needed to make a deﬁnite conclusion. Percep-\\ntually, the results obtained are still not as realistic as were obtained in the case of image based on\\nmethods. Recently there has been surge in models that use optical ﬂow[31][50][38] to generate\\nvideos. This is a promising direction to explore.\\nFollowing the approach of [19], the discriminator we used was mirror reﬂection of the generator\\narchitecture. Due to this, the network architecture of discriminator in our model is drastically\\ndifferent than that of C3D model which was used for quantitative comparison. As there are fewer\\nfeature channels in our Discriminator, it is weaker than C3D model or the discriminators used for\\nprevious works[34][40][43]. It is interesting to note that our model performs better than existing\\napproaches despite a discriminator with fewer parameters.\\nThere is enough space to explore if incorporation of the idea of progressive growing of gans\\nto more complex architectures such as [34][40] that have different temporal and spatial generators.\\nFurthermore, incorporation of prior ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1815: ('parison. As there are fewer\\nfeature channels in our Discriminator, it is weaker than C3D model or the discriminators used for\\nprevious works[34][40][43]. It is interesting to note that our model performs better than existing\\napproaches despite a discriminator with fewer parameters.\\nThere is enough space to explore if incorporation of the idea of progressive growing of gans\\nto more complex architectures such as [34][40] that have different temporal and spatial generators.\\nFurthermore, incorporation of prior information such as class label can be expected to drastically\\nimprove the results. The higher quality image generation in [19] was possible due to higher quality\\n33\\nCHAPTER 9. C ONCLUSION AND DISCUSSION\\nwell aligned training data. Application of similar super-resolution techniques can be expected to\\nfurther improve the quality of video generation. Furthermore, well alignment of faces in Trailer-\\nFaces dataset can be expected to signiﬁcantly impact the quality of videos generated. However,\\nthe problem of alignment of faces in videos is not as well-posed problem as alignment of faces in\\nimages and is more challenging.\\nFor evaluation of our generative models, we relied on C3D models trained on Sports-1M dataset\\nand ﬁne tuned in UCF101 dataset. This model has clip level accuracy of approximately 75% on\\ntest split. The effectiveness of a model with far from 100% accuracy for evaluation of generative\\nmodels is a research problem in itself. Furthermore, recently accuracy of 98:0%was achieved on\\nUCF101 with Two-Stream Inﬂated 3D ConvNet (I3D)[5]. We can expect the I3D model to give\\nmore valid Inception and FID Scores. Furthermore, for training on UCF101, we only used central\\n32 frames of UCF101 for training. This method was slightly different than use of randomly selected\\n32 consecutive frames[34][40]. It is also important to point out that, we obtained the best possible\\ninception score of 83:18%. Whereas, in [34], best possible score of 34:33% was reported. It is\\npossible that authors downsampled original videos to 6', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1816: ('am Inﬂated 3D ConvNet (I3D)[5]. We can expect the I3D model to give\\nmore valid Inception and FID Scores. Furthermore, for training on UCF101, we only used central\\n32 frames of UCF101 for training. This method was slightly different than use of randomly selected\\n32 consecutive frames[34][40]. It is also important to point out that, we obtained the best possible\\ninception score of 83:18%. Whereas, in [34], best possible score of 34:33% was reported. It is\\npossible that authors downsampled original videos to 64x64 and then again upscaled to 128x128\\nbefore feeding into C3D model. This is reasonable as their model is trained on 64x64 videos. We\\ndirectly downscaled to 128x128 before feeding into the network as we designed our network to\\ntrain on 128x128 resolution.\\n34\\nAppendix A\\nNetwork Architecture\\n35\\nAPPENDIX A. N ETWORK ARCHITECTURE\\nGenerator Activation Output shape Parameters\\nLatent vector - 128x1x1x1 -\\nFully-connected LReLU 8192x1x1x1 1.04m\\nConv 3x3x3 LReLU 128x4x4x4 0.44m\\nUpsample - 128x8x8x8 -\\nConv 3x3x3 LReLU 128x8x8x8 0.44m\\nConv 3x3x3 LReLU 128x8x8x8 0.44m\\nUpsample - 128x8x16x16 -\\nConv 3x3x3 LReLU 128x8x16x16 0.44m\\nConv 3x3x3 LReLU 128x8x16x16 0.44m\\nUpsample - 128x8x32x32 -\\nConv 3x3x3 LReLU 64x8x32x32 0.22m\\nConv 3x3x3 LReLU 64x8x32x32 0.22m\\nUpsample - 64x16x64x64 -\\nConv 3x3x3 LReLU 32x16x64x64 55k\\nConv 3x3x3 LReLU 32x16x64x64 27k\\nUpsample - 32x16x128x128 -\\nConv 3x3x3 LReLU 16x16x128x128 13.8k\\nConv 3x3x3 LReLU 16x16x128x128 6.9k\\nUpsample - 16x32x256x256 -\\nConv 3x3x3 LReLU 8x32x256x256 3.4k\\nConv 3x3x3 LReLU 8x32x256x256 1.7k\\nConv 1x1x1 LReLU 3x32x256x256 27\\nTotal Parameters 3.7m\\nTable A.1: Generator architecture for generation of 256x256x32 videos.\\n36\\nAPPENDIX A. N ETWORK ARCHITECTURE\\nDiscriminator Activation Output shape Parameters\\nInput Image - 128x1x1 -\\nConv 1x1x1 LReLU 128x4x4x4 32\\nConv 3x3x3 LReLU 128x4x4x4 1.73k\\nConv 3x3x3 LReLU 128x4x4x4 3.47k\\nDownsample - 128x8x8x8 -\\nConv 3x3x3 LReLU 128x8x8x8 6.92k\\nConv 3x3x3 LReLU 128x8x8x8 13.85k\\nDownsample - 128x8x16x16 -\\nConv 3x3x3 LReLU 128x8x16x16 27.68k\\nConv 3x3x', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1817: ('32x256x256 1.7k\\nConv 1x1x1 LReLU 3x32x256x256 27\\nTotal Parameters 3.7m\\nTable A.1: Generator architecture for generation of 256x256x32 videos.\\n36\\nAPPENDIX A. N ETWORK ARCHITECTURE\\nDiscriminator Activation Output shape Parameters\\nInput Image - 128x1x1 -\\nConv 1x1x1 LReLU 128x4x4x4 32\\nConv 3x3x3 LReLU 128x4x4x4 1.73k\\nConv 3x3x3 LReLU 128x4x4x4 3.47k\\nDownsample - 128x8x8x8 -\\nConv 3x3x3 LReLU 128x8x8x8 6.92k\\nConv 3x3x3 LReLU 128x8x8x8 13.85k\\nDownsample - 128x8x16x16 -\\nConv 3x3x3 LReLU 128x8x16x16 27.68k\\nConv 3x3x3 LReLU 128x8x16x16 55.36k\\nDownsample - 128x8x32x32 -\\nConv 3x3x3 LReLU 64x8x32x32 0.11m\\nConv 3x3x3 LReLU 64x8x32x32 0.22m\\nDownsample - 64x16x64x64 -\\nConv 3x3x3 LReLU 32x16x64x64 0.44k\\nConv 3x3x3 LReLU 32x16x64x64 0.44k\\nDownsample - 32x16x128x128 -\\nConv 3x3x3 LReLU 16x16x128x128 0.44m\\nConv 3x3x3 LReLU 16x16x128x128 0.44m\\nDownsample - 16x32x256x256 -\\nMinibatch Stddev - 129x4x4x4 -\\nConv 3x3x3 LReLU 8x32x256x256 .44m\\nFully-connected linear 1x1x1x128 1.04m\\nFully-connected linear 1x1x1x1 129\\nTotal Parameters 3.7m\\nTable A.2: Discriminator architecture for generation of 256x256x32 videos.\\n37\\nAPPENDIX A. N ETWORK ARCHITECTURE\\n38\\nAppendix B\\nLatent Space Interpolations\\nGolf Dataset\\nFigure B.1: Linear interpolation in latent space to generate samples from Golf dataset - 1.\\n39\\nAPPENDIX B. L ATENT SPACE INTERPOLATIONS\\nFigure B.2: Linear interpolation in latent space to generate samples from Golf dataset - 2\\nAeroplane Dataset\\nFigure B.3: Linear interpolation in latent space to generate samples from Aeroplane dataset - 1\\n40\\nAPPENDIX B. L ATENT SPACE INTERPOLATIONS\\nFigure B.4: Linear interpolation in latent space to generate samples from Aeroplane dataset - 2\\nTrailerFaces\\nFigure B.5: Linear interpolation in latent space to generate samples from TrailerFaces dataset - 1\\n41\\nAPPENDIX B. L ATENT SPACE INTERPOLATIONS\\nFigure B.6: Linear interpolation in latent space to generate samples from TrailerFaces dataset - 2\\n42\\nBibliography\\n[1] Niki Aifanti, Christos Papachristou, and Anastasios Delopoulos. The mug facial expression\\ndatabase. ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1818: ('APPENDIX B. L ATENT SPACE INTERPOLATIONS\\nFigure B.4: Linear interpolation in latent space to generate samples from Aeroplane dataset - 2\\nTrailerFaces\\nFigure B.5: Linear interpolation in latent space to generate samples from TrailerFaces dataset - 1\\n41\\nAPPENDIX B. L ATENT SPACE INTERPOLATIONS\\nFigure B.6: Linear interpolation in latent space to generate samples from TrailerFaces dataset - 2\\n42\\nBibliography\\n[1] Niki Aifanti, Christos Papachristou, and Anastasios Delopoulos. The mug facial expression\\ndatabase. In Image analysis for multimedia interactive services (WIAMIS), 2010 11th inter-\\nnational workshop on , pages 1–4. IEEE, 2010.\\n[2] Martin Arjovsky, Soumith Chintala, and L ´eon Bottou. Wasserstein generative adversarial\\nnetworks. In Doina Precup and Yee Whye Teh, editors, Proceedings of the 34th Interna-\\ntional Conference on Machine Learning , volume 70 of Proceedings of Machine Learning\\nResearch , pages 214–223, International Convention Centre, Sydney, Australia, 06–11 Aug\\n2017. PMLR.\\n[3] Yoshua Bengio, J ´erˆome Louradour, Ronan Collobert, and Jason Weston. Curriculum learning.\\nInProceedings of the 26th annual international conference on machine learning , pages 41–\\n48. ACM, 2009.\\n[4] Nicolas Bonnotte. Unidimensional and evolution methods for optimal transportation . PhD\\nthesis, Universit ´e Paris Sud - Paris XI, 2013.\\n[5] Joao Carreira and Andrew Zisserman. Quo vadis, action recognition? a new model and\\nthe kinetics dataset. In 2017 IEEE Conference on Computer Vision and Pattern Recognition\\n(CVPR) , pages 4724–4733. IEEE, 2017.\\n[6] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo.\\nStargan: Uniﬁed generative adversarial networks for multi-domain image-to-image transla-\\ntion. arXiv preprint arXiv:1711.09020 , 2017.\\n[7] Ishan Deshpande, Ziyu Zhang, and Alexander Schwing. Generative modeling using the sliced\\nwasserstein distance. arXiv preprint arXiv:1803.11188 , 2018.\\n43\\nBIBLIOGRAPHY\\n[8] Ishan Deshpande, Ziyu Zhang, and Alexander G. Schwing. Generative modeling using the\\nsliced w', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1819: ('4724–4733. IEEE, 2017.\\n[6] Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo.\\nStargan: Uniﬁed generative adversarial networks for multi-domain image-to-image transla-\\ntion. arXiv preprint arXiv:1711.09020 , 2017.\\n[7] Ishan Deshpande, Ziyu Zhang, and Alexander Schwing. Generative modeling using the sliced\\nwasserstein distance. arXiv preprint arXiv:1803.11188 , 2018.\\n43\\nBIBLIOGRAPHY\\n[8] Ishan Deshpande, Ziyu Zhang, and Alexander G. Schwing. Generative modeling using the\\nsliced wasserstein distance. CoRR , abs/1803.11188, 2018.\\n[9] Arnab Ghosh, Viveka Kulharia, Vinay Namboodiri, Philip HS Torr, and Puneet K Dokania.\\nMulti-agent diverse generative adversarial networks. arXiv preprint arXiv:1704.02906 , 2017.\\n[10] Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil\\nOzair, Aaron Courville, and Yoshua Bengio. Generative adversarial nets. In Z. Ghahramani,\\nM. Welling, C. Cortes, N. D. Lawrence, and K. Q. Weinberger, editors, Advances in Neural\\nInformation Processing Systems 27 , pages 2672–2680. Curran Associates, Inc., 2014.\\n[11] Karol Gregor, Ivo Danihelka, Alex Graves, Danilo Jimenez Rezende, and Daan Wierstra.\\nDraw: A recurrent neural network for image generation. arXiv preprint arXiv:1502.04623 ,\\n2015.\\n[12] Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron C Courville.\\nImproved training of wasserstein gans. In I. Guyon, U. V . Luxburg, S. Bengio, H. Wallach,\\nR. Fergus, S. Vishwanathan, and R. Garnett, editors, Advances in Neural Information Pro-\\ncessing Systems 30 , pages 5767–5777. Curran Associates, Inc., 2017.\\n[13] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochre-\\niter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In\\nAdvances in Neural Information Processing Systems , pages 6629–6640, 2017.\\n[14] De-An Huang, Vignesh Ramanathan, Dhruv Mahajan, Lorenzo Torresani, Manohar Paluri,\\nLi Fei-Fei, and Juan Carlos Niebles. What makes a video a video: Analyzing', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1820: ('ural Information Pro-\\ncessing Systems 30 , pages 5767–5777. Curran Associates, Inc., 2017.\\n[13] Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochre-\\niter. Gans trained by a two time-scale update rule converge to a local nash equilibrium. In\\nAdvances in Neural Information Processing Systems , pages 6629–6640, 2017.\\n[14] De-An Huang, Vignesh Ramanathan, Dhruv Mahajan, Lorenzo Torresani, Manohar Paluri,\\nLi Fei-Fei, and Juan Carlos Niebles. What makes a video a video: Analyzing temporal\\ninformation in video understanding models and datasets.\\n[15] Xun Huang, Yixuan Li, Omid Poursaeed, John Hopcroft, and Serge Belongie. Stacked gener-\\native adversarial networks. In IEEE Conference on Computer Vision and Pattern Recognition\\n(CVPR) , volume 2, page 4, 2017.\\n[16] Zhiwu Huang, Bernhard Kratzwald, Danda Pani Paudel, Jiqing Wu, and Luc Van Gool.\\nFace translation between images and videos using identity-aware cyclegan. arXiv preprint\\narXiv:1712.00971 , 2017.\\n[17] Phillip Isola, Jun-Yan Zhu, Tinghui Zhou, and Alexei A Efros. Image-to-image translation\\nwith conditional adversarial networks. arXiv preprint , 2017.\\n44\\nBIBLIOGRAPHY\\n[18] Nal Kalchbrenner, A ¨aron van den Oord, Karen Simonyan, Ivo Danihelka, Oriol Vinyals, Alex\\nGraves, and Koray Kavukcuoglu. Video pixel networks. CoRR , abs/1610.00527, 2016.\\n[19] Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of GANs\\nfor improved quality, stability, and variation. In International Conference on Learning Rep-\\nresentations , 2018.\\n[20] H. Kim, P. Garrido, A. Tewari, W. Xu, J. Thies, N. Nießner, P. P ´erez, C. Richardt,\\nM. Zollh ¨ofer, and C. Theobalt. Deep video portraits. ACM Transactions on Graphics 2018\\n(TOG) , 2018.\\n[21] Soheil Kolouri, Yang Zou, and Gustavo K Rohde. Sliced wasserstein kernels for probabil-\\nity distributions. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition , pages 5258–5267, 2016.\\n[22] Marek Kowalski, Jacek Naruniec, and Tomasz Trzcinski. Deep alignment network: A co', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1821: ('tions , 2018.\\n[20] H. Kim, P. Garrido, A. Tewari, W. Xu, J. Thies, N. Nießner, P. P ´erez, C. Richardt,\\nM. Zollh ¨ofer, and C. Theobalt. Deep video portraits. ACM Transactions on Graphics 2018\\n(TOG) , 2018.\\n[21] Soheil Kolouri, Yang Zou, and Gustavo K Rohde. Sliced wasserstein kernels for probabil-\\nity distributions. In Proceedings of the IEEE Conference on Computer Vision and Pattern\\nRecognition , pages 5258–5267, 2016.\\n[22] Marek Kowalski, Jacek Naruniec, and Tomasz Trzcinski. Deep alignment network: A con-\\nvolutional neural network for robust face alignment. In Proceedings of the International\\nConference on Computer Vision & Pattern Recognition (CVPRW), Faces-in-the-wild Work-\\nshop/Challenge , volume 3, page 6, 2017.\\n[23] Bernhard Kratzwald, Zhiwu Huang, Danda Pani Paudel, and Luc Van Gool. Towards an\\nunderstanding of our world by ganing videos in the wild. CoRR , abs/1711.11453, 2017.\\n[24] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classiﬁcation with deep\\nconvolutional neural networks. In Advances in neural information processing systems , pages\\n1097–1105, 2012.\\n[25] Christian Ledig, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew Cunningham, Ale-\\njandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo-\\nrealistic single image super-resolution using a generative adversarial network. In Proceed-\\nings of the IEEE Conference on Computer Vision and Pattern Recognition , pages 4681–4690,\\n2017.\\n[26] Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the\\nwild. In Proceedings of International Conference on Computer Vision (ICCV) , 2015.\\n[27] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian Goodfellow. Adversarial autoen-\\ncoders. In International Conference on Learning Representations , 2016.\\n45\\nBIBLIOGRAPHY\\n[28] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smol-\\nley. Least squares generative adversarial networks. In 2017 IEEE International Conference\\non Computer Vision (ICCV) , pages 2813', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1822: ('rning face attributes in the\\nwild. In Proceedings of International Conference on Computer Vision (ICCV) , 2015.\\n[27] Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, and Ian Goodfellow. Adversarial autoen-\\ncoders. In International Conference on Learning Representations , 2016.\\n45\\nBIBLIOGRAPHY\\n[28] Xudong Mao, Qing Li, Haoran Xie, Raymond YK Lau, Zhen Wang, and Stephen Paul Smol-\\nley. Least squares generative adversarial networks. In 2017 IEEE International Conference\\non Computer Vision (ICCV) , pages 2813–2821. IEEE, 2017.\\n[29] Michael Mathieu, Camille Couprie, and Yann LeCun. Deep multi-scale video prediction\\nbeyond mean square error. arXiv preprint arXiv:1511.05440 , 2015.\\n[30] Mehdi Mirza and Simon Osindero. Conditional generative adversarial nets. arXiv preprint\\narXiv:1411.1784 , 2014.\\n[31] Katsunori Ohnishi, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada. Hierarchical\\nvideo generation from orthogonal information: Optical ﬂow and texture. In AAAI , 2018.\\n[32] Aaron van den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu. Pixel recurrent neural\\nnetworks. arXiv preprint arXiv:1601.06759 , 2016.\\n[33] Alec Radford, Luke Metz, and Soumith Chintala. Unsupervised representation learning with\\ndeep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434 , 2015.\\n[34] Masaki Saito, Eiichi Matsumoto, and Shunta Saito. Temporal generative adversarial nets with\\nsingular value clipping. In ICCV , 2017.\\n[35] Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen,\\nand Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V .\\nLuxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Sys-\\ntems 29 , pages 2234–2242. Curran Associates, Inc., 2016.\\n[36] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. Ucf101: A dataset of 101 human\\nactions classes from videos in the wild. arXiv preprint arXiv:1212.0402 , 2012.\\n[37] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman. Synthesizing\\nobama: learning lip ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1823: ('nd Xi Chen. Improved techniques for training gans. In D. D. Lee, M. Sugiyama, U. V .\\nLuxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Sys-\\ntems 29 , pages 2234–2242. Curran Associates, Inc., 2016.\\n[36] Khurram Soomro, Amir Roshan Zamir, and Mubarak Shah. Ucf101: A dataset of 101 human\\nactions classes from videos in the wild. arXiv preprint arXiv:1212.0402 , 2012.\\n[37] Supasorn Suwajanakorn, Steven M Seitz, and Ira Kemelmacher-Shlizerman. Synthesizing\\nobama: learning lip sync from audio. ACM Transactions on Graphics (TOG) , 36(4):95, 2017.\\n[38] Matthew Tesfaldet, Marcus A. Brubaker, and Konstantinos G. Derpanis. Two-stream con-\\nvolutional networks for dynamic texture synthesis. In IEEE Conference on Computer Vision\\nand Pattern Recognition (CVPR) , 2018.\\n[39] Du Tran, Heng Wang, Lorenzo Torresani, Jamie Ray, Yann LeCun, and Manohar Paluri.\\nA closer look at spatiotemporal convolutions for action recognition. arXiv preprint\\narXiv:1711.11248 , 2017.\\n46\\nBIBLIOGRAPHY\\n[40] Sergey Tulyakov, Ming-Yu Liu, Xiaodong Yang, and Jan Kautz. Mocogan: Decomposing\\nmotion and content for video generation. CoRR , abs/1707.04993, 2017.\\n[41] Aaron van den Oord, Nal Kalchbrenner, Lasse Espeholt, Oriol Vinyals, Alex Graves, et al.\\nConditional image generation with pixelcnn decoders. In Advances in Neural Information\\nProcessing Systems , pages 4790–4798, 2016.\\n[42] Ruben Villegas, Jimei Yang, Yuliang Zou, Sungryull Sohn, Xunyu Lin, and Honglak Lee.\\nLearning to generate long-term future via hierarchical prediction. In Proceedings of the 34th\\nInternational Conference on Machine Learning (ICML) , 2017.\\n[43] Carl V ondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dy-\\nnamics. In D. D. Lee, M. Sugiyama, U. V . Luxburg, I. Guyon, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 29 , pages 613–621. Curran Associates,\\nInc., 2016.\\n[44] Chaoyue Wang, Chang Xu, Chaohui Wanga, and Dacheng Tao. Perceptual adversarial net-\\nworks for image-to-image transformation. ', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1824: ('l prediction. In Proceedings of the 34th\\nInternational Conference on Machine Learning (ICML) , 2017.\\n[43] Carl V ondrick, Hamed Pirsiavash, and Antonio Torralba. Generating videos with scene dy-\\nnamics. In D. D. Lee, M. Sugiyama, U. V . Luxburg, I. Guyon, and R. Garnett, editors,\\nAdvances in Neural Information Processing Systems 29 , pages 613–621. Curran Associates,\\nInc., 2016.\\n[44] Chaoyue Wang, Chang Xu, Chaohui Wanga, and Dacheng Tao. Perceptual adversarial net-\\nworks for image-to-image transformation. IEEE Transactions on Image Processing , 2018.\\n[45] Lior Wolf, Tal Hassner, and Itay Maoz. Face recognition in unconstrained videos with\\nmatched background similarity. In Computer Vision and Pattern Recognition (CVPR), 2011\\nIEEE Conference on , pages 529–534. IEEE, 2011.\\n[46] Jiajun Wu, Yifan Wang, Tianfan Xue, Xingyuan Sun, William T Freeman, and Joshua B\\nTenenbaum. MarrNet: 3D Shape Reconstruction via 2.5D Sketches. In Advances In Neural\\nInformation Processing Systems , 2017.\\n[47] Jiajun Wu, Chengkai Zhang, Tianfan Xue, William T Freeman, and Joshua B Tenenbaum.\\nLearning a probabilistic latent space of object shapes via 3d generative-adversarial modeling.\\nInAdvances in Neural Information Processing Systems , pages 82–90, 2016.\\n[48] Jiqing Wu, Zhiwu Huang, Wen Li, and Luc Van Gool. Generative autotransporters. CoRR ,\\nabs/1706.02631, 2017.\\n[49] Saining Xie, Chen Sun, Jonathan Huang, Zhuowen Tu, and Kevin Murphy. Rethinking spa-\\ntiotemporal feature learning for video understanding. arXiv preprint arXiv:1712.04851 , 2017.\\n[50] Wei Xiong, Wenhan Luo, Lin Ma, Wei Liu, and Jiebo Luo. Learning to generate time-lapse\\nvideos using multi-stage dynamic generative adversarial networks. CoRR , abs/1709.07592,\\n2017.\\n47\\nBIBLIOGRAPHY\\n[51] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, and\\nDimitris Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative\\nadversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV) , pages 5907–5915, 2017.\\n[52] Jun-Yan Zhu, Taesung Park', 'Towards High Resolution Video Generation with Progressive Growing.pdf'), 1825: ('51 , 2017.\\n[50] Wei Xiong, Wenhan Luo, Lin Ma, Wei Liu, and Jiebo Luo. Learning to generate time-lapse\\nvideos using multi-stage dynamic generative adversarial networks. CoRR , abs/1709.07592,\\n2017.\\n47\\nBIBLIOGRAPHY\\n[51] Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, and\\nDimitris Metaxas. Stackgan: Text to photo-realistic image synthesis with stacked generative\\nadversarial networks. In IEEE Int. Conf. Comput. Vision (ICCV) , pages 5907–5915, 2017.\\n[52] Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros. Unpaired image-to-image\\ntranslation using cycle-consistent adversarial networks. arXiv preprint arXiv:1703.10593 ,\\n2017.\\n[53] Jun-Yan Zhu, Richard Zhang, Deepak Pathak, Trevor Darrell, Alexei A Efros, Oliver Wang,\\nand Eli Shechtman. Toward multimodal image-to-image translation. In Advances in Neural\\nInformation Processing Systems 30 . 2017.\\n48', 'Towards High Resolution Video Generation with Progressive Growing.pdf')}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the index is trained (for trained indices)\n",
        "print(\"Is the index trained?\", index.is_trained)\n",
        "\n",
        "# Print the index type\n",
        "print(\"Index type:\", type(index))\n",
        "\n",
        "# Check the number of vectors in the index\n",
        "print(f\"Number of vectors in the index: {index.ntotal}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KVk8f2Y5exf",
        "outputId": "1d63a615-656f-4547-c538-be955174e154"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the index trained? True\n",
            "Index type: <class 'faiss.swigfaiss_avx512.IndexFlatIP'>\n",
            "Number of vectors in the index: 1826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def search_faiss(query, top_k=15):\n",
        "    query = get_embedding(query)\n",
        "    query_embedding = np.array([query])\n",
        "    embedding = query_embedding.reshape(1, -1)\n",
        "    normalize_embedding = normalize_embeddings(embedding)\n",
        "    distances, indices = index.search(normalize_embedding, top_k)\n",
        "    return [chunk_map[idx] for idx in indices[0]]"
      ],
      "metadata": {
        "id": "mva3qXWfk6Si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(query, retrieved_limitations, retrieved_previous_implementations, current_implementation):\n",
        "    prompt = f\"\"\"\n",
        "You are an AI assistant evaluating the feasibility and novelty of a research approach based on retrieved information. Only focus on the relevant limitations and implementations related to the query. Strictly ignore any unrelated content.\n",
        "\n",
        "**Query:**\n",
        "{query}\n",
        "\n",
        "**Current Implementation:**\n",
        "{current_implementation}\n",
        "\n",
        "**Retrieved Limitations (For Feasibility Analysis):**\n",
        "{retrieved_limitations}\n",
        "\n",
        "**Retrieved Previous Implementations (For Novelty Analysis):**\n",
        "{retrieved_previous_implementations}\n",
        "\n",
        "**Evaluation Criteria:**\n",
        "\n",
        "Feasibility Rubric:\n",
        "1. Highly Impractical (Rating 1)\n",
        "\n",
        "Challenges: The approach faces fundamental flaws, such as severe technical limitations, critical errors in assumptions, or unsolvable scalability issues.\n",
        "Implementation: The idea cannot be realistically executed with existing tools or methods and would fail under typical conditions.\n",
        "Risk: There are significant risks (e.g., security, performance) that cannot be easily mitigated or are likely to lead to failure.\n",
        "Examples: Security issues that cannot be resolved, approaches that are computationally unfeasible at scale, or major technical hurdles without clear solutions.\n",
        "2. Challenging to Implement (Rating 2)\n",
        "\n",
        "Challenges: The idea presents significant obstacles, such as major performance bottlenecks, security risks, or issues with scalability that would make it difficult to execute effectively.\n",
        "Implementation: The idea requires substantial adjustments or resources to become viable, and careful planning is necessary for success.\n",
        "Risk: High risk, including issues that could lead to significant failure unless properly managed.\n",
        "Examples: Major data bottlenecks, scalability challenges, or risks of model instability (like hallucinations) that require significant innovation or effort to mitigate.\n",
        "3. Feasible with Significant Effort (Rating 3)\n",
        "\n",
        "Challenges: The approach is achievable but faces clear challenges that need to be addressed, such as optimization, error handling, or complex dependencies.\n",
        "Implementation: The idea can be executed, but substantial resources, testing, and refinement are required.\n",
        "Risk: Moderate risk, where careful management of the process is needed to avoid potential pitfalls (e.g., handling edge cases, scalability).\n",
        "Examples: A viable idea but requires significant engineering work, model fine-tuning, and optimization to be effective and scalable.\n",
        "4. Mostly Feasible with Some Risk (Rating 4)\n",
        "\n",
        "Challenges: The approach works well in most conditions with only minor risks or challenges that can be addressed through optimization or incremental improvements.\n",
        "Implementation: Practical to implement with manageable risks, requiring some refinement but no major adjustments to current resources.\n",
        "Risk: Low risk, where the approach is likely to succeed but with some areas needing attention (e.g., improving model stability).\n",
        "Examples: A solution that can be scaled with moderate adjustments or where only minor technical challenges remain.\n",
        "5. Highly Feasible with Minimal or No Risk (Rating 5)\n",
        "\n",
        "Challenges: The approach is fully practical, and any minor limitations can be easily addressed.\n",
        "Implementation: Ready to be implemented without major risks or limitations.\n",
        "Risk: Very low risk, and the approach is efficient, scalable, and well-suited to current methods.\n",
        "Examples: A proven method with minimal refinement needed, able to handle expected scenarios smoothly.\n",
        "Novelty Rubric:\n",
        "Novelty Rubric:\n",
        "\n",
        "Identical to Existing Methods (Rating 1)\n",
        "\n",
        "Contribution: The approach is nearly identical to prior implementations without any meaningful change or adaptation. It replicates existing work with no significant variation.\n",
        "Innovation: The idea offers no new insights or improvements over previous implementations.\n",
        "Examples: Direct repetition of previously applied techniques with no unique adaptations or variations.\n",
        "\n",
        "Minor Variations but Largely Follows Prior Work (Rating 2)\n",
        "\n",
        "Contribution: The approach introduces minor changes to previous implementations but does not make any significant contribution to the field.\n",
        "Innovation: There is some degree of originality, but the method or solution still aligns closely with previous work.\n",
        "Examples: Slight modifications to methods or frameworks that overlap heavily with existing solutions without adding substantial value.\n",
        "\n",
        "Some Novelty but Overlaps Significantly (Rating 3)\n",
        "\n",
        "Contribution: The idea introduces some novel elements or improvements compared to previous implementations, but the core concept or methodology remains similar to existing work.\n",
        "Innovation: It presents meaningful novelty but builds on the foundation of prior implementations.\n",
        "Examples: New applications or improvements that enhance the current method but don't fully break from previous models or implementations.\n",
        "\n",
        "Distinct Contributions (Rating 4)\n",
        "\n",
        "Contribution: The approach offers a significant advancement over prior implementations, incorporating new ideas, methods, or techniques that meaningfully differ from the existing work.\n",
        "Innovation: The idea is a clear departure from prior work, contributing new insights, frameworks, or strategies that advance the field.\n",
        "Examples: Introduction of new methodologies, algorithms, or frameworks that noticeably improve or expand upon existing solutions.\n",
        "\n",
        "Highly Novel and Groundbreaking (Rating 5)\n",
        "\n",
        "Contribution: The idea presents a groundbreaking shift or entirely new methodology that significantly deviates from previous work, leading to a major innovation in the field.\n",
        "Innovation: The approach introduces a disruptive concept that changes the understanding of the problem or solution, with far-reaching implications.\n",
        "Examples: A revolutionary idea that redefines current approaches or introduces a new paradigm, leading to major changes in the field.\n",
        "\n",
        "Feasible: Approaches rated 4-5.\n",
        "Infeasible: Approaches rated 1-3.\n",
        "Novelty Classification:\n",
        "\n",
        "Novel: Approaches rated 4-5.\n",
        "Not Novel: Approaches rated 1-3.\n",
        "\"\"\"\n",
        "    return prompt\n"
      ],
      "metadata": {
        "id": "72dgELUplOf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# user_input = input()\n"
      ],
      "metadata": {
        "id": "jHytjGTB_K68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "implementation = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0hSeB8sWJt2C",
        "outputId": "62eb89ec-8ea5-4878-9857-2ab8f1ea767c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Camouflaged object detection (COD) aims to detect/segment camouflaged objects embedded in the environment, which has attracted increasing attention over the past decades. Although several COD methods have been developed, they still suffer from unsatisfactory performance due to the intrinsic similarities between the foreground objects and background surroundings. In this paper, we propose a novel Feature Aggregation and Propagation Network (FAP-Net) for camouflaged object detection. Specifically, we propose a Boundary Guidance Module (BGM) to explicitly model the boundary characteristic, which can provide boundary-enhanced features to boost the COD performance. To capture the scale variations of the camouflaged objects, we propose a Multi-scale Feature Aggregation Module (MFAM) to characterize the multi-scale information from each layer and obtain the aggregated feature representations. Furthermore, we propose a Cross-level Fusion and Propagation Module (CFPM). In the CFPM, the feature fusion part can effectively integrate the features from adjacent layers to exploit the cross-level correlations, and the feature propagation part can transmit valuable context information from the encoder to the decoder network via a gate unit. Finally, we formulate a unified and end-to-end trainable framework where cross-level features can be effectively fused and propagated for capturing rich context information. Extensive experiments on three benchmark camouflaged datasets demonstrate that our FAP-Net outperforms other state-of-the-art COD models. Moreover, our model can be extended to the polyp segmentation task, and the comparison results further validate the effectiveness of the proposed model in segmenting polyps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# query = \"Given abstract and proposed solution \" + user_input + \"What are the key performance, scalability, and cost benefits of the proposed system compared to traditional approaches in [domain]? How does the new system address previous limitations and what new challenges or trade-offs does it introduce? What are the real-world implications and practical limitations of implementing this system, and how does its performance hold up under various conditions (e.g., workloads, resource allocation)\""
      ],
      "metadata": {
        "id": "z2RIhnWw_PHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query = ''' What are the sources, formats, and characteristics of datasets commonly used in ''' + topic"
      ],
      "metadata": {
        "id": "cH2Hh-2tJXey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# query='''What are the real-world constraints and practical challenges in deploying Proposed Solution at scale?'''+topic"
      ],
      "metadata": {
        "id": "yoC39SoBtLj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "limitation_query = f\"What are the limitations of {implementation}?\""
      ],
      "metadata": {
        "id": "RdLKGwOqtL3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(limitation_query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDuwxyL8PQ5P",
        "outputId": "f2d44a61-5ffe-4944-f59d-a2c2ff824d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are the limitations of Camouflaged object detection (COD) aims to detect/segment camouflaged objects embedded in the environment, which has attracted increasing attention over the past decades. Although several COD methods have been developed, they still suffer from unsatisfactory performance due to the intrinsic similarities between the foreground objects and background surroundings. In this paper, we propose a novel Feature Aggregation and Propagation Network (FAP-Net) for camouflaged object detection. Specifically, we propose a Boundary Guidance Module (BGM) to explicitly model the boundary characteristic, which can provide boundary-enhanced features to boost the COD performance. To capture the scale variations of the camouflaged objects, we propose a Multi-scale Feature Aggregation Module (MFAM) to characterize the multi-scale information from each layer and obtain the aggregated feature representations. Furthermore, we propose a Cross-level Fusion and Propagation Module (CFPM). In the CFPM, the feature fusion part can effectively integrate the features from adjacent layers to exploit the cross-level correlations, and the feature propagation part can transmit valuable context information from the encoder to the decoder network via a gate unit. Finally, we formulate a unified and end-to-end trainable framework where cross-level features can be effectively fused and propagated for capturing rich context information. Extensive experiments on three benchmark camouflaged datasets demonstrate that our FAP-Net outperforms other state-of-the-art COD models. Moreover, our model can be extended to the polyp segmentation task, and the comparison results further validate the effectiveness of the proposed model in segmenting polyps.?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(implementation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoG9Ca18aGmE",
        "outputId": "b1b7c59c-08b9-4d2d-a359-4c91187164ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Camouflaged object detection (COD) aims to detect/segment camouflaged objects embedded in the environment, which has attracted increasing attention over the past decades. Although several COD methods have been developed, they still suffer from unsatisfactory performance due to the intrinsic similarities between the foreground objects and background surroundings. In this paper, we propose a novel Feature Aggregation and Propagation Network (FAP-Net) for camouflaged object detection. Specifically, we propose a Boundary Guidance Module (BGM) to explicitly model the boundary characteristic, which can provide boundary-enhanced features to boost the COD performance. To capture the scale variations of the camouflaged objects, we propose a Multi-scale Feature Aggregation Module (MFAM) to characterize the multi-scale information from each layer and obtain the aggregated feature representations. Furthermore, we propose a Cross-level Fusion and Propagation Module (CFPM). In the CFPM, the feature fusion part can effectively integrate the features from adjacent layers to exploit the cross-level correlations, and the feature propagation part can transmit valuable context information from the encoder to the decoder network via a gate unit. Finally, we formulate a unified and end-to-end trainable framework where cross-level features can be effectively fused and propagated for capturing rich context information. Extensive experiments on three benchmark camouflaged datasets demonstrate that our FAP-Net outperforms other state-of-the-art COD models. Moreover, our model can be extended to the polyp segmentation task, and the comparison results further validate the effectiveness of the proposed model in segmenting polyps.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_results_implementations = search_faiss(implementation, top_k=6)\n",
        "\n",
        "retrieved_implementations = [result[0] for result in top_results_implementations]\n",
        "for i, result in enumerate(top_results_implementations, 1):\n",
        "    print(f\"Result {i}:\\nPaper - {result[1]}\\n\\n\")\n",
        "\n",
        "top_results_limitations = search_faiss(limitation_query, top_k=6)\n",
        "\n",
        "retrieved_limitations = [result[0] for result in top_results_limitations]\n",
        "for i, result in enumerate(top_results_limitations, 1):\n",
        "    print(f\"Result {i}:\\nPaper - {result[1]}\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKqCt3RM_WjD",
        "outputId": "d1217def-9e1e-4d9b-bf66-8944711d4cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result 1:\n",
            "Paper - Adaptive Graph Convolutional Recurrent Network.pdf\n",
            "\n",
            "\n",
            "Result 2:\n",
            "Paper - NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf\n",
            "\n",
            "\n",
            "Result 3:\n",
            "Paper - Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf\n",
            "\n",
            "\n",
            "Result 4:\n",
            "Paper - CogVideo Large-scale Pretraining for Text-to-Video.pdf\n",
            "\n",
            "\n",
            "Result 5:\n",
            "Paper - Noise Estimation Using Density Estimation.pdf\n",
            "\n",
            "\n",
            "Result 6:\n",
            "Paper - The CHERI capability model- Revisiting RISC in an age of risk.pdf\n",
            "\n",
            "\n",
            "Result 1:\n",
            "Paper - Adaptive Graph Convolutional Recurrent Network.pdf\n",
            "\n",
            "\n",
            "Result 2:\n",
            "Paper - NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf\n",
            "\n",
            "\n",
            "Result 3:\n",
            "Paper - Addressing-failure-prediction-by-learning-model-confidence-Paper.pdf\n",
            "\n",
            "\n",
            "Result 4:\n",
            "Paper - CogVideo Large-scale Pretraining for Text-to-Video.pdf\n",
            "\n",
            "\n",
            "Result 5:\n",
            "Paper - Noise Estimation Using Density Estimation.pdf\n",
            "\n",
            "\n",
            "Result 6:\n",
            "Paper - NEUROLM A UNIVERSAL MULTI-TASK FOUNDATION.pdf\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = input()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJyAufm4eKJA",
        "outputId": "f0b782b6-0fd2-44e6-85d6-a11c432c0300"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resource-Aware Saliency-Guided Differentiable Pruning for Deep Neural Networks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = create_prompt(query, retrieved_limitations, retrieved_implementations, implementation)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7yD3K5Y_qsP",
        "outputId": "474649a6-9f7e-4b2f-a47d-012479b60c28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are an AI assistant evaluating the feasibility and novelty of a research approach based on retrieved information. Only focus on the relevant limitations and implementations related to the query. Strictly ignore any unrelated content.\n",
            "\n",
            "**Query:**\n",
            "Resource-Aware Saliency-Guided Differentiable Pruning for Deep Neural Networks\n",
            "\n",
            "**Current Implementation:**\n",
            "The increasing demand for efficient deep learning model deployment on Tiny Machine Learning (tinyML) and Edge platforms necessitates the development of methods that enable automated and effective network pruning, tailored to tinyML hardware constraints. In this paper, we present a novel differentiable pruning method that accepts total available memory on a tinyML hardware and employs saliency based measurements to identify and prune less significant connections within a deep neural network (DNN). Our approach integrates network compression within the training process, adapting resource utilization to the specific constraints of FPGAs, particularly focusing on on-chip memory. By leveraging a custom tinyML accelerator, we enable an efficient hardware-software co-design. Our framework further quantizes the model to int-8 to optimize the balance between model size and accuracy, crucial for tinyML applications. The efficacy of our approach is examined for the compression of LeNet and VGG16 DNNs. When compared to similar state of the art pruning techniques, our approach for no drop in accuracy further compresses LeNet by 1.15 ×. In the case of VGG16, compared to the baseline implementation, for a 4% drop in accuracy we compress the model up to 55 ×. A comparative analysis of our FPGA hardware accelerator against leading image classification accelerators emphasizes the merits of our approach with a marked improvement in throughput by 1.46 × for LeNet and energy efficiency by 1.7 × for VGG16., Resource-Aware Saliency-Guided Differentiable Pruning for Deep Neural Networks\n",
            "\n",
            "**Retrieved Limitations (For Feasibility Analysis):**\n",
            "[' processing.\\nSection IIIpresents the available datasets, Section IVreviews\\nEEG artifacts and their types, and Section Vdiscusses the\\npreprocessing techniques used to remove these artifacts. Sec-\\ntionVIfocuses on the features of EEG and the methods used\\nfor their extraction. Section VIIdiscusses the most commonly\\nused classification techniques, and Section VIII presents\\nan overview of existing review papers. Finally, Section IX\\ndiscusses future research directions and concludes the paper.\\nOverall, this study provides up-to-date and comprehensive\\nreferences based on influential articles published in scholarly\\njournals and prime academic conferences after 2017 while\\nhighlighting open challenges and possibilities that should be\\naddressed to enhance the accuracy of the models.\\nA. MAIN CONTRIBUTIONS OF THIS STUDY\\nThis study provides new insights into the potential of EEG\\nsignals for diagnosing, monitoring, and managing brain\\ndisorders. While many survey articles have been published on\\nEEG signal processing, these articles often focus on general\\naspects of the field and do not provide a comprehensive\\noverview of EEG for medical diagnosis. In 2022, Orban et al.\\n[5]provided a comprehensive review of EEG; however, it also\\ndiscusses the development of natural interaction strategies,\\nwith a specific emphasis on EEG recording, preprocessing,\\nclassification of diseases, and control strategies. It does not\\nprovide insight into EEG in medical healthcare and diagnosis.\\nIn[6], the researchers presented an extensive review of EEG\\nsignaling but mainly focused on the general applications of\\nEEG-controlling devices. Reference [7]provides a review of\\nusing DL models for EEG signal processing; however, it only\\nfocuses on signal denoising and processing. The literature\\nreview reveals a lack of an extensive review of EEG signals\\nfor medical diagnosis, healthcare, and monitoring; this study\\npresents a comprehensive review with the following main\\ncontributions.\\nVOLUME 11, 2023 143117\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for M', 'ons, EEG is used in\\nneuromarketing and psychological studies to evaluate a\\npatient’s cognitive state, such as mood and anxiety. For\\nexample, brain-computer interface (BCI) involves moving\\nthe cursor on the screen using the brain, wheelchairs, and\\nmilitary scenarios [21]. EEG is recognized as one of the most\\nefficient imaging methods for detecting brain electric currents\\n143118 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 3. EEG of a healthy subject recorded for 200 seconds, broken\\ndown into the five main frequency bands of cerebral oscillations, also\\ncalled brainwaves.\\nTABLE 1. The five bands of EEG signals.\\ndue to the coordinated actions of hundreds of neurons.\\nThis approach offers high temporal resolution, which may\\nbe viewed on the screen as a digital representation of\\na continuous voltage flow. This technique can determine\\ncortical activity even at the lowest time intervals. EEG\\nis an essential tool for clinical and non-clinical settings,\\nand ongoing research continues to explore its potential\\napplications.\\nC. CURRENT CHALLENGES IN EEG PROCESSING\\nProcessing EEG signals poses several challenges that must be\\naddressed for accurate analysis. One of the most significant\\nchallenges is the Signal to Noise Ratio (SNR), and the\\npresence of different noise sources, such as artifacts or\\ninterference, which makes signal preprocessing difficult [23],\\n[24]. The SNR of the EEG is sensitive to external factors,\\nincluding light, smells, blinking, movement, temperature,\\nand controlled lab environments. These inherited noise\\nsources complicate their analysis as the EEG processingalgorithms work on an adequate quality of the signals.\\nVarious techniques can be utilized to overcome the challenge\\nof low SNR and external noise sources in EEG processing.\\nThese techniques include using high-quality electrodes,\\noptimal electrode placement, advanced signal filtering and\\ndenoising algorithms, and improved experimental setups and\\nstimulation techniques [22].\\n', 've sub-datasets (A-E) for healthy people\\nand patients with epilepsy. The data can be downloaded\\nfor free from http://epileptologie-bonn.de/. 100 EEG signal\\nrecordings last for 23.6 seconds per channel in each dataset.\\nFour phases are measured: surface EEG with open and closed\\neyes and intracranial EEG with interictal and seizure phases.\\nEach channel contains 4097 samples, sampled at a rate of\\n173.61 samples per second. The zip files of the datasets are\\navailable with labels. The Bonn dataset is not chosen for the\\ndevelopment of epilepsy prediction algorithms as it is only\\none channel and recorded for a shorter duration.\\nC. AMERICAN EPILEPSY SOCIETY DATASET\\nThis dataset [33] consists of EEG recordings of seven\\nparticipants for 1300 hours. The subjects are two humans and\\nfive canines with channels from 15 to 24 per subject. The\\nEEG recordings include a line noise of 60 Hz that could be\\nfixed using a notch filter [34].\\nFIGURE 5. Two records for EEG tracing of CHB12_23: (a) no seizure,\\n(b) seizure [31].\\nD. EUROPEAN EPILEPTIC DATASET\\nThe European Epileptic Dataset, part of the EU-funded\\nproject ‘‘EPILESIAE’’ [35], is one of the most comprehen-\\nsive data sources currently available. This dataset contains\\nEEG signals recorded for 300 subjects aged 13 to 67 years,\\nrepresenting a wide spectrum of epilepsy symptoms. A total\\nof 6488 hours of EEG recordings with more than 250 seizures\\nwere included in the dataset, of which 50 included intracra-\\nnial recordings with up to 122 channels. Datasets are\\navailable on http://epilepsy-database.eu/, but they must be\\npaid for. They are saved in.edf format. Moreover, the\\ndataset is not labeled as preictal, ictal, or interictal but\\ncan be analyzed based on the timing information of the\\nseizures.\\nE. EEG DATASET FOR ALZHEIMER\\nAlzheimer’s disease (AD) is a neurodegenerative disorder\\nthat causes memory loss, changes in behavior, and other\\ncognitive problems. They are most common in people over\\n65 but can occur at younger ages. Recently a new dataset\\nof EEG signals for Alzheimer’s has been de']\n",
            "\n",
            "**Retrieved Previous Implementations (For Novelty Analysis):**\n",
            "['ons, EEG is used in\\nneuromarketing and psychological studies to evaluate a\\npatient’s cognitive state, such as mood and anxiety. For\\nexample, brain-computer interface (BCI) involves moving\\nthe cursor on the screen using the brain, wheelchairs, and\\nmilitary scenarios [21]. EEG is recognized as one of the most\\nefficient imaging methods for detecting brain electric currents\\n143118 VOLUME 11, 2023\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for Medical Diagnosis, Healthcare, and Monitoring\\nFIGURE 3. EEG of a healthy subject recorded for 200 seconds, broken\\ndown into the five main frequency bands of cerebral oscillations, also\\ncalled brainwaves.\\nTABLE 1. The five bands of EEG signals.\\ndue to the coordinated actions of hundreds of neurons.\\nThis approach offers high temporal resolution, which may\\nbe viewed on the screen as a digital representation of\\na continuous voltage flow. This technique can determine\\ncortical activity even at the lowest time intervals. EEG\\nis an essential tool for clinical and non-clinical settings,\\nand ongoing research continues to explore its potential\\napplications.\\nC. CURRENT CHALLENGES IN EEG PROCESSING\\nProcessing EEG signals poses several challenges that must be\\naddressed for accurate analysis. One of the most significant\\nchallenges is the Signal to Noise Ratio (SNR), and the\\npresence of different noise sources, such as artifacts or\\ninterference, which makes signal preprocessing difficult [23],\\n[24]. The SNR of the EEG is sensitive to external factors,\\nincluding light, smells, blinking, movement, temperature,\\nand controlled lab environments. These inherited noise\\nsources complicate their analysis as the EEG processingalgorithms work on an adequate quality of the signals.\\nVarious techniques can be utilized to overcome the challenge\\nof low SNR and external noise sources in EEG processing.\\nThese techniques include using high-quality electrodes,\\noptimal electrode placement, advanced signal filtering and\\ndenoising algorithms, and improved experimental setups and\\nstimulation techniques [22].\\n', ' processing.\\nSection IIIpresents the available datasets, Section IVreviews\\nEEG artifacts and their types, and Section Vdiscusses the\\npreprocessing techniques used to remove these artifacts. Sec-\\ntionVIfocuses on the features of EEG and the methods used\\nfor their extraction. Section VIIdiscusses the most commonly\\nused classification techniques, and Section VIII presents\\nan overview of existing review papers. Finally, Section IX\\ndiscusses future research directions and concludes the paper.\\nOverall, this study provides up-to-date and comprehensive\\nreferences based on influential articles published in scholarly\\njournals and prime academic conferences after 2017 while\\nhighlighting open challenges and possibilities that should be\\naddressed to enhance the accuracy of the models.\\nA. MAIN CONTRIBUTIONS OF THIS STUDY\\nThis study provides new insights into the potential of EEG\\nsignals for diagnosing, monitoring, and managing brain\\ndisorders. While many survey articles have been published on\\nEEG signal processing, these articles often focus on general\\naspects of the field and do not provide a comprehensive\\noverview of EEG for medical diagnosis. In 2022, Orban et al.\\n[5]provided a comprehensive review of EEG; however, it also\\ndiscusses the development of natural interaction strategies,\\nwith a specific emphasis on EEG recording, preprocessing,\\nclassification of diseases, and control strategies. It does not\\nprovide insight into EEG in medical healthcare and diagnosis.\\nIn[6], the researchers presented an extensive review of EEG\\nsignaling but mainly focused on the general applications of\\nEEG-controlling devices. Reference [7]provides a review of\\nusing DL models for EEG signal processing; however, it only\\nfocuses on signal denoising and processing. The literature\\nreview reveals a lack of an extensive review of EEG signals\\nfor medical diagnosis, healthcare, and monitoring; this study\\npresents a comprehensive review with the following main\\ncontributions.\\nVOLUME 11, 2023 143117\\nN. S. Amer, S. B. Belhaouari: EEG Signal Processing for M', 've sub-datasets (A-E) for healthy people\\nand patients with epilepsy. The data can be downloaded\\nfor free from http://epileptologie-bonn.de/. 100 EEG signal\\nrecordings last for 23.6 seconds per channel in each dataset.\\nFour phases are measured: surface EEG with open and closed\\neyes and intracranial EEG with interictal and seizure phases.\\nEach channel contains 4097 samples, sampled at a rate of\\n173.61 samples per second. The zip files of the datasets are\\navailable with labels. The Bonn dataset is not chosen for the\\ndevelopment of epilepsy prediction algorithms as it is only\\none channel and recorded for a shorter duration.\\nC. AMERICAN EPILEPSY SOCIETY DATASET\\nThis dataset [33] consists of EEG recordings of seven\\nparticipants for 1300 hours. The subjects are two humans and\\nfive canines with channels from 15 to 24 per subject. The\\nEEG recordings include a line noise of 60 Hz that could be\\nfixed using a notch filter [34].\\nFIGURE 5. Two records for EEG tracing of CHB12_23: (a) no seizure,\\n(b) seizure [31].\\nD. EUROPEAN EPILEPTIC DATASET\\nThe European Epileptic Dataset, part of the EU-funded\\nproject ‘‘EPILESIAE’’ [35], is one of the most comprehen-\\nsive data sources currently available. This dataset contains\\nEEG signals recorded for 300 subjects aged 13 to 67 years,\\nrepresenting a wide spectrum of epilepsy symptoms. A total\\nof 6488 hours of EEG recordings with more than 250 seizures\\nwere included in the dataset, of which 50 included intracra-\\nnial recordings with up to 122 channels. Datasets are\\navailable on http://epilepsy-database.eu/, but they must be\\npaid for. They are saved in.edf format. Moreover, the\\ndataset is not labeled as preictal, ictal, or interictal but\\ncan be analyzed based on the timing information of the\\nseizures.\\nE. EEG DATASET FOR ALZHEIMER\\nAlzheimer’s disease (AD) is a neurodegenerative disorder\\nthat causes memory loss, changes in behavior, and other\\ncognitive problems. They are most common in people over\\n65 but can occur at younger ages. Recently a new dataset\\nof EEG signals for Alzheimer’s has been de']\n",
            "\n",
            "**Evaluation Criteria:**\n",
            "\n",
            "Feasibility Rubric:\n",
            "1. Highly Impractical (Rating 1)\n",
            "\n",
            "Challenges: The approach faces fundamental flaws, such as severe technical limitations, critical errors in assumptions, or unsolvable scalability issues.\n",
            "Implementation: The idea cannot be realistically executed with existing tools or methods and would fail under typical conditions.\n",
            "Risk: There are significant risks (e.g., security, performance) that cannot be easily mitigated or are likely to lead to failure.\n",
            "Examples: Security issues that cannot be resolved, approaches that are computationally unfeasible at scale, or major technical hurdles without clear solutions.\n",
            "2. Challenging to Implement (Rating 2)\n",
            "\n",
            "Challenges: The idea presents significant obstacles, such as major performance bottlenecks, security risks, or issues with scalability that would make it difficult to execute effectively.\n",
            "Implementation: The idea requires substantial adjustments or resources to become viable, and careful planning is necessary for success.\n",
            "Risk: High risk, including issues that could lead to significant failure unless properly managed.\n",
            "Examples: Major data bottlenecks, scalability challenges, or risks of model instability (like hallucinations) that require significant innovation or effort to mitigate.\n",
            "3. Feasible with Significant Effort (Rating 3)\n",
            "\n",
            "Challenges: The approach is achievable but faces clear challenges that need to be addressed, such as optimization, error handling, or complex dependencies.\n",
            "Implementation: The idea can be executed, but substantial resources, testing, and refinement are required.\n",
            "Risk: Moderate risk, where careful management of the process is needed to avoid potential pitfalls (e.g., handling edge cases, scalability).\n",
            "Examples: A viable idea but requires significant engineering work, model fine-tuning, and optimization to be effective and scalable.\n",
            "4. Mostly Feasible with Some Risk (Rating 4)\n",
            "\n",
            "Challenges: The approach works well in most conditions with only minor risks or challenges that can be addressed through optimization or incremental improvements.\n",
            "Implementation: Practical to implement with manageable risks, requiring some refinement but no major adjustments to current resources.\n",
            "Risk: Low risk, where the approach is likely to succeed but with some areas needing attention (e.g., improving model stability).\n",
            "Examples: A solution that can be scaled with moderate adjustments or where only minor technical challenges remain.\n",
            "5. Highly Feasible with Minimal or No Risk (Rating 5)\n",
            "\n",
            "Challenges: The approach is fully practical, and any minor limitations can be easily addressed.\n",
            "Implementation: Ready to be implemented without major risks or limitations.\n",
            "Risk: Very low risk, and the approach is efficient, scalable, and well-suited to current methods.\n",
            "Examples: A proven method with minimal refinement needed, able to handle expected scenarios smoothly.\n",
            "Novelty Rubric:\n",
            "Novelty Rubric:\n",
            "\n",
            "Identical to Existing Methods (Rating 1)\n",
            "\n",
            "Contribution: The approach is nearly identical to prior implementations without any meaningful change or adaptation. It replicates existing work with no significant variation.\n",
            "Innovation: The idea offers no new insights or improvements over previous implementations.\n",
            "Examples: Direct repetition of previously applied techniques with no unique adaptations or variations.\n",
            "\n",
            "Minor Variations but Largely Follows Prior Work (Rating 2)\n",
            "\n",
            "Contribution: The approach introduces minor changes to previous implementations but does not make any significant contribution to the field.\n",
            "Innovation: There is some degree of originality, but the method or solution still aligns closely with previous work.\n",
            "Examples: Slight modifications to methods or frameworks that overlap heavily with existing solutions without adding substantial value.\n",
            "\n",
            "Some Novelty but Overlaps Significantly (Rating 3)\n",
            "\n",
            "Contribution: The idea introduces some novel elements or improvements compared to previous implementations, but the core concept or methodology remains similar to existing work.\n",
            "Innovation: It presents meaningful novelty but builds on the foundation of prior implementations.\n",
            "Examples: New applications or improvements that enhance the current method but don't fully break from previous models or implementations.\n",
            "\n",
            "Distinct Contributions (Rating 4)\n",
            "\n",
            "Contribution: The approach offers a significant advancement over prior implementations, incorporating new ideas, methods, or techniques that meaningfully differ from the existing work.\n",
            "Innovation: The idea is a clear departure from prior work, contributing new insights, frameworks, or strategies that advance the field.\n",
            "Examples: Introduction of new methodologies, algorithms, or frameworks that noticeably improve or expand upon existing solutions.\n",
            "\n",
            "Highly Novel and Groundbreaking (Rating 5)\n",
            "\n",
            "Contribution: The idea presents a groundbreaking shift or entirely new methodology that significantly deviates from previous work, leading to a major innovation in the field.\n",
            "Innovation: The approach introduces a disruptive concept that changes the understanding of the problem or solution, with far-reaching implications.\n",
            "Examples: A revolutionary idea that redefines current approaches or introduces a new paradigm, leading to major changes in the field.\n",
            "\n",
            "Feasible: Approaches rated 4-5.\n",
            "Infeasible: Approaches rated 1-3.\n",
            "Novelty Classification:\n",
            "\n",
            "Novel: Approaches rated 4-5.\n",
            "Not Novel: Approaches rated 1-3.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5jjCc-lNtw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}